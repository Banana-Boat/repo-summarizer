{"index": 0, "repo": "spring-cloud-aws-jdbc-2.2.6.RELEASE", "code": "Interface DatabasePlatformSupport {\n\t// Constructs the database URL for the database instance.\n\tString getDatabaseUrlForDatabase(DatabaseType databaseType, String hostname, int port, String databaseName);\n\t// Returns the fully qualified driver class name for the database platform.\n\tString getDriverClassNameForDatabase(DatabaseType databaseType);\n}", "des": "Support interface used by the DataSourceFactory implementation to retrieve the necessary configuration data for every database platform. As databases platform have differences in the URL scheme, driver class name this interface provides an abstraction to retrieve the information based on the particular database platform."}
{"index": 1, "repo": "spring-cloud-aws-jdbc-2.2.6.RELEASE", "code": "Enum DatabaseType {\n\tstatic DatabaseType fromEngine(String engineName);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DatabaseType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DatabaseType[] values();\n}", "des": "Enumeration that holds all supported databases. The enumeration is mainly driven by the supported databases by the underlying AWS cloud implementation."}
{"index": 2, "repo": "spring-cloud-aws-jdbc-2.2.6.RELEASE", "code": "Interface DataSourceFactory {\n\t// Will be called if the datasource is not used anymore to allow the factory to release any resource that are used by the created object.\n\tvoid closeDataSource(DataSource dataSource);\n\t// Creates a datasource with the passed in information.\n\tDataSource createDataSource(DataSourceInformation dataSourceInformation);\n}", "des": "Factory to create DataSource instances at runtime. In contrast to the regular datasource definitions, this interface allows the dynamic creation of datasource at runtime. This is especially useful and needed if the datasource information like the url, username and password are not available at configuration time. With this factory it is possible to create datasource with configuration information which is fetched while starting the application. Because of the dynamic creation of datasource at runtime, this interface also provides the lifecycle method closeDataSource(javax.sql.DataSource) to actually shutdown the created datasource. This method should be called while destroying the application itself."}
{"index": 3, "repo": "spring-cloud-aws-jdbc-2.2.6.RELEASE", "code": "Enum InstanceStatus {\n\t// Operation that returns true if the database is available from the Amazon RDS perspective.\n\tboolean isAvailable();\n\t// Operation that returns true if a second call will likely succeed.\n\tboolean isRetryable();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic InstanceStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic InstanceStatus[] values();\n}", "des": "Enumeration that holds all possible Amazon RDS database instance states. Used by client code to check if the database is available at all, and to verify if a retry is useful."}
{"index": 4, "repo": "spring-cloud-aws-jdbc-2.2.6.RELEASE", "code": "Class RdbmsRetryOperationsInterceptor {\n\t// Checks that there is no retry operation open before delegating to the method RetryOperationsInterceptor.invoke(org.aopalliance.intercept.MethodInvocation) method.\n\tObject invoke(org.aopalliance.intercept.MethodInvocation invocation);\n\t// Returns whenever there is already a proxy running inside this thread execution.\n\tprotected boolean isRetryContextOperationActive();\n}", "des": "Subclass of RetryOperationsInterceptor that checks that there is no transaction available while starting a retryable operation. This class also ensures that there is only one outer retry operation in case of nested retryable methods."}
{"index": 5, "repo": "spring-cloud-aws-jdbc-2.2.6.RELEASE", "code": "Class SqlRetryPolicy {\n\t// Returns if this method is retryable based on the RetryContext.\n\tboolean canRetry(org.springframework.retry.RetryContext context);\n\tvoid close(org.springframework.retry.RetryContext context);\n\torg.springframework.retry.RetryContext open(org.springframework.retry.RetryContext parent);\n\tvoid registerThrowable(org.springframework.retry.RetryContext context, Throwable throwable);\n\t// Configures the maximum number of retries.\n\tvoid setMaxNumberOfRetries(int maxNumberOfRetries);\n}", "des": "RetryPolicy implementation that checks for database error which are retryable. Normally this are well known exceptions inside the JDBC (1.6) exception hierarchy and also the Spring DataAccessException hierarchy. In addition to that, this class also tries for permanent exception which are related to a connection of the database. This is useful because Amazon RDS database instances might be retryable even if there is a permanent error. This is typically the case in a master a/z failover where the source instance might not be available but a second attempt might succeed because the DNS record has been updated to the failover instance."}
{"index": 6, "repo": "spring-cloud-aws-jdbc-2.2.6.RELEASE", "code": "Class StaticDatabasePlatformSupport {\n\tprotected Map<DatabaseType,String> getAuthenticationInfo();\n\t// Template method that must be implemented in order to retrieve all driver class names for every supported database platform.\n\tprotected Map<DatabaseType,String> getDriverClassNameMappings();\n\t// Template method that mus be implemented to get all scheme names for every supported database platform.\n\tprotected Map<DatabaseType,String> getSchemeNames();\n}", "des": "Simple implementation that holds statically all information for the database platform."}
{"index": 7, "repo": "connect-api-3.5.0", "code": "Class AbstractState {\n\tboolean equals(Object o);\n\t// Provides the current state of the connector or task.\n\tString state();\n\t// The error message associated with the connector or task.\n\tString traceMessage();\n\t// The identifier of the worker associated with the connector or the task.\n\tString workerId();\n}", "des": "Provides the current status for a connector or a task, along with an identifier for its Connect worker"}
{"index": 8, "repo": "connect-api-3.5.0", "code": "Interface ConnectClusterState {\n\t// Get details about the setup of the Connect cluster.\n\tdefault ConnectClusterDetails clusterDetails();\n\t// Lookup the current configuration of a connector.\n\tdefault Map<String,String> connectorConfig(String connName);\n\t// Lookup the current health of a connector and its tasks.\n\tConnectorHealth connectorHealth(String connName);\n\t// Get the names of the connectors currently deployed in this cluster.\n\tCollection<String> connectors();\n}", "des": "Provides the ability to lookup connector metadata, including status and configurations, as well as immutable cluster information such as Kafka cluster ID. This is made available to ConnectRestExtension implementations. The Connect framework provides the implementation for this interface."}
{"index": 9, "repo": "connect-api-3.5.0", "code": "Interface ConnectorContext {\n\t// Raise an unrecoverable exception to the Connect framework.\n\tvoid raiseError(Exception e);\n\t// Requests that the runtime reconfigure the Tasks for this source.\n\tvoid requestTaskReconfiguration();\n}", "des": "ConnectorContext allows Connectors to proactively interact with the Kafka Connect runtime."}
{"index": 10, "repo": "connect-api-3.5.0", "code": "Class ConnectorHealth {\n\t// Provides the current state of the connector.\n\tConnectorState connectorState();\n\tboolean equals(Object o);\n\t// Provides the name of the connector.\n\tString name();\n\t// Provides the current state of the connector tasks.\n\tMap<Integer,TaskState> tasksState();\n\t// Provides the type of the connector.\n\tConnectorType type();\n}", "des": "Provides basic health information about the connector and its tasks."}
{"index": 11, "repo": "connect-api-3.5.0", "code": "Enum ConnectorTransactionBoundaries {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConnectorTransactionBoundaries valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConnectorTransactionBoundaries[] values();\n}", "des": "An enum to represent the level of support for connector-defined transaction boundaries."}
{"index": 12, "repo": "connect-api-3.5.0", "code": "Enum ConnectorType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConnectorType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConnectorType[] values();\n}", "des": "Enum definition that identifies the type of the connector."}
{"index": 13, "repo": "connect-api-3.5.0", "code": "Interface ConnectRestExtensionContext {\n\t// Provides the cluster state and health information about the connectors and tasks.\n\tConnectClusterState clusterState();\n\t// Provides an implementation of Configurable that can be used to register JAX-RS resources.\n\tjavax.ws.rs.core.Configurable<? extends javax.ws.rs.core.Configurable<?>> configurable();\n}", "des": "The interface provides the ability for ConnectRestExtension implementations to access the JAX-RS Configurable and cluster state ConnectClusterState. The implementation for the interface is provided by the Connect framework."}
{"index": 14, "repo": "connect-api-3.5.0", "code": "Class ConverterConfig {\n\t// Create a new ConfigDef instance containing the configurations defined by ConverterConfig.\n\tstatic org.apache.kafka.common.config.ConfigDef newConfigDef();\n\t// Get the type of converter as defined by the TYPE_CONFIG configuration.\n\tConverterType type();\n}", "des": "Abstract class that defines the configuration options for Converter and HeaderConverter instances."}
{"index": 15, "repo": "connect-api-3.5.0", "code": "Enum ConverterType {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConverterType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConverterType[] values();\n\t// Find the ConverterType with the given name, using a case-insensitive match.\n\tstatic ConverterType withName(String name);\n}", "des": "The type of Converter and HeaderConverter."}
{"index": 16, "repo": "connect-api-3.5.0", "code": "Class Date {\n\t// Returns a SchemaBuilder for a Date.\n\tstatic SchemaBuilder builder();\n\t// Convert a value from its logical format (Date) to its encoded format (int).\n\tstatic int fromLogical(Schema schema, Date value);\n\t// Convert a value from its encoded format (int) to its logical format (Date).\n\tstatic Date toLogical(Schema schema, int value);\n}", "des": ""}
{"index": 17, "repo": "connect-api-3.5.0", "code": "Class Decimal {\n\t// Returns a SchemaBuilder for a Decimal with the given scale factor.\n\tstatic SchemaBuilder builder(int scale);\n\t// Convert a value from its logical format (BigDecimal) to its encoded format (byte[]).\n\tstatic byte[] fromLogical(Schema schema, BigDecimal value);\n\tstatic Schema schema(int scale);\n\t// Convert a value from its encoded format (byte[]) to its logical format (BigDecimal).\n\tstatic BigDecimal toLogical(Schema schema, byte[] value);\n}", "des": ""}
{"index": 18, "repo": "connect-api-3.5.0", "code": "Enum ExactlyOnceSupport {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExactlyOnceSupport valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExactlyOnceSupport[] values();\n}", "des": "An enum to represent the level of support for exactly-once semantics from a source connector."}
{"index": 19, "repo": "connect-api-3.5.0", "code": "Class Field {\n\tboolean equals(Object o);\n\t// Get the index of this field within the struct.\n\tint index();\n\t// Get the name of this field.\n\tString name();\n\t// Get the schema of this field\n\tSchema schema();\n}", "des": ""}
{"index": 20, "repo": "connect-api-3.5.0", "code": "Interface HeaderConverter {\n\t// Configuration specification for this set of header converters.\n\torg.apache.kafka.common.config.ConfigDef config();\n\t// Convert the Header's value into its byte array representation.\n\tbyte[] fromConnectHeader(String topic, String headerKey, Schema schema, Object value);\n\t// Convert the header name and byte array value into a Header object.\n\tSchemaAndValue toConnectHeader(String topic, String headerKey, byte[] value);\n}", "des": "The HeaderConverter interface provides support for translating between Kafka Connect's runtime data format and byte[]. This is similar to the Converter interface, but specifically for Headers."}
{"index": 21, "repo": "connect-api-3.5.0", "code": "Interface OffsetStorageReader {\n\t// Get the offset for the specified partition.\n\t<T> Map<String,Object> offset(Map<String,T> partition);\n\t// Get a set of offsets for the specified partition identifiers.\n\t<T> Map<Map<String,T>,Map<String,Object>> offsets(Collection<Map<String,T>> partitions);\n}", "des": ""}
{"index": 22, "repo": "connect-api-3.5.0", "code": "Interface Predicate<R extends ConnectRecord<R>> {\n\tvoid close();\n\t// Configuration specification for this predicate.\n\torg.apache.kafka.common.config.ConfigDef config();\n\t// Returns whether the given record satisfies this predicate.\n\tboolean test(R record);\n}", "des": ""}
{"index": 23, "repo": "connect-api-3.5.0", "code": "Enum Schema.Type {\n\tString getName();\n\tboolean isPrimitive();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Schema.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Schema.Type[] values();\n}", "des": "The type of a schema. These only include the core types; logical types must be determined by checking the schema name."}
{"index": 24, "repo": "connect-api-3.5.0", "code": "Class SimpleHeaderConverter {\n\tvoid close();\n\t// Configuration specification for this set of header converters.\n\torg.apache.kafka.common.config.ConfigDef config();\n\tvoid configure(Map<String,?> configs);\n\t// Convert the Header's value into its byte array representation.\n\tbyte[] fromConnectHeader(String topic, String headerKey, Schema schema, Object value);\n\t// Convert the header name and byte array value into a Header object.\n\tSchemaAndValue toConnectHeader(String topic, String headerKey, byte[] value);\n}", "des": "A HeaderConverter that serializes header values as strings and that deserializes header values to the most appropriate numeric, boolean, array, or map representation. Schemas are not serialized, but are inferred upon deserialization when possible."}
{"index": 25, "repo": "connect-api-3.5.0", "code": "Class SourceConnector {\n\t// Signals whether the connector implementation is capable of defining the transaction boundaries for a connector with the given configuration.\n\tConnectorTransactionBoundaries canDefineTransactionBoundaries(Map<String,String> connectorConfig);\n\t// Signals whether the connector supports exactly-once semantics with a proposed configuration.\n\tExactlyOnceSupport exactlyOnceSupport(Map<String,String> connectorConfig);\n}", "des": "SourceConnectors implement the connector interface to pull data from another system and send it to Kafka."}
{"index": 26, "repo": "connect-api-3.5.0", "code": "Enum SourceTask.TransactionBoundary {\n\t// Parse a SourceTask.TransactionBoundary from the given string.\n\tstatic SourceTask.TransactionBoundary fromProperty(String property);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SourceTask.TransactionBoundary valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SourceTask.TransactionBoundary[] values();\n}", "des": "Represents the permitted values for the SourceTask.TRANSACTION_BOUNDARY_CONFIG property."}
{"index": 27, "repo": "connect-api-3.5.0", "code": "Interface SourceTaskContext {\n\t// Get the Task configuration.\n\tMap<String,String> configs();\n\t// Get the OffsetStorageReader for this SourceTask.\n\tOffsetStorageReader offsetStorageReader();\n\t// Get a TransactionContext that can be used to define producer transaction boundaries when exactly-once support is enabled for the connector.\n\tdefault TransactionContext transactionContext();\n}", "des": "SourceTaskContext is provided to SourceTasks to allow them to interact with the underlying runtime."}
{"index": 28, "repo": "connect-api-3.5.0", "code": "Interface Task {\n\t// Start the Task\n\tvoid start(Map<String,String> props);\n\t// Stop this task.\n\tvoid stop();\n\t// Get the version of this task.\n\tString version();\n}", "des": ""}
{"index": 29, "repo": "connect-api-3.5.0", "code": "Class Time {\n\t// Returns a SchemaBuilder for a Time.\n\tstatic SchemaBuilder builder();\n\t// Convert a value from its logical format (Date) to its encoded format (int).\n\tstatic int fromLogical(Schema schema, Date value);\n\t// Convert a value from its encoded format (int) to its logical format (Date).\n\tstatic Date toLogical(Schema schema, int value);\n}", "des": ""}
{"index": 30, "repo": "connect-api-3.5.0", "code": "Class Timestamp {\n\t// Returns a SchemaBuilder for a Timestamp.\n\tstatic SchemaBuilder builder();\n\t// Convert a value from its logical format (Date) to its encoded format (long).\n\tstatic long fromLogical(Schema schema, Date value);\n\t// Convert a value from its encoded format (long) to its logical format (Date).\n\tstatic Date toLogical(Schema schema, long value);\n}", "des": ""}
{"index": 31, "repo": "connect-api-3.5.0", "code": "Interface TransactionContext {\n\t// Requests a transaction abort after the next batch of records from SourceTask.poll().\n\tvoid abortTransaction();\n\t// Requests a transaction abort after a source record is processed.\n\tvoid abortTransaction(SourceRecord record);\n\t// Request a transaction commit after the next batch of records from SourceTask.poll() is processed.\n\tvoid commitTransaction();\n\t// Request a transaction commit after a source record is processed.\n\tvoid commitTransaction(SourceRecord record);\n}", "des": "Provided to source tasks to allow them to define their own producer transaction boundaries when exactly-once support is enabled."}
{"index": 32, "repo": "connect-api-3.5.0", "code": "Interface Transformation<R extends ConnectRecord<R>> {\n\t// Apply transformation to the record and return another record object (which may be record itself) or null, corresponding to a map or filter operation respectively.\n\tR apply(R record);\n\t// Signal that this transformation instance will no longer will be used.\n\tvoid close();\n\t// Configuration specification for this transformation.\n\torg.apache.kafka.common.config.ConfigDef config();\n}", "des": "Single message transformation for Kafka Connect record types."}
{"index": 33, "repo": "hadoop-yarn-client-3.3.6", "code": "Enum NMClientAsyncImpl.ContainerEventType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NMClientAsyncImpl.ContainerEventType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NMClientAsyncImpl.ContainerEventType[] values();\n}", "des": "The type of the event of interacting with a container"}
{"index": 34, "repo": "phoenix-core-5.1.3", "code": "Interface Aggregator {\n\t// Incrementally aggregate the value with the current row\n\tvoid aggregate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\t// Get the size in bytes\n\tint getSize();\n\t// Determines whether or not we should track the heap size as this aggregator is executing on the server side.\n\tboolean trackSize();\n}", "des": "Interface to abstract the incremental calculation of an aggregated value."}
{"index": 35, "repo": "phoenix-core-5.1.3", "code": "Class AtomicMetric {\n\t// Change the metric by the specified amount\n\tvoid change(long delta);\n\t// Decrease the value of metric by 1\n\tvoid decrement();\n\tString getCurrentMetricState();\n\tMetricType getMetricType();\n\tlong getValue();\n\t// Increase the value of metric by 1\n\tvoid increment();\n\t// Reset the metric\n\tvoid reset();\n}", "des": "Version of Metric that can be used when the metric is being concurrently accessed or modified by multiple threads."}
{"index": 36, "repo": "phoenix-core-5.1.3", "code": "Class BaseAggregator {\n\t// Means of traversing expression tree through visitor.\n\t<T> T accept(ExpressionVisitor<T> visitor);\n\t// Get the size in bytes\n\tint getSize();\n\tboolean isNullable();\n\t// Determines whether or not we should track the heap size as this aggregator is executing on the server side.\n\tboolean trackSize();\n}", "des": "Base class for Aggregator implementations"}
{"index": 37, "repo": "phoenix-core-5.1.3", "code": "Class BaseParseNodeVisitor<E> {\n\tvoid addElement(List<E> l, E element);\n\tList<E> newElementList(int size);\n\t// Fall through visit method.\n\tE visit(ParseNode expressionNode);\n\t// Fall through visitEnter method.\n\tboolean visitEnter(CompoundParseNode expressionNode);\n\tE visitLeave(CompoundParseNode expressionNode, List<E> l);\n}", "des": "Base class for parse node visitors."}
{"index": 38, "repo": "phoenix-core-5.1.3", "code": "Class BaseQueryServicesImpl {\n\tvoid close();\n\t// Get executor service used for parallel scans\n\tThreadPoolExecutor getExecutor();\n\t// Get the memory manager used to track memory usage\n\tMemoryManager getMemoryManager();\n\t// Get query optimizer used to choose the best query plan\n\tQueryOptimizer getOptimizer();\n\t// Get the properties from the HBase configuration in a read-only structure that avoids any synchronization\n\tReadOnlyProps getProps();\n}", "des": "Base class for QueryService implementors."}
{"index": 39, "repo": "phoenix-core-5.1.3", "code": "Class CeilParseNode {\n\t// Entry point for parser to instantiate compiled representation of built-in function\n\tExpression create(List<Expression> children, StatementContext context);\n\t// When ceiling off decimals, user need not specify the scale.\n\tboolean evalToNullIfParamIsNull(StatementContext context, int index);\n\tstatic Expression getCeilExpression(List<Expression> children);\n}", "des": "Parse node corresponding to CeilFunction. It also acts as a factory for creating the right kind of ceil expression according to the data type of the first child."}
{"index": 40, "repo": "phoenix-core-5.1.3", "code": "Class ChildMemoryManager {\n\t// Allocate up to reqBytes of memory, dialing the amount down to minBytes if full amount is not available.\n\tMemoryManager.MemoryChunk allocate(long minBytes, long nBytes);\n\t// Get the amount of available memory (in bytes) not yet allocated.\n\tlong getAvailableMemory();\n\t// Get the total amount of memory (in bytes) that may be allocated.\n\tlong getMaxMemory();\n}", "des": "Child memory manager that delegates through to global memory manager, but enforces that at most a threshold percentage is used by this memory manager. No blocking is done if the threshold is exceeded, but the standard blocking will be done by the global memory manager."}
{"index": 41, "repo": "phoenix-core-5.1.3", "code": "Class ClientProcessingPlan {\n\tStatementContext getContext();\n\tInteger getLimit();\n\tInteger getOffset();\n\t// Return the compiled Order By clause of SelectStatement.\n\tOrderByCompiler.OrderBy getOrderBy();\n\t// Returns projector used to formulate resultSet row\n\tRowProjector getProjector();\n\tFilterableStatement getStatement();\n\tTableRef getTableRef();\n\tExpression getWhere();\n}", "des": "Query plan that does where, order-by limit at client side, which is for derived-table queries that cannot be flattened by SubselectRewriter."}
{"index": 42, "repo": "phoenix-core-5.1.3", "code": "Class Closeables {\n\t// Allows you to close as many of the Closeables as possible.\n\tstatic void closeAll(Iterable<? extends Closeable> iterable);\n\tstatic IOException closeAllQuietly(Iterable<? extends Closeable> iterable);\n\t// Close a Closeable, returning an IOException if it occurs while closing instead of throwing it.\n\tstatic IOException closeQuietly(Closeable closeable);\n}", "des": "Utilities for operating on Closeables."}
{"index": 43, "repo": "phoenix-core-5.1.3", "code": "Class CoalesceFunction {\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n\tInteger getMaxLength();\n\tString getName();\n\tboolean isNullable();\n\t// Determines if an evaluate is required after partial evaluation is run.\n\tboolean requiresFinalEvaluation();\n}", "des": "Function used to provide an alternative value when the first argument is null. Usage: COALESCE(expr1,expr2) If expr1 is not null, then it is returned, otherwise expr2 is returned. TODO: better bind parameter type matching, since arg2 must be coercible to arg1. consider allowing a common base type?"}
{"index": 44, "repo": "phoenix-core-5.1.3", "code": "Class CollationKeyFunction {\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n\tString getName();\n\tboolean isNullable();\n\t// Used to determine if the same ScalarFunction instance may be used by multiple threads.\n\tboolean isThreadSafe();\n\tvoid readFields(DataInput input);\n}", "des": "A Phoenix Function that calculates a collation key for an input string based on a caller-provided locale and collator strength and decomposition settings. The locale should be specified as xx_yy_variant where xx is the ISO 639-1 2-letter language code, yy is the the ISO 3166 2-letter country code. Both countryCode and variant are optional. For example, zh_TW_STROKE, zh_TW and zh are all valid locale representations. Note the language code, country code and variant are used as arguments to the constructor of java.util.Locale. This function originally used the open-source i18n-util package to obtain the collators it needs from the provided locale. As i18n-util is not maintained anymore, the relevant parts from it were copied into Phoenix. See: https://issues.apache.org/jira/browse/PHOENIX-6818 The LinguisticSort implementation from i18n-util encapsulates sort-related functionality for a substantive list of locales. For each locale, it provides a collator and an Oracle-specific database function that can be used to sort strings according to the natural language rules of that locale. This function uses the collator returned by LinguisticSort.getCollator to produce a collation key for its input string. A user can expect that the sorting semantics of this function for a given locale is equivalent to the sorting behaviour of an Oracle query that is constructed using the Oracle functions returned by LinguisticSort for that locale. The optional third argument to the function is a boolean that specifies whether to use the upper-case collator (case-insensitive) returned by LinguisticSort.getUpperCaseCollator. The optional fourth and fifth arguments are used to set respectively the strength and composition of the collator returned by LinguisticSort using the setStrength and setDecomposition methods of java.text.Collator."}
{"index": 45, "repo": "phoenix-core-5.1.3", "code": "Interface ColumnProjector {\n\t// Get the expression\n\tExpression getExpression();\n\t// Get the column name as it was referenced in the query\n\tString getName();\n\t// Get the name of the hbase table containing the column\n\tString getTableName();\n\t// Get the value of the column, coercing it if necessary to the specified type\n\tObject getValue(Tuple tuple, PDataType type, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tboolean isCaseSensitive();\n}", "des": "Interface used to access the value of a projected column."}
{"index": 46, "repo": "phoenix-core-5.1.3", "code": "Interface ColumnValueEncoder {\n\t// append a value that is not present to the array (used to support DEFAULT expressions)\n\tvoid appendAbsentValue();\n\t// append a column value to the array\n\tvoid appendValue(byte[] bytes, int offset, int length);\n\tbyte[] encode();\n}", "des": "Interface to encode column values into a serialized byte[] that will be stored in a single cell The last byte of the serialized byte[] should be the serialized value of the PTable.ImmutableStorageScheme that was used."}
{"index": 47, "repo": "phoenix-core-5.1.3", "code": "Class ComparisonParseNode {\n\t<T> T accept(ParseNodeVisitor<T> visitor);\n\t// Return the comparison operator associated with the given comparison expression node\n\tabstract org.apache.hadoop.hbase.filter.CompareFilter.CompareOp getFilterOp();\n\t// Return the inverted operator for the CompareOp\n\tabstract org.apache.hadoop.hbase.filter.CompareFilter.CompareOp getInvertFilterOp();\n\tvoid toSQL(ColumnResolver resolver, StringBuilder buf);\n}", "des": "Common base class =, >, >=, <, <=, !="}
{"index": 48, "repo": "phoenix-core-5.1.3", "code": "Class CSVCommonsLoader {\n\t// Translate a field separator, escape character, or phrase delimiter into a control character if it is a single digit other than 0.\n\tstatic char asControlCharacter(char delimiter);\n\torg.apache.commons.csv.CSVFormat getFormat();\n\t// Data is batched up based on connection batch size.\n\tvoid upsert(org.apache.commons.csv.CSVParser csvParser);\n\tvoid upsert(Reader reader);\n\t// Upserts data from CSV file.\n\tvoid upsert(String fileName);\n}", "des": "Upserts CSV data using Phoenix JDBC connection"}
{"index": 49, "repo": "phoenix-core-5.1.3", "code": "Class DefaultValueExpression {\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n\tInteger getMaxLength();\n\tString getName();\n\tboolean isNullable();\n\t// Determines if an evaluate is required after partial evaluation is run.\n\tboolean requiresFinalEvaluation();\n}", "des": "Internal function used to get the default value for a column not specified in UPSERT. If expr1 is evaluated (can be null), then it is returned, otherwise expr2 is returned."}
{"index": 50, "repo": "phoenix-core-5.1.3", "code": "Class DelegateQueryServices {\n\tvoid close();\n\tprotected QueryServices getDelegate();\n\t// Get executor service used for parallel scans\n\tThreadPoolExecutor getExecutor();\n\t// Get the memory manager used to track memory usage\n\tMemoryManager getMemoryManager();\n\t// Get query optimizer used to choose the best query plan\n\tQueryOptimizer getOptimizer();\n\t// Get the properties from the HBase configuration in a read-only structure that avoids any synchronization\n\tReadOnlyProps getProps();\n}", "des": "Class that delegates QueryService calls through to a parent QueryService."}
{"index": 51, "repo": "phoenix-core-5.1.3", "code": "Class DistinctCountHyperLogLogAggregateFunction {\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tDistinctCountClientAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n}", "des": "Built-in function for Distinct Count Aggregation function in approximation. This aggregator is implemented using HyperLogLog. Please refer to PHOENIX-418 https://issues.apache.org/jira/browse/PHOENIX-418 1, Accuracy input is not a customizeable. In HyperLogLog accuracy is propertional to 1/sqrt(m), m is the size of the hll hash. Also, this process is irrelavent to runtime or space complexity. 2, The two parameters that requires during HLL initialization. i.e., the precision value for the normal set and the precision value for the sparse set, is hard coded as static final variable. Any change of them requires re-deployment of the phoenix server coprocessors."}
{"index": 52, "repo": "phoenix-core-5.1.3", "code": "Class EmptyScanner {\n\tvoid close();\n\tApplyAndFilterDeletesFilter.DeleteTracker getDeleteTracker();\n\torg.apache.hadoop.hbase.Cell next();\n\t// Read the KeyValue at the top of this without 'popping' it off the top of the scanner.\n\torg.apache.hadoop.hbase.Cell peek();\n\t// Seek to immediately before the given KeyValue.\n\tboolean seek(org.apache.hadoop.hbase.Cell next);\n}", "des": "Scanner that has no underlying data"}
{"index": 53, "repo": "phoenix-core-5.1.3", "code": "Class EnvironmentEdgeManager {\n\t// Defers to the delegate and calls the EnvironmentEdge.currentTime() method.\n\tstatic long currentTimeMillis();\n\t// Retrieves the singleton instance of the EnvironmentEdge that is being managed.\n\tstatic EnvironmentEdge getDelegate();\n\t// Injects the given edge such that it becomes the managed entity.\n\tstatic void injectEdge(EnvironmentEdge edge);\n\t// Resets the managed instance to the default instance: DefaultEnvironmentEdge.\n\tstatic void reset();\n}", "des": "Manages a singleton instance of the environment edge. This class shall implement static versions of the interface EnvironmentEdge, then defer to the delegate on invocation."}
{"index": 54, "repo": "phoenix-core-5.1.3", "code": "Class EqualParseNode {\n\t// Return the comparison operator associated with the given comparison expression node\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getFilterOp();\n\t// Return the inverted operator for the CompareOp\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getInvertFilterOp();\n}", "des": "Node representing the equal operator in SQL"}
{"index": 55, "repo": "phoenix-core-5.1.3", "code": "Class EquiDepthStreamHistogram {\n\t// Add a new value to the histogram, updating the count for the appropriate bucket\n\tvoid addValue(byte[] value);\n\t// Compute the buckets, which have the boundaries and estimated counts.\n\tList<EquiDepthStreamHistogram.Bucket> computeBuckets();\n\tlong getTotalCount();\n}", "des": "Equi-Depth histogram based on http://web.cs.ucla.edu/~zaniolo/papers/Histogram-EDBT2011-CamReady.pdf, but without the sliding window - we assume a single window over the entire data set. Used to generate the bucket boundaries of a histogram where each bucket has the same # of items. This is useful, for example, for pre-splitting an index table, by feeding in data from the indexed column. Works on streaming data - the histogram is dynamically updated for each new value. Add values by calling addValue(), then at the end computeBuckets() can be called to get the buckets with their bounds. Average time complexity: O(log(B x p) + (B x p)/T) = nearly constant B = number of buckets, p = expansion factor constant, T = # of values Space complexity: different from paper since here we keep the blocked bars but don't have expiration, comes out to basically O(log(T))"}
{"index": 56, "repo": "phoenix-core-5.1.3", "code": "Class ExpressionProjector {\n\t// Get the expression\n\tExpression getExpression();\n\t// Get the column name as it was referenced in the query\n\tString getName();\n\t// Get the name of the hbase table containing the column\n\tString getTableName();\n\t// Get the value of the column, coercing it if necessary to the specified type\n\tObject getValue(Tuple tuple, PDataType type, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tboolean isCaseSensitive();\n}", "des": "Projector for getting value from a select statement for an expression"}
{"index": 57, "repo": "phoenix-core-5.1.3", "code": "Class FilteredKeyValueScanner {\n\tvoid close();\n\t// Same a KeyValueScanner#next() except that we filter out the next KeyValue until we find one that passes the filter.\n\torg.apache.hadoop.hbase.Cell next();\n\t// Read the KeyValue at the top of this without 'popping' it off the top of the scanner.\n\torg.apache.hadoop.hbase.Cell peek();\n\tboolean reseek(org.apache.hadoop.hbase.Cell key);\n\t// Seek to immediately before the given KeyValue.\n\tboolean seek(org.apache.hadoop.hbase.Cell key);\n}", "des": "Combine a simplified version of the logic in the ScanQueryMatcher and the KeyValueScanner. We can get away with this here because we are only concerned with a single MemStore for the index; we don't need to worry about multiple column families or minimizing seeking through file - we just want to iterate the kvs quickly, in-memory."}
{"index": 58, "repo": "phoenix-core-5.1.3", "code": "Class FirstValueFunction {\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for FIRST_VALUE() WITHIN GROUP (ORDER BY ASC/DESC) aggregate function"}
{"index": 59, "repo": "phoenix-core-5.1.3", "code": "Class FirstValuesFunction {\n\tPDataType getDataType();\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for FIRST_VALUES(, ) WITHIN GROUP (ORDER BY ASC/DESC) aggregate function"}
{"index": 60, "repo": "phoenix-core-5.1.3", "code": "Class FloorParseNode {\n\t// Entry point for parser to instantiate compiled representation of built-in function\n\tExpression create(List<Expression> children, StatementContext context);\n\t// When rounding off decimals, user need not specify the scale.\n\tboolean evalToNullIfParamIsNull(StatementContext context, int index);\n\tstatic Expression getFloorExpression(List<Expression> children);\n}", "des": "Parse node corresponding to FloorFunction. It also acts as a factory for creating the right kind of floor expression according to the data type of the first child."}
{"index": 61, "repo": "phoenix-core-5.1.3", "code": "Enum GlobalClientMetrics {\n\tvoid decrement();\n\tGlobalMetric getMetric();\n\tstatic Collection<GlobalMetric> getMetrics();\n\tMetricType getMetricType();\n\tvoid increment();\n\tstatic boolean isMetricsEnabled();\n\tvoid update(long value);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GlobalClientMetrics valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GlobalClientMetrics[] values();\n}", "des": "Central place where we keep track of all the global client phoenix metrics. These metrics are different from ReadMetricQueue or MutationMetricQueue as they are collected at the client JVM level as opposed to the above two which are collected for every phoenix request."}
{"index": 62, "repo": "phoenix-core-5.1.3", "code": "Class GlobalMetricImpl {\n\t// Change the metric by the specified amount\n\tvoid change(long delta);\n\t// Decrease the value of metric by 1\n\tvoid decrement();\n\tString getCurrentMetricState();\n\tMetricType getMetricType();\n\tlong getNumberOfSamples();\n\tlong getValue();\n\t// Increase the value of metric by 1\n\tvoid increment();\n\t// Reset the internal state.\n\tvoid reset();\n}", "des": "Default implementation used when GlobalMetrics are enabled"}
{"index": 63, "repo": "phoenix-core-5.1.3", "code": "Class GreaterThanOrEqualParseNode {\n\t// Return the comparison operator associated with the given comparison expression node\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getFilterOp();\n\t// Return the inverted operator for the CompareOp\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getInvertFilterOp();\n}", "des": "Node representing the greater than or equal to operator (>=) in SQL"}
{"index": 64, "repo": "phoenix-core-5.1.3", "code": "Class GreaterThanParseNode {\n\t// Return the comparison operator associated with the given comparison expression node\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getFilterOp();\n\t// Return the inverted operator for the CompareOp\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getInvertFilterOp();\n}", "des": "Node representing the greater than operator (>) in SQL"}
{"index": 65, "repo": "phoenix-core-5.1.3", "code": "Class GuidePostsCacheImpl {\n\t// Returns the PTableStats for the given tableName, using the provided valueLoader if no such mapping exists.\n\tGuidePostsInfo get(GuidePostsKey key);\n\t// Removes the mapping for tableName if it exists.\n\tvoid invalidate(GuidePostsKey key);\n\t// Removes all mappings from the cache.\n\tvoid invalidateAll();\n\t// Cache the given stats to the cache for the given tableName.\n\tvoid put(GuidePostsKey key, GuidePostsInfo info);\n}", "des": "\"Client-side\" cache for storing GuidePostsInfo for a column family. Intended to decouple Phoenix from a specific version of Guava's cache."}
{"index": 66, "repo": "phoenix-core-5.1.3", "code": "Class IndexKeyValueSkipListSet {\n\t// Create a new IndexKeyValueSkipListSet based on the passed comparator.\n\tstatic IndexKeyValueSkipListSet create(org.apache.hadoop.hbase.CellComparator comparator);\n\t// Add the passed KeyValue to the set, only if one is not already set.\n\torg.apache.hadoop.hbase.Cell putIfAbsent(org.apache.hadoop.hbase.Cell kv);\n}", "des": "Like a KeyValueSkipListSet, but also exposes useful, atomic methods (e.g. #putIfAbsent(KeyValue))."}
{"index": 67, "repo": "phoenix-core-5.1.3", "code": "Enum IndexScrutinyTool.SourceTable {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IndexScrutinyTool.SourceTable valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IndexScrutinyTool.SourceTable[] values();\n}", "des": "Which table to use as the source table"}
{"index": 68, "repo": "phoenix-core-5.1.3", "code": "Class IndexToolUtil {\n\t// Updates the index state.\n\tstatic void updateIndexState(org.apache.hadoop.conf.Configuration configuration, PIndexState state);\n\t// Updates the index state.\n\tstatic void updateIndexState(Connection connection, String masterTable, String indexTable, PIndexState state);\n}", "des": "Utility class for IndexTool"}
{"index": 69, "repo": "phoenix-core-5.1.3", "code": "Class IndexUtil.IndexStatusUpdater {\n\t// Update the Empty cell values to VERIFIED in the passed keyValues list\n\tvoid setVerified(org.apache.hadoop.hbase.CellScanner cellScanner);\n\t// Update the Empty cell values to VERIFIED in the passed keyValues list\n\tvoid setVerified(List<org.apache.hadoop.hbase.Cell> keyValues);\n}", "des": "Updates the EMPTY cell value to VERIFIED for global index table rows."}
{"index": 70, "repo": "phoenix-core-5.1.3", "code": "Class InstanceResolver {\n\tstatic void clearSingletons();\n\t// Resolves all instances of a specified class and add it to the list of default implementations\n\tstatic <T> List get(Class<T> clazz, List<T> defaultInstances);\n\t// Resolves an instance of the specified class if it has not already been resolved.\n\tstatic <T> T getSingleton(Class<T> clazz, T defaultInstance);\n}", "des": "Resolves object instances registered using the JDK 6+ ServiceLoader."}
{"index": 71, "repo": "phoenix-core-5.1.3", "code": "Class LastValueFunction {\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for LAST_VALUE() WITHIN GROUP (ORDER BY ASC/DESC) aggregate function"}
{"index": 72, "repo": "phoenix-core-5.1.3", "code": "Class LastValuesFunction {\n\tPDataType getDataType();\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for FIRST_VALUES(, ) WITHIN GROUP (ORDER BY ASC/DESC) aggregate function"}
{"index": 73, "repo": "phoenix-core-5.1.3", "code": "Class LessThanOrEqualParseNode {\n\t// Return the comparison operator associated with the given comparison expression node\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getFilterOp();\n\t// Return the inverted operator for the CompareOp\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getInvertFilterOp();\n}", "des": "Node representing the less than or equal to operator (<=) in SQL"}
{"index": 74, "repo": "phoenix-core-5.1.3", "code": "Class LessThanParseNode {\n\t// Return the comparison operator associated with the given comparison expression node\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getFilterOp();\n\t// Return the inverted operator for the CompareOp\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getInvertFilterOp();\n}", "des": "Node representing the less than operator (<) in SQL"}
{"index": 75, "repo": "phoenix-core-5.1.3", "code": "Enum LocaleUtils {\n\tstatic LocaleUtils get();\n\t// Returns a locale for language-only (\"en\") or language/country (\"en_UK\") iso codes\n\tLocale getLocaleByIsoCode(String isoCode);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LocaleUtils valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LocaleUtils[] values();\n}", "des": "This utility class was partially copied from Salesforce's internationalization utility library (com.salesforce.i18n:i18n-util:1.0.4), which was released under the 3-clause BSD License. The i18n-util library is not maintained anymore, and it was using vulnerable dependencies. For more info, see: https://issues.apache.org/jira/browse/PHOENIX-6818 A collection of utilities for dealing with Locales."}
{"index": 76, "repo": "phoenix-core-5.1.3", "code": "Class LockManager {\n\tLockManager.RowLock lockRow(byte[] row, int waitDuration);\n\t// Lock the row or throw otherwise\n\tLockManager.RowLock lockRow(ImmutableBytesPtr rowKey, int waitDuration);\n\t// Unlock the row.\n\tvoid unlockRow(byte[] row);\n}", "des": "Class, copied for the most part from HRegion.getRowLockInternal implementation that manages reentrant row locks based on the row key. Phoenix needs to manage it's own locking due to secondary indexes needing a consistent snapshot from the time the mvcc is acquired until the time it is advanced (PHOENIX-4053)."}
{"index": 77, "repo": "phoenix-core-5.1.3", "code": "Interface LogWriter {\n\t// will be called when disruptor is getting shutdown\n\tvoid close();\n\t// if writer is closed and cannot write further event\n\tboolean isClosed();\n\t// Called by ring buffer event handler to write RingBufferEvent\n\tvoid write(org.apache.phoenix.log.RingBufferEvent event);\n}", "des": "Used by the event handler to write RingBufferEvent, this is done in a separate thread from the application configured during disruptor"}
{"index": 78, "repo": "phoenix-core-5.1.3", "code": "Interface MemoryManager.MemoryChunk {\n\t// Free up the memory associated with this chunk\n\tvoid close();\n\t// Get the size in bytes of the allocated chunk.\n\tlong getSize();\n\t// Resize an already allocated memory chunk up or down to a new amount.\n\tvoid resize(long nBytes);\n}", "des": "Chunk of allocated memory. To reclaim the memory, call close()"}
{"index": 79, "repo": "phoenix-core-5.1.3", "code": "Class MergeSortResultIterator {\n\tvoid close();\n\tprotected abstract int compare(Tuple t1, Tuple t2);\n\t// Grab the next row's worth of values.\n\tTuple next();\n\t// Returns the next result without advancing the iterator\n\tTuple peek();\n}", "des": "Base class for a ResultIterator that does a merge sort on the list of iterators provided."}
{"index": 80, "repo": "phoenix-core-5.1.3", "code": "Interface Metric {\n\t// Change the metric by the specified amount\n\tvoid change(long delta);\n\t// Decrease the value of metric by 1\n\tvoid decrement();\n\tString getCurrentMetricState();\n\tMetricType getMetricType();\n\tlong getValue();\n\t// Increase the value of metric by 1\n\tvoid increment();\n\t// Reset the metric\n\tvoid reset();\n}", "des": "Interface that represents phoenix-internal metric."}
{"index": 81, "repo": "phoenix-core-5.1.3", "code": "Enum MetricInfo {\n\tstatic String getColumnName(String traceName);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MetricInfo valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MetricInfo[] values();\n}", "des": "Metrics and their conversion from the trace name to the name we store in the stats table"}
{"index": 82, "repo": "phoenix-core-5.1.3", "code": "Interface MetricsPhoenixTTLSource {\n\t// Report the number of requests to mask TTL expired rows.\n\tlong getDeleteExpiredRequestCount();\n\t// Report the number of requests to mask TTL expired rows.\n\tlong getMaskExpiredRequestCount();\n\t// Keeps track of the number of requests to delete TTL expired rows.\n\tvoid incrementDeleteExpiredRequestCount();\n\t// Keeps track of the number of requests to mask TTL expired rows.\n\tvoid incrementMaskExpiredRequestCount();\n}", "des": "Interface for metrics about PhoenixTTLRegionObserver."}
{"index": 83, "repo": "phoenix-core-5.1.3", "code": "Class MetricsPhoenixTTLSourceImpl {\n\t// Report the number of requests to mask TTL expired rows.\n\tlong getDeleteExpiredRequestCount();\n\t// Report the number of requests to mask TTL expired rows.\n\tlong getMaskExpiredRequestCount();\n\t// Keeps track of the number of requests to delete TTL expired rows.\n\tvoid incrementDeleteExpiredRequestCount();\n\t// Keeps track of the number of requests to mask TTL expired rows.\n\tvoid incrementMaskExpiredRequestCount();\n}", "des": "Implementation for tracking PhoenixTTLRegionObserver metrics."}
{"index": 84, "repo": "phoenix-core-5.1.3", "code": "Enum MetricType {\n\tString columnName();\n\tPDataType dataType();\n\tString description();\n\tstatic String getMetricColumnsDetails();\n\tboolean isLoggingEnabled(LogLevel connectionLogLevel);\n\tLogLevel logLevel();\n\tString shortName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MetricType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MetricType[] values();\n}", "des": "Keeping LogLevel.OFF for metrics which are calculated globally only and doesn't need to be logged in SYSTEM.LOG"}
{"index": 85, "repo": "phoenix-core-5.1.3", "code": "Class MinAggregateFunction {\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tString getName();\n\tSortOrder getSortOrder();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for finding MIN."}
{"index": 86, "repo": "phoenix-core-5.1.3", "code": "Class ModulusExpression {\n\t// Means of traversing expression tree through visitor.\n\t<T> T accept(ExpressionVisitor<T> visitor);\n\tArithmeticExpression clone(List<Expression> children);\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n\tprotected String getOperatorString();\n}", "des": "Implementation of the LENGTH() build-in function. is the string of characters we want to find the length of. If is NULL or empty, null is returned."}
{"index": 87, "repo": "phoenix-core-5.1.3", "code": "Class NoOpGlobalMetricImpl {\n\t// Change the metric by the specified amount\n\tvoid change(long delta);\n\t// Decrease the value of metric by 1\n\tvoid decrement();\n\tString getCurrentMetricState();\n\tMetricType getMetricType();\n\tlong getNumberOfSamples();\n\tlong getValue();\n\t// Increase the value of metric by 1\n\tvoid increment();\n\t// Reset the metric\n\tvoid reset();\n}", "des": "Implementation used when GlobalMetrics are disabled"}
{"index": 88, "repo": "phoenix-core-5.1.3", "code": "Class NotEqualParseNode {\n\t// Return the comparison operator associated with the given comparison expression node\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getFilterOp();\n\t// Return the inverted operator for the CompareOp\n\torg.apache.hadoop.hbase.filter.CompareFilter.CompareOp getInvertFilterOp();\n}", "des": "Node representing a not equal expression (!=,<>) in SQL"}
{"index": 89, "repo": "phoenix-core-5.1.3", "code": "Class NotExpression {\n\t// Means of traversing expression tree through visitor.\n\t<T> T accept(ExpressionVisitor<T> visitor);\n\tstatic Expression create(Expression child, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n}", "des": "Implementation of the NOT operator that negates it's single boolean child expression."}
{"index": 90, "repo": "phoenix-core-5.1.3", "code": "Class NthValueFunction {\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for NTH_VALUE(, ) WITHIN GROUP (ORDER BY ASC/DESC) aggregate function"}
{"index": 91, "repo": "phoenix-core-5.1.3", "code": "Enum OracleUpperTable {\n\tstatic OracleUpperTable forLinguisticSort(String sort);\n\tLocale getLocale();\n\tString getSql(String expr);\n\tString getSqlFormatString();\n\tString toUpperCase(String value);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OracleUpperTable valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OracleUpperTable[] values();\n}", "des": "This utility class was partially copied from Salesforce's internationalization utility library (com.salesforce.i18n:i18n-util:1.0.4), which was released under the 3-clause BSD License. The i18n-util library is not maintained anymore, and it was using vulnerable dependencies. For more info, see: https://issues.apache.org/jira/browse/PHOENIX-6818 Generated by i18n.OracleUpperTableGeneratorTest"}
{"index": 92, "repo": "phoenix-core-5.1.3", "code": "Class OrderedAggregatingResultIterator {\n\t// Provides a means of re-aggregating a result row.\n\tAggregator[] aggregate(Tuple result);\n\tprotected AggregatingResultIterator getDelegate();\n\t// Grab the next row's worth of values.\n\tTuple next();\n}", "des": "Result scanner that sorts aggregated rows by columns specified in the ORDER BY clause."}
{"index": 93, "repo": "phoenix-core-5.1.3", "code": "Class ParseNode {\n\tabstract <T> T accept(ParseNodeVisitor<T> visitor);\n\t// Allows node to override what the alias is for a given node.\n\tString getAlias();\n\tabstract List<ParseNode> getChildren();\n\t// Returns whether this ParseNode is a SubqueryParseNode or contains any SubqueryParseNode descendant.\n\tboolean hasSubquery();\n\tboolean isStateless();\n\tabstract void toSQL(ColumnResolver resolver, StringBuilder buf);\n}", "des": "Abstract base class for a parse node in SQL"}
{"index": 94, "repo": "phoenix-core-5.1.3", "code": "Class PercentileContAggregateFunction {\n\tPDataType getDataType();\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tDistinctValueWithCountClientAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for PERCENTILE_CONT() WITHIN GROUP (ORDER BY ASC/DESC) aggregate function"}
{"index": 95, "repo": "phoenix-core-5.1.3", "code": "Class PercentileDiscAggregateFunction {\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tDistinctValueWithCountClientAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for PERCENTILE_DISC() WITHIN GROUP (ORDER BY ASC/DESC) aggregate function"}
{"index": 96, "repo": "phoenix-core-5.1.3", "code": "Class PercentRankAggregateFunction {\n\tPDataType getDataType();\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tDistinctValueWithCountClientAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "PERCENT_RANK([,]) WITHIN GROUP (ORDER BY [,] ASC/DESC) aggregate function"}
{"index": 97, "repo": "phoenix-core-5.1.3", "code": "Enum PhoenixConfigurationUtil.MRJobType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PhoenixConfigurationUtil.MRJobType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PhoenixConfigurationUtil.MRJobType[] values();\n}", "des": "Determines type of Phoenix Map Reduce job. 1. QUERY allows running arbitrary queries without aggregates 2. UPDATE_STATS collects statistics for the table"}
{"index": 98, "repo": "phoenix-core-5.1.3", "code": "Class PhoenixContextExecutor {\n\t// Execute an operation (synchronously) using the context classloader used to load this class, instead of the currently-set context classloader of the current thread.\n\tstatic <T> T call(Callable<T> target);\n\t// Same as call(java.util.concurrent.Callable), but doesn't throw checked exceptions.\n\tstatic <T> T callWithoutPropagation(Callable<T> target);\n\tstatic CallWrapper inContext();\n}", "des": "Executes Callables using a context classloader that is set up to load classes from Phoenix. Loading HBase configuration settings and endpoint coprocessor classes is done via the context classloader of the calling thread. When Phoenix is being run via a JDBC-enabled GUI, the driver is often loaded dynamically and executed via multiple threads, which makes it difficult or impossible to predict the state of the classloader hierarchy in the current thread. This class is intended to get around that, to ensure that the same classloader used to load Phoenix classes is set as the context classloader for specific calls."}
{"index": 99, "repo": "phoenix-core-5.1.3", "code": "Enum PhoenixIndexToolJobCounters {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PhoenixIndexToolJobCounters valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PhoenixIndexToolJobCounters[] values();\n}", "des": "Counters used for Index Tool MR job"}
{"index": 100, "repo": "phoenix-core-5.1.3", "code": "Enum PhoenixJobCounters {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PhoenixJobCounters valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PhoenixJobCounters[] values();\n}", "des": "Counters used during Map Reduce jobs"}
{"index": 101, "repo": "phoenix-core-5.1.3", "code": "Enum PhoenixScrutinyJobCounters {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PhoenixScrutinyJobCounters valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PhoenixScrutinyJobCounters[] values();\n}", "des": "Counters used for Index Scrutiny MR job"}
{"index": 102, "repo": "phoenix-core-5.1.3", "code": "Interface PhoenixStatsLoader {\n\t// Called by client stats cache to load stats from underneath layers\n\tGuidePostsInfo loadStats(GuidePostsKey statsKey);\n\t// Called by client stats cache to load stats from underneath layers\n\tGuidePostsInfo loadStats(GuidePostsKey statsKey, GuidePostsInfo prevGuidepostInfo);\n\t// Use to check whether this is the time to load stats from stats table.\n\tboolean needsLoad();\n}", "des": "The interface for talking to underneath layers to load stats from stats table for a given key"}
{"index": 103, "repo": "phoenix-core-5.1.3", "code": "Class PhoenixStopWatch {\n\t// Returns the current elapsed time shown on this stopwatch, expressed in milliseconds.\n\tlong elapsedMillis();\n\t// Returns true if start() has been called on this stopwatch, and stop() has not been called since the last call to start().\n\tboolean isRunning();\n\t// Starts the stopwatch.\n\tPhoenixStopWatch start();\n\t// Stops the stopwatch.\n\tPhoenixStopWatch stop();\n}", "des": "Bare-bones implementation of a stop watch that only measures time in milliseconds. If you want to be fancy then please use the guava Stopwatch. However, be warned that the Guava's Stopwatch is a beta class and is subject to incompatible changes and removal. So save the future upgrade pain and use this class instead."}
{"index": 104, "repo": "phoenix-core-5.1.3", "code": "Enum PhoenixTransactionContext.PhoenixVisibilityLevel {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PhoenixTransactionContext.PhoenixVisibilityLevel valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PhoenixTransactionContext.PhoenixVisibilityLevel[] values();\n}", "des": "Visibility levels needed for checkpointing and"}
{"index": 105, "repo": "phoenix-core-5.1.3", "code": "Interface PName {\n\t// Get the server-side name as referenced in HBase-related APIs such as Scan, Filter, etc.\n\tbyte[] getBytes();\n\tImmutableBytesPtr getBytesPtr();\n\tint getEstimatedSize();\n\t// Get the client-side, normalized name as referenced in a SQL statement.\n\tString getString();\n}", "des": "Interface to encapsulate both the client-side name together with the server-side name for a named object"}
{"index": 106, "repo": "phoenix-core-5.1.3", "code": "Class PrefixByteDecoder {\n\t// Decodes bytes encoded with PrefixByteEncoder.\n\torg.apache.hadoop.hbase.io.ImmutableBytesWritable decode(DataInput in);\n\t// Resets state of decoder if it will be used to decode bytes from a different DataInput.\n\tvoid reset();\n}", "des": "Prefix decoder for byte arrays. For encoding, see PrefixByteEncoder."}
{"index": 107, "repo": "phoenix-core-5.1.3", "code": "Class PTable.EncodedCQCounter {\n\t// Copy constructor\n\tstatic PTable.EncodedCQCounter copy(PTable.EncodedCQCounter counterToCopy);\n\t// Get the next qualifier to be used for the column family.\n\tInteger getNextQualifier(String columnFamily);\n\tboolean increment(String columnFamily);\n\tvoid setValue(String columnFamily, Integer value);\n\tMap<String,Integer> values();\n}", "des": "Class to help track encoded column qualifier counters per column family."}
{"index": 108, "repo": "phoenix-core-5.1.3", "code": "Interface QueryServices {\n\t// Get executor service used for parallel scans\n\tThreadPoolExecutor getExecutor();\n\t// Get the memory manager used to track memory usage\n\tMemoryManager getMemoryManager();\n\t// Get query optimizer used to choose the best query plan\n\tQueryOptimizer getOptimizer();\n\t// Get the properties from the HBase configuration in a read-only structure that avoids any synchronization\n\tReadOnlyProps getProps();\n}", "des": "Interface to group together services needed during querying. The parameters that may be set in Configuration are documented here: https://github.com/forcedotcom/phoenix/wiki/Tuning"}
{"index": 109, "repo": "phoenix-core-5.1.3", "code": "Class RoundParseNode {\n\t// Entry point for parser to instantiate compiled representation of built-in function\n\tExpression create(List<Expression> children, StatementContext context);\n\t// When rounding off decimals, user need not specify the scale.\n\tboolean evalToNullIfParamIsNull(StatementContext context, int index);\n\tstatic Expression getRoundExpression(List<Expression> children);\n}", "des": "Parse node corresponding to RoundFunction. It also acts as a factory for creating the right kind of round expression according to the data type of the first child."}
{"index": 110, "repo": "phoenix-core-5.1.3", "code": "Class RowKeyBytesStringFunction {\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n\tString getName();\n\tboolean isStateless();\n\t// Determines whether or not the result of the function invocation will be ordered in the same way as the input to the function.\n\tFunctionExpression.OrderPreserving preservesOrder();\n}", "des": "Function to return Rowkey(s) of result(s) in a printable/usable format. The returned result can be used for debugging(eg. using HBase shell), logging etc."}
{"index": 111, "repo": "phoenix-core-5.1.3", "code": "Class RowKeyValueAccessor {\n\tboolean equals(Object obj);\n\tint getIndex();\n\t// Calculate the length of the PK column value\n\tint getLength(byte[] keyBuffer, int keyOffset, int maxOffset);\n\t// Calculate the byte offset in the row key to the start of the PK column value\n\tint getOffset(byte[] keyBuffer, int keyOffset);\n\tvoid readFields(DataInput input);\n\tvoid write(DataOutput output);\n}", "des": "Class that encapsulates accessing a value stored in the row key."}
{"index": 112, "repo": "phoenix-core-5.1.3", "code": "Interface Scanner {\n\torg.apache.hadoop.hbase.Cell next();\n\t// Read the KeyValue at the top of this without 'popping' it off the top of the scanner.\n\torg.apache.hadoop.hbase.Cell peek();\n\t// Seek to immediately before the given KeyValue.\n\tboolean seek(org.apache.hadoop.hbase.Cell next);\n}", "des": "Scan the primary table. This is similar to HBase's scanner, but ensures that you will never see deleted columns/rows"}
{"index": 113, "repo": "phoenix-core-5.1.3", "code": "Interface ServerCachingProtocol {\n\t// Add the cache to the region server cache.\n\tboolean addServerCache(byte[] tenantId, byte[] cacheId, org.apache.hadoop.hbase.io.ImmutableBytesWritable cachePtr, byte[] txState, ServerCachingProtocol.ServerCacheFactory cacheFactory);\n\t// Remove the cache from the region server cache.\n\tboolean removeServerCache(byte[] tenantId, byte[] cacheId);\n}", "des": "EndPoint coprocessor to send a cache to a region server. Used for: a) hash joins, to send the smaller side of the join to each region server b) secondary indexes, to send the necessary meta data to each region server"}
{"index": 114, "repo": "phoenix-core-5.1.3", "code": "Class SignFunction {\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n\tString getName();\n\t// Determines whether or not the result of the function invocation will be ordered in the same way as the input to the function.\n\tFunctionExpression.OrderPreserving preservesOrder();\n}", "des": "Base class for built-in SIGN function."}
{"index": 115, "repo": "phoenix-core-5.1.3", "code": "Class SpillFile {\n\tvoid close();\n\t// Create a new SpillFile using the Java TempFile creation function.\n\tstatic SpillFile createSpillFile(File spillFilesDir);\n\t// Random access to a page of the current spill file\n\tRandomAccessFile getPage(int index);\n}", "des": "This class abstracts a SpillFile It is a accessible on a per page basis For every SpillFile object a single spill file is always created. Additional overflow files are dynamically created in case the page index requested is not covered by the spillFiles allocated so far"}
{"index": 116, "repo": "phoenix-core-5.1.3", "code": "Enum SQLExceptionCode {\n\tstatic SQLExceptionCode fromErrorCode(int errorCode);\n\tint getErrorCode();\n\tSQLExceptionCode.Factory getExceptionFactory();\n\tString getMessage();\n\tString getSQLState();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SQLExceptionCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SQLExceptionCode[] values();\n}", "des": "Various SQLException Information. Including a vendor-specific errorcode and a standard SQLState."}
{"index": 117, "repo": "phoenix-core-5.1.3", "code": "Class StddevPopFunction {\n\tPDataType getDataType();\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tDistinctValueWithCountClientAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for STDDEV_POP() aggregate function"}
{"index": 118, "repo": "phoenix-core-5.1.3", "code": "Class StddevSampFunction {\n\tPDataType getDataType();\n\tString getName();\n\t// Create the aggregator to do client-side aggregation based on the results returned from the aggregating coprocessor.\n\tDistinctValueWithCountClientAggregator newClientAggregator();\n\t// Create the aggregator to do server-side aggregation.\n\tAggregator newServerAggregator(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Built-in function for STDDEV_SAMP() aggregate function"}
{"index": 119, "repo": "phoenix-core-5.1.3", "code": "Class StringConcatExpression {\n\t// Means of traversing expression tree through visitor.\n\t<T> T accept(ExpressionVisitor<T> visitor);\n\t// Access the value by setting a pointer to it (as opposed to making a copy of it which can be expensive)\n\tboolean evaluate(Tuple tuple, org.apache.hadoop.hbase.io.ImmutableBytesWritable ptr);\n\tPDataType getDataType();\n\t// Determines if an evaluate is required after partial evaluation is run.\n\tboolean requiresFinalEvaluation();\n}", "des": "Implementation for || string concatenation expression."}
{"index": 120, "repo": "phoenix-core-5.1.3", "code": "Class TableLogWriter {\n\t// will be called when disruptor is getting shutdown\n\tvoid close();\n\t// if writer is closed and cannot write further event\n\tboolean isClosed();\n\t// Called by ring buffer event handler to write RingBufferEvent\n\tvoid write(org.apache.phoenix.log.RingBufferEvent event);\n}", "des": "Writes RingBuffer log event into table"}
{"index": 121, "repo": "phoenix-core-5.1.3", "code": "Enum Tracing.Frequency {\n\tString getKey();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Tracing.Frequency valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Tracing.Frequency[] values();\n}", "des": "Manage the types of frequencies that we support. By default, we never turn on tracing."}
{"index": 122, "repo": "phoenix-core-5.1.3", "code": "Enum UncoveredIndexRegionScanner.State {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic UncoveredIndexRegionScanner.State valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic UncoveredIndexRegionScanner.State[] values();\n}", "des": "The states of the processing a page of index rows"}
{"index": 123, "repo": "phoenix-core-5.1.3", "code": "Interface UpsertExecutor.UpsertListener<RECORD> {\n\t// Called when executing a prepared statement has failed on a given record.\n\tvoid errorOnRecord(RECORD record, Throwable throwable);\n\t// Called when an upsert has been sucessfully completed.\n\tvoid upsertDone(long upsertCount);\n}", "des": "A listener that is called for events based on incoming JSON data."}
{"index": 124, "repo": "phoenix-core-5.1.3", "code": "Interface WhereOptimizer.KeyExpressionVisitor.KeySlots {\n\t// List of slots that store binding of constant values for primary key columns.\n\tList<org.apache.phoenix.compile.WhereOptimizer.KeyExpressionVisitor.KeySlot> getSlots();\n\t// Tracks whether or not the contained KeySlot(s) contain a slot that includes only a partial extraction of the involved expressions.\n\tboolean isPartialExtraction();\n}", "des": "Top level data structure used to drive the formation of the start/stop row of scans, essentially taking the expression tree of a WHERE clause and producing the ScanRanges instance during query compilation."}
{"index": 125, "repo": "phoenix-core-5.1.3", "code": "Class WhereOptimizer.KeyExpressionVisitor.MultiKeySlot {\n\t// List of slots that store binding of constant values for primary key columns.\n\tList<org.apache.phoenix.compile.WhereOptimizer.KeyExpressionVisitor.KeySlot> getSlots();\n\t// Tracks whether or not the contained KeySlot(s) contain a slot that includes only a partial extraction of the involved expressions.\n\tboolean isPartialExtraction();\n}", "des": "Implementation of KeySlots for AND and OR expressions. The List will be in PK order."}
{"index": 126, "repo": "phoenix-core-5.1.3", "code": "Class WhereOptimizer.KeyExpressionVisitor.SingleKeySlot {\n\t// List of slots that store binding of constant values for primary key columns.\n\tList<org.apache.phoenix.compile.WhereOptimizer.KeyExpressionVisitor.KeySlot> getSlots();\n\t// Tracks whether or not the contained KeySlot(s) contain a slot that includes only a partial extraction of the involved expressions.\n\tboolean isPartialExtraction();\n}", "des": "Implementation of KeySlots for a constant value,"}
{"index": 127, "repo": "ignite-core-2.15.0", "code": "Class AbstractClientIndex {\n\t// Checks whether index handles specified cache row.\n\tboolean canHandle(CacheDataRow row);\n\t// Destroy index.\n\tvoid destroy(boolean softDelete);\n\t// Callback that runs when the underlying cache is updated.\n\tvoid onUpdate(@Nullable CacheDataRow oldRow, @Nullable CacheDataRow newRow, boolean prevRowAvailable);\n\tIgniteException unsupported();\n}", "des": "Base class for all index implementations for Ignite client nodes. Client nodes don't persist any data, but they still need to know about indexes structures for planning of queries that starts on client nodes."}
{"index": 128, "repo": "ignite-core-2.15.0", "code": "Class AbstractFailureHandler {\n\tSet<FailureType> getIgnoredFailureTypes();\n\t// Actual failure handling.\n\tprotected abstract boolean handle(Ignite ignite, FailureContext failureCtx);\n\t// Handles failure occurred on ignite instance.\n\tboolean onFailure(Ignite ignite, FailureContext failureCtx);\n\t// Sets failure types that must be ignored by failure handler.\n\tvoid setIgnoredFailureTypes(Set<FailureType> failureTypes);\n}", "des": "Abstract superclass for FailureHandler implementations. Maintains a set of ignored failure types. Failure handler will not invalidate kernal context for this failures and will not handle it."}
{"index": 129, "repo": "ignite-core-2.15.0", "code": "Class AbstractInnerIO {\n\t// Get lookup row.\n\tIndexRow getLookupRow(BPlusTree<IndexRow,?> tree, long pageAddr, int idx);\n\tint inlineSize();\n\tlong link(long pageAddr, int idx);\n\t// Store row info from the given source.\n\tvoid store(long dstPageAddr, int dstIdx, BPlusIO<IndexRow> srcIo, long srcPageAddr, int srcIdx);\n\t// Store the needed info about the row in the page.\n\tvoid storeByOffset(long pageAddr, int off, IndexRow row);\n}", "des": "Inner page to store index rows."}
{"index": 130, "repo": "ignite-core-2.15.0", "code": "Class AbstractLeafIO {\n\t// Get lookup row.\n\tIndexRow getLookupRow(BPlusTree<IndexRow,?> tree, long pageAddr, int idx);\n\tint inlineSize();\n\tlong link(long pageAddr, int idx);\n\t// Store row info from the given source.\n\tvoid store(long dstPageAddr, int dstIdx, BPlusIO<IndexRow> srcIo, long srcPageAddr, int srcIdx);\n\t// Store the needed info about the row in the page.\n\tvoid storeByOffset(long pageAddr, int off, IndexRow row);\n}", "des": "Leaf page to store index rows."}
{"index": 131, "repo": "ignite-core-2.15.0", "code": "Class AbstractMarshaller {\n\tMarshallerContext getContext();\n\t// Undeployment callback invoked when class loader is being undeployed.\n\tabstract void onUndeploy(ClassLoader ldr);\n\t// Sets marshaller context.\n\tvoid setContext(MarshallerContext ctx);\n}", "des": "Base class for marshallers. Provides default implementations of methods that work with byte array or GridByteArrayList. These implementations use GridByteArrayInputStream or GridByteArrayOutputStream to marshal and unmarshal objects."}
{"index": 132, "repo": "ignite-core-2.15.0", "code": "Class AbstractSecurityAwareExternalizable<T> {\n\t// Writes access denied message.\n\tprotected void logAccessDeniedMessage(AccessControlException e);\n\tvoid readExternal(ObjectInput in);\n\t// Get user object where resources must be injected.\n\tT userObject();\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Abstract security aware Externalizable."}
{"index": 133, "repo": "ignite-core-2.15.0", "code": "Class AbstractSystemViewExporterSpi {\n\t// Sets export filter.\n\tvoid setExportFilter(Predicate<SystemView<?>> filter);\n\t// Sets system view registry that SPI should export.\n\tvoid setSystemViewRegistry(ReadOnlySystemViewRegistry mlreg);\n\t// This method is called to start SPI.\n\tvoid spiStart(@Nullable String igniteInstanceName);\n\t// This method is called to stop SPI.\n\tvoid spiStop();\n}", "des": "Basic class for SystemViewExporterSpi implementations."}
{"index": 134, "repo": "ignite-core-2.15.0", "code": "Class AdaptiveJobCountLoadProbe {\n\t// Calculates load value for a given node.\n\tdouble getLoad(ClusterNode node, int jobsSentSinceLastUpdate);\n\t// Gets flag indicating whether to use average job counts vs. current.\n\tboolean isUseAverage();\n\t// Sets flag indicating whether to use average job counts vs. current.\n\tvoid setUseAverage(boolean useAvg);\n}", "des": "Implementation of node load probing based on active and waiting job count. Based on setUseAverage(boolean) parameter, this implementation will either use average job count values or current (default is to use averages)."}
{"index": 135, "repo": "ignite-core-2.15.0", "code": "Class AdaptiveProcessingTimeLoadProbe {\n\t// Calculates load value for a given node.\n\tdouble getLoad(ClusterNode node, int jobsSentSinceLastUpdate);\n\t// Gets flag indicating whether to use average execution time vs. current.\n\tboolean isUseAverage();\n\t// Sets flag indicating whether to use average execution time vs. current.\n\tvoid setUseAverage(boolean useAvg);\n}", "des": "Implementation of node load probing based on total job processing time. Based on setUseAverage(boolean) parameter, this implementation will either use average job execution time values or current (default is to use averages). The algorithm returns a sum of job wait time and job execution time."}
{"index": 136, "repo": "ignite-core-2.15.0", "code": "Interface AffinityFunction {\n\t// Gets affinity nodes for a partition.\n\tList<List<ClusterNode>> assignPartitions(AffinityFunctionContext affCtx);\n\t// Gets partition number for a given key starting from 0.\n\tint partition(Object key);\n\t// Gets total number of partitions available.\n\tint partitions();\n\t// Removes node from affinity.\n\tvoid removeNode(UUID nodeId);\n\t// Resets cache affinity to its initial state.\n\tvoid reset();\n}", "des": "Cache key affinity which maps keys to nodes. This interface is utilized for both, replicated and partitioned caches. Cache affinity can be configured for individual caches via CacheConfiguration.getAffinity() method."}
{"index": 137, "repo": "ignite-core-2.15.0", "code": "Interface AffinityFunctionContext {\n\t// Gets number of backups for new assignment.\n\tint backups();\n\t// Gets current topology snapshot.\n\tList<ClusterNode> currentTopologySnapshot();\n\t// Gets current topology version number.\n\tAffinityTopologyVersion currentTopologyVersion();\n\t// Gets discovery event caused topology change.\n\t@Nullable DiscoveryEvent discoveryEvent();\n\t// Gets affinity assignment for given partition on previous topology version.\n\t@Nullable List<ClusterNode> previousAssignment(int part);\n}", "des": "Affinity function context. This context is passed to AffinityFunction for partition reassignment on every topology change event."}
{"index": 138, "repo": "ignite-core-2.15.0", "code": "Class AffinityKey<K> {\n\t// Gets affinity key to use for affinity mapping.\n\t<T> T affinityKey();\n\t// Sets affinity key to use for affinity mapping.\n\tvoid affinityKey(Object affKey);\n\t// Equality check which delegates to the underlying key equality.\n\tboolean equals(Object obj);\n\t// Gets wrapped key.\n\tK key();\n\t// Sets wrapped key.\n\tvoid key(K key);\n\tvoid readExternal(ObjectInput in);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Optional wrapper for cache keys to provide support for custom affinity mapping. The value returned by affinityKey(Object) method will be used for key-to-node affinity."}
{"index": 139, "repo": "ignite-core-2.15.0", "code": "Interface AlwaysFailoverSpiMBean {\n\t// Gets maximum number of attempts to execute a failed job on another node.\n\tint getMaximumFailoverAttempts();\n\t// Get total number of jobs that were failed over.\n\tint getTotalFailoverJobsCount();\n}", "des": "Management bean for AlwaysFailoverSpi."}
{"index": 140, "repo": "ignite-core-2.15.0", "code": "Class AlwaysTrueReducer<T> {\n\t// Collects given value.\n\tboolean collect(T e);\n\t// Reduces collected values into one.\n\tT reduce();\n}", "des": "Reducer which always returns true from IgniteReducer.collect(Object)"}
{"index": 141, "repo": "ignite-core-2.15.0", "code": "Class AtomicLongMetric {\n\t// Adds x to the metric.\n\tvoid add(long x);\n\t// Adds -1 to the metric.\n\tvoid decrement();\n\t// Adds 1 to the metric.\n\tvoid increment();\n\t// Resets metric state.\n\tvoid reset();\n\tlong value();\n\t// Sets value.\n\tvoid value(long val);\n}", "des": "Long metric implementation."}
{"index": 142, "repo": "ignite-core-2.15.0", "code": "Class AtomicLongViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(AtomicLongView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. AtomicLongView attributes walker."}
{"index": 143, "repo": "ignite-core-2.15.0", "code": "Class AtomicReferenceViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(AtomicReferenceView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. AtomicReferenceView attributes walker."}
{"index": 144, "repo": "ignite-core-2.15.0", "code": "Class AtomicSequenceViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(AtomicSequenceView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. AtomicSequenceView attributes walker."}
{"index": 145, "repo": "ignite-core-2.15.0", "code": "Class AtomicStampedViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(AtomicStampedView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. AtomicStampedView attributes walker."}
{"index": 146, "repo": "ignite-core-2.15.0", "code": "Class AttributeNodeFilter {\n\t// Predicate body.\n\tboolean apply(ClusterNode node);\n\t// Gets attributes.\n\tMap<String,Object> getAttrs();\n}", "des": "Implementation of IgnitePredicate<ClusterNode> based on user attributes. This filter can be used in methods like ClusterGroup.forPredicate(IgnitePredicate), CacheConfiguration.setNodeFilter(IgnitePredicate), ServiceConfiguration.setNodeFilter(IgnitePredicate), etc."}
{"index": 147, "repo": "ignite-core-2.15.0", "code": "Interface BaselineNode {\n\t// Gets a node attribute.\n\t<T> T attribute(String name);\n\t// Gets all node attributes.\n\tMap<String,Object> attributes();\n\t// Gets consistent globally unique node ID.\n\tObject consistentId();\n}", "des": "Interface representing a single node from baseline topology."}
{"index": 148, "repo": "ignite-core-2.15.0", "code": "Class BaselineNodeAttributeViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(BaselineNodeAttributeView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. BaselineNodeAttributeView attributes walker."}
{"index": 149, "repo": "ignite-core-2.15.0", "code": "Class BaselineNodeViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(BaselineNodeView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. BaselineNodeView attributes walker."}
{"index": 150, "repo": "ignite-core-2.15.0", "code": "Class BasicRateLimiter {\n\t// Acquires the given number of permits from this RateLimiter, blocking until the request can be granted.\n\tvoid acquire(long permits);\n\tdouble getRate();\n\tboolean isUnlimited();\n\t// Updates the stable rate.\n\tvoid setRate(double permitsPerSecond);\n}", "des": "The simplified version of Google Guava smooth rate limiter. The primary feature of a rate limiter is its \"stable rate\", the maximum rate that is should allow at normal conditions. This is enforced by \"throttling\" incoming requests as needed, i.e. compute, for an incoming request, the appropriate throttle time, and make the calling thread wait as much. The simplest way to maintain a rate of QPS is to keep the timestamp of the last granted request, and ensure that (1/QPS) seconds have elapsed since then. For example, for a rate of QPS=5 (5 tokens per second), if we ensure that a request isn't granted earlier than 200ms after the last one, then we achieve the intended rate. If a request comes and the last request was granted only 100ms ago, then we wait for another 100ms. At this rate, serving 15 fresh permits (i.e. for an acquire(15) request) naturally takes 3 seconds. It is important to realize that such a limiter has a very superficial memory of the past: it only remembers the last request. if the limiter was unused for a long period of time, then a request arrived and was immediately granted? This limiter would immediately forget about that past underutilization."}
{"index": 151, "repo": "ignite-core-2.15.0", "code": "Class BigEndianAscendingWordSerializer {\n\t// Returns the backing array of bytes that contain the serialized words.\n\tbyte[] getBytes();\n\t// Writes the word to the backing array.\n\tvoid writeWord(long word);\n}", "des": "A serializer that writes a sequence of fixed bit-width 'words' to a byte array. Bitwise OR is used to write words into bytes, so a low bit in a word is also a low bit in a byte. However, a high byte in a word is written at a lower index in the array than a low byte in a word. The first word is written at the lowest array index. Each serializer is one time use and returns its backing byte array."}
{"index": 152, "repo": "ignite-core-2.15.0", "code": "Class BinaryAbstractIdentityResolver {\n\t// Compare two binary objects for equality.\n\tboolean equals(BinaryObject o1, BinaryObject o2);\n\t// Internal equals routine.\n\tprotected abstract boolean equals0(BinaryObject o1, BinaryObject o2);\n\t// Compute hash code for binary object.\n\tint hashCode(BinaryObject obj);\n\t// Internal hash code routine.\n\tprotected abstract int hashCode0(BinaryObject obj);\n}", "des": "Abstract identity resolver with common routines."}
{"index": 153, "repo": "ignite-core-2.15.0", "code": "Class BinaryArrayIdentityResolver {\n\t// Internal equals routine.\n\tprotected boolean equals0(BinaryObject o1, BinaryObject o2);\n\t// Internal hash code routine.\n\tprotected int hashCode0(BinaryObject obj);\n\t// Get singleton instance.\n\tstatic BinaryArrayIdentityResolver instance();\n}", "des": "Identity resolver implementation which compares raw array content of the binary object."}
{"index": 154, "repo": "ignite-core-2.15.0", "code": "Class BinaryBasicIdMapper {\n\tboolean equals(Object o);\n\t// Get field ID.\n\tint fieldId(int typeId, String fieldName);\n\t// Gets whether to use strings in lower case or not.\n\tboolean isLowerCase();\n\t// Sets whether to use strings in lower case or not.\n\tBinaryBasicIdMapper setLowerCase(boolean isLowerCase);\n\t// Get type ID.\n\tint typeId(String typeName);\n}", "des": "Base binary ID mapper implementation."}
{"index": 155, "repo": "ignite-core-2.15.0", "code": "Class BinaryBasicNameMapper {\n\tboolean equals(Object o);\n\t// Gets field name.\n\tString fieldName(String fieldName);\n\t// Gets whether to use simple name of class or not.\n\tboolean isSimpleName();\n\t// Sets whether to use simple name of class or not.\n\tBinaryBasicNameMapper setSimpleName(boolean isSimpleName);\n\t// Gets type clsName.\n\tString typeName(String clsName);\n}", "des": "Base binary name mapper implementation."}
{"index": 156, "repo": "ignite-core-2.15.0", "code": "Class BinaryClassDescriptor {\n\t// Checks whether the class values are explicitly excluded from marshalling.\n\tboolean excluded();\n\tboolean isWriteReplace();\n\tboolean registered();\n\t// Register current stable schema if applicable.\n\tvoid registerStableSchema();\n\tint typeId();\n\tboolean useOptimizedMarshaller();\n\t// Perform write replace.\n\tObject writeReplace(Object obj);\n}", "des": "Binary class descriptor."}
{"index": 157, "repo": "ignite-core-2.15.0", "code": "Class BinaryEnumCache {\n\t// Clears cache.\n\tstatic void clear();\n\t// Get value for the given class and ordinal.\n\tstatic <T> T get(Class<?> cls, int ord);\n}", "des": "Cache for enum constants."}
{"index": 158, "repo": "ignite-core-2.15.0", "code": "Interface BinaryField {\n\t// Check whether field exists in the object.\n\tboolean exists(BinaryObject obj);\n\t// Get field's name.\n\tString name();\n\t// Get field's value from the given object.\n\t<T> T value(BinaryObject obj);\n}", "des": "Binary object field. Can be used to speed object field lookup."}
{"index": 159, "repo": "ignite-core-2.15.0", "code": "Class BinaryFieldAccessor {\n\t// Create accessor for the field.\n\tstatic BinaryFieldAccessor create(Field field, int id);\n\t// Get mode.\n\tBinaryWriteMode mode();\n\t// Read field.\n\tvoid read(Object obj, BinaryReaderExImpl reader);\n\t// Read field.\n\tprotected abstract void read0(Object obj, BinaryReaderExImpl reader);\n\t// Write field.\n\tvoid write(Object obj, BinaryWriterExImpl writer);\n\t// Write field.\n\tprotected abstract void write0(Object obj, BinaryWriterExImpl writer);\n}", "des": "Field accessor to speedup access."}
{"index": 160, "repo": "ignite-core-2.15.0", "code": "Class BinaryFieldImpl {\n\t// Check whether field exists in the object.\n\tboolean exists(BinaryObject obj);\n\tint fieldId();\n\t// Get relative field offset.\n\tint fieldOrder(BinaryObjectExImpl obj);\n\t// Get field's name.\n\tString name();\n\t// Reads field value from the given byte buffer.\n\t<F> F readField(ByteBuffer buf);\n\tint typeId();\n\t// Get field's value from the given object.\n\t<T> T value(BinaryObject obj);\n\t// Writes field value to the given byte buffer.\n\tboolean writeField(BinaryObject obj, ByteBuffer buf);\n}", "des": "Implementation of binary field descriptor."}
{"index": 161, "repo": "ignite-core-2.15.0", "code": "Interface BinaryIdentityResolver {\n\t// Compare two binary objects for equality.\n\tboolean equals(@Nullable BinaryObject o1, @Nullable BinaryObject o2);\n\t// Compute hash code for binary object.\n\tint hashCode(BinaryObject obj);\n}", "des": "Interface to compute hash codes for new binary objects and compare them for equality."}
{"index": 162, "repo": "ignite-core-2.15.0", "code": "Interface BinaryIdMapper {\n\t// Gets ID for provided field name.\n\tint fieldId(int typeId, String fieldName);\n\t// Gets type ID for provided type name.\n\tint typeId(String typeName);\n}", "des": "Type and field ID mapper for binary objects. Ignite never writes full strings for field or type names. Instead, for performance reasons, Ignite writes integer hash codes for type and field names. It has been tested that hash code conflicts for the type names or the field names within the same type are virtually non-existent and, to gain performance, it is safe to work with hash codes. For the cases when hash codes for different types or fields actually do collide BinaryIdMapper allows to override the automatically generated hash code IDs for the type and field names."}
{"index": 163, "repo": "ignite-core-2.15.0", "code": "Interface Binarylizable {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "Interface that allows to implement custom serialization logic for binary objects. IgniteObject is not required to implement this interface, in which case Ignite will automatically serialize binary objects using reflection."}
{"index": 164, "repo": "ignite-core-2.15.0", "code": "Interface BinaryMemoryAllocatorChunk {\n\t// Allocate.\n\tbyte[] allocate(int size);\n\tboolean isAcquired();\n\t// Reallocate.\n\tbyte[] reallocate(byte[] data, int size);\n\t// Shrinks array size if needed.\n\tvoid release(byte[] data, int maxMsgSize);\n}", "des": "Memory allocator chunk."}
{"index": 165, "repo": "ignite-core-2.15.0", "code": "Class BinaryMetadataViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(BinaryMetadataView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. BinaryMetadataView attributes walker."}
{"index": 166, "repo": "ignite-core-2.15.0", "code": "Interface BinaryNameMapper {\n\t// Gets field name.\n\tString fieldName(String fieldName);\n\t// Gets type clsName.\n\tString typeName(String clsName);\n}", "des": "Maps type and field names to different names. Prepares class/type names and field names before pass them to BinaryIdMapper."}
{"index": 167, "repo": "ignite-core-2.15.0", "code": "Interface BinaryObjectEx {\n\t// Check if flag set.\n\tboolean isFlagSet(short flag);\n\t// Get raw type.\n\t@Nullable BinaryType rawType();\n\tint typeId();\n}", "des": "Extended binary object interface."}
{"index": 168, "repo": "ignite-core-2.15.0", "code": "Interface BinaryPositionReadable {\n\t// Read byte at the given position.\n\tbyte readBytePositioned(int pos);\n\t// Read integer at the given position.\n\tint readIntPositioned(int pos);\n\t// Read short at the given position.\n\tshort readShortPositioned(int pos);\n}", "des": "Interface allowing for positioned read."}
{"index": 169, "repo": "ignite-core-2.15.0", "code": "Interface BinaryRawWriterEx {\n\t// Cleans resources.\n\tvoid close();\n\tBinaryOutputStream out();\n\t// Reserve a room for an integer.\n\tint reserveInt();\n\t// Write int value at the specific position.\n\tvoid writeInt(int pos, int val);\n\tvoid writeObjectDetached(@Nullable Object obj);\n}", "des": "Extended writer interface."}
{"index": 170, "repo": "ignite-core-2.15.0", "code": "Class BinaryReaderHandles {\n\t// Get object by position.\n\t<T> T get(int pos);\n\t// Put object to registry and return previous position (if any).\n\tvoid put(int pos, Object obj);\n}", "des": "Reader handles."}
{"index": 171, "repo": "ignite-core-2.15.0", "code": "Interface BinaryReaderHandlesHolder {\n\t// Get handle.\n\tObject getHandle(int pos);\n\t// Get all handles.\n\tBinaryReaderHandles handles();\n\t// Set handle.\n\tvoid setHandle(Object obj, int pos);\n}", "des": "Holder for handles."}
{"index": 172, "repo": "ignite-core-2.15.0", "code": "Class BinaryReaderHandlesHolderImpl {\n\t// Get handle.\n\tObject getHandle(int pos);\n\t// Get all handles.\n\tBinaryReaderHandles handles();\n\t// Set handle.\n\tvoid setHandle(Object obj, int pos);\n}", "des": "Simple holder for handles."}
{"index": 173, "repo": "ignite-core-2.15.0", "code": "Class BinaryReflectiveSerializer {\n\t// Reads fields from provided reader.\n\tvoid readBinary(Object obj, BinaryReader reader);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(Object obj, BinaryWriter writer);\n}", "des": "Binary serializer which writes object fields using reflection. Transient fields are not written."}
{"index": 174, "repo": "ignite-core-2.15.0", "code": "Class BinarySchema.Builder {\n\t// Add field.\n\tvoid addField(int fieldId);\n\t// Build schema.\n\tBinarySchema build();\n\t// Create new schema builder.\n\tstatic BinarySchema.Builder newBuilder();\n}", "des": "Schema builder."}
{"index": 175, "repo": "ignite-core-2.15.0", "code": "Enum BinarySchema.Confirmation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BinarySchema.Confirmation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BinarySchema.Confirmation[] values();\n}", "des": "Order confirmation result."}
{"index": 176, "repo": "ignite-core-2.15.0", "code": "Class BinarySchemaRegistry {\n\t// Add schema.\n\tvoid addSchema(int schemaId, BinarySchema schema);\n\t// Get schema for the given ID.\n\t@Nullable BinarySchema schema(int schemaId);\n\tList<BinarySchema> schemas();\n}", "des": "Binary schema registry. Contains all well-known object schemas."}
{"index": 177, "repo": "ignite-core-2.15.0", "code": "Class BinarySerializedFieldComparator {\n\t// Compare fields.\n\tstatic boolean equals(BinarySerializedFieldComparator c1, BinarySerializedFieldComparator c2);\n\t// Locate the field.\n\tvoid findField(int order);\n}", "des": "Compares fiels in serialized form when possible."}
{"index": 178, "repo": "ignite-core-2.15.0", "code": "Interface BinarySerializer {\n\t// Reads fields from provided reader.\n\tvoid readBinary(Object obj, BinaryReader reader);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(Object obj, BinaryWriter writer);\n}", "des": "Interface that allows to implement custom serialization logic for binary objects. Can be used instead of Binarylizable in case if the class cannot be changed directly."}
{"index": 179, "repo": "ignite-core-2.15.0", "code": "Class BinaryTreeMap {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Reconstructs object on unmarshalling.\n\tprotected Object readResolve();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "Binary TreeMap wrapper."}
{"index": 180, "repo": "ignite-core-2.15.0", "code": "Class BinaryTreeSet {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Reconstructs object on unmarshalling.\n\tprotected Object readResolve();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "Binary TreeSet wrapper."}
{"index": 181, "repo": "ignite-core-2.15.0", "code": "Enum BinaryWriteMode {\n\tint typeId();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BinaryWriteMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BinaryWriteMode[] values();\n}", "des": "Various write modes for binary objects."}
{"index": 182, "repo": "ignite-core-2.15.0", "code": "Class BinaryWriterSchemaHolder {\n\t// Build the schema.\n\tvoid build(BinarySchema.Builder builder, int fieldCnt);\n\t// Pop current object's frame.\n\tvoid pop(int fieldCnt);\n\t// Push another frame.\n\tvoid push(int id, int off);\n\t// Write collected frames and pop them.\n\tint write(BinaryOutputStream out, int fieldCnt, boolean compactFooter);\n}", "des": "Binary writer schema holder."}
{"index": 183, "repo": "ignite-core-2.15.0", "code": "Class BooleanInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected BooleanIndexKey get0(long pageAddr, int off);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, BooleanIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining Boolean values."}
{"index": 184, "repo": "ignite-core-2.15.0", "code": "Class BooleanMetricImpl {\n\t// Resets metric state.\n\tvoid reset();\n\tboolean value();\n\t// Sets value.\n\tvoid value(boolean val);\n}", "des": "Metric that holds boolean primitive."}
{"index": 185, "repo": "ignite-core-2.15.0", "code": "Enum BPlusTree.Result {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BPlusTree.Result valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BPlusTree.Result[] values();\n}", "des": "Operation result."}
{"index": 186, "repo": "ignite-core-2.15.0", "code": "Class BulkLoadAckClientParameters {\n\t// Checks if packet size value is valid.\n\tstatic boolean isValidPacketSize(int sz);\n\t// Returns the local name of file to send.\n\t@NotNull String localFileName();\n\t// Returns the packet size.\n\tint packetSize();\n\t// Creates proper packet size error message if isValidPacketSize(int) check has failed.\n\tstatic String packetSizeErrorMesssage(int size);\n}", "des": "Bulk load parameters, which are parsed from SQL command and sent from server to client."}
{"index": 187, "repo": "ignite-core-2.15.0", "code": "Class BulkLoadParser {\n\t// Creates a parser for a given format options.\n\tstatic BulkLoadParser createParser(BulkLoadFormat format);\n\t// Parses a batch of input data and returns a list of records parsed (in most cases this is a list of strings).\n\tprotected abstract Iterable<List<Object>> parseBatch(byte[] batchData, boolean isLastBatch);\n}", "des": "Bulk load file format parser superclass + factory of known formats."}
{"index": 188, "repo": "ignite-core-2.15.0", "code": "Class BulkLoadStreamerWriter {\n\t// Closure body.\n\tvoid apply(IgniteBiTuple<?,?> entry);\n\tvoid close();\n\t// Returns number of entry updates made by the writer.\n\tlong updateCnt();\n}", "des": "A bulk load cache writer object that adds entries using IgniteDataStreamer."}
{"index": 189, "repo": "ignite-core-2.15.0", "code": "Class BusyExecutor {\n\t// Allow operations.\n\tvoid activate();\n\t// Run task on busy lock.\n\tboolean busyRun(Runnable r);\n\t// Stop all running tasks.\n\tvoid deactivate();\n\t// Execute cancellable task in thread pool under busy lock.\n\tvoid execute(CancellableTask ct);\n\t// Execute task in thread pool under busy lock.\n\tvoid execute(Runnable r);\n\t// Submit task to execute in thread pool under busy lock.\n\tCompletableFuture<Boolean> submit(Runnable r);\n}", "des": "Executor with busy run support. Can run any tasks while active and safelly wait untill they stopped."}
{"index": 190, "repo": "ignite-core-2.15.0", "code": "Class ByteBufferExpander {\n\t// Current byte buffer.\n\tByteBuffer buffer();\n\tvoid close();\n\t// Expands current byte buffer to the requested size.\n\tByteBuffer expand(int size);\n}", "des": "ByteBuffer wrapper for dynamically expand buffer size."}
{"index": 191, "repo": "ignite-core-2.15.0", "code": "Class ByteInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected ByteIndexKey get0(long pageAddr, int off);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, ByteIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining Byte values."}
{"index": 192, "repo": "ignite-core-2.15.0", "code": "Class BytesInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey bytes);\n\tboolean compareBinaryUnsigned();\n\t// Restores value from inline.\n\tprotected BytesIndexKey get0(long pageAddr, int off);\n\t// Return inlined size for specified key.\n\tprotected int inlineSize0(BytesIndexKey val);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, BytesIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining byte arrays."}
{"index": 193, "repo": "ignite-core-2.15.0", "code": "Enum CacheAbstractJdbcStore.TypeKind {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheAbstractJdbcStore.TypeKind valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheAbstractJdbcStore.TypeKind[] values();\n}", "des": "Type kind."}
{"index": 194, "repo": "ignite-core-2.15.0", "code": "Enum CacheAtomicityMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable CacheAtomicityMode fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheAtomicityMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheAtomicityMode[] values();\n}", "des": "Cache atomicity mode controls whether cache should maintain fully transactional semantics or more light-weight atomic behavior. It is recommended that ATOMIC mode is used whenever transactions and explicit locking are not needed. Note that in ATOMIC mode cache will still maintain full data consistency across all cache nodes."}
{"index": 195, "repo": "ignite-core-2.15.0", "code": "Class CacheConfigurationEnrichment {\n\t// Returns all field names that can be potentially enriched.\n\tSet<String> fields();\n\tString getFieldClassName(String fieldName);\n\tbyte[] getFieldSerializedValue(String fieldName);\n\t// Returns true if this enrichment contains serialized valued for the specified field.\n\tboolean hasField(String name);\n}", "des": "Object that contains serialized values for fields marked with SerializeSeparately in CacheConfiguration. This object is needed to exchange and store shrinked cache configurations to avoid possible ClassNotFoundException errors during deserialization on nodes where some specific class may not exist."}
{"index": 196, "repo": "ignite-core-2.15.0", "code": "Class CacheConsistencyViolationEvent {\n\t// Returns cache name.\n\tString getCacheName();\n\t// Returns a mapping of keys to a collection of original entries.\n\tMap<Object,CacheConsistencyViolationEvent.EntriesInfo> getEntries();\n\t// Returns a mapping of keys to a collection of repaired entries.\n\tMap<Object,Object> getRepairedEntries();\n\t// Returns strategy.\n\tReadRepairStrategy getStrategy();\n}", "des": "This is an experimental API."}
{"index": 197, "repo": "ignite-core-2.15.0", "code": "Class CacheContinuousQueryBatchAck {\n\t// Deployment enabled flag indicates whether deployment info has to be added to this message.\n\tboolean addDeploymentInfo();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Batch acknowledgement."}
{"index": 198, "repo": "ignite-core-2.15.0", "code": "Class CacheDistributionGroup {\n\tint getGroupId();\n\tString getGroupName();\n\tList<CacheDistributionPartition> getPartitions();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tvoid setGroupId(int grpId);\n\tvoid setGroupName(String grpName);\n\tvoid setPartitions(List<CacheDistributionPartition> partitions);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "DTO for CacheDistributionTask, contains information about group"}
{"index": 199, "repo": "ignite-core-2.15.0", "code": "Class CacheDistributionTaskArg {\n\tSet<String> getCaches();\n\tSet<String> getUserAttributes();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tvoid setUserAttributes(Set<String> userAttrs);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Input params for CacheDistributionTask"}
{"index": 200, "repo": "ignite-core-2.15.0", "code": "Class CacheDistributionTaskResult {\n\tMap<UUID,Exception> exceptions();\n\tCollection<CacheDistributionNode> jobResults();\n\t// Print collect information on the distribution of partitions.\n\tvoid print(PrintStream out);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of CacheDistributionTask"}
{"index": 201, "repo": "ignite-core-2.15.0", "code": "Interface CacheEntryVersion {\n\t// Cluster id is a value to distinguish updates in case user wants to aggregate and sort updates from several Ignite clusters.\n\tbyte clusterId();\n\tint nodeOrder();\n\t// Order of the update.\n\tlong order();\n\t// If source of the update is \"local\" cluster then null will be returned.\n\tCacheEntryVersion otherClusterVersion();\n\tint topologyVersion();\n}", "des": "Entry event order. Two concurrent updates of the same entry can be ordered based on CacheEntryVersion comparsion. Greater value means that event occurs later."}
{"index": 202, "repo": "ignite-core-2.15.0", "code": "Enum CacheFilterEnum {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable CacheFilterEnum fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheFilterEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheFilterEnum[] values();\n}", "des": "Represents a type of cache(s) that can be used for comparing update counters and checksums between primary and backup partitions."}
{"index": 203, "repo": "ignite-core-2.15.0", "code": "Class CacheGroupIoViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(CacheGroupIoView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. CacheGroupIoView attributes walker."}
{"index": 204, "repo": "ignite-core-2.15.0", "code": "Class CacheGroupViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(CacheGroupView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. CacheGroupView attributes walker."}
{"index": 205, "repo": "ignite-core-2.15.0", "code": "Class CacheInvokeResult<T> {\n\t// Entry processor error;\n\tException error();\n\t// Static constructor.\n\tstatic <T> CacheInvokeResult<T> fromError(Exception err);\n\t// Static constructor.\n\tstatic <T> CacheInvokeResult<T> fromResult(T res);\n\tT get();\n\tvoid readExternal(ObjectInput in);\n\tT result();\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Implementation of EntryProcessorResult."}
{"index": 206, "repo": "ignite-core-2.15.0", "code": "Class CacheJdbcStoreSessionListener {\n\t// Gets data source.\n\tDataSource getDataSource();\n\t// On session end callback.\n\tvoid onSessionEnd(CacheStoreSession ses, boolean commit);\n\t// On session start callback.\n\tvoid onSessionStart(CacheStoreSession ses);\n\t// Sets data source.\n\tvoid setDataSource(DataSource dataSrc);\n\t// Starts grid component, called on grid start.\n\tvoid start();\n\t// Stops grid component, called on grid shutdown.\n\tvoid stop();\n}", "des": "Cache store session listener based on JDBC connection."}
{"index": 207, "repo": "ignite-core-2.15.0", "code": "Class CacheJtaManagerAdapter {\n\t// Checks if cache is working in JTA transaction and enlist cache as XAResource if necessary.\n\tabstract void checkJta();\n\tabstract void registerCache(CacheConfiguration<?,?> cfg);\n\t// Gets transaction manager finder.\n\tabstract @Nullable Object tmLookup();\n}", "des": "Provides possibility to integrate cache transactions with JTA."}
{"index": 208, "repo": "ignite-core-2.15.0", "code": "Class CacheKeyConfiguration {\n\tboolean equals(Object o);\n\t// Gets affinity key field name.\n\tString getAffinityKeyFieldName();\n\t// Sets type name for which affinity field name is being defined.\n\tString getTypeName();\n\t// Sets affinity key field name.\n\tCacheKeyConfiguration setAffinityKeyFieldName(String affKeyFieldName);\n\tCacheKeyConfiguration setTypeName(String typeName);\n}", "des": "Configuration defining various aspects of cache keys without explicit usage of annotations on user classes."}
{"index": 209, "repo": "ignite-core-2.15.0", "code": "Enum CacheMetricsOperation {\n\tstatic @Nullable CacheMetricsOperation of(String strRep);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheMetricsOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheMetricsOperation[] values();\n}", "des": "Enum for cache metrics command operations."}
{"index": 210, "repo": "ignite-core-2.15.0", "code": "Enum CacheMode {\n\tbyte code();\n\t// Efficiently gets enumerated value from its code.\n\tstatic @Nullable CacheMode fromCode(int code);\n\tstatic byte toCode(@Nullable CacheMode mode);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheMode[] values();\n}", "des": "Enumeration of all supported caching modes. Cache mode is specified in CacheConfiguration and cannot be changed after cache has started."}
{"index": 211, "repo": "ignite-core-2.15.0", "code": "Class CacheNoopJtaManager {\n\t// Checks if cache is working in JTA transaction and enlist cache as XAResource if necessary.\n\tvoid checkJta();\n\tvoid registerCache(CacheConfiguration<?,?> cfg);\n\t// Gets transaction manager finder.\n\t@Nullable Object tmLookup();\n}", "des": "No-op implementation of CacheJtaManagerAdapter."}
{"index": 212, "repo": "ignite-core-2.15.0", "code": "Interface CacheObjectTransformerManager {\n\t// Restores the data.\n\tByteBuffer restore(ByteBuffer transformed);\n\t// Transforms the data.\n\t@Nullable ByteBuffer transform(ByteBuffer original);\n}", "des": "Provides cache object's bytes transformation (eg. encryption, compression, etc)."}
{"index": 213, "repo": "ignite-core-2.15.0", "code": "Enum CacheOperationFilter {\n\t// Creare predicate from operation filter.\n\t@Nullable CacheEntryPredicate createPredicate(@Nullable CacheObject val);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheOperationFilter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheOperationFilter[] values();\n}", "des": "Cache operation filter."}
{"index": 214, "repo": "ignite-core-2.15.0", "code": "Class CacheOsConflictResolutionManager<K,V> {\n\tCacheVersionConflictResolver conflictResolver();\n\tvoid onDisconnected(IgniteFuture<?> reconnectFut);\n\tvoid onKernalStart();\n\tvoid onKernalStop(boolean cancel);\n\t// Prints memory statistics (sizes of internal data structures, etc.).\n\tvoid printMemoryStats();\n\t// Starts manager.\n\tvoid start(GridCacheContext<K,V> cctx);\n\t// Stops manager.\n\tvoid stop(boolean cancel, boolean destroy);\n}", "des": "OS conflict resolver manager."}
{"index": 215, "repo": "ignite-core-2.15.0", "code": "Class CachePagesListViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(CachePagesListView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. CachePagesListView attributes walker."}
{"index": 216, "repo": "ignite-core-2.15.0", "code": "Enum CachePeekMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable CachePeekMode fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CachePeekMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CachePeekMode[] values();\n}", "des": "Enumeration of all supported cache peek modes. Peek modes can be passed into IgniteCache.localPeek(Object, CachePeekMode...), IgniteCache.localEntries(CachePeekMode...), IgniteCache.localSize(CachePeekMode...) and IgniteCache.size(CachePeekMode...) methods."}
{"index": 217, "repo": "ignite-core-2.15.0", "code": "Interface CachePluginContext<C extends CachePluginConfiguration> {\n\tIgnite grid();\n\tCacheConfiguration igniteCacheConfiguration();\n\tIgniteConfiguration igniteConfiguration();\n\t// Gets local grid node.\n\tClusterNode localNode();\n\t// Gets logger for given class.\n\tIgniteLogger log(Class<?> cls);\n}", "des": "Cache plugin context."}
{"index": 218, "repo": "ignite-core-2.15.0", "code": "Interface CacheQueryFuture<T> {\n\t// Cancels this query future and stop receiving any further results for the query associated with this future.\n\tboolean cancel();\n\t// Checks if all data is fetched by the query.\n\tboolean isDone();\n\t// Returns next element from result set.\n\tT next();\n}", "des": "Cache query future returned by query execution. Refer to CacheQuery documentation for more information."}
{"index": 219, "repo": "ignite-core-2.15.0", "code": "Enum CacheQueryType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheQueryType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheQueryType[] values();\n}", "des": "Cache query type."}
{"index": 220, "repo": "ignite-core-2.15.0", "code": "Enum CacheRebalanceMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable CacheRebalanceMode fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheRebalanceMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheRebalanceMode[] values();\n}", "des": "Cache rebalance mode. When rebalancing is enabled (i.e. has value other than NONE), distributed caches will attempt to rebalance all necessary values from other grid nodes. This enumeration is used to configure rebalancing via CacheConfiguration.getRebalanceMode() configuration property. If not configured explicitly, then CacheConfiguration.DFLT_REBALANCE_MODE is used."}
{"index": 221, "repo": "ignite-core-2.15.0", "code": "Class CacheResetLostPartitionsTaskArg {\n\tSet<String> getCaches();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Input params for CacheResetLostPartitionsTask"}
{"index": 222, "repo": "ignite-core-2.15.0", "code": "Class CacheResetLostPartitionsTaskResult {\n\tMap<String,String> getMessageMap();\n\t// Print job result.\n\tvoid print(PrintStream out);\n\tString put(String groupName, String message);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tvoid setMessageMap(Map<String,String> messageMap);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of CacheResetLostPartitionsTask"}
{"index": 223, "repo": "ignite-core-2.15.0", "code": "Class CacheStatisticsClearMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\tCollection<String> caches();\n\t// Creates new discovery cache if message caused topology version change.\n\tDiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\t// Initial message flag.\n\tboolean initial();\n\tboolean isMutable();\n\tUUID requestId();\n}", "des": "Cache statistics clear discovery message."}
{"index": 224, "repo": "ignite-core-2.15.0", "code": "Class CacheStatisticsModeChangeMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\tCollection<String> caches();\n\t// Creates new discovery cache if message caused topology version change.\n\tDiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tboolean enabled();\n\tIgniteUuid id();\n\t// Initial message flag.\n\tboolean initial();\n\tboolean isMutable();\n\tUUID requestId();\n}", "des": "Cache statistics mode change discovery message."}
{"index": 225, "repo": "ignite-core-2.15.0", "code": "Class CacheStoreAdapter<K,V> {\n\tvoid deleteAll(Collection<?> keys);\n\tMap<K,V> loadAll(Iterable<? extends K> keys);\n\t// Default empty implementation.\n\tvoid loadCache(IgniteBiInClosure<K,V> clo, Object... args);\n\t// Default empty implementation for ending transactions.\n\tvoid sessionEnd(boolean commit);\n\tvoid writeAll(Collection<javax.cache.Cache.Entry<? extends K,? extends V>> entries);\n}", "des": "Cache storage convenience adapter. It provides default implementation for bulk operations, such as loadAll(Iterable), writeAll(Collection), and deleteAll(Collection) by sequentially calling corresponding CacheLoader.load(Object), CacheWriter.write(Cache.Entry), and CacheWriter.delete(Object) operations. Use this adapter whenever such behaviour is acceptable. However in many cases it maybe more preferable to take advantage of database batch update functionality, and therefore default adapter implementation may not be the best option."}
{"index": 226, "repo": "ignite-core-2.15.0", "code": "Interface CacheStoreSessionListener {\n\t// On session end callback.\n\tvoid onSessionEnd(CacheStoreSession ses, boolean commit);\n\t// On session start callback.\n\tvoid onSessionStart(CacheStoreSession ses);\n}", "des": "Cache store session listener that allows to implement callbacks for session lifecycle."}
{"index": 227, "repo": "ignite-core-2.15.0", "code": "Class CacheStripedExecutor {\n\t// Awaits while all submitted tasks completed.\n\tvoid awaitApplyComplete();\n\tboolean error();\n\tStripedExecutor executor();\n\tvoid onError(IgniteCheckedException e);\n\t// Submit task to striped executor.\n\tvoid submit(Runnable task, int grpId, int partId);\n}", "des": "Wrapper over StripedExecutor, that groups submitted tasks by cache group and partition."}
{"index": 228, "repo": "ignite-core-2.15.0", "code": "Class CacheViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(CacheView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. CacheView attributes walker."}
{"index": 229, "repo": "ignite-core-2.15.0", "code": "Enum CacheWriteSynchronizationMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable CacheWriteSynchronizationMode fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CacheWriteSynchronizationMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CacheWriteSynchronizationMode[] values();\n}", "des": "Mode indicating how Ignite should wait for write replies from other nodes. Default value is PRIMARY_SYNC}, which means that Ignite will wait for write or commit to complete on primary node, but will not wait for backups to be updated."}
{"index": 230, "repo": "ignite-core-2.15.0", "code": "Interface CdcCacheEvent {\n\tint cacheId();\n\t// Note, CacheConfiguration.getQueryEntities() value not changed on table schema change.\n\tCacheConfiguration<?,?> configuration();\n\t// Returns current state of configured QueryEntity.\n\tCollection<QueryEntity> queryEntities();\n}", "des": "Notification of CdcConsumer about cache creation/change events."}
{"index": 231, "repo": "ignite-core-2.15.0", "code": "Class CdcMain {\n\tstatic String cdcInstanceName(String igniteInstanceName);\n\t// Waits and consumes new WAL segments until stopped.\n\tvoid consumeWalSegmentsUntilStopped();\n\t// Creates consumer state.\n\tprotected CdcConsumerState createState(Path stateDir);\n\t// Runs Change Data Capture.\n\tvoid run();\n\t// Runs Change Data Capture application with possible exception.\n\tvoid runX();\n\t// Stops the application.\n\tvoid stop();\n}", "des": "Change Data Capture (CDC) application. The application runs independently of Ignite node process and provides the ability for the CdcConsumer to consume events(CdcEvent) from WAL segments. The user should provide CdcConsumer implementation with custom consumption logic. Ignite node should be explicitly configured for using CdcMain. Set DataRegionConfiguration.setCdcEnabled(boolean) to true. Optional: Set DataStorageConfiguration.setCdcWalPath(String) to path to the directory to store WAL segments for CDC. Optional: Set DataStorageConfiguration.setWalForceArchiveTimeout(long) to configure timeout for force WAL rollover, so new events will be available for consumptions with the predicted time. When DataStorageConfiguration.getCdcWalPath() is true then Ignite node on each WAL segment rollover creates hard link to archive WAL segment in DataStorageConfiguration.getCdcWalPath() directory. CdcMain application takes segment file and consumes events from it. After successful consumption (see CdcConsumer.onEvents(Iterator)) WAL segment will be deleted from directory. Several Ignite nodes can be started on the same host. If your deployment done with custom consistent id then you should specify it via IgniteConfiguration.setConsistentId(Serializable) in provided IgniteConfiguration. Application works as follows: Searches node work directory based on provided IgniteConfiguration. Awaits for the creation of CDC directory if it not exists. Acquires file lock to ensure exclusive consumption. Loads state of consumption if it exists. Infinitely waits for new available segment and processes it."}
{"index": 232, "repo": "ignite-core-2.15.0", "code": "Class CheckIndexInlineSizesResult {\n\t// Adds to result information about indexes from node.\n\tvoid addResult(UUID nodeId, Map<String,Integer> indexNameToInlineSize);\n\tMap<UUID,Map<String,Integer>> inlineSizes();\n\t// Merge current result with given instance.\n\tvoid merge(CheckIndexInlineSizesResult res);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Represents information about secondary indexes inline size from the cluster nodes."}
{"index": 233, "repo": "ignite-core-2.15.0", "code": "Class CheckpointContextImpl {\n\t// Await all async tasks from executor was finished.\n\tvoid awaitPendingTasksFinished();\n\tExecutor executor();\n\tIgniteInternalFuture<?> finishedStateFut();\n\tboolean needToSnapshot(String cacheOrGrpName);\n\tboolean nextSnapshot();\n\tPartitionAllocationMap partitionStatMap();\n\tCheckpointProgress progress();\n\t// Whether to flush WAL after a Checkpoint begin.\n\tboolean walFlush();\n\tvoid walFlush(boolean flush);\n}", "des": "Context with information about current checkpoint."}
{"index": 234, "repo": "ignite-core-2.15.0", "code": "Enum CheckpointEntryType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CheckpointEntryType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CheckpointEntryType[] values();\n}", "des": "Checkpoint entry types."}
{"index": 235, "repo": "ignite-core-2.15.0", "code": "Class CheckpointEvent {\n\t// Gets checkpoint key associated with this event.\n\tString key();\n\t// Sets checkpoint key.\n\tvoid key(String cpKey);\n\t// Gets a shortened version of toString() result.\n\tString shortDisplay();\n}", "des": "Grid checkpoint event."}
{"index": 236, "repo": "ignite-core-2.15.0", "code": "Interface CheckpointListener {\n\t// Do some actions after checkpoint end.\n\tdefault void afterCheckpointEnd(CheckpointListener.Context ctx);\n\t// Do some actions before checkpoint write lock.\n\tvoid beforeCheckpointBegin(CheckpointListener.Context ctx);\n\tvoid onCheckpointBegin(CheckpointListener.Context ctx);\n\tvoid onMarkCheckpointBegin(CheckpointListener.Context ctx);\n}", "des": "Listener which methods will be called in a corresponded checkpoint life cycle period."}
{"index": 237, "repo": "ignite-core-2.15.0", "code": "Interface CheckpointSpi {\n\t// Loads checkpoint from storage by its unique key.\n\t@Nullable byte[] loadCheckpoint(String key);\n\t// This method instructs the checkpoint provider to clean saved data for a given key.\n\tboolean removeCheckpoint(String key);\n\t// Saves checkpoint to the storage.\n\tboolean saveCheckpoint(String key, byte[] state, long timeout, boolean overwrite);\n\t// Sets the checkpoint listener.\n\tvoid setCheckpointListener(CheckpointListener lsnr);\n}", "des": "Checkpoint SPI provides an ability to save an intermediate job state. It can be useful when long running jobs need to store some intermediate state to protect from system or application failures. Grid job can save intermediate state in certain points of the execution (e.g., periodically) and upon start check if previously saved state exists. This allows job to restart from the last save checkpoint in case of preemption or other types of failover."}
{"index": 238, "repo": "ignite-core-2.15.0", "code": "Enum CheckpointState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CheckpointState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CheckpointState[] values();\n}", "des": "Possible checkpoint states. Ordinal is important. Every next state follows the previous one."}
{"index": 239, "repo": "ignite-core-2.15.0", "code": "Class CheckpointTimeoutLock {\n\tboolean checkpointLockIsHeldByThread();\n\t// Gets the checkpoint read lock.\n\tvoid checkpointReadLock();\n\t// Timeout for checkpoint read lock acquisition.\n\tlong checkpointReadLockTimeout();\n\t// Sets timeout for checkpoint read lock acquisition.\n\tvoid checkpointReadLockTimeout(long val);\n\t// Releases the checkpoint read lock.\n\tvoid checkpointReadUnlock();\n\t// Prepare the lock to further usage.\n\tvoid start();\n\t// Forbid to take this lock.\n\tvoid stop();\n}", "des": "Checkpoint lock for outer usage which should be used to protect data during writing to memory. It contains complex logic for the correct taking of inside checkpoint lock(timeout, force checkpoint, etc.)."}
{"index": 240, "repo": "ignite-core-2.15.0", "code": "Enum CheckpointWriteOrder {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable CheckpointWriteOrder fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CheckpointWriteOrder valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CheckpointWriteOrder[] values();\n}", "des": "This enum defines order of writing pages to disk storage during checkpoint."}
{"index": 241, "repo": "ignite-core-2.15.0", "code": "Class CircularStringBuilder {\n\t// Appends the string representation of the Object argument.\n\tCircularStringBuilder append(Object obj);\n\t// Appends the specified string to this character sequence.\n\tCircularStringBuilder append(String str);\n\t// Append StringBuffer\n\tCircularStringBuilder append(StringBuffer sb);\n\t// Returns the current capacity.\n\tint capacity();\n\tint getSkipped();\n\t// Returns the length (character count).\n\tint length();\n\t// Reset internal builder state\n\tvoid reset();\n}", "des": "Basic string builder over circular buffer."}
{"index": 242, "repo": "ignite-core-2.15.0", "code": "Class ClearCachesTaskArg {\n\tList<String> caches();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for ClearCachesTask."}
{"index": 243, "repo": "ignite-core-2.15.0", "code": "Class ClearCachesTaskResult {\n\tList<String> clearedCaches();\n\tList<String> nonExistentCaches();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of ClearCachesTask."}
{"index": 244, "repo": "ignite-core-2.15.0", "code": "Class ClientAtomicLongRequest {\n\t// Gets the atomic long.\n\tprotected GridCacheAtomicLongImpl atomicLong(ClientConnectionContext ctx);\n\t// Gets a response for non-existent atomic long.\n\tprotected ClientResponse notFoundResponse();\n}", "des": "Atomic long value request."}
{"index": 245, "repo": "ignite-core-2.15.0", "code": "Enum ClientBitmaskFeature {\n\tstatic EnumSet<ClientBitmaskFeature> allFeaturesAsEnumSet();\n\tstatic EnumSet<ClientBitmaskFeature> enumSet(byte[] bytes);\n\tint featureId();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClientBitmaskFeature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClientBitmaskFeature[] values();\n}", "des": "Defines supported features for thin client."}
{"index": 246, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheChangeDummyDiscoveryMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n\tboolean skipForExchangeMerge();\n}", "des": "Dummy discovery message which is not really sent via ring, it is just added in local discovery worker queue."}
{"index": 247, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheClearKeyRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Clear key request."}
{"index": 248, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheClearKeysRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Clear keys request."}
{"index": 249, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheClearRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache clear request."}
{"index": 250, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheContainsKeyRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "ContainsKey request."}
{"index": 251, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheContainsKeysRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "ContainsKeys request."}
{"index": 252, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheEntryListenersRegistry {\n\t// Deregister listener handler.\n\tClientCacheEntryListenerHandler<?,?> deregisterCacheEntryListener(String cacheName, javax.cache.configuration.CacheEntryListenerConfiguration<?,?> cfg);\n\t// Register listener handler.\n\tboolean registerCacheEntryListener(String cacheName, javax.cache.configuration.CacheEntryListenerConfiguration<?,?> cfg, ClientCacheEntryListenerHandler<?,?> hnd);\n}", "des": "Per-cache cache entry listeners registry. Listeners can't be stored inside ClientCache instance, since there can be several such instances per one cache."}
{"index": 253, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheGetAllRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "GetAll request."}
{"index": 254, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheGetAndPutIfAbsentRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache get and put if absent request."}
{"index": 255, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheGetAndPutRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache get and put request."}
{"index": 256, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheGetAndRemoveRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache get and remove request."}
{"index": 257, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheGetAndReplaceRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache get and replace request."}
{"index": 258, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheGetRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache get request."}
{"index": 259, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheGetSizeRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache size request."}
{"index": 260, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheIndexQueryRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "IndexQuery request."}
{"index": 261, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheKeyRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Gets the key.\n\tObject key();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\tprotected abstract ClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache request involving key."}
{"index": 262, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheKeysRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Gets the set of keys.\n\tSet<Object> keys();\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Key set request."}
{"index": 263, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheKeyValueRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Gets transaction ID.\n\tint txId();\n\t// Gets the value.\n\tObject val();\n}", "des": "Cache request involving key and value."}
{"index": 264, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheLocalPeekRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache local peek request. Only should be used in testing purposes."}
{"index": 265, "repo": "ignite-core-2.15.0", "code": "Class ClientCachePutAllConflictRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Client TcpClientCache.putAllConflict(Map) request."}
{"index": 266, "repo": "ignite-core-2.15.0", "code": "Class ClientCachePutAllRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "PutAll request."}
{"index": 267, "repo": "ignite-core-2.15.0", "code": "Class ClientCachePutIfAbsentRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache put if absent request."}
{"index": 268, "repo": "ignite-core-2.15.0", "code": "Class ClientCachePutRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache put request."}
{"index": 269, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheQueryContinuousHandle {\n\t// Closes the resource.\n\tvoid close();\n\tvoid onUpdated(Iterable<javax.cache.event.CacheEntryEvent<?,?>> iterable);\n\t// Sets the cursor.\n\tvoid setCursor(QueryCursor<?> cur);\n\t// Sets the cursor id.\n\tvoid startNotifications(long id);\n}", "des": "Continuous query handle. NOTE: Do not mark with IgniteAsyncCallback - it disables batching and sends events one by one."}
{"index": 270, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheQueryRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Gets transaction ID.\n\tint txId();\n\tprotected void updateAffinityMetrics(ClientConnectionContext ctx, int part);\n}", "des": "Abstract query request."}
{"index": 271, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheRemoveAllConflictRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Client TcpClientCache.removeAllConflict(Map) request."}
{"index": 272, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheRemoveAllRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache removeAll request."}
{"index": 273, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheRemoveIfEqualsRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache remove request with value."}
{"index": 274, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheRemoveKeyRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Remove request."}
{"index": 275, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheRemoveKeysRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Remove keys request."}
{"index": 276, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheReplaceIfEqualsRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache replace request."}
{"index": 277, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheReplaceRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\tClientResponse process0(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Cache replace request."}
{"index": 278, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheScanQueryRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Scan query request."}
{"index": 279, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheSqlFieldsQueryRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Sql query request."}
{"index": 280, "repo": "ignite-core-2.15.0", "code": "Class ClientCacheSqlQueryRequest {\n\t// Gets a value indicating whether request was made under transaction.\n\tboolean isTransactional();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Sql query request."}
{"index": 281, "repo": "ignite-core-2.15.0", "code": "Interface ClientCluster {\n\t// Disables write-ahead logging for specified cache.\n\tboolean disableWal(String cacheName);\n\t// Enables write-ahead logging for specified cache.\n\tboolean enableWal(String cacheName);\n\t// Checks if write-ahead logging is enabled for specified cache.\n\tboolean isWalEnabled(String cacheName);\n\t// Gets current cluster state.\n\tClusterState state();\n\t// Changes current cluster state to given newState cluster state.\n\tvoid state(ClusterState newState);\n}", "des": "Thin client cluster facade. Represents whole cluster (all available nodes)."}
{"index": 282, "repo": "ignite-core-2.15.0", "code": "Class ClientClusterGroupProjection {\n\t// Applies projection.\n\tClusterGroup apply(ClusterGroup clusterGrp);\n\t// Reads projection from a stream.\n\tstatic ClientClusterGroupProjection read(BinaryRawReader reader);\n}", "des": "Client cluster group projection representation. Decodes a remote projection request from a client node."}
{"index": 283, "repo": "ignite-core-2.15.0", "code": "Interface ClientConnection {\n\t// Closes the connection.\n\tvoid close();\n\t// Gets local address of this session.\n\t@Nullable InetSocketAddress localAddress();\n\t// Gets address of remote peer on this session.\n\t@Nullable InetSocketAddress remoteAddress();\n\t// Sends a message.\n\tvoid send(ByteBuffer msg, @Nullable Runnable onDone);\n}", "des": "Client connection: abstracts away sending and receiving messages."}
{"index": 284, "repo": "ignite-core-2.15.0", "code": "Interface ClientConnectionMultiplexer {\n\t// Opens a new connection.\n\tClientConnection open(InetSocketAddress addr, ClientMessageHandler msgHnd, ClientConnectionStateHandler stateHnd);\n\t// Initializes this instance.\n\tvoid start();\n\t// Stops this instance.\n\tvoid stop();\n}", "des": "Client connection multiplexer: manages multiple connections with a shared resource pool (worker threads, etc)."}
{"index": 285, "repo": "ignite-core-2.15.0", "code": "Class ClientConnectionViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ClientConnectionView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ClientConnectionView attributes walker."}
{"index": 286, "repo": "ignite-core-2.15.0", "code": "Class ClientDataStreamerAddDataRequest {\n\t// Returns invalid node state response.\n\tprotected ClientResponse getInvalidNodeStateResponse();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n}", "des": "Adds data to the existing streamer."}
{"index": 287, "repo": "ignite-core-2.15.0", "code": "Class ClientDataStreamerHandle {\n\t// Closes the resource.\n\tvoid close();\n\t// Gets the wrapped streamer.\n\tIgniteDataStreamer<KeyCacheObject,CacheObject> getStreamer();\n}", "des": "Streamer handle."}
{"index": 288, "repo": "ignite-core-2.15.0", "code": "Class ClientDataStreamerStartRequest {\n\t// Returns invalid node state response.\n\tprotected ClientResponse getInvalidNodeStateResponse();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n}", "des": "Starts the data streamer."}
{"index": 289, "repo": "ignite-core-2.15.0", "code": "Class ClientExceptionsUtils {\n\t// Returns true if the exception that is provided is thrown because an attempt to open a direct connection was made while only inverse connections are allowed.\n\tstatic boolean isAttemptToEstablishDirectConnectionWhenOnlyInverseIsAllowed(Throwable t);\n\t// Returns true if the exception relates to cluster topology change that prevents a connection, AND the given node is client.\n\tstatic boolean isClientNodeTopologyException(Throwable t, ClusterNode node);\n}", "des": "Utils to analyze client-related exceptions."}
{"index": 290, "repo": "ignite-core-2.15.0", "code": "Class ClientExecuteTaskResponse {\n\t// Encodes the response data.\n\tvoid encode(ClientConnectionContext ctx, BinaryRawWriterEx writer);\n\t// Callback for response sent event.\n\tvoid onSent();\n}", "des": "Execute task response."}
{"index": 291, "repo": "ignite-core-2.15.0", "code": "Class ClientIgniteSetRequest {\n\t// Gets the IgniteSet.\n\tprotected <T> IgniteSet<T> igniteSet(ClientConnectionContext ctx);\n\t// Gets the name.\n\tprotected String name();\n\t// Gets a response for non-existent set.\n\tprotected ClientResponse notFoundResponse();\n\t// Processes the request.\n\tClientResponse process(ClientConnectionContext ctx);\n\t// Processes the request.\n\tprotected ClientResponse process(IgniteSet<Object> set);\n}", "des": "Ignite set get or update request."}
{"index": 292, "repo": "ignite-core-2.15.0", "code": "Interface ClientListenerMessageParser {\n\t// Decode request from byte array.\n\tClientListenerRequest decode(ClientMessage msg);\n\t// Decode command type.\n\tint decodeCommandType(ClientMessage msg);\n\t// Decode request Id.\n\tlong decodeRequestId(ClientMessage msg);\n\t// Encode response to byte array.\n\tClientMessage encode(ClientListenerResponse resp);\n}", "des": "Client listener message parser."}
{"index": 293, "repo": "ignite-core-2.15.0", "code": "Class ClientListenerNioMessageParser {\n\t// This method is called when input bytes are available on the underlying network connection.\n\tObject decode(GridNioSession ses, ByteBuffer buf);\n\t// This method is called whenever a message should be sent to the network connection and network buffer is ready to be filled with bytes.\n\tByteBuffer encode(GridNioSession ses, Object msg);\n}", "des": "This class implements stream parser."}
{"index": 294, "repo": "ignite-core-2.15.0", "code": "Class ClientListenerProcessor {\n\tvoid closeAllSessions();\n\tClientListenerMetrics metrics();\n\tClientProcessorMXBean mxBean();\n\t// Callback that notifies that kernal has successfully started, including all managers and processors.\n\tvoid onKernalStart(boolean active);\n\t// Callback to notify that kernal is about to stop.\n\tvoid onKernalStop(boolean cancel);\n\tint port();\n\tboolean sendServerExceptionStackTraceToClient();\n\t// Starts grid component.\n\tvoid start();\n}", "des": "Client connector processor."}
{"index": 295, "repo": "ignite-core-2.15.0", "code": "Class ClientMessageParser {\n\t// Decodes the request.\n\tClientListenerRequest decode(BinaryReaderExImpl reader);\n\t// Decode request from byte array.\n\tClientListenerRequest decode(ClientMessage msg);\n\t// Decode command type.\n\tint decodeCommandType(ClientMessage msg);\n\t// Decode request Id.\n\tlong decodeRequestId(ClientMessage msg);\n\t// Encode response to byte array.\n\tClientMessage encode(ClientListenerResponse resp);\n}", "des": "Thin client message parser."}
{"index": 296, "repo": "ignite-core-2.15.0", "code": "Class ClientNotification {\n\t// Encodes the notification data.\n\tvoid encode(ClientConnectionContext ctx, BinaryRawWriterEx writer);\n\t// Gets the resource id.\n\tlong resourceId();\n}", "des": "Server to client notification for some resource."}
{"index": 297, "repo": "ignite-core-2.15.0", "code": "Enum ClientOperationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClientOperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClientOperationType[] values();\n}", "des": "Client operation type."}
{"index": 298, "repo": "ignite-core-2.15.0", "code": "Interface ClientProcessorMXBean {\n\t// Drop all active connections.\n\tvoid dropAllConnections();\n\t// Drops client connection by id, if exists.\n\tboolean dropConnection(long id);\n\t// Returns list of active connections.\n\tList<String> getConnections();\n\t// If sets to true shows full stack trace otherwise highlevel short error message.\n\tvoid showFullStackOnClientSide(boolean show);\n}", "des": "MXBean interface that provides access to ODBC\\JDBC\\Thin client connections."}
{"index": 299, "repo": "ignite-core-2.15.0", "code": "Class ClientResourceRegistry {\n\t// Cleans all handles and closes all ClientCloseableResources.\n\tvoid clean();\n\t// Gets the object by handle.\n\t<T> T get(long hnd);\n\t// Allocates server handle for an object.\n\tlong put(Object obj);\n\t// Releases the handle.\n\tvoid release(long hnd);\n}", "des": "Per-connection resource registry."}
{"index": 300, "repo": "ignite-core-2.15.0", "code": "Class ClientResponse {\n\t// Encodes the response data.\n\tvoid encode(ClientConnectionContext ctx, BinaryRawWriterEx writer);\n\t// Encodes the response data.\n\tvoid encode(ClientConnectionContext ctx, BinaryRawWriterEx writer, ClientAffinityTopologyVersion affinityVer);\n\t// Gets the request id.\n\tlong requestId();\n}", "des": "Thin client response."}
{"index": 301, "repo": "ignite-core-2.15.0", "code": "Interface ClientRetryPolicyContext {\n\t// Gets the client configuration.\n\tClientConfiguration configuration();\n\t// Gets the connection exception that caused current retry iteration.\n\tClientConnectionException exception();\n\t// Gets the current iteration number (zero-based).\n\tint iteration();\n\t// Gets the operation type.\n\tClientOperationType operation();\n}", "des": "Retry policy context. See ClientRetryPolicy.shouldRetry(org.apache.ignite.client.ClientRetryPolicyContext)."}
{"index": 302, "repo": "ignite-core-2.15.0", "code": "Interface ClientTransaction {\n\t// Ends the transaction.\n\tvoid close();\n\t// Commits this transaction.\n\tvoid commit();\n\t// Rolls back this transaction.\n\tvoid rollback();\n}", "des": "Thin client transaction."}
{"index": 303, "repo": "ignite-core-2.15.0", "code": "Interface ClientTxAwareRequest {\n\t// Request was made under transaction.\n\tboolean isTransactional();\n\t// Gets transaction ID.\n\tint txId();\n}", "des": "Interface for transaction aware requests."}
{"index": 304, "repo": "ignite-core-2.15.0", "code": "Class ClientTxContext {\n\t// Acquire context to work with transaction in the current thread.\n\tvoid acquire(boolean resumeTx);\n\t// Close transaction context.\n\tvoid close();\n\t// Release context.\n\tvoid release(boolean suspendTx);\n\t// Gets transaction.\n\tGridNearTxLocal tx();\n\t// Gets transaction id.\n\tint txId();\n}", "des": "Client transaction context."}
{"index": 305, "repo": "ignite-core-2.15.0", "code": "Class ClockPageReplacementFlags {\n\t// Clear page hit flag.\n\tvoid clearFlag(int pageIdx);\n\t// Find page to replace.\n\tint poll();\n\t// Memory required to service pagesCnt pages.\n\tstatic long requiredMemory(int pagesCnt);\n\t// Set page hit flag.\n\tvoid setFlag(int pageIdx);\n}", "des": "Clock page replacement algorithm implementation."}
{"index": 306, "repo": "ignite-core-2.15.0", "code": "Class ClockPageReplacementPolicy {\n\t// Existing page touched.\n\tvoid onHit(long relPtr);\n\t// Page removed from the page memory.\n\tvoid onRemove(long relPtr);\n\t// Finds page to replace.\n\tlong replace();\n}", "des": "CLOCK page replacement policy implementation."}
{"index": 307, "repo": "ignite-core-2.15.0", "code": "Class ClockPageReplacementPolicyFactory {\n\t// Create page replacement policy.\n\tPageReplacementPolicy create(org.apache.ignite.internal.processors.cache.persistence.pagemem.PageMemoryImpl.Segment seg, long ptr, int pagesCnt);\n\t// Calculaete amount of memory required to service pagesCnt pages.\n\tlong requiredMemory(int pagesCnt);\n}", "des": "ClockPageReplacementPolicy factory."}
{"index": 308, "repo": "ignite-core-2.15.0", "code": "Class ClusterGraph {\n\t// Checks that given nodesSet forms fully-connected component.\n\tboolean checkFullyConnected(BitSet nodesSet);\n\t// Finds connected components in cluster graph.\n\tList<BitSet> findConnectedComponents();\n\t// Finds largest fully-connected component from given nodesSet.\n\tBitSet findLargestFullyConnectedComponent(BitSet nodesSet);\n}", "des": "Class to represent cluster nodes avalaible connections as graph. Provides several graph algorithms to analyze cluster nodes connections."}
{"index": 309, "repo": "ignite-core-2.15.0", "code": "Class ClusterNodeAttributeAffinityBackupFilter {\n\t// Defines a predicate which returns true if a node is acceptable for a backup or false otherwise.\n\tboolean apply(ClusterNode candidate, List<ClusterNode> previouslySelected);\n\t// Gets attribute names.\n\tString[] getAttributeNames();\n}", "des": "Attribute-based affinity backup filter that forces each partition's primary and backup nodes to different hardware which is not expected to fail simultaneously, e.g., in AWS, to different \"availability zones\". This is a per-partition selection, and different partitions may choose different primaries. See RendezvousAffinityFunction.setAffinityBackupFilter(org.apache.ignite.lang.IgniteBiPredicate<org.apache.ignite.cluster.ClusterNode, java.util.List<org.apache.ignite.cluster.ClusterNode>>)."}
{"index": 310, "repo": "ignite-core-2.15.0", "code": "Class ClusterNodeViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ClusterNodeView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ClusterNodeView attributes walker."}
{"index": 311, "repo": "ignite-core-2.15.0", "code": "Interface ClusterStartNodeResult {\n\t// Gets error message if any.\n\t@Nullable String getError();\n\t// Gets host name.\n\tString getHostName();\n\t// Gets result of success or failure.\n\tboolean isSuccess();\n}", "des": "Cluster start node result information."}
{"index": 312, "repo": "ignite-core-2.15.0", "code": "Class ClusterStartNodeResultImpl {\n\t// Gets error message if any.\n\tString getError();\n\t// Gets host name.\n\tString getHostName();\n\t// Gets result of success or failure.\n\tboolean isSuccess();\n\t// Sets error message.\n\tvoid setError(String error);\n\t// Sets host name.\n\tvoid setHostName(String hostName);\n\t// Sets success result.\n\tvoid setSuccess(boolean success);\n}", "des": "Implementation for cluster start node result."}
{"index": 313, "repo": "ignite-core-2.15.0", "code": "Enum ClusterState {\n\tboolean active();\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable ClusterState fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClusterState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClusterState[] values();\n}", "des": "Cluster states."}
{"index": 314, "repo": "ignite-core-2.15.0", "code": "Class ClusterTagUpdatedEvent {\n\t// Cluster ID which tag was updated.\n\tUUID clusterId();\n\t// Value of cluster tag after update request that triggered this event.\n\tString newTag();\n\t// Value of cluster tag before update request that triggered this event.\n\tString previousTag();\n}", "des": "Event type indicating that cluster tag has been updated."}
{"index": 315, "repo": "ignite-core-2.15.0", "code": "Interface CollisionContext {\n\t// Gets ordered collection of collision contexts for jobs that are currently executing.\n\tCollection<CollisionJobContext> activeJobs();\n\t// Gets collection of jobs that are currently in held state.\n\tCollection<CollisionJobContext> heldJobs();\n\t// Gets ordered collection of collision contexts for jobs that are currently waiting for execution.\n\tCollection<CollisionJobContext> waitingJobs();\n}", "des": "Context for resolving collisions. This context contains collections of waiting jobs, active jobs, and held jobs. If continuations are not used (see ComputeJobContinuation), then collection of held jobs will always be empty. CollisionSpi will manipulate these lists to make sure that only allowed number of jobs are running in parallel or waiting to be executed."}
{"index": 316, "repo": "ignite-core-2.15.0", "code": "Interface CollisionJobContext {\n\t// Activates the job.\n\tboolean activate();\n\t// Cancels the job.\n\tboolean cancel();\n\t// Job for this context.\n\tComputeJob getJob();\n\t// Gets job context.\n\tComputeJobContext getJobContext();\n\t// Gets current task session associated with this job.\n\tComputeTaskSession getTaskSession();\n}", "des": "This interface defines set of operations that collision SPI implementation can perform on jobs that are either waiting or executing."}
{"index": 317, "repo": "ignite-core-2.15.0", "code": "Interface CollisionSpi {\n\t// This is a callback called: new grid job arrived executing job finished its execution topology changed periodically (on EventType.EVT_NODE_METRICS_UPDATED) When new job arrives it is added to the end of the wait list and this method is called.\n\tvoid onCollision(CollisionContext ctx);\n\t// Listener to be set for notification of external collision events (e.g. job stealing).\n\tvoid setExternalCollisionListener(@Nullable CollisionExternalListener lsnr);\n}", "des": "Collision SPI allows to regulate how grid jobs get executed when they arrive on a destination node for execution. Its functionality is similar to tasks management via customizable GCD (Great Central Dispatch) on Mac OS X as it allows developer to provide custom job dispatching on a single node. In general a grid node will have multiple jobs arriving to it for execution and potentially multiple jobs that are already executing or waiting for execution on it. There are multiple possible strategies dealing with this situation, like all jobs can proceed in parallel, or jobs can be serialized i.e., or only one job can execute in any given point of time, or only certain number or types of grid jobs can proceed in parallel, etc..."}
{"index": 318, "repo": "ignite-core-2.15.0", "code": "Class ColumnStatisticsCollector {\n\t// Add value to statistics.\n\tvoid add(Object val);\n\t// Aggregate specified (partition or local) column statistics into (local or global) single one.\n\tstatic ColumnStatistics aggregate(List<ColumnStatistics> partStats, StatisticsColumnOverrides overrides);\n\tint columnId();\n\tString columnName();\n\tClass<?> columnType();\n\t// Get total column statistics.\n\tColumnStatistics finish();\n}", "des": "Collector to compute statistic by single column."}
{"index": 319, "repo": "ignite-core-2.15.0", "code": "Class CommandLineStartup {\n\t// Tests whether argument is help argument.\n\tstatic boolean isHelp(String arg);\n\t// Main entry point.\n\tstatic void main(String[] args);\n}", "des": "This class defines command-line Ignite startup. This startup can be used to start Ignite outside of any hosting environment from command line. This startup is a Java application with main(String[]) method that accepts command line arguments. It accepts just one parameter which is Spring XML configuration file path. You can run this class from command line without parameters to get help message."}
{"index": 320, "repo": "ignite-core-2.15.0", "code": "Interface CommunicationListener<T extends Serializable> {\n\t// Callback invoked when connection with remote node is lost.\n\tvoid onDisconnected(UUID nodeId);\n\t// NOTE: CommunicationSpi should ignore very first 4 bytes received from sender node and pass the rest of the received message to the listener.\n\tvoid onMessage(UUID nodeId, T msg, IgniteRunnable msgC);\n}", "des": "Listener SPI notifies IO manager with."}
{"index": 321, "repo": "ignite-core-2.15.0", "code": "Class CommunicationWorker {\n\tvoid addProcessDisconnectRequest(DisconnectedSessionInfo sesInfo);\n\t// Connection stat processing.\n\tprotected void body();\n\t// Marks that instance must destroyed.\n\tvoid stop();\n}", "des": "Works with connections states."}
{"index": 322, "repo": "ignite-core-2.15.0", "code": "Interface CompactablePageIO {\n\t// Compacts page contents to the output buffer.\n\tvoid compactPage(ByteBuffer page, ByteBuffer out, int pageSize);\n\t// Restores the original page in place.\n\tvoid restorePage(ByteBuffer compactPage, int pageSize);\n}", "des": "Page IO that supports compaction."}
{"index": 323, "repo": "ignite-core-2.15.0", "code": "Interface ComputeGridMonitor {\n\t// Processing a change in a task.\n\tvoid processStatusChange(ComputeTaskStatusSnapshot snapshot);\n\t// Processing task snapshots.\n\tvoid processStatusSnapshots(Collection<ComputeTaskStatusSnapshot> snapshots);\n}", "des": "Monitor for updating task statuses."}
{"index": 324, "repo": "ignite-core-2.15.0", "code": "Interface ComputeJob {\n\t// This method is called when system detects that completion of this job can no longer alter the overall outcome (for example, when parent task has already reduced the results).\n\tvoid cancel();\n\t// Executes this job.\n\tObject execute();\n}", "des": "Defines executable unit for ComputeTask. Description Grid job is an executable unit of ComputeTask. Grid task gets split into jobs when ComputeTask.map(List, Object) method is called. This method returns all jobs for the task mapped to their corresponding grid nodes for execution. Grid will then serialize this jobs and send them to requested nodes for execution. When a node receives a request to execute a job, the following sequence of events takes place: If collision SPI is defined, then job gets put on waiting list which is passed to underlying CollisionSpi SPI. Otherwise job will be submitted to the executor service responsible for job execution immediately upon arrival. If collision SPI is configured, then it will decide one of the following scheduling policies: Job will be kept on waiting list. In this case, job will not get a chance to execute until next time the Collision SPI is called. Job will be moved to active list. In this case system will proceed with job execution. Job will be rejected. In this case the ComputeJobResult passed into ComputeTask.result(ComputeJobResult, List) method will contain ComputeExecutionRejectedException exception. If you are using any of the task adapters shipped with Ignite, then job will be failed over automatically for execution on another node. For activated jobs, an instance of distributed task session (see ComputeTaskSession) will be injected. System will execute the job by calling execute() method. If job gets cancelled while executing then cancel() method will be called. Note that just like with Thread.interrupt() method, grid job cancellation serves as a hint that a job should stop executing or exhibit some other user defined behavior. Generally it is up to a job to decide whether it wants to react to cancellation or ignore it. Job cancellation can happen for several reasons: Collision SPI cancelled an active job. Parent task has completed without waiting for this job's result. User cancelled task by calling IgniteFuture.cancel() method. Once job execution is complete, the return value will be sent back to parent task and will be passed into ComputeTask.result(ComputeJobResult, List) method via ComputeJobResult instance. If job execution resulted in a checked exception, then ComputeJobResult.getException() method will contain that exception. If job execution threw a runtime exception or error, then it will be wrapped into ComputeUserUndeclaredException exception."}
{"index": 325, "repo": "ignite-core-2.15.0", "code": "Interface ComputeJobContext {\n\t// Gets attribute from this job context.\n\t<K,V> V getAttribute(K key);\n\t// Gets all attributes present in this job context.\n\tMap<?,?> getAttributes();\n\t// Gets ID of the job this context belongs to.\n\tIgniteUuid getJobId();\n\t// Sets an attribute into this job context.\n\tvoid setAttribute(Object key, @Nullable Object val);\n\t// Sets map of attributes into this job context.\n\tvoid setAttributes(Map<?,?> attrs);\n}", "des": "Context attached to every job executed on the grid. Note that unlike ComputeTaskSession, which distributes all attributes to all jobs in the task including the task itself, job context attributes belong to a job and do not get sent over network unless a job moves from one node to another."}
{"index": 326, "repo": "ignite-core-2.15.0", "code": "Interface ComputeJobContinuation {\n\t// Resumes job if it was held by holdcc() method.\n\tvoid callcc();\n\t// Checks if job execution has been temporarily held (suspended).\n\tboolean heldcc();\n\t// Holds (suspends) a given job indefinitely until callcc() is called.\n\t<T> T holdcc();\n\t// Holds (suspends) a given job for specified timeout or until callcc() is called.\n\t<T> T holdcc(long timeout);\n}", "des": "Defines continuation support for grid job context."}
{"index": 327, "repo": "ignite-core-2.15.0", "code": "Class ComputeJobContinuationAdapter {\n\t// Resumes job if it was held by ComputeJobContinuation.holdcc() method.\n\tvoid callcc();\n\t// Checks if job execution has been temporarily held (suspended).\n\tboolean heldcc();\n\t// Holds (suspends) a given job indefinitely until ComputeJobContinuation.callcc() is called.\n\t<T> T holdcc();\n\t// Holds (suspends) a given job for specified timeout or until ComputeJobContinuation.callcc() is called.\n\t<T> T holdcc(long timeout);\n}", "des": "Convenience adapter for ComputeJob implementations. It provides the following functionality: Default implementation of ComputeJob.cancel() method and ability to check whether cancellation occurred. Ability to set and get a job arguments via ComputeJobAdapter.setArguments(Object...) and ComputeJobAdapter.argument(int) methods. Here is an example of how ComputeJobAdapter can be used from task logic to create jobs. The example creates job adapter as anonymous class, but you are free to create a separate class for it. public class TestGridTask extends ComputeTaskSplitAdapter { // Used to imitate some logic for the // sake of this example private int multiplier = 3; @Override protected Collection split(int gridSize, final String arg) throws IgniteCheckedException { List> jobs = new ArrayList>(gridSize); for (int i = 0; i < gridSize; i++) { jobs.add(new ComputeJobAdapter() { // Job execution logic. public Object execute() throws IgniteCheckedException { return multiplier * arg.length(); } }); } return jobs; } // Aggregate multiple job results into // one task result. public Integer reduce(List results) throws IgniteCheckedException { int sum = 0; // For the sake of this example, let's sum all results. for (ComputeJobResult res : results) { sum += (Integer)res.getData(); } return sum; } }"}
{"index": 328, "repo": "ignite-core-2.15.0", "code": "Enum ComputeJobResultPolicy {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable ComputeJobResultPolicy fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ComputeJobResultPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ComputeJobResultPolicy[] values();\n}", "des": "This enumeration provides different types of actions following the last received job result. See ComputeTask.result(ComputeJobResult, List) for more details."}
{"index": 329, "repo": "ignite-core-2.15.0", "code": "Interface ComputeJobSibling {\n\t// Sends a request to cancel this sibling.\n\tvoid cancel();\n\t// Gets ID of this grid job sibling.\n\tIgniteUuid getJobId();\n}", "des": "Job sibling interface defines a job from the same split. In other words a sibling is a job returned from the same ComputeTask.map(List, Object) method invocation."}
{"index": 330, "repo": "ignite-core-2.15.0", "code": "Enum ComputeJobStatusEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ComputeJobStatusEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ComputeJobStatusEnum[] values();\n}", "des": "Compute job status."}
{"index": 331, "repo": "ignite-core-2.15.0", "code": "Enum ComputeJobView.ComputeJobState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ComputeJobView.ComputeJobState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ComputeJobView.ComputeJobState[] values();\n}", "des": "Compute job state."}
{"index": 332, "repo": "ignite-core-2.15.0", "code": "Class ComputeJobViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ComputeJobView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ComputeJobView attributes walker."}
{"index": 333, "repo": "ignite-core-2.15.0", "code": "Class ComputeMXBeanImpl {\n\t// Kills compute task by the session idenitifier.\n\tvoid cancel(IgniteUuid sesId);\n\t// Kills compute task by the session idenitifier.\n\tvoid cancel(String sesId);\n}", "des": "ComputeMXBean implementation."}
{"index": 334, "repo": "ignite-core-2.15.0", "code": "Interface ComputeTaskContinuousMapper {\n\t// Sends collection of jobs to nodes automatically picked by the underlying load balancer.\n\tvoid send(Collection<? extends ComputeJob> jobs);\n\t// Sends job to a node automatically picked by the underlying load balancer.\n\tvoid send(ComputeJob job);\n\t// Sends given job to a specific grid node.\n\tvoid send(ComputeJob job, ClusterNode node);\n\t// Sends collection of grid jobs to assigned nodes.\n\tvoid send(Map<? extends ComputeJob,ClusterNode> mappedJobs);\n}", "des": "Defines a mapper that can be used for asynchronous job sending. Useful for streaming jobs within the same task. Note that if job number within a task grows too large, it is best to attach ComputeTaskNoResultCache annotation to task to make sure that collection of job results and job siblings does not grow indefinitely."}
{"index": 335, "repo": "ignite-core-2.15.0", "code": "Interface ComputeTaskFuture<R> {\n\t// Synchronously waits for completion of the computation and returns computation result.\n\tR get();\n\t// Synchronously waits for completion of the computation for up to the timeout specified and returns computation result.\n\tR get(long timeout, TimeUnit unit);\n\t// Gets task session of execution grid task.\n\tComputeTaskSession getTaskSession();\n}", "des": "This class defines a handler for asynchronous task execution. It's similar in design to standard JDK Future interface but has improved and easier to use exception hierarchy."}
{"index": 336, "repo": "ignite-core-2.15.0", "code": "Class ComputeTaskInternalFuture<R> {\n\t// Default no-op implementation that always returns false.\n\tboolean cancel();\n\tstatic <R> ComputeTaskInternalFuture<R> finishedFuture(GridKernalContext ctx, Class<?> taskCls, IgniteCheckedException e);\n\t// Gets task timeout.\n\tComputeTaskSession getTaskSession();\n\tIgniteLogger logger();\n\tComputeTaskFuture<R> publicFuture();\n}", "des": "This class provide implementation for task future."}
{"index": 337, "repo": "ignite-core-2.15.0", "code": "Enum ComputeTaskSessionScope {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable ComputeTaskSessionScope fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ComputeTaskSessionScope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ComputeTaskSessionScope[] values();\n}", "des": "Defines life-time scopes for checkpoint operations. Such operations include: ComputeTaskSession.saveCheckpoint(String, Object, ComputeTaskSessionScope, long)"}
{"index": 338, "repo": "ignite-core-2.15.0", "code": "Class ComputeTaskSplitAdapter<T,R> {\n\t// This method is called to map or split grid task into multiple grid jobs.\n\t@NotNull Map<? extends ComputeJob,ClusterNode> map(List<ClusterNode> subgrid, T arg);\n\t// This is a simplified version of ComputeTask.map(List, Object) method.\n\tprotected abstract Collection<? extends ComputeJob> split(int gridSize, T arg);\n}", "des": "This class defines simplified adapter for ComputeTask. This adapter can be used when jobs can be randomly assigned to available grid nodes. This adapter is sufficient in most homogeneous environments where all nodes are equally suitable for executing grid job. See split(int, Object) method for more details."}
{"index": 339, "repo": "ignite-core-2.15.0", "code": "Enum ComputeTaskStatusEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ComputeTaskStatusEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ComputeTaskStatusEnum[] values();\n}", "des": "Task status."}
{"index": 340, "repo": "ignite-core-2.15.0", "code": "Class ComputeTaskViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ComputeTaskView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ComputeTaskView attributes walker."}
{"index": 341, "repo": "ignite-core-2.15.0", "code": "Class ConcurrentLinkedHashMap.HashEntry<K,V> {\n\t// Returns key of this entry.\n\tK getKey();\n\t// Return value of this entry.\n\tV getValue();\n}", "des": "ConcurrentHashMap list entry. Note that this is never exported out as a user-visible Map.Entry. Because the value field is volatile, not final, it is legal wrt the Java Memory Model for an unsynchronized reader to see null instead of initial value when read via a data race. Although a reordering leading to this is not likely to ever actually occur, the Segment.readValueUnderLock method is used as a snapshot in case a null (pre-initialized) value is ever seen in an unsynchronized access method."}
{"index": 342, "repo": "ignite-core-2.15.0", "code": "Enum ConcurrentLinkedHashMap.QueuePolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConcurrentLinkedHashMap.QueuePolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConcurrentLinkedHashMap.QueuePolicy[] values();\n}", "des": "Defines queue policy for this hash map."}
{"index": 343, "repo": "ignite-core-2.15.0", "code": "Class ConfigurationViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ConfigurationView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ConfigurationView attributes walker."}
{"index": 344, "repo": "ignite-core-2.15.0", "code": "Class ConnectGateway {\n\tvoid disconnected(IgniteFuture<?> reconnectFut);\n\t// Enter to critical section.\n\tvoid enter();\n\t// Leave critical section.\n\tvoid leave();\n\t// Reset error.\n\tvoid reconnected();\n\t// Add error to this class.\n\tvoid stopped();\n\tboolean tryEnter();\n}", "des": "Lock and error control work flow."}
{"index": 345, "repo": "ignite-core-2.15.0", "code": "Interface ConnectorMessageInterceptor {\n\t// Intercepts received objects.\n\t@Nullable Object onReceive(@Nullable Object obj);\n\t// Intercepts received objects.\n\t@Nullable Object onSend(Object obj);\n}", "des": "Interface for user-defined object interceptors."}
{"index": 346, "repo": "ignite-core-2.15.0", "code": "Class ConsistentIdMapper {\n\t// Maps UUID to compact ID for given baseline topology.\n\tshort mapToCompactId(AffinityTopologyVersion topVer, UUID nodeId);\n\t// Map primary -> backup node compact ID accordingly to baseline topology..\n\tMap<Short,Collection<Short>> mapToCompactIds(AffinityTopologyVersion topVer, @Nullable Map<UUID,Collection<UUID>> txNodes, BaselineTopology baselineTop);\n\t// Maps UUID to compact ID for given baseline topology.\n\tUUID mapToUuid(AffinityTopologyVersion topVer, short nodeConstId);\n}", "des": "Class is needed for map UUID to consistent id and vice versa."}
{"index": 347, "repo": "ignite-core-2.15.0", "code": "Class ContinuousQueryViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ContinuousQueryView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ContinuousQueryView attributes walker."}
{"index": 348, "repo": "ignite-core-2.15.0", "code": "Class CountDownLatchViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(CountDownLatchView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. CountDownLatchView attributes walker."}
{"index": 349, "repo": "ignite-core-2.15.0", "code": "Class DataEntry {\n\tint cacheId();\n\tlong expireTime();\n\t// Entry flags.\n\tbyte flags();\n\tstatic byte flags(boolean primary);\n\tstatic byte flags(boolean primary, boolean preload, boolean fromStore);\n\tKeyCacheObject key();\n\tGridCacheVersion nearXidVersion();\n\tGridCacheOperation op();\n\tlong partitionCounter();\n\t// Sets partition update counter to entry.\n\tDataEntry partitionCounter(long partCnt);\n\tint partitionId();\n\tCacheObject value();\n\tGridCacheVersion writeVersion();\n}", "des": "Represents Data Entry (key, value) pair update operation in WAL log."}
{"index": 350, "repo": "ignite-core-2.15.0", "code": "Enum DataPageEvictionMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable DataPageEvictionMode fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DataPageEvictionMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DataPageEvictionMode[] values();\n}", "des": "Defines memory page eviction algorithm. A mode is set for a specific DataRegionConfiguration. Only data pages, that store key-value entries, are eligible for eviction. The other types of pages, like index or meta pages, are not evictable."}
{"index": 351, "repo": "ignite-core-2.15.0", "code": "Interface DataRegionMetricsProvider {\n\t// Calculates empty data pages count for region.\n\tlong emptyDataPages();\n\t// Calculates free space of partially filled pages for this data region.\n\tlong partiallyFilledPagesFreeSpace();\n}", "des": "This interface provides calculated metrics for data region."}
{"index": 352, "repo": "ignite-core-2.15.0", "code": "Class DataStreamerUpdatesHandler {\n\t// Processing the results of the SnapshotHandler.invoke(SnapshotHandlerContext) method received from all nodes.\n\tvoid complete(String name, Collection<SnapshotHandlerResult<Boolean>> results);\n\t// Local processing of a snapshot operation.\n\tBoolean invoke(SnapshotHandlerContext ctx);\n\t// Snapshot handler type.\n\tSnapshotHandlerType type();\n}", "des": "A snapshot haldler that monitors and warns of inconsistent by nature updates from DataStreamer which can issue data inconsistency in snapshot."}
{"index": 353, "repo": "ignite-core-2.15.0", "code": "Class DateInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected DateIndexKey get0(long pageAddr, int off);\n\t// Return inlined size for specified key.\n\tprotected int inlineSize0(DateIndexKey key);\n\tboolean isComparableTo(IndexKey key);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, DateIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining DateIndexKey values."}
{"index": 354, "repo": "ignite-core-2.15.0", "code": "Class DB2Dialect {\n\tboolean hasMerge();\n\t// Construct query to get ranges bounds.\n\tString loadCacheSelectRangeQuery(String fullTblName, Collection<String> keyCols);\n\t// Construct merge query.\n\tString mergeQuery(String fullTblName, Collection<String> keyCols, Collection<String> uniqCols);\n}", "des": "A dialect compatible with the IBM DB2 database."}
{"index": 355, "repo": "ignite-core-2.15.0", "code": "Class DeadlockProbe {\n\tProbedTx blocker();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tGridCacheVersion initiatorVersion();\n\tboolean nearCheck();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tCollection<ProbedTx> waitChain();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Probe message travelling between transactions (from waiting to blocking) during deadlock detection."}
{"index": 356, "repo": "ignite-core-2.15.0", "code": "Class DeferredSpan {\n\t// Logs work to span.\n\tSpan addLog(Supplier<String> logDescSupplier);\n\t// Adds tag to span with String value.\n\tSpan addTag(String tagName, Supplier<String> tagValSupplier);\n\t// Ends span.\n\tSpan end();\n\tSet<Scope> includedScopes();\n\tboolean isChainable(Scope scope);\n\tboolean isEnded();\n\tbyte[] serializedSpan();\n\t// Explicitly set status for span.\n\tSpan setStatus(SpanStatus spanStatus);\n\tSpanType type();\n}", "des": "Encapsulates concept of a deferred-initialized span. It's used to overcome OpenCensus span implementation, that starts span immediately after deserialization."}
{"index": 357, "repo": "ignite-core-2.15.0", "code": "Interface DefragmentationMXBean {\n\t// Cancel defragmentation.\n\tboolean cancel();\n\t// Get defragmentation status.\n\tboolean inProgress();\n\t// Get count of processed partitions.\n\tint processedPartitions();\n\t// Schedule defragmentation for given caches.\n\tboolean schedule(String cacheNames);\n\t// Get defragmentation's start time.\n\tlong startTime();\n\t// Get total count of partitions.\n\tint totalPartitions();\n}", "des": "JMX bean for defragmentation manager."}
{"index": 358, "repo": "ignite-core-2.15.0", "code": "Class DefragmentationMXBeanImpl {\n\t// Cancel defragmentation.\n\tboolean cancel();\n\t// Get defragmentation status.\n\tboolean inProgress();\n\t// Get count of processed partitions.\n\tint processedPartitions();\n\t// Schedule defragmentation for given caches.\n\tboolean schedule(String cacheNames);\n\t// Get defragmentation's start time.\n\tlong startTime();\n\t// Get total count of partitions.\n\tint totalPartitions();\n}", "des": "Defragmentation MX bean implementation."}
{"index": 359, "repo": "ignite-core-2.15.0", "code": "Class DelayedDirtyPageStoreWrite {\n\t// Runs actual write if required.\n\tvoid finishReplacement();\n\t// Callback for write page.\n\tvoid writePage(FullPageId fullPageId, ByteBuffer byteBuf, int tag);\n}", "des": "Not thread safe and stateful class for page replacement of one page with write() delay. This allows to write page content without holding segment lock. Page data is copied into temp buffer during writePage(FullPageId, ByteBuffer, int) and then sent to real implementation by finishReplacement()."}
{"index": 360, "repo": "ignite-core-2.15.0", "code": "Class DeploymentEvent {\n\t// Gets deployment alias for this event.\n\tString alias();\n\t// Sets deployment alias for this event.\n\tvoid alias(String alias);\n\t// Gets a shortened version of toString() result.\n\tString shortDisplay();\n}", "des": "Grid deployment event."}
{"index": 361, "repo": "ignite-core-2.15.0", "code": "Enum DeploymentMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable DeploymentMode fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DeploymentMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DeploymentMode[] values();\n}", "des": "Grid deployment mode. Deployment mode is specified at grid startup via IgniteConfiguration.getDeploymentMode() configuration property (it can also be specified in Spring XML configuration file). The main difference between all deployment modes is how classes are loaded on remote nodes via peer-class-loading mechanism."}
{"index": 362, "repo": "ignite-core-2.15.0", "code": "Interface DeploymentResource {\n\t// Gets resource class loader.\n\tClassLoader getClassLoader();\n\t// Gets resource name, either class name or alias name, such as alias specified by ComputeTaskName annotation.\n\tString getName();\n\t// Gets resource class.\n\tClass<?> getResourceClass();\n}", "des": "Generic abstraction over deployed resource containing resource's name, class and corresponding class loader."}
{"index": 363, "repo": "ignite-core-2.15.0", "code": "Class DeploymentResourceAdapter {\n\tboolean equals(Object obj);\n\t// Gets resource class loader.\n\tClassLoader getClassLoader();\n\t// Gets resource name, either class name or alias name, such as alias specified by ComputeTaskName annotation.\n\tString getName();\n\t// Gets resource class.\n\tClass<?> getResourceClass();\n}", "des": "Simple adapter for DeploymentResource interface."}
{"index": 364, "repo": "ignite-core-2.15.0", "code": "Interface DeploymentSpi {\n\t// Finds class loader for the given class.\n\tDeploymentResource findResource(String rsrcName);\n\t// Registers a class loader with this SPI.\n\tboolean register(ClassLoader ldr, Class<?> rsrc);\n\t// Sets or unsets deployment event listener.\n\tvoid setListener(@Nullable DeploymentListener lsnr);\n\t// Unregisters all class loaders that have a class with given name or have a class with give ComputeTaskName value.\n\tboolean unregister(String rsrcName);\n}", "des": "Grid deployment SPI is in charge of deploying tasks and classes from different sources."}
{"index": 365, "repo": "ignite-core-2.15.0", "code": "Class DiagnosticProcessor {\n\t// Creation and filling of a file with pages that can be corrupted.\n\tstatic File corruptedPagesFile(Path dirPath, FileIOFactory ioFactory, int grpId, long... pageIds);\n\t// Print diagnostic info about failure occurred on ignite instance.\n\tvoid onFailure(FailureContext failureCtx);\n}", "des": "Processor which contained helper methods for different diagnostic cases."}
{"index": 366, "repo": "ignite-core-2.15.0", "code": "Interface DirectMemoryProvider {\n\tvoid initialize(long[] chunkSizes);\n\t// Attempts to allocate next memory region.\n\tDirectMemoryRegion nextRegion();\n\t// Shuts down the provider.\n\tvoid shutdown(boolean deallocate);\n}", "des": "Direct memory provider interface. Not thread-safe."}
{"index": 367, "repo": "ignite-core-2.15.0", "code": "Class DirectMessageState<T extends DirectMessageStateItem> {\n\t// Go backward.\n\tvoid backward(boolean reset);\n\t// Go forward.\n\tvoid forward();\n\tT item();\n\t// Resets state.\n\tvoid reset();\n}", "des": "Message state."}
{"index": 368, "repo": "ignite-core-2.15.0", "code": "Interface DiscoveryCustomMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\tDiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n\t// See DiscoverySpiCustomMessage.stopProcess().\n\tdefault boolean stopProcess();\n}", "des": "DiscoveryCustomMessage messages are handled by discovery protocol which provides some guarantees around them. When some node sends DiscoveryCustomMessage with GridDiscoveryManager.sendCustomEvent(DiscoveryCustomMessage) call, message firstly goes to current coordinator, is verified there and after that gets sent to the cluster. Only after verification it is delivered to listeners on all nodes starting from coordinator. To register a listener GridDiscoveryManager.setCustomEventListener(Class, CustomEventListener) method is used. Discovery protocol guarantees include: All discovery messages are observed by all nodes in exactly the same order, it is guaranteed by handling them in single-threaded mode. New server node joining process in default implementation involves two passes of different messages across the cluster: TcpDiscoveryNodeAddedMessage and TcpDiscoveryNodeAddFinishedMessage messages. It is guaranteed that all discovery messages observed by coordinator in between these two messages are reordered and guaranteed to be delivered to newly joined node. Yet there are some features and limitations one should be aware of when using custom discovery messaging mechanism: Guarantee #2 doesn't encompass DiscoveryCustomMessages created automatically on ackMessage() method call. If there were messages of this type in between TcpDiscoveryNodeAddedMessage and TcpDiscoveryNodeAddFinishedMessage messages, they won't be delivered to new joiner node. There is no guarantee for a given DiscoveryCustomMessage to be delivered only once. It is possible that because of node failure antecedent node will resend messages it thinks were not sent by failed node. Duplicate messages are not filtered out on receiver side. DiscoveryCustomMessages are delivered to client nodes in asynchronous fashion as clients don't participate in the cluster ring. Any blocking operations like obtaining locks or doing I/O must be avoided in message handlers as they may lead to deadlocks and cluster failures."}
{"index": 369, "repo": "ignite-core-2.15.0", "code": "Interface DiscoveryMetricsProvider {\n\t// Returns metrics data about all caches on local node.\n\tMap<Integer,CacheMetrics> cacheMetrics();\n\t// This method always returns up-to-date metrics data about local node.\n\tClusterMetrics metrics();\n}", "des": "Provides metrics to discovery SPI. It is responsibility of discovery SPI to make sure that all nodes have updated metrics data about each other."}
{"index": 370, "repo": "ignite-core-2.15.0", "code": "Interface DiscoverySpiCustomMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoverySpiCustomMessage ackMessage();\n\tboolean isMutable();\n\t// Called on discovery coordinator node after listener is notified.\n\tboolean stopProcess();\n}", "des": "Message to send across ring."}
{"index": 371, "repo": "ignite-core-2.15.0", "code": "Interface DiscoverySpiDataExchange {\n\t// Collects data from all components.\n\tDiscoveryDataBag collect(DiscoveryDataBag dataBag);\n\t// Notifies discovery manager about data received from remote node.\n\tvoid onExchange(DiscoveryDataBag dataBag);\n}", "des": "Handler for initial data exchange between Ignite nodes. Data exchange is initiated by a new node when it tries to join topology and finishes before it actually joins."}
{"index": 372, "repo": "ignite-core-2.15.0", "code": "Interface DiscoverySpiListener {\n\t// Notification for grid node discovery events.\n\tIgniteFuture<?> onDiscovery(DiscoveryNotification notification);\n\t// Notification of local node initialization.\n\tvoid onLocalNodeInitialized(ClusterNode locNode);\n}", "des": "Listener for grid node discovery events. See DiscoverySpi for information on how grid nodes get discovered."}
{"index": 373, "repo": "ignite-core-2.15.0", "code": "Interface DiscoverySpiMBean {\n\t// Exclude node from discovery.\n\tvoid excludeNode(String nodeId);\n\t// Gets current coordinator node formatted as a string.\n\t@Nullable String getCoordinatorNodeFormatted();\n\t// Gets local node formatted as a string.\n\tString getLocalNodeFormatted();\n\t// Gets failed nodes count.\n\tlong getNodesFailed();\n\t// Gets joined nodes count.\n\tlong getNodesJoined();\n\t// Gets left nodes count.\n\tlong getNodesLeft();\n\t// Gets current SPI state.\n\tString getSpiState();\n}", "des": "Generic MBean interface to monitor DiscoverySpi subsystem."}
{"index": 374, "repo": "ignite-core-2.15.0", "code": "Interface DiscoverySpiNodeAuthenticator {\n\t// Security credentials.\n\tSecurityContext authenticateNode(ClusterNode node, SecurityCredentials cred);\n\t// Gets global node authentication flag.\n\tboolean isGlobalNodeAuthentication();\n}", "des": "Node authenticator."}
{"index": 375, "repo": "ignite-core-2.15.0", "code": "Enum DiskPageCompression {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable DiskPageCompression fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DiskPageCompression valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DiskPageCompression[] values();\n}", "des": "Disk page compression options."}
{"index": 376, "repo": "ignite-core-2.15.0", "code": "Interface DistributedChangeableProperty<T extends Serializable> {\n\t// Update only local value without updating remote cluster.\n\tvoid localUpdate(Serializable newVal);\n\t// This property have been attached to processor.\n\tvoid onAttached();\n\t// On this property ready to be update on cluster wide.\n\tvoid onReadyForUpdate(@NotNull PropertyUpdateClosure updater);\n\tT parse(String str);\n}", "des": "Inner interface to maintenance of distributed property."}
{"index": 377, "repo": "ignite-core-2.15.0", "code": "Interface DistributedConfigurationLifecycleListener {\n\t// Notify about processor ready to register properties.\n\tvoid onReadyToRegister(DistributedPropertyDispatcher dispatcher);\n\t// Notify about processor ready to write.\n\tdefault void onReadyToWrite();\n}", "des": "Lifecycle listener for distributed configuration."}
{"index": 378, "repo": "ignite-core-2.15.0", "code": "Interface DistributedMetastorageLifecycleListener {\n\t// Called when global metastorage is ready for reading.\n\tdefault void onReadyForRead(ReadableDistributedMetaStorage metastorage);\n\t// Called when global metastorage is available for writing.\n\tdefault void onReadyForWrite(DistributedMetaStorage metastorage);\n}", "des": "Listener for DistributedMetaStorage lifecycle events."}
{"index": 379, "repo": "ignite-core-2.15.0", "code": "Enum DistributedProcess.DistributedProcessType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DistributedProcess.DistributedProcessType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DistributedProcess.DistributedProcessType[] values();\n}", "des": "Defines distributed processes."}
{"index": 380, "repo": "ignite-core-2.15.0", "code": "Interface DistributedProperty<T extends Serializable> {\n\tvoid addListener(DistributePropertyListener<? super T> listener);\n\tT get();\n\tString getName();\n\tT getOrDefault(T dfltVal);\n\t// Change value across whole cluster.\n\tboolean propagate(T newVal);\n\t// Change value across whole cluster.\n\tGridFutureAdapter<?> propagateAsync(T newVal);\n\t// Change value across whole cluster.\n\tGridFutureAdapter<?> propagateAsync(T expectedVal, T newVal);\n}", "des": "Public interface of distributed property usage."}
{"index": 381, "repo": "ignite-core-2.15.0", "code": "Interface DistributedPropertyDispatcher {\n\t// Attach already created property.\n\t<T extends DistributedChangeableProperty>void registerProperties(T... props);\n\t// Attach already created property.\n\t<T extends Serializable>DistributedProperty<T> registerProperty(DistributedChangeableProperty<T> prop);\n}", "des": "Dispatcher of distributed properties. Hold of all register properties of distributed configuration."}
{"index": 382, "repo": "ignite-core-2.15.0", "code": "Class DoubleInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected DoubleIndexKey get0(long pageAddr, int off);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, DoubleIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining Double values."}
{"index": 383, "repo": "ignite-core-2.15.0", "code": "Class DoubleMetricImpl {\n\t// Adds x to the metric.\n\tvoid add(double x);\n\t// Resets metric state.\n\tvoid reset();\n\tdouble value();\n\t// Sets value.\n\tvoid value(double val);\n}", "des": "Double metric."}
{"index": 384, "repo": "ignite-core-2.15.0", "code": "Interface DurableBackgroundTask<R> {\n\t// Canceling the task.\n\tvoid cancel();\n\t// Converting the current task to another after restoring from metaStorage.\n\tdefault DurableBackgroundTask<?> convertAfterRestoreIfNeeded();\n\t// Asynchronous task execution.\n\tIgniteInternalFuture<DurableBackgroundTaskResult<R>> executeAsync(GridKernalContext ctx);\n\t// Getting the name of the task to identify it.\n\tString name();\n}", "des": "Durable task that should be used to do long operations (e.g. index deletion) in background."}
{"index": 385, "repo": "ignite-core-2.15.0", "code": "Enum DurableBackgroundTaskState.State {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DurableBackgroundTaskState.State valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DurableBackgroundTaskState.State[] values();\n}", "des": "Enumeration of the current state of the task."}
{"index": 386, "repo": "ignite-core-2.15.0", "code": "Class EarliestCheckpointMapSnapshot {\n\t// Returns true if a checkpoint was present during the snapshot capture, false otherwise.\n\tboolean checkpointWasPresent(UUID checkpointId);\n\t// Gets a group state by a checkpoint id.\n\t@Nullable Map<Integer,CheckpointEntry.GroupState> groupState(UUID checkpointId);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Earliest checkpoint map snapshot. Speeds up construction of the earliestCp map in the CheckpointHistory."}
{"index": 387, "repo": "ignite-core-2.15.0", "code": "Interface EncryptionCacheKeyProvider {\n\t// Returns group encryption key, that was set for writing.\n\t@Nullable GroupKey getActiveKey(int grpId);\n\t// Returns group encryption key with specified ID.\n\t@Nullable GroupKey groupKey(int grpId, int keyId);\n}", "des": "Provider for cache's encryption keys."}
{"index": 388, "repo": "ignite-core-2.15.0", "code": "Class EncryptionConfiguration {\n\t// Gets the number of pages that is scanned during re-encryption under checkpoint lock.\n\tint getReencryptionBatchSize();\n\t// Gets re-encryption rate limit.\n\tdouble getReencryptionRateLimit();\n\t// Sets the number of pages that is scanned during re-encryption under checkpoint lock.\n\tEncryptionConfiguration setReencryptionBatchSize(int reencryptionBatchSize);\n\t// Sets re-encryption rate limit.\n\tEncryptionConfiguration setReencryptionRateLimit(double reencryptionRateLimit);\n}", "des": "Encryption configuration."}
{"index": 389, "repo": "ignite-core-2.15.0", "code": "Interface EncryptionMXBean {\n\t// Starts cache group encryption key change process.\n\tvoid changeCacheGroupKey(String cacheOrGrpName);\n\t// Starts master key change process.\n\tvoid changeMasterKey(String masterKeyName);\n\t// Gets the current master key name.\n\tString getMasterKeyName();\n}", "des": "Encryption features MBean."}
{"index": 390, "repo": "ignite-core-2.15.0", "code": "Class EncryptionMXBeanImpl {\n\t// Starts cache group encryption key change process.\n\tvoid changeCacheGroupKey(String cacheOrGrpName);\n\t// Starts master key change process.\n\tvoid changeMasterKey(String masterKeyName);\n\t// Gets the current master key name.\n\tString getMasterKeyName();\n}", "des": "Encryption features MBean."}
{"index": 391, "repo": "ignite-core-2.15.0", "code": "Enum EnlistOperation {\n\tGridCacheOperation cacheOperation();\n\tstatic @Nullable EnlistOperation fromOrdinal(int ord);\n\tboolean isDeleteOrLock();\n\tboolean isInvoke();\n\t// Indicates that an operation cannot create new row.\n\tboolean noCreate();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EnlistOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EnlistOperation[] values();\n}", "des": "Operations on entries which could be performed during transaction. Operations are used during SQL statements execution, but does not define exact SQL statements semantics. It is better to treat them independently and having their own semantics."}
{"index": 392, "repo": "ignite-core-2.15.0", "code": "Interface EventStorageSpi {\n\t// Queries locally-stored events only.\n\t<T extends Event>Collection<T> localEvents(IgnitePredicate<T> p);\n\t// Records single event.\n\tvoid record(Event evt);\n}", "des": "This SPI provides local node events storage. SPI allows for recording local node events and querying recorded local events. Every node during its life-cycle goes through a serious of events such as task deployment, task execution, job execution, etc. For performance reasons Ignite is designed to store all locally produced events locally. These events can be later retrieved using either distributed query: IgniteEvents.remoteQuery(org.apache.ignite.lang.IgnitePredicate, long, int...) or local only query: IgniteEvents.localQuery(org.apache.ignite.lang.IgnitePredicate, int...) NOTE: this SPI (i.e. methods in this interface) should never be used directly. SPIs provide internal view on the subsystem and is used internally by Ignite kernal. In rare use cases when access to a specific implementation of this SPI is required - an instance of this SPI can be obtained via Ignite.configuration() method to check its configuration properties or call other non-SPI methods. Note again that calling methods from this interface on the obtained instance can lead to undefined behavior and explicitly not supported."}
{"index": 393, "repo": "ignite-core-2.15.0", "code": "Class ExchangeLatchManager {\n\t// Checks that latch manager can use V2 protocol and skip joining nodes from latch participants.\n\tboolean canSkipJoiningNodes(AffinityTopologyVersion topVer);\n\t// Drops client latches created by getOrCreate(String, AffinityTopologyVersion).\n\tvoid dropClientLatches(AffinityTopologyVersion topVer);\n\t// Creates new latch with specified id and topVer or returns existing latch.\n\tLatch getOrCreate(String id, AffinityTopologyVersion topVer);\n}", "des": "Class is responsible to create and manage instances of distributed latches Latch."}
{"index": 394, "repo": "ignite-core-2.15.0", "code": "Class ExecutorConfiguration {\n\t// Get thread pool name.\n\tString getName();\n\t// Get thread pool size.\n\tint getSize();\n\t// Set thread pool name.\n\tExecutorConfiguration setName(String name);\n\t// Set thread pool size.\n\tExecutorConfiguration setSize(int size);\n}", "des": "Custom thread pool configuration for compute tasks. See IgniteCompute.withAsync() for more information."}
{"index": 395, "repo": "ignite-core-2.15.0", "code": "Class ExponentialBackoffTimeoutStrategy {\n\tstatic long backoffTimeout(long timeout, long maxTimeout);\n\t// Check if total timeout will be reached in now() + timeInFut.\n\tboolean checkTimeout(long timeInFut);\n\t// Get next timeout based on previously timeout calculated by strategy.\n\tlong nextTimeout(long timeout);\n\t// Compute expected max backoff timeout based on initTimeout, maxTimeout and reconCnt and backoff coefficient.\n\tstatic long totalBackoffTimeout(long initTimeout, long maxTimeout, long reconCnt);\n}", "des": "Strategy which incorporates retriable network operation, handling of totalTimeout logic. It increases startTimeout based on exponential backoff algorithm. If failure detection is enabled it relies on totalTimeout otherwise implements exponential backoff totalTimeout logic based on startTimeout, maxTimeout and retryCnt."}
{"index": 396, "repo": "ignite-core-2.15.0", "code": "Enum FailureType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FailureType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FailureType[] values();\n}", "des": "Types of failures."}
{"index": 397, "repo": "ignite-core-2.15.0", "code": "Class FairFifoPageEvictionTracker {\n\tprotected boolean checkTouch(long pageId);\n\t// Evicts one data page.\n\tvoid evictDataPage();\n\t// Call this method when last entry is removed from data page.\n\tvoid forgetPage(long pageId);\n\t// Starts grid component, called on grid start.\n\tvoid start();\n\t// Stops grid component, called on grid shutdown.\n\tvoid stop();\n\t// Call this method when data page is accessed.\n\tvoid touchPage(long pageId);\n}", "des": "On-heap FIFO page eviction tracker. Only for test purposes."}
{"index": 398, "repo": "ignite-core-2.15.0", "code": "Interface FieldsQueryCursor<T> {\n\t// Gets number of columns in a row.\n\tint getColumnsCount();\n\t// Gets field name.\n\tString getFieldName(int idx);\n}", "des": "SQL query result cursor. This extends QueryCursor to expose fields metadata to public API for SqlFieldsQueries."}
{"index": 399, "repo": "ignite-core-2.15.0", "code": "Class FileDescriptor {\n\tint compareTo(FileDescriptor o);\n\tboolean equals(Object o);\n\tFile file();\n\t// Getting segment file name.\n\tstatic String fileName(long idx);\n\t// Return absolute pathname string of this file descriptor pathname.\n\tString getAbsolutePath();\n\t// Return absolute WAL segment file index.\n\tlong getIdx();\n\tlong idx();\n\tboolean isCompressed();\n\t// Make fileIo by this description.\n\tSegmentIO toReadOnlyIO(FileIOFactory fileIOFactory);\n}", "des": "WAL file descriptor."}
{"index": 400, "repo": "ignite-core-2.15.0", "code": "Interface FileHandleManager {\n\tWALPointer flush(WALPointer ptr, boolean explicitFsync);\n\t// Initialize FileWriteHandle for first time.\n\tFileWriteHandle initHandle(SegmentIO fileIO, long position, RecordSerializer serializer);\n\t// Create next file handle.\n\tFileWriteHandle nextHandle(SegmentIO fileIO, RecordSerializer serializer);\n\t// On deactivate.\n\tvoid onDeactivate();\n\t// Resume logging.\n\tvoid resumeLogging();\n}", "des": "Manager of FileWriteHandle."}
{"index": 401, "repo": "ignite-core-2.15.0", "code": "Class FileHandleManagerImpl {\n\tWALPointer flush(WALPointer ptr, boolean explicitFsync);\n\t// Initialize FileWriteHandle for first time.\n\tFileWriteHandle initHandle(SegmentIO fileIO, long position, RecordSerializer serializer);\n\t// Create next file handle.\n\tFileWriteHandle nextHandle(SegmentIO fileIO, RecordSerializer serializer);\n\t// On deactivate.\n\tvoid onDeactivate();\n\t// Resume logging.\n\tvoid resumeLogging();\n}", "des": "Manager for FileWriteHandleImpl."}
{"index": 402, "repo": "ignite-core-2.15.0", "code": "Interface FileIOFactory {\n\t// Creates I/O interface for file with default I/O mode.\n\tdefault FileIO create(File file);\n\t// Creates I/O interface for file with specified mode.\n\tFileIO create(File file, OpenOption... modes);\n}", "des": "FileIO factory definition."}
{"index": 403, "repo": "ignite-core-2.15.0", "code": "Class FileLockHolder {\n\t// Closes file channel\n\tvoid close();\n\t// Locked or not.\n\tboolean isLocked();\n\t// This info will appear in error message of concurrent processes that will try to lock on the same file.\n\tabstract String lockInfo();\n\tString lockPath();\n\t// Releases file lock\n\tvoid release();\n\tvoid tryLock(long lockWaitTimeMillis);\n\tprotected abstract String warningMessage(String lockInfo);\n}", "des": "Abstract file lock holder. Implementations should provide lockInfo() that will appear in error message for concurrent processes that will try to lock the same file and warningMessage(String) to print on each lock try."}
{"index": 404, "repo": "ignite-core-2.15.0", "code": "Class FilePageStoreManager.LongOperationAsyncExecutor {\n\t// Executes closure that can't run in parallel with long operation that is executed by async(java.lang.Runnable).\n\t<T> T afterAsyncCompletion(IgniteOutClosure<T> closure);\n\t// Executes long operation in dedicated thread.\n\tvoid async(Runnable runnable);\n\t// Cancels async tasks.\n\tvoid awaitAsyncTaskCompletion(boolean cancel);\n}", "des": "Synchronization wrapper for long operations that should be executed asynchronously and operations that can not be executed in parallel with long operation. Uses ReadWriteLock to provide such synchronization scenario."}
{"index": 405, "repo": "ignite-core-2.15.0", "code": "Class FileVersionCheckingFactory {\n\t// Creates instance of PageStore based on given file.\n\tPageStore createPageStore(byte type, File file, LongConsumer allocatedTracker);\n\t// Creates instance of PageStore based on file path provider.\n\tPageStore createPageStore(byte type, IgniteOutClosure<Path> pathProvider, LongConsumer allocatedTracker);\n\tint headerSize(int ver);\n\t// Resolves latest page store version.\n\tint latestVersion();\n}", "des": "Checks version in files if it's present on the disk, creates store with latest version otherwise."}
{"index": 406, "repo": "ignite-core-2.15.0", "code": "Class FlatIterator<T> {\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tT nextX();\n\t// This method is the same as Iterator.remove(), but allows for failure with exception.\n\tvoid removeX();\n}", "des": "Iterator over the elements of given iterators."}
{"index": 407, "repo": "ignite-core-2.15.0", "code": "Class FloatInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected FloatIndexKey get0(long pageAddr, int off);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, FloatIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining Float values."}
{"index": 408, "repo": "ignite-core-2.15.0", "code": "Class FsyncFileHandleManagerImpl {\n\tWALPointer flush(WALPointer ptr, boolean explicitFsync);\n\t// Initialize FileWriteHandle for first time.\n\tFileWriteHandle initHandle(SegmentIO fileIO, long position, RecordSerializer serializer);\n\t// Create next file handle.\n\tFileWriteHandle nextHandle(SegmentIO fileIO, RecordSerializer serializer);\n\t// On deactivate.\n\tvoid onDeactivate();\n\t// Resume logging.\n\tvoid resumeLogging();\n}", "des": "Implementation of FileWriteHandle for FSYNC mode."}
{"index": 409, "repo": "ignite-core-2.15.0", "code": "Class FullMessage<R extends Serializable> {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\tDiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tMap<UUID,Throwable> error();\n\tIgniteUuid id();\n\tboolean isMutable();\n\tUUID processId();\n\tMap<UUID,R> result();\n\tint type();\n}", "des": "Full process message. Contains single nodes results."}
{"index": 410, "repo": "ignite-core-2.15.0", "code": "Class GenerateEncryptionKeyRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tIgniteUuid id();\n\tint keyCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Generate encryption key request."}
{"index": 411, "repo": "ignite-core-2.15.0", "code": "Class GenerateEncryptionKeyResponse {\n\t// Gets message type.\n\tshort directType();\n\tCollection<byte[]> encryptionKeys();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tbyte[] masterKeyDigest();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tIgniteUuid requestId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Generate encryption key response."}
{"index": 412, "repo": "ignite-core-2.15.0", "code": "Class GridAbsClosure {\n\t// Absolute closure body.\n\tabstract void apply();\n\t// Delegates to apply() method.\n\tvoid run();\n}", "des": "Defines a convenient absolute, i.e. no-arg and no return value closure. This closure that has void return type and no arguments (free variables). Thread Safety Note that this interface does not impose or assume any specific thread-safety by its implementations. Each implementation can elect what type of thread-safety it provides, if any."}
{"index": 413, "repo": "ignite-core-2.15.0", "code": "Class GridAbsClosureX {\n\t// Absolute closure body.\n\tvoid apply();\n\t// Closure body that can throw IgniteCheckedException.\n\tabstract void applyx();\n}", "des": "Convenient abs-closure subclass that allows for thrown grid exception. This class implements apply() method that calls applyx() method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 414, "repo": "ignite-core-2.15.0", "code": "Class GridAbsPredicateX {\n\t// Predicate body.\n\tboolean apply();\n\t// Predicate body that can throw IgniteCheckedException.\n\tabstract boolean applyx();\n}", "des": "Convenient predicate subclass that allows for thrown grid exception. This class implements apply() method that calls applyx() method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 415, "repo": "ignite-core-2.15.0", "code": "Class GridAbstractCommunicationClient {\n\tboolean async();\n\tboolean close();\n\tboolean closed();\n\tint connectionIndex();\n\t// Forces client close.\n\tvoid forceClose();\n\t// Gets idle time of this client.\n\tlong getIdleTime();\n\t// Updates used time.\n\tprotected void markUsed();\n\t// Releases this client by decreasing reservations.\n\tvoid release();\n\tboolean reserve();\n}", "des": "Implements basic lifecycle for communication clients."}
{"index": 416, "repo": "ignite-core-2.15.0", "code": "Class GridArrays {\n\t// Nullify array elements from the given index until the first null element (assuming that after the first null tail is already cleared).\n\tstatic void clearTail(Object[] arr, int fromIdx);\n\tstatic long[] remove(long[] arr, int idx);\n\tstatic <T> T[] remove(T[] arr, int idx);\n\t// Set element to the array at the given index.\n\tstatic <T> T[] set(T[] arr, int idx, T o);\n}", "des": "Utility methods to work with arrays."}
{"index": 417, "repo": "ignite-core-2.15.0", "code": "Class GridAtomicInitializer<T> {\n\t// Await for completion.\n\tboolean await();\n\t// Executes initialization operation only once.\n\tT init(Callable<T> c);\n\t// Should be called only if succeeded.\n\tT result();\n\tboolean succeeded();\n}", "des": "Executes initialization operation once."}
{"index": 418, "repo": "ignite-core-2.15.0", "code": "Class GridBoundedConcurrentLinkedHashSet<E> {\n\t// Note that unlike regular add operation on a set, this method will only add the passed in element if it's not already present in set.\n\tboolean add(E e);\n\t// Note that unlike regular add operation on a set, this method will only add the passed in element if it's not already present in set.\n\tE addx(E e);\n\tint sizex();\n}", "des": "Concurrent set with an upper bound. Once set reaches its maximum capacity, the eldest elements will be removed based on insertion or access order."}
{"index": 419, "repo": "ignite-core-2.15.0", "code": "Class GridBoundedConcurrentOrderedSet<E> {\n\tboolean add(E e);\n\tGridBoundedConcurrentOrderedSet<E> clone();\n\t// This method is not supported and always throws UnsupportedOperationException.\n\tboolean remove(Object o);\n\t// Approximate size at this point of time.\n\tint size();\n}", "des": "Concurrent ordered set that automatically manages its maximum size. Once it exceeds its maximum, it will start removing smallest elements until the maximum is reached again."}
{"index": 420, "repo": "ignite-core-2.15.0", "code": "Class GridBufferedParser {\n\t// This method is called when input bytes are available on the underlying network connection.\n\tbyte[] decode(GridNioSession ses, ByteBuffer buf);\n\t// This method is called whenever a message should be sent to the network connection and network buffer is ready to be filled with bytes.\n\tByteBuffer encode(GridNioSession ses, Object msg);\n}", "des": "This class implements stream parser based on GridNioServerBuffer."}
{"index": 421, "repo": "ignite-core-2.15.0", "code": "Class GridBusyLock {\n\t// Blocks current thread till all activities left \"busy\" state and prevents them from further entering to \"busy\" state.\n\tvoid block();\n\t// Checks if busy lock was blocked by current thread.\n\tboolean blockedByCurrentThread();\n\t// Enters \"busy\" state.\n\tboolean enterBusy();\n\t// Leaves \"busy\" state.\n\tvoid leaveBusy();\n\t// Makes possible for activities entering busy state again.\n\tvoid unblock();\n}", "des": "Synchronization aid to track \"busy\" state of a subsystem that owns it."}
{"index": 422, "repo": "ignite-core-2.15.0", "code": "Class GridCacheAdapter.FutureHolder {\n\t// Gets future.\n\tIgniteInternalFuture future();\n\t// Sets future.\n\tvoid future(@Nullable IgniteInternalFuture fut);\n\tboolean holdsLock();\n\t// Acquires lock.\n\tvoid lock();\n\t// Tries to acquire lock.\n\tboolean tryLock();\n\t// Releases lock.\n\tvoid unlock();\n}", "des": "Holder for last async operation future."}
{"index": 423, "repo": "ignite-core-2.15.0", "code": "Class GridCacheAtomicReferenceValue<T> {\n\t// Gets class loader for the class.\n\tClassLoader classLoader();\n\t// Gets top level user class being deployed.\n\tClass<?> deployClass();\n\tT get();\n\tvoid readExternal(ObjectInput in);\n\tvoid set(T val);\n\tDataStructureType type();\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Atomic reference value."}
{"index": 424, "repo": "ignite-core-2.15.0", "code": "Class GridCacheAtomicStampedValue<T,S> {\n\t// Gets class loader for the class.\n\tClassLoader classLoader();\n\t// Gets top level user class being deployed.\n\tClass<?> deployClass();\n\tIgniteBiTuple<T,S> get();\n\tvoid readExternal(ObjectInput in);\n\tvoid set(T val, S stamp);\n\tS stamp();\n\tDataStructureType type();\n\tT value();\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Atomic stamped value."}
{"index": 425, "repo": "ignite-core-2.15.0", "code": "Class GridCacheClearAllRunnable<K,V> {\n\t// Clear entry from cache.\n\tprotected void clearEntry(GridCacheEntryEx e);\n\tint id();\n\t// Check whether this worker owns particular key.\n\tprotected boolean owns(KeyCacheObject key);\n\tboolean readers();\n\tvoid run();\n\tint totalCount();\n}", "des": "Base runnable for IgniteInternalCache.clearLocally(boolean, boolean, boolean) routine."}
{"index": 426, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheCountDownLatchEx {\n\t// Get current count down latch key.\n\tGridCacheInternalKey key();\n\t// Callback to notify latch on changes.\n\tvoid onUpdate(int cnt);\n}", "des": "Grid cache count down latch ('Ex' stands for external)."}
{"index": 427, "repo": "ignite-core-2.15.0", "code": "Class GridCacheDefaultAffinityKeyMapper {\n\t// If key class has annotation AffinityKeyMapped, then the value of annotated method or field will be used to get affinity value instead of the key itself.\n\tObject affinityKey(Object key);\n\t@Nullable String affinityKeyPropertyName(Class<?> cls);\n\tvoid ignite(Ignite ignite);\n\t// Resets cache affinity mapper to its initial state.\n\tvoid reset();\n}", "des": "Default key affinity mapper. If key class has annotation AffinityKeyMapped, then the value of annotated field will be used to get affinity value instead of the key itself. If there is no annotation, then the key is used as is."}
{"index": 428, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheFuture<R> {\n\t// Gets duration in milliseconds between start of the future and current time if future is not finished, or between start and finish of this future.\n\tlong duration();\n\tIgniteUuid futureId();\n\t// Marks this future as non-trackable.\n\tvoid markNotTrackable();\n\t// Callback for when node left.\n\tboolean onNodeLeft(UUID nodeId);\n\t// Gets start time for this future.\n\tlong startTime();\n\tboolean trackable();\n}", "des": "This interface should be implemented by all distributed futures."}
{"index": 429, "repo": "ignite-core-2.15.0", "code": "Class GridCacheGroupIdMessage {\n\tboolean cacheGroupMessage();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tint groupId();\n\tint handlerId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Message related to particular cache group."}
{"index": 430, "repo": "ignite-core-2.15.0", "code": "Class GridCacheIdMessage {\n\tboolean cacheGroupMessage();\n\tint cacheId();\n\tvoid cacheId(int cacheId);\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tint handlerId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Message related to particular cache."}
{"index": 431, "repo": "ignite-core-2.15.0", "code": "Class GridCacheLazyPlainVersionedEntry<K,V> {\n\t// Gets entry's key.\n\tK key();\n\t// Returns the value stored in the cache when this entry was created.\n\tV value(boolean keepBinary);\n\t// Gets entry's value.\n\tV value(CacheObjectValueContext ctx);\n}", "des": "Lazy plain versioned entry."}
{"index": 432, "repo": "ignite-core-2.15.0", "code": "Class GridCacheLocalQueryFuture<K,V,R> {\n\t// TODO: IGNITE-15728 Provide custom reducer for ScanQueryFallbackClosableIterator.\n\tvoid awaitFirstItemAvailable();\n\t// Cancels query on remote nodes and cleanes owned resources.\n\tprotected void cancelQuery(Throwable err);\n\t// Invokes in case of this future error.\n\tprotected void onError(Throwable err);\n\t// Handles new data page from query node.\n\tprotected void onPage(UUID nodeId, Collection<R> data, boolean lastPage);\n}", "des": "Local query future."}
{"index": 433, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheLockCallback {\n\t// Called when entry has no more candidates.\n\tvoid onFreed(GridDistributedCacheEntry entry);\n\t// Called when entry gets a first candidate.\n\tvoid onLocked(GridDistributedCacheEntry entry);\n\t// Called when entry lock ownership changes.\n\tvoid onOwnerChanged(GridCacheEntryEx entry, GridCacheMvccCandidate owner);\n}", "des": "Lock and Unlock callbacks."}
{"index": 434, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheLockEx {\n\t// Get current reentrant lock latch key.\n\tGridCacheInternalKey key();\n\t// Callback to notify semaphore on topology changes.\n\tvoid onNodeRemoved(UUID nodeId);\n\t// Callback to notify local reentrant lock instance on node reconnected.\n\tvoid onReconnected(UUID nodeId);\n\t// Callback to notify local reentrant lock instance on node stop.\n\tvoid onStop();\n\t// Callback to notify reentrant lock on changes.\n\tvoid onUpdate(GridCacheLockState state);\n}", "des": "Grid cache reentrant lock ('Ex' stands for external)."}
{"index": 435, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheManager<K,V> {\n\tvoid onDisconnected(IgniteFuture<?> reconnectFut);\n\tvoid onKernalStart();\n\tvoid onKernalStop(boolean cancel);\n\t// Prints memory statistics (sizes of internal data structures, etc.).\n\tvoid printMemoryStats();\n\t// Starts manager.\n\tvoid start(GridCacheContext<K,V> cctx);\n\t// Stops manager.\n\tvoid stop(boolean cancel, boolean destroy);\n}", "des": "Interface for cache managers."}
{"index": 436, "repo": "ignite-core-2.15.0", "code": "Enum GridCacheOperation {\n\tstatic @Nullable GridCacheOperation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridCacheOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridCacheOperation[] values();\n}", "des": "Cache value operations."}
{"index": 437, "repo": "ignite-core-2.15.0", "code": "Class GridCachePlainVersionedEntry<K,V> {\n\t// Gets ID of initiator data center.\n\tbyte dataCenterId();\n\t// Gets entry's expire time.\n\tlong expireTime();\n\tboolean isStartVersion();\n\t// Gets entry's key.\n\tK key();\n\t// Gets entry's order in initiator data center.\n\tlong order();\n\t// Gets entry's topology version in initiator data center.\n\tint topologyVersion();\n\t// Gets entry's TTL.\n\tlong ttl();\n\t// Gets entry's value.\n\tV value(CacheObjectValueContext ctx);\n\tGridCacheVersion version();\n}", "des": "Plain versioned entry."}
{"index": 438, "repo": "ignite-core-2.15.0", "code": "Class GridCachePluginContext<C extends CachePluginConfiguration> {\n\tIgnite grid();\n\tCacheConfiguration igniteCacheConfiguration();\n\tIgniteConfiguration igniteConfiguration();\n\t// Gets local grid node.\n\tClusterNode localNode();\n\t// Gets logger for given class.\n\tIgniteLogger log(Class<?> cls);\n}", "des": "Cache plugin context."}
{"index": 439, "repo": "ignite-core-2.15.0", "code": "Class GridCacheQueryManager.CacheSqlIndexMetadata {\n\t// Gets order of the index for each indexed field.\n\tboolean descending(String field);\n\tCollection<String> descendings();\n\t// Gets names of fields indexed by this index.\n\tCollection<String> fields();\n\t// Gets name of the index.\n\tString name();\n\tvoid readExternal(ObjectInput in);\n\t// Gets whether this is a unique index.\n\tboolean unique();\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Cache metadata index."}
{"index": 440, "repo": "ignite-core-2.15.0", "code": "Class GridCacheQueryMetricsAdapter {\n\t// Gets average execution time of query.\n\tdouble averageTime();\n\t// Gets total number execution of query.\n\tint executions();\n\t// Gets total number of times a query execution failed.\n\tint fails();\n\t// Gets maximum execution time of query.\n\tlong maximumTime();\n\t// Gets minimum execution time of query.\n\tlong minimumTime();\n\t// Resets query metrics.\n\tvoid reset();\n\tQueryMetrics snapshot();\n\t// Update metrics.\n\tvoid update(long duration, boolean fail);\n}", "des": "Adapter for QueryMetrics."}
{"index": 441, "repo": "ignite-core-2.15.0", "code": "Class GridCacheQueryMetricsAdapter.QueryMetricsSnapshot {\n\t// Gets average execution time of query.\n\tdouble averageTime();\n\t// Gets total number execution of query.\n\tint executions();\n\t// Gets total number of times a query execution failed.\n\tint fails();\n\t// Gets maximum execution time of query.\n\tlong maximumTime();\n\t// Gets minimum execution time of query.\n\tlong minimumTime();\n\tvoid readExternal(ObjectInput in);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Query metrics snapshot."}
{"index": 442, "repo": "ignite-core-2.15.0", "code": "Enum GridCacheQueryType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable GridCacheQueryType fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridCacheQueryType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridCacheQueryType[] values();\n}", "des": "Defines different cache query types. For more information on cache query types and their usage see CacheQuery documentation."}
{"index": 443, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheRemovable {\n\tvoid needCheckNotRemoved();\n\t// Set status of data structure as removed.\n\tboolean onRemoved();\n\t// Would return this object work to normal.\n\tvoid restart(IgniteInternalCache cache);\n\t// Would suspend calls for this object.\n\tvoid suspend();\n}", "des": "Provides callback for marking object as removed."}
{"index": 444, "repo": "ignite-core-2.15.0", "code": "Class GridCacheRestMetrics {\n\t// Gets hits.\n\tint getHits();\n\t// Gets misses.\n\tint getMisses();\n\t// Gets reads.\n\tint getReads();\n\t// Gets writes.\n\tint getWrites();\n\t// Creates map with strings.\n\tMap<String,Long> map();\n\t// Sets hits.\n\tvoid setHits(int hits);\n\t// Sets misses.\n\tvoid setMisses(int misses);\n\t// Sets reads.\n\tvoid setReads(int reads);\n\t// Sets writes.\n\tvoid setWrites(int writes);\n}", "des": "Grid cache metrics for rest."}
{"index": 445, "repo": "ignite-core-2.15.0", "code": "Class GridCacheReturnCompletableWrapper {\n\t// Allows wait for properly initialized value.\n\tIgniteInternalFuture<GridCacheReturn> fut();\n\t// Marks as initialized.\n\tvoid initialize(GridCacheReturn ret);\n\t@Nullable UUID nodeId();\n}", "des": "Provides initialized GridCacheReturn."}
{"index": 446, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheSemaphoreEx {\n\t// Get current semaphore key.\n\tGridCacheInternalKey key();\n\t// Callback to notify semaphore on topology changes.\n\tvoid onNodeRemoved(UUID nodeId);\n\t// Callback to notify semaphore on changes.\n\tvoid onUpdate(GridCacheSemaphoreState val);\n\t// Callback to notify local semaphore instance on node stop.\n\tvoid stop();\n}", "des": "Grid cache semaphore ('Ex' stands for external)."}
{"index": 447, "repo": "ignite-core-2.15.0", "code": "Class GridCacheSharedTtlCleanupManager {\n\tboolean eagerTtlEnabled();\n\tprotected void onKernalStop0(boolean cancel);\n\t// Register ttl manager of cache for periodical check on expired entries.\n\tvoid register(GridCacheTtlManager mgr);\n\t// Unregister ttl manager of cache from periodical check on expired entries.\n\tvoid unregister(GridCacheTtlManager mgr);\n}", "des": "Periodically removes expired entities from caches with CacheConfiguration.isEagerTtl() flag set."}
{"index": 448, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheSqlIndexMetadata {\n\t// Gets order of the index for each indexed field.\n\tboolean descending(String field);\n\tCollection<String> descendings();\n\t// Gets names of fields indexed by this index.\n\tCollection<String> fields();\n\t// Gets name of the index.\n\tString name();\n\t// Gets whether this is a unique index.\n\tboolean unique();\n}", "des": "Ignite index descriptor."}
{"index": 449, "repo": "ignite-core-2.15.0", "code": "Class GridCacheTxRecoveryFuture {\n\tIgniteUuid futureId();\n\t// Marks this future as non-trackable.\n\tvoid markNotTrackable();\n\t// Callback to notify that future is finished.\n\tboolean onDone(@Nullable Boolean res, @Nullable Throwable err);\n\t// Callback for when node left.\n\tboolean onNodeLeft(UUID nodeId);\n\tvoid onResult(UUID nodeId, GridCacheTxRecoveryResponse res);\n\t// Initializes future.\n\tvoid prepare();\n\tboolean trackable();\n\tIgniteInternalTx tx();\n}", "des": "Future verifying that all remote transactions related to transaction were prepared or committed."}
{"index": 450, "repo": "ignite-core-2.15.0", "code": "Interface GridCacheVersionedEntry<K,V> {\n\t// Gets ID of initiator data center.\n\tbyte dataCenterId();\n\t// Gets entry's expire time.\n\tlong expireTime();\n\t// Gets entry's key.\n\tK key();\n\t// Gets entry's order in initiator data center.\n\tlong order();\n\t// Gets entry's topology version in initiator data center.\n\tint topologyVersion();\n\t// Gets entry's TTL.\n\tlong ttl();\n\t// Gets entry's value.\n\tV value(CacheObjectValueContext ctx);\n}", "des": "Cache entry along with version information."}
{"index": 451, "repo": "ignite-core-2.15.0", "code": "Class GridCheckpointRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tString getCheckpointSpi();\n\tString getKey();\n\tIgniteUuid getSessionId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "This class defines checkpoint request."}
{"index": 452, "repo": "ignite-core-2.15.0", "code": "Class GridClassLoaderCache {\n\t// Gets cached ClassLoader for efficiency since class loader detection has proven to be slow.\n\tstatic ClassLoader classLoader(Class<?> cls);\n\t// Intended for test purposes only.\n\tstatic void clear();\n\tstatic void onUndeployed(ClassLoader ldr);\n\tstatic void printMemoryStats();\n}", "des": "Caches class loaders for classes."}
{"index": 453, "repo": "ignite-core-2.15.0", "code": "Class GridClientBalancerAdapter {\n\t// If set to true balancer should prefer directly connectable nodes over others.\n\tboolean isPreferDirectNodes();\n\t// Returns only directly available nodes from given collection.\n\tprotected static Collection<GridClientNode> selectDirectNodes(Collection<? extends GridClientNode> nodes);\n\t// Sets prefer direct nodes.\n\tGridClientBalancerAdapter setPreferDirectNodes(boolean preferDirectNodes);\n}", "des": "Base class for balancers. Contains common direct connection handling logic."}
{"index": 454, "repo": "ignite-core-2.15.0", "code": "Interface GridClientBeforeNodeStart {\n\t// Getting a client projection of node state before its start.\n\tGridClientNodeStateBeforeStart beforeStartState();\n\t// Checking for an error.\n\tGridClientException checkLastError();\n\t// Closes client instance.\n\tvoid close();\n\t// Indicates whether client is connected to remote Grid.\n\tboolean connected();\n\t// Gets a unique client identifier.\n\tUUID id();\n}", "des": "Ignite Java client API for communicate with node before it start. If node has already started, then there will be errors. For get an instance, need to use GridClientFactory.startBeforeNodeStart(org.apache.ignite.internal.client.GridClientConfiguration)."}
{"index": 455, "repo": "ignite-core-2.15.0", "code": "Class GridClientCacheBean {\n\tboolean equals(Object obj);\n\t// Gets cache mode.\n\tGridClientCacheMode getMode();\n\t// Gets cache name.\n\tString getName();\n\t// Gets custom name of the sql schema.\n\tString getSqlSchema();\n\t// Sets cache mode.\n\tvoid setMode(GridClientCacheMode mode);\n\t// Sets cache name.\n\tvoid setName(String name);\n\t// Sets custom name of the sql schema.\n\tvoid setSqlSchema(String sqlSchema);\n}", "des": "Cache bean."}
{"index": 456, "repo": "ignite-core-2.15.0", "code": "Enum GridClientCacheMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridClientCacheMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridClientCacheMode[] values();\n}", "des": "Cache type on remote node."}
{"index": 457, "repo": "ignite-core-2.15.0", "code": "Enum GridClientCacheRequest.GridCacheOperation {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable GridClientCacheRequest.GridCacheOperation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridClientCacheRequest.GridCacheOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridClientCacheRequest.GridCacheOperation[] values();\n}", "des": "Available cache operations."}
{"index": 458, "repo": "ignite-core-2.15.0", "code": "Interface GridClientClusterState {\n\t// Get the cluster name.\n\tString clusterName();\n\t// Unique identifier of cluster STATE command was sent to.\n\tUUID id();\n\tClusterState state();\n\t// Changes cluster state to newState.\n\tvoid state(ClusterState newState, boolean forceDeactivation);\n\t// User-defined tag of cluster STATE command was sent to.\n\tString tag();\n}", "des": "Interface for managing state of grid cluster and obtaining information about it: ID and tag."}
{"index": 459, "repo": "ignite-core-2.15.0", "code": "Interface GridClientFuture<R> {\n\t// Synchronously waits for completion and returns result.\n\tR get();\n\t// Synchronously waits for completion and returns result.\n\tR get(long timeout, TimeUnit unit);\n\t// Checks if future is done.\n\tboolean isDone();\n\t// Register new listeners for notification when future completes.\n\tvoid listen(GridClientFutureListener<R>... lsnrs);\n}", "des": "Future for asynchronous operations."}
{"index": 460, "repo": "ignite-core-2.15.0", "code": "Class GridClientJdkMarshaller {\n\t// Marshals object to byte array.\n\tByteBuffer marshal(Object obj, int off);\n\t// Unmarshals object from byte array.\n\t<T> T unmarshal(byte[] bytes);\n}", "des": "Simple marshaller that utilize JDK serialization features."}
{"index": 461, "repo": "ignite-core-2.15.0", "code": "Interface GridClientMarshaller {\n\t// Marshals object to byte array.\n\tByteBuffer marshal(Object obj, int off);\n\t// Unmarshals object from byte array.\n\t<T> T unmarshal(byte[] bytes);\n}", "des": "Marshaller for binary protocol messages."}
{"index": 462, "repo": "ignite-core-2.15.0", "code": "Class GridClientOptimizedMarshaller {\n\t// Marshals object to byte array.\n\tByteBuffer marshal(Object obj, int off);\n\t// Unmarshals object from byte array.\n\t<T> T unmarshal(byte[] bytes);\n}", "des": "Wrapper, that adapts OptimizedMarshaller to GridClientMarshaller interface."}
{"index": 463, "repo": "ignite-core-2.15.0", "code": "Enum GridClientPacketType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridClientPacketType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridClientPacketType[] values();\n}", "des": "Type of message being parsed."}
{"index": 464, "repo": "ignite-core-2.15.0", "code": "Enum GridClientProtocol {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridClientProtocol valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridClientProtocol[] values();\n}", "des": "Protocol that will be used when client connections are created."}
{"index": 465, "repo": "ignite-core-2.15.0", "code": "Class GridClientRoundRobinBalancer {\n\t// Gets next node for executing client command.\n\tGridClientNode balancedNode(Collection<? extends GridClientNode> nodes);\n\t// Callback for new nodes joining the remote grid.\n\tvoid onNodeAdded(GridClientNode node);\n\t// Callback for nodes leaving the remote grid.\n\tvoid onNodeRemoved(GridClientNode node);\n}", "des": "Simple balancer that implements round-robin balancing."}
{"index": 466, "repo": "ignite-core-2.15.0", "code": "Interface GridClientTopologyListener {\n\t// Callback for new nodes joining the remote grid.\n\tvoid onNodeAdded(GridClientNode node);\n\t// Callback for nodes leaving the remote grid.\n\tvoid onNodeRemoved(GridClientNode node);\n}", "des": "Listener interface for notifying on nodes joining or leaving remote grid."}
{"index": 467, "repo": "ignite-core-2.15.0", "code": "Class GridClientZipOptimizedMarshaller {\n\t// Default marshaller that will be used in case of backward compatibility.\n\tGridClientMarshaller defaultMarshaller();\n\t// Marshals object to byte array.\n\tByteBuffer marshal(Object obj, int off);\n\t// Unmarshals object from byte array.\n\t<T> T unmarshal(byte[] bytes);\n\t// Zips bytes.\n\tstatic byte[] zipBytes(byte[] input);\n}", "des": "Wrapper, that adapts OptimizedMarshaller to GridClientMarshaller interface."}
{"index": 468, "repo": "ignite-core-2.15.0", "code": "Interface GridCloseableIterator<T> {\n\t// Closes the iterator and frees all the resources held by the iterator.\n\tvoid close();\n\t// Checks if iterator has been closed.\n\tboolean isClosed();\n}", "des": "Defines \"rich\" closeable iterator interface that is also acts like lambda function and iterable."}
{"index": 469, "repo": "ignite-core-2.15.0", "code": "Class GridClosure3X<E1,E2,E3,R> {\n\t// Closure body.\n\tR apply(E1 e1, E2 e2, E3 e3);\n\t// Closure body that can throw IgniteCheckedException.\n\tabstract R applyx(E1 e1, E2 e2, E3 e3);\n}", "des": "Convenient closure subclass that allows for thrown grid exception. This class implements apply(Object, Object, Object) method that calls applyx(Object, Object, Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 470, "repo": "ignite-core-2.15.0", "code": "Enum GridClosureCallMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable GridClosureCallMode fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridClosureCallMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridClosureCallMode[] values();\n}", "des": "Distribution modes for one or more closures executed via Grid.call(...) methods. In other words, given a set of jobs (closures) and set of grid nodes this enumeration provides three simple modes of how these jobs will be mapped to the nodes."}
{"index": 471, "repo": "ignite-core-2.15.0", "code": "Class GridCollections {\n\t// Gets locked collection wrapping given set.\n\tstatic <E> Collection<E> lockedCollection(Collection<E> c);\n\t// Gets locked map wrapping given map.\n\tstatic <K,V> Map<K,V> lockedMap(Map<K,V> m);\n\t// Gets locked set wrapping given set.\n\tstatic <E> Set<E> lockedSet(Set<E> s);\n}", "des": "Provides locked wrappers around given maps and collections. Since ReentrantLock performs a lot better than standard Java synchronization, these locked wrappers should perform better as their analogous methods in java.util.Collections class."}
{"index": 472, "repo": "ignite-core-2.15.0", "code": "Class GridCollisionJobContextAdapter {\n\t// Job for this context.\n\tComputeJob getJob();\n\t// Gets job context.\n\tComputeJobContext getJobContext();\n\tGridJobWorker getJobWorker();\n\t// Gets current task session associated with this job.\n\tGridJobSessionImpl getTaskSession();\n}", "des": "Adapter for CollisionJobContext."}
{"index": 473, "repo": "ignite-core-2.15.0", "code": "Class GridCollisionManager {\n\t// Invoke collision SPI.\n\tvoid onCollision(Collection<CollisionJobContext> waitJobs, Collection<CollisionJobContext> activeJobs, Collection<CollisionJobContext> heldJobs);\n\tvoid setCollisionExternalListener(@Nullable CollisionExternalListener lsnr);\n\t// Starts grid component.\n\tvoid start();\n\t// Stops grid component.\n\tvoid stop(boolean cancel);\n\t// Unsets external collision listener.\n\tvoid unsetCollisionExternalListener();\n}", "des": "This class defines a collision manager."}
{"index": 474, "repo": "ignite-core-2.15.0", "code": "Enum GridComponent.DiscoveryDataExchangeType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridComponent.DiscoveryDataExchangeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridComponent.DiscoveryDataExchangeType[] values();\n}", "des": "Unique component type for discovery data exchange."}
{"index": 475, "repo": "ignite-core-2.15.0", "code": "Class GridCompoundReadRepairFuture {\n\tvoid add(IgniteInternalFuture<Void> fut);\n\t// Closure body.\n\tvoid apply(IgniteInternalFuture<Void> fut);\n\t// Mark this future as initialized.\n\tvoid markInitialized();\n}", "des": "Compound future that represents the result of the external fixes for some keys."}
{"index": 476, "repo": "ignite-core-2.15.0", "code": "Class GridConcurrentHashSet<E> {\n\t// Note that unlike regular add operation on a set, this method will only add the passed in element if it's not already present in set.\n\tboolean add(E e);\n\t// Note that unlike regular add operation on a set, this method will only add the passed in element if it's not already present in set.\n\tE addx(E e);\n}", "des": "Concurrent set implementation."}
{"index": 477, "repo": "ignite-core-2.15.0", "code": "Class GridConcurrentLinkedHashSet<E> {\n\t// Note that unlike regular add operation on a set, this method will only add the passed in element if it's not already present in set.\n\tboolean add(E e);\n\t// Note that unlike regular add operation on a set, this method will only add the passed in element if it's not already present in set.\n\tE addx(E e);\n\tIterator<E> descendingIterator();\n}", "des": "Concurrent linked set implementation."}
{"index": 478, "repo": "ignite-core-2.15.0", "code": "Class GridConcurrentMultiPairQueue.Result<K,V> {\n\t// Current key.\n\tK getKey();\n\t// Current value.\n\tV getValue();\n\t// Current state setter.\n\tvoid set(K k, V v, int seg);\n}", "des": "State holder."}
{"index": 479, "repo": "ignite-core-2.15.0", "code": "Interface GridContinuousBatch {\n\t// Adds element to this batch.\n\tvoid add(Object obj);\n\t// Collects elements that are currently in this batch.\n\tCollection<Object> collect();\n\tint size();\n}", "des": "Continuous routine batch."}
{"index": 480, "repo": "ignite-core-2.15.0", "code": "Class GridContinuousBatchAdapter {\n\t// Adds element to this batch.\n\tvoid add(Object obj);\n\t// Collects elements that are currently in this batch.\n\tCollection<Object> collect();\n\tint size();\n}", "des": "Continuous routine batch adapter."}
{"index": 481, "repo": "ignite-core-2.15.0", "code": "Enum GridContinuousHandler.RegisterStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridContinuousHandler.RegisterStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridContinuousHandler.RegisterStatus[] values();\n}", "des": "Listener registration status."}
{"index": 482, "repo": "ignite-core-2.15.0", "code": "Class GridContinuousProcessor.RemoteRoutineInfo {\n\tboolean autoUnsubscribe();\n\tint bufferSize();\n\t// Clears delayed register flag if it was set.\n\tboolean clearDelayedRegister();\n\tboolean delayedRegister();\n\tGridContinuousHandler handler();\n\tlong interval();\n\tlong lastSendTime();\n\t// Marks info to be registered when cache is started.\n\tvoid markDelayedRegister();\n\tUUID nodeId();\n}", "des": "Remote routine info."}
{"index": 483, "repo": "ignite-core-2.15.0", "code": "Class GridCountDownCallback {\n\t// Decrements the internal counter.\n\tvoid countDown();\n\t// Decrements the internal counter.\n\tvoid countDown(boolean doIncreaseExecutionCounter);\n}", "des": "Allows to execute callback when a set of operations will be completed. Also has an execution counter, which allows to block callback execution in case if it is below given threshold. By default, threshold is 0 and nothing blocks callback execution."}
{"index": 484, "repo": "ignite-core-2.15.0", "code": "Interface GridCursor<T> {\n\t// Gets element at current position.\n\tT get();\n\t// Attempt to move cursor position forward.\n\tboolean next();\n}", "des": "Simple cursor abstraction. Initial state must be \"before first\"."}
{"index": 485, "repo": "ignite-core-2.15.0", "code": "Class GridCursorIteratorWrapper<V> {\n\t// Gets element at current position.\n\tV get();\n\t// Attempt to move cursor position forward.\n\tboolean next();\n}", "des": "Wrap Iterator and adapt it to GridCursor."}
{"index": 486, "repo": "ignite-core-2.15.0", "code": "Class GridDelimitedParser {\n\t// This method is called when input bytes are available on the underlying network connection.\n\tbyte[] decode(GridNioSession ses, ByteBuffer buf);\n\t// This method is called whenever a message should be sent to the network connection and network buffer is ready to be filled with bytes.\n\tByteBuffer encode(GridNioSession ses, Object msg);\n}", "des": "This class implements stream parser based on GridNioDelimitedBuffer."}
{"index": 487, "repo": "ignite-core-2.15.0", "code": "Class GridDeploymentMetadata {\n\tClassLoader classLoader();\n\tvoid classLoader(ClassLoader clsLdr);\n\t// Sets property clsLdrId.\n\tvoid classLoaderId(IgniteUuid clsLdrId);\n\tIgnitePredicate<ClusterNode> nodeFilter();\n\tvoid nodeFilter(IgnitePredicate<ClusterNode> nodeFilter);\n\t// Gets parent loader.\n\tClassLoader parentLoader();\n\t// Sets parent loader.\n\tvoid parentLoader(ClassLoader parentLdr);\n\tMap<UUID,IgniteUuid> participants();\n\tvoid participants(Map<UUID,IgniteUuid> participants);\n}", "des": "Deployment metadata."}
{"index": 488, "repo": "ignite-core-2.15.0", "code": "Class GridDeploymentRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tCollection<UUID> nodeIds();\n\tvoid nodeIds(Collection<UUID> nodeIds);\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Deployment request."}
{"index": 489, "repo": "ignite-core-2.15.0", "code": "Class GridDeploymentResponse {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Grid deployment response containing requested resource bytes."}
{"index": 490, "repo": "ignite-core-2.15.0", "code": "Class GridDhtAssignmentFetchFuture {\n\tint groupId();\n\tlong id();\n\t// Initializes fetch future.\n\tvoid init(boolean needPartState);\n\t// Callback to notify that future is finished.\n\tboolean onDone(@Nullable GridDhtAffinityAssignmentResponse res, @Nullable Throwable err);\n\tvoid onNodeLeft(UUID leftNodeId);\n\tvoid onResponse(UUID nodeId, GridDhtAffinityAssignmentResponse res);\n}", "des": "Future that fetches affinity assignment from remote cache nodes."}
{"index": 491, "repo": "ignite-core-2.15.0", "code": "Class GridDhtCache<K,V> {\n\tboolean isDht();\n\t// Gets name of this cache (null for default cache).\n\tString name();\n\tGridNearTransactionalCache<K,V> near();\n\tvoid near(GridNearTransactionalCache<K,V> near);\n\t// Starts this cache.\n\tvoid start();\n}", "des": "DHT cache."}
{"index": 492, "repo": "ignite-core-2.15.0", "code": "Class GridDhtForceKeysFuture<K,V> {\n\tIgniteUuid futureId();\n\t// Initializes this future.\n\tvoid init();\n\t// Node that future should be able to provide keys to retry before it completes, so it's not necessary to wait till future is done to get retry keys.\n\tCollection<Integer> invalidPartitions();\n\tvoid onDiscoveryEvent(DiscoveryEvent evt);\n\t// Callback to notify that future is finished.\n\tboolean onDone(@Nullable Collection<K> res, @Nullable Throwable err);\n\tvoid onResult(GridDhtForceKeysResponse res);\n}", "des": "Force keys request future."}
{"index": 493, "repo": "ignite-core-2.15.0", "code": "Class GridDhtPartitionDemander {\n\t// Handles supply message from nodeId with specified topicId.\n\tvoid handleSupplyMessage(UUID nodeId, GridDhtPartitionSupplyMessage supplyMsg);\n\t// Owns the partition recursively.\n\tprotected void ownPartition(GridDhtPartitionDemander.RebalanceFuture fut, int p, UUID nodeId, GridDhtPartitionSupplyMessage supplyMsg);\n\t// Enqueues supply message.\n\tvoid registerSupplyMessage(UUID nodeId, GridDhtPartitionSupplyMessage supplyMsg, Runnable r);\n}", "des": "Thread pool for requesting partitions from other nodes and populating local cache."}
{"index": 494, "repo": "ignite-core-2.15.0", "code": "Class GridDhtPartitionsSingleRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tint handlerId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Request for single partition info."}
{"index": 495, "repo": "ignite-core-2.15.0", "code": "Enum GridDhtPartitionState {\n\tboolean active();\n\tstatic @Nullable GridDhtPartitionState fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridDhtPartitionState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridDhtPartitionState[] values();\n}", "des": "Partition states."}
{"index": 496, "repo": "ignite-core-2.15.0", "code": "Class GridDhtPartitionSupplier {\n\t// For each demand message method lookups (or creates new) supply context and starts to iterate entries across requested partitions.\n\tvoid handleDemandMessage(int topicId, UUID nodeId, GridDhtPartitionDemandMessage demandMsg);\n\t// Check is cache having any active context for supply.\n\tboolean isSupply();\n}", "des": "Class for supplying partitions to demanding nodes."}
{"index": 497, "repo": "ignite-core-2.15.0", "code": "Class GridDhtPreloaderAssignments {\n\tboolean affinityReassign();\n\tboolean cancelled();\n\tvoid cancelled(boolean cancelled);\n\t// Retains only moving partitions for the current topology.\n\tvoid retainMoving(GridDhtPartitionTopology top);\n\t// Gets a supplier node for a partition.\n\tClusterNode supplier(int part);\n\tAffinityTopologyVersion topologyVersion();\n}", "des": "Partition to node assignments."}
{"index": 498, "repo": "ignite-core-2.15.0", "code": "Class GridDhtTxQueryAbstractEnlistFuture {\n\t// Entry processed callback.\n\tprotected void onEntryProcessed(KeyCacheObject key, GridCacheUpdateTxResult res);\n\t// Gets query result.\n\tprotected Long result0();\n}", "des": "Abstract future processing transaction enlisting and locking of entries produced with DML and SELECT FOR UPDATE queries."}
{"index": 499, "repo": "ignite-core-2.15.0", "code": "Class GridDhtTxQueryResultsEnlistFuture {\n\t// Gets source to be updated iterator.\n\tprotected UpdateSourceIterator<?> createIterator();\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tObject nextX();\n\tEnlistOperation operation();\n}", "des": "Future processing transaction enlisting and locking of entries produces by complex DML queries with reduce step."}
{"index": 500, "repo": "ignite-core-2.15.0", "code": "Class GridDirectParser {\n\t// This method is called when input bytes are available on the underlying network connection.\n\t@Nullable Object decode(GridNioSession ses, ByteBuffer buf);\n\t// This method is called whenever a message should be sent to the network connection and network buffer is ready to be filled with bytes.\n\tByteBuffer encode(GridNioSession ses, Object msg);\n}", "des": "Parser for direct messages."}
{"index": 501, "repo": "ignite-core-2.15.0", "code": "Class GridDiscoveryTopologySnapshot {\n\t// Gets topology nodes from topology snapshot.\n\tCollection<ClusterNode> topologyNodes();\n\t// Gets topology version if this event is raised on topology change and configured discovery SPI implementation supports topology versioning.\n\tlong topologyVersion();\n}", "des": "Topology snapshot managed by discovery manager."}
{"index": 502, "repo": "ignite-core-2.15.0", "code": "Enum GridDrType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridDrType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridDrType[] values();\n}", "des": "Data center replication type."}
{"index": 503, "repo": "ignite-core-2.15.0", "code": "Class GridEmbeddedFuture<A,B> {\n\t// Default no-op implementation that always returns false.\n\tboolean cancel();\n\t// Returns true if this computation was cancelled before it completed normally.\n\tboolean isCancelled();\n}", "des": "Future which waits for embedded future to complete and then asynchronously executes provided closure with embedded future result."}
{"index": 504, "repo": "ignite-core-2.15.0", "code": "Class GridEmptyCloseableIterator<T> {\n\t// Closes the iterator and frees all the resources held by the iterator.\n\tvoid close();\n\t// Checks if iterator has been closed.\n\tboolean isClosed();\n}", "des": "Empty closeable iterator."}
{"index": 505, "repo": "ignite-core-2.15.0", "code": "Class GridEmptyIterator<T> {\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tT nextX();\n\t// This method is the same as Iterator.remove(), but allows for failure with exception.\n\tvoid removeX();\n}", "des": "Empty iterator."}
{"index": 506, "repo": "ignite-core-2.15.0", "code": "Class GridEventStorageMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Event storage message."}
{"index": 507, "repo": "ignite-core-2.15.0", "code": "Class GridFailoverManager {\n\tClusterNode failover(GridTaskSessionImpl taskSes, ComputeJobResult jobRes, List<ClusterNode> top, int affPartId, @Nullable String affCacheName, @Nullable AffinityTopologyVersion topVer);\n\t// Starts grid component.\n\tvoid start();\n\t// Stops grid component.\n\tvoid stop(boolean cancel);\n}", "des": "Grid failover spi manager."}
{"index": 508, "repo": "ignite-core-2.15.0", "code": "Class GridFileUtils {\n\t// Copy file\n\tstatic void copy(FileIOFactory srcFactory, File src, FileIOFactory dstFactory, File dst, long maxBytes);\n\t// Copy file\n\tstatic void copy(FileIO src, FileIO dst, long maxBytes);\n\t// Checks that creating hard links between given paths is available.\n\tstatic void ensureHardLinkAvailable(Path path1, Path path2);\n}", "des": "General files manipulation utilities."}
{"index": 509, "repo": "ignite-core-2.15.0", "code": "Class GridHandleTable {\n\t// Resets table to its initial (empty) state.\n\tvoid clear();\n\tObject[] objects();\n\t// Looks up and returns handle associated with the given object.\n\tint putIfAbsent(Object obj);\n}", "des": "Lightweight identity hash table which maps objects to integer handles, assigned in ascending order."}
{"index": 510, "repo": "ignite-core-2.15.0", "code": "Class GridInClosure3X<E1,E2,E3> {\n\t// Closure body.\n\tvoid apply(E1 e1, E2 e2, E3 e3);\n\t// In-closure body that can throw IgniteCheckedException.\n\tabstract void applyx(E1 e1, E2 e2, E3 e3);\n}", "des": "Convenient in-closure subclass that allows for thrown grid exception. This class implements apply(Object, Object, Object) method that calls applyx(Object, Object, Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 511, "repo": "ignite-core-2.15.0", "code": "Class GridIndexingManager {\n\tprotected void onKernalStop0(boolean cancel);\n\tIgniteSpiCloseableIterator<?> query(String cacheName, Collection<Object> params, IndexingQueryFilter filters);\n\tvoid remove(String cacheName, Object key);\n\t// Starts grid component.\n\tvoid start();\n\t// Stops grid component.\n\tvoid stop(boolean cancel);\n\t// Writes key-value pair to index.\n\t<K,V> void store(String cacheName, K key, V val, long expirationTime);\n}", "des": "Manages cache indexing."}
{"index": 512, "repo": "ignite-core-2.15.0", "code": "Class GridIoMessageFactory {\n\t// Always throws UnsupportedOperationException.\n\tMessage create(short type);\n\t// Registers all messages factories.\n\tvoid registerAll(IgniteMessageFactory factory);\n}", "des": "Message factory implementation."}
{"index": 513, "repo": "ignite-core-2.15.0", "code": "Interface GridIterator<T> {\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tT nextX();\n\t// This method is the same as Iterator.remove(), but allows for failure with exception.\n\tvoid removeX();\n}", "des": "Defines \"rich\" iterator interface that is also acts like lambda function and iterable."}
{"index": 514, "repo": "ignite-core-2.15.0", "code": "Class GridJobSiblingImpl {\n\t// Sends a request to cancel this sibling.\n\tvoid cancel();\n\t// Gets ID of this grid job sibling.\n\tIgniteUuid getJobId();\n\tboolean isJobDone();\n\tObject jobTopic();\n\tUUID nodeId();\n\tvoid nodeId(UUID nodeId);\n\tvoid onJobDone();\n\tvoid readExternal(ObjectInput in);\n\tObject taskTopic();\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "This class provides implementation for job sibling."}
{"index": 515, "repo": "ignite-core-2.15.0", "code": "Class GridJobSiblingsRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tIgniteUuid sessionId();\n\tObject topic();\n\tbyte[] topicBytes();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Job siblings request."}
{"index": 516, "repo": "ignite-core-2.15.0", "code": "Class GridJobSiblingsResponse {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tCollection<ComputeJobSibling> jobSiblings();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tvoid unmarshalSiblings(Marshaller marsh);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Job siblings response."}
{"index": 517, "repo": "ignite-core-2.15.0", "code": "Enum GridKernalState {\n\tstatic @Nullable GridKernalState fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridKernalState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridKernalState[] values();\n}", "des": "Kernal life cycle states."}
{"index": 518, "repo": "ignite-core-2.15.0", "code": "Class GridLoadBalancerManager {\n\tClusterNode getBalancedNode(GridTaskSessionImpl ses, List<ClusterNode> top, ComputeJob job);\n\tComputeLoadBalancer getLoadBalancer(GridTaskSessionImpl ses, List<ClusterNode> top);\n\t// Starts grid component.\n\tvoid start();\n\t// Stops grid component.\n\tvoid stop(boolean cancel);\n}", "des": "Load balancing manager."}
{"index": 519, "repo": "ignite-core-2.15.0", "code": "Interface GridManager {\n\tboolean enabled();\n\t// This method executed after manager started SPI.\n\tvoid onAfterSpiStart();\n\t// This method executed before manager will start SPI.\n\tvoid onBeforeSpiStart();\n}", "des": "This interface defines life-cycle for kernal manager. Managers provide layer of indirection between kernal and SPI modules. Kernel never calls SPI modules directly but rather calls manager that further delegate the apply to specific SPI module."}
{"index": 520, "repo": "ignite-core-2.15.0", "code": "Enum GridMetadataAwareAdapter.EntryKey {\n\t// Returns key.\n\tint key();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridMetadataAwareAdapter.EntryKey valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridMetadataAwareAdapter.EntryKey[] values();\n}", "des": "Enum stored predefined keys."}
{"index": 521, "repo": "ignite-core-2.15.0", "code": "Class GridMutableLong {\n\t// Gets the current value.\n\tlong get();\n\t// Increments by one the current value.\n\tlong incrementAndGet();\n\t// Sets the new value.\n\tvoid set(long v);\n}", "des": "A mutable long for use in collections."}
{"index": 522, "repo": "ignite-core-2.15.0", "code": "Class GridNearAtomicSingleUpdateFuture {\n\tprotected void map(AffinityTopologyVersion topVer);\n\t// Maps future on ready topology.\n\tprotected void mapOnTopology();\n\tvoid onDhtResponse(UUID nodeId, GridDhtAtomicNearResponse res);\n\t// Callback for when node left.\n\tboolean onNodeLeft(UUID nodeId);\n\t// Response callback.\n\tvoid onPrimaryResponse(UUID nodeId, GridNearAtomicUpdateResponse res, boolean nodeErr);\n}", "des": "DHT atomic cache near update future."}
{"index": 523, "repo": "ignite-core-2.15.0", "code": "Class GridNearAtomicUpdateFuture {\n\tprotected void map(AffinityTopologyVersion topVer);\n\t// Maps future on ready topology.\n\tprotected void mapOnTopology();\n\tvoid onDhtResponse(UUID nodeId, GridDhtAtomicNearResponse res);\n\t// Callback for when node left.\n\tboolean onNodeLeft(UUID nodeId);\n\t// Response callback.\n\tvoid onPrimaryResponse(UUID nodeId, GridNearAtomicUpdateResponse res, boolean nodeErr);\n}", "des": "DHT atomic cache near update future."}
{"index": 524, "repo": "ignite-core-2.15.0", "code": "Class GridNearTxEnlistFuture {\n\tboolean checkResponse(UUID nodeId, GridNearTxEnlistResponse res, Throwable err);\n\t// Start iterating the data rows and form batches.\n\tprotected void map(boolean topLocked);\n\t// Callback for when node left.\n\tboolean onNodeLeft(UUID nodeId);\n\tvoid onResult(UUID nodeId, GridNearTxEnlistResponse res);\n\tSet<UUID> pendingResponseNodes();\n}", "des": "A future tracking requests for remote nodes transaction enlisting and locking produces by cache API operations."}
{"index": 525, "repo": "ignite-core-2.15.0", "code": "Class GridNearTxFinishRequest {\n\t// Gets message type.\n\tshort directType();\n\tboolean explicitLock();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tint miniId();\n\tvoid miniId(int miniId);\n\t@Nullable MvccSnapshot mvccSnapshot();\n\tint partition();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tboolean storeEnabled();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Near transaction finish request."}
{"index": 526, "repo": "ignite-core-2.15.0", "code": "Class GridNearTxPrepareFutureAdapter {\n\tIgniteUuid futureId();\n\t// Marks this future as non-trackable.\n\tvoid markNotTrackable();\n\t// Called when related GridNearTxLocal is completed asynchronously on timeout,\n\tabstract void onNearTxLocalTimeout();\n\tabstract void onResult(UUID nodeId, GridNearTxPrepareResponse res);\n\t// Prepares transaction.\n\tabstract void prepare();\n\tboolean trackable();\n\tIgniteInternalTx tx();\n\tGridCacheVersion version();\n}", "des": "Common code for tx prepare in optimistic and pessimistic modes."}
{"index": 527, "repo": "ignite-core-2.15.0", "code": "Class GridNearTxQueryEnlistFuture {\n\t// Start iterating the data rows and form batches.\n\tprotected void map(boolean topLocked);\n\t// Callback for when node left.\n\tboolean onNodeLeft(UUID nodeId);\n\tvoid onResult(UUID nodeId, GridNearTxQueryEnlistResponse res);\n\tSet<UUID> pendingResponseNodes();\n}", "des": "Cache lock future."}
{"index": 528, "repo": "ignite-core-2.15.0", "code": "Class GridNearTxQueryResultsEnlistFuture {\n\tboolean checkResponse(UUID nodeId, GridNearTxQueryResultsEnlistResponse res, Throwable err);\n\t// Start iterating the data rows and form batches.\n\tprotected void map(boolean topLocked);\n\t// Callback for when node left.\n\tboolean onNodeLeft(UUID nodeId);\n\tvoid onResult(UUID nodeId, GridNearTxQueryResultsEnlistResponse res);\n\tSet<UUID> pendingResponseNodes();\n}", "des": "A future tracking requests for remote nodes transaction enlisting and locking of entries produced with complex DML queries requiring reduce step."}
{"index": 529, "repo": "ignite-core-2.15.0", "code": "Class GridNearTxQueryResultsEnlistResponse {\n\tIgniteUuid dhtFutureId();\n\tGridCacheVersion dhtVersion();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "A response to GridNearTxQueryResultsEnlistRequest."}
{"index": 530, "repo": "ignite-core-2.15.0", "code": "Class GridNearUnlockRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Near cache unlock request."}
{"index": 531, "repo": "ignite-core-2.15.0", "code": "Class GridNioClientConnectionMultiplexer {\n\t// Opens a new connection.\n\tClientConnection open(InetSocketAddress addr, ClientMessageHandler msgHnd, ClientConnectionStateHandler stateHnd);\n\t// Initializes this instance.\n\tvoid start();\n\t// Stops this instance.\n\tvoid stop();\n}", "des": "Client connection multiplexer based on GridNioServer."}
{"index": 532, "repo": "ignite-core-2.15.0", "code": "Class GridNioClientParser {\n\t// This method is called when input bytes are available on the underlying network connection.\n\t@Nullable Object decode(GridNioSession ses, ByteBuffer buf);\n\t// This method is called whenever a message should be sent to the network connection and network buffer is ready to be filled with bytes.\n\tByteBuffer encode(GridNioSession ses, Object msg);\n}", "des": "Client message parser."}
{"index": 533, "repo": "ignite-core-2.15.0", "code": "Class GridNioEmbeddedFuture<R> {\n\t// Callback to notify that future is finished.\n\tvoid onDone(GridNioFuture<R> res);\n\t// Callback to notify that future is finished.\n\tvoid onDone(@Nullable GridNioFuture<R> delegate, @Nullable Throwable err);\n}", "des": "Future that delegates to some other future."}
{"index": 534, "repo": "ignite-core-2.15.0", "code": "Class GridNioFinishedFuture<R> {\n\tIgniteInClosure<IgniteException> ackClosure();\n\tboolean messageThread();\n\t// Sets flag indicating that message send future was created in thread that was processing a message.\n\tvoid messageThread(boolean msgThread);\n\t// The method will be called when ack received.\n\tvoid onAckReceived();\n\tboolean skipRecovery();\n}", "des": "Future that represents already completed result."}
{"index": 535, "repo": "ignite-core-2.15.0", "code": "Interface GridNioFuture<R> {\n\tIgniteInClosure<IgniteException> ackClosure();\n\tboolean messageThread();\n\t// Sets flag indicating that message send future was created in thread that was processing a message.\n\tvoid messageThread(boolean msgThread);\n\t// The method will be called when ack received.\n\tvoid onAckReceived();\n\tboolean skipRecovery();\n}", "des": "NIO future."}
{"index": 536, "repo": "ignite-core-2.15.0", "code": "Class GridNioFutureImpl<R> {\n\tIgniteInClosure<IgniteException> ackClosure();\n\tboolean messageThread();\n\t// Sets flag indicating that message send future was created in thread that was processing a message.\n\tvoid messageThread(boolean msgThread);\n\t// The method will be called when ack received.\n\tvoid onAckReceived();\n\tboolean skipRecovery();\n}", "des": "Default future implementation."}
{"index": 537, "repo": "ignite-core-2.15.0", "code": "Interface GridNioParser {\n\t// This method is called when input bytes are available on the underlying network connection.\n\t@Nullable Object decode(GridNioSession ses, ByteBuffer buf);\n\t// This method is called whenever a message should be sent to the network connection and network buffer is ready to be filled with bytes.\n\tByteBuffer encode(GridNioSession ses, Object msg);\n}", "des": "This interface declares a basic contract on message parsing and encoding to the underlying network layer."}
{"index": 538, "repo": "ignite-core-2.15.0", "code": "Class GridNioServerBuffer {\n\t// Get data withing the buffer.\n\tbyte[] data();\n\t// Checks whether the byte array is filled.\n\tboolean isFilled();\n\t@Nullable byte[] read(ByteBuffer buf);\n\tvoid reset();\n}", "des": "NIO server buffer."}
{"index": 539, "repo": "ignite-core-2.15.0", "code": "Enum GridNioSessionMetaKey {\n\t// Returns next NIO session key ordinal for non-existing enum value.\n\tstatic int nextUniqueKey();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridNioSessionMetaKey valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridNioSessionMetaKey[] values();\n}", "des": "Meta keys for GridNioSession."}
{"index": 540, "repo": "ignite-core-2.15.0", "code": "Class GridNodePredicate {\n\t// Predicate body.\n\tboolean apply(ClusterNode n);\n\tboolean equals(Object o);\n\tIterator<UUID> iterator();\n\t// Gets set of node IDs this predicate is based on.\n\tSet<UUID> nodeIds();\n}", "des": "Convenient node predicate as a separate class. It allows to avoid \"dragging\" enclosing class's state when predicates are created as anonymous classes in stateful enclosing context. This class is also optimized for evaluation of large number of nodes."}
{"index": 541, "repo": "ignite-core-2.15.0", "code": "Enum GridOffHeapEvent {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable GridOffHeapEvent fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridOffHeapEvent valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridOffHeapEvent[] values();\n}", "des": "Off-heap event types."}
{"index": 542, "repo": "ignite-core-2.15.0", "code": "Class GridPartitionedGetFuture<K,V> {\n\t// Explicit predefined single mapping (backup or primary).\n\tClusterNode affNode();\n\t// Initializes future.\n\tvoid init(AffinityTopologyVersion topVer);\n\tprotected boolean isMini(IgniteInternalFuture<?> f);\n\tprotected void map(Collection<KeyCacheObject> keys, Map<ClusterNode,LinkedHashMap<KeyCacheObject,Boolean>> mapped, AffinityTopologyVersion topVer);\n\t// Callback to notify that future is finished.\n\tboolean onDone(Map<K,V> res, Throwable err);\n}", "des": "Colocated get future."}
{"index": 543, "repo": "ignite-core-2.15.0", "code": "Interface GridPeerDeployAware {\n\t// Gets class loader for the class.\n\tClassLoader classLoader();\n\t// Gets top level user class being deployed.\n\tClass<?> deployClass();\n}", "des": "Represents any class that needs to maintain or carry on peer deployment information."}
{"index": 544, "repo": "ignite-core-2.15.0", "code": "Class GridPeerDeployAwareAdapter {\n\t// Gets class loader for the class.\n\tClassLoader classLoader();\n\t// Gets top level user class being deployed.\n\tClass<?> deployClass();\n\t// Sets object that from which peer deployment information will be copied, i.e. this lambda object will be peer deployed using the same class loader as given object.\n\tvoid peerDeployLike(Object obj);\n}", "des": "Adapter for common interfaces in closures, reducers and predicates."}
{"index": 545, "repo": "ignite-core-2.15.0", "code": "Class GridPeerDeployAwareTaskAdapter<T,R> {\n\t// Gets class loader for the class.\n\tClassLoader classLoader();\n\t// Gets top level user class being deployed.\n\tClass<?> deployClass();\n}", "des": "Peer deployment aware task adapter."}
{"index": 546, "repo": "ignite-core-2.15.0", "code": "Class GridPredicate3X<E1,E2,E3> {\n\t// Predicate body.\n\tboolean apply(E1 e1, E2 e2, E3 e3);\n\t// Predicate body that can throw IgniteCheckedException.\n\tabstract boolean applyx(E1 e1, E2 e2, E3 e3);\n}", "des": "Convenient predicate subclass that allows for thrown grid exception. This class implements apply(Object, Object, Object) method that calls applyx(Object, Object, Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 547, "repo": "ignite-core-2.15.0", "code": "Class GridProtocolHandler {\n\t// Deregisters deployment manager.\n\tstatic void deregisterDeploymentManager();\n\tprotected URLConnection openConnection(URL url);\n\t// Registers deployment manager.\n\tstatic void registerDeploymentManager(GridDeploymentManager mgr);\n}", "des": "Custom stream protocol handler implementation."}
{"index": 548, "repo": "ignite-core-2.15.0", "code": "Interface GridProxyListener {\n\t// Method is called right after the traced method.\n\tvoid afterCall(Class<?> cls, String mtdName, Object[] args, Object res, Throwable e);\n\t// Method is called right before the traced method.\n\tvoid beforeCall(Class<?> cls, String mtdName, Object[] args);\n}", "des": "Interception listener is notified about method apply. For each intercepted method apply the listener will be called twice - before and after the apply."}
{"index": 549, "repo": "ignite-core-2.15.0", "code": "Class GridQueryCancel {\n\t// Adds a cancel action.\n\tvoid add(QueryCancellable clo);\n\t// Executes cancel closure.\n\tvoid cancel();\n\t// Stops query execution if a user requested cancel.\n\tvoid checkCancelled();\n\tboolean isCanceled();\n}", "des": "Holds query cancel state."}
{"index": 550, "repo": "ignite-core-2.15.0", "code": "Class GridQueryCancelRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tlong queryRequestId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Cancel map part of query request."}
{"index": 551, "repo": "ignite-core-2.15.0", "code": "Class GridQueryFailResponse {\n\t// Gets message type.\n\tshort directType();\n\tString error();\n\tbyte failCode();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tlong queryRequestId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Error message."}
{"index": 552, "repo": "ignite-core-2.15.0", "code": "Interface GridQueryFieldMetadata {\n\t// Gets field name.\n\tString fieldName();\n\t// Gets field type name.\n\tString fieldTypeName();\n\t// Gets field nullability.\n\tint nullability();\n\t// Gets field precision.\n\tint precision();\n\t// Gets field scale.\n\tint scale();\n\t// Gets schema name.\n\tString schemaName();\n\t// Gets name of type to which this field belongs.\n\tString typeName();\n}", "des": "Query field descriptor. This descriptor is used to provide metadata about fields returned in query result."}
{"index": 553, "repo": "ignite-core-2.15.0", "code": "Interface GridQueryFieldsResult {\n\t// Gets iterator over queried fields.\n\tIgniteSpiCloseableIterator<List<?>> iterator();\n\t// Gets metadata for queried fields.\n\tList<GridQueryFieldMetadata> metaData();\n}", "des": "Field query result. It is composed of fields metadata and iterator over queried fields."}
{"index": 554, "repo": "ignite-core-2.15.0", "code": "Class GridQueryFieldsResultAdapter {\n\t// Gets iterator over queried fields.\n\tGridCloseableIterator<List<?>> iterator();\n\t// Gets metadata for queried fields.\n\tList<GridQueryFieldMetadata> metaData();\n}", "des": "Convenience adapter for GridQueryFieldsResult."}
{"index": 555, "repo": "ignite-core-2.15.0", "code": "Interface GridQueryIndexDescriptor {\n\t// Specifies order of the index for each indexed field.\n\tboolean descending(String field);\n\t// Gets all fields to be indexed.\n\tCollection<String> fields();\n\t// Gets inline size for SORTED index.\n\tint inlineSize();\n\tString name();\n\t// Gets index type.\n\tQueryIndexType type();\n}", "des": "Describes an index to be created for a certain type. It contains all necessary information about fields, order, uniqueness, and specified whether this is SQL or Text index. See also GridQueryTypeDescriptor.indexes()."}
{"index": 556, "repo": "ignite-core-2.15.0", "code": "Class GridQueryKillRequest {\n\tboolean asyncResponse();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tlong nodeQryId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tlong requestId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Query kill request."}
{"index": 557, "repo": "ignite-core-2.15.0", "code": "Class GridQueryKillResponse {\n\t// Gets message type.\n\tshort directType();\n\tString error();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tlong requestId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Query kill response."}
{"index": 558, "repo": "ignite-core-2.15.0", "code": "Class GridQueryNextPageRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tbyte getFlags();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tint pageSize();\n\tint query();\n\tlong queryRequestId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tint segmentId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Request to fetch next page."}
{"index": 559, "repo": "ignite-core-2.15.0", "code": "Class GridQueue<E> {\n\tboolean add(E e);\n\tE element();\n\tIterator<E> iterator();\n\tboolean offer(E e);\n\t// Same as offer(Object), but returns created node.\n\tGridQueue.Node<E> offerx(E e);\n\tE peek();\n\tGridQueue.Node<E> peekx();\n\t// Polls element from head of the queue.\n\tE poll();\n\tE remove();\n\tboolean remove(Object o);\n\t// Gets queue size.\n\tint size();\n\t// Unlinks node from the queue.\n\tvoid unlink(GridQueue.Node<E> n);\n}", "des": "Queue which supports addition at tail and removing at head. This queue also exposes its internal linked list nodes and allows for constant time removal from the middle of the queue."}
{"index": 560, "repo": "ignite-core-2.15.0", "code": "Class GridQueue.Node<E> {\n\t// Gets this node's item.\n\tE item();\n\t// Checks if node is unlinked.\n\tboolean unlinked();\n}", "des": "Node for internal linked list."}
{"index": 561, "repo": "ignite-core-2.15.0", "code": "Class GridRedisAppendCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis APPEND command handler."}
{"index": 562, "repo": "ignite-core-2.15.0", "code": "Enum GridRedisCommand {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridRedisCommand valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridRedisCommand[] values();\n}", "des": "Supported Redis-specific commands. See Redis commands for details."}
{"index": 563, "repo": "ignite-core-2.15.0", "code": "Class GridRedisDbSizeCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis DBSIZE command handler."}
{"index": 564, "repo": "ignite-core-2.15.0", "code": "Class GridRedisDelCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis DEL command handler."}
{"index": 565, "repo": "ignite-core-2.15.0", "code": "Class GridRedisExistsCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis EXISTS command handler."}
{"index": 566, "repo": "ignite-core-2.15.0", "code": "Class GridRedisExpireCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis EXPIRE/PEXPIRE command handler."}
{"index": 567, "repo": "ignite-core-2.15.0", "code": "Class GridRedisFlushCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis FLUSHDB/FLUSHALL command handler."}
{"index": 568, "repo": "ignite-core-2.15.0", "code": "Class GridRedisGetCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis GET command handler."}
{"index": 569, "repo": "ignite-core-2.15.0", "code": "Class GridRedisGetRangeCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis SETRANGE command handler."}
{"index": 570, "repo": "ignite-core-2.15.0", "code": "Class GridRedisGetSetCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis GETSET command handler."}
{"index": 571, "repo": "ignite-core-2.15.0", "code": "Class GridRedisIncrDecrCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis INCR/DECR command handler."}
{"index": 572, "repo": "ignite-core-2.15.0", "code": "Class GridRedisMGetCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis MGET command handler."}
{"index": 573, "repo": "ignite-core-2.15.0", "code": "Class GridRedisMSetCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis MSET command handler."}
{"index": 574, "repo": "ignite-core-2.15.0", "code": "Class GridRedisNioListener {\n\t// This method is called whenever a new client is connected and session is created.\n\tvoid onConnected(GridNioSession ses);\n\t// This method is called whenever client is disconnected due to correct connection close or due to IOException during network operations.\n\tvoid onDisconnected(GridNioSession ses, @Nullable Exception e);\n\t// This method is called whenever a GridNioParser returns non-null value.\n\tvoid onMessage(GridNioSession ses, GridRedisMessage msg);\n}", "des": "Listener for Redis protocol requests."}
{"index": 575, "repo": "ignite-core-2.15.0", "code": "Class GridRedisSetCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis SET command handler."}
{"index": 576, "repo": "ignite-core-2.15.0", "code": "Class GridRedisSetRangeCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis SETRANGE command handler."}
{"index": 577, "repo": "ignite-core-2.15.0", "code": "Class GridRedisStrlenCommandHandler {\n\t// Converts GridRedisMessage to GridRestRequest.\n\tGridRestRequest asRestRequest(GridRedisMessage msg);\n\t// Prepares a response according to the request.\n\tByteBuffer makeResponse(GridRestResponse restRes, List<String> params);\n\tCollection<GridRedisCommand> supportedCommands();\n}", "des": "Redis STRLEN command handler."}
{"index": 578, "repo": "ignite-core-2.15.0", "code": "Interface GridReservable {\n\t// Releases.\n\tvoid release();\n\t// Reserves.\n\tboolean reserve();\n}", "des": "Reservations support."}
{"index": 579, "repo": "ignite-core-2.15.0", "code": "Class GridResourceIoc {\n\t// Injects given resource via field or setter with specified annotations on provided target object.\n\tboolean inject(Object target, Class<? extends Annotation> annCls, org.apache.ignite.internal.processors.resource.GridResourceInjector injector, @Nullable GridDeployment dep, @Nullable Class<?> depCls);\n\t// Print memory statistics\n\tvoid printMemoryStats();\n}", "des": "Resource container contains caches for classes used for injection. Caches used to improve the efficiency of standard Java reflection mechanism."}
{"index": 580, "repo": "ignite-core-2.15.0", "code": "Enum GridRestCommand {\n\tstatic @Nullable GridRestCommand fromKey(String key);\n\tstatic @Nullable GridRestCommand fromOrdinal(int ord);\n\tString key();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridRestCommand valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridRestCommand[] values();\n}", "des": "Supported commands."}
{"index": 581, "repo": "ignite-core-2.15.0", "code": "Class GridRestProcessor {\n\tprotected IgniteInternalFuture<GridRestResponse> handleAsync0(GridRestRequest req);\n\t// Callback that notifies that kernal has successfully started, including all managers and processors.\n\tvoid onKernalStart(boolean active);\n\t// Callback to notify that kernal is about to stop.\n\tvoid onKernalStop(boolean cancel);\n\t// Prints memory statistics (sizes of internal structures, etc.).\n\tvoid printMemoryStats();\n\t// Starts grid component.\n\tvoid start();\n}", "des": "Rest processor implementation."}
{"index": 582, "repo": "ignite-core-2.15.0", "code": "Interface GridRestProtocol {\n\t// Returns protocol properties for setting node attributes.\n\tCollection<IgniteBiTuple<String,Object>> getProperties();\n\tString name();\n\t// Grid start callback.\n\tvoid onKernalStart();\n\t// Processor start callback.\n\tvoid onProcessorStart();\n\t// Starts protocol.\n\tvoid start(GridRestProtocolHandler hnd);\n\t// Stops protocol.\n\tvoid stop();\n}", "des": "REST protocol."}
{"index": 583, "repo": "ignite-core-2.15.0", "code": "Class GridRestWarmUpRequest {\n\t// Return true to stop warm-up.\n\tboolean stopWarmUp();\n\t// Set need to stop warm-up.\n\tGridRestWarmUpRequest stopWarmUp(boolean stopWarmUp);\n}", "des": "Grid warm-up request."}
{"index": 584, "repo": "ignite-core-2.15.0", "code": "Class GridReversedLinesFileReader {\n\t// Closes underlying resources.\n\tvoid close();\n\t// Returns the lines of the file from bottom to top.\n\tString readLine();\n}", "des": "Reads lines in a file reversely (similar to a BufferedReader, but starting at the last line). Useful for e.g. searching in log files."}
{"index": 585, "repo": "ignite-core-2.15.0", "code": "Class GridRouterCommandLineStartup {\n\t// Wrapper method to run router from command-line.\n\tstatic void main(String[] args);\n\t// Search given context for required configuration and starts router.\n\tvoid start(Map<Class<?>,Collection> beans);\n\t// Stops router.\n\tvoid stop();\n}", "des": "Loader class for router."}
{"index": 586, "repo": "ignite-core-2.15.0", "code": "Class GridRouterFactory {\n\t// Returns collection of all currently running TCP routers.\n\tstatic Collection<GridTcpRouter> allTcpRouters();\n\t// Starts a TCP router with given configuration.\n\tstatic GridTcpRouter startTcpRouter(GridTcpRouterConfiguration cfg);\n\t// Stops all currently active routers.\n\tstatic void stopAllRouters();\n\t// Stops particular TCP router.\n\tstatic void stopTcpRouter(UUID tcpRouterId);\n\t// Returns TCP router with the given id.\n\tstatic @Nullable GridTcpRouter tcpRouter(UUID id);\n}", "des": "This factory is responsible for router lifecycle management. All router should be started, accessed and stopped through this factory. Embedding router You can use GridTcpRouterConfiguration to set configuration parameters and pass them to startTcpRouter(GridTcpRouterConfiguration)."}
{"index": 587, "repo": "ignite-core-2.15.0", "code": "Class GridSetWrapper<E> {\n\tboolean add(E e);\n\tvoid clear();\n\tboolean contains(Object o);\n\t// Provides default map value to child classes.\n\tprotected Object defaultValue();\n\tboolean isEmpty();\n\tIterator<E> iterator();\n\t// Gets wrapped map.\n\tprotected <T extends Map<E,Object>>T map();\n\tboolean remove(Object o);\n\tint size();\n\tObject[] toArray();\n\t<T> T[] toArray(T[] a);\n}", "des": "Set implementation that delegates to map."}
{"index": 588, "repo": "ignite-core-2.15.0", "code": "Class GridSnapshotLock<X> {\n\t// Must be called before update begin.\n\tvoid beginUpdate();\n\tprotected abstract X doSnapshot();\n\t// Signal that update operation finished.\n\tvoid endUpdate();\n\tX snapshot();\n\tboolean tryBeginUpdate();\n}", "des": "Synchronization primitive allowing concurrent updates and taking consistent snapshots."}
{"index": 589, "repo": "ignite-core-2.15.0", "code": "Class GridSpiCloseableIteratorWrapper<T> {\n\t// Invoked on iterator close.\n\tprotected void onClose();\n\tprotected boolean onHasNext();\n\tprotected T onNext();\n\t// Called on remove from iterator.\n\tprotected void onRemove();\n}", "des": "Wrapper used to covert IgniteSpiCloseableIterator to GridCloseableIterator."}
{"index": 590, "repo": "ignite-core-2.15.0", "code": "Class GridSpinBusyLock {\n\t// Blocks current thread till all activities left \"busy\" state and prevents them from further entering to \"busy\" state.\n\tvoid block();\n\t// Checks if busy lock was blocked by current thread.\n\tboolean blockedByCurrentThread();\n\t// Enters \"busy\" state.\n\tboolean enterBusy();\n\t// Leaves \"busy\" state.\n\tvoid leaveBusy();\n\tboolean tryBlock(long millis);\n\t// Makes possible for activities entering busy state again.\n\tvoid unblock();\n}", "des": "Synchronization aid to track \"busy\" state of a subsystem that owns it."}
{"index": 591, "repo": "ignite-core-2.15.0", "code": "Class GridStringBuilderFactory {\n\t// Acquires a cached instance of StringBuilder if current thread is not using it yet.\n\tstatic SB acquire();\n\t// Releases StringBuilder back to cache.\n\tstatic void release(SB builder);\n}", "des": "Per-thread cache of StringBuilder instances."}
{"index": 592, "repo": "ignite-core-2.15.0", "code": "Class GridStripedReadWriteLock {\n\t// Gets concurrency level.\n\tint concurrencyLevel();\n\t// Gets all locks.\n\tReadWriteLock[] getAllLocks();\n\t// Returns Lock object for the given key.\n\tReadWriteLock getLock(int key);\n\t// Returns Lock object for the given key.\n\tReadWriteLock getLock(long key);\n\t// Returns lock for object.\n\tReadWriteLock getLock(@Nullable Object o);\n}", "des": "This is an utility class for 'splitting' locking of some int- or long-keyed resources. Map int and long values to some number of locks, and supply convenience methods to obtain and release these locks using key values."}
{"index": 593, "repo": "ignite-core-2.15.0", "code": "Class GridStripedSpinBusyLock {\n\t// Block.\n\tvoid block();\n\t// Enter busy state.\n\tboolean enterBusy();\n\t// Leave busy state.\n\tvoid leaveBusy();\n}", "des": "Striped spin busy lock. Aimed to provide efficient \"read\" lock semantics while still maintaining safety when entering \"busy\" state."}
{"index": 594, "repo": "ignite-core-2.15.0", "code": "Class GridTaskCancelRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Gets execution ID of task to be cancelled.\n\tIgniteUuid sessionId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Request for cancelling tasks."}
{"index": 595, "repo": "ignite-core-2.15.0", "code": "Class GridTaskSessionRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tMap<?,?> getAttributes();\n\tbyte[] getAttributesBytes();\n\tIgniteUuid getJobId();\n\tIgniteUuid getSessionId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Task session request."}
{"index": 596, "repo": "ignite-core-2.15.0", "code": "Class GridTaskWorker<T,R> {\n\tString affCacheName();\n\tint affPartId();\n\t// Maps this task's jobs to nodes and sends them out.\n\tprotected void body();\n\tlong endTime();\n\tboolean equals(Object obj);\n\tGridTaskSessionImpl getSession();\n\tComputeTask<T,R> getTask();\n\tboolean isInternal();\n\t// Timeout callback.\n\tvoid onTimeout();\n\tvoid setTask(ComputeTask<T,R> task);\n\tIgniteUuid timeoutId();\n}", "des": "Grid task worker. Handles full task life cycle."}
{"index": 597, "repo": "ignite-core-2.15.0", "code": "Class GridTcpMemcachedNioListener {\n\t// This method is called whenever a new client is connected and session is created.\n\tvoid onConnected(GridNioSession ses);\n\t// This method is called whenever client is disconnected due to correct connection close or due to IOException during network operations.\n\tvoid onDisconnected(GridNioSession ses, @Nullable Exception e);\n\t// This method is called whenever a GridNioParser returns non-null value.\n\tvoid onMessage(GridNioSession ses, GridMemcachedMessage req);\n}", "des": "Handles memcache requests."}
{"index": 598, "repo": "ignite-core-2.15.0", "code": "Class GridTcpRestProtocol {\n\t// Return node attribute name to store used address.\n\tprotected String getAddressPropertyName();\n\t// Return node attribute name to store used host name.\n\tprotected String getHostNamePropertyName();\n\t// Return node attribute name to store used port number.\n\tprotected String getPortPropertyName();\n\tString name();\n\t// Processor start callback.\n\tvoid onProcessorStart();\n\t// Starts protocol.\n\tvoid start(GridRestProtocolHandler hnd);\n\t// Stops protocol.\n\tvoid stop();\n}", "des": "TCP binary protocol implementation."}
{"index": 599, "repo": "ignite-core-2.15.0", "code": "Interface GridTcpRouter {\n\t// Returns configuration used to start router.\n\tGridTcpRouterConfiguration configuration();\n\t// Returns router Id.\n\tUUID id();\n}", "des": "TCP router interface."}
{"index": 600, "repo": "ignite-core-2.15.0", "code": "Class GridTestPrintStreamFactory {\n\t// Acquires output stream for logging errors in tests.\n\tstatic GridTestPrintStream acquireErr();\n\t// Acquires output stream for logging tests.\n\tstatic GridTestPrintStream acquireOut();\n\t// Gets original standard error.\n\tstatic PrintStream getStdErr();\n\t// Gets original standard out.\n\tstatic PrintStream getStdOut();\n\t// Releases standard error.\n\tstatic void releaseErr();\n\t// Releases standard out.\n\tstatic void releaseOut();\n}", "des": "Factory that allow to acquire/release Print Stream for test logging."}
{"index": 601, "repo": "ignite-core-2.15.0", "code": "Class GridTimer {\n\tlong duration();\n\tlong endTime();\n\tboolean maxedOut();\n\tString name();\n\tlong startTime();\n\t// Stops this timer.\n\tlong stop();\n\t// Stops this timer.\n\tboolean stopx();\n\tlong threshold();\n}", "des": "Timer to use mostly for debugging purposes."}
{"index": 602, "repo": "ignite-core-2.15.0", "code": "Class GridTuple<V> {\n\tObject clone();\n\tboolean equals(Object obj);\n\t// Gets value.\n\tV get();\n\tIterator<V> iterator();\n\tvoid readExternal(ObjectInput in);\n\t// Sets value.\n\tvoid set(V val);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Convenience class representing mutable tuple of a single value. Thread Safety This class doesn't provide any synchronization for multi-threaded access and it is responsibility of the user of this class to provide outside synchronization, if needed."}
{"index": 603, "repo": "ignite-core-2.15.0", "code": "Class GridTuple3<V1,V2,V3> {\n\tObject clone();\n\tboolean equals(Object o);\n\t// Gets first value.\n\tV1 get1();\n\t// Gets second value.\n\tV2 get2();\n\t// Gets third value.\n\tV3 get3();\n\tIterator<Object> iterator();\n\tvoid readExternal(ObjectInput in);\n\t// Sets all values.\n\tvoid set(V1 val1, V2 val2, V3 val3);\n\t// Sets first value.\n\tvoid set1(V1 val1);\n\t// Sets second value.\n\tvoid set2(V2 val2);\n\t// Sets third value.\n\tvoid set3(V3 val3);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Convenience class representing mutable tuple of three values. Thread Safety This class doesn't provide any synchronization for multi-threaded access and it is responsibility of the user of this class to provide outside synchronization, if needed."}
{"index": 604, "repo": "ignite-core-2.15.0", "code": "Class GridWorkerPool {\n\t// Schedules runnable task for execution.\n\tvoid execute(GridWorker w);\n\t// Waits for all workers to finish.\n\tvoid join(boolean cancel);\n}", "des": "Pool of runnable workers. This class automatically takes care of error handling that has to do with executing a runnable task and ensures that all tasks are finished when stop occurs."}
{"index": 605, "repo": "ignite-core-2.15.0", "code": "Class HandshakeMessage {\n\tlong connectCount();\n\tint connectionIndex();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tint getMessageSize();\n\tUUID nodeId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tlong received();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Handshake message."}
{"index": 606, "repo": "ignite-core-2.15.0", "code": "Class HandshakeMessage2 {\n\tint connectionIndex();\n\t// Gets message type.\n\tshort directType();\n\tint getMessageSize();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Updated handshake message."}
{"index": 607, "repo": "ignite-core-2.15.0", "code": "Class HandshakeWaitMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Message requesting to wait until node's SPI context initialize."}
{"index": 608, "repo": "ignite-core-2.15.0", "code": "Class Hasher {\n\t// Calculate hash by specified byte array.\n\tlong fastHash(byte[] arr);\n\t// Calculate hash by specified part of byte array.\n\tlong fastHash(byte[] arr, int off, int len);\n}", "des": "Implement Murmur8_128 hash function for byte arrays."}
{"index": 609, "repo": "ignite-core-2.15.0", "code": "Class HistogramMetricImpl {\n\tlong[] bounds();\n\t// Sets bounds for this histogram.\n\tvoid bounds(long[] bounds);\n\t@Nullable String getAsString();\n\t// Resets metric state.\n\tvoid reset();\n\t// Resets histogram state with the specified bounds.\n\tvoid reset(long[] bounds);\n\tClass<long[]> type();\n\tlong[] value();\n\t// Sets value.\n\tvoid value(long x);\n}", "des": "Histogram metric implementation."}
{"index": 610, "repo": "ignite-core-2.15.0", "code": "Interface HistoryAffinityAssignment {\n\t// In case this instance is lightweight wrapper of another instance, this method should return reference to an original one.\n\tHistoryAffinityAssignment origin();\n\t// Should return true if instance is \"heavy\" and should be taken into account during history size management.\n\tboolean requiresHistoryCleanup();\n}", "des": "Interface for historical calculated affinity assignment."}
{"index": 611, "repo": "ignite-core-2.15.0", "code": "Class HitRateMetric {\n\t// Adds x to the metric.\n\tvoid add(long x);\n\t// Adds 1 to the metric.\n\tvoid increment();\n\tlong rateTimeInterval();\n\t// Resets metric state.\n\tvoid reset();\n\t// Resets metric with the new parametes.\n\tvoid reset(long rateTimeInterval);\n\t// Resets metric with the new parameters.\n\tvoid reset(long rateTimeInterval, int size);\n\tlong value();\n}", "des": "Accumulates approximate hit rate statistics. Calculates number of hits in last rateTimeInterval milliseconds. Algorithm is based on circular array of size hit counters, each is responsible for last corresponding time interval of rateTimeInterval/size milliseconds. Resulting number of hits is sum of all counters."}
{"index": 612, "repo": "ignite-core-2.15.0", "code": "Enum HLLType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HLLType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HLLType[] values();\n}", "des": "The types of algorithm/data structure that HLL can utilize. For more information, see the Javadoc for HLL."}
{"index": 613, "repo": "ignite-core-2.15.0", "code": "Class IdleVerifyDumpResult {\n\tMap<PartitionKeyV2,List<PartitionHashRecordV2>> clusterHashes();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Encapsulates result of VerifyBackupPartitionsDumpTask."}
{"index": 614, "repo": "ignite-core-2.15.0", "code": "Interface IgniteAtomicReference<T> {\n\t// Removes this atomic reference.\n\tvoid close();\n\t// Conditionally sets the new value.\n\tboolean compareAndSet(T expVal, T newVal);\n\t// Gets current value of an atomic reference.\n\tT get();\n\t// Name of atomic reference.\n\tString name();\n\t// Gets status of atomic.\n\tboolean removed();\n\t// Unconditionally sets the value.\n\tvoid set(T val);\n}", "des": "This interface provides a rich API for working with distributed atomic reference."}
{"index": 615, "repo": "ignite-core-2.15.0", "code": "Interface IgniteBiPredicate<E1,E2> {\n\t// Returns a composed predicate that represents a short-circuiting logical AND of this predicate and another.\n\tdefault IgniteBiPredicate<E1,E2> and(IgniteBiPredicate<E1,E2> then);\n\t// Predicate body.\n\tboolean apply(E1 e1, E2 e2);\n}", "des": "Defines a predicate which accepts two parameters and returns true or false."}
{"index": 616, "repo": "ignite-core-2.15.0", "code": "Interface IgniteCacheExpiryPolicy {\n\t@Nullable Map<KeyCacheObject,GridCacheVersion> entries();\n\tlong forAccess();\n\tlong forCreate();\n\tlong forUpdate();\n\t@Nullable Map<UUID,Collection<IgniteBiTuple<KeyCacheObject,GridCacheVersion>>> readers();\n\tboolean readyToFlush(int cnt);\n\t// Clears information about updated entries.\n\tvoid reset();\n\t// Callback for ttl update on entry access.\n\tvoid ttlUpdated(KeyCacheObject key, GridCacheVersion ver, @Nullable Collection<UUID> rdrs);\n}", "des": "Wrapper for ExpiryPolicy used to track information about cache entries whose time to live was modified after access."}
{"index": 617, "repo": "ignite-core-2.15.0", "code": "Interface IgniteChangeGlobalStateSupport {\n\t// Called when cluster performing activation.\n\tvoid onActivate(GridKernalContext kctx);\n\t// Called when cluster performing deactivation.\n\tvoid onDeActivate(GridKernalContext kctx);\n}", "des": "Provides callback during activation/deactivation cluster."}
{"index": 618, "repo": "ignite-core-2.15.0", "code": "Class IgniteCheckedException {\n\t// Gets first exception of given class from 'cause' hierarchy if any.\n\t<T extends Throwable>T getCause(@Nullable Class<T> cls);\n\t// Checks if this exception has given class in 'cause' hierarchy.\n\tboolean hasCause(Class<? extends Throwable>... cls);\n}", "des": "General grid exception. This exception is used to indicate any error condition within Grid."}
{"index": 619, "repo": "ignite-core-2.15.0", "code": "Class IgniteClosure2X<E1,E2,R> {\n\t// Closure body.\n\tR apply(E1 e1, E2 e2);\n\t// Closure body that can throw IgniteCheckedException.\n\tabstract R applyx(E1 e1, E2 e2);\n}", "des": "Convenient closure subclass that allows for thrown grid exception. This class implements apply(Object, Object) method that calls applyx(Object, Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 620, "repo": "ignite-core-2.15.0", "code": "Class IgniteClosureX<E,R> {\n\t// Closure body.\n\tR apply(E e);\n\t// Closure body that can throw IgniteCheckedException.\n\tabstract R applyx(E e);\n}", "des": "Convenient closure subclass that allows for thrown grid exception. This class implements apply(Object) method that calls applyx(Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 621, "repo": "ignite-core-2.15.0", "code": "Interface IgniteClusterMXBean {\n\t// Gets cluster ID.\n\tUUID getId();\n\t// Gets current cluster tag.\n\tString getTag();\n\t// Changes cluster tag to provided value.\n\tvoid tag(String newTag);\n}", "des": "MX Bean allows to access information about cluster ID and tag and change tag."}
{"index": 622, "repo": "ignite-core-2.15.0", "code": "Class IgniteClusterMXBeanImpl {\n\t// Gets cluster ID.\n\tUUID getId();\n\t// Gets current cluster tag.\n\tString getTag();\n\t// Changes cluster tag to provided value.\n\tvoid tag(String newTag);\n}", "des": "Implementation of IgniteClusterMXBean interface."}
{"index": 623, "repo": "ignite-core-2.15.0", "code": "Class IgniteDataTransferObject {\n\tbyte getProtocolVersion();\n\tvoid readExternal(ObjectInput in);\n\t// Load object's specific data content.\n\tprotected abstract void readExternalData(byte protoVer, ObjectInput in);\n\tprotected static <T> @Nullable List<T> toList(Collection<T> col);\n\tprotected static <T> @Nullable Set<T> toSet(Collection<T> col);\n\tvoid writeExternal(ObjectOutput out);\n\t// Save object's specific data content.\n\tprotected abstract void writeExternalData(ObjectOutput out);\n}", "des": "Base class for data transfer objects."}
{"index": 624, "repo": "ignite-core-2.15.0", "code": "Interface IgniteDefragmentation {\n\t// Cancel scheduled or ongoing defragmentation.\n\tIgniteDefragmentation.CancelResult cancel();\n\tboolean inProgress();\n\tint processedPartitions();\n\t// Schedule defragmentaton on next start of the node.\n\tIgniteDefragmentation.ScheduleResult schedule(List<String> cacheNames);\n\tlong startTime();\n\t// Get the status of the ongoing defragmentation.\n\tIgniteDefragmentation.DefragmentationStatus status();\n\tint totalPartitions();\n}", "des": "Defragmentation operation service."}
{"index": 625, "repo": "ignite-core-2.15.0", "code": "Enum IgniteDefragmentation.CancelResult {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IgniteDefragmentation.CancelResult valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IgniteDefragmentation.CancelResult[] values();\n}", "des": "Result of the cancellation."}
{"index": 626, "repo": "ignite-core-2.15.0", "code": "Enum IgniteDefragmentation.ScheduleResult {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IgniteDefragmentation.ScheduleResult valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IgniteDefragmentation.ScheduleResult[] values();\n}", "des": "Result of the scheduling."}
{"index": 627, "repo": "ignite-core-2.15.0", "code": "Class IgniteDefragmentationImpl {\n\t// Cancel scheduled or ongoing defragmentation.\n\tIgniteDefragmentation.CancelResult cancel();\n\tboolean inProgress();\n\tint processedPartitions();\n\t// Schedule defragmentaton on next start of the node.\n\tIgniteDefragmentation.ScheduleResult schedule(List<String> cacheNames);\n\tlong startTime();\n\t// Get the status of the ongoing defragmentation.\n\tIgniteDefragmentation.DefragmentationStatus status();\n\tint totalPartitions();\n}", "des": "Defragmentation operation service implementation."}
{"index": 628, "repo": "ignite-core-2.15.0", "code": "Interface IgniteEncryption {\n\t// Starts cache group encryption key change process.\n\tIgniteFuture<Void> changeCacheGroupKey(Collection<String> cacheOrGrpNames);\n\t// Starts master key change process.\n\tIgniteFuture<Void> changeMasterKey(String masterKeyName);\n\t// Gets the current master key name.\n\tString getMasterKeyName();\n}", "des": "Defines encryption features."}
{"index": 629, "repo": "ignite-core-2.15.0", "code": "Class IgniteException {\n\t// Gets first exception of given class from 'cause' hierarchy if any.\n\t<T extends Throwable>T getCause(@Nullable Class<T> cls);\n\t// Checks if this exception has given class in 'cause' hierarchy.\n\tboolean hasCause(Class<? extends Throwable>... cls);\n}", "des": "General grid exception. This exception is used to indicate any error condition within Grid."}
{"index": 630, "repo": "ignite-core-2.15.0", "code": "Class IgniteExceptionRegistry {\n\t// Errors count.\n\tlong errorCount();\n\tstatic IgniteExceptionRegistry get();\n\t// Gets suppressed errors.\n\tList<IgniteExceptionRegistry.ExceptionInfo> getErrors(long order);\n\t// Puts exception into queue.\n\tvoid onException(String msg, Throwable e);\n\t// Prints errors.\n\tvoid printErrors(IgniteLogger log);\n\t// Sets max size.\n\tvoid setMaxSize(int maxSize);\n}", "des": "Utility to collect suppressed errors within internal code."}
{"index": 631, "repo": "ignite-core-2.15.0", "code": "Class IgniteIllegalStateException {\n\t// Gets first exception of given class from 'cause' hierarchy if any.\n\t<T extends Throwable>T getCause(@Nullable Class<T> cls);\n\t// Checks if this exception has given class in 'cause' hierarchy.\n\tboolean hasCause(Class<? extends Throwable>... cls);\n}", "des": "This exception indicates the ignite access in invalid state."}
{"index": 632, "repo": "ignite-core-2.15.0", "code": "Class IgniteInClosure2X<E1,E2> {\n\t// Closure body.\n\tvoid apply(E1 e1, E2 e2);\n\t// In-closure body that can throw IgniteCheckedException.\n\tabstract void applyx(E1 e1, E2 e2);\n}", "des": "Convenient in-closure subclass that allows for thrown grid exception. This class implements apply(Object, Object) method that calls applyx(Object, Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 633, "repo": "ignite-core-2.15.0", "code": "Class IgniteInClosureX<T> {\n\t// Closure body.\n\tvoid apply(T t);\n\t// In-closure body that can throw IgniteCheckedException.\n\tabstract void applyx(T t);\n}", "des": "Convenient in-closure subclass that allows for thrown grid exception. This class implements apply(Object) method that calls applyx(Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 634, "repo": "ignite-core-2.15.0", "code": "Class IgniteIrreparableConsistencyViolationException {\n\t// Inconsistent keys found but can not be repaired using the specified strategy.\n\tCollection<Object> irreparableKeys();\n\t// Inconsistent keys found but can be repaired using the specified strategy.\n\tCollection<Object> repairableKeys();\n}", "des": "Irreparable consistency violation exception."}
{"index": 635, "repo": "ignite-core-2.15.0", "code": "Interface IgniteLoggerEx {\n\t// Adds console appender to the logger.\n\tvoid addConsoleAppender(boolean clearOutput);\n\t// Flush any buffered output.\n\tvoid flush();\n\t// Sets application name and node ID.\n\tvoid setApplicationAndNode(@Nullable String application, @Nullable UUID nodeId);\n}", "des": "Internal extension of IgniteLogger."}
{"index": 636, "repo": "ignite-core-2.15.0", "code": "Class IgniteMBeansManager {\n\t// Register an Ignite MBean.\n\t<T> void registerMBean(String grp, String name, T impl, Class<T> itf);\n\t// Registers kernal MBeans (for kernal, metrics, thread pools) after node start.\n\tvoid registerMBeansAfterNodeStarted();\n\t// Registers kernal MBeans during init phase.\n\tvoid registerMBeansDuringInitPhase();\n\t// Unregisters all previously registered MBeans.\n\tboolean unregisterAllMBeans();\n}", "des": "Class that registers and unregisters MBeans for kernal."}
{"index": 637, "repo": "ignite-core-2.15.0", "code": "Class IgniteMessageFactoryImpl {\n\t// Creates new message instance of provided direct type.\n\t@Nullable Message create(short directType);\n\t// Register message factory with given direct type.\n\tvoid register(short directType, Supplier<Message> supplier);\n\t// Returns direct types of all registered messages.\n\tshort[] registeredDirectTypes();\n}", "des": "Message factory implementation which is responsible for instantiation of all communication messages."}
{"index": 638, "repo": "ignite-core-2.15.0", "code": "Class IgniteNodeStartUtils {\n\t// Parses and expands range of IPs, if needed.\n\tstatic Set<String> expandHost(String addr);\n\t// Parses INI file.\n\tstatic IgniteBiTuple<Collection<Map<String,Object>>,Map<String,Object>> parseFile(File file);\n\t// Makes specifications.\n\tstatic Map<String,Collection<IgniteRemoteStartSpecification>> specifications(Collection<Map<String,Object>> hosts, @Nullable Map<String,Object> dflts);\n}", "des": "Util methods for IgniteCluster.startNodes(..) methods."}
{"index": 639, "repo": "ignite-core-2.15.0", "code": "Class IgniteOutClosureX<T> {\n\t// Closure body.\n\tT apply();\n\t// Out-closure body that can throw IgniteCheckedException.\n\tabstract T applyx();\n}", "des": "Convenient out-closure subclass that allows for thrown grid exception. This class implements apply() method that calls applyx() method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 640, "repo": "ignite-core-2.15.0", "code": "Enum IgnitePortProtocol {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable IgnitePortProtocol fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IgnitePortProtocol valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IgnitePortProtocol[] values();\n}", "des": "Protocols supported by port processor."}
{"index": 641, "repo": "ignite-core-2.15.0", "code": "Class IgnitePredicate2X<E1,E2> {\n\t// Predicate body.\n\tboolean apply(E1 e1, E2 e2);\n\t// Predicate body that can throw IgniteCheckedException.\n\tabstract boolean applyx(E1 e1, E2 e2);\n}", "des": "Convenient predicate subclass that allows for thrown grid exception. This class implements apply(Object, Object) method that calls applyx(Object, Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 642, "repo": "ignite-core-2.15.0", "code": "Class IgnitePredicateX<E1> {\n\t// Predicate body.\n\tboolean apply(E1 e);\n\t// Predicate body that can throw IgniteCheckedException.\n\tabstract boolean applyx(E1 e);\n}", "des": "Convenient predicate subclass that allows for thrown grid exception. This class implements apply(Object) method that calls applyx(Object) method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 643, "repo": "ignite-core-2.15.0", "code": "Class IgniteQueryErrorCode {\n\t// Map Ignite specific error code to standard SQL state.\n\tstatic String codeToSqlState(int statusCode);\n\t// Create a SQLException for given code and message with detected state.\n\tstatic SQLException createJdbcSqlException(String msg, int code);\n}", "des": "Error codes for query operations."}
{"index": 644, "repo": "ignite-core-2.15.0", "code": "Interface IgniteRebalanceIterator {\n\tboolean historical(int partId);\n\tboolean isPartitionDone(int partId);\n\tboolean isPartitionMissing(int partId);\n\t// Return next element without moving iterator cursor to the next one.\n\tCacheDataRow peek();\n\t// Marks partition as missing.\n\tvoid setPartitionMissing(int partId);\n}", "des": "Iterator over supplied data for rebalancing."}
{"index": 645, "repo": "ignite-core-2.15.0", "code": "Interface IgniteReducer<E,R> {\n\t// Collects given value.\n\tboolean collect(E e);\n\t// Reduces collected values into one.\n\tR reduce();\n}", "des": "Defines generic reducer that collects multiple values and reduces them into one. Reducers are useful in computations when results from multiple remote jobs need to be reduced into one, e.g. IgniteCompute.call(Collection, IgniteReducer) method."}
{"index": 646, "repo": "ignite-core-2.15.0", "code": "Class IgniteReducer2X<E1,E2,R> {\n\t// Closure body.\n\tR apply();\n\t// Reducer body that can throw IgniteCheckedException.\n\tabstract R applyx();\n}", "des": "Convenient reducer subclass that allows for thrown grid exception. This class implements apply() method that calls applyx() method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 647, "repo": "ignite-core-2.15.0", "code": "Class IgniteReducer3X<E1,E2,E3,R> {\n\t// Closure body.\n\tR apply();\n\t// Reducer body that can throw IgniteCheckedException.\n\tabstract R applyx();\n}", "des": "Convenient reducer subclass that allows for thrown grid exception. This class implements apply() method that calls applyx() method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 648, "repo": "ignite-core-2.15.0", "code": "Class IgniteReducerX<E1,R> {\n\t// Reducer body that can throw IgniteCheckedException.\n\tabstract R applyx();\n\t// Reduces collected values into one.\n\tR reduce();\n}", "des": "Convenient reducer subclass that allows for thrown grid exception. This class implements reduce() method that calls applyx() method and properly wraps IgniteCheckedException into GridClosureException instance."}
{"index": 649, "repo": "ignite-core-2.15.0", "code": "Class IgniteReflectionFactory<T> {\n\tT create();\n\tClass<? extends T> getComponentClass();\n\t// Gets a map of properties.\n\tMap<String,Serializable> getProperties();\n\tboolean isSingleton();\n\tvoid setComponentClass(Class<T> cls);\n\t// Sets a map of properties.\n\tvoid setProperties(Map<String,Serializable> props);\n\tvoid setSingleton(boolean singleton);\n}", "des": "Factory implementation that use reflection to create instance of given class."}
{"index": 650, "repo": "ignite-core-2.15.0", "code": "Class IgniteRemoteMapTask<T,R> {\n\t// This method is called to map or split grid task into multiple grid jobs.\n\t@NotNull Map<? extends ComputeJob,ClusterNode> map(List<ClusterNode> subgrid, T arg);\n\t// Reduces (or aggregates) results received so far into one compound result to be returned to caller via ComputeTaskFuture.get() method.\n\tR reduce(List<ComputeJobResult> results);\n}", "des": "Util task that will execute ComputeTask on a given node."}
{"index": 651, "repo": "ignite-core-2.15.0", "code": "Interface IgniteSpiManagementMBean {\n\t// Gets Ignite installation home folder (i.e.\n\tString getIgniteHome();\n\t// Gets ID of the local node.\n\tUUID getLocalNodeId();\n\t// Gets name of the SPI.\n\tString getName();\n\t// Get start timestamp of this SPI.\n\tlong getStartTimestamp();\n\t// Gets string presentation of the start timestamp.\n\tString getStartTimestampFormatted();\n\t// Gets up-time of this SPI in ms.\n\tlong getUpTime();\n\t// Gets string presentation of up-time for this SPI.\n\tString getUpTimeFormatted();\n}", "des": "This interface defines basic MBean for all SPI implementations. Every SPI implementation should provide implementation for this MBean interface. Note that SPI implementation can extend this interface as necessary."}
{"index": 652, "repo": "ignite-core-2.15.0", "code": "Class IgniteSpiMBeanAdapter {\n\t// Gets Ignite installation home folder (i.e.\n\tString getIgniteHome();\n\t// Gets ID of the local node.\n\tUUID getLocalNodeId();\n\t// Gets name of the SPI.\n\tString getName();\n\t// Get start timestamp of this SPI.\n\tlong getStartTimestamp();\n\t// Gets string presentation of the start timestamp.\n\tString getStartTimestampFormatted();\n\t// Gets up-time of this SPI in ms.\n\tlong getUpTime();\n\t// Gets string presentation of up-time for this SPI.\n\tString getUpTimeFormatted();\n}", "des": "This class provides convenient adapter for MBean implementations."}
{"index": 653, "repo": "ignite-core-2.15.0", "code": "Class IgniteSpiMultiException {\n\t// Adds a new cause for multi-exception.\n\tvoid add(Throwable cause);\n\t// Gets nested causes for this multi-exception.\n\tList<Throwable> nestedCauses();\n\tvoid printStackTrace(PrintStream s);\n}", "des": "Grid SPI exception which may contain more than one failure."}
{"index": 654, "repo": "ignite-core-2.15.0", "code": "Class IgniteSpiOperationTimeoutHelper {\n\t// Checks whether the given Exception is a timeout.\n\tboolean checkFailureTimeoutReached(Exception e);\n\t// Returns a timeout value to use for the next network operation.\n\tlong nextTimeoutChunk(long dfltTimeout);\n}", "des": "Object that incorporates logic that determines a timeout value for the next network related operation and checks whether a failure detection timeout is reached or not. A new instance of the class should be created for every complex network based operations that usually consists of request and response parts."}
{"index": 655, "repo": "ignite-core-2.15.0", "code": "Class IgniteSpiThread {\n\t// Body of SPI thread.\n\tprotected abstract void body();\n\t// Should be overridden by child classes if cleanup logic is required.\n\tprotected void cleanup();\n\tvoid run();\n}", "des": "This class provides convenient adapter for threads used by SPIs. This class adds necessary plumbing on top of the IgniteThread class: Proper exception handling in body()"}
{"index": 656, "repo": "ignite-core-2.15.0", "code": "Enum IgniteState {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable IgniteState fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IgniteState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IgniteState[] values();\n}", "des": "Possible states of Ignition. You can register a listener for state change notifications via Ignition.addListener(IgnitionListener) method."}
{"index": 657, "repo": "ignite-core-2.15.0", "code": "Class IgniteTicker {\n\t// Returns the number of nanoseconds elapsed since this ticker's fixed point of reference.\n\tabstract long read();\n\t// A ticker that reads the current time using System.nanoTime().\n\tstatic IgniteTicker systemTicker();\n}", "des": "A time source; returns a time value representing the number of nanoseconds elapsed since some fixed but arbitrary point in time. Note that most users should use IgniteStopwatch instead of interacting with this class directly."}
{"index": 658, "repo": "ignite-core-2.15.0", "code": "Interface IgniteTxLocalEx {\n\t@Nullable Throwable commitError();\n\t// Finishes transaction (either commit or rollback).\n\tboolean localFinish(boolean commit, boolean clearThreadMap);\n\tGridCacheVersion minVersion();\n\t// Remembers that particular cache partition was touched by current tx.\n\tvoid touchPartition(int cacheId, int partId);\n\tvoid userCommit();\n\tvoid userRollback(boolean clearThreadMap);\n}", "des": "Local transaction API."}
{"index": 659, "repo": "ignite-core-2.15.0", "code": "Interface IgnitionMXBean {\n\t// Gets state of default grid instance.\n\tString getState();\n\t// Gets state for a given grid instance.\n\tString getState(String name);\n\t// Restart JVM.\n\tvoid restart(boolean cancel);\n\t// Stops default grid instance.\n\tboolean stop(boolean cancel);\n\t// Stops named Ignite instance.\n\tboolean stop(String name, boolean cancel);\n\t// Stops all started grids.\n\tvoid stopAll(boolean cancel);\n}", "des": "This interface defines JMX view on Ignition."}
{"index": 660, "repo": "ignite-core-2.15.0", "code": "Class IgnitionMXBeanAdapter {\n\t// Gets state of default grid instance.\n\tString getState();\n\t// Gets state for a given grid instance.\n\tString getState(String name);\n\t// Restart JVM.\n\tvoid restart(boolean cancel);\n\t// Stops default grid instance.\n\tboolean stop(boolean cancel);\n\t// Stops named Ignite instance.\n\tboolean stop(String name, boolean cancel);\n\t// Stops all started grids.\n\tvoid stopAll(boolean cancel);\n}", "des": "Management bean that provides access to Ignition."}
{"index": 661, "repo": "ignite-core-2.15.0", "code": "Enum IndexBuildStatusHolder.Status {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IndexBuildStatusHolder.Status valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IndexBuildStatusHolder.Status[] values();\n}", "des": "Enumeration of statuses."}
{"index": 662, "repo": "ignite-core-2.15.0", "code": "Class IndexDescriptor {\n\t// Index handler.\n\tIndex index();\n\tint inlineSize();\n\tboolean isAffinity();\n\tboolean isPk();\n\tboolean isProxy();\n\tLinkedHashMap<String,IndexKeyDefinition> keyDefinitions();\n\tString name();\n\t// Table descriptor.\n\tTableDescriptor table();\n\t// Target index descriptor for proxy index.\n\tIndexDescriptor targetIdx();\n\tQueryIndexType type();\n}", "des": "Local database index object."}
{"index": 663, "repo": "ignite-core-2.15.0", "code": "Class IndexesRebuildTask {\n\t// Start to rebuild.\n\t@Nullable IgniteInternalFuture<?> rebuild(GridCacheContext<?,?> cctx, boolean force, IndexRebuildCancelToken cancelTok);\n\t// Actual start rebuilding.\n\tprotected void startRebuild(GridCacheContext cctx, GridFutureAdapter<Void> fut, SchemaIndexCacheVisitorClosure clo, IndexRebuildCancelToken cancelTok);\n\t// Stop rebuilding indexes.\n\tvoid stopRebuild(GridCacheContextInfo cacheInfo, IgniteLogger log);\n}", "des": "Task that rebuilds indexes."}
{"index": 664, "repo": "ignite-core-2.15.0", "code": "Class IndexForceRebuildTaskArg {\n\tSet<String> cacheGrps();\n\tSet<String> cacheNames();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for IndexForceRebuildTask."}
{"index": 665, "repo": "ignite-core-2.15.0", "code": "Class IndexForceRebuildTaskRes {\n\tSet<IndexRebuildStatusInfoContainer> cachesWithRebuildInProgress();\n\tSet<IndexRebuildStatusInfoContainer> cachesWithStartedRebuild();\n\tSet<String> notFoundCacheNames();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of IndexForceRebuildTask."}
{"index": 666, "repo": "ignite-core-2.15.0", "code": "Class IndexingQueryCacheFilter {\n\t// Apply filter.\n\tboolean apply(Object key);\n\t// Apply filter.\n\tboolean applyPartition(int part);\n}", "des": "Indexing query filter for specific cache."}
{"index": 667, "repo": "ignite-core-2.15.0", "code": "Interface IndexingSpi {\n\t// Executes query.\n\tIterator<javax.cache.Cache.Entry<?,?>> query(@Nullable String cacheName, Collection<Object> params, @Nullable IndexingQueryFilter filters);\n\t// Removes index entry by key.\n\tvoid remove(@Nullable String cacheName, Object key);\n\t// Updates index.\n\tvoid store(@Nullable String cacheName, Object key, Object val, long expirationTime);\n}", "des": "Indexing SPI allows user to index cache content. Using indexing SPI user can index data in cache and run queries."}
{"index": 668, "repo": "ignite-core-2.15.0", "code": "Class IndexKeyFactory {\n\t// Register wrapper for custom IndexKey type.\n\tstatic void register(IndexKeyType keyType, Function<Object,IndexKey> wrapper);\n\t// Wraps user object to IndexKey object.\n\tstatic IndexKey wrap(Object o, IndexKeyType keyType, CacheObjectValueContext coctx, IndexKeyTypeSettings keyTypeSettings);\n\t// Wraps user object to IndexKey object.\n\tstatic IndexKey wrap(Object o, int keyType, CacheObjectValueContext coctx, IndexKeyTypeSettings keyTypeSettings);\n}", "des": "Factory for creating IndexKey objects."}
{"index": 669, "repo": "ignite-core-2.15.0", "code": "Enum IndexKeyType {\n\tint code();\n\t// Find type by class.\n\tstatic IndexKeyType forClass(Class<?> cls);\n\t// Find type by code.\n\tstatic IndexKeyType forCode(int code);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IndexKeyType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IndexKeyType[] values();\n}", "des": "List of available types to use as index key."}
{"index": 670, "repo": "ignite-core-2.15.0", "code": "Class IndexListInfoContainer {\n\tString cacheName();\n\tstatic Comparator<IndexListInfoContainer> comparator();\n\tboolean equals(Object o);\n\tString groupName();\n\tString indexName();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tString tableName();\n\tvoid tableName(String tblName);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Container for index info."}
{"index": 671, "repo": "ignite-core-2.15.0", "code": "Class IndexListTaskArg {\n\tString cachesRegEx();\n\tString groupsRegEx();\n\tString indexesRegEx();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument object for CacheIndexListTask"}
{"index": 672, "repo": "ignite-core-2.15.0", "code": "Enum IndexPageType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IndexPageType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IndexPageType[] values();\n}", "des": "Enumeration of types of b-tree index pages."}
{"index": 673, "repo": "ignite-core-2.15.0", "code": "Class IndexQueryReducer<R> {\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tR nextX();\n\tprotected CompletableFuture<Comparator<NodePage<R>>> pageComparator();\n}", "des": "Reducer for IndexQuery results."}
{"index": 674, "repo": "ignite-core-2.15.0", "code": "Class IndexRebuildCacheInfo {\n\t// Getting cache name.\n\tString cacheName();\n\tbyte getProtocolVersion();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tboolean recreate();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Information about the cache for which index rebuilding was started. Designed for MetaStorage."}
{"index": 675, "repo": "ignite-core-2.15.0", "code": "Class IndexRebuildStatusInfoContainer {\n\tString cacheName();\n\tstatic Comparator<IndexRebuildStatusInfoContainer> comparator();\n\tboolean equals(Object o);\n\tString groupName();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Container for index rebuild status info."}
{"index": 676, "repo": "ignite-core-2.15.0", "code": "Class IndexRebuildStatusTaskArg {\n\tUUID nodeId();\n\tvoid nodeId(UUID nodeId);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for IndexRebuildStatusTask."}
{"index": 677, "repo": "ignite-core-2.15.0", "code": "Class IndexRenameRootPageRecord {\n\t// Getting cache id.\n\tint cacheId();\n\t// Calculating the size of the data.\n\tint dataSize();\n\t// Getting new name of underlying index tree name.\n\tString newTreeName();\n\t// Getting old name of underlying index tree name.\n\tString oldTreeName();\n\t// Getting number of segments.\n\tint segments();\n\tWALRecord.RecordType type();\n\t// Writing data to the buffer.\n\tvoid writeRecord(ByteBuffer buf);\n}", "des": "Logical record for renaming index root pages."}
{"index": 678, "repo": "ignite-core-2.15.0", "code": "Class IndexRowCache {\n\t// Get row by link.\n\tIndexRowImpl get(long link);\n\t// Cache registration callback.\n\tvoid onCacheRegistered();\n\t// Cache un-registration callback.\n\tboolean onCacheUnregistered(GridCacheContextInfo cacheInfo);\n\t// Put row by link.\n\tvoid put(IndexRowImpl row);\n\t// Remove row by link.\n\tvoid remove(long link);\n\tint size();\n}", "des": "H2 row cache."}
{"index": 679, "repo": "ignite-core-2.15.0", "code": "Class IndexRowCacheRegistry {\n\t// Get row cache for the given cache group.\n\t@Nullable IndexRowCache forGroup(int grpId);\n\t// Callback invoked on cache registration within indexing.\n\tvoid onCacheRegistered(GridCacheContextInfo cacheInfo);\n\t// Callback invoked when cache gets unregistered.\n\tvoid onCacheUnregistered(GridCacheContextInfo cacheInfo);\n}", "des": "Index row cache registry."}
{"index": 680, "repo": "ignite-core-2.15.0", "code": "Interface IndexRowComparator {\n\t// Compare index keys.\n\tint compareKey(IndexKey left, IndexKey right);\n\t// Compare inlined index key with specified key.\n\tint compareKey(long pageAddr, int off, int maxSize, IndexKey key, InlineIndexKeyType type);\n\t// Compare index rows by key specified with idx.\n\tint compareRow(IndexRow left, IndexRow right, int idx);\n}", "des": "Comparator for index rows."}
{"index": 681, "repo": "ignite-core-2.15.0", "code": "Class IndexRowComparatorImpl {\n\t// Compare index keys.\n\tint compareKey(IndexKey left, IndexKey right);\n\t// Compare inlined index key with specified key.\n\tint compareKey(long pageAddr, int off, int maxSize, IndexKey key, InlineIndexKeyType type);\n\t// Compare index rows by key specified with idx.\n\tint compareRow(IndexRow left, IndexRow right, int idx);\n}", "des": "Provide default logic of rows comparison. Consider: 1. NULL is the least value. 2. Comparison of different types is not supported."}
{"index": 682, "repo": "ignite-core-2.15.0", "code": "Class IndexValueCursor<V> {\n\t// Gets element at current position.\n\tV get();\n\t// Attempt to move cursor position forward.\n\tboolean next();\n}", "des": "Cursor over index values."}
{"index": 683, "repo": "ignite-core-2.15.0", "code": "Class InitMessage<I extends Serializable> {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\tDiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n\tUUID processId();\n\tI request();\n\tint type();\n\tboolean waitClientResults();\n}", "des": "Initiate message."}
{"index": 684, "repo": "ignite-core-2.15.0", "code": "Class InlineIndexKeyTypeRegistry {\n\t// Get key type for specified key.\n\tstatic InlineIndexKeyType get(IndexKey key, IndexKeyType expType, IndexKeyTypeSettings keyTypeSettings);\n\t// Get key type for a class.\n\tstatic InlineIndexKeyType get(IndexKeyType expType, IndexKeyTypeSettings keyTypeSettings);\n\t// Return list of key types for specified key definitions and key type settings.\n\tstatic List<InlineIndexKeyType> types(Collection<IndexKeyDefinition> keyDefs, IndexKeyTypeSettings settings);\n}", "des": "Provide mapping for java types and IndexKeyType that supports inlining."}
{"index": 685, "repo": "ignite-core-2.15.0", "code": "Class InlineObjectBytesDetector {\n\t// Performs inspection or operation on a specified row and returns true if this row is required or matches or /operation successful (depending on the context).\n\tboolean apply(BPlusTree<IndexRow,IndexRow> tree, BPlusIO<IndexRow> io, long pageAddr, int idx);\n\tboolean inlineObjectSupported();\n\t// Static analyze inline_size and inline columns set.\n\tstatic boolean objectMayBeInlined(int inlineSize, Collection<IndexKeyDefinition> keyDefs);\n}", "des": "This class helps to detect whether tree contains inlined JO type. When starting on old Ignite versions it's impossible to discover whether JO type was inlined or not. Then try to find that with 2 steps: 1. analyze of inline size; 2. traverse tree and check stored values."}
{"index": 686, "repo": "ignite-core-2.15.0", "code": "Class IntegerInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected IntegerIndexKey get0(long pageAddr, int off);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, IntegerIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining Integer values."}
{"index": 687, "repo": "ignite-core-2.15.0", "code": "Class IntMetricImpl {\n\t// Adds x to the metric.\n\tvoid add(int x);\n\t// Adds 1 to the metric.\n\tvoid increment();\n\t// Resets metric state.\n\tvoid reset();\n\tint value();\n\t// Sets value.\n\tvoid value(int val);\n}", "des": "Int metric implementation."}
{"index": 688, "repo": "ignite-core-2.15.0", "code": "Class IntSumReducer {\n\t// Collects given value.\n\tboolean collect(Integer e);\n\t// Reduces collected values into one.\n\tInteger reduce();\n}", "des": "Reducer that calculates sum of integer elements."}
{"index": 689, "repo": "ignite-core-2.15.0", "code": "Interface IoPool {\n\t// Gets the Executor for this Pool.\n\tExecutor executor();\n\t// Gets the numeric identifier of the pool.\n\tbyte id();\n}", "des": "The interface of IO Messaging Pool Extension."}
{"index": 690, "repo": "ignite-core-2.15.0", "code": "Interface IoStatisticsHolder {\n\tlong logicalReads();\n\tString metricRegistryName();\n\tlong physicalReads();\n\t// Track logical read of given page.\n\tvoid trackLogicalRead(long pageAddr);\n\t// Track physical and logical read of given page.\n\tvoid trackPhysicalAndLogicalRead(long pageAddr);\n}", "des": "Holder of IO statistics."}
{"index": 691, "repo": "ignite-core-2.15.0", "code": "Class IoStatisticsHolderCache {\n\tint cacheGroupId();\n\tlong logicalReads();\n\tString metricRegistryName();\n\tlong physicalReads();\n\t// Track logical read of given page.\n\tvoid trackLogicalRead(long pageAddr);\n\t// Track physical and logical read of given page.\n\tvoid trackPhysicalAndLogicalRead(long pageAddr);\n}", "des": "Cache statistics holder to gather statistics related to concrete cache."}
{"index": 692, "repo": "ignite-core-2.15.0", "code": "Class IoStatisticsHolderIndex {\n\tlong logicalReads();\n\tString metricRegistryName();\n\tlong physicalReads();\n\t// Track logical read of given page.\n\tvoid trackLogicalRead(long pageAddr);\n\t// Track physical and logical read of given page.\n\tvoid trackPhysicalAndLogicalRead(long pageAddr);\n}", "des": "Index statistics holder to gather statistics related to concrete index."}
{"index": 693, "repo": "ignite-core-2.15.0", "code": "Class IoStatisticsHolderNoOp {\n\tlong logicalReads();\n\tString metricRegistryName();\n\tlong physicalReads();\n\t// Track logical read of given page.\n\tvoid trackLogicalRead(long pageAddr);\n\t// Track physical and logical read of given page.\n\tvoid trackPhysicalAndLogicalRead(long pageAddr);\n}", "des": "No Operation IO statistics holder. Use in case statistics shouldn't be gathered."}
{"index": 694, "repo": "ignite-core-2.15.0", "code": "Class IoStatisticsHolderQuery {\n\tlong logicalReads();\n\t// Add given given statistics into this.\n\tvoid merge(long logicalReads, long physicalReads);\n\tString metricRegistryName();\n\tlong physicalReads();\n\t// Track logical read of given page.\n\tvoid trackLogicalRead(long pageAddr);\n\t// Track physical and logical read of given page.\n\tvoid trackPhysicalAndLogicalRead(long pageAddr);\n}", "des": "Query Statistics holder to gather statistics related to concrete query. Used in org.apache.ignite.internal.stat.IoStatisticsHolderIndex and org.apache.ignite.internal.stat.IoStatisticsHolderCache. Query Statistics holder to gather statistics related to concrete query. Used in org.apache.ignite.internal.stat.IoStatisticsHolderIndex and org.apache.ignite.internal.stat.IoStatisticsHolderCache."}
{"index": 695, "repo": "ignite-core-2.15.0", "code": "Class IoStatisticsQueryHelper {\n\t// Finish gathering IO statistics for query.\n\tstatic IoStatisticsHolder finishGatheringQueryStatistics();\n\t// Merge query statistics.\n\tstatic void mergeQueryStatistics(IoStatisticsHolderQuery qryStat);\n\t// Start gathering IO statistics for query.\n\tstatic void startGatheringQueryStatistics();\n}", "des": "Helper for gathering IO statistics."}
{"index": 696, "repo": "ignite-core-2.15.0", "code": "Enum IoStatisticsType {\n\tString metricGroupName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IoStatisticsType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IoStatisticsType[] values();\n}", "des": "Type of statistics."}
{"index": 697, "repo": "ignite-core-2.15.0", "code": "Class IpcClientTcpEndpoint {\n\t// Closes endpoint.\n\tvoid close();\n\t// Gets input stream associated with this IPC endpoint.\n\tInputStream inputStream();\n\t// Gets output stream associated with this IPC endpoint.\n\tOutputStream outputStream();\n\t// Returns socket timeout.\n\tint timeout();\n\t// Enable/disable socket timeout with specified timeout.\n\tvoid timeout(int ms);\n}", "des": "Loopback IPC endpoint based on socket."}
{"index": 698, "repo": "ignite-core-2.15.0", "code": "Interface IpcEndpoint {\n\t// Closes endpoint.\n\tvoid close();\n\t// Gets input stream associated with this IPC endpoint.\n\tInputStream inputStream();\n\t// Gets output stream associated with this IPC endpoint.\n\tOutputStream outputStream();\n}", "des": "IPC endpoint used for point-to-point communication."}
{"index": 699, "repo": "ignite-core-2.15.0", "code": "Enum IpcEndpointType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IpcEndpointType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IpcEndpointType[] values();\n}", "des": "IPC endpoint type."}
{"index": 700, "repo": "ignite-core-2.15.0", "code": "Interface IpcServerEndpoint {\n\t// Accepts client IPC connection.\n\tIpcEndpoint accept();\n\t// Closes server IPC.\n\tvoid close();\n\t// Gets host endpoint is bound to.\n\t@Nullable String getHost();\n\t// Gets port endpoint is bound to.\n\tint getPort();\n\t// Indicates if this endpoint is a management endpoint.\n\tboolean isManagement();\n\t// Starts configured endpoint implementation.\n\tvoid start();\n}", "des": "IPC server endpoint that is capable for client connections accepting."}
{"index": 701, "repo": "ignite-core-2.15.0", "code": "Interface IWordSerializer {\n\t// Returns the backing array of bytes that contain the serialized words.\n\tbyte[] getBytes();\n\t// Writes the word to the backing array.\n\tvoid writeWord(long word);\n}", "des": "Writes 'words' of fixed width, in sequence, to a byte array."}
{"index": 702, "repo": "ignite-core-2.15.0", "code": "Class JavaLoggerFileHandler {\n\tvoid close();\n\t// Returns current log file.\n\t@Nullable String fileName();\n\tvoid flush();\n\tboolean isLoggable(LogRecord record);\n\t// Resolves logging directory.\n\tstatic File logDirectory(String workDir);\n\t// Sets Node id and instantiates FileHandler delegate.\n\tvoid nodeId(@Nullable String app, @Nullable UUID nodeId, String workDir);\n\t// Sets Node id and instantiates FileHandler delegate.\n\tvoid nodeId(UUID nodeId, String workDir);\n\tvoid publish(LogRecord record);\n}", "des": "File logging handler which skips all the messages until node ID is set."}
{"index": 703, "repo": "ignite-core-2.15.0", "code": "Class JdbcBatchExecuteRequest {\n\tboolean isLastStreamBatch();\n\tList<JdbcQuery> queries();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t@Nullable String schemaName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC batch execute request."}
{"index": 704, "repo": "ignite-core-2.15.0", "code": "Class JdbcBatchExecuteResult {\n\tint errorCode();\n\tString errorMessage();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tint[] updateCounts();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC batch execute result."}
{"index": 705, "repo": "ignite-core-2.15.0", "code": "Class JdbcBinaryTypeGetRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tint typeId();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC get binary type metadata request."}
{"index": 706, "repo": "ignite-core-2.15.0", "code": "Class JdbcBinaryTypeGetResult {\n\t// Returns metadata of binary type.\n\tBinaryMetadata meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Returns ID of initial request.\n\tlong reqId();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC get binary type metadata result."}
{"index": 707, "repo": "ignite-core-2.15.0", "code": "Class JdbcBinaryTypeNameGetRequest {\n\t// Returns ID of platform.\n\tbyte platformId();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Returns ID of binary type.\n\tint typeId();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC get binary type name request."}
{"index": 708, "repo": "ignite-core-2.15.0", "code": "Class JdbcBinaryTypeNameGetResult {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Returns ID of initial request.\n\tlong reqId();\n\t// Returns name of the binary type.\n\tString typeName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC get binary type name result."}
{"index": 709, "repo": "ignite-core-2.15.0", "code": "Class JdbcBinaryTypeNamePutRequest {\n\t// Returns ID of platform.\n\tbyte platformId();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Returns ID of binary type.\n\tint typeId();\n\t// Returns type name.\n\tString typeName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC put binary type name request."}
{"index": 710, "repo": "ignite-core-2.15.0", "code": "Class JdbcBinaryTypePutRequest {\n\t// Returns metadata of binary type.\n\tBinaryMetadata meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC put binary type metadata request."}
{"index": 711, "repo": "ignite-core-2.15.0", "code": "Class JdbcBulkLoadAckResult {\n\t// Returns the cursor ID.\n\tlong cursorId();\n\t// Returns the parameters for the client.\n\tBulkLoadAckClientParameters params();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "A reply from server to SQL COPY command, which is essentially a request from server to client to send files from client to server (see IGNITE-6917 for details)."}
{"index": 712, "repo": "ignite-core-2.15.0", "code": "Class JdbcBulkLoadBatchRequest {\n\t// Returns the batch index.\n\tlong batchIdx();\n\t// Returns the command (see CMD_xxx constants for details).\n\tint cmd();\n\t// Returns the original cursor ID.\n\tlong cursorId();\n\t// Returns the data.\n\t@NotNull byte[] data();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "A JDBC request that sends a batch of a file to the server. Used when handling SqlBulkLoadCommand command."}
{"index": 713, "repo": "ignite-core-2.15.0", "code": "Class JdbcBulkLoadProcessor {\n\t// Closes the underlying objects.\n\tvoid close();\n\t// Gets notified if current bulk load failed.\n\tvoid onFail(Exception reason);\n\t// Completely processes a bulk load batch request.\n\tvoid processBatch(JdbcBulkLoadBatchRequest req);\n\t// Provides update counter for sending in the JdbcBatchExecuteResult.\n\tlong updateCnt();\n}", "des": "JDBC wrapper around BulkLoadProcessor that provides extra logic. Unlike other \"single shot\" request-reply commands, the COPY command the client-server interaction looks like this:"}
{"index": 714, "repo": "ignite-core-2.15.0", "code": "Class JdbcCachePartitionsRequest {\n\tSet<Integer> cacheIds();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "Jdbc thin request for partiton distribution."}
{"index": 715, "repo": "ignite-core-2.15.0", "code": "Class JdbcCachePartitionsResult {\n\tList<JdbcThinPartitionAwarenessMappingGroup> getMappings();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "Jdbc thin partiton result that contains partition mappings."}
{"index": 716, "repo": "ignite-core-2.15.0", "code": "Class JdbcColumnMetaV2 {\n\t// Return 'nullable' flag in compatibility mode (according with column name and column type).\n\tboolean isNullable();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC column metadata."}
{"index": 717, "repo": "ignite-core-2.15.0", "code": "Class JdbcColumnMetaV3 {\n\tString defaultValue();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC column metadata V3."}
{"index": 718, "repo": "ignite-core-2.15.0", "code": "Class JdbcColumnMetaV4 {\n\tint precision();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tint scale();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC column metadata V4."}
{"index": 719, "repo": "ignite-core-2.15.0", "code": "Class JdbcIndexMeta {\n\tboolean equals(Object o);\n\tList<String> fields();\n\tList<Boolean> fieldsAsc();\n\tString indexName();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tString schemaName();\n\tString tableName();\n\tQueryIndexType type();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC index metadata."}
{"index": 720, "repo": "ignite-core-2.15.0", "code": "Class JdbcMessageParser {\n\tprotected BinaryReaderExImpl createReader(ClientMessage msg);\n\tprotected BinaryWriterExImpl createWriter(int cap);\n\t// Decode request from byte array.\n\tClientListenerRequest decode(ClientMessage msg);\n\t// Decode command type.\n\tint decodeCommandType(ClientMessage msg);\n\t// Decode request Id.\n\tlong decodeRequestId(ClientMessage msg);\n\t// Encode response to byte array.\n\tClientMessage encode(ClientListenerResponse msg);\n}", "des": "JDBC message parser."}
{"index": 721, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaColumnsRequest {\n\tString columnName();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t@Nullable String schemaName();\n\tString tableName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC get columns metadata request."}
{"index": 722, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaColumnsResult {\n\tprotected JdbcColumnMeta createMetaColumn();\n\tList<JdbcColumnMeta> meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC columns metadata result."}
{"index": 723, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaIndexesRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t@Nullable String schemaName();\n\tString tableName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC indexes metadata request."}
{"index": 724, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaIndexesResult {\n\tList<JdbcIndexMeta> meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC indexes metadata result."}
{"index": 725, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaParamsRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tString schemaName();\n\tString sql();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC SQL query parameters metadata request."}
{"index": 726, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaParamsResult {\n\tList<JdbcParameterMeta> meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC SQL query parameters metadata result."}
{"index": 727, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaPrimaryKeysRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t@Nullable String schemaName();\n\tString tableName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC get primary keys metadata request."}
{"index": 728, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaPrimaryKeysResult {\n\tList<JdbcPrimaryKeyMeta> meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC primary keys metadata result."}
{"index": 729, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaSchemasRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tString schemaName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC tables metadata request."}
{"index": 730, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaSchemasResult {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tCollection<String> schemas();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC tables metadata result."}
{"index": 731, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaTablesRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tString schemaName();\n\tString tableName();\n\tString[] tableTypes();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC tables metadata request."}
{"index": 732, "repo": "ignite-core-2.15.0", "code": "Class JdbcMetaTablesResult {\n\tList<JdbcTableMeta> meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC tables metadata result."}
{"index": 733, "repo": "ignite-core-2.15.0", "code": "Class JdbcOrderedBatchExecuteRequest {\n\tint compareTo(@NotNull JdbcOrderedBatchExecuteRequest o);\n\tlong order();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC batch execute ordered request."}
{"index": 734, "repo": "ignite-core-2.15.0", "code": "Class JdbcOrderedBatchExecuteResult {\n\tlong order();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC batch execute ordered result."}
{"index": 735, "repo": "ignite-core-2.15.0", "code": "Class JdbcParameterMeta {\n\tint isNullable();\n\tboolean isSigned();\n\tint mode();\n\tint precision();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tint scale();\n\tint type();\n\tString typeClass();\n\tString typeName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC SQL query parameter metadata."}
{"index": 736, "repo": "ignite-core-2.15.0", "code": "Class JdbcPrimaryKeyMeta {\n\tboolean equals(Object o);\n\tList<String> fields();\n\tString name();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tString schemaName();\n\tString tableName();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC primary key metadata."}
{"index": 737, "repo": "ignite-core-2.15.0", "code": "Class JdbcQuery {\n\tObject[] args();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tString sql();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC SQL query with parameters."}
{"index": 738, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryCancelRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tlong requestIdToBeCancelled();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query cancel request."}
{"index": 739, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryCloseRequest {\n\tlong cursorId();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query close request."}
{"index": 740, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryDescriptor {\n\tGridQueryCancel cancelHook();\n\t// Descrements usage count.\n\tvoid decrementUsageCount();\n\t// Increments usage count.\n\tvoid incrementUsageCount();\n\tboolean isCanceled();\n\tboolean isExecutionStarted();\n\t// Marks descriptor as canceled.\n\tvoid markCancelled();\n\tint usageCount();\n}", "des": "JDBC query descriptor used for appropriate query cancellation."}
{"index": 741, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryExecuteMultipleStatementsResult {\n\tboolean isLast();\n\tList<List<Object>> items();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tList<JdbcResultInfo> results();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query execute result for query with multiple SQL statements."}
{"index": 742, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryExecuteResult {\n\tlong cursorId();\n\tboolean isQuery();\n\tList<List<Object>> items();\n\tboolean last();\n\tPartitionResult partitionResult();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tlong updateCount();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query execute result."}
{"index": 743, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryFetchRequest {\n\tlong cursorId();\n\tint pageSize();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query fetch request."}
{"index": 744, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryFetchResult {\n\tList<List<Object>> items();\n\tboolean last();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query fetch result."}
{"index": 745, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryMetadataRequest {\n\tlong cursorId();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query metadata request."}
{"index": 746, "repo": "ignite-core-2.15.0", "code": "Class JdbcQueryMetadataResult {\n\tList<JdbcColumnMeta> meta();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC query metadata result."}
{"index": 747, "repo": "ignite-core-2.15.0", "code": "Interface JdbcRawBinarylizable {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "Interface that allows to implement custom serialization logic to raw binary streams."}
{"index": 748, "repo": "ignite-core-2.15.0", "code": "Class JdbcRequest {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tstatic JdbcRequest readRequest(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Reads JdbcRequest Id.\n\tstatic long readRequestId(byte[] msg);\n\t// Reads JdbcRequest command type.\n\tstatic byte readType(byte[] msg);\n\tlong requestId();\n\tbyte type();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC request."}
{"index": 749, "repo": "ignite-core-2.15.0", "code": "Class JdbcResponse {\n\tboolean activeTransaction();\n\tvoid activeTransaction(boolean activeTx);\n\tAffinityTopologyVersion affinityVersion();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tJdbcResult response();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "SQL listener response."}
{"index": 750, "repo": "ignite-core-2.15.0", "code": "Class JdbcResult {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tstatic JdbcResult readResult(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC response result."}
{"index": 751, "repo": "ignite-core-2.15.0", "code": "Class JdbcResultInfo {\n\tlong cursorId();\n\tboolean isQuery();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tlong updateCount();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC statement result information. Keeps statement type (SELECT or UPDATE) and queryId or update count (depends on statement type)."}
{"index": 752, "repo": "ignite-core-2.15.0", "code": "Enum JdbcStatementType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic JdbcStatementType fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JdbcStatementType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JdbcStatementType[] values();\n}", "des": "JDBC statement type."}
{"index": 753, "repo": "ignite-core-2.15.0", "code": "Class JdbcTableMeta {\n\tboolean equals(Object o);\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\tString schemaName();\n\tString tableName();\n\tString tableType();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC table metadata."}
{"index": 754, "repo": "ignite-core-2.15.0", "code": "Enum JdbcThinFeature {\n\tstatic EnumSet<JdbcThinFeature> allFeaturesAsEnumSet();\n\tstatic EnumSet<JdbcThinFeature> enumSet(byte[] bytes);\n\tint featureId();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JdbcThinFeature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JdbcThinFeature[] values();\n}", "des": "Defines supported features for JDBC thin client."}
{"index": 755, "repo": "ignite-core-2.15.0", "code": "Class JdbcThinTcpIo {\n\t// Close the client IO.\n\tvoid close();\n\tboolean connected();\n\tConnectionProperties connectionProperties();\n\tUUID nodeId();\n\tInetSocketAddress socketAddress();\n\t// Returns socket timeout.\n\tint timeout();\n\t// Enable/disable socket timeout with specified timeout.\n\tvoid timeout(int ms);\n}", "des": "JDBC IO layer implementation based on blocking IPC streams."}
{"index": 756, "repo": "ignite-core-2.15.0", "code": "Class JdbcUpdateBinarySchemaResult {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader, JdbcProtocolContext protoCtx);\n\t// Returns ID of initial operation.\n\tlong reqId();\n\t// Returns status of updating.\n\tboolean success();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer, JdbcProtocolContext protoCtx);\n}", "des": "JDBC update binary schema result."}
{"index": 757, "repo": "ignite-core-2.15.0", "code": "Class JmxMetricExporterSpi {\n\t// Sets export filter.\n\tvoid setExportFilter(Predicate<ReadOnlyMetricRegistry> filter);\n\t// Sets metrics registry that SPI should export.\n\tvoid setMetricRegistry(ReadOnlyMetricManager reg);\n\t// This method is called to start SPI.\n\tvoid spiStart(@Nullable String igniteInstanceName);\n\t// This method is called to stop SPI.\n\tvoid spiStop();\n}", "des": "Overview Ignite provides this default built-in implementation of MetricExporterSpi it exports metrics as JMX beans. This implementation works by `pull` architecture which means that after the Ignite node start it should respond to incoming user request. Java Example See the example below of how the internal metrics can be obtained through your application by constructing MBean names."}
{"index": 758, "repo": "ignite-core-2.15.0", "code": "Class JmxSystemViewExporterSpi {\n\t// Registers JMX bean for specific system view.\n\tprotected void register(SystemView<?> sysView);\n\t// This method is called to start SPI.\n\tvoid spiStart(@Nullable String igniteInstanceName);\n\t// This method is called to stop SPI.\n\tvoid spiStop();\n}", "des": "This SPI implementation exports system views as JMX beans."}
{"index": 759, "repo": "ignite-core-2.15.0", "code": "Interface JobStealingFailoverSpiMBean {\n\t// Gets maximum number of attempts to execute a failed job on another node.\n\tint getMaximumFailoverAttempts();\n\t// Get total number of jobs that were failed over including stolen ones.\n\tint getTotalFailedOverJobsCount();\n\t// Get total number of jobs that were stolen.\n\tint getTotalStolenJobsCount();\n}", "des": "Management bean for JobStealingFailoverSpi."}
{"index": 760, "repo": "ignite-core-2.15.0", "code": "Class JobStealingRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Job stealing request."}
{"index": 761, "repo": "ignite-core-2.15.0", "code": "Interface Latch {\n\t// Awaits current latch completion.\n\tvoid await();\n\t// Awaits current latch completion with specified timeout.\n\tvoid await(long timeout, TimeUnit timeUnit);\n\t// Decrements count on current latch.\n\tvoid countDown();\n}", "des": "Simple distributed count down latch interface. Latch supports count down and await logic. Latch functionality is not relied on caches and has own state management ExchangeLatchManager."}
{"index": 762, "repo": "ignite-core-2.15.0", "code": "Class LatchAckMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tboolean isFinal();\n\tString latchId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tAffinityTopologyVersion topVer();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Message is used to send acks for Latch instances management."}
{"index": 763, "repo": "ignite-core-2.15.0", "code": "Class LazyServiceConfiguration {\n\t// Checks if configurations are equal ignoring the node filter.\n\tboolean equalsIgnoreNodeFilter(Object o);\n\t// Gets service call interceptors.\n\tServiceCallInterceptor[] getInterceptors();\n\t// Gets service instance.\n\tService getService();\n\tbyte[] interceptorBytes();\n\tbyte[] serviceBytes();\n\tString serviceClassName();\n}", "des": "Lazy service configuration."}
{"index": 764, "repo": "ignite-core-2.15.0", "code": "Interface LifecycleAware {\n\t// Starts grid component, called on grid start.\n\tvoid start();\n\t// Stops grid component, called on grid shutdown.\n\tvoid stop();\n}", "des": "All components provided in Ignite configuration can implement this interface. If a component implements this interface, then method start() will be called during grid startup and stop() will be called during stop."}
{"index": 765, "repo": "ignite-core-2.15.0", "code": "Enum LifecycleEventType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable LifecycleEventType fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LifecycleEventType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LifecycleEventType[] values();\n}", "des": "Node lifecycle event types. These events are used to notify lifecycle beans about changes in node lifecycle state."}
{"index": 766, "repo": "ignite-core-2.15.0", "code": "Class LinkMap {\n\t// Frees the internal allocated resources.\n\tvoid close();\n\t// Get new link by old link.\n\tlong get(long oldLink);\n\t// Add link mapping.\n\tvoid put(long oldLink, long newLink);\n}", "des": "Class that holds mappings of old links to new links."}
{"index": 767, "repo": "ignite-core-2.15.0", "code": "Class LongAdderMetric {\n\t// Adds x to the metric.\n\tvoid add(long x);\n\t// Adds -1 to the metric.\n\tvoid decrement();\n\t// Adds 1 to the metric.\n\tvoid increment();\n\t// Resets metric state.\n\tvoid reset();\n\tlong value();\n}", "des": "Long metric implementation based on LongAdder."}
{"index": 768, "repo": "ignite-core-2.15.0", "code": "Class LongAdderWithDelegateMetric {\n\t// Adds x to the metric.\n\tvoid add(long x);\n\t// Adds -1 to the metric.\n\tvoid decrement();\n\t// Adds 1 to the metric.\n\tvoid increment();\n}", "des": "Long metric implementation based on LongAdder with delegate."}
{"index": 769, "repo": "ignite-core-2.15.0", "code": "Class LongInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected LongIndexKey get0(long pageAddr, int off);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, LongIndexKey key, int maxSize);\n}", "des": "Inline index column implementation for inlining Long values."}
{"index": 770, "repo": "ignite-core-2.15.0", "code": "Class LongJVMPauseDetector {\n\tstatic boolean enabled();\n\t@Nullable IgniteBiTuple<Long,Long> getLastLongPause();\n\tlong getLastWakeUpTime();\n\t// Starts worker if not started yet.\n\tvoid start();\n\t// Stops the worker if one is created and running.\n\tvoid stop();\n}", "des": "Class for detection of long JVM pauses. It has a worker thread, which wakes up in cycle every PRECISION (default is 50) milliseconds, and monitors a time values between awakenings. If worker pause exceeds the expected value more than THRESHOLD default is 500), the difference is considered as JVM pause, most likely STW, and event of long JVM pause is registered. The values of PRECISION, THRESHOLD and EVT_CNT (event window size, default is 20) can be configured in system or environment properties IGNITE_JVM_PAUSE_DETECTOR_PRECISION, IGNITE_JVM_PAUSE_DETECTOR_THRESHOLD and IGNITE_JVM_PAUSE_DETECTOR_LAST_EVENTS_COUNT accordingly."}
{"index": 771, "repo": "ignite-core-2.15.0", "code": "Class LongSumReducer {\n\t// Collects given value.\n\tboolean collect(Long e);\n\t// Reduces collected values into one.\n\tLong reduce();\n}", "des": "Reducer that calculates sum of long integer elements."}
{"index": 772, "repo": "ignite-core-2.15.0", "code": "Class MaintenanceFileStore {\n\t// Deletes file with maintenance tasks.\n\tvoid clear();\n\tvoid deleteMaintenanceTask(String taskName);\n\tMap<String,MaintenanceTask> getAllTasks();\n\tvoid init();\n\t// Stops\n\tvoid stop();\n\tvoid writeMaintenanceTask(MaintenanceTask task);\n}", "des": "Provides API for durable storage of MaintenanceTasks and hides implementation details from higher levels. Human-readable storage format is rigid but simple. Maintenance file with tasks is stored in work directory of node under persistent store root defined by consistentId of node. Each task is written to disk as a String on a separate line. Task consists of two or three parts: task UUID, task description and optional parameters."}
{"index": 773, "repo": "ignite-core-2.15.0", "code": "Class MappedFileMemoryProvider {\n\tvoid initialize(long[] sizes);\n\t// Attempts to allocate next memory region.\n\tDirectMemoryRegion nextRegion();\n\t// Shuts down the provider.\n\tvoid shutdown(boolean deallocate);\n}", "des": "Memory provider implementation based on memory mapped file."}
{"index": 774, "repo": "ignite-core-2.15.0", "code": "Class MappingAcceptedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n}", "des": "Is sent as an acknowledgement for successfully proposed new mapping (see MappingProposedMessage). If any nodes were waiting for this mapping to be accepted they will be unblocked on receiving this message."}
{"index": 775, "repo": "ignite-core-2.15.0", "code": "Class MappingProposedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tboolean duplicated();\n\tIgniteUuid id();\n\tboolean isMutable();\n}", "des": "Node sends this message when it wants to propose new marshaller mapping and to ensure that there are no conflicts with this mapping on other nodes in cluster. After sending this message to the cluster sending node gets blocked until mapping is either accepted or rejected. When it completes a pass around the cluster ring with no conflicts observed, MappingAcceptedMessage is sent as an acknowledgement that everything is fine."}
{"index": 776, "repo": "ignite-core-2.15.0", "code": "Class MarshallerExclusions {\n\t// Intended for test purposes only.\n\tstatic void clearCache();\n\t// Checks whether or not given class should be excluded from marshalling.\n\tstatic boolean isExcluded(Class<?> cls);\n}", "des": "Controls what classes should be excluded from marshalling by default."}
{"index": 777, "repo": "ignite-core-2.15.0", "code": "Class MarshallerPlatformIds {\n\t// Gets all known platform ids except the specified one.\n\tstatic byte[] otherPlatforms(byte platformId);\n\t// Gets the platform name by id.\n\tstatic String platformName(byte platformId);\n}", "des": "Constants for platform IDs to feed into MarshallerContext."}
{"index": 778, "repo": "ignite-core-2.15.0", "code": "Interface MemoryEventStorageSpiMBean {\n\t// Removes all events from the event queue.\n\tvoid clearAll();\n\t// Gets event time-to-live value.\n\tlong getExpireAgeMs();\n\t// Gets maximum event queue size.\n\tlong getExpireCount();\n\t// Gets current queue size of the event queue.\n\tlong getQueueSize();\n}", "des": "Management bean for MemoryEventStorageSpi. Beside properties defined for every SPI bean this one gives access to: Event expiration time (see getExpireAgeMs()) Maximum queue size (see getExpireCount()) Method that removes all items from queue (see clearAll())"}
{"index": 779, "repo": "ignite-core-2.15.0", "code": "Interface Message {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Base class for all communication messages."}
{"index": 780, "repo": "ignite-core-2.15.0", "code": "Enum MessageCollectionItemType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable MessageCollectionItemType fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MessageCollectionItemType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MessageCollectionItemType[] values();\n}", "des": "Enum representing possible types of collection items."}
{"index": 781, "repo": "ignite-core-2.15.0", "code": "Interface MessageFactoryProvider {\n\t// Always throws UnsupportedOperationException.\n\tdefault @Nullable Message create(short type);\n\t// Registers all messages factories.\n\tvoid registerAll(IgniteMessageFactory factory);\n}", "des": "Provider of communication message factories."}
{"index": 782, "repo": "ignite-core-2.15.0", "code": "Interface MessageFormatter {\n\t// Creates new message reader instance.\n\tMessageReader reader(UUID rmtNodeId, MessageFactory msgFactory);\n\t// Creates new message writer instance.\n\tMessageWriter writer(UUID rmtNodeId);\n}", "des": "Provides a custom format for communication messages."}
{"index": 783, "repo": "ignite-core-2.15.0", "code": "Class MetadataListResult {\n\tCollection<BinaryMetadata> metadata();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Represents information about cluster metadata."}
{"index": 784, "repo": "ignite-core-2.15.0", "code": "Class MetadataMarshalled {\n\tBinaryMetadata metadata();\n\tbyte[] metadataMarshalled();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Represents information about cluster metadata."}
{"index": 785, "repo": "ignite-core-2.15.0", "code": "Class MetadataRemoveAcceptedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tboolean duplicated();\n\tvoid duplicated(boolean duplicated);\n\tIgniteUuid id();\n\tboolean isMutable();\n\tint typeId();\n}", "des": "Acknowledge message for MetadataRemoveProposedMessage: see its javadoc for detailed description of protocol. As discovery messaging doesn't guarantee that message makes only one pass across the cluster MetadataRemoveAcceptedMessage enables to mark it as duplicated so other nodes won't process it but skip."}
{"index": 786, "repo": "ignite-core-2.15.0", "code": "Class MetadataRemoveProposedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n\tboolean isOnCoordinator();\n\tvoid setOnCoordinator(boolean onCoordinator);\n\tint typeId();\n}", "des": "MetadataRemoveProposedMessage and MetadataRemoveAcceptedMessage messages make a basis for discovery-based protocol for manage metadata describing objects in binary format stored in Ignite caches."}
{"index": 787, "repo": "ignite-core-2.15.0", "code": "Class MetadataRequestMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tint typeId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "As DiscoveryCustomMessage messages are delivered to client nodes asynchronously it is possible that server nodes are allowed to send to clients some BinaryObjects clients don't have metadata for. When client detects obsolete metadata (by checking if current version of metadata has schemaId) it requests up-to-date metadata using communication SPI. API to make a request is provided by BinaryMetadataTransport.requestUpToDateMetadata(int) method."}
{"index": 788, "repo": "ignite-core-2.15.0", "code": "Class MetadataResponseMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Carries latest version of metadata to client as a response for MetadataRequestMessage."}
{"index": 789, "repo": "ignite-core-2.15.0", "code": "Class MetadataUpdateAcceptedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tboolean duplicated();\n\tvoid duplicated(boolean duplicated);\n\tIgniteUuid id();\n\tboolean isMutable();\n\tint typeId();\n}", "des": "Acknowledge message for MetadataUpdateProposedMessage: see its javadoc for detailed description of protocol. As discovery messaging doesn't guarantee that message makes only one pass across the cluster MetadataUpdateAcceptedMessage enables to mark it as duplicated so other nodes won't process it but skip."}
{"index": 790, "repo": "ignite-core-2.15.0", "code": "Class MetadataUpdateProposedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n\tBinaryMetadata metadata();\n\tvoid metadata(BinaryMetadata metadata);\n\tint typeId();\n}", "des": "MetadataUpdateProposedMessage and MetadataUpdateAcceptedMessage messages make a basis for discovery-based protocol for exchanging metadata describing objects in binary format stored in Ignite caches. All interactions with binary metadata are performed through BinaryMetadataHandler interface implemented in CacheObjectBinaryProcessorImpl processor. Protocol works as follows: Each thread aiming to add/update metadata sends MetadataUpdateProposedMessage and blocks until receiving acknowledge or reject for proposed update. Coordinator node checks whether proposed update is in conflict with current version of metadata for the same typeId. In case of conflict initial MetadataUpdateProposedMessage is marked rejected and sent to initiator. If there are no conflicts on coordinator, pending version for metadata of this typeId is bumped up by one; MetadataUpdateProposedMessage with pending version information is sent across the cluster. Each node on receiving non-rejected MetadataUpdateProposedMessage updates pending version for the typeId in metadata local cache. When MetadataUpdateProposedMessage finishes pass, ack is sent. Ack has the same accepted version as pending version of initial MetadataUpdateProposedMessage message. Each node on receiving MetadataUpdateAcceptedMessage updates accepted version for the typeId. All threads waiting for arrival of ack with this accepted version are unblocked. If a thread on some node decides to read metadata which has ongoing update (with pending version strictly greater than accepted version) it gets blocked until MetadataUpdateAcceptedMessage arrives with accepted version equals to pending version of this metadata to the moment when is was initially read by the thread."}
{"index": 791, "repo": "ignite-core-2.15.0", "code": "Class MetaPageInfo {\n\tboolean flagsSupported();\n\tboolean inlineObjectHash();\n\tboolean inlineObjectSupported();\n\tint inlineSize();\n\t// Reads meta page info from page memory.\n\tstatic MetaPageInfo read(long metaPageId, int grpId, PageMemory pageMemory);\n\tboolean useUnwrappedPk();\n\t// Writes meta page info into page memory.\n\tvoid write(long metaPageId, int grpId, PageMemory pageMemory);\n}", "des": "Meta page stores meta data about InlineIndexTree."}
{"index": 792, "repo": "ignite-core-2.15.0", "code": "Class MetaStorage.TmpStorage {\n\t// Put data\n\tvoid add(String key, byte[] val);\n\tvoid close();\n\t// Read data from storage\n\tStream<IgniteBiTuple<String,byte[]>> stream();\n}", "des": "Temporary storage"}
{"index": 793, "repo": "ignite-core-2.15.0", "code": "Interface MetastorageLifecycleListener {\n\t// Is called when metastorage is made ready for read-only operations very early on node startup phase.\n\tdefault void onReadyForRead(ReadOnlyMetastorage metastorage);\n\t// Fully functional metastore capable of performing reading and writing operations.\n\tdefault void onReadyForReadWrite(ReadWriteMetastorage metastorage);\n}", "des": "Listener for events of metastore lifecycle. Database manager is responsible for initializing metastore on node startup and notifying other components about its readiness."}
{"index": 794, "repo": "ignite-core-2.15.0", "code": "Class MetastorageViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(MetastorageView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. MetastorageView attributes walker."}
{"index": 795, "repo": "ignite-core-2.15.0", "code": "Interface MetricExporterSpi {\n\t// Sets export filter.\n\tvoid setExportFilter(Predicate<ReadOnlyMetricRegistry> filter);\n\t// Sets metrics registry that SPI should export.\n\tvoid setMetricRegistry(ReadOnlyMetricManager registry);\n}", "des": "Exporter of metric information to the external recipient. Expected, that each implementation would support some specific protocol. Implementation of this Spi should work by pull paradigm. So after start SPI should respond to some incoming request. HTTP servlet or JMX bean are good examples of expected implementations."}
{"index": 796, "repo": "ignite-core-2.15.0", "code": "Interface MetricsMxBean {\n\t// Change HistogramMetric configuration.\n\tvoid configureHistogramMetric(String name, long[] bounds);\n\t// Change HitRateMetric configuration.\n\tvoid configureHitRateMetric(String name, long rateTimeInterval);\n\t// Resets metrics for of a given registry.\n\tvoid resetMetrics(String registry);\n}", "des": "Metrics MXBean interface."}
{"index": 797, "repo": "ignite-core-2.15.0", "code": "Class MetricsMxBeanImpl {\n\t// Change HistogramMetric configuration.\n\tvoid configureHistogramMetric(String name, long[] bounds);\n\t// Change HitRateMetric configuration.\n\tvoid configureHitRateMetric(String name, long rateTimeInterval);\n\t// Resets metrics for of a given registry.\n\tvoid resetMetrics(String registry);\n}", "des": "MetricsMxBean implementation."}
{"index": 798, "repo": "ignite-core-2.15.0", "code": "Class MetricsViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(MetricsView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. MetricsView attributes walker."}
{"index": 799, "repo": "ignite-core-2.15.0", "code": "Class MissingMappingRequestMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tbyte platformId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tint typeId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Client node receives discovery messages in asynchronous mode so it is possible that all server nodes already accepted new mapping but clients are unaware about it. In this case it is possible for client node to receive a request to perform some operation on such class client doesn't know about its mapping. Upon receiving such request client sends an explicit MissingMappingRequestMessage mapping request to one of server nodes using CommunicationSPI and waits for MissingMappingResponseMessage response. If server node where mapping request was sent to leaves the cluster for some reason mapping request gets automatically resent to the next alive server node in topology."}
{"index": 800, "repo": "ignite-core-2.15.0", "code": "Class MissingMappingResponseMessage {\n\tString className();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tbyte platformId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tint typeId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "On receiving a MissingMappingRequestMessage mapping request server node looks up class name for requested platformId and typeId in its local marshaller cache and sends back a MissingMappingResponseMessage mapping response with resolved class name."}
{"index": 801, "repo": "ignite-core-2.15.0", "code": "Class MTC {\n\tstatic @NotNull Span span();\n\t// Attach given span to current thread if it isn't null or NOOP_SPAN.\n\tstatic MTC.TraceSurroundings support(Span startSpan);\n\t// Attach given span to current thread if it isn't null or NOOP_SPAN.\n\tstatic MTC.TraceSurroundings supportContinual(Span startSpan);\n\t// Support initial span.\n\tstatic void supportInitial(Span startSpan);\n}", "des": "Mapped tracing context. Thread local context which holding the information for tracing."}
{"index": 802, "repo": "ignite-core-2.15.0", "code": "Class MvccQuerySnapshotRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tlong futureId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tboolean processedFromNioThread();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tboolean waitForCoordinatorInit();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Request to get MVCC snapshot for a query."}
{"index": 803, "repo": "ignite-core-2.15.0", "code": "Interface MvccQueryTracker {\n\tGridCacheContext context();\n\tdefault long id();\n\t// Marks tracker as done.\n\tvoid onDone();\n\t// Requests version on coordinator.\n\tIgniteInternalFuture<MvccSnapshot> requestSnapshot();\n\tMvccSnapshot snapshot();\n\tAffinityTopologyVersion topologyVersion();\n}", "des": "Mvcc tracker."}
{"index": 804, "repo": "ignite-core-2.15.0", "code": "Class MvccQueryTrackerImpl {\n\tGridCacheContext context();\n\tlong id();\n\t// Marks tracker as done.\n\tvoid onDone();\n\t// Mvcc coordinator change callback.\n\tlong onMvccCoordinatorChange(@NotNull MvccCoordinator newCrd);\n\t// Requests version on coordinator.\n\tIgniteInternalFuture<MvccSnapshot> requestSnapshot();\n\tMvccSnapshot snapshot();\n\tAffinityTopologyVersion topologyVersion();\n}", "des": "Tracker used for an optimistic tx and not-in-tx queries."}
{"index": 805, "repo": "ignite-core-2.15.0", "code": "Class MvccTxSnapshotRequest {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tlong futureId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tboolean processedFromNioThread();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tboolean waitForCoordinatorInit();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Request to get MVCC snapshot for a new transaction."}
{"index": 806, "repo": "ignite-core-2.15.0", "code": "Interface MvccUpdateVersionAware {\n\tlong newMvccCoordinatorVersion();\n\tlong newMvccCounter();\n\tint newMvccOperationCounter();\n\tbyte newMvccTxState();\n\tdefault MvccVersion newMvccVersion();\n\t// Sets new mvcc version.\n\tdefault void newMvccVersion(long crd, long cntr, int opCntr);\n\t// Copies new MVCC version\n\tdefault void newMvccVersion(MvccUpdateVersionAware other);\n\t// Sets new MVCC version\n\tdefault void newMvccVersion(MvccVersion ver);\n}", "des": "Interface for objects aware theirs mvcc update version."}
{"index": 807, "repo": "ignite-core-2.15.0", "code": "Class MvccVersionImpl {\n\tlong coordinatorVersion();\n\tlong counter();\n\t// Gets message type.\n\tshort directType();\n\tboolean equals(Object o);\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tint operationCounter();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Base MVCC version implementation."}
{"index": 808, "repo": "ignite-core-2.15.0", "code": "Class MySQLDialect {\n\tString escape(String ident);\n\tboolean hasMerge();\n\t// Construct query to get ranges bounds.\n\tString loadCacheSelectRangeQuery(String fullTblName, Collection<String> keyCols);\n\t// Construct merge query.\n\tString mergeQuery(String fullTblName, Collection<String> keyCols, Collection<String> uniqCols);\n}", "des": "A dialect compatible with the MySQL database."}
{"index": 809, "repo": "ignite-core-2.15.0", "code": "Class NearTxResultHandler {\n\t// Closure body.\n\tvoid apply(IgniteInternalFuture<GridCacheReturn> fut0);\n\t// Response factory method.\n\tstatic GridNearTxEnlistResponse createResponse(GridDhtTxEnlistFuture fut);\n\t// Response factory method.\n\tstatic <T> T createResponse(IgniteInternalFuture<?> future);\n\tstatic NearTxResultHandler instance();\n}", "des": "Response factory."}
{"index": 810, "repo": "ignite-core-2.15.0", "code": "Enum NestedTxMode {\n\t// Get enum value from int\n\tstatic NestedTxMode fromByte(byte val);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NestedTxMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NestedTxMode[] values();\n}", "des": "Behavior options when an attempt to start a nested transaction is made."}
{"index": 811, "repo": "ignite-core-2.15.0", "code": "Class NodeAttributeViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(NodeAttributeView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. NodeAttributeView attributes walker."}
{"index": 812, "repo": "ignite-core-2.15.0", "code": "Class NodeIdMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tbyte[] nodeIdBytes();\n\tstatic byte[] nodeIdBytesWithType(UUID nodeId);\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Node ID message."}
{"index": 813, "repo": "ignite-core-2.15.0", "code": "Class NodeMetricsViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(NodeMetricsView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. NodeMetricsView attributes walker."}
{"index": 814, "repo": "ignite-core-2.15.0", "code": "Class NodePageStream<R> {\n\t// Add new query result page of data.\n\tvoid addPage(Collection<R> data, boolean last);\n\t// Cancel query on all nodes.\n\tvoid cancel(Throwable err);\n\tboolean closed();\n\tboolean hasRemotePages();\n\t// Returns a last delivered page from this stream.\n\tCompletableFuture<NodePage<R>> headPage();\n\tUUID nodeId();\n}", "des": "This class provides an interface headPage() that returns a future will be completed with NodePage of cache query result from single node. A new page requests when previous page was fetched by class consumer."}
{"index": 815, "repo": "ignite-core-2.15.0", "code": "Class NoopEventStorageSpi {\n\t// Queries locally-stored events only.\n\t<T extends Event>Collection<T> localEvents(IgnitePredicate<T> p);\n\t// Records single event.\n\tvoid record(Event evt);\n\t// This method is called to start SPI.\n\tvoid spiStart(@Nullable String gridName);\n\t// This method is called to stop SPI.\n\tvoid spiStop();\n}", "des": "No-op implementation of EventStorageSpi."}
{"index": 816, "repo": "ignite-core-2.15.0", "code": "Class NoopMetricExporterSpi {\n\t// Sets export filter.\n\tvoid setExportFilter(Predicate<ReadOnlyMetricRegistry> filter);\n\t// Sets metrics registry that SPI should export.\n\tvoid setMetricRegistry(ReadOnlyMetricManager registry);\n\t// This method is called to start SPI.\n\tvoid spiStart(@Nullable String igniteInstanceName);\n\t// This method is called to stop SPI.\n\tvoid spiStop();\n}", "des": "No-op implementation of metric exporter SPI."}
{"index": 817, "repo": "ignite-core-2.15.0", "code": "Class NoopSpan {\n\t// Logs work to span.\n\tSpan addLog(Supplier<String> logDescSupplier);\n\t// Adds tag to span with String value.\n\tSpan addTag(String tagName, Supplier<String> tagValSupplier);\n\t// Ends span.\n\tSpan end();\n\tSet<Scope> includedScopes();\n\tboolean isEnded();\n\t// Explicitly set status for span.\n\tSpan setStatus(SpanStatus spanStatus);\n\tSpanType type();\n}", "des": "Noop and null-safe implementation of Span."}
{"index": 818, "repo": "ignite-core-2.15.0", "code": "Class NoopSpiSpecificSpan {\n\t// Logs work to span.\n\tNoopSpiSpecificSpan addLog(String logDesc);\n\t// Adds tag to span with String value.\n\tNoopSpiSpecificSpan addTag(String tagName, String tagVal);\n\t// Ends span.\n\tNoopSpiSpecificSpan end();\n\tboolean isEnded();\n\t// Explicitly set status for span.\n\tNoopSpiSpecificSpan setStatus(SpanStatus spanStatus);\n}", "des": "Noop and null-safe implementation of SpiSpecificSpan."}
{"index": 819, "repo": "ignite-core-2.15.0", "code": "Class NoOpWarmUpStrategy {\n\t// Returns configuration class for mapping to strategy.\n\tClass<NoOpWarmUpConfiguration> configClass();\n\t// Stop warming up.\n\tvoid stop();\n\t// Warm up.\n\tvoid warmUp(NoOpWarmUpConfiguration cfg, DataRegion region);\n}", "des": "Noop warming up strategy."}
{"index": 820, "repo": "ignite-core-2.15.0", "code": "Enum NullsOrder {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NullsOrder valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NullsOrder[] values();\n}", "des": "Enum to store possible nulls ordering."}
{"index": 821, "repo": "ignite-core-2.15.0", "code": "Class NumberUtil {\n\t// Converts the specified array of hex characters into an array of bytes (low byte first).\n\tstatic byte[] fromHex(String string, int offset, int count);\n\t// Computes the log2 (log-base-two) of the specified value.\n\tstatic double log2(double value);\n\t// Converts the specified array of bytes into a string of hex characters (low byte first).\n\tstatic String toHex(byte[] bytes, int offset, int cnt);\n}", "des": "A collection of utilities to work with numbers."}
{"index": 822, "repo": "ignite-core-2.15.0", "code": "Class ObjectHashInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey v);\n\t// Restores value from inline.\n\tprotected JavaObjectIndexKey get0(long pageAddr, int off);\n\t// Return inlined size for specified key.\n\tprotected int inlineSize0(JavaObjectIndexKey key);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, JavaObjectIndexKey val, int maxSize);\n}", "des": "Inline index key implementation for inlining hash of Java objects."}
{"index": 823, "repo": "ignite-core-2.15.0", "code": "Class ObjectStatisticsEvent {\n\t// Get statistics key.\n\tStatisticsKey key();\n\t// Get object statistics.\n\tObjectStatisticsImpl statistics();\n\t// Get affinity topology version.\n\tAffinityTopologyVersion topologyVersion();\n}", "des": "Local object statistics change event."}
{"index": 824, "repo": "ignite-core-2.15.0", "code": "Class ObjectStatisticsImpl {\n\tObjectStatisticsImpl clone();\n\tMap<String,ColumnStatistics> columnsStatistics();\n\t// Get column statistics.\n\tColumnStatistics columnStatistics(String colName);\n\tboolean equals(Object o);\n\tlong rowCount();\n\t// Remove specified columns from clone of current ObjectStatistics object.\n\t<T extends ObjectStatisticsImpl>T subtract(Set<String> cols);\n}", "des": "All statistics by some object (table or index)."}
{"index": 825, "repo": "ignite-core-2.15.0", "code": "Enum OdbcEscapeType {\n\tboolean allowEmpty();\n\tString body();\n\t// Get values in convenient order, where the most frequent values goes first, and \"startsWith\" invocation is enough to get type (i.e.\n\tstatic OdbcEscapeType[] sortedValues();\n\tboolean standard();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OdbcEscapeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OdbcEscapeType[] values();\n}", "des": "ODBC escape sequence type."}
{"index": 826, "repo": "ignite-core-2.15.0", "code": "Class OdbcMessageParser {\n\t// Decode request from byte array.\n\tClientListenerRequest decode(ClientMessage msg);\n\t// Decode command type.\n\tint decodeCommandType(ClientMessage msg);\n\t// Decode request Id.\n\tlong decodeRequestId(ClientMessage msg);\n\t// Encode response to byte array.\n\tClientMessage encode(ClientListenerResponse msg0);\n}", "des": "JDBC message parser."}
{"index": 827, "repo": "ignite-core-2.15.0", "code": "Class OdbcQuery {\n\tObject[] args();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReaderExImpl reader);\n\tString sql();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriterExImpl writer);\n}", "des": "ODBC SQL query with parameters."}
{"index": 828, "repo": "ignite-core-2.15.0", "code": "Class OdbcQueryResults {\n\t// Close all cursors.\n\tvoid closeAll();\n\tOdbcResultSet currentResultSet();\n\tboolean hasUnfetchedRows();\n\t// Move to next result set.\n\tvoid nextResultSet();\n\t// Get affected rows for all result sets.\n\tlong[] rowsAffected();\n}", "des": "ODBC result set"}
{"index": 829, "repo": "ignite-core-2.15.0", "code": "Enum Operation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Operation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Operation[] values();\n}", "des": "Operation type for VisorPageLocksTask"}
{"index": 830, "repo": "ignite-core-2.15.0", "code": "Class OracleDialect {\n\tboolean hasMerge();\n\t// Construct query to get ranges bounds.\n\tString loadCacheSelectRangeQuery(String fullTblName, Collection<String> keyCols);\n\t// Construct merge query.\n\tString mergeQuery(String fullTblName, Collection<String> keyCols, Collection<String> uniqCols);\n}", "des": "A dialect compatible with the Oracle database."}
{"index": 831, "repo": "ignite-core-2.15.0", "code": "Interface PageEvictionTracker {\n\t// Evicts one data page.\n\tvoid evictDataPage();\n\t// Check if page eviction is required according to the configured policy.\n\tboolean evictionRequired();\n\t// Call this method when last entry is removed from data page.\n\tvoid forgetPage(long pageId);\n\t// Call this method when data page is accessed.\n\tvoid touchPage(long pageId);\n}", "des": "Entry point for per-page eviction. Accepts information about touching data pages, capable of evicting \"the least needed\" page (according to implemented eviction algorithm)."}
{"index": 832, "repo": "ignite-core-2.15.0", "code": "Interface PageIdAllocator {\n\t// Allocates a page from the space for the given partition ID and the given flags.\n\tlong allocatePage(int grpId, int partId, byte flags);\n\t// The given page is free now.\n\tboolean freePage(int grpId, long pageId);\n}", "des": "Allocates page ID's."}
{"index": 833, "repo": "ignite-core-2.15.0", "code": "Interface PageLockTrackerMXBean {\n\t// Take page locks dump.\n\tString dumpLocks();\n\t// Take page locks dump and save to file.\n\tString dumpLocksToFile();\n\t// Take page locks dump and save to file for specific path.\n\tString dumpLocksToFile(String path);\n\t// Take page locks dump and print it to console.\n\tvoid dumpLocksToLog();\n}", "des": "This interface defines JMX managment interface for page lock tracking."}
{"index": 834, "repo": "ignite-core-2.15.0", "code": "Class PageLockTrackerMXBeanImpl {\n\t// Take page locks dump.\n\tString dumpLocks();\n\t// Take page locks dump and save to file.\n\tString dumpLocksToFile();\n\t// Take page locks dump and save to file for specific path.\n\tString dumpLocksToFile(String path);\n\t// Take page locks dump and print it to console.\n\tvoid dumpLocksToLog();\n}", "des": "Implementation of PageLockTrackerMXBean."}
{"index": 835, "repo": "ignite-core-2.15.0", "code": "Enum PageMemoryImpl.ThrottlingPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PageMemoryImpl.ThrottlingPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PageMemoryImpl.ThrottlingPolicy[] values();\n}", "des": "Throttling enabled and its type enum."}
{"index": 836, "repo": "ignite-core-2.15.0", "code": "Interface PageMetrics {\n\t// Number of index pages loaded into memory.\n\tLongAdderMetric indexPages();\n\t// Resets all metric counters.\n\tvoid reset();\n\t// Total number of allocated pages.\n\tLongAdderMetric totalPages();\n}", "des": "Container for different memory page-related metrics."}
{"index": 837, "repo": "ignite-core-2.15.0", "code": "Enum PageReplacementMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable PageReplacementMode fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PageReplacementMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PageReplacementMode[] values();\n}", "des": "Defines memory page replacement algorithm. A mode is set for a specific DataRegionConfiguration."}
{"index": 838, "repo": "ignite-core-2.15.0", "code": "Class PageReplacementPolicy {\n\t// Existing page touched.\n\tvoid onHit(long relPtr);\n\t// New page added.\n\tvoid onMiss(long relPtr);\n\t// Page removed from the page memory.\n\tvoid onRemove(long relPtr);\n\t// Finds page to replace.\n\tabstract long replace();\n}", "des": "Abstract page replacement policy."}
{"index": 839, "repo": "ignite-core-2.15.0", "code": "Interface PageReplacementPolicyFactory {\n\t// Create page replacement policy.\n\tPageReplacementPolicy create(org.apache.ignite.internal.processors.cache.persistence.pagemem.PageMemoryImpl.Segment seg, long ptr, int pagesCnt);\n\t// Calculaete amount of memory required to service pagesCnt pages.\n\tlong requiredMemory(int pagesCnt);\n}", "des": "Page replacement policy factory."}
{"index": 840, "repo": "ignite-core-2.15.0", "code": "Class PagesList.PagesCache {\n\t// Add pageId to the tail of the list.\n\tboolean add(long pageId);\n\t// Flush all stripes to one list and clear stripes.\n\tGridLongList flush();\n\t// Poll next page from the list.\n\tlong poll();\n\t// Remove page from the list.\n\tboolean removePage(long pageId);\n\t// Cache size.\n\tint size();\n}", "des": "Class to store page-list cache onheap."}
{"index": 841, "repo": "ignite-core-2.15.0", "code": "Class PagesListViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(PagesListView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. PagesListView attributes walker."}
{"index": 842, "repo": "ignite-core-2.15.0", "code": "Class PagesTimestampHistogramViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(PagesTimestampHistogramView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. PagesTimestampHistogramView attributes walker."}
{"index": 843, "repo": "ignite-core-2.15.0", "code": "Class PagesWriteThrottle {\n\t// Whether Checkpoint Buffer is currently close to exhaustion.\n\tboolean isCpBufferOverflowThresholdExceeded();\n\t// Callback to notify throttling policy checkpoint was started.\n\tvoid onBeginCheckpoint();\n\t// Callback to notify throttling policy checkpoint was finished.\n\tvoid onFinishCheckpoint();\n\t// Callback to apply throttling delay.\n\tvoid onMarkDirty(boolean isPageInCheckpoint);\n\t// Callback to wakeup throttled threads.\n\tvoid wakeupThrottledThreads();\n}", "des": "Throttles threads that generate dirty pages during ongoing checkpoint. Designed to avoid zero dropdowns that can happen if checkpoint buffer is overflowed."}
{"index": 844, "repo": "ignite-core-2.15.0", "code": "Interface PagesWriteThrottlePolicy {\n\t// Whether Checkpoint Buffer is currently close to exhaustion.\n\tboolean isCpBufferOverflowThresholdExceeded();\n\t// Callback to notify throttling policy checkpoint was started.\n\tvoid onBeginCheckpoint();\n\t// Callback to notify throttling policy checkpoint was finished.\n\tvoid onFinishCheckpoint();\n\t// Callback to apply throttling delay.\n\tvoid onMarkDirty(boolean isPageInCheckpoint);\n\t// Callback to wakeup throttled threads.\n\tvoid wakeupThrottledThreads();\n}", "des": "Throttling policy, encapsulates logic of delaying write operations."}
{"index": 845, "repo": "ignite-core-2.15.0", "code": "Enum PartitionAffinityFunctionType {\n\tint value();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PartitionAffinityFunctionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PartitionAffinityFunctionType[] values();\n}", "des": "Affinity function type."}
{"index": 846, "repo": "ignite-core-2.15.0", "code": "Class PartitionCompositeNode {\n\t// Get partitions.\n\tCollection<Integer> apply(PartitionClientContext cliCtx, Object... args);\n\tString cacheName();\n\tint joinGroup();\n\tPartitionNode left();\n\tPartitionCompositeNodeOperator operator();\n\t// Try optimizing partition nodes into a simpler form.\n\tPartitionNode optimize();\n\tPartitionNode right();\n}", "des": "Composite node which consists of two child nodes and a relation between them."}
{"index": 847, "repo": "ignite-core-2.15.0", "code": "Enum PartitionCompositeNodeOperator {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable PartitionCompositeNodeOperator fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PartitionCompositeNodeOperator valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PartitionCompositeNodeOperator[] values();\n}", "des": "Composite node operator."}
{"index": 848, "repo": "ignite-core-2.15.0", "code": "Class PartitionDataTypeUtils {\n\t// Convert argument to the given type.\n\tstatic Object convert(Object arg, PartitionParameterType targetType);\n\t// Utility method that helps to convert String to UUID.\n\tstatic Object stringToUUID(String s);\n}", "des": "Utility methods for partition extractor."}
{"index": 849, "repo": "ignite-core-2.15.0", "code": "Class PartitionDestroyRequest {\n\t// Initiates partition destroy.\n\tboolean beginDestroy();\n\t// Cancels partition destroy request.\n\tboolean cancel();\n\tint groupId();\n\tvoid onDone(Throwable err);\n\tint partitionId();\n\tvoid waitCompleted();\n}", "des": "Partition destroy request."}
{"index": 850, "repo": "ignite-core-2.15.0", "code": "Class PartitionGroupNode {\n\t// Get partitions.\n\tCollection<Integer> apply(PartitionClientContext ctx, Object... args);\n\tString cacheName();\n\tboolean constantsOnly();\n\t// Check if value exists.\n\tboolean contains(PartitionSingleNode val);\n\t// Check if current group node contains exactly the same set of siblings.\n\tboolean containsExact(Collection<PartitionSingleNode> siblings);\n\tint joinGroup();\n\tSet<PartitionSingleNode> siblings();\n}", "des": "Flat group of partitions."}
{"index": 851, "repo": "ignite-core-2.15.0", "code": "Class PartitionHashRecordV2 {\n\tObject consistentId();\n\tboolean equals(Object o);\n\tbyte getProtocolVersion();\n\tboolean isPrimary();\n\tint partitionHash();\n\tPartitionKeyV2 partitionKey();\n\tPartitionHashRecordV2.PartitionState partitionState();\n\tint partitionVersionsHash();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tlong size();\n\tObject updateCounter();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Record containing partition checksum, primary flag and consistent ID of owner."}
{"index": 852, "repo": "ignite-core-2.15.0", "code": "Class PartitionJoinCondition {\n\tboolean cross();\n\tboolean equals(Object obj);\n\t// Left alias.\n\tString leftAlias();\n\tString leftColumn();\n\t// Right alias.\n\tString rightAlias();\n\tString rightColumn();\n}", "des": "Join condition."}
{"index": 853, "repo": "ignite-core-2.15.0", "code": "Class PartitionJoinGroup {\n\t// Add table to the group.\n\tPartitionJoinGroup addTable(PartitionTable tbl);\n\tPartitionTableAffinityDescriptor affinityDescriptor();\n\t// Remove table from the group.\n\tboolean removeTable(PartitionTable tbl);\n\tCollection<PartitionTable> tables();\n}", "des": "Group of joined tables whose affinity function could be \"merged\"."}
{"index": 854, "repo": "ignite-core-2.15.0", "code": "Class PartitionKeyV2 {\n\tboolean equals(Object o);\n\tint groupId();\n\tString groupName();\n\tvoid groupName(String grpName);\n\tint partitionId();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Partition key - pair of cache group ID and partition ID."}
{"index": 855, "repo": "ignite-core-2.15.0", "code": "Enum PartitionLossPolicy {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable PartitionLossPolicy fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PartitionLossPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PartitionLossPolicy[] values();\n}", "des": "Partition loss policy. Defines how a cache will behave in a case when one or more partitions are lost because of a node(s) failure."}
{"index": 856, "repo": "ignite-core-2.15.0", "code": "Interface PartitionMetaStorage<T extends Storable> {\n\tvoid insertDataRow(T row, IoStatisticsHolder statHolder);\n\tlong metaPageId();\n\t// Read row data by link as byte array.\n\tbyte[] readRow(long link);\n\tvoid removeDataRowByLink(long link, IoStatisticsHolder statHolder);\n\t// Saves storage metadata.\n\tvoid saveMetadata(IoStatisticsHolder statHolder);\n}", "des": "Provides a way to associate any Storable implementation as partition metadata."}
{"index": 857, "repo": "ignite-core-2.15.0", "code": "Interface PartitionNode {\n\t// Get partitions.\n\tCollection<Integer> apply(@Nullable PartitionClientContext cliCtx, Object... args);\n\tString cacheName();\n\tint joinGroup();\n\t// Try optimizing partition nodes into a simpler form.\n\tdefault PartitionNode optimize();\n}", "des": "Common node of partition tree."}
{"index": 858, "repo": "ignite-core-2.15.0", "code": "Enum PartitionParameterType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable PartitionParameterType fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PartitionParameterType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PartitionParameterType[] values();\n}", "des": "Partition argument type."}
{"index": 859, "repo": "ignite-core-2.15.0", "code": "Class PartitionResult {\n\tPartitionTableAffinityDescriptor affinity();\n\tString cacheName();\n\t// Calculate partitions for the query.\n\tstatic int[] calculatePartitions(int[] explicitParts, PartitionResult derivedParts, Object[] args);\n\tboolean isClientPartitionAwarenessApplicable();\n\tint partitionsCount();\n\tAffinityTopologyVersion topologyVersion();\n\t// Tree.\n\tPartitionNode tree();\n}", "des": "Partition extraction result."}
{"index": 860, "repo": "ignite-core-2.15.0", "code": "Class PartitionResultMarshaler {\n\t// Writes partition result to provided writer.\n\tstatic void marshal(BinaryWriterExImpl writer, PartitionResult partRes);\n\t// Reads fields from provided reader.\n\tstatic PartitionResult unmarshal(BinaryReaderExImpl reader);\n}", "des": "Marshaller that lets to serialize and deserialize partiton result for the purposes of jdbc thin client size best effort affinity."}
{"index": 861, "repo": "ignite-core-2.15.0", "code": "Class PartitionSingleNode {\n\t// Get partitions.\n\tCollection<Integer> apply(PartitionClientContext cliCtx, Object... args);\n\t// Apply arguments and get single partition.\n\tabstract Integer applySingle(@Nullable PartitionClientContext cliCtx, Object... args);\n\tString cacheName();\n\tabstract boolean constant();\n\tboolean equals(Object obj);\n\tint joinGroup();\n\tPartitionTable table();\n\tabstract int value();\n}", "des": "Node with a single partition."}
{"index": 862, "repo": "ignite-core-2.15.0", "code": "Class PartitionStateViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(PartitionStateView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. PartitionStateView attributes walker."}
{"index": 863, "repo": "ignite-core-2.15.0", "code": "Class PartitionTableModel {\n\t// Add excluded table\n\tvoid addExcludedTable(String alias);\n\t// Add equi-join condition.\n\tvoid addJoin(PartitionJoinCondition cond);\n\t// Add table.\n\tvoid addTable(PartitionTable tbl, PartitionTableAffinityDescriptor aff);\n\t// Get affinity descriptor for the group.\n\t@Nullable PartitionTableAffinityDescriptor joinGroupAffinity(int grpId);\n\t// Get table by alias.\n\t@Nullable PartitionTable table(String alias);\n}", "des": "Partition join model. Describes how tables are joined with each other."}
{"index": 864, "repo": "ignite-core-2.15.0", "code": "Class PartitionUpdateCounterMvccImpl {\n\tPartitionUpdateCounter copy();\n\tprotected PartitionUpdateCounterTrackingImpl createInstance();\n\t// Increment HWM by delta.\n\tlong reserve(long delta);\n\t// Returns HWM.\n\tlong reserved();\n}", "des": "Update counter implementation for MVCC mode."}
{"index": 865, "repo": "ignite-core-2.15.0", "code": "Class PdsConsistentIdProcessor {\n\t// Prepares and caches PDS folder settings.\n\tPdsFolderSettings<GridCacheDatabaseSharedManager.NodeFileLockHolder> resolveFolders();\n\t// Stops grid component.\n\tvoid stop(boolean cancel);\n}", "des": "Component for resolving PDS storage file names, also used for generating consistent ID for case PDS mode is enabled"}
{"index": 866, "repo": "ignite-core-2.15.0", "code": "Class PdsFolderResolver<L extends FileLockHolder> {\n\tPdsFolderSettings<L> generateNew();\n\t// Generates DB subfolder name for provided node index (local) and UUID (consistent ID)\n\tstatic @NotNull String genNewStyleSubfolderName(int nodeIdx, UUID uuid);\n\tstatic @Nullable PdsFolderResolver.FolderCandidate parseSubFolderName(@NotNull File subFolderFile, @NotNull IgniteLogger log);\n\t// Resolves PdsFolderSettings according to specified IgniteConfiguration, consistentId.\n\tPdsFolderSettings<L> resolve();\n}", "des": "This class contains logic to resolve and possibly lock PDS folder based on provided IgniteConfiguration and consistentId."}
{"index": 867, "repo": "ignite-core-2.15.0", "code": "Interface PerformanceStatisticsMBean {\n\t// Rotate performance statistics in the cluster.\n\tvoid rotate();\n\t// Start collecting performance statistics in the cluster.\n\tvoid start();\n\tboolean started();\n\t// Stop collecting performance statistics in the cluster.\n\tvoid stop();\n}", "des": "MBean that provides access to performance statistics management."}
{"index": 868, "repo": "ignite-core-2.15.0", "code": "Class PerformanceStatisticsMBeanImpl {\n\t// Rotate performance statistics in the cluster.\n\tvoid rotate();\n\t// Start collecting performance statistics in the cluster.\n\tvoid start();\n\tboolean started();\n\t// Stop collecting performance statistics in the cluster.\n\tvoid stop();\n}", "des": "PerformanceStatisticsMBean implementation."}
{"index": 869, "repo": "ignite-core-2.15.0", "code": "Enum PersistenceOperation {\n\tstatic @Nullable PersistenceOperation fromOrdinal(int ordinal);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PersistenceOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PersistenceOperation[] values();\n}", "des": "Persistence cleaning operations."}
{"index": 870, "repo": "ignite-core-2.15.0", "code": "Class PipelineBlock<I,O> {\n\t// Accepts a portion of input.\n\tabstract void accept(I inputPortion, boolean isLastPortion);\n\t// Sets the next block in this block and returns the next block.\n\t<N> PipelineBlock<O,N> append(PipelineBlock<O,N> next);\n}", "des": "A file parsing pipeline block. Accepts an portion of an input (isLastPortion flag is provided to signify the last block to process) and optionally calls the next block with transformed input or performs any other handling, such as storing input to internal structures."}
{"index": 871, "repo": "ignite-core-2.15.0", "code": "Class PlatformAbstractBootstrap {\n\t// Get configuration transformer closure.\n\tprotected abstract IgniteClosure<IgniteConfiguration,IgniteConfiguration> closure(long envPtr);\n\t// Init the bootstrap.\n\tvoid init(long dataPtr);\n\t// Processes any additional input data.\n\tprotected void processInput(PlatformInputStream input);\n\t// Start Ignite node.\n\tPlatformProcessor start(IgniteConfiguration cfg, @Nullable GridSpringResourceContext springCtx, long envPtr);\n}", "des": "Base interop bootstrap implementation."}
{"index": 872, "repo": "ignite-core-2.15.0", "code": "Class PlatformAbstractConfigurationClosure {\n\t// Closure body.\n\tIgniteConfiguration apply(IgniteConfiguration igniteCfg);\n\t// Internal apply routine.\n\tprotected abstract void apply0(IgniteConfiguration igniteCfg);\n}", "des": "Abstract interop configuration closure."}
{"index": 873, "repo": "ignite-core-2.15.0", "code": "Class PlatformAbstractFunc {\n\t// Invokes this instance.\n\tprotected Object invoke();\n\tString name();\n\t// Performs platform callback.\n\tprotected abstract void platformCallback(PlatformCallbackGateway gate, long memPtr);\n}", "des": "Base class for simple computations (Callable, Runnable). Cleaner alternative to PlatformClosureJob, uses less wrapping for the underlying object, and a single callback."}
{"index": 874, "repo": "ignite-core-2.15.0", "code": "Class PlatformAbstractJob {\n\t// Create job in native platform if needed.\n\tprotected boolean createJob(PlatformContext ctx);\n\t// Executes this job.\n\t@Nullable Object execute();\n\t// Internal job execution routine.\n\tprotected abstract Object execute0(PlatformContext ctx);\n\t// Gets native job.\n\tObject job();\n\tString name();\n\t// Gets native pointer to deployed job.\n\tlong pointer();\n\t// Run local job.\n\tprotected Object runLocal(PlatformContext ctx, boolean cancel);\n}", "des": "Base interop job."}
{"index": 875, "repo": "ignite-core-2.15.0", "code": "Class PlatformAbstractMemory {\n\t// Gets capacity.\n\tint capacity();\n\t// Gets data pointer.\n\tlong data();\n\t// Gets input stream.\n\tPlatformInputStream input();\n\t// Gets length.\n\tint length();\n\t// Gets output stream.\n\tPlatformOutputStream output();\n\t// Gets pointer which can be passed between platforms.\n\tlong pointer();\n}", "des": "Interop memory chunk abstraction."}
{"index": 876, "repo": "ignite-core-2.15.0", "code": "Class PlatformAffinity {\n\t// Process IN operation.\n\tlong processInLongOutLong(int type, long val);\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n\t// Process IN-OUT operation.\n\tvoid processInStreamOutStream(int type, BinaryRawReaderEx reader, BinaryRawWriterEx writer);\n}", "des": "Affinity wrapper for platforms."}
{"index": 877, "repo": "ignite-core-2.15.0", "code": "Class PlatformAffinityFunctionTarget {\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n\t// Process OUT operation.\n\tvoid processOutStream(int type, BinaryRawWriterEx writer);\n}", "des": "Platform affinity function target: to be invoked when Platform function calls base implementation of one of the AffinityFunction methods."}
{"index": 878, "repo": "ignite-core-2.15.0", "code": "Interface PlatformAsyncResult {\n\t// Async operation future.\n\tIgniteFuture future();\n\t// Async operation result writer method.\n\tvoid write(BinaryRawWriterEx writer, Object result);\n}", "des": "Represents asynchronous operation result."}
{"index": 879, "repo": "ignite-core-2.15.0", "code": "Class PlatformAtomicLong {\n\t// Process IN operation.\n\tlong processInLongOutLong(int type, long val);\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n}", "des": "Platform atomic long wrapper."}
{"index": 880, "repo": "ignite-core-2.15.0", "code": "Class PlatformBinaryProcessor {\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n\t// Process IN-OUT operation.\n\tvoid processInStreamOutStream(int type, BinaryRawReaderEx reader, BinaryRawWriterEx writer);\n\t// Process OUT operation.\n\tvoid processOutStream(int type, BinaryRawWriterEx writer);\n}", "des": "Platform binary processor."}
{"index": 881, "repo": "ignite-core-2.15.0", "code": "Interface PlatformBootstrap {\n\t// Init the bootstrap.\n\tvoid init(long dataPtr);\n\t// Start Ignite node.\n\tPlatformProcessor start(IgniteConfiguration cfg, @Nullable GridSpringResourceContext springCtx, long envPtr);\n}", "des": "Platform bootstrap. Responsible for starting Ignite node with non-Java platform."}
{"index": 882, "repo": "ignite-core-2.15.0", "code": "Interface PlatformBootstrapFactory {\n\t// Create bootstrap instance.\n\tPlatformBootstrap create();\n\t// Get bootstrap factory ID.\n\tint id();\n}", "des": "Platform bootstrap factory."}
{"index": 883, "repo": "ignite-core-2.15.0", "code": "Interface PlatformCacheEntryFilter {\n\t// Sets the cache context.\n\tvoid cacheContext(GridCacheContext cctx);\n\t// Callback invoked when filter is no longer needed.\n\tvoid onClose();\n}", "des": "Platform cache entry filter interface."}
{"index": 884, "repo": "ignite-core-2.15.0", "code": "Class PlatformCacheEntryFilterImpl {\n\t// Predicate body.\n\tboolean apply(Object k, Object v);\n\t// Sets the cache context.\n\tvoid cacheContext(GridCacheContext cctx);\n\t// Callback invoked when filter is no longer needed.\n\tvoid onClose();\n\tvoid setIgniteInstance(Ignite ignite);\n}", "des": "Interop filter. Delegates apply to native platform."}
{"index": 885, "repo": "ignite-core-2.15.0", "code": "Interface PlatformCacheExtension {\n\t// Get extension ID.\n\tint id();\n\t// Invokes in-out operation with long return type.\n\tlong processInOutStreamLong(PlatformCache target, int type, BinaryRawReaderEx reader, PlatformMemory mem);\n}", "des": "Platform cache extension. Decouples other modules from cache."}
{"index": 886, "repo": "ignite-core-2.15.0", "code": "Class PlatformCacheManager {\n\tvoid onDisconnected(IgniteFuture reconnectFut);\n\tvoid onKernalStart();\n\tvoid onKernalStop(boolean cancel);\n\t// Prints memory statistics (sizes of internal data structures, etc.).\n\tvoid printMemoryStats();\n\t// Starts manager.\n\tvoid start(GridCacheContext cctx);\n\t// Stops manager.\n\tvoid stop(boolean cancel, boolean destroy);\n}", "des": "Platform cache manager - delegates functionality to native platforms (.NET, C++, ...)."}
{"index": 887, "repo": "ignite-core-2.15.0", "code": "Interface PlatformCachePluginConfigurationClosureFactory {\n\t// Creates configuration closure instance.\n\tPlatformCachePluginConfigurationClosure create();\n\t// Gets the factory id.\n\tint id();\n}", "des": "Factory for @PlatformCachePluginConfigurationClosure with a unique id."}
{"index": 888, "repo": "ignite-core-2.15.0", "code": "Class PlatformClosureJob {\n\t// This method is called when system detects that completion of this job can no longer alter the overall outcome (for example, when parent task has already reduced the results).\n\tvoid cancel();\n\t// Internal job execution routine.\n\t@Nullable Object execute0(PlatformContext ctx);\n\tvoid readExternal(ObjectInput in);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Light-weight interop job. Comparing to regular job, this guy has simpler logic because we should not bother with delayed serialization and cancellation. NOTE: Legacy. New implementations should use PlatformAbstractFunc and derivatives instead."}
{"index": 889, "repo": "ignite-core-2.15.0", "code": "Interface PlatformContinuousQuery {\n\t// Close continuous query.\n\tvoid close();\n\t// Gets initial query cursor (if any).\n\tPlatformTarget getInitialQueryCursor();\n\t// Start continuous query execution.\n\tvoid start(IgniteCacheProxy cache, boolean loc, int bufSize, long timeInterval, boolean autoUnsubscribe, Query initialQry, boolean includeExpired);\n}", "des": "Platform continuous query."}
{"index": 890, "repo": "ignite-core-2.15.0", "code": "Class PlatformContinuousQueryProxy {\n\t// Process IN operation.\n\tlong processInLongOutLong(int type, long val);\n\t// Process OUT operation.\n\tPlatformTarget processOutObject(int type);\n}", "des": "Proxy that implements PlatformTarget."}
{"index": 891, "repo": "ignite-core-2.15.0", "code": "Class PlatformCppBootstrapFactory {\n\t// Create bootstrap instance.\n\tPlatformBootstrap create();\n\t// Get bootstrap factory ID.\n\tint id();\n}", "des": "Platform .Net bootstrap factory."}
{"index": 892, "repo": "ignite-core-2.15.0", "code": "Class PlatformDataStreamer {\n\tboolean allowOverwrite();\n\tvoid allowOverwrite(boolean val);\n\tint perNodeBufferSize();\n\tvoid perNodeBufferSize(int val);\n\tint perNodeParallelOperations();\n\tvoid perNodeParallelOperations(int val);\n\t// Process IN operation.\n\tlong processInLongOutLong(int type, long val);\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n\tboolean skipStore();\n\tvoid skipStore(boolean skipStore);\n}", "des": "Interop data streamer wrapper."}
{"index": 893, "repo": "ignite-core-2.15.0", "code": "Class PlatformDefaultJavaObjectFactory<T> {\n\t// Constructs and returns a fully configured instance of T.\n\tT create();\n\t// Initialize factory.\n\tvoid initialize(@Nullable Object payload, @Nullable Map<String,Object> props);\n}", "des": "Default Java object factory implementation."}
{"index": 894, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetBootstrap {\n\t// Get configuration transformer closure.\n\tprotected PlatformAbstractConfigurationClosure closure(long envPtr);\n\t// Processes any additional input data.\n\tprotected void processInput(PlatformInputStream input);\n}", "des": "Interop .Net bootstrap."}
{"index": 895, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetBootstrapFactory {\n\t// Create bootstrap instance.\n\tPlatformBootstrap create();\n\t// Get bootstrap factory ID.\n\tint id();\n}", "des": "Interop .Net bootstrap factory."}
{"index": 896, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetCacheStoreFactory {\n\tPlatformDotNetCacheStore create();\n\t// Get properties.\n\tMap<String,?> getProperties();\n\t// Gets .NET type name.\n\tString getTypeName();\n\t// Set properties.\n\tvoid setProperties(Map<String,?> props);\n\t// Sets .NET type name.\n\tvoid setTypeName(String typName);\n}", "des": "Wrapper for .NET cache store implementations."}
{"index": 897, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetEntityFrameworkCacheEntry {\n\tbyte[] data();\n\tString[] entitySets();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "EntityFramework cache entry."}
{"index": 898, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetEntityFrameworkCacheExtension {\n\t// Get extension ID.\n\tint id();\n\t// Invokes in-out operation with long return type.\n\tlong processInOutStreamLong(PlatformCache target, int type, BinaryRawReaderEx reader, PlatformMemory mem);\n}", "des": "EntityFramework cache extension."}
{"index": 899, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetEntityFrameworkCacheKey {\n\tint compareTo(@NotNull PlatformDotNetEntityFrameworkCacheKey o);\n\tboolean equals(Object o);\n\t// Gets the query text.\n\tString query();\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Gets the entity set versions.\n\tlong[] versions();\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "EntityFramework cache key: query + versions."}
{"index": 900, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetLifecycleBean {\n\t// Get properties.\n\tMap<String,?> getProperties();\n\t// Get type name.\n\tString getTypeName();\n\t// Set properties.\n\tvoid setProperties(Map<String,?> props);\n\t// Set type name.\n\tvoid setTypeName(String typName);\n}", "des": "Lifecycle bean implementation which can be used to configure .Net lifecycle beans in Java Spring configuration."}
{"index": 901, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetSessionCacheExtension {\n\t// Get extension ID.\n\tint id();\n\t// Invokes in-out operation with long return type.\n\tlong processInOutStreamLong(PlatformCache target, int type, BinaryRawReaderEx reader, PlatformMemory mem);\n}", "des": "Custom entry processor invoker."}
{"index": 902, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetSessionLockResult {\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Writes to a binary writer.\n\tvoid writeBinary(BinaryRawWriter writer);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "Result of the PlatformDotNetSessionLockProcessor execution."}
{"index": 903, "repo": "ignite-core-2.15.0", "code": "Class PlatformDotNetSessionSetAndUnlockProcessor {\n\tVoid process(javax.cache.processor.MutableEntry<String,PlatformDotNetSessionData> entry, Object... args);\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "Processor to unlock and optionally update the session."}
{"index": 904, "repo": "ignite-core-2.15.0", "code": "Interface PlatformEventFilterListener {\n\t// Initializes the filter.\n\tvoid initialize(GridKernalContext ctx);\n\t// Callback invoked when filter is closed.\n\tvoid onClose();\n}", "des": "Platform event filter and listener."}
{"index": 905, "repo": "ignite-core-2.15.0", "code": "Class PlatformEventFilterListenerImpl {\n\t// Predicate body.\n\tboolean apply(Event evt);\n\t// Predicate body.\n\tboolean apply(UUID uuid, Event evt);\n\tboolean equals(Object o);\n\t// Initializes the filter.\n\tvoid initialize(GridKernalContext gridCtx);\n\t// Callback invoked when filter is closed.\n\tvoid onClose();\n\tvoid readExternal(ObjectInput in);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Platform event filter. Delegates apply to native platform."}
{"index": 906, "repo": "ignite-core-2.15.0", "code": "Class PlatformEvents {\n\t// Process IN operation.\n\tlong processInLongOutLong(int type, long val);\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n\t// Process IN-OUT operation.\n\tvoid processInStreamOutStream(int type, BinaryRawReaderEx reader, BinaryRawWriterEx writer);\n\t// Process OUT operation.\n\tPlatformTarget processOutObject(int type);\n\t// Process OUT operation.\n\tvoid processOutStream(int type, BinaryRawWriterEx writer);\n}", "des": "Interop events."}
{"index": 907, "repo": "ignite-core-2.15.0", "code": "Class PlatformExternalMemory {\n\t// Close memory releasing it.\n\tvoid close();\n\t// Reallocate memory chunk.\n\tvoid reallocate(int cap);\n}", "des": "Interop external memory chunk."}
{"index": 908, "repo": "ignite-core-2.15.0", "code": "Class PlatformFieldsQueryCursor {\n\t// Process OUT operation.\n\tvoid processOutStream(int type, BinaryRawWriterEx writer);\n\t// Write value to the stream.\n\tprotected void write(BinaryRawWriterEx writer, List vals);\n}", "des": "Interop cursor for fields query."}
{"index": 909, "repo": "ignite-core-2.15.0", "code": "Class PlatformFullJob {\n\t// This method is called when system detects that completion of this job can no longer alter the overall outcome (for example, when parent task has already reduced the results).\n\tvoid cancel();\n\t// Internal job execution routine.\n\t@Nullable Object execute0(PlatformContext ctx);\n\tvoid readExternal(ObjectInput in);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Wrapper around job created in native platform."}
{"index": 910, "repo": "ignite-core-2.15.0", "code": "Interface PlatformFutureUtils.Writer {\n\t// Determines whether this writer can write given data.\n\tboolean canWrite(Object obj, Throwable err);\n\t// Write object.\n\tvoid write(BinaryRawWriterEx writer, Object obj, Throwable err);\n}", "des": "Writer allowing special future result handling."}
{"index": 911, "repo": "ignite-core-2.15.0", "code": "Class PlatformJavaObjectFactoryProxy {\n\t// Get factory instance.\n\tPlatformJavaObjectFactory factory(GridKernalContext ctx);\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\tvoid readExternal(ObjectInput in);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Wrapper for Java object factory."}
{"index": 912, "repo": "ignite-core-2.15.0", "code": "Interface PlatformJob {\n\t// Gets native job.\n\tObject job();\n\t// Gets native pointer to deployed job.\n\tlong pointer();\n}", "des": "Platform closure job interface."}
{"index": 913, "repo": "ignite-core-2.15.0", "code": "Class PlatformLifecycleBean {\n\t// Set pointers.\n\tvoid initialize(PlatformCallbackGateway gate, long ptr);\n\t// This method is called when lifecycle event occurs.\n\tvoid onLifecycleEvent(LifecycleEventType evt);\n}", "des": "Lifecycle aware bean for interop."}
{"index": 914, "repo": "ignite-core-2.15.0", "code": "Interface PlatformListenable {\n\t// Cancel this instance.\n\tboolean cancel();\n\t// Returns true if this listenable was canceled before completion.\n\tboolean isCancelled();\n\t// Listen.\n\tvoid listen(IgniteBiInClosure<Object,Throwable> lsnr);\n}", "des": "Platform listenable."}
{"index": 915, "repo": "ignite-core-2.15.0", "code": "Interface PlatformMemory {\n\t// Gets capacity.\n\tint capacity();\n\t// Close memory releasing it.\n\tvoid close();\n\t// Gets data pointer.\n\tlong data();\n\t// Gets input stream.\n\tPlatformInputStream input();\n\t// Gets length.\n\tint length();\n\t// Gets output stream.\n\tPlatformOutputStream output();\n\t// Gets pointer which can be passed between platforms.\n\tlong pointer();\n\t// Reallocate memory chunk.\n\tvoid reallocate(int cap);\n}", "des": "Interop memory chunk."}
{"index": 916, "repo": "ignite-core-2.15.0", "code": "Interface PlatformMemoryManager {\n\t// Allocates memory.\n\tPlatformMemory allocate();\n\t// Allocates memory having at least the given capacity.\n\tPlatformMemory allocate(int cap);\n\t// Gets memory from existing pointer.\n\tPlatformMemory get(long memPtr);\n}", "des": "Interop memory manager interface."}
{"index": 917, "repo": "ignite-core-2.15.0", "code": "Class PlatformMemoryManagerImpl {\n\t// Allocates memory.\n\tPlatformMemory allocate();\n\t// Allocates memory having at least the given capacity.\n\tPlatformMemory allocate(int cap);\n\t// Gets memory from existing pointer.\n\tPlatformMemory get(long memPtr);\n}", "des": "Interop memory manager implementation."}
{"index": 918, "repo": "ignite-core-2.15.0", "code": "Class PlatformMemoryPool {\n\t// Allocate memory chunk, optionally pooling it.\n\tPlatformMemory allocate(int cap);\n\t// Get pooled memory chunk.\n\tPlatformMemory get(long memPtr);\n}", "des": "Memory pool associated with a thread."}
{"index": 919, "repo": "ignite-core-2.15.0", "code": "Interface PlatformMessageFilter {\n\t// Initializes the filter.\n\tvoid initialize(GridKernalContext ctx);\n\t// Closes the filter.\n\tvoid onClose();\n}", "des": "Platform message filter."}
{"index": 920, "repo": "ignite-core-2.15.0", "code": "Class PlatformMessageFilterImpl {\n\t// Predicate body.\n\tboolean apply(UUID uuid, Object m);\n\t// Initializes the filter.\n\tvoid initialize(GridKernalContext kernalCtx);\n\t// Closes the filter.\n\tvoid onClose();\n}", "des": "Platform message filter. Delegates apply to native platform."}
{"index": 921, "repo": "ignite-core-2.15.0", "code": "Class PlatformMessageLocalFilter {\n\t// Predicate body.\n\tboolean apply(UUID uuid, Object m);\n\tboolean equals(Object o);\n\t// Initializes the filter.\n\tvoid initialize(GridKernalContext ctx);\n\t// Closes the filter.\n\tvoid onClose();\n}", "des": "Interop local filter. Delegates apply to native platform, uses id to identify native target."}
{"index": 922, "repo": "ignite-core-2.15.0", "code": "Class PlatformMessaging {\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n\t// Process IN-OUT operation.\n\tvoid processInStreamOutStream(int type, BinaryRawReaderEx reader, BinaryRawWriterEx writer);\n\t// Process OUT operation.\n\tPlatformTarget processOutObject(int type);\n}", "des": "Interop messaging."}
{"index": 923, "repo": "ignite-core-2.15.0", "code": "Interface PlatformPluginConfigurationClosureFactory {\n\t// Creates configuration instance.\n\tPlatformPluginConfigurationClosure create();\n\t// Gets the factory id.\n\tint id();\n}", "des": "Factory for @PlatformPluginConfigurationClosure with a unique id."}
{"index": 924, "repo": "ignite-core-2.15.0", "code": "Interface PlatformPluginExtension {\n\t// Creates the PlatformTarget for this extension.\n\tPlatformTarget createTarget();\n\t// Get extension ID.\n\tint id();\n}", "des": "Platform extension."}
{"index": 925, "repo": "ignite-core-2.15.0", "code": "Class PlatformPluginProcessor {\n\t// Callback to notify that kernal is about to stop.\n\tvoid onKernalStop(boolean cancel);\n\t// Stops grid component.\n\tvoid stop(boolean cancel);\n}", "des": "Platform plugin processor"}
{"index": 926, "repo": "ignite-core-2.15.0", "code": "Class PlatformPooledMemory {\n\t// Close memory releasing it.\n\tvoid close();\n\t// Reallocate memory chunk.\n\tvoid reallocate(int cap);\n}", "des": "Interop pooled memory chunk."}
{"index": 927, "repo": "ignite-core-2.15.0", "code": "Interface PlatformService {\n\t// Invokes native service method.\n\tObject invokeMethod(String mthdName, boolean srvKeepBinary, boolean deserializeResult, @Nullable Object[] args, @Nullable Map<String,Object> callAttrs);\n\t// Gets native pointer.\n\tlong pointer();\n}", "des": "Base class for all platform services."}
{"index": 928, "repo": "ignite-core-2.15.0", "code": "Class PlatformTransactions {\n\t// Process IN operation.\n\tlong processInLongOutLong(int type, long val);\n\t// Process IN operation.\n\tlong processInStreamOutLong(int type, BinaryRawReaderEx reader);\n\t// Process IN-OUT operation.\n\tvoid processInStreamOutStream(int type, BinaryRawReaderEx reader, BinaryRawWriterEx writer);\n\t// Process OUT operation.\n\tvoid processOutStream(int type, BinaryRawWriterEx writer);\n}", "des": "Native transaction wrapper implementation."}
{"index": 929, "repo": "ignite-core-2.15.0", "code": "Enum PlatformType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PlatformType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PlatformType[] values();\n}", "des": "Interop platform type."}
{"index": 930, "repo": "ignite-core-2.15.0", "code": "Class PlatformUnpooledMemory {\n\t// Close memory releasing it.\n\tvoid close();\n\t// Reallocate memory chunk.\n\tvoid reallocate(int cap);\n}", "des": "Interop un-pooled memory chunk."}
{"index": 931, "repo": "ignite-core-2.15.0", "code": "Class PrintRawToFileHandler {\n\t// Method which called after all iteration would be finished.\n\tvoid finish();\n\tprotected byte[] getBytes(IgniteBiTuple<WALPointer,WALRecord> record);\n\tprotected byte[] getHeader();\n\t// Handling one more record during iteration over WAL.\n\tvoid handle(IgniteBiTuple<WALPointer,WALRecord> record);\n}", "des": "Handler to print raw pages data into file for further diagnostic."}
{"index": 932, "repo": "ignite-core-2.15.0", "code": "Class PropertiesListResult {\n\tCollection<String> properties();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "List of the distributed properties names."}
{"index": 933, "repo": "ignite-core-2.15.0", "code": "Class PropertyOperationResult {\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tString value();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of an operation with property."}
{"index": 934, "repo": "ignite-core-2.15.0", "code": "Interface PropertyUpdateClosure {\n\t// Update property on cluster using compare and set way.\n\tGridFutureAdapter<?> casUpdate(String key, Serializable expectedValue, Serializable newValue);\n\t// Update property on cluster.\n\tGridFutureAdapter<?> update(String key, Serializable newValue);\n}", "des": "Closure of cluster wide update of distributed property."}
{"index": 935, "repo": "ignite-core-2.15.0", "code": "Enum ProtocolBitmaskFeature {\n\tstatic EnumSet<ProtocolBitmaskFeature> allFeaturesAsEnumSet();\n\tstatic EnumSet<ProtocolBitmaskFeature> enumSet(byte[] bytes);\n\tint featureId();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ProtocolBitmaskFeature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ProtocolBitmaskFeature[] values();\n}", "des": "Defines supported bitmask features for thin client."}
{"index": 936, "repo": "ignite-core-2.15.0", "code": "Class ProtocolContext {\n\t// Check that feature is supported by the server.\n\tvoid checkFeatureSupported(ProtocolBitmaskFeature feature);\n\tEnumSet<ProtocolBitmaskFeature> features();\n\tboolean isFeatureSupported(ProtocolBitmaskFeature feature);\n\tboolean isFeatureSupported(ProtocolVersionFeature feature);\n\t// Check if the feature was supported in the protocol version.\n\tstatic boolean isFeatureSupported(ProtocolVersion ver, ProtocolVersionFeature feature);\n\tProtocolVersion version();\n}", "des": "Protocol Context."}
{"index": 937, "repo": "ignite-core-2.15.0", "code": "Class Query<R> {\n\t// Gets optional page size, if 0, then default is used.\n\tint getPageSize();\n\t// Returns true if this query should be executed on local node only.\n\tboolean isLocal();\n\t// Prepares the partitions.\n\tprotected int[] prepare(int[] parts);\n\t// Sets whether this query should be executed on local node only.\n\tQuery<R> setLocal(boolean loc);\n\t// Sets optional page size, if 0, then default is used.\n\tQuery<R> setPageSize(int pageSize);\n}", "des": "Main API for configuring and executing cache queries. Supported queries are: SQL Fields query.Provides SQL way with full syntax to access cache data. See SqlFieldsQuery for details. Full-text query. Uses full-text search engine based on Apache Lucene engine. See TextQuery for details. Scan query. Provides effective and flexible way to full cache\\partition scan. See ScanQuery for details. Continuous query. Provides flexible way to process all existed cache data and all future cache updates as well. See ContinuousQuery for details. Spi query. Allow run queries for pluggable user query engine implementation. See SpiQuery for details."}
{"index": 938, "repo": "ignite-core-2.15.0", "code": "Interface QueryCursor<T> {\n\t// Closes all resources related to this cursor.\n\tvoid close();\n\t// Gets all query results and stores them in the collection.\n\tList<T> getAll();\n}", "des": "Query result cursor. Implements Iterable only for convenience, e.g. Iterable.iterator() can be obtained only once. Also if iteration is started then getAll() method calls are prohibited."}
{"index": 939, "repo": "ignite-core-2.15.0", "code": "Enum QueryCursorImpl.State {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QueryCursorImpl.State valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QueryCursorImpl.State[] values();\n}", "des": "Query cursor state"}
{"index": 940, "repo": "ignite-core-2.15.0", "code": "Interface QueryEngineConfiguration {\n\t// Is this query engine should be used by default.\n\tboolean isDefault();\n\t// Sets whether this query engine should be used by default.\n\tQueryEngineConfiguration setDefault(boolean isDflt);\n}", "des": "Interface for the configuration of the query engine."}
{"index": 941, "repo": "ignite-core-2.15.0", "code": "Interface QueryEngineConfigurationEx {\n\t// Query engine class.\n\tClass<? extends QueryEngine> engineClass();\n\t// Query engine name.\n\tString engineName();\n}", "des": "Internal interface for the query engine configuration."}
{"index": 942, "repo": "ignite-core-2.15.0", "code": "Class QueryEntityIndexDescriptor {\n\t// Adds field to this index.\n\tvoid addField(String field, int orderNum, boolean descending);\n\t// Specifies order of the index for each indexed field.\n\tboolean descending(String field);\n\t// Gets all fields to be indexed.\n\tCollection<String> fields();\n\t// Gets inline size for SORTED index.\n\tint inlineSize();\n\tString name();\n\t// Gets index type.\n\tQueryIndexType type();\n}", "des": "Index descriptor."}
{"index": 943, "repo": "ignite-core-2.15.0", "code": "Class QueryEntityPatch {\n\t// Builder method for patch with conflicts.\n\tstatic QueryEntityPatch conflict(String conflicts);\n\t// Builder method for empty patch.\n\tstatic QueryEntityPatch empty();\n\tString getConflictsMessage();\n\tCollection<SchemaAbstractOperation> getPatchOperations();\n\t// Check for conflict in this patch.\n\tboolean hasConflict();\n\tboolean isEmpty();\n\t// Builder method for patch with operations.\n\tstatic QueryEntityPatch patch(Collection<SchemaAbstractOperation> patchOperations);\n}", "des": "Query entity patch which contain SchemaAbstractOperation operations for changing query entity. This patch can only add properties to entity and can't remove them. Other words, the patch will contain only add operations (e.g.: SchemaAlterTableAddColumnOperation, SchemaIndexCreateOperation ) and not remove ones. It contain only add operation because at the moment we don't have history of schema operations and by current state we can't understand some property was already deleted or it has not been added yet."}
{"index": 944, "repo": "ignite-core-2.15.0", "code": "Class QueryFieldAccessor {\n\tString getPropertyName();\n\tClass<?> getType();\n\t// Get property value from given object.\n\tObject getValue(Object obj);\n\t// Set property value on given object.\n\tvoid setValue(Object obj, Object newVal);\n}", "des": "Accessor that deals with fields."}
{"index": 945, "repo": "ignite-core-2.15.0", "code": "Class QueryIndexDescriptorImpl {\n\t// Adds field to this index.\n\tQueryIndexDescriptorImpl addField(String field, int orderNum, boolean descending);\n\t// Specifies order of the index for each indexed field.\n\tboolean descending(String field);\n\t// Gets all fields to be indexed.\n\tCollection<String> fields();\n\t// Gets inline size for SORTED index.\n\tint inlineSize();\n\tString name();\n\t// Gets index type.\n\tQueryIndexType type();\n\tQueryTypeDescriptorImpl typeDescriptor();\n}", "des": "Index descriptor."}
{"index": 946, "repo": "ignite-core-2.15.0", "code": "Enum QueryIndexType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable QueryIndexType fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QueryIndexType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QueryIndexType[] values();\n}", "des": "Index type."}
{"index": 947, "repo": "ignite-core-2.15.0", "code": "Class QueryMethodsAccessor {\n\tString getPropertyName();\n\tClass<?> getType();\n\t// Get property value from given object.\n\tObject getValue(Object obj);\n\t// Set property value on given object.\n\tvoid setValue(Object obj, Object newVal);\n}", "des": "Getter and setter methods based accessor."}
{"index": 948, "repo": "ignite-core-2.15.0", "code": "Interface QueryMetrics {\n\t// Gets average execution time of query.\n\tdouble averageTime();\n\t// Gets total number execution of query.\n\tint executions();\n\t// Gets total number of times a query execution failed.\n\tint fails();\n\t// Gets maximum execution time of query.\n\tlong maximumTime();\n\t// Gets minimum execution time of query.\n\tlong minimumTime();\n}", "des": "Cache query metrics used to obtain statistics on query."}
{"index": 949, "repo": "ignite-core-2.15.0", "code": "Interface QueryMXBean {\n\t// Kills continuous query by the identifier.\n\tvoid cancelContinuous(String originNodeId, String routineId);\n\t// Kills scan query by the identifiers.\n\tvoid cancelScan(String originNodeId, String cacheName, Long id);\n\t// Kills SQL query by the identifier.\n\tvoid cancelSQL(String id);\n}", "des": "Query MXBean interface."}
{"index": 950, "repo": "ignite-core-2.15.0", "code": "Interface QueryPropertyAccessor {\n\tString getPropertyName();\n\tClass<?> getType();\n\t// Get property value from given object.\n\tObject getValue(Object obj);\n\t// Set property value on given object.\n\tvoid setValue(Object obj, Object newVal);\n}", "des": "Way of accessing a property - either via field or getter and setter methods."}
{"index": 951, "repo": "ignite-core-2.15.0", "code": "Class QueryReadOnlyMethodsAccessor {\n\tString getPropertyName();\n\tClass<?> getType();\n\t// Get property value from given object.\n\tObject getValue(Object obj);\n\t// Set property value on given object.\n\tvoid setValue(Object obj, Object newVal);\n}", "des": "Accessor with getter only."}
{"index": 952, "repo": "ignite-core-2.15.0", "code": "Class QuerySysIndexDescriptorImpl {\n\t// Specifies order of the index for each indexed field.\n\tboolean descending(String field);\n\t// Gets all fields to be indexed.\n\tCollection<String> fields();\n\t// Gets inline size for SORTED index.\n\tint inlineSize();\n\tString name();\n\t// Gets index type.\n\tQueryIndexType type();\n}", "des": "Sys Indexes descriptor."}
{"index": 953, "repo": "ignite-core-2.15.0", "code": "Class QueueViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(QueueView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. QueueView attributes walker."}
{"index": 954, "repo": "ignite-core-2.15.0", "code": "Class RandomLruPageReplacementPolicyFactory {\n\t// Create page replacement policy.\n\tPageReplacementPolicy create(org.apache.ignite.internal.processors.cache.persistence.pagemem.PageMemoryImpl.Segment seg, long ptr, int pagesCnt);\n\t// Calculaete amount of memory required to service pagesCnt pages.\n\tlong requiredMemory(int pagesCnt);\n}", "des": "RandomLruPageReplacementPolicy factory."}
{"index": 955, "repo": "ignite-core-2.15.0", "code": "Interface ReadOnlyMetricManager {\n\t// Adds listener of metrics registry creation events.\n\tvoid addMetricRegistryCreationListener(Consumer<ReadOnlyMetricRegistry> lsnr);\n\t// Adds listener of metrics registry remove events.\n\tvoid addMetricRegistryRemoveListener(Consumer<ReadOnlyMetricRegistry> lsnr);\n}", "des": "Read only metric manager."}
{"index": 956, "repo": "ignite-core-2.15.0", "code": "Enum ReadRepairStrategy {\n\t// Provides strategy by name.\n\tstatic ReadRepairStrategy fromString(String name);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReadRepairStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReadRepairStrategy[] values();\n}", "des": "Read repair strategies."}
{"index": 957, "repo": "ignite-core-2.15.0", "code": "Interface RecordDataSerializer {\n\t// Reads record data of type from buffer in.\n\tWALRecord readRecord(WALRecord.RecordType type, ByteBufferBackedDataInput in, int size);\n\t// Calculates size of record data.\n\tint size(WALRecord record);\n\t// Writes record data to buffer buf.\n\tvoid writeRecord(WALRecord record, ByteBuffer buf);\n}", "des": "Interface to provide size, read and write operations with WAL records without any headers and meta information."}
{"index": 958, "repo": "ignite-core-2.15.0", "code": "Class RecordDataV1Serializer {\n\t// Return shared cache context.\n\tGridCacheSharedContext cctx();\n\tprotected int dataSize(DataRecord dataRec);\n\tprotected int entrySize(DataEntry entry);\n\t// Reads record data of type from buffer in.\n\tWALRecord readRecord(WALRecord.RecordType type, ByteBufferBackedDataInput in, int size);\n\t// Calculates size of record data.\n\tint size(WALRecord record);\n\t// Writes record data to buffer buf.\n\tvoid writeRecord(WALRecord rec, ByteBuffer buf);\n}", "des": "Record data V1 serializer."}
{"index": 959, "repo": "ignite-core-2.15.0", "code": "Interface RecordIO {\n\t// Reads record data with headers from in.\n\tWALRecord readWithHeaders(ByteBufferBackedDataInput in, WALPointer expPtr);\n\t// Calculates and returns size of record data and headers.\n\tint sizeWithHeaders(WALRecord record);\n\t// Writes record data with headers to buf.\n\tvoid writeWithHeaders(WALRecord record, ByteBuffer buf);\n}", "des": "Internal interface to provide size, read and write operations of WAL records including record header and data."}
{"index": 960, "repo": "ignite-core-2.15.0", "code": "Interface RecordSerializer {\n\t// Loads record from input\n\tWALRecord readRecord(FileInput in, WALPointer expPtr);\n\t// Calculates record size in byte including expected wal pointer, CRC and type field\n\tint size(WALRecord record);\n\tint version();\n\t// Flag to write (or not) wal pointer to record\n\tboolean writePointer();\n\tvoid writeRecord(WALRecord record, ByteBuffer buf);\n}", "des": "Record serializer."}
{"index": 961, "repo": "ignite-core-2.15.0", "code": "Class RecordV2Serializer {\n\t// Loads record from input\n\tWALRecord readRecord(FileInput in, WALPointer expPtr);\n\t// Calculates record size in byte including expected wal pointer, CRC and type field\n\tint size(WALRecord record);\n\tint version();\n\t// Flag to write (or not) wal pointer to record\n\tboolean writePointer();\n\tvoid writeRecord(WALRecord record, ByteBuffer buf);\n}", "des": "Record V2 serializer. Stores records in following format: Record type from WALRecord.RecordType.index() incremented by 1 WAL pointer to double check consistency Record length Data CRC or zero padding"}
{"index": 962, "repo": "ignite-core-2.15.0", "code": "Class RecoveryLastReceivedMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tlong received();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Recovery acknowledgment message."}
{"index": 963, "repo": "ignite-core-2.15.0", "code": "Class ReentrantLockViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ReentrantLockView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ReentrantLockView attributes walker."}
{"index": 964, "repo": "ignite-core-2.15.0", "code": "Class ReentrantReadWriteLockWithTracking {\n\t// Queries the number of reentrant read holds on this lock by the current thread.\n\tint getReadHoldCount();\n\t// Queries the number of read locks held for this lock.\n\tint getReadLockCount();\n\t// Queries if the write lock is held by the current thread.\n\tboolean isWriteLockedByCurrentThread();\n\tlong lockWaitThreshold();\n\tReentrantReadWriteLock.ReadLock readLock();\n\tReentrantReadWriteLock.WriteLock writeLock();\n}", "des": "ReentrantReadWriteLock adapter with readLock tracking."}
{"index": 965, "repo": "ignite-core-2.15.0", "code": "Enum ReservationReason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReservationReason valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReservationReason[] values();\n}", "des": "Represent a reason by that a WAL history was bounded."}
{"index": 966, "repo": "ignite-core-2.15.0", "code": "Enum RestQueryRequest.QueryType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RestQueryRequest.QueryType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RestQueryRequest.QueryType[] values();\n}", "des": "Supported query types."}
{"index": 967, "repo": "ignite-core-2.15.0", "code": "Enum RolloverType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RolloverType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RolloverType[] values();\n}", "des": "Defines WAL logging type with regard to segment rollover."}
{"index": 968, "repo": "ignite-core-2.15.0", "code": "Interface ScannerHandler {\n\t// Execute 'then' handler after 'this'.\n\tdefault ScannerHandler andThen(ScannerHandler then);\n\t// Method which called after all iteration would be finished.\n\tdefault void finish();\n\t// Handling one more record during iteration over WAL.\n\tvoid handle(IgniteBiTuple<WALPointer,WALRecord> record);\n\t// Make string from given wal record.\n\tstatic String toStringRecord(WALRecord walRecord);\n}", "des": "Scanner handler which provide ability to do some handling on each record during iteration."}
{"index": 969, "repo": "ignite-core-2.15.0", "code": "Class ScanQueryViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ScanQueryView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ScanQueryView attributes walker."}
{"index": 970, "repo": "ignite-core-2.15.0", "code": "Class ScheduleIndexRebuildJobRes {\n\tMap<String,Set<String>> cacheToIndexes();\n\tSet<String> notFoundCacheNames();\n\tSet<String> notFoundGroupNames();\n\tMap<String,Set<String>> notFoundIndexes();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of the ScheduleIndexRebuildJob."}
{"index": 971, "repo": "ignite-core-2.15.0", "code": "Class ScheduleIndexRebuildTaskArg {\n\tSet<String> cacheGroups();\n\tMap<String,Set<String>> cacheToIndexes();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for the ScheduleIndexRebuildTask."}
{"index": 972, "repo": "ignite-core-2.15.0", "code": "Class ScheduleIndexRebuildTaskRes {\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tMap<UUID,ScheduleIndexRebuildJobRes> results();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of the ScheduleIndexRebuildTask."}
{"index": 973, "repo": "ignite-core-2.15.0", "code": "Class SchemaDescriptor {\n\tvoid add(TableDescriptor tbl);\n\t// Increments counter for number of caches having this schema.\n\tboolean decrementUsageCount();\n\t// Drop table.\n\tvoid drop(TableDescriptor tbl);\n\t// Increments counter for number of caches having this schema.\n\tvoid incrementUsageCount();\n\tboolean predefined();\n\tString schemaName();\n\tTableDescriptor tableByName(String tblName);\n\tTableDescriptor tableByTypeName(String cacheName, String typeName);\n\tCollection<TableDescriptor> tables();\n}", "des": "Local database schema object."}
{"index": 974, "repo": "ignite-core-2.15.0", "code": "Class SchemaIndexCacheStat {\n\t// Adds statistics from stat to the current statistics.\n\tvoid accumulate(SchemaIndexCacheStat stat);\n\t// Adds to number of scanned keys given scanned.\n\tvoid add(int scanned);\n\t// Adds type to indexed types.\n\tvoid addType(QueryTypeDescriptorImpl type);\n\tint scannedKeys();\n\tCollection<String> typeNames();\n\tCollection<QueryTypeDescriptorImpl> types();\n}", "des": "Class for accumulation of record types and number of indexed records in index tree."}
{"index": 975, "repo": "ignite-core-2.15.0", "code": "Class SchemaIndexCacheVisitorImpl {\n\t// This method is called before creating or rebuilding indexes.\n\tprotected void beforeExecute();\n\t// Visit cache entries and pass them to closure.\n\tvoid visit(SchemaIndexCacheVisitorClosure clo);\n}", "des": "Visitor who create/rebuild indexes in parallel by partition for a given cache."}
{"index": 976, "repo": "ignite-core-2.15.0", "code": "Class SchemaOperationManager {\n\t// Handle node finish.\n\tvoid onNodeFinished(UUID nodeId, @Nullable SchemaOperationException err);\n\t// Handle node leave event.\n\tvoid onNodeLeave(UUID nodeId, ClusterNode curCrd);\n\t// Map operation handling.\n\tvoid start();\n\tSchemaOperationWorker worker();\n}", "des": "Schema operation manager."}
{"index": 977, "repo": "ignite-core-2.15.0", "code": "Class SchemaOperationWorker {\n\t// The implementation should provide the execution body for this runnable.\n\tprotected void body();\n\tboolean cacheRegistered();\n\t// Cancel operation.\n\tvoid cancel();\n\tIgniteInternalFuture future();\n\tboolean nop();\n\tSchemaAbstractOperation operation();\n\t// Perform initialization routine.\n\tSchemaOperationWorker start();\n}", "des": "Schema operation executor."}
{"index": 978, "repo": "ignite-core-2.15.0", "code": "Class SchemaProposeDiscoveryMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t@Nullable IgniteUuid deploymentId();\n\tvoid deploymentId(IgniteUuid depId);\n\t@Nullable SchemaOperationException error();\n\tboolean exchange();\n\tvoid exchange(boolean exchange);\n\tboolean hasError();\n\tboolean initialized();\n\tboolean isMutable();\n\t// Set error.\n\tvoid onError(SchemaOperationException err);\n\tString schemaName();\n}", "des": "Schema change propose discovery message."}
{"index": 979, "repo": "ignite-core-2.15.0", "code": "Enum Scope {\n\t// Created Scope from it's index.\n\tstatic Scope fromIndex(short idx);\n\tshort idx();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Scope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Scope[] values();\n}", "des": "Tracing span scope."}
{"index": 980, "repo": "ignite-core-2.15.0", "code": "Class SecurityAwareCustomMessageWrapper {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoverySpiCustomMessage ackMessage();\n\t// Gets security Subject ID.\n\tUUID securitySubjectId();\n}", "des": "Extends CustomMessageWrapper with ID of security subject that initiated the current message."}
{"index": 981, "repo": "ignite-core-2.15.0", "code": "Class SecurityAwareIoPool {\n\t// Gets the Executor for this Pool.\n\tExecutor executor();\n\t// Gets the numeric identifier of the pool.\n\tbyte id();\n}", "des": "Wrapper of IoPool that executes tasks in security context that was actual when task was added to pool queue."}
{"index": 982, "repo": "ignite-core-2.15.0", "code": "Class SecurityCredentials {\n\tboolean equals(Object o);\n\t// Gets login.\n\tObject getLogin();\n\t// Gets password.\n\tObject getPassword();\n\t// Gets user-specific object.\n\t@Nullable Object getUserObject();\n\tvoid readExternal(ObjectInput in);\n\t// Sets login.\n\tvoid setLogin(Object login);\n\t// Sets password.\n\tvoid setPassword(Object password);\n\t// Sets user-specific object.\n\tvoid setUserObject(@Nullable Object userObj);\n\tvoid writeExternal(ObjectOutput out);\n}", "des": "Security credentials used for node authentication. Security credentials are provided by SecurityCredentialsProvider which is specified on node startup in configuration."}
{"index": 983, "repo": "ignite-core-2.15.0", "code": "Enum SecurityPermission {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable SecurityPermission fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SecurityPermission valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SecurityPermission[] values();\n}", "des": "Supported security permissions within grid. Permissions are specified on per-cache, per-task or per-service level."}
{"index": 984, "repo": "ignite-core-2.15.0", "code": "Enum SecuritySubjectType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable SecuritySubjectType fromOrdinal(byte ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SecuritySubjectType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SecuritySubjectType[] values();\n}", "des": "Supported security subject types. Subject type can be retrieved form SecuritySubject.type() method."}
{"index": 985, "repo": "ignite-core-2.15.0", "code": "Enum SegmentationPolicy {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable SegmentationPolicy fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SegmentationPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SegmentationPolicy[] values();\n}", "des": "Policy that defines how node will react on topology segmentation. Note that default segmentation policy is defined by IgniteConfiguration.DFLT_SEG_PLC property."}
{"index": 986, "repo": "ignite-core-2.15.0", "code": "Class SegmentedLruPageList {\n\t// Add page to the tail of protected or probationary LRU list.\n\tvoid addToTail(int pageIdx, boolean protectedPage);\n\t// Move page to the tail of protected LRU list.\n\tvoid moveToTail(int pageIdx);\n\t// Remove page from the head of LRU list.\n\tint poll();\n\t// Remove page from LRU list by page index.\n\tvoid remove(int pageIdx);\n\t// Memory required to service pagesCnt pages.\n\tstatic long requiredMemory(int pagesCnt);\n}", "des": "Pages Segmented-LRU (SLRU) list implementation."}
{"index": 987, "repo": "ignite-core-2.15.0", "code": "Class SegmentedLruPageReplacementPolicy {\n\t// Existing page touched.\n\tvoid onHit(long relPtr);\n\t// New page added.\n\tvoid onMiss(long relPtr);\n\t// Page removed from the page memory.\n\tvoid onRemove(long relPtr);\n\t// Finds page to replace.\n\tlong replace();\n}", "des": "Segmented-LRU page replacement policy implementation."}
{"index": 988, "repo": "ignite-core-2.15.0", "code": "Class SegmentedLruPageReplacementPolicyFactory {\n\t// Create page replacement policy.\n\tPageReplacementPolicy create(org.apache.ignite.internal.processors.cache.persistence.pagemem.PageMemoryImpl.Segment seg, long ptr, int pagesCnt);\n\t// Calculaete amount of memory required to service pagesCnt pages.\n\tlong requiredMemory(int pagesCnt);\n}", "des": "SegmentedLruPageReplacementPolicy factory."}
{"index": 989, "repo": "ignite-core-2.15.0", "code": "Enum SegmentedRingByteBuffer.BufferMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SegmentedRingByteBuffer.BufferMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SegmentedRingByteBuffer.BufferMode[] values();\n}", "des": "Buffer mode."}
{"index": 990, "repo": "ignite-core-2.15.0", "code": "Class SemaphoreViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SemaphoreView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SemaphoreView attributes walker."}
{"index": 991, "repo": "ignite-core-2.15.0", "code": "Interface Service {\n\t// Cancels this service.\n\tdefault void cancel();\n\t// Starts execution of this service.\n\tdefault void execute();\n\t// Pre-initializes service before execution.\n\tdefault void init();\n}", "des": "An instance of grid-managed service. Grid-managed services may be deployed from IgniteServices facade or directly from grid configuration at startup. Deployment Whenever service is deployed, Ignite will automatically calculate how many instances of this service should be deployed on each node within the cluster. Whenever service is deployed on a cluster node, Ignite will call execute() method on that service. It is up to the user to control whenever the service should exit from the execute method. For example, user may choose to implement service as follows: public class MyIgniteService implements Service { ... // Example of ignite resource injection. All resources are optional. // You should inject resources only as needed. @IgniteInstanceResource private Ignite ignite; @ServiceContextResource private ServiceContext ctx; ... @Override public void cancel() { // No-op. } @Override public void execute() { // Loop until service is cancelled. while (!ctx.isCancelled()) { // Do something. ... } } } Consecutively, this service can be deployed as follows: ... IgniteServices svcs = ignite.services(); svcs.deployClusterSingleton(\"mySingleton\", new MyIgniteService()); Or from grid configuration on startup: IgniteConfiguration gridCfg = new IgniteConfiguration(); IgniteServiceConfiguration svcCfg = new IgniteServiceConfiguration(); // Configuration for cluster-singleton service. svcCfg.setName(\"mySingleton\"); svcCfg.setMaxPerNodeCount(1); svcCfg.setTotalCount(1); svcCfg.setService(new MyIgniteService()); gridCfg.setServiceConfiguration(svcCfg); ... Ignition.start(gridCfg); Cancellation Services can be cancelled by calling any of the cancel methods on IgniteServices API. Whenever a deployed service is cancelled, Ignite will automatically call cancel() method on that service."}
{"index": 992, "repo": "ignite-core-2.15.0", "code": "Interface ServiceCallContext {\n\t// Get the string attribute.\n\tString attribute(String name);\n\t// Get the binary attribute.\n\tbyte[] binaryAttribute(String name);\n\t// Create a context builder.\n\tstatic ServiceCallContextBuilder builder();\n}", "des": "Service call context."}
{"index": 993, "repo": "ignite-core-2.15.0", "code": "Class ServiceCallContextBuilder {\n\tServiceCallContext build();\n\t// Put binary attribute.\n\tServiceCallContextBuilder put(String name, byte[] value);\n\t// Put string attribute.\n\tServiceCallContextBuilder put(String name, String value);\n}", "des": "Service call context builder."}
{"index": 994, "repo": "ignite-core-2.15.0", "code": "Class ServiceCallContextImpl {\n\t// Get the string attribute.\n\tString attribute(String name);\n\t// Get the binary attribute.\n\tbyte[] binaryAttribute(String name);\n\tMap<String,Object> values();\n}", "des": "Service call context implementation."}
{"index": 995, "repo": "ignite-core-2.15.0", "code": "Interface ServiceContext {\n\t// Gets affinity key used for key-to-node affinity calculation.\n\t<K> K affinityKey();\n\t// Gets cache name used for key-to-node affinity calculation.\n\t@Nullable String cacheName();\n\t// Gets context of the current service call.\n\t@Nullable ServiceCallContext currentCallContext();\n\t// Gets service execution ID.\n\tUUID executionId();\n\t// Get flag indicating whether service has been cancelled or not.\n\tboolean isCancelled();\n\t// Gets service name.\n\tString name();\n}", "des": "Service execution context. This context is provided using ServiceContextResource annotation and contains information about specific service execution."}
{"index": 996, "repo": "ignite-core-2.15.0", "code": "Class ServiceDeploymentProcessId {\n\t// Gets message type.\n\tshort directType();\n\tboolean equals(Object o);\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tIgniteUuid requestId();\n\tAffinityTopologyVersion topologyVersion();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Service deployment process' identifier."}
{"index": 997, "repo": "ignite-core-2.15.0", "code": "Class ServiceViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(ServiceView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. ServiceView attributes walker."}
{"index": 998, "repo": "ignite-core-2.15.0", "code": "Class SetViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SetView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SetView attributes walker."}
{"index": 999, "repo": "ignite-core-2.15.0", "code": "Interface SharedFsCheckpointSpiMBean {\n\t// Gets path to the directory where all checkpoints are saved.\n\tString getCurrentDirectoryPath();\n\t// Gets collection of all configured paths where checkpoints can be saved.\n\tCollection<String> getDirectoryPaths();\n}", "des": "Management bean that provides general administrative and configuration information about shared file system checkpoints."}
{"index": 1000, "repo": "ignite-core-2.15.0", "code": "Class ShortInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected ShortIndexKey get0(long pageAddr, int off);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, ShortIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining Short values."}
{"index": 1001, "repo": "ignite-core-2.15.0", "code": "Enum ShutdownPolicy {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic ShutdownPolicy fromOrdinal(int ord);\n\t// Return shutdown policy matching to string.\n\tShutdownPolicy fromString(String val);\n\tint index();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ShutdownPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ShutdownPolicy[] values();\n}", "des": "This class reperesents a policy of shutdown. The policy specifies data safety guarantees on ordinary shutdown of one or more cluster nodes."}
{"index": 1002, "repo": "ignite-core-2.15.0", "code": "Class SingleCursor<T> {\n\t// Note that this implementation violates the contract of GridCusror.\n\tT get();\n\t// Attempt to move cursor position forward.\n\tboolean next();\n}", "des": "Cursor that holds single value only."}
{"index": 1003, "repo": "ignite-core-2.15.0", "code": "Class SingleNodeMessage<R extends Serializable> {\n\t// Gets message type.\n\tshort directType();\n\tThrowable error();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tboolean hasError();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tUUID processId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tR response();\n\tint type();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Single node result message."}
{"index": 1004, "repo": "ignite-core-2.15.0", "code": "Class SnapshotFilesFailureMessage {\n\t// Gets message type.\n\tshort directType();\n\tString errorMessage();\n\tSnapshotFilesFailureMessage errorMessage(String errMsg);\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tString id();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Message indicating a failure occurred during processing snapshot files request."}
{"index": 1005, "repo": "ignite-core-2.15.0", "code": "Interface SnapshotHandler<T> {\n\t// Processing the results of the invoke(SnapshotHandlerContext) method received from all nodes.\n\tdefault void complete(String name, Collection<SnapshotHandlerResult<T>> results);\n\t// Local processing of a snapshot operation.\n\tT invoke(SnapshotHandlerContext ctx);\n\t// Snapshot handler type.\n\tSnapshotHandlerType type();\n}", "des": "Snapshot operation handler."}
{"index": 1006, "repo": "ignite-core-2.15.0", "code": "Enum SnapshotHandlerType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SnapshotHandlerType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SnapshotHandlerType[] values();\n}", "des": "Type of snapshot operation handler."}
{"index": 1007, "repo": "ignite-core-2.15.0", "code": "Class SnapshotMetadataVerificationTaskArg {\n\tint incrementIndex();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tString snapshotName();\n\tString snapshotPath();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Input parameters for checking snapshot metadata."}
{"index": 1008, "repo": "ignite-core-2.15.0", "code": "Class SnapshotPartitionsVerifyTaskArg {\n\tCollection<String> cacheGroupNames();\n\tboolean check();\n\tMap<ClusterNode,List<SnapshotMetadata>> clusterMetadata();\n\tint incrementIndex();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tString snapshotPath();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Input parameters for checking snapshot partitions consistency task."}
{"index": 1009, "repo": "ignite-core-2.15.0", "code": "Class SnapshotPartitionsVerifyTaskResult {\n\tMap<ClusterNode,Exception> exceptions();\n\tIdleVerifyResultV2 idleVerifyResult();\n\tMap<ClusterNode,List<SnapshotMetadata>> metas();\n\t// Print formatted result to the given printer.\n\tvoid print(Consumer<String> printer);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "The result of execution snapshot partitions verify task which besides calculating partition hashes of IdleVerifyResultV2 also contains the snapshot metadata distribution across the cluster."}
{"index": 1010, "repo": "ignite-core-2.15.0", "code": "Class SnapshotViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SnapshotView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SnapshotView attributes walker."}
{"index": 1011, "repo": "ignite-core-2.15.0", "code": "Class SocketStreamer<T,K,V> {\n\t// Sets server address.\n\tvoid setAddr(InetAddress addr);\n\t// Sets message converter.\n\tvoid setConverter(SocketMessageConverter<T> converter);\n\t// Sets message delimiter.\n\tvoid setDelimiter(byte[] delim);\n\t// Sets direct mode flag.\n\tvoid setDirectMode(boolean directMode);\n\t// Sets port number.\n\tvoid setPort(int port);\n\t// Sets threadds amount.\n\tvoid setThreads(int threads);\n\t// Starts streamer.\n\tvoid start();\n\t// Stops streamer.\n\tvoid stop();\n}", "des": "Server that receives data from TCP socket, converts it to key-value pairs using StreamTupleExtractor and streams into IgniteDataStreamer instance."}
{"index": 1012, "repo": "ignite-core-2.15.0", "code": "Class SortedEvictionPolicyFactory<K,V> {\n\tSortedEvictionPolicy<K,V> create();\n\t// Gets entries comparator.\n\tComparator<EvictableEntry<K,V>> getComp();\n\t// Sets entries comparator.\n\tvoid setComp(Comparator<EvictableEntry<K,V>> comp);\n}", "des": "Factory class for SortedEvictionPolicy. Creates cache Eviction policy which will select the minimum cache entry for eviction."}
{"index": 1013, "repo": "ignite-core-2.15.0", "code": "Enum SortOrder {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SortOrder valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SortOrder[] values();\n}", "des": "Enum of possible sort orders."}
{"index": 1014, "repo": "ignite-core-2.15.0", "code": "Interface Span {\n\t// Logs work to span.\n\tSpan addLog(Supplier<String> logDescSupplier);\n\t// Adds tag to span with String value.\n\tSpan addTag(String tagName, Supplier<String> tagValSupplier);\n\t// Ends span.\n\tSpan end();\n\tSet<Scope> includedScopes();\n\tdefault boolean isChainable(Scope scope);\n\tboolean isEnded();\n\t// Explicitly set status for span.\n\tSpan setStatus(SpanStatus spanStatus);\n\tSpanType type();\n}", "des": "Logical piece of a trace that represents a single operation. Each unit work is called a Span in a trace. Spans include metadata about the work, including the time spent in the step (latency), status, time events, attributes, links. You can use tracing to debug errors and latency issues in your applications."}
{"index": 1015, "repo": "ignite-core-2.15.0", "code": "Class SpanImpl {\n\t// Logs work to span.\n\tSpan addLog(Supplier<String> logDescSupplier);\n\t// Adds tag to span with String value.\n\tSpan addTag(String tagName, Supplier<String> tagValSupplier);\n\t// Ends span.\n\tSpan end();\n\tSet<Scope> includedScopes();\n\tboolean isEnded();\n\t// Explicitly set status for span.\n\tSpan setStatus(SpanStatus spanStatus);\n\tSpiSpecificSpan spiSpecificSpan();\n\tSpanType type();\n}", "des": "Implementation of a Span"}
{"index": 1016, "repo": "ignite-core-2.15.0", "code": "Enum SpanStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SpanStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SpanStatus[] values();\n}", "des": "Various statuses for Spans execution."}
{"index": 1017, "repo": "ignite-core-2.15.0", "code": "Enum SpanType {\n\tstatic SpanType fromIndex(int idx);\n\tint index();\n\tboolean rootSpan();\n\tScope scope();\n\tString spanName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SpanType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SpanType[] values();\n}", "des": "List of span type names used in appropriate sub-systems."}
{"index": 1018, "repo": "ignite-core-2.15.0", "code": "Class SpiQuery<K,V> {\n\t// Gets SQL arguments.\n\tObject[] getArgs();\n\t// Sets SQL arguments.\n\tSpiQuery<K,V> setArgs(Object... args);\n\t// Sets whether this query should be executed on local node only.\n\tSpiQuery<K,V> setLocal(boolean loc);\n\t// Sets optional page size, if 0, then default is used.\n\tSpiQuery<K,V> setPageSize(int pageSize);\n}", "des": "Query to be used by IndexingSpi implementations."}
{"index": 1019, "repo": "ignite-core-2.15.0", "code": "Interface SpiSpecificSpan {\n\t// Logs work to span.\n\tSpiSpecificSpan addLog(String logDesc);\n\t// Adds tag to span with String value.\n\tSpiSpecificSpan addTag(String tagName, String tagVal);\n\t// Ends span.\n\tSpiSpecificSpan end();\n\tboolean isEnded();\n\t// Explicitly set status for span.\n\tSpiSpecificSpan setStatus(SpanStatus spanStatus);\n}", "des": "Logical piece of a trace that insulates spi specific logic."}
{"index": 1020, "repo": "ignite-core-2.15.0", "code": "Class SqlAnalyzeCommand {\n\t// Build statistics object configuration from command arguments.\n\tStatisticsObjectConfiguration buildConfig(StatisticsTarget target, Map<String,String> params);\n\tCollection<StatisticsObjectConfiguration> configurations();\n\t// Parse command.\n\tSqlCommand parse(SqlLexer lex);\n}", "des": "ANALYZE command to mark object for statistics collection."}
{"index": 1021, "repo": "ignite-core-2.15.0", "code": "Class SqlCommandProcessor {\n\t// Commits active transaction if exists.\n\tprotected void finishActiveTxIfNecessary();\n\tboolean isCommandSupported(SqlCommand cmd);\n\t// Execute command.\n\t@Nullable FieldsQueryCursor<List<?>> runCommand(SqlCommand cmdNative);\n}", "des": "Processor responsible for execution of native Ignite commands."}
{"index": 1022, "repo": "ignite-core-2.15.0", "code": "Class SqlIndexViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlIndexView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlIndexView attributes walker."}
{"index": 1023, "repo": "ignite-core-2.15.0", "code": "Class SqlKillQueryCommand {\n\tboolean async();\n\tUUID nodeId();\n\tlong nodeQueryId();\n\t// Parse command.\n\tSqlCommand parse(SqlLexer lex);\n\t// Parse global SQL query id.\n\tstatic T2<UUID,Long> parseGlobalQueryId(String globalQryId);\n\tString schemaName();\n\tvoid schemaName(String schemaName);\n}", "des": "KILL QUERY command."}
{"index": 1024, "repo": "ignite-core-2.15.0", "code": "Class SqlLexer {\n\tboolean eod();\n\t// Get next token without lexer state change.\n\tSqlLexerToken lookAhead();\n\tint position();\n\t// Shift lexer to the next position.\n\tboolean shift();\n\tString sql();\n\tString token();\n\tchar tokenFirstChar();\n\tint tokenPosition();\n\tSqlLexerTokenType tokenType();\n}", "des": "SQL lexer."}
{"index": 1025, "repo": "ignite-core-2.15.0", "code": "Enum SqlLexerTokenType {\n\tCharacter asChar();\n\tString asString();\n\t// Get token type for character.\n\tstatic SqlLexerTokenType forChar(char c);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlLexerTokenType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlLexerTokenType[] values();\n}", "des": "Lexer token type."}
{"index": 1026, "repo": "ignite-core-2.15.0", "code": "Class SqlParser {\n\t// Last successfully parsed sql statement.\n\tString lastCommandSql();\n\t// Get next command.\n\tSqlCommand nextCommand();\n\t// Not yet parsed part of the sql query.\n\tString remainingSql();\n}", "des": "SQL parser."}
{"index": 1027, "repo": "ignite-core-2.15.0", "code": "Class SqlQueryExecutionEvent {\n\t// Gets query arguments.\n\t@Nullable Object[] arguments();\n\t// Gets security subject ID.\n\t@Nullable UUID subjectId();\n\t// Gets query text.\n\t@Nullable String text();\n}", "des": "Query execution event. This event is triggered after a corresponding SQL query validated and before it is executed. Unlike EventType.EVT_CACHE_QUERY_EXECUTED, EventType.EVT_SQL_QUERY_EXECUTION is fired only once for a request and does not relate to a specific cache."}
{"index": 1028, "repo": "ignite-core-2.15.0", "code": "Class SqlQueryHistoryViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlQueryHistoryView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlQueryHistoryView attributes walker."}
{"index": 1029, "repo": "ignite-core-2.15.0", "code": "Class SqlQueryViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlQueryView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlQueryView attributes walker."}
{"index": 1030, "repo": "ignite-core-2.15.0", "code": "Class SqlSchemaViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlSchemaView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlSchemaView attributes walker."}
{"index": 1031, "repo": "ignite-core-2.15.0", "code": "Class SQLServerDialect {\n\tString escape(String ident);\n\tboolean hasMerge();\n\t// Construct query to get ranges bounds.\n\tString loadCacheSelectRangeQuery(String fullTblName, Collection<String> keyCols);\n\t// Construct merge query.\n\tString mergeQuery(String fullTblName, Collection<String> keyCols, Collection<String> uniqCols);\n}", "des": "A dialect compatible with the Microsoft SQL Server database."}
{"index": 1032, "repo": "ignite-core-2.15.0", "code": "Class SqlStatisticsCommands {\n\t// Parse command.\n\tSqlCommand parse(SqlLexer lex);\n\tprotected String[] parseColumnList(SqlLexer lex, boolean allowParams);\n\tString schemaName();\n\tvoid schemaName(String schemaName);\n\tCollection<StatisticsTarget> targets();\n\t// Test if it is the end of command.\n\tprotected boolean tryEnd(SqlLexer lex);\n}", "des": "Base class for statistics related commands."}
{"index": 1033, "repo": "ignite-core-2.15.0", "code": "Class SqlTableColumnViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlTableColumnView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlTableColumnView attributes walker."}
{"index": 1034, "repo": "ignite-core-2.15.0", "code": "Class SqlTableViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlTableView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlTableView attributes walker."}
{"index": 1035, "repo": "ignite-core-2.15.0", "code": "Class SqlViewColumnViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlViewColumnView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlViewColumnView attributes walker."}
{"index": 1036, "repo": "ignite-core-2.15.0", "code": "Class SqlViewViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SqlViewView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. SqlViewView attributes walker."}
{"index": 1037, "repo": "ignite-core-2.15.0", "code": "Enum SslMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SslMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SslMode[] values();\n}", "des": "SSL/TLS modes."}
{"index": 1038, "repo": "ignite-core-2.15.0", "code": "Enum SslProtocol {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SslProtocol valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SslProtocol[] values();\n}", "des": "SSL Protocol."}
{"index": 1039, "repo": "ignite-core-2.15.0", "code": "Class StaticMvccQueryTracker {\n\tGridCacheContext context();\n\t// Marks tracker as done.\n\tvoid onDone();\n\t// Requests version on coordinator.\n\tIgniteInternalFuture<MvccSnapshot> requestSnapshot();\n\tMvccSnapshot snapshot();\n\tAffinityTopologyVersion topologyVersion();\n}", "des": "Simple MVCC tracker used only as an Mvcc snapshot holder."}
{"index": 1040, "repo": "ignite-core-2.15.0", "code": "Class StatisticsColumnConfigurationViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(StatisticsColumnConfigurationView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. StatisticsColumnConfigurationView attributes walker."}
{"index": 1041, "repo": "ignite-core-2.15.0", "code": "Class StatisticsColumnGlobalDataViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(StatisticsColumnGlobalDataView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. StatisticsColumnGlobalDataView attributes walker."}
{"index": 1042, "repo": "ignite-core-2.15.0", "code": "Class StatisticsColumnLocalDataViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(StatisticsColumnLocalDataView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. StatisticsColumnLocalDataView attributes walker."}
{"index": 1043, "repo": "ignite-core-2.15.0", "code": "Class StatisticsColumnOverrides {\n\t// Get number of distinct values in column.\n\tLong distinct();\n\tboolean equals(Object o);\n\t// Get number of null values in column.\n\tLong nulls();\n\t// Get average size in bytes.\n\tInteger size();\n\t// Get total number of values in column.\n\tLong total();\n}", "des": "Configuration overrides."}
{"index": 1044, "repo": "ignite-core-2.15.0", "code": "Class StatisticsColumnPartitionDataViewWalker {\n\tint count();\n\tList<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(StatisticsColumnPartitionDataView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. StatisticsColumnPartitionDataView attributes walker."}
{"index": 1045, "repo": "ignite-core-2.15.0", "code": "Class StatisticsDecimalMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tBigDecimal value();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "H2 Decimal."}
{"index": 1046, "repo": "ignite-core-2.15.0", "code": "Class StatisticsKeyMessage {\n\tList<String> colNames();\n\t// Gets message type.\n\tshort directType();\n\tboolean equals(Object o);\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tString obj();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tString schema();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Key, describing the object of statistics. For example: table with some columns."}
{"index": 1047, "repo": "ignite-core-2.15.0", "code": "Class StatisticsObjectConfiguration.Diff {\n\t// Statistics columns to drop.\n\tSet<String> dropCols();\n\t// Statistics columns to update.\n\tMap<String,StatisticsColumnConfiguration> updateCols();\n}", "des": "Difference between current and target configuration."}
{"index": 1048, "repo": "ignite-core-2.15.0", "code": "Class StatisticsProcessor {\n\t// Start gathering.\n\tvoid start();\n\t// Stop gathering.\n\tvoid stop();\n\t// Update statistics for the given key to actual state.\n\tvoid updateLocalStatistics(LocalStatisticsGatheringContext ctx);\n}", "des": "Process all tasks, related to statistics repository. Mostly - statistics collection, invalidation (due to configuration, topology or obsolescence issues) and loads. Input tasks should be scheduled throug management pool while gathering pool used to process heavy operations in parallel. Manage gathering pool and it's jobs. To guarantee gracefull shutdown: 1) Any job can be added into gatheringInProgress only in active state (check after adding) 2) State can be disactivated only after cancelling all jobs and getting busyLock block 3) Each job should do it's work in busyLock with periodically checking of it's cancellation status."}
{"index": 1049, "repo": "ignite-core-2.15.0", "code": "Class StatisticsResponse {\n\tStatisticsObjectData data();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tUUID reqId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Response for statistics request."}
{"index": 1050, "repo": "ignite-core-2.15.0", "code": "Class StatisticsTarget {\n\t// Columns array.\n\tString[] columns();\n\tboolean equals(Object o);\n\t// Statistic key (schema and table name).\n\tStatisticsKey key();\n\t// Object name.\n\tString obj();\n\tString schema();\n}", "des": "Target to collect statistics by."}
{"index": 1051, "repo": "ignite-core-2.15.0", "code": "Enum StatisticsType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable StatisticsType fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StatisticsType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StatisticsType[] values();\n}", "des": "Types of statistics width."}
{"index": 1052, "repo": "ignite-core-2.15.0", "code": "Enum StatisticsUsageState {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic StatisticsUsageState fromOrdinal(int ord);\n\t// Return statistics state matching to string.\n\tStatisticsUsageState fromString(String val);\n\tint index();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StatisticsUsageState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StatisticsUsageState[] values();\n}", "des": "Statistics usage state."}
{"index": 1053, "repo": "ignite-core-2.15.0", "code": "Class StopNodeOrHaltFailureHandler {\n\t// Actual failure handling.\n\tprotected boolean handle(Ignite ignite, FailureContext failureCtx);\n\t// Get stop node timeout.\n\tlong timeout();\n\t// Get try stop.\n\tboolean tryStop();\n}", "des": "Handler will try to stop node if tryStop value is true. If node can't be stopped during provided timeout or tryStop value is false then JVM process will be terminated forcibly using Runtime.getRuntime().halt()."}
{"index": 1054, "repo": "ignite-core-2.15.0", "code": "Class StreamTransformer<K,V> {\n\t// Creates a new transformer based on instance of CacheEntryProcessor.\n\tstatic <K,V> StreamTransformer<K,V> from(CacheEntryProcessor<K,V,Object> ep);\n\t// Updates cache with batch of entries.\n\tvoid receive(IgniteCache<K,V> cache, Collection<Map.Entry<K,V>> entries);\n}", "des": "Convenience adapter to transform update existing values in streaming cache based on the previously cached value."}
{"index": 1055, "repo": "ignite-core-2.15.0", "code": "Class StreamVisitor<K,V> {\n\t// Creates a new visitor based on instance of IgniteBiInClosure.\n\tstatic <K,V> StreamVisitor<K,V> from(IgniteBiInClosure<IgniteCache<K,V>,Map.Entry<K,V>> c);\n\t// Updates cache with batch of entries.\n\tvoid receive(IgniteCache<K,V> cache, Collection<Map.Entry<K,V>> entries);\n}", "des": "Convenience adapter to visit every key-value tuple in the stream. Note, that the visitor does not update the cache. If the tuple needs to be stored in the cache, then cache.put(...) should be called explicitly."}
{"index": 1056, "repo": "ignite-core-2.15.0", "code": "Class StringConcatReducer {\n\t// Collects given value.\n\tboolean collect(String s);\n\t// Reduces collected values into one.\n\tString reduce();\n}", "des": "Reducer that concatenates strings using provided delimiter."}
{"index": 1057, "repo": "ignite-core-2.15.0", "code": "Class StripedCompositeReadWriteLock {\n\t// Queries the number of reentrant read holds on this lock by the current thread.\n\tint getReadHoldCount();\n\t// Queries if the write lock is held by the current thread.\n\tboolean isWriteLockedByCurrentThread();\n\t@NotNull Lock readLock();\n\t@NotNull Lock writeLock();\n}", "des": "ReadWriteLock with striping mechanics. Compared to ReentrantReadWriteLock it has slightly improved performance of ReadWriteLock.readLock() operations at the cost of ReadWriteLock.writeLock() operations and memory consumption. It also supports reentrancy semantics like ReentrantReadWriteLock."}
{"index": 1058, "repo": "ignite-core-2.15.0", "code": "Class StripedExecutorTaskViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(StripedExecutorTaskView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. StripedExecutorTaskView attributes walker."}
{"index": 1059, "repo": "ignite-core-2.15.0", "code": "Class StrListAppenderBlock {\n\t// Accepts a portion of input.\n\tvoid accept(String[] elements, boolean isLastPortion);\n\t// Sets the output list.\n\tvoid output(List<List<Object>> output);\n}", "des": "The PipelineBlock which appends its input to a user-supplied list."}
{"index": 1060, "repo": "ignite-core-2.15.0", "code": "Class SystemDataRegionConfiguration {\n\t// Initial size of a data region reserved for system cache.\n\tlong getInitialSize();\n\t// Maximum data region size in bytes reserved for system cache.\n\tlong getMaxSize();\n\t// Sets initial size of a data region reserved for system cache.\n\tSystemDataRegionConfiguration setInitialSize(long initSize);\n\t// Sets maximum data region size in bytes reserved for system cache.\n\tSystemDataRegionConfiguration setMaxSize(long maxSize);\n}", "des": "This class allows defining system data region configuration with various parameters for Apache Ignite page memory (see DataStorageConfiguration. This class is similiar to DataRegionConfiguration, but with restricted set of properties."}
{"index": 1061, "repo": "ignite-core-2.15.0", "code": "Interface SystemViewExporterSpi {\n\t// Sets export filter.\n\tvoid setExportFilter(Predicate<SystemView<?>> filter);\n\t// Sets system view registry that SPI should export.\n\tvoid setSystemViewRegistry(ReadOnlySystemViewRegistry registry);\n}", "des": "Exporter of system view to the external recepient. Expected, that each implementation would support some specific protocol. Implementation of this Spi should work by pull paradigm. So after start SPI should respond to some incoming request. HTTP servlet or JMX bean are good examples of expected implementations."}
{"index": 1062, "repo": "ignite-core-2.15.0", "code": "Interface SystemViewRowAttributeWalker<R> {\n\tint count();\n\tdefault List<String> filtrableAttributes();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(R row, SystemViewRowAttributeWalker.AttributeWithValueVisitor visitor);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor visitor);\n}", "des": "Utility class for quick iteration over row properties."}
{"index": 1063, "repo": "ignite-core-2.15.0", "code": "Class TcpCommunicationConnectionCheckFuture {\n\tlong endTime();\n\tIgniteUuid id();\n\tvoid init(long timeout);\n\t// Callback to notify that future is finished.\n\tboolean onDone(@Nullable BitSet res, @Nullable Throwable err);\n\t// Local event callback.\n\tvoid onEvent(Event evt);\n\t// Timeout callback.\n\tvoid onTimeout();\n}", "des": "Tcp Communication Connection Check Future."}
{"index": 1064, "repo": "ignite-core-2.15.0", "code": "Class TcpConnectionRequestDiscoveryMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\tint connectionIndex();\n\t// Creates new discovery cache if message caused topology version change.\n\tDiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n\tUUID receiverNodeId();\n}", "des": "Message is part of communication via discovery protocol. It is used when a node (say node A) cannot establish a communication connection to other node (node B) in topology due to firewall or network configuration and sends this message requesting inverse connection: node B receives request and opens communication connection to node A thus allowing both nodes to communicate to each other."}
{"index": 1065, "repo": "ignite-core-2.15.0", "code": "Class TcpDiscoveryDiscardMessage {\n\t// Flag indicating whether the ID to discard is for a custom message or not.\n\tboolean customMessageDiscard();\n\t// Gets message ID to discard (this and all preceding).\n\tIgniteUuid msgId();\n}", "des": "Message sent by coordinator when some operation handling is over. All receiving nodes should discard this and all preceding messages in local buffers."}
{"index": 1066, "repo": "ignite-core-2.15.0", "code": "Class TcpDiscoveryHandshakeRequest {\n\t// Gets topology change flag.\n\tboolean changeTopology();\n\t// Sets topology change flag and previous node ID to check.\n\tvoid changeTopology(UUID prevNodeId);\n\t// Gets expected previous node ID to check.\n\tUUID checkPreviousNodeId();\n}", "des": "Handshake request."}
{"index": 1067, "repo": "ignite-core-2.15.0", "code": "Class TcpDiscoveryHandshakeResponse {\n\tboolean clientAck();\n\tvoid clientAck(boolean clientAck);\n\tboolean isDiscoveryDataPacketCompression();\n\t// Gets order of the node sent the response.\n\tlong order();\n\t// Sets order of the node sent the response.\n\tvoid order(long order);\n\t// Gets previous node alive flag.\n\tboolean previousNodeAlive();\n\t// Sets topology change flag.\n\tvoid previousNodeAlive(boolean prevNodeAlive);\n\tvoid setDiscoveryDataPacketCompression(boolean discoveryDataPacketCompression);\n}", "des": "Handshake response."}
{"index": 1068, "repo": "ignite-core-2.15.0", "code": "Enum TcpDiscoverySpiState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TcpDiscoverySpiState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TcpDiscoverySpiState[] values();\n}", "des": "State of local node TcpDiscoverySpi."}
{"index": 1069, "repo": "ignite-core-2.15.0", "code": "Class TcpDiscoveryStatusCheckMessage {\n\t// Gets creator node.\n\t@Nullable TcpDiscoveryNode creatorNode();\n\t// Gets creator node addresses.\n\tCollection<InetSocketAddress> creatorNodeAddrs();\n\tboolean equals(Object obj);\n\t// Gets failed node id.\n\tUUID failedNodeId();\n\t// Gets creator status.\n\tint status();\n\t// Sets creator node status (should be set by coordinator).\n\tvoid status(int status);\n}", "des": "Message sent by node to its next to ensure that next node and connection to it are alive. Receiving node should send it across the ring, until message does not reach coordinator. Coordinator responds directly to node."}
{"index": 1070, "repo": "ignite-core-2.15.0", "code": "Class TcpInverseConnectionResponseMessage {\n\tint connectionIndex();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Inverse connection response message sent by client node as a response to inverse connection request received by discovery. The main purpose of this message is to communicate back to server node connection index of a thread waiting for establishing of communication connection."}
{"index": 1071, "repo": "ignite-core-2.15.0", "code": "Class TextQueryReducer<R> {\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tR nextX();\n\tprotected CompletableFuture<Comparator<NodePage<R>>> pageComparator();\n}", "des": "Reducer for TextQuery results."}
{"index": 1072, "repo": "ignite-core-2.15.0", "code": "Class ThreadLocalRowHandlerHolder {\n\t// Clear index row handler for current context.\n\tstatic void clearRowHandler();\n\t// Get index row handler for current context.\n\tstatic InlineIndexRowHandler rowHandler();\n\t// Set index row handler for current context.\n\tstatic void rowHandler(InlineIndexRowHandler rowHnd);\n}", "des": "Holds an index row handler during work session with an index tree."}
{"index": 1073, "repo": "ignite-core-2.15.0", "code": "Class TimeInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected TimeIndexKey get0(long pageAddr, int off);\n\t// Return inlined size for specified key.\n\tprotected int inlineSize0(TimeIndexKey key);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, TimeIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining TimeIndexKey values."}
{"index": 1074, "repo": "ignite-core-2.15.0", "code": "Interface TimeoutStrategy {\n\t// Check if total timeout will be reached by now.\n\tdefault boolean checkTimeout();\n\t// Check if total timeout will be reached in now() + timeInFut.\n\tboolean checkTimeout(long timeInFut);\n\t// Get next timeout.\n\tdefault long nextTimeout();\n\t// Get next timeout based on previously timeout calculated by strategy.\n\tlong nextTimeout(long currTimeout);\n}", "des": "Strategy to calculate next timeout and check if total timeout reached."}
{"index": 1075, "repo": "ignite-core-2.15.0", "code": "Class TimestampInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected TimestampIndexKey get0(long pageAddr, int off);\n\t// Return inlined size for specified key.\n\tprotected int inlineSize0(TimestampIndexKey key);\n\tboolean isComparableTo(IndexKey key);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, TimestampIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining TimestampIndexKey values."}
{"index": 1076, "repo": "ignite-core-2.15.0", "code": "Class TraceableMessagesHandler {\n\t// Called when message is received.\n\tvoid afterReceive(TraceableMessage msg);\n\t// Called when message is going to be send.\n\tvoid beforeSend(TraceableMessage msg);\n\t// Injects a sub-span to msg as child span contained in given parent.\n\t<T extends TraceableMessage>T branch(T msg, TraceableMessage parent);\n\tvoid finishProcessing(TraceableMessage msg);\n}", "des": "Helper to handle traceable messages."}
{"index": 1077, "repo": "ignite-core-2.15.0", "code": "Class TracingConfigurationCoordinates.Builder {\n\t// Builder's build() method.\n\tTracingConfigurationCoordinates build();\n\t// Builder method that allows to set optional label attribute.\n\t@NotNull TracingConfigurationCoordinates.Builder withLabel(@Nullable String lb);\n}", "des": "TracingConfigurationCoordinates builder."}
{"index": 1078, "repo": "ignite-core-2.15.0", "code": "Class TracingConfigurationParameters.Builder {\n\t// Builder's build() method.\n\tTracingConfigurationParameters build();\n\t// Builder method that allows to set included scopes.\n\t@NotNull TracingConfigurationParameters.Builder withIncludedScopes(Set<Scope> includedScopes);\n\t// Builder method that allows to set sampling rate.\n\t@NotNull TracingConfigurationParameters.Builder withSamplingRate(double samplingRate);\n}", "des": "TracingConfigurationParameters builder."}
{"index": 1079, "repo": "ignite-core-2.15.0", "code": "Interface TracingSpi<S extends SpiSpecificSpan> {\n\t// Creates Span given name and explicit parent.\n\tS create(@NotNull String name, @Nullable byte[] serializedSpan);\n\t// Creates Span given name and explicit parent.\n\tS create(@NotNull String name, S parentSpan);\n\t// Serializes span to byte array to send context over network.\n\tbyte[] serialize(S span);\n\tbyte type();\n}", "des": "Tracing SPI interface."}
{"index": 1080, "repo": "ignite-core-2.15.0", "code": "Enum TracingSpiType {\n\tbyte index();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TracingSpiType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TracingSpiType[] values();\n}", "des": "Type of the tracing spi."}
{"index": 1081, "repo": "ignite-core-2.15.0", "code": "Class TrackingPageDeltaRecord {\n\t// Apply changes from this delta to the given page.\n\tvoid applyDelta(PageMemory pageMem, long pageAddr);\n\tlong lastSuccessfulSnapshotTag();\n\tlong nextSnapshotTag();\n\t// Page Id which should be marked as changed\n\tlong pageIdToMark();\n\tWALRecord.RecordType type();\n}", "des": "Delta record for updates in tracking pages"}
{"index": 1082, "repo": "ignite-core-2.15.0", "code": "Enum TransactionConcurrency {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable TransactionConcurrency fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TransactionConcurrency valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TransactionConcurrency[] values();\n}", "des": "Transaction concurrency control. See Transaction for more information on transaction concurrency controls."}
{"index": 1083, "repo": "ignite-core-2.15.0", "code": "Enum TransactionIsolation {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable TransactionIsolation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TransactionIsolation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TransactionIsolation[] values();\n}", "des": "Defines different cache transaction isolation levels. See Transaction documentation for more information about cache transaction isolation levels."}
{"index": 1084, "repo": "ignite-core-2.15.0", "code": "Class TransactionsHashRecord {\n\tObject localConsistentId();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tObject remoteConsistentId();\n\tint transactionHash();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Represents committed transactions hash for a pair of nodes."}
{"index": 1085, "repo": "ignite-core-2.15.0", "code": "Enum TransactionState {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable TransactionState fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TransactionState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TransactionState[] values();\n}", "des": "Cache transaction state."}
{"index": 1086, "repo": "ignite-core-2.15.0", "code": "Class TransactionViewWalker {\n\tint count();\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(SystemViewRowAttributeWalker.AttributeVisitor v);\n\t// Calls visitor for each row attribute.\n\tvoid visitAll(TransactionView row, SystemViewRowAttributeWalker.AttributeWithValueVisitor v);\n}", "des": "Generated by org.apache.ignite.codegen.SystemViewRowAttributeWalkerGenerator. TransactionView attributes walker."}
{"index": 1087, "repo": "ignite-core-2.15.0", "code": "Class TransformFilteringIterator<T2,T1> {\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tT2 nextX();\n\t// This method is the same as Iterator.remove(), but allows for failure with exception.\n\tvoid removeX();\n}", "des": "Iterator from given iter and optional filtering predicate."}
{"index": 1088, "repo": "ignite-core-2.15.0", "code": "Enum TransmissionPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TransmissionPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TransmissionPolicy[] values();\n}", "des": "Class represents ways of data handling for a file ready to be sent through an opened transmission sender session. It is necessary to choose which type of handler will be used and how file should be handled prior to sending file to the remote node."}
{"index": 1089, "repo": "ignite-core-2.15.0", "code": "Enum TxKeyLockType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable TxKeyLockType fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TxKeyLockType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TxKeyLockType[] values();\n}", "des": "Describes transaction key lock ownership type."}
{"index": 1090, "repo": "ignite-core-2.15.0", "code": "Class TxLock {\n\tboolean candiate();\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tUUID nearNodeId();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tboolean owner();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tboolean requested();\n\tlong threadId();\n\tGridCacheVersion txId();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Corresponds to one GridCacheMvccCandidate from local MVCC candidates queue. There is one exclusion: TxLock instance with OWNERSHIP_REQUESTED corresponds to lock request to remote node from near node that isn't primary node for key."}
{"index": 1091, "repo": "ignite-core-2.15.0", "code": "Class TxLockList {\n\tvoid add(TxLock txLock);\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tboolean isEmpty();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tList<TxLock> txLocks();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "List of transaction locks for particular key."}
{"index": 1092, "repo": "ignite-core-2.15.0", "code": "Enum TxMappingType {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable TxMappingType fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TxMappingType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TxMappingType[] values();\n}", "des": "Describes transaction mapping type."}
{"index": 1093, "repo": "ignite-core-2.15.0", "code": "Class TxVerboseId {\n\t// Parses instance from text representation (can be UUID or GridCacheVersion).\n\tstatic TxVerboseId fromString(String text);\n\tGridCacheVersion gridCacheVersion();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tIgniteUuid uuid();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for FetchNearXidVersionTask."}
{"index": 1094, "repo": "ignite-core-2.15.0", "code": "Class TxVerboseKey {\n\tTxKeyLockType lockType();\n\tGridCacheVersion ownerVersion();\n\tboolean read();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tString txKey();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Encapsulates info about transaction key and its lock ownership for --tx --info output."}
{"index": 1095, "repo": "ignite-core-2.15.0", "code": "Class UnsafeMemoryProvider {\n\tvoid initialize(long[] sizes);\n\t// Attempts to allocate next memory region.\n\tDirectMemoryRegion nextRegion();\n\t// Shuts down the provider.\n\tvoid shutdown(boolean deallocate);\n}", "des": "Memory provider implementation based on unsafe memory access."}
{"index": 1096, "repo": "ignite-core-2.15.0", "code": "Class UnsortedCacheQueryReducer<R> {\n\t// This method is the same as Iterator.hasNext(), but allows for failure with exception.\n\tboolean hasNextX();\n\t// This method is the same as Iterator.next(), but allows for failure with exception.\n\tR nextX();\n}", "des": "Reducer of cache query results, no ordering of results is provided."}
{"index": 1097, "repo": "ignite-core-2.15.0", "code": "Class UnwrapDataEntry {\n\t// Unwraps key value from cache key object into primitive boxed type or source class.\n\tObject unwrappedKey();\n\t// Unwraps value value from cache value object into primitive boxed type or source class.\n\tObject unwrappedValue();\n}", "des": "Data Entry for automatic unwrapping key and value from Data Entry"}
{"index": 1098, "repo": "ignite-core-2.15.0", "code": "Class UnwrapMvccDataEntry {\n\t// Unwraps key value from cache key object into primitive boxed type or source class.\n\tObject unwrappedKey();\n\t// Unwraps value value from cache value object into primitive boxed type or source class.\n\tObject unwrappedValue();\n}", "des": "Data Entry for automatic unwrapping key and value from Mvcc Data Entry"}
{"index": 1099, "repo": "ignite-core-2.15.0", "code": "Interface UnwrappedDataEntry {\n\t// Unwraps key value from cache key object into primitive boxed type or source class.\n\tObject unwrappedKey();\n\t// Unwraps value value from cache value object into primitive boxed type or source class.\n\tObject unwrappedValue();\n}", "des": "Interface for Data Entry for automatic unwrapping key and value from Data Entry"}
{"index": 1100, "repo": "ignite-core-2.15.0", "code": "Class UserAcceptedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n}", "des": "Is sent as an acknowledgement for end (with success or error) of user management operation on the cluster (see UserProposedMessage and UserManagementOperation)."}
{"index": 1101, "repo": "ignite-core-2.15.0", "code": "Class UserAuthenticateRequestMessage {\n\t// Gets message type.\n\tshort directType();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tIgniteUuid id();\n\tString name();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tString password();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Message is sent from client to coordinator node when a user needs to authorize on client node."}
{"index": 1102, "repo": "ignite-core-2.15.0", "code": "Class UserAuthenticateResponseMessage {\n\t// Gets message type.\n\tshort directType();\n\tString errorMessage();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tIgniteUuid id();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tboolean success();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Is sent from coordinator node to client to deliver the results of the user authentication."}
{"index": 1103, "repo": "ignite-core-2.15.0", "code": "Class UserCacheObjectByteArrayImpl {\n\t// Prepares cache object for cache (e.g. copies user-provided object if needed).\n\tCacheObject prepareForCache(CacheObjectContext ctx);\n\t<T> T value(CacheObjectValueContext ctx, boolean cpy);\n\t// Deserializes a value from an internal representation.\n\t<T> T value(CacheObjectValueContext ctx, boolean cpy, ClassLoader ldr);\n}", "des": "Wraps value provided by user, must be copied before stored in cache."}
{"index": 1104, "repo": "ignite-core-2.15.0", "code": "Enum UserManagementOperation.OperationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic UserManagementOperation.OperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic UserManagementOperation.OperationType[] values();\n}", "des": "User action type."}
{"index": 1105, "repo": "ignite-core-2.15.0", "code": "Class UserManagementOperationFinishedMessage {\n\t// Gets message type.\n\tshort directType();\n\tString errorMessage();\n\t// Gets fields count.\n\tbyte fieldsCount();\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\tIgniteUuid operationId();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tboolean success();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Message indicating that user operation is finished locally on the node. Server nodes send this message to coordinator when the user operation is finished."}
{"index": 1106, "repo": "ignite-core-2.15.0", "code": "Class UserProposedMessage {\n\t// Called when custom message has been handled by all nodes.\n\t@Nullable DiscoveryCustomMessage ackMessage();\n\t// Creates new discovery cache if message caused topology version change.\n\t@Nullable DiscoCache createDiscoCache(GridDiscoveryManager mgr, AffinityTopologyVersion topVer, DiscoCache discoCache);\n\tIgniteUuid id();\n\tboolean isMutable();\n}", "des": "A node sends this message when it wants to propose user operation (add / update / remove). After sending this message to the cluster sending node gets blocked until operation acknowledgement is received. UserAcceptedMessage is sent as an acknowledgement that operation is finished on the all nodes of the cluster."}
{"index": 1107, "repo": "ignite-core-2.15.0", "code": "Class UUIDCollectionMessage {\n\t// Gets message type.\n\tshort directType();\n\tboolean equals(Object o);\n\t// Gets fields count.\n\tbyte fieldsCount();\n\tstatic UUIDCollectionMessage of(UUID... uuids);\n\t// Method called when ack message received.\n\tvoid onAckReceived();\n\t// Reads this message from provided byte buffer.\n\tboolean readFrom(ByteBuffer buf, MessageReader reader);\n\tCollection<UUID> uuids();\n\t// Writes this message to provided byte buffer.\n\tboolean writeTo(ByteBuffer buf, MessageWriter writer);\n}", "des": "Collection of UUIDs."}
{"index": 1108, "repo": "ignite-core-2.15.0", "code": "Class UuidInlineIndexKeyType {\n\t// Compares inlined and given value.\n\tint compare0(long pageAddr, int off, IndexKey key);\n\t// Restores value from inline.\n\tprotected UuidIndexKey get0(long pageAddr, int off);\n\t// Return inlined size for specified key.\n\tprotected int inlineSize0(UuidIndexKey val);\n\t// Puts given value into inline index tree.\n\tprotected int put0(long pageAddr, int off, UuidIndexKey key, int maxSize);\n}", "des": "Inline index key implementation for inlining UUID values."}
{"index": 1109, "repo": "ignite-core-2.15.0", "code": "Class VacuumMetricsReducer {\n\t// Collects given value.\n\tboolean collect(@Nullable VacuumMetrics metrics);\n\t// Reduces collected values into one.\n\tVacuumMetrics reduce();\n}", "des": "Vacuum metrics reducer."}
{"index": 1110, "repo": "ignite-core-2.15.0", "code": "Class ValidateIndexesCheckSizeIssue {\n\t// Return error.\n\tThrowable error();\n\t// Return index size.\n\tlong indexSize();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Issue when checking size of cache and index."}
{"index": 1111, "repo": "ignite-core-2.15.0", "code": "Class ValidateIndexesCheckSizeResult {\n\t// Return cache size.\n\tlong cacheSize();\n\t// Return issues when checking size of cache and index.\n\tCollection<ValidateIndexesCheckSizeIssue> issues();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of checking size cache and index."}
{"index": 1112, "repo": "ignite-core-2.15.0", "code": "Class ValidateIndexesPartitionResult {\n\tbyte getProtocolVersion();\n\tList<IndexValidationIssue> issues();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tboolean reportIssue(IndexValidationIssue t);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Encapsulates intermediate results of validation of SQL index."}
{"index": 1113, "repo": "ignite-core-2.15.0", "code": "Class VisorBaselineNode {\n\t@NotNull Collection<VisorBaselineNode.ResolvedAddresses> getAddrs();\n\tMap<String,Object> getAttributes();\n\tString getConsistentId();\n\t@Nullable Long getOrder();\n\tbyte getProtocolVersion();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for BaselineNode."}
{"index": 1114, "repo": "ignite-core-2.15.0", "code": "Class VisorBaselineNode.ResolvedAddresses {\n\tString address();\n\tString hostname();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Simple data class for storing (hostname, address) pairs"}
{"index": 1115, "repo": "ignite-core-2.15.0", "code": "Enum VisorBaselineOperation {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable VisorBaselineOperation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VisorBaselineOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VisorBaselineOperation[] values();\n}", "des": "Baseline operation types."}
{"index": 1116, "repo": "ignite-core-2.15.0", "code": "Class VisorBaselineTaskArg {\n\tVisorBaselineAutoAdjustSettings getAutoAdjustSettings();\n\tList<String> getConsistentIds();\n\tVisorBaselineOperation getOperation();\n\tbyte getProtocolVersion();\n\tlong getTopologyVersion();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for VisorBaselineTask."}
{"index": 1117, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheAffinityConfiguration {\n\tString getFunction();\n\tString getMapper();\n\tint getPartitionedBackups();\n\tint getPartitions();\n\t@Nullable Boolean isExcludeNeighbors();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for affinity configuration properties."}
{"index": 1118, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheConfigurationCollectorTaskArg {\n\tCollection<String> getCacheNames();\n\tbyte getProtocolVersion();\n\tString getRegex();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for VisorCacheConfigurationCollectorTask."}
{"index": 1119, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheEvictionConfiguration {\n\t@Nullable String getFilter();\n\t@Nullable String getPolicy();\n\t@Nullable Integer getPolicyMaxSize();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for eviction configuration properties."}
{"index": 1120, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheGroupEncryptionTaskArg {\n\tString groupName();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Cache group aware task argument."}
{"index": 1121, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheGroupEncryptionTaskResult<T> {\n\tMap<UUID,IgniteException> exceptions();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\tMap<UUID,T> results();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Multinode cache group encryption task result."}
{"index": 1122, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheJdbcType {\n\tString getDatabaseSchema();\n\tString getDatabaseTable();\n\tList<VisorCacheJdbcTypeField> getKeyFields();\n\tString getKeyType();\n\tList<VisorCacheJdbcTypeField> getValueFields();\n\tString getValueType();\n\tstatic List<VisorCacheJdbcType> list(javax.cache.configuration.Factory factory);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for JdbcType."}
{"index": 1123, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheJdbcTypeField {\n\tString getDatabaseName();\n\tint getDatabaseType();\n\tString getJavaName();\n\tString getJavaType();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for JdbcTypeField."}
{"index": 1124, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheMetricsTaskArg {\n\tSet<String> cacheNames();\n\tCacheMetricsOperation operation();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Task argument for VisorCacheMetricsTask."}
{"index": 1125, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheMetricsTaskResult {\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Get task result or task execution error.\n\tMap<String,Boolean> result();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result wrapper for VisorCacheMetricsTask."}
{"index": 1126, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheNearConfiguration {\n\t@Nullable Integer getNearEvictMaxSize();\n\t@Nullable String getNearEvictPolicy();\n\tint getNearStartSize();\n\tboolean isNearEnabled();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for near cache configuration properties."}
{"index": 1127, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheRebalanceConfiguration {\n\tlong getBatchesPrefetchCnt();\n\tint getBatchSize();\n\tCacheRebalanceMode getMode();\n\tlong getPartitionedDelay();\n\tint getRebalanceOrder();\n\tlong getThrottle();\n\tlong getTimeout();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for cache rebalance configuration properties."}
{"index": 1128, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheScanTaskArg {\n\tString getCacheName();\n\tint getLimit();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for VisorCacheStopTask."}
{"index": 1129, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheScanTaskResult {\n\tList<List<?>> entries();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tList<String> titles();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of running VisorCacheScanTask."}
{"index": 1130, "repo": "ignite-core-2.15.0", "code": "Class VisorCacheStopTaskArg {\n\tString getCacheName();\n\tList<String> getCacheNames();\n\tbyte getProtocolVersion();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for VisorCacheStopTask."}
{"index": 1131, "repo": "ignite-core-2.15.0", "code": "Class VisorCancelServiceTaskArg {\n\tString getName();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for VisorCancelServiceTask."}
{"index": 1132, "repo": "ignite-core-2.15.0", "code": "Class VisorClusterNode {\n\t// Get cluster node addresses.\n\tCollection<String> getAddresses();\n\t// Get cluster node attributes.\n\tMap<String,Object> getAttributes();\n\t// Get cluster node consistent id.\n\tString getConsistentId();\n\t// Get cluster node host names.\n\tCollection<String> getHostNames();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for ClusterNode."}
{"index": 1133, "repo": "ignite-core-2.15.0", "code": "Class VisorComputeCancelSessionsTaskArg {\n\tSet<IgniteUuid> getSessionIds();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Arguments for task VisorComputeCancelSessionsTask"}
{"index": 1134, "repo": "ignite-core-2.15.0", "code": "Class VisorComputeCancelSessionTaskArg {\n\tIgniteUuid getSessionId();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Arguments for task VisorComputeCancelSessionsTask"}
{"index": 1135, "repo": "ignite-core-2.15.0", "code": "Class VisorConnectivityArgs {\n\t// Get list of node ids to check connectivity to\n\t@Nullable Set<UUID> getNodeIds();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Connectivity task arguments"}
{"index": 1136, "repo": "ignite-core-2.15.0", "code": "Class VisorConnectivityResult {\n\t// Get connectivity statuses for a node\n\t@Nullable Map<ClusterNode,Boolean> getNodeIds();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Connectivity task result"}
{"index": 1137, "repo": "ignite-core-2.15.0", "code": "Class VisorContinuousQueryCancelTaskArg {\n\tUUID getNodeId();\n\tUUID getRoutineId();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Arguments of task for cancel CONTINUOUS query."}
{"index": 1138, "repo": "ignite-core-2.15.0", "code": "Class VisorFindAndDeleteGarbageInPersistenceJobResult {\n\tMap<Integer,Map<Integer,Long>> checkResult();\n\tboolean hasGarbage();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of job work which is sent between nodes."}
{"index": 1139, "repo": "ignite-core-2.15.0", "code": "Class VisorFindAndDeleteGarbageInPersistenceTaskArg {\n\tboolean deleteFoundGarbage();\n\tSet<String> getGrpNames();\n\tSet<UUID> getNodes();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "VisorFindAndDeleteGarbageInPersistenceTask arguments."}
{"index": 1140, "repo": "ignite-core-2.15.0", "code": "Class VisorFindAndDeleteGarbageInPersistenceTaskResult {\n\tMap<UUID,Exception> exceptions();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tMap<UUID,VisorFindAndDeleteGarbageInPersistenceJobResult> result();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of running VisorFindAndDeleteGarbageInPersistenceTask which would contain result from all participating nodes."}
{"index": 1141, "repo": "ignite-core-2.15.0", "code": "Class VisorIdleVerifyDumpTaskArg {\n\tbyte getProtocolVersion();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Arguments for VisorIdleVerifyDumpTask."}
{"index": 1142, "repo": "ignite-core-2.15.0", "code": "Class VisorIdleVerifyTaskResult {\n\tMap<PartitionKey,List<PartitionHashRecord>> getConflicts();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result for task VisorIdleVerifyTask"}
{"index": 1143, "repo": "ignite-core-2.15.0", "code": "Class VisorJob<A,R> {\n\t// Executes this job.\n\t@Nullable Object execute();\n\tSecurityPermissionSet requiredPermissions();\n\t// Execution logic of concrete job.\n\tprotected abstract R run(A arg);\n}", "des": "Base class for Visor jobs."}
{"index": 1144, "repo": "ignite-core-2.15.0", "code": "Class VisorMetricTaskArg {\n\tlong[] bounds();\n\tString name();\n\tlong rateTimeInterval();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Represents argument for VisorMetricTask execution."}
{"index": 1145, "repo": "ignite-core-2.15.0", "code": "Enum VisorPerformanceStatisticsOperation {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable VisorPerformanceStatisticsOperation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VisorPerformanceStatisticsOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VisorPerformanceStatisticsOperation[] values();\n}", "des": "Performance statistics operation options."}
{"index": 1146, "repo": "ignite-core-2.15.0", "code": "Class VisorPerformanceStatisticsTaskArg {\n\tVisorPerformanceStatisticsOperation operation();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Represents argument for VisorPerformanceStatisticsTask execution."}
{"index": 1147, "repo": "ignite-core-2.15.0", "code": "Class VisorQueryCancelOnInitiatorTaskArg {\n\tUUID getNodeId();\n\tlong getQueryId();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Arguments for task VisorQueryCancelOnInitiatorTask."}
{"index": 1148, "repo": "ignite-core-2.15.0", "code": "Class VisorQueryConfiguration {\n\tList<String> getIndexedTypes();\n\tlong getLongQueryWarningTimeout();\n\tList<String> getSqlFunctionClasses();\n\tString getSqlSchema();\n\tboolean isSqlEscapeAll();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for cache query configuration data."}
{"index": 1149, "repo": "ignite-core-2.15.0", "code": "Class VisorQueryIndex {\n\tList<VisorQueryIndexField> getFields();\n\tString getName();\n\tQueryIndexType getType();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for QueryIndex."}
{"index": 1150, "repo": "ignite-core-2.15.0", "code": "Class VisorQueryIndexField {\n\tString getName();\n\tboolean getSortOrder();\n\tstatic List<VisorQueryIndexField> list(QueryIndex idx);\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object for QueryEntity."}
{"index": 1151, "repo": "ignite-core-2.15.0", "code": "Class VisorReencryptionRateTaskArg {\n\t@Nullable Double rate();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Re-encryption rate task argument."}
{"index": 1152, "repo": "ignite-core-2.15.0", "code": "Class VisorScanQueryCancelTaskArg {\n\tString getCacheName();\n\tUUID getOriginNodeId();\n\tlong getQueryId();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Arguments of task for cancel SCAN query."}
{"index": 1153, "repo": "ignite-core-2.15.0", "code": "Class VisorShutdownPolicyTaskArg {\n\t// Get policy.\n\tShutdownPolicy getShutdown();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Set policy.\n\tvoid setShutdown(ShutdownPolicy shutdown);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Arguments for shutdown policy task."}
{"index": 1154, "repo": "ignite-core-2.15.0", "code": "Class VisorShutdownPolicyTaskResult {\n\t// Get policy.\n\tShutdownPolicy getShutdown();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Set policy.\n\tvoid setShutdown(ShutdownPolicy shutdown);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Shutdown policy visor trsk result."}
{"index": 1155, "repo": "ignite-core-2.15.0", "code": "Class VisorSnapshotCancelTaskArg {\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\tUUID requestId();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for the task to cancel snapshot operation."}
{"index": 1156, "repo": "ignite-core-2.15.0", "code": "Class VisorSnapshotCheckTaskArg {\n\tint incrementIndex();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\tString snapshotName();\n\tString snapshotPath();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for the task to check snapshot."}
{"index": 1157, "repo": "ignite-core-2.15.0", "code": "Class VisorSnapshotCreateTaskArg {\n\tboolean incremental();\n\tboolean onlyPrimary();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\tString snapshotName();\n\tString snapshotPath();\n\tboolean sync();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for the task to create snapshot."}
{"index": 1158, "repo": "ignite-core-2.15.0", "code": "Class VisorSnapshotRestoreTaskArg {\n\tboolean check();\n\tCollection<String> groupNames();\n\tint incrementIndex();\n\tVisorSnapshotRestoreTaskAction jobAction();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for the task to manage snapshot restore operation."}
{"index": 1159, "repo": "ignite-core-2.15.0", "code": "Enum VisorSnapshotStatusTask.SnapshotOperation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VisorSnapshotStatusTask.SnapshotOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VisorSnapshotStatusTask.SnapshotOperation[] values();\n}", "des": "Snapshot operation type."}
{"index": 1160, "repo": "ignite-core-2.15.0", "code": "Class VisorSnapshotTaskResult {\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte ver, ObjectInput in);\n\t@Nullable Object result();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Snapshot task result wrapper."}
{"index": 1161, "repo": "ignite-core-2.15.0", "code": "Enum VisorSystemViewTask.SimpleType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VisorSystemViewTask.SimpleType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VisorSystemViewTask.SimpleType[] values();\n}", "des": "Represents lightweight type descriptors."}
{"index": 1162, "repo": "ignite-core-2.15.0", "code": "Class VisorSystemViewTaskResult {\n\tList<String> attributes();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tMap<UUID,List<List<?>>> rows();\n\tList<VisorSystemViewTask.SimpleType> types();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Reperesents result of VisorSystemViewTask."}
{"index": 1163, "repo": "ignite-core-2.15.0", "code": "Class VisorTaskArgument<A> {\n\tA getArgument();\n\tList<UUID> getNodes();\n\tboolean isDebug();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Visor tasks argument."}
{"index": 1164, "repo": "ignite-core-2.15.0", "code": "Class VisorTracingConfigurationItem {\n\tboolean equals(Object o);\n\tSet<Scope> includedScopes();\n\tString label();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tDouble samplingRate();\n\tScope scope();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Data transfer object that contains scope, label, sampling rate and set of included scopes."}
{"index": 1165, "repo": "ignite-core-2.15.0", "code": "Enum VisorTracingConfigurationOperation {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable VisorTracingConfigurationOperation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VisorTracingConfigurationOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VisorTracingConfigurationOperation[] values();\n}", "des": "Tracing configuration operation options."}
{"index": 1166, "repo": "ignite-core-2.15.0", "code": "Class VisorTracingConfigurationTaskArg {\n\tVisorTracingConfigurationOperation operation();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for VisorTracingConfigurationTask."}
{"index": 1167, "repo": "ignite-core-2.15.0", "code": "Enum VisorTxOperation {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable VisorTxOperation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VisorTxOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VisorTxOperation[] values();\n}", "des": "Defines possible Visor operation on transactions."}
{"index": 1168, "repo": "ignite-core-2.15.0", "code": "Class VisorTxTaskResult {\n\tList<VisorTxInfo> getInfos();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result for VisorTxTask."}
{"index": 1169, "repo": "ignite-core-2.15.0", "code": "Class VisorWalTaskArg {\n\t// Get nodes consistent ids.\n\tList<String> getConsistentIds();\n\t// Get WAL task operation.\n\tVisorWalTaskOperation getOperation();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Argument for VisorWalTask."}
{"index": 1170, "repo": "ignite-core-2.15.0", "code": "Enum VisorWalTaskOperation {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable VisorWalTaskOperation fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VisorWalTaskOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VisorWalTaskOperation[] values();\n}", "des": "WAL Task operation types."}
{"index": 1171, "repo": "ignite-core-2.15.0", "code": "Class VisorWalTaskResult {\n\t// Get occurred errors by node consistent id.\n\tMap<String,Exception> exceptions();\n\t// Get nodes info by node consistent id.\n\tMap<String,VisorClusterNode> getNodesInfo();\n\t// Load object's specific data content.\n\tprotected void readExternalData(byte protoVer, ObjectInput in);\n\tMap<String,Collection<String>> results();\n\t// Save object's specific data content.\n\tprotected void writeExternalData(ObjectOutput out);\n}", "des": "Result of VisorWalTask."}
{"index": 1172, "repo": "ignite-core-2.15.0", "code": "Class WalFilters {\n\t// Filtering all checkpoint records.\n\tstatic Predicate<IgniteBiTuple<WALPointer,WALRecord>> checkpoint();\n\t// Filtering all records whose pageId is contained in pageOwnerIds.\n\tstatic Predicate<IgniteBiTuple<WALPointer,WALRecord>> pageOwner(Set<T2<Integer,Long>> pageOwnerIds);\n\t// Filtering all records whose partitionId is contained in partsMetaupdate.\n\tstatic Predicate<IgniteBiTuple<WALPointer,WALRecord>> partitionMetaStateUpdate(Set<T2<Integer,Integer>> partsMetaupdate);\n}", "des": "Class for holding only very basic WAL filters for using in FilteredWalIterator. *"}
{"index": 1173, "repo": "ignite-core-2.15.0", "code": "Enum WALMode {\n\t// Efficiently gets enumerated value from its ordinal.\n\tstatic @Nullable WALMode fromOrdinal(int ord);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WALMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WALMode[] values();\n}", "des": "WAL Mode. This enum defines crash recovery guarantees when Ignite persistence is enabled."}
{"index": 1174, "repo": "ignite-core-2.15.0", "code": "Enum WALRecord.RecordPurpose {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WALRecord.RecordPurpose valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WALRecord.RecordPurpose[] values();\n}", "des": "Record purposes set."}
{"index": 1175, "repo": "ignite-core-2.15.0", "code": "Enum WALRecord.RecordType {\n\tstatic WALRecord.RecordType fromIndex(int idx);\n\tint index();\n\tWALRecord.RecordPurpose purpose();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WALRecord.RecordType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WALRecord.RecordType[] values();\n}", "des": "Record type. Ordinal of this record will be written to file. Note: Do not change order of elements"}
{"index": 1176, "repo": "ignite-core-2.15.0", "code": "Class WalStateDistributedProcess {\n\tboolean completed();\n\t// Handle node finish.\n\tvoid onNodeFinished(UUID nodeId, WalStateAckMessage ack);\n\t// Handle node leave.\n\tvoid onNodeLeft(UUID nodeId);\n\tUUID operationId();\n\t// Prepare finish message based on obtained results.\n\tWalStateFinishMessage prepareFinishMessage();\n}", "des": "Distributed process governing WAL state change."}
{"index": 1177, "repo": "ignite-core-2.15.0", "code": "Interface WarmUpStrategy<T extends WarmUpConfiguration> {\n\t// Returns configuration class for mapping to strategy.\n\tClass<T> configClass();\n\t// Stop warming up.\n\tvoid stop();\n\t// Warm up.\n\tvoid warmUp(T cfg, DataRegion region);\n}", "des": "Interface for warming up."}
{"index": 1178, "repo": "ignite-core-2.15.0", "code": "Class WebSessionAttributeProcessor {\n\tVoid process(javax.cache.processor.MutableEntry<String,WebSessionEntity> entry, Object... arguments);\n\t// Reads fields from provided reader.\n\tvoid readBinary(BinaryReader reader);\n\t// Writes fields to provided writer.\n\tvoid writeBinary(BinaryWriter writer);\n}", "des": "Updates web session attributes according to updatesMap and accessTime, maxInactiveInterval."}
{"index": 1179, "repo": "ignite-core-2.15.0", "code": "Interface WeightedRandomLoadBalancingSpiMBean {\n\t// Gets weight of this node.\n\tint getNodeWeight();\n\t// Checks whether node weights are considered when doing random load balancing.\n\tboolean isUseWeights();\n}", "des": "Management MBean for WeightedRandomLoadBalancingSpi SPI."}
{"index": 1180, "repo": "ignite-core-2.15.0", "code": "Interface WorkersControlMXBean {\n\t// Returns names of all registered workers.\n\tList<String> getWorkerNames();\n\t// Stops thread by id, if exists.\n\tboolean stopThreadById(long id);\n\t// Stops thread by name, if exists and unique.\n\tboolean stopThreadByUniqueName(String name);\n\t// Terminates worker.\n\tboolean terminateWorker(String name);\n}", "des": "MBean that provides ability to terminate worker that registered in the workers registry."}
{"index": 1181, "repo": "ignite-core-2.15.0", "code": "Class WorkersControlMXBeanImpl {\n\t// Returns names of all registered workers.\n\tList<String> getWorkerNames();\n\t// Stops thread by id, if exists.\n\tboolean stopThreadById(long id);\n\t// Stops thread by name, if exists and unique.\n\tboolean stopThreadByUniqueName(String name);\n\t// Terminates worker.\n\tboolean terminateWorker(String name);\n}", "des": "MBean that provides control of system workersRegistry."}
{"index": 1182, "repo": "nutch-2.4", "code": "Enum AuthenticationTypeEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AuthenticationTypeEnum valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AuthenticationTypeEnum[] values();\n}", "des": "Authentication enum which holds authentication types for NutchServer REST API."}
{"index": 1183, "repo": "nutch-2.4", "code": "Enum AuthorizationRoleEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AuthorizationRoleEnum valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AuthorizationRoleEnum[] values();\n}", "des": "Authorization Roles enum which holds authorization roles for NutchServer REST API. Supported roles are user as USER and admin as USER"}
{"index": 1184, "repo": "nutch-2.4", "code": "Class AutomatonURLFilter {\n\t// Creates a new RegexRule.\n\tprotected RegexRule createRule(boolean sign, java.lang.String regex);\n\t// Rules specified as a config property will override rules specified as a config file.\n\tprotected java.io.Reader getRulesReader(Configuration conf);\n\tstatic void main(java.lang.String[] args);\n}", "des": "RegexURLFilterBase implementation based on the dk.brics.automaton Finite-State Automata for JavaTM."}
{"index": 1185, "repo": "nutch-2.4", "code": "Class CCIndexingFilter {\n\t// Add the features represented by a license URL.\n\tvoid addUrlFeatures(NutchDocument doc, java.lang.String urlString);\n\t// Adds fields or otherwise modifies the document that will be indexed for a parse.\n\tNutchDocument filter(NutchDocument doc, java.lang.String url, WebPage page);\n\tConfiguration getConf();\n\tjava.util.Collection<WebPage.Field> getFields();\n\tvoid setConf(Configuration conf);\n}", "des": "Adds basic searchable fields to a document."}
{"index": 1186, "repo": "nutch-2.4", "code": "Class DeflateUtils {\n\t// Returns a deflated copy of the input array.\n\tstatic byte[] deflate(byte[] in);\n\t// Returns an inflated copy of the input array.\n\tstatic byte[] inflate(byte[] in);\n\t// Returns an inflated copy of the input array.\n\tstatic byte[] inflateBestEffort(byte[] in);\n\t// Returns an inflated copy of the input array, truncated to sizeLimit bytes, if necessary.\n\tstatic byte[] inflateBestEffort(byte[] in, int sizeLimit);\n}", "des": "A collection of utility methods for working on deflated data."}
{"index": 1187, "repo": "nutch-2.4", "code": "Class DmozParser {\n\t// Command-line access.\n\tstatic void main(java.lang.String[] argv);\n\t// Iterate through all the items in this structured DMOZ file.\n\tvoid parseDmozFile(java.io.File dmozFile, int subsetDenom, boolean includeAdult, int skew, java.util.regex.Pattern topicPattern, boolean snippet);\n}", "des": "Utility that converts DMOZ RDF into a flat file of URLs to be injected."}
{"index": 1188, "repo": "nutch-2.4", "code": "Enum DomainSuffix.Status {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DomainSuffix.Status valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DomainSuffix.Status[] values();\n}", "des": "Enumeration of the status of the tld. Please see domain-suffixes.xml."}
{"index": 1189, "repo": "nutch-2.4", "code": "Class DomainSuffixes {\n\t// Return the DomainSuffix object for the extension, if extension is a top level domain returned object will be an instance of TopLevelDomain\n\tDomainSuffix get(java.lang.String extension);\n\t// Singleton instance, lazy instantination\n\tstatic DomainSuffixes getInstance();\n\t// return whether the extension is a registered domain entry\n\tboolean isDomainSuffix(java.lang.String extension);\n}", "des": "Storage class for DomainSuffix objects Note: this class is singleton"}
{"index": 1190, "repo": "nutch-2.4", "code": "Class ExtensionPoint {\n\t// Install a corresponding extension to this extension point.\n\tvoid addExtension(Extension extension);\n\t// Returns a array of extensions that listen to this extension point\n\tExtension[] getExtensions();\n\t// Returns the unique id of the extension point.\n\tjava.lang.String getId();\n\t// Returns the name of the extension point.\n\tjava.lang.String getName();\n\t// Returns a path to the xml schema of a extension point.\n\tjava.lang.String getSchema();\n}", "des": "The ExtensionPoint provide meta information of a extension point."}
{"index": 1191, "repo": "nutch-2.4", "code": "Enum FakeHandler.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FakeHandler.Mode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FakeHandler.Mode[] values();\n}", "des": "Create links to hosts generated from a pool of numHosts/numPages random names."}
{"index": 1192, "repo": "nutch-2.4", "code": "Class FileResponse {\n\t// Returns the response code.\n\tint getCode();\n\tbyte[] getContent();\n\t// Returns the value of a named header.\n\tjava.lang.String getHeader(java.lang.String name);\n\tContent toContent();\n}", "des": "FileResponse.java mimics file replies as http response. It tries its best to follow http's way for headers, response codes as well as exceptions. Comments: (1) java.net.URL and java.net.URLConnection can handle file: scheme. However they are not flexible enough, so not used in this implementation. (2) java.io.File is used for its abstractness across platforms. Warning: java.io.File API (1.4.2) does not elaborate on how special files, such as /dev/* in unix and /proc/* on linux, are treated. Tests show (a) java.io.File.isFile() return false for /dev/* (b) java.io.File.isFile() return true for /proc/* (c) java.io.File.length() return 0 for /proc/* We are probably oaky for now. Could be buggy here. How about special files on windows? (3) java.io.File API (1.4.2) does not seem to know unix hard link files. They are just treated as individual files. (4) No funcy POSIX file attributes yet. May never need?"}
{"index": 1193, "repo": "nutch-2.4", "code": "Class FSUtils {\n\t// Closes a group of MapFile readers.\n\tstatic void closeReaders(MapFile.Reader[] readers);\n\t// Closes a group of SequenceFile readers.\n\tstatic void closeReaders(SequenceFile.Reader[] readers);\n\t// Replaces the current path with the new path and if set removes the old path.\n\tstatic void replace(FileSystem fs, Path current, Path replacement, boolean removeOld);\n}", "des": "Utility methods for common filesystem operations."}
{"index": 1194, "repo": "nutch-2.4", "code": "Class FtpResponse {\n\t// Returns the response code.\n\tint getCode();\n\tbyte[] getContent();\n\t// Returns the value of a named header.\n\tjava.lang.String getHeader(java.lang.String name);\n\tContent toContent();\n}", "des": "FtpResponse.java mimics ftp replies as http response. It tries its best to follow http's way for headers, response codes as well as exceptions. Comments: In this class, all FtpException*.java thrown by Client.java and some important commons-net exceptions passed by Client.java must have been properly dealt with. They'd better not be leaked to the caller of this class."}
{"index": 1195, "repo": "nutch-2.4", "code": "Class GZIPUtils {\n\t// Returns an gunzipped copy of the input array.\n\tstatic byte[] unzip(byte[] in);\n\t// Returns an gunzipped copy of the input array.\n\tstatic byte[] unzipBestEffort(byte[] in);\n\t// Returns an gunzipped copy of the input array, truncated to sizeLimit bytes, if necessary.\n\tstatic byte[] unzipBestEffort(byte[] in, int sizeLimit);\n\t// Returns an gzipped copy of the input array.\n\tstatic byte[] zip(byte[] in);\n}", "des": "A collection of utility methods for working on GZIPed data."}
{"index": 1196, "repo": "nutch-2.4", "code": "Enum Host.Field {\n\t// Gets field's index.\n\tint getIndex();\n\t// Gets field's name.\n\tjava.lang.String getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Host.Field valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Host.Field[] values();\n}", "des": "Enum containing all data bean's fields."}
{"index": 1197, "repo": "nutch-2.4", "code": "Class Http {\n\tjava.util.Collection<WebPage.Field> getFields();\n\t// Fetches the url with a configured HTTP client and gets the response.\n\tprotected Response getResponse(java.net.URL url, WebPage page, boolean redirect);\n\t// Main method.\n\tstatic void main(java.lang.String[] args);\n\t// Reads the configuration from the Nutch configuration files and sets the configuration.\n\tvoid setConf(Configuration conf);\n}", "des": "This class is a protocol plugin that configures an HTTP client for Basic, Digest and NTLM authentication schemes for web server as well as proxy server. It takes care of HTTPS protocol as well as cookies in a single fetch session."}
{"index": 1198, "repo": "nutch-2.4", "code": "Interface HttpAuthentication {\n\t// Gets the credentials generated by the HttpAuthentication object.\n\tjava.util.List getCredentials();\n\t// Gets the realm used by the HttpAuthentication object during creation.\n\tjava.lang.String getRealm();\n}", "des": "The base level of services required for Http Authentication"}
{"index": 1199, "repo": "nutch-2.4", "code": "Class HttpResponse {\n\t// Returns the response code.\n\tint getCode();\n\t// Returns the full content of the response.\n\tbyte[] getContent();\n\t// Returns the value of a named header.\n\tjava.lang.String getHeader(java.lang.String name);\n\t// Returns all the headers.\n\tMetadata getHeaders();\n\t// Returns the URL used to retrieve this response.\n\tjava.net.URL getUrl();\n}", "des": "An HTTP response."}
{"index": 1200, "repo": "nutch-2.4", "code": "Class HttpResponse {\n\t// Returns the response code.\n\tint getCode();\n\t// Returns the full content of the response.\n\tbyte[] getContent();\n\t// Returns the value of a named header.\n\tjava.lang.String getHeader(java.lang.String name);\n\t// Returns all the headers.\n\tMetadata getHeaders();\n\t// Returns the URL used to retrieve this response.\n\tjava.net.URL getUrl();\n}", "des": "An HTTP response."}
{"index": 1201, "repo": "nutch-2.4", "code": "Class HttpRobotRulesParser {\n\t// Compose unique key to store and access robot rules in cache for given URL\n\tprotected static java.lang.String getCacheKey(java.net.URL url);\n\t// Get the rules from robots.txt which applies for the given url.\n\tcrawlercommons.robots.BaseRobotRules getRobotRulesSet(Protocol http, java.net.URL url);\n}", "des": "This class is used for parsing robots for urls belonging to HTTP protocol. It extends the generic RobotRulesParser class and contains Http protocol specific implementation for obtaining the robots file."}
{"index": 1202, "repo": "nutch-2.4", "code": "Class IndexingFilters {\n\t// Run all defined filters.\n\tNutchDocument filter(NutchDocument doc, java.lang.String url, WebPage page);\n\t// Gets all the fields for a given WebPage Many datastores need to setup the mapreduce job by specifying the fields needed.\n\tjava.util.Collection<WebPage.Field> getFields();\n}", "des": "Creates and caches IndexingFilter implementing plugins."}
{"index": 1203, "repo": "nutch-2.4", "code": "Class LockUtil {\n\t// Create a lock file.\n\tstatic void createLockFile(FileSystem fs, Path lockFile, boolean accept);\n\t// Remove lock file.\n\tstatic boolean removeLockFile(FileSystem fs, Path lockFile);\n}", "des": "Utility methods for handling application-level locking."}
{"index": 1204, "repo": "nutch-2.4", "code": "Class MetaWrapper {\n\t// Add metadata.\n\tvoid addMeta(java.lang.String name, java.lang.String value);\n\t// Get metadata.\n\tjava.lang.String getMeta(java.lang.String name);\n\t// Get all metadata.\n\tMetadata getMetadata();\n\t// Get multiple metadata.\n\tjava.lang.String[] getMetaValues(java.lang.String name);\n\tvoid readFields(java.io.DataInput in);\n\t// Set metadata.\n\tvoid setMeta(java.lang.String name, java.lang.String value);\n\tvoid write(java.io.DataOutput out);\n}", "des": "This is a simple decorator that adds metadata to any Writable-s that can be serialized by NutchWritable. This is useful when data needs to be temporarily enriched during processing, but this temporary metadata doesn't need to be permanently stored after the job is done."}
{"index": 1205, "repo": "nutch-2.4", "code": "Class NodeWalker {\n\t// Return the current node.\n\torg.w3c.dom.Node getCurrentNode();\n\t// * Returns true if there are more nodes on the current stack.\n\tboolean hasNext();\n\t// Returns the next Node on the stack and pushes all of its children onto the stack, allowing us to walk the node tree without the use of recursion.\n\torg.w3c.dom.Node nextNode();\n\t// Skips over and removes from the node stack the children of the last node.\n\tvoid skipChildren();\n}", "des": ""}
{"index": 1206, "repo": "nutch-2.4", "code": "Class NutchConfiguration {\n\t// Create a Configuration for Nutch.\n\tstatic Configuration create();\n\t// Create a Configuration from supplied properties.\n\tstatic Configuration create(boolean addNutchResources, java.util.Properties nutchProperties);\n\t// Retrieve a Nutch UUID of this configuration object, or null if the configuration was created elsewhere.\n\tstatic java.lang.String getUUID(Configuration conf);\n}", "des": "Utility to create Hadoop Configurations that include Nutch-specific resources."}
{"index": 1207, "repo": "nutch-2.4", "code": "Class NutchJob {\n\t// Creates a new NutchJob with no particular Cluster and a given Configuration.\n\tstatic NutchJob getInstance(Configuration conf);\n\t// Creates a new NutchJob with no particular Cluster and a given jobName.\n\tstatic NutchJob getInstance(Configuration conf, java.lang.String jobName);\n\tstatic boolean shouldProcess(java.lang.CharSequence mark, org.apache.avro.util.Utf8 batchId);\n\tboolean waitForCompletion(boolean verbose);\n}", "des": "A Job for Nutch jobs."}
{"index": 1208, "repo": "nutch-2.4", "code": "Class OutlinkExtractor {\n\t// Extracts Outlink from given plain text.\n\tstatic Outlink[] getOutlinks(java.lang.String plainText, Configuration conf);\n\t// Extracts Outlink from given plain text and adds anchor to the extracted Outlinks\n\tstatic Outlink[] getOutlinks(java.lang.String plainText, java.lang.String anchor, Configuration conf);\n}", "des": "Extractor to extract Outlinks / URLs from plain text using Regular Expressions."}
{"index": 1209, "repo": "nutch-2.4", "code": "Class ParsePluginsReader {\n\tjava.lang.String getFParsePluginsFile();\n\t// Tests parsing of the parse-plugins.xml file.\n\tstatic void main(java.lang.String[] args);\n\t// Reads the parse-plugins.xml file and returns the ParsePluginList defined by it.\n\tParsePluginList parse(Configuration conf);\n\tvoid setFParsePluginsFile(java.lang.String parsePluginsFile);\n}", "des": "A reader to load the information stored in the $NUTCH_HOME/conf/parse-plugins.xml file."}
{"index": 1210, "repo": "nutch-2.4", "code": "Class ParserFactory {\n\t// Finds the best-suited parse plugin for a given contentType.\n\tprotected java.util.List<Extension> getExtensions(java.lang.String contentType);\n\tjava.util.Collection<WebPage.Field> getFields();\n\t// Function returns a Parser instance with the specified extId, representing its extension ID.\n\tParser getParserById(java.lang.String id);\n\t// Function returns an array of Parsers for a given content type.\n\tParser[] getParsers(java.lang.String contentType, java.lang.String url);\n}", "des": "Creates and caches Parser plugins."}
{"index": 1211, "repo": "nutch-2.4", "code": "Enum ParseStatus.Field {\n\t// Gets field's index.\n\tint getIndex();\n\t// Gets field's name.\n\tjava.lang.String getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ParseStatus.Field valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ParseStatus.Field[] values();\n}", "des": "Enum containing all data bean's fields."}
{"index": 1212, "repo": "nutch-2.4", "code": "Class Plugin {\n\tprotected void finalize();\n\t// Returns the plugin descriptor\n\tPluginDescriptor getDescriptor();\n\t// Shutdown the plugin.\n\tvoid shutDown();\n\t// Will be invoked until plugin start up.\n\tvoid startUp();\n}", "des": "A nutch-plugin is an container for a set of custom logic that provide extensions to the nutch core functionality or another plugin that provides an API for extending. A plugin can provide one or a set of extensions. Extensions are components that can be dynamically installed as a kind of listener to extension points. Extension points are a kind of publisher that provide a API and invoke one or a set of installed extensions. Each plugin may extend the base Plugin. Plugin instances are used as the point of life cycle managemet of plugin related functionality. The Plugin will be startuped and shutdown by the nutch plugin management system. A possible usecase of the Plugin implementation is to create or close a database connection."}
{"index": 1213, "repo": "nutch-2.4", "code": "Class PluginManifestParser {\n\t// Return the named plugin folder.\n\tjava.io.File getPluginFolder(java.lang.String name);\n\t// Returns a list of all found plugin descriptors.\n\tjava.util.Map<java.lang.String,PluginDescriptor> parsePluginFolder(java.lang.String[] pluginFolders);\n}", "des": "The PluginManifestParser parser just parse the manifest file in all plugin directories."}
{"index": 1214, "repo": "nutch-2.4", "code": "Class PrefixStringMatcher {\n\t// Returns the longest prefix of input that is matched, or null if no match exists.\n\tjava.lang.String longestMatch(java.lang.String input);\n\tstatic void main(java.lang.String[] argv);\n\t// Returns true if the given String is matched by a prefix in the trie\n\tboolean matches(java.lang.String input);\n\t// Returns the shortest prefix of input that is matched, or null if no match exists.\n\tjava.lang.String shortestMatch(java.lang.String input);\n}", "des": "A class for efficiently matching Strings against a set of prefixes."}
{"index": 1215, "repo": "nutch-2.4", "code": "Enum ProtocolStatus.Field {\n\t// Gets field's index.\n\tint getIndex();\n\t// Gets field's name.\n\tjava.lang.String getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ProtocolStatus.Field valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ProtocolStatus.Field[] values();\n}", "des": "Enum containing all data bean's fields."}
{"index": 1216, "repo": "nutch-2.4", "code": "Class RegexRule {\n\t// Return if this rule is used for filtering-in or out.\n\tprotected boolean accept();\n\t// Checks if a url matches this rule.\n\tprotected abstract boolean match(java.lang.String url);\n}", "des": "A generic regular expression rule."}
{"index": 1217, "repo": "nutch-2.4", "code": "Class RegexURLFilter {\n\t// Creates a new RegexRule.\n\tprotected RegexRule createRule(boolean sign, java.lang.String regex);\n\t// Rules specified as a config property will override rules specified as a config file.\n\tprotected java.io.Reader getRulesReader(Configuration conf);\n\tstatic void main(java.lang.String[] args);\n}", "des": "Filters URLs based on a file of regular expressions using the Java Regex implementation."}
{"index": 1218, "repo": "nutch-2.4", "code": "Class RelTagIndexingFilter {\n\t// The RelTagIndexingFilter filter object.\n\tNutchDocument filter(NutchDocument doc, java.lang.String url, WebPage page);\n\t// Get the Configuration object\n\tConfiguration getConf();\n\t// Gets all the fields for a given WebPage Many datastores need to setup the mapreduce job by specifying the fields needed.\n\tjava.util.Collection<WebPage.Field> getFields();\n\t// Set the Configuration object\n\tvoid setConf(Configuration conf);\n}", "des": "An IndexingFilter that adds tag field(s) to the document."}
{"index": 1219, "repo": "nutch-2.4", "code": "Class ResolveUrls {\n\t// Runs the resolve urls tool.\n\tstatic void main(java.lang.String[] args);\n\t// Creates a thread pool for resolving urls.\n\tvoid resolveUrls();\n}", "des": "A simple tool that will spin up multiple threads to resolve urls to ip addresses. This can be used to verify that pages that are failing due to UnknownHostException during fetching are actually bad and are not failing due to a dns problem in fetching."}
{"index": 1220, "repo": "nutch-2.4", "code": "Interface Response {\n\t// Returns the response code.\n\tint getCode();\n\t// Returns the full content of the response.\n\tbyte[] getContent();\n\t// Returns the value of a named header.\n\tjava.lang.String getHeader(java.lang.String name);\n\t// Returns all the headers.\n\tMetadata getHeaders();\n\t// Returns the URL used to retrieve this response.\n\tjava.net.URL getUrl();\n}", "des": "A response interface. Makes all protocols model HTTP."}
{"index": 1221, "repo": "nutch-2.4", "code": "Interface RobotRules {\n\t// Get Crawl-Delay, in milliseconds.\n\tlong getCrawlDelay();\n\t// Get expire time\n\tlong getExpireTime();\n\t// Returns false if the robots.txt file prohibits us from accessing the given url, or true otherwise.\n\tboolean isAllowed(java.net.URL url);\n}", "des": "This class holds the rules which were parsed from a robots.txt file, and can test paths against those rules."}
{"index": 1222, "repo": "nutch-2.4", "code": "Class Sftp {\n\t// Get the Configuration object\n\tConfiguration getConf();\n\tjava.util.Collection<WebPage.Field> getFields();\n\tProtocolOutput getProtocolOutput(java.lang.String url, WebPage page);\n\t// Retrieve robot rules applicable for this url.\n\tcrawlercommons.robots.BaseRobotRules getRobotRules(java.lang.String url, WebPage page);\n\t// Set the Configuration object\n\tvoid setConf(Configuration arg0);\n}", "des": "This class uses the Jsch package to fetch content using the Sftp protocol."}
{"index": 1223, "repo": "nutch-2.4", "code": "Class SuffixStringMatcher {\n\t// Returns the longest suffix of input that is matched, or null if no match exists.\n\tjava.lang.String longestMatch(java.lang.String input);\n\tstatic void main(java.lang.String[] argv);\n\t// Returns true if the given String is matched by a suffix in the trie\n\tboolean matches(java.lang.String input);\n\t// Returns the shortest suffix of input that is matched, or null if no match exists.\n\tjava.lang.String shortestMatch(java.lang.String input);\n}", "des": "A class for efficiently matching Strings against a set of suffixes. Zero-length Strings are ignored."}
{"index": 1224, "repo": "nutch-2.4", "code": "Class URLFilters {\n\t// Run all defined filters.\n\tjava.lang.String filter(java.lang.String urlString);\n\t// If the page is a sitemap, return true\n\tstatic boolean isSitemap(WebPage page);\n}", "des": "Creates and caches URLFilter implementing plugins."}
{"index": 1225, "repo": "nutch-2.4", "code": "Enum WebPage.Field {\n\t// Gets field's index.\n\tint getIndex();\n\t// Gets field's name.\n\tjava.lang.String getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WebPage.Field valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WebPage.Field[] values();\n}", "des": "Enum containing all data bean's fields."}
{"index": 1226, "repo": "nutch-2.4", "code": "Class XMLCharacterRecognizer {\n\t// Returns whether the specified ch conforms to the XML 1.0 definition of whitespace.\n\tstatic boolean isWhiteSpace(char ch);\n\t// Tell if the string is whitespace.\n\tstatic boolean isWhiteSpace(char[] ch, int start, int length);\n\t// Tell if the string is whitespace.\n\tstatic boolean isWhiteSpace(java.lang.String s);\n\t// Tell if the string is whitespace.\n\tstatic boolean isWhiteSpace(java.lang.StringBuffer buf);\n}", "des": "Class used to verify whether the specified ch conforms to the XML 1.0 definition of whitespace."}
{"index": 1227, "repo": "flink-core-1.17.1", "code": "class AbstractDeserializationSchema<T> {\n\t// De-serializes the byte message.\n\tabstract T deserialize(byte[] message);\n\t// Gets the type produced by this deserializer.\n\tTypeInformation<T> getProducedType();\n\t// Method to decide whether the element signals the end of the stream.\n\tboolean isEndOfStream(T nextElement);\n}", "des": "The deserialization schema describes how to turn the byte messages delivered by certain data sources (for example Apache Kafka) into data types (Java/Scala objects) that are processed by Flink."}
{"index": 1228, "repo": "flink-core-1.17.1", "code": "class AbstractID {\n\tint compareTo(AbstractID o);\n\tboolean equals(Object obj);\n\t// Gets the bytes underlying this ID.\n\tbyte[] getBytes();\n\t// Gets the lower 64 bits of the ID.\n\tlong getLowerPart();\n\t// Gets the upper 64 bits of the ID.\n\tlong getUpperPart();\n\t// Returns pure String representation of the ID in hexadecimal.\n\tString toHexString();\n}", "des": "A statistically unique identification number."}
{"index": 1229, "repo": "flink-core-1.17.1", "code": "interface Accumulator<V,R extends Serializable> {\n\tvoid add(V value);\n\t// Duplicates the accumulator.\n\tAccumulator<V,R> clone();\n\tR getLocalValue();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<V,R> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "Accumulators collect distributed statistics or aggregates in a from user functions and operators. Each parallel instance creates and updates its own accumulator object, and the different parallel instances of the accumulator are later merged. merged by the system at the end of the job. The result can be obtained from the result of a job execution, or from the web runtime monitor."}
{"index": 1230, "repo": "flink-core-1.17.1", "code": "interface AggregateFunction<IN,ACC,OUT> {\n\t// Adds the given input value to the given accumulator, returning the new accumulator value.\n\tACC add(IN value, ACC accumulator);\n\t// Creates a new accumulator, starting a new aggregate.\n\tACC createAccumulator();\n\t// Gets the result of the aggregation from the accumulator.\n\tOUT getResult(ACC accumulator);\n\t// Merges two accumulators, returning an accumulator with the merged state.\n\tACC merge(ACC a, ACC b);\n}", "des": "The AggregateFunction is a flexible aggregation function, characterized by the following features: The aggregates may use different types for input values, intermediate aggregates, and result type, to support a wide range of aggregation types. Support for distributive aggregations: Different intermediate aggregates can be merged together, to allow for pre-aggregation/final-aggregation optimizations."}
{"index": 1231, "repo": "flink-core-1.17.1", "code": "interface Aggregator<T extends Value> {\n\t// Aggregates the given element.\n\tvoid aggregate(T element);\n\t// Gets the aggregator's current aggregate.\n\tT getAggregate();\n\t// Resets the internal state of the aggregator.\n\tvoid reset();\n}", "des": "Aggregators are a means of aggregating values across parallel instances of a function. Aggregators collect simple statistics (such as the number of processed elements) about the actual work performed in a function. Aggregators are specific to iterations and are commonly used to check the convergence of an iteration by using a ConvergenceCriterion. In contrast to the Accumulator (whose result is available at the end of a job, the aggregators are computed once per iteration superstep. Their value can be used to check for convergence (at the end of the iteration superstep) and it can be accessed in the next iteration superstep."}
{"index": 1232, "repo": "flink-core-1.17.1", "code": "class AggregatorWithName<T extends Value> {\n\t// Gets the aggregator.\n\tAggregator<T> getAggregator();\n\t// Gets the name that the aggregator is registered under.\n\tString getName();\n}", "des": "Simple utility class holding an Aggregator with the name it is registered under."}
{"index": 1233, "repo": "flink-core-1.17.1", "code": "interface AppendingState<IN,OUT> {\n\t// Updates the operator state accessible by get() by adding the given value to the list of values.\n\tvoid add(IN value);\n\t// Returns the current value for the state.\n\tOUT get();\n}", "des": "Base interface for partitioned state that supports adding elements and inspecting the current state. Elements can either be kept in a buffer (list-like) or aggregated into one value."}
{"index": 1234, "repo": "flink-core-1.17.1", "code": "class AutoCloseableRegistry {\n\t// This implementation implies that any exception is possible during closing.\n\tprotected void doClose(List<AutoCloseable> toClose);\n\t// Does the actual registration of the closeable with the registry map.\n\tprotected void doRegister(AutoCloseable closeable, Map<AutoCloseable,Object> closeableMap);\n\t// Does the actual un-registration of the closeable from the registry map.\n\tprotected boolean doUnRegister(AutoCloseable closeable, Map<AutoCloseable,Object> closeableMap);\n}", "des": "This class allows to register instances of AutoCloseable, which are all closed if this registry is closed."}
{"index": 1235, "repo": "flink-core-1.17.1", "code": "class AverageAccumulator {\n\tvoid add(double value);\n\tvoid add(Double value);\n\tvoid add(int value);\n\tvoid add(long value);\n\t// Duplicates the accumulator.\n\tAverageAccumulator clone();\n\tDouble getLocalValue();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Double,Double> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that computes the average value. Input can be long, integer, or double and the result is double."}
{"index": 1236, "repo": "flink-core-1.17.1", "code": "interface BaseStatistics {\n\t// Gets the average width of a record, in bytes.\n\tfloat getAverageRecordWidth();\n\t// Gets the number of records in the input (= base cardinality).\n\tlong getNumberOfRecords();\n\t// Gets the total size of the input.\n\tlong getTotalInputSize();\n}", "des": "Interface describing the basic statistics that can be obtained from the input."}
{"index": 1237, "repo": "flink-core-1.17.1", "code": "enum BatchShuffleMode {\n\t// Returns the description for the enum constant.\n\tInlineElement getDescription();\n\t// \n\tstatic BatchShuffleMode valueOf(String name);\n\t// ,  \n\tstatic BatchShuffleMode[] values();\n}", "des": "Defines how data is exchanged between tasks in batch ExecutionOptions.RUNTIME_MODE if the shuffling behavior has not been set explicitly for an individual exchange."}
{"index": 1238, "repo": "flink-core-1.17.1", "code": "interface BiConsumerWithException<T,U,E extends Throwable> {\n\t// Performs this operation on the given arguments.\n\tvoid accept(T t, U u);\n\t// Convert a BiConsumerWithException into a BiConsumer.\n\tstatic <A,B> java.util.function.BiConsumer<A,B> unchecked(BiConsumerWithException<A,B,?> biConsumerWithException);\n}", "des": "A checked extension of the BiConsumer interface."}
{"index": 1239, "repo": "flink-core-1.17.1", "code": "interface BiFunctionWithException<T,U,R,E extends Throwable> {\n\t// Apply the given values t and u to obtain the resulting value.\n\tR apply(T t, U u);\n\t// Convert at BiFunctionWithException into a BiFunction.\n\tstatic <A,B,C> java.util.function.BiFunction<A,B,C> unchecked(BiFunctionWithException<A,B,C,?> biFunctionWithException);\n}", "des": "BiFunction interface which can throw exceptions."}
{"index": 1240, "repo": "flink-core-1.17.1", "code": "interface BlockLocation {\n\t// Get the list of hosts (hostname) hosting this block.\n\tString[] getHosts();\n\t// Get the length of the block.\n\tlong getLength();\n\t// Get the start offset of the file associated with this block.\n\tlong getOffset();\n}", "des": "A BlockLocation lists hosts, offset and length of block."}
{"index": 1241, "repo": "flink-core-1.17.1", "code": "enum Boundedness {\n\t// \n\tstatic Boundedness valueOf(String name);\n\t// ,  \n\tstatic Boundedness[] values();\n}", "des": "The boundedness of a stream. A stream could either be \"bounded\" (a stream with finite records) or \"unbounded\" (a stream with infinite records)."}
{"index": 1242, "repo": "flink-core-1.17.1", "code": "class BoundedOutOfOrdernessWatermarks<T> {\n\t// Called for every event, allows the watermark generator to examine and remember the event timestamps, or to emit a watermark based on the event itself.\n\tvoid onEvent(T event, long eventTimestamp, WatermarkOutput output);\n\t// Called periodically, and might emit a new watermark, or not.\n\tvoid onPeriodicEmit(WatermarkOutput output);\n}", "des": "A WatermarkGenerator for situations where records are out of order, but you can place an upper bound on how far the events are out of order. An out-of-order bound B means that once an event with timestamp T was encountered, no events older than T - B will follow any more."}
{"index": 1243, "repo": "flink-core-1.17.1", "code": "interface BroadcastState<K,V> {\n\t// Returns all the mappings in the state.\n\tIterable<Map.Entry<K,V>> entries();\n\t// Iterates over all the mappings in the state.\n\tIterator<Map.Entry<K,V>> iterator();\n\t// Associates a new value with the given key.\n\tvoid put(K key, V value);\n\t// Copies all of the mappings from the given map into the state.\n\tvoid putAll(Map<K,V> map);\n\t// Deletes the mapping of the given key.\n\tvoid remove(K key);\n}", "des": "A type of state that can be created to store the state of a BroadcastStream. This state assumes that the same elements are sent to all instances of an operator."}
{"index": 1244, "repo": "flink-core-1.17.1", "code": "class BulkIterationBase.PartialSolutionPlaceHolder<OT> {\n\t// Contains the logic to invoke the visitor and continue the traversal.\n\tvoid accept(Visitor<Operator<?>> visitor);\n\tBulkIterationBase<OT> getContainingBulkIteration();\n\t// Gets the user code wrapper.\n\tUserCodeWrapper<?> getUserCodeWrapper();\n}", "des": "Specialized operator to use as a recognizable place-holder for the input to the step function when composing the nested data flow."}
{"index": 1245, "repo": "flink-core-1.17.1", "code": "class BulkIterationBase.TerminationCriterionAggregator {\n\tvoid aggregate(long count);\n\t// Aggregates the given element.\n\tvoid aggregate(LongValue count);\n\t// Gets the aggregator's current aggregate.\n\tLongValue getAggregate();\n\t// Resets the internal state of the aggregator.\n\tvoid reset();\n}", "des": "Aggregator that basically only adds 1 for every output tuple of the termination criterion branch"}
{"index": 1246, "repo": "flink-core-1.17.1", "code": "class BulkIterationBase.TerminationCriterionMapper<X> {\n\t// The core method of the FlatMapFunction.\n\tvoid flatMap(X in, Collector<X> out);\n\t// Initialization method for the function.\n\tvoid open(Configuration parameters);\n}", "des": "Special Mapper that is added before a termination criterion and is only a container for an special aggregator"}
{"index": 1247, "repo": "flink-core-1.17.1", "code": "interface BulkWriter<T> {\n\t// Adds an element to the encoder.\n\tvoid addElement(T element);\n\t// Finishes the writing.\n\tvoid finish();\n\t// Flushes all intermediate buffered data to the output stream.\n\tvoid flush();\n}", "des": "An encoder that encodes data in a bulk fashion, encoding many records together at a time."}
{"index": 1248, "repo": "flink-core-1.17.1", "code": "class ByteValueParser {\n\t// Returns an instance of the parsed value type.\n\tByteValue createValue();\n\t// Gets the parsed field.\n\tByteValue getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, ByteValue reusable);\n}", "des": "Parses a decimal text field into a ByteValue. Only characters '1' to '0' and '-' are allowed."}
{"index": 1249, "repo": "flink-core-1.17.1", "code": "class Bzip2InputStreamFactory {\n\t// Creates a InflaterInputStream that wraps the given input stream.\n\torg.apache.commons.compress.compressors.bzip2.BZip2CompressorInputStream create(InputStream in);\n\t// Lists a collection of typical file extensions (e.g., \"gz\", \"gzip\") that are associated with the compression algorithm in the InflaterInputStream T.\n\tCollection<String> getCommonFileExtensions();\n\tstatic Bzip2InputStreamFactory getInstance();\n}", "des": "Factory for Bzip2 decompressors."}
{"index": 1250, "repo": "flink-core-1.17.1", "code": "interface CacheSupportedPipelineExecutor {\n\t// Invalidate the cluster dataset with the given id.\n\tCompletableFuture<Void> invalidateClusterDataset(AbstractID clusterDatasetId, Configuration configuration, ClassLoader userCodeClassloader);\n\t// Return a set of ids of the completed cluster dataset.\n\tCompletableFuture<Set<AbstractID>> listCompletedClusterDatasetIds(Configuration configuration, ClassLoader userCodeClassloader);\n}", "des": "The pipeline executor that support caching intermediate dataset."}
{"index": 1251, "repo": "flink-core-1.17.1", "code": "interface CheckpointableInputFormat<S extends InputSplit,T extends Serializable> {\n\t// Returns the split currently being read, along with its current state.\n\tT getCurrentState();\n\t// Restores the state of a parallel instance reading from an InputFormat.\n\tvoid reopen(S split, T state);\n}", "des": "An interface that describes InputFormats that allow checkpointing/restoring their state."}
{"index": 1252, "repo": "flink-core-1.17.1", "code": "interface CheckpointListener {\n\t// This method is called as a notification once a distributed checkpoint has been aborted.\n\tdefault void notifyCheckpointAborted(long checkpointId);\n\t// Notifies the listener that the checkpoint with the given checkpointId completed and was committed.\n\tvoid notifyCheckpointComplete(long checkpointId);\n}", "des": "This interface is typically only needed for transactional interaction with the \"outside world\", like committing external side effects on checkpoints. An example is committing external transactions once a checkpoint completes. Invocation Guarantees"}
{"index": 1253, "repo": "flink-core-1.17.1", "code": "enum CheckpointType {\n\t// Returns the description for the enum constant.\n\tInlineElement getDescription();\n\t// \n\tstatic CheckpointType valueOf(String name);\n\t// ,  \n\tstatic CheckpointType[] values();\n}", "des": "Describes the type in which a checkpoint should be taken."}
{"index": 1254, "repo": "flink-core-1.17.1", "code": "interface ChillSerializerRegistrar {\n\t// Returns the registration ID that immediately follows the last registered serializer.\n\tint getNextRegistrationId();\n\t// Registers all serializers with the given Kryo.\n\tvoid registerSerializers(com.esotericsoftware.kryo.Kryo kryo);\n}", "des": "Interface for flink-core to interact with the FlinkChillPackageRegistrar in flink-java."}
{"index": 1255, "repo": "flink-core-1.17.1", "code": "class ClassLoaderUtil {\n\t// Returns the interpretation of URL in string format.\n\tstatic String formatURL(URL url);\n\t// Gets information about URL class loaders.\n\tstatic String getUserCodeClassLoaderInfo(ClassLoader loader);\n\t// Checks, whether the class that was not found in the given exception, can be resolved through the given class loader.\n\tstatic boolean validateClassLoadable(ClassNotFoundException cnfe, ClassLoader cl);\n}", "des": "Utilities for information with respect to class loaders, specifically class loaders for the dynamic loading of user defined classes."}
{"index": 1256, "repo": "flink-core-1.17.1", "code": "class Clock {\n\t// Gets the current absolute time, in milliseconds.\n\tabstract long absoluteTimeMillis();\n\t// Gets the current relative time, in milliseconds.\n\tabstract long relativeTimeMillis();\n\t// Gets the current relative time, in nanoseconds.\n\tabstract long relativeTimeNanos();\n}", "des": "A clock that gives access to time. This clock returns two flavors of time: Absolute Time"}
{"index": 1257, "repo": "flink-core-1.17.1", "code": "class CloseableRegistry {\n\t// This implementation doesn't imply any exception during closing due to backward compatibility.\n\tvoid doClose(List<Closeable> toClose);\n\t// Does the actual registration of the closeable with the registry map.\n\tprotected void doRegister(Closeable closeable, Map<Closeable,Object> closeableMap);\n\t// Does the actual un-registration of the closeable from the registry map.\n\tprotected boolean doUnRegister(Closeable closeable, Map<Closeable,Object> closeableMap);\n}", "des": "This class allows to register instances of Closeable, which are all closed if this registry is closed."}
{"index": 1258, "repo": "flink-core-1.17.1", "code": "enum ClusterOptions.UserSystemExitMode {\n\t// Returns the description for the enum constant.\n\tInlineElement getDescription();\n\t// \n\tstatic ClusterOptions.UserSystemExitMode valueOf(String name);\n\t// ,  \n\tstatic ClusterOptions.UserSystemExitMode[] values();\n}", "des": "The mode of how to handle user code attempting to exit JVM."}
{"index": 1259, "repo": "flink-core-1.17.1", "code": "interface Collector<T> {\n\t// Closes the collector.\n\tvoid close();\n\t// Emits a record.\n\tvoid collect(T record);\n}", "des": "Collects a record and forwards it. The collector is the \"push\" counterpart of the Iterator, which \"pulls\" data in."}
{"index": 1260, "repo": "flink-core-1.17.1", "code": "enum CompositeTypeSerializerSnapshot.OuterSchemaCompatibility {\n\t// \n\tstatic CompositeTypeSerializerSnapshot.OuterSchemaCompatibility valueOf(String name);\n\t// ,  \n\tstatic CompositeTypeSerializerSnapshot.OuterSchemaCompatibility[] values();\n}", "des": "Indicates schema compatibility of the serializer configuration persisted as the outer snapshot."}
{"index": 1261, "repo": "flink-core-1.17.1", "code": "class CompressedSerializedValue<T> {\n\t// Decompress and deserialize the data to get the original object.\n\tT deserializeValue(ClassLoader loader);\n\t// Construct a compressed serialized value with a serialized byte array.\n\tstatic <T> CompressedSerializedValue<T> fromBytes(byte[] compressedSerializedData);\n\t// Constructs a compressed serialized value for the given object.\n\tstatic <T> CompressedSerializedValue<T> fromObject(T object);\n\t// Returns the size of the compressed serialized data.\n\tint getSize();\n}", "des": "An extension of SerializedValue that compresses the value after the serialization."}
{"index": 1262, "repo": "flink-core-1.17.1", "code": "class ConfigOptions.ListConfigOptionBuilder<E> {\n\t// Creates a ConfigOption with the given default value.\n\tConfigOption<List<E>> defaultValues(E... values);\n\t// Creates a ConfigOption without a default value.\n\tConfigOption<List<E>> noDefaultValue();\n}", "des": "Builder for ConfigOption of list of type E."}
{"index": 1263, "repo": "flink-core-1.17.1", "code": "class ConfigOptions.TypedConfigOptionBuilder<T> {\n\t// Defines that the option's type should be a list of previously defined atomic type.\n\tConfigOptions.ListConfigOptionBuilder<T> asList();\n\t// Creates a ConfigOption with the given default value.\n\tConfigOption<T> defaultValue(T value);\n\t// Creates a ConfigOption without a default value.\n\tConfigOption<T> noDefaultValue();\n}", "des": "Builder for ConfigOption with a defined atomic type."}
{"index": 1264, "repo": "flink-core-1.17.1", "code": "interface CopyableValue<T> {\n\t// Performs a deep copy of this object into a new instance.\n\tT copy();\n\t// Copies the next serialized instance from source to target.\n\tvoid copy(DataInputView source, DataOutputView target);\n\t// Performs a deep copy of this object into the target instance.\n\tvoid copyTo(T target);\n\t// Gets the length of the data type when it is serialized, in bytes.\n\tint getBinaryLength();\n}", "des": "Interface to be implemented by basic types that support to be copied efficiently."}
{"index": 1265, "repo": "flink-core-1.17.1", "code": "class CopyableValueSerializer.CopyableValueSerializerSnapshot<T extends CopyableValue<T>> {\n\t// Create a serializer that is able to serialize the generic type typeClass.\n\tprotected TypeSerializer<T> createSerializer(Class<T> typeClass);\n\t// Gets the type class from the corresponding serializer.\n\tprotected Class<T> getTypeClass(CopyableValueSerializer serializer);\n\t// Gets the serializer's class.\n\tprotected Class<?> serializerClass();\n}", "des": "TypeSerializerSnapshot for the CopyableValueSerializer."}
{"index": 1266, "repo": "flink-core-1.17.1", "code": "class CopyingListCollector<T> {\n\t// Closes the collector.\n\tvoid close();\n\t// Emits a record.\n\tvoid collect(T record);\n}", "des": "A Collector that collects deep copies of its elements in a list."}
{"index": 1267, "repo": "flink-core-1.17.1", "code": "enum CrossOperatorBase.CrossHint {\n\t// \n\tstatic CrossOperatorBase.CrossHint valueOf(String name);\n\t// ,  \n\tstatic CrossOperatorBase.CrossHint[] values();\n}", "des": "The cross hint tells the system which sizes to expect from the data sets"}
{"index": 1268, "repo": "flink-core-1.17.1", "code": "interface DataInputView {\n\t// Tries to fill the given byte array b.\n\tint read(byte[] b);\n\t// Reads up to len bytes of memory and stores it into b starting at offset off.\n\tint read(byte[] b, int off, int len);\n\t// Skips numBytes bytes of memory.\n\tvoid skipBytesToRead(int numBytes);\n}", "des": "This interface defines a view over some memory that can be used to sequentially read the contents of the memory. The view is typically backed by one or more MemorySegment."}
{"index": 1269, "repo": "flink-core-1.17.1", "code": "interface DataOutputView {\n\t// Skips numBytes bytes memory.\n\tvoid skipBytesToWrite(int numBytes);\n\t// Copies numBytes bytes from the source to this view.\n\tvoid write(DataInputView source, int numBytes);\n}", "des": "This interface defines a view over some memory that can be used to sequentially write contents to the memory. The view is typically backed by one or more MemorySegment."}
{"index": 1270, "repo": "flink-core-1.17.1", "code": "class DataOutputViewStreamWrapper {\n\t// Skips numBytes bytes memory.\n\tvoid skipBytesToWrite(int numBytes);\n\t// Copies numBytes bytes from the source to this view.\n\tvoid write(DataInputView source, int numBytes);\n}", "des": "Utility class that turns an OutputStream into a DataOutputView."}
{"index": 1271, "repo": "flink-core-1.17.1", "code": "class DefaultExecutorServiceLoader {\n\t// Loads the PipelineExecutorFactory which is compatible with the provided configuration.\n\tPipelineExecutorFactory getExecutorFactory(Configuration configuration);\n\t// Loads and returns a stream of the names of all available executors.\n\tjava.util.stream.Stream<String> getExecutorNames();\n}", "des": "The default implementation of the PipelineExecutorServiceLoader. This implementation uses Java service discovery to find the available executor factories."}
{"index": 1272, "repo": "flink-core-1.17.1", "code": "class DefaultInputSplitAssigner {\n\t// Returns the next input split that shall be consumed.\n\tInputSplit getNextInputSplit(String host, int taskId);\n\t// Return the splits to assigner if the task failed to process it.\n\tvoid returnInputSplit(List<InputSplit> splits, int taskId);\n}", "des": "This is the default implementation of the InputSplitAssigner interface. The default input split assigner simply returns all input splits of an input vertex in the order they were originally computed."}
{"index": 1273, "repo": "flink-core-1.17.1", "code": "class DeflateInflaterInputStreamFactory {\n\t// Creates a InflaterInputStream that wraps the given input stream.\n\tInflaterInputStream create(InputStream in);\n\t// Lists a collection of typical file extensions (e.g., \"gz\", \"gzip\") that are associated with the compression algorithm in the InflaterInputStream T.\n\tCollection<String> getCommonFileExtensions();\n\tstatic DeflateInflaterInputStreamFactory getInstance();\n}", "des": "Factory for input streams that decompress the \"deflate\" compression format."}
{"index": 1274, "repo": "flink-core-1.17.1", "code": "interface DelegationTokenReceiver {\n\t// Called to initialize receiver after construction.\n\tvoid init(Configuration configuration);\n\t// Callback function when new delegation tokens obtained.\n\tvoid onNewTokensObtained(byte[] tokens);\n\t// Config prefix of the service.\n\tdefault String serviceConfigPrefix();\n\t// Name of the service to receive delegation tokens for.\n\tString serviceName();\n}", "des": "Delegation token receiver API. Instances of DelegationTokenReceivers are loaded both on JobManager and TaskManager side through service loader. Basically the implementation of this interface is responsible to receive the serialized form of tokens produced by DelegationTokenProvider."}
{"index": 1275, "repo": "flink-core-1.17.1", "code": "class DeltaIterationBase.SolutionSetPlaceHolder<ST> {\n\t// Contains the logic to invoke the visitor and continue the traversal.\n\tvoid accept(Visitor<Operator<?>> visitor);\n\tDeltaIterationBase<ST,?> getContainingWorksetIteration();\n\t// Gets the user code wrapper.\n\tUserCodeWrapper<?> getUserCodeWrapper();\n}", "des": "Specialized operator to use as a recognizable place-holder for the solution set input to the step function."}
{"index": 1276, "repo": "flink-core-1.17.1", "code": "class DeltaIterationBase.WorksetPlaceHolder<WT> {\n\t// Contains the logic to invoke the visitor and continue the traversal.\n\tvoid accept(Visitor<Operator<?>> visitor);\n\tDeltaIterationBase<?,WT> getContainingWorksetIteration();\n\t// Gets the user code wrapper.\n\tUserCodeWrapper<?> getUserCodeWrapper();\n}", "des": "Specialized operator to use as a recognizable place-holder for the working set input to the step function."}
{"index": 1277, "repo": "flink-core-1.17.1", "code": "interface DeserializationSchema<T> {\n\t// Deserializes the byte message.\n\tT deserialize(byte[] message);\n\t// Deserializes the byte message.\n\tdefault void deserialize(byte[] message, Collector<T> out);\n\t// Method to decide whether the element signals the end of the stream.\n\tboolean isEndOfStream(T nextElement);\n\t// Initialization method for the schema.\n\tdefault void open(DeserializationSchema.InitializationContext context);\n}", "des": "The deserialization schema describes how to turn the byte messages delivered by certain data sources (for example Apache Kafka) into data types (Java/Scala objects) that are processed by Flink."}
{"index": 1278, "repo": "flink-core-1.17.1", "code": "interface DeserializationSchema.InitializationContext {\n\t// Returns the metric group for the parallel subtask of the source that runs this DeserializationSchema.\n\torg.apache.flink.metrics.MetricGroup getMetricGroup();\n\t// Gets the UserCodeClassLoader to load classes that are not in system's classpath, but are part of the jar file of a user job.\n\tUserCodeClassLoader getUserCodeClassLoader();\n}", "des": "A contextual information provided for DeserializationSchema.open(InitializationContext) method. It can be used to: Register user metrics via getMetricGroup() Access the user code class loader."}
{"index": 1279, "repo": "flink-core-1.17.1", "code": "class DoubleCounter {\n\tvoid add(double value);\n\t// Consider using add(double) instead for primitive double values\n\tvoid add(Double value);\n\t// Duplicates the accumulator.\n\tDoubleCounter clone();\n\tDouble getLocalValue();\n\tdouble getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Double,Double> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that sums up double values."}
{"index": 1280, "repo": "flink-core-1.17.1", "code": "class DoubleMaximum {\n\tvoid add(double value);\n\t// Consider using add(double) instead for primitive double values\n\tvoid add(Double value);\n\t// Duplicates the accumulator.\n\tDoubleMaximum clone();\n\tDouble getLocalValue();\n\tdouble getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Double,Double> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that finds the maximum double value."}
{"index": 1281, "repo": "flink-core-1.17.1", "code": "class DoubleMinimum {\n\tvoid add(double value);\n\t// Consider using add(double) instead for primitive double values\n\tvoid add(Double value);\n\t// Duplicates the accumulator.\n\tDoubleMinimum clone();\n\tDouble getLocalValue();\n\tdouble getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Double,Double> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that finds the minimum double value."}
{"index": 1282, "repo": "flink-core-1.17.1", "code": "class DoubleSumAggregator {\n\t// Adds the given value to the current aggregate.\n\tvoid aggregate(double value);\n\t// Aggregates the given element.\n\tvoid aggregate(DoubleValue element);\n\t// Gets the aggregator's current aggregate.\n\tDoubleValue getAggregate();\n\t// Resets the internal state of the aggregator.\n\tvoid reset();\n}", "des": "An Aggregator that sums up DoubleValue values."}
{"index": 1283, "repo": "flink-core-1.17.1", "code": "class DoubleValueParser {\n\t// Returns an instance of the parsed value type.\n\tDoubleValue createValue();\n\t// Gets the parsed field.\n\tDoubleValue getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, DoubleValue reusable);\n}", "des": "Parses a text field into a DoubleValue."}
{"index": 1284, "repo": "flink-core-1.17.1", "code": "interface DuplicatingFileSystem {\n\t// Tells if we can perform duplicate/copy between given paths.\n\tboolean canFastDuplicate(Path source, Path destination);\n\t// Duplicates the source path into the destination path.\n\tvoid duplicate(List<DuplicatingFileSystem.CopyRequest> requests);\n}", "des": "An extension interface for FileSystems that can perform cheap DFS side duplicate operation. Such an operation can improve the time required for creating cheaply independent snapshots from incremental snapshots."}
{"index": 1285, "repo": "flink-core-1.17.1", "code": "interface DuplicatingFileSystem.CopyRequest {\n\t// The path where to duplicate the source file.\n\tPath getDestination();\n\t// The path of the source file to duplicate.\n\tPath getSource();\n\t// A factory method for creating a simple pair of source/destination.\n\tstatic DuplicatingFileSystem.CopyRequest of(Path source, Path destination);\n}", "des": "A pair of source and destination to duplicate a file."}
{"index": 1286, "repo": "flink-core-1.17.1", "code": "class Either.Left<L,R> {\n\tboolean equals(Object object);\n\t// Retrieve the Left value of Either.\n\tL left();\n\t// Creates a left value of Either\n\tstatic <L,R> Either.Left<L,R> of(L left);\n\t// Retrieve the Right value of Either.\n\tR right();\n\t// Sets the encapsulated value to another value\n\tvoid setValue(L value);\n}", "des": "A left value of Either"}
{"index": 1287, "repo": "flink-core-1.17.1", "code": "class Either.Right<L,R> {\n\tboolean equals(Object object);\n\t// Retrieve the Left value of Either.\n\tL left();\n\t// Creates a right value of Either\n\tstatic <L,R> Either.Right<L,R> of(R right);\n\t// Retrieve the Right value of Either.\n\tR right();\n\t// Sets the encapsulated value to another value\n\tvoid setValue(R value);\n}", "des": "A right value of Either"}
{"index": 1288, "repo": "flink-core-1.17.1", "code": "interface EntropyInjectingFileSystem {\n\t// Creates a string with random entropy to be injected into a path.\n\tString generateEntropy();\n\t// Gets the marker string that represents the substring of a path to be replaced by the entropy characters.\n\tString getEntropyInjectionKey();\n}", "des": "An interface to be implemented by a FileSystem that is aware of entropy injection."}
{"index": 1289, "repo": "flink-core-1.17.1", "code": "enum ExecutionConfig.ClosureCleanerLevel {\n\t// Returns the description for the enum constant.\n\tInlineElement getDescription();\n\t// \n\tstatic ExecutionConfig.ClosureCleanerLevel valueOf(String name);\n\t// ,  \n\tstatic ExecutionConfig.ClosureCleanerLevel[] values();\n}", "des": "Configuration settings for the closure cleaner."}
{"index": 1290, "repo": "flink-core-1.17.1", "code": "enum ExecutionMode {\n\t// \n\tstatic ExecutionMode valueOf(String name);\n\t// ,  \n\tstatic ExecutionMode[] values();\n}", "des": "The execution mode specifies how a batch program is executed in terms of data exchange: pipelining or batched."}
{"index": 1291, "repo": "flink-core-1.17.1", "code": "class Executors {\n\t// Return a direct executor.\n\tstatic Executor directExecutor();\n\t// Return a new direct executor service.\n\tstatic ExecutorService newDirectExecutorService();\n}", "des": "Collection of Executor and ExecutorService implementations."}
{"index": 1292, "repo": "flink-core-1.17.1", "code": "class ExecutorUtils {\n\t// Gracefully shutdown the given ExecutorService.\n\tstatic void gracefulShutdown(long timeout, TimeUnit unit, ExecutorService... executorServices);\n\t// Shuts the given ExecutorService down in a non-blocking fashion.\n\tstatic CompletableFuture<Void> nonBlockingShutdown(long timeout, TimeUnit unit, ExecutorService... executorServices);\n}", "des": "Utilities for Executors."}
{"index": 1293, "repo": "flink-core-1.17.1", "code": "interface ExternalResourceInfo {\n\t// Get all property keys.\n\tCollection<String> getKeys();\n\t// Get the property indicated by the specified key.\n\tOptional<String> getProperty(String key);\n}", "des": "Contains the information of an external resource."}
{"index": 1294, "repo": "flink-core-1.17.1", "code": "enum FieldParser.ParseErrorState {\n\t// \n\tstatic FieldParser.ParseErrorState valueOf(String name);\n\t// ,  \n\tstatic FieldParser.ParseErrorState[] values();\n}", "des": "An enumeration of different types of errors that may occur."}
{"index": 1295, "repo": "flink-core-1.17.1", "code": "class FileInputFormat.FileBaseStatistics {\n\t// Gets the estimated average number of bytes per record.\n\tfloat getAverageRecordWidth();\n\t// Gets the timestamp of the last modification.\n\tlong getLastModificationTime();\n\t// Gets the estimates number of records in the file, computed as the file size divided by the average record width, rounded up.\n\tlong getNumberOfRecords();\n\t// Gets the file size.\n\tlong getTotalInputSize();\n}", "des": "Encapsulation of the basic statistics the optimizer obtains about a file. Contained are the size of the file and the average bytes of a single record. The statistics also have a time-stamp that records the modification time of the file and indicates as such for which time the statistics were valid."}
{"index": 1296, "repo": "flink-core-1.17.1", "code": "class FileInputSplit {\n\tboolean equals(Object obj);\n\t// Returns the number of bytes in the file to process.\n\tlong getLength();\n\t// Returns the path of the file containing this split's data.\n\tPath getPath();\n\t// Returns the position of the first byte in the file to process.\n\tlong getStart();\n}", "des": "A file input split provides information on a particular part of a file, possibly hosted on a distributed file system and replicated among several hosts."}
{"index": 1297, "repo": "flink-core-1.17.1", "code": "enum FileOutputFormat.OutputDirectoryMode {\n\t// \n\tstatic FileOutputFormat.OutputDirectoryMode valueOf(String name);\n\t// ,  \n\tstatic FileOutputFormat.OutputDirectoryMode[] values();\n}", "des": "Behavior for creating output directories."}
{"index": 1298, "repo": "flink-core-1.17.1", "code": "class FilePathFilter {\n\t// Returns the default filter, which excludes the following files: Files starting with \"_\" Files starting with \".\n\tstatic FilePathFilter createDefaultFilter();\n\t// Returns true if the filePath given is to be ignored when processing a directory, e.g.\n\tabstract boolean filterPath(Path filePath);\n}", "des": "The filterPath(Path) method is responsible for deciding if a path is eligible for further processing or not. This can serve to exclude temporary or partial files that are still being written."}
{"index": 1299, "repo": "flink-core-1.17.1", "code": "interface FileStatus {\n\t// Get the access time of the file.\n\tlong getAccessTime();\n\t// Get the block size of the file.\n\tlong getBlockSize();\n\t// Return the length of this file.\n\tlong getLen();\n\t// Get the modification time of the file.\n\tlong getModificationTime();\n\t// Returns the corresponding Path to the FileStatus.\n\tPath getPath();\n\t// Get the replication factor of a file.\n\tshort getReplication();\n\t// Checks if this object represents a directory.\n\tboolean isDir();\n}", "des": "Interface that represents the client side information for a file independent of the file system."}
{"index": 1300, "repo": "flink-core-1.17.1", "code": "enum FileSystem.WriteMode {\n\t// \n\tstatic FileSystem.WriteMode valueOf(String name);\n\t// ,  \n\tstatic FileSystem.WriteMode[] values();\n}", "des": "The possible write modes. The write mode decides what happens if a file should be created, but already exists."}
{"index": 1301, "repo": "flink-core-1.17.1", "code": "interface FileSystemFactory {\n\t// Creates a new file system for the given file system URI.\n\tFileSystem create(URI fsUri);\n\t// Gets the scheme of the file system created by this factory.\n\tString getScheme();\n}", "des": "A factory to create file systems."}
{"index": 1302, "repo": "flink-core-1.17.1", "code": "enum FileSystemKind {\n\t// \n\tstatic FileSystemKind valueOf(String name);\n\t// ,  \n\tstatic FileSystemKind[] values();\n}", "des": "An enumeration defining the kind and characteristics of a FileSystem."}
{"index": 1303, "repo": "flink-core-1.17.1", "code": "class FileSystemSafetyNet {\n\t// Closes the safety net for a thread.\n\tstatic void closeSafetyNetAndGuardedResourcesForThread();\n\t// Activates the safety net for a thread.\n\tstatic void initializeSafetyNetForThread();\n}", "des": "The FileSystemSafetyNet can be used to guard a thread against FileSystem stream resource leaks. When activated for a thread, it tracks all streams that are opened by FileSystems that the thread obtains. The safety net has a global cleanup hook that will close all streams that were not properly closed."}
{"index": 1304, "repo": "flink-core-1.17.1", "code": "interface FinalizeOnMaster.FinalizationContext {\n\t// Get the finished attempt number of subtask.\n\tint getFinishedAttempt(int subtaskIndex);\n\t// Get the parallelism with which the format or functions was run.\n\tint getParallelism();\n}", "des": "A context that provides parallelism and finished attempts infos."}
{"index": 1305, "repo": "flink-core-1.17.1", "code": "interface FlinkConnectorRateLimiter {\n\t// Acquires permits for the rate limiter.\n\tvoid acquire(int permits);\n\tvoid close();\n\tlong getRate();\n\t// A method that can be used to create and configure a ratelimiter based on the runtimeContext.\n\tvoid open(RuntimeContext runtimeContext);\n\t// Sets the desired rate for the rate limiter.\n\tvoid setRate(long rate);\n}", "des": "An interface to create a ratelimiter"}
{"index": 1306, "repo": "flink-core-1.17.1", "code": "enum FlinkUserCodeClassLoaders.ResolveOrder {\n\tstatic FlinkUserCodeClassLoaders.ResolveOrder fromString(String resolveOrder);\n\t// \n\tstatic FlinkUserCodeClassLoaders.ResolveOrder valueOf(String name);\n\t// ,  \n\tstatic FlinkUserCodeClassLoaders.ResolveOrder[] values();\n}", "des": "Class resolution order for Flink URL ClassLoader."}
{"index": 1307, "repo": "flink-core-1.17.1", "code": "class FloatValueParser {\n\t// Returns an instance of the parsed value type.\n\tFloatValue createValue();\n\t// Gets the parsed field.\n\tFloatValue getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, FloatValue reusable);\n}", "des": "Parses a text field into a FloatValue"}
{"index": 1308, "repo": "flink-core-1.17.1", "code": "class FSDataInputStream {\n\t// Gets the current position in the input stream.\n\tabstract long getPos();\n\t// Seek to the given offset from the start of the file.\n\tabstract void seek(long desired);\n}", "des": "Interface for a data input stream to a file on a FileSystem."}
{"index": 1309, "repo": "flink-core-1.17.1", "code": "class FSDataInputStreamWrapper {\n\tint available();\n\tvoid close();\n\t// Gets the current position in the input stream.\n\tlong getPos();\n\tFSDataInputStream getWrappedDelegate();\n\tvoid mark(int readlimit);\n\tboolean markSupported();\n\tint read();\n\tint read(byte[] b);\n\tint read(byte[] b, int off, int len);\n\tvoid reset();\n\t// Seek to the given offset from the start of the file.\n\tvoid seek(long desired);\n\tlong skip(long n);\n}", "des": "Simple forwarding wrapper around FSDataInputStream."}
{"index": 1310, "repo": "flink-core-1.17.1", "code": "class FSDataOutputStream {\n\t// Closes the output stream.\n\tabstract void close();\n\t// Flushes the stream, writing any data currently buffered in stream implementation to the proper output stream.\n\tabstract void flush();\n\t// Gets the position of the stream (non-negative), defined as the number of bytes from the beginning of the file to the current writing position.\n\tabstract long getPos();\n\t// Flushes the data all the way to the persistent non-volatile storage (for example disks).\n\tabstract void sync();\n}", "des": "An output stream to a file that is created via a FileSystem. This class extends the base OutputStream with some additional important methods. Data Persistence Guarantees"}
{"index": 1311, "repo": "flink-core-1.17.1", "code": "class FutureUtils.ConjunctFuture<T> {\n\t// Gets the number of Futures in the conjunction that are already complete.\n\tabstract int getNumFuturesCompleted();\n\t// Gets the total number of Futures in the conjunction.\n\tabstract int getNumFuturesTotal();\n}", "des": "A future that is complete once multiple other futures completed. The futures are not necessarily of the same type. The ConjunctFuture fails (completes exceptionally) once one of the Futures in the conjunction fails."}
{"index": 1312, "repo": "flink-core-1.17.1", "code": "class GatedRateLimiter {\n\t// Returns a future that is completed once another event would not exceed the rate limit.\n\tCompletionStage<Void> acquire();\n\t// Notifies this RateLimiter that the checkpoint with the given checkpointId completed and was committed.\n\tvoid notifyCheckpointComplete(long checkpointId);\n}", "des": "An implementation of RateLimiter that completes defined number of futures in-between the external notification events. The first cycle completes immediately, without waiting for the external notifications."}
{"index": 1313, "repo": "flink-core-1.17.1", "code": "class GroupCombineOperatorBase<IN,OUT,FT extends GroupCombineFunction<IN,OUT>> {\n\tprotected List<OUT> executeOnCollections(List<IN> inputData, RuntimeContext ctx, ExecutionConfig executionConfig);\n\t// Gets the order of elements within a reduce group.\n\tOrdering getGroupOrder();\n\t// Sets the order of the elements within a reduce group.\n\tvoid setGroupOrder(Ordering order);\n}", "des": "Base operator for the combineGroup transformation. It receives the UDF GroupCombineFunction as an input. This class is later processed by the compiler to generate the plan."}
{"index": 1314, "repo": "flink-core-1.17.1", "code": "class GuavaFlinkConnectorRateLimiter {\n\t// Acquires permits for the rate limiter.\n\tvoid acquire(int permits);\n\tvoid close();\n\tlong getRate();\n\t// Creates a rate limiter with the runtime context provided.\n\tvoid open(RuntimeContext runtimeContext);\n\t// Set the global per consumer and per sub-task rates.\n\tvoid setRate(long globalRate);\n}", "des": "An implementation of FlinkConnectorRateLimiter that uses Guava's RateLimiter for rate limiting."}
{"index": 1315, "repo": "flink-core-1.17.1", "code": "class GzipInflaterInputStreamFactory {\n\t// Creates a InflaterInputStream that wraps the given input stream.\n\tGZIPInputStream create(InputStream in);\n\t// Lists a collection of typical file extensions (e.g., \"gz\", \"gzip\") that are associated with the compression algorithm in the InflaterInputStream T.\n\tCollection<String> getCommonFileExtensions();\n\tstatic GzipInflaterInputStreamFactory getInstance();\n}", "des": "Factory for input streams that decompress the GZIP compression format."}
{"index": 1316, "repo": "flink-core-1.17.1", "code": "class Histogram {\n\tvoid add(Integer value);\n\t// Duplicates the accumulator.\n\tAccumulator<Integer,TreeMap<Integer,Integer>> clone();\n\tTreeMap<Integer,Integer> getLocalValue();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Integer,TreeMap<Integer,Integer>> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "Histogram accumulator, which builds a histogram in a distributed manner. Implemented as a Integer->Integer TreeMap, so that the entries are sorted according to the values."}
{"index": 1317, "repo": "flink-core-1.17.1", "code": "class IndexedCombinedWatermarkStatus {\n\tstatic IndexedCombinedWatermarkStatus forInputsCount(int inputsCount);\n\tlong getCombinedWatermark();\n\tboolean isIdle();\n\t// Updates the idleness for the given partial watermark.\n\tboolean updateStatus(int index, boolean idle);\n\t// Updates the value for the given partial watermark.\n\tboolean updateWatermark(int index, long timestamp);\n}", "des": "Represents combined value and status of a watermark for a set number of input partial watermarks."}
{"index": 1318, "repo": "flink-core-1.17.1", "code": "interface InflaterInputStreamFactory<T extends InputStream> {\n\t// Creates a InflaterInputStream that wraps the given input stream.\n\tT create(InputStream in);\n\t// Lists a collection of typical file extensions (e.g., \"gz\", \"gzip\") that are associated with the compression algorithm in the InflaterInputStream T.\n\tCollection<String> getCommonFileExtensions();\n}", "des": "Creates a new instance of a certain subclass of InflaterInputStream."}
{"index": 1319, "repo": "flink-core-1.17.1", "code": "interface InputSplitAssigner {\n\t// Returns the next input split that shall be consumed.\n\tInputSplit getNextInputSplit(String host, int taskId);\n\t// Return the splits to assigner if the task failed to process it.\n\tvoid returnInputSplit(List<InputSplit> splits, int taskId);\n}", "des": "An input split assigner distributes the InputSplits among the instances on which a data source exists."}
{"index": 1320, "repo": "flink-core-1.17.1", "code": "interface InputSplitSource<T extends InputSplit> {\n\t// Computes the input splits.\n\tT[] createInputSplits(int minNumSplits);\n\t// Returns the assigner for the input splits.\n\tInputSplitAssigner getInputSplitAssigner(T[] inputSplits);\n}", "des": "InputSplitSources create InputSplits that define portions of data to be produced by InputFormats."}
{"index": 1321, "repo": "flink-core-1.17.1", "code": "enum InputStatus {\n\t// \n\tstatic InputStatus valueOf(String name);\n\t// ,  \n\tstatic InputStatus[] values();\n}", "des": "An InputStatus indicates the availability of data from an asynchronous input. When asking an asynchronous input to produce data, it returns this status to indicate how to proceed."}
{"index": 1322, "repo": "flink-core-1.17.1", "code": "class InputStreamFSInputWrapper {\n\tvoid close();\n\t// Gets the current position in the input stream.\n\tlong getPos();\n\tint read();\n\tint read(byte[] b);\n\tint read(byte[] b, int off, int len);\n\t// Seek to the given offset from the start of the file.\n\tvoid seek(long desired);\n}", "des": "This class wraps an InputStream and exposes it as FSDataInputStream. NB: seek(long) and getPos() are currently not supported."}
{"index": 1323, "repo": "flink-core-1.17.1", "code": "class IntCounter {\n\tvoid add(int value);\n\t// Consider using add(int) instead for primitive int values\n\tvoid add(Integer value);\n\t// Duplicates the accumulator.\n\tIntCounter clone();\n\tInteger getLocalValue();\n\tint getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Integer,Integer> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that sums up Integer values."}
{"index": 1324, "repo": "flink-core-1.17.1", "code": "class IntMaximum {\n\tvoid add(int value);\n\t// Consider using add(int) instead for primitive integer values\n\tvoid add(Integer value);\n\t// Duplicates the accumulator.\n\tIntMaximum clone();\n\tInteger getLocalValue();\n\tint getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Integer,Integer> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that finds the maximum integer value."}
{"index": 1325, "repo": "flink-core-1.17.1", "code": "class IntMinimum {\n\tvoid add(int value);\n\t// Consider using add(int) instead for primitive integer values\n\tvoid add(Integer value);\n\t// Duplicates the accumulator.\n\tIntMinimum clone();\n\tInteger getLocalValue();\n\tint getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Integer,Integer> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that finds the minimum integer value."}
{"index": 1326, "repo": "flink-core-1.17.1", "code": "class IntValueParser {\n\t// Returns an instance of the parsed value type.\n\tIntValue createValue();\n\t// Gets the parsed field.\n\tIntValue getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, IntValue reusable);\n}", "des": "Parses a decimal text field into a IntValue. Only characters '1' to '0' and '-' are allowed."}
{"index": 1327, "repo": "flink-core-1.17.1", "code": "interface IOReadableWritable {\n\t// Reads the object's internal data from the given data input view.\n\tvoid read(DataInputView in);\n\t// Writes the object's internal data to the given data output view.\n\tvoid write(DataOutputView out);\n}", "des": "This interface must be implemented by every class whose objects have to be serialized to their binary representation and vice-versa. In particular, records have to implement this interface in order to specify how their data can be transferred to a binary representation."}
{"index": 1328, "repo": "flink-core-1.17.1", "code": "class IterableUtils {\n\t// Flatmap the two-dimensional Iterable into an one-dimensional Iterable and convert the keys into items.\n\tstatic <K,V,G extends Iterable<K>>Iterable<V> flatMap(Iterable<G> itemGroups, java.util.function.Function<K,V> mapper);\n\t// Convert the given Iterable to a Stream.\n\tstatic <E> java.util.stream.Stream<E> toStream(Iterable<E> iterable);\n}", "des": "A collection of utilities that expand the usage of Iterable."}
{"index": 1329, "repo": "flink-core-1.17.1", "code": "interface IteratorSourceSplit<E,IterT extends Iterator<E>> {\n\t// Gets the iterator over the elements of this split.\n\tIterT getIterator();\n\t// Converts an iterator (that may have returned some elements already) back into a source split.\n\tIteratorSourceSplit<E,IterT> getUpdatedSplitForIterator(IterT iterator);\n}", "des": "A SourceSplit that represents a sequence of elements captured in an iterator. The split produces the iterator and converts the iterator back to a new split during checkpointing."}
{"index": 1330, "repo": "flink-core-1.17.1", "code": "class JMXService {\n\t// Acquire the global singleton JMXServer instance.\n\tstatic Optional<org.apache.flink.management.jmx.JMXServer> getInstance();\n\tstatic Optional<Integer> getPort();\n\t// Start the JMV-wide singleton JMX server.\n\tstatic void startInstance(String portsConfig);\n\t// Stop the JMX server.\n\tstatic void stopInstance();\n}", "des": "Provide a JVM-wide singleton JMX Service."}
{"index": 1331, "repo": "flink-core-1.17.1", "code": "class JobID {\n\t// Creates a new JobID from the given byte sequence.\n\tstatic JobID fromByteArray(byte[] bytes);\n\tstatic JobID fromByteBuffer(ByteBuffer buf);\n\t// Parses a JobID from the given string.\n\tstatic JobID fromHexString(String hexString);\n\t// Creates a new (statistically) random JobID.\n\tstatic JobID generate();\n}", "des": "Unique (at least statistically unique) identifier for a Flink Job. Jobs in Flink correspond to dataflow graphs."}
{"index": 1332, "repo": "flink-core-1.17.1", "code": "interface JobListener {\n\t// Callback on job execution finished, successfully or unsuccessfully.\n\tvoid onJobExecuted(JobExecutionResult jobExecutionResult, Throwable throwable);\n\t// Callback on job submission.\n\tvoid onJobSubmitted(JobClient jobClient, Throwable throwable);\n}", "des": "A listener that is notified on specific job status changed, which should be firstly registered by #registerJobListener of execution environments."}
{"index": 1333, "repo": "flink-core-1.17.1", "code": "enum JobManagerOptions.HybridPartitionDataConsumeConstraint {\n\tboolean isOnlyConsumeFinishedPartition();\n\t// \n\tstatic JobManagerOptions.HybridPartitionDataConsumeConstraint valueOf(String name);\n\t// ,  \n\tstatic JobManagerOptions.HybridPartitionDataConsumeConstraint[] values();\n}", "des": "Constraints of upstream hybrid partition data consumption by downstream."}
{"index": 1334, "repo": "flink-core-1.17.1", "code": "enum JobManagerOptions.JobStoreType {\n\t// \n\tstatic JobManagerOptions.JobStoreType valueOf(String name);\n\t// ,  \n\tstatic JobManagerOptions.JobStoreType[] values();\n}", "des": "Type of job store implementation."}
{"index": 1335, "repo": "flink-core-1.17.1", "code": "enum JobManagerOptions.SchedulerType {\n\t// \n\tstatic JobManagerOptions.SchedulerType valueOf(String name);\n\t// ,  \n\tstatic JobManagerOptions.SchedulerType[] values();\n}", "des": "Type of scheduler implementation."}
{"index": 1336, "repo": "flink-core-1.17.1", "code": "enum JobStatus {\n\t// Checks whether this state is globally terminal.\n\tboolean isGloballyTerminalState();\n\t// Checks whether this state is locally terminal.\n\tboolean isTerminalState();\n\t// \n\tstatic JobStatus valueOf(String name);\n\t// ,  \n\tstatic JobStatus[] values();\n}", "des": "Possible states of a job once it has been accepted by the dispatcher."}
{"index": 1337, "repo": "flink-core-1.17.1", "code": "class JobSubmissionResult {\n\t// Returns the JobExecutionResult if available.\n\tJobExecutionResult getJobExecutionResult();\n\t// Returns the JobID assigned to the job by the Flink runtime.\n\tJobID getJobID();\n\t// Checks if this JobSubmissionResult is also a JobExecutionResult.\n\tboolean isJobExecutionResult();\n}", "des": "The result of submitting a job to a JobManager."}
{"index": 1338, "repo": "flink-core-1.17.1", "code": "enum JoinOperatorBase.JoinHint {\n\t// \n\tstatic JoinOperatorBase.JoinHint valueOf(String name);\n\t// ,  \n\tstatic JoinOperatorBase.JoinHint[] values();\n}", "des": "An enumeration of hints, optionally usable to tell the system how exactly execute the join."}
{"index": 1339, "repo": "flink-core-1.17.1", "code": "enum KryoRegistration.SerializerDefinitionType {\n\t// \n\tstatic KryoRegistration.SerializerDefinitionType valueOf(String name);\n\t// ,  \n\tstatic KryoRegistration.SerializerDefinitionType[] values();\n}", "des": "IMPORTANT: the order of the enumerations must not change, since their ordinals are used for serialization."}
{"index": 1340, "repo": "flink-core-1.17.1", "code": "class LineBreakElement {\n\t// Transforms itself into String representation using given format.\n\tvoid format(Formatter formatter);\n\t// Creates a line break in the description.\n\tstatic LineBreakElement linebreak();\n}", "des": "Represents a line break in the Description."}
{"index": 1341, "repo": "flink-core-1.17.1", "code": "class LinkElement {\n\t// Transforms itself into String representation using given format.\n\tvoid format(Formatter formatter);\n\tString getLink();\n\tString getText();\n\t// Creates a link with a given url.\n\tstatic LinkElement link(String link);\n\t// Creates a link with a given url and description.\n\tstatic LinkElement link(String link, String text);\n}", "des": "Element that represents a link in the Description."}
{"index": 1342, "repo": "flink-core-1.17.1", "code": "class ListAccumulator<T> {\n\tvoid add(T value);\n\t// Duplicates the accumulator.\n\tAccumulator<T,ArrayList<T>> clone();\n\tArrayList<T> getLocalValue();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<T,ArrayList<T>> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "This accumulator stores a collection of objects."}
{"index": 1343, "repo": "flink-core-1.17.1", "code": "class ListCollector<T> {\n\t// Closes the collector.\n\tvoid close();\n\t// Emits a record.\n\tvoid collect(T record);\n}", "des": "A Collector that puts the collected elements into a given list."}
{"index": 1344, "repo": "flink-core-1.17.1", "code": "class ListElement {\n\t// Transforms itself into String representation using given format.\n\tvoid format(Formatter formatter);\n\tList<InlineElement> getEntries();\n\t// Creates a list with blocks of text.\n\tstatic ListElement list(InlineElement... elements);\n}", "des": "Represents a list in the Description."}
{"index": 1345, "repo": "flink-core-1.17.1", "code": "class ListKeyGroupedIterator<E> {\n\t// Returns an iterator over all values that belong to the current key.\n\tListKeyGroupedIterator.ValuesIterator getValues();\n\t// Moves the iterator to the next key.\n\tboolean nextKey();\n}", "des": "The KeyValueIterator returns a key and all values that belong to the key (share the same key)."}
{"index": 1346, "repo": "flink-core-1.17.1", "code": "class ListSerializerSnapshot<T> {\n\t// Creates an instance of the outer serializer with a given array of its nested serializers.\n\tprotected ListSerializer<T> createOuterSerializerWithNestedSerializers(TypeSerializer<?>[] nestedSerializers);\n\t// Returns the version of the current outer snapshot's written binary format.\n\tint getCurrentOuterSnapshotVersion();\n\t// Gets the nested serializers from the outer serializer.\n\tprotected TypeSerializer<?>[] getNestedSerializers(ListSerializer<T> outerSerializer);\n}", "des": "Snapshot class for the ListSerializer."}
{"index": 1347, "repo": "flink-core-1.17.1", "code": "interface ListState<T> {\n\t// Updates the operator state accessible by AppendingState.get() by adding the given values to existing list of values.\n\tvoid addAll(List<T> values);\n\t// Updates the operator state accessible by AppendingState.get() by updating existing values to to the given list of values.\n\tvoid update(List<T> values);\n}", "des": "State interface for partitioned list state in Operations. The state is accessed and modified by user functions, and checkpointed consistently by the system as part of the distributed snapshots."}
{"index": 1348, "repo": "flink-core-1.17.1", "code": "class LocalBlockLocation {\n\tint compareTo(BlockLocation o);\n\t// Get the list of hosts (hostname) hosting this block.\n\tString[] getHosts();\n\t// Get the length of the block.\n\tlong getLength();\n\t// Get the start offset of the file associated with this block.\n\tlong getOffset();\n}", "des": "Implementation of the BlockLocation interface for a local file system."}
{"index": 1349, "repo": "flink-core-1.17.1", "code": "class LocalDataInputStream {\n\tint available();\n\tvoid close();\n\t// Gets the current position in the input stream.\n\tlong getPos();\n\tint read();\n\tint read(byte[] buffer, int offset, int length);\n\t// Seek to the given offset from the start of the file.\n\tvoid seek(long desired);\n\tlong skip(long n);\n}", "des": "The LocalDataInputStream class is a wrapper class for a data input stream to the local file system."}
{"index": 1350, "repo": "flink-core-1.17.1", "code": "class LocalFileSystemFactory {\n\t// Creates a new file system for the given file system URI.\n\tFileSystem create(URI fsUri);\n\t// Gets the scheme of the file system created by this factory.\n\tString getScheme();\n}", "des": "A factory for the LocalFileSystem."}
{"index": 1351, "repo": "flink-core-1.17.1", "code": "class LocatableInputSplit {\n\tboolean equals(Object obj);\n\t// Returns the names of the hosts storing the data this input split refers to\n\tString[] getHostnames();\n\t// Returns the number of this input split.\n\tint getSplitNumber();\n}", "des": "A locatable input split is an input split referring to input data which is located on one or more hosts."}
{"index": 1352, "repo": "flink-core-1.17.1", "code": "class LocatableInputSplitAssigner {\n\t// Returns the next input split that shall be consumed.\n\tLocatableInputSplit getNextInputSplit(String host, int taskId);\n\tint getNumberOfLocalAssignments();\n\tint getNumberOfRemoteAssignments();\n\t// Return the splits to assigner if the task failed to process it.\n\tvoid returnInputSplit(List<InputSplit> splits, int taskId);\n}", "des": "The locatable input split assigner assigns to each host splits that are local, before assigning splits that are not local."}
{"index": 1353, "repo": "flink-core-1.17.1", "code": "class LongCounter {\n\tvoid add(long value);\n\t// Consider using add(long) instead for primitive long values\n\tvoid add(Long value);\n\t// Duplicates the accumulator.\n\tLongCounter clone();\n\tLong getLocalValue();\n\tlong getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Long,Long> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that sums up long values."}
{"index": 1354, "repo": "flink-core-1.17.1", "code": "class LongMaximum {\n\tvoid add(long value);\n\t// Consider using add(long) instead for primitive long values\n\tvoid add(Long value);\n\t// Duplicates the accumulator.\n\tLongMaximum clone();\n\tLong getLocalValue();\n\tlong getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Long,Long> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that finds the maximum long value."}
{"index": 1355, "repo": "flink-core-1.17.1", "code": "class LongMinimum {\n\tvoid add(long value);\n\t// Consider using add(long) instead for primitive long values\n\tvoid add(Long value);\n\t// Duplicates the accumulator.\n\tLongMinimum clone();\n\tLong getLocalValue();\n\tlong getLocalValuePrimitive();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<Long,Long> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "An accumulator that finds the minimum long value."}
{"index": 1356, "repo": "flink-core-1.17.1", "code": "class LongSumAggregator {\n\t// Adds the given value to the current aggregate.\n\tvoid aggregate(long value);\n\t// Aggregates the given element.\n\tvoid aggregate(LongValue element);\n\t// Gets the aggregator's current aggregate.\n\tLongValue getAggregate();\n\t// Resets the internal state of the aggregator.\n\tvoid reset();\n}", "des": "An Aggregator that sums up long values."}
{"index": 1357, "repo": "flink-core-1.17.1", "code": "class LongValueParser {\n\t// Returns an instance of the parsed value type.\n\tLongValue createValue();\n\t// Gets the parsed field.\n\tLongValue getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, LongValue reusable);\n}", "des": "Parses a decimal text field into a LongValue. Only characters '1' to '0' and '-' are allowed."}
{"index": 1358, "repo": "flink-core-1.17.1", "code": "class LongValueSequenceIterator {\n\tlong getCurrent();\n\t// The maximum number of splits into which this iterator can be split up.\n\tint getMaximumNumberOfSplits();\n\tlong getTo();\n\tboolean hasNext();\n\tLongValue next();\n\tvoid remove();\n\t// Splits this iterator into a number disjoint iterators.\n\tLongValueSequenceIterator[] split(int numPartitions);\n}", "des": "The LongValueSequenceIterator is an iterator that returns a sequence of numbers (as LongValue)s. The iterator is splittable (as defined by SplittableIterator, i.e., it can be divided into multiple iterators that each return a subsequence of the number sequence."}
{"index": 1359, "repo": "flink-core-1.17.1", "code": "enum ManagedMemoryUseCase {\n\t// \n\tstatic ManagedMemoryUseCase valueOf(String name);\n\t// ,  \n\tstatic ManagedMemoryUseCase[] values();\n}", "des": "Use cases of managed memory."}
{"index": 1360, "repo": "flink-core-1.17.1", "code": "enum ManagedMemoryUseCase.Scope {\n\t// \n\tstatic ManagedMemoryUseCase.Scope valueOf(String name);\n\t// ,  \n\tstatic ManagedMemoryUseCase.Scope[] values();\n}", "des": "Scope at which memory is managed for a use case."}
{"index": 1361, "repo": "flink-core-1.17.1", "code": "class ManualClock {\n\t// Gets the current absolute time, in milliseconds.\n\tlong absoluteTimeMillis();\n\t// Advances the time by the given duration.\n\tvoid advanceTime(java.time.Duration duration);\n\t// Advances the time by the given duration.\n\tvoid advanceTime(long duration, TimeUnit timeUnit);\n\t// Gets the current relative time, in milliseconds.\n\tlong relativeTimeMillis();\n\t// Gets the current relative time, in nanoseconds.\n\tlong relativeTimeNanos();\n}", "des": "A Clock implementation which allows to advance time manually."}
{"index": 1362, "repo": "flink-core-1.17.1", "code": "class MapStateDescriptor<UK,UV> {\n\t// Gets the serializer for the keys in the state.\n\tTypeSerializer<UK> getKeySerializer();\n\tStateDescriptor.Type getType();\n\t// Gets the serializer for the values in the state.\n\tTypeSerializer<UV> getValueSerializer();\n}", "des": "A StateDescriptor for MapState. This can be used to create state where the type is a map that can be updated and iterated over."}
{"index": 1363, "repo": "flink-core-1.17.1", "code": "enum MemorySize.MemoryUnit {\n\tstatic String getAllUnits();\n\tlong getMultiplier();\n\tString[] getUnits();\n\tstatic boolean hasUnit(String text);\n\t// \n\tstatic MemorySize.MemoryUnit valueOf(String name);\n\t// ,  \n\tstatic MemorySize.MemoryUnit[] values();\n}", "des": "Enum which defines memory unit, mostly used to parse value from configuration file."}
{"index": 1364, "repo": "flink-core-1.17.1", "code": "enum MetricOptions.JobStatusMetrics {\n\t// Returns the description for the enum constant.\n\tInlineElement getDescription();\n\t// \n\tstatic MetricOptions.JobStatusMetrics valueOf(String name);\n\t// ,  \n\tstatic MetricOptions.JobStatusMetrics[] values();\n}", "des": "Enum describing the different kinds of job status metrics."}
{"index": 1365, "repo": "flink-core-1.17.1", "code": "class MultisetTypeInfo<T> {\n\t// Returns true if the given object can be equaled with this object.\n\tboolean canEqual(Object obj);\n\tboolean equals(Object obj);\n\t// Gets the type information for the elements contained in the Multiset\n\tTypeInformation<T> getElementTypeInfo();\n\tstatic <C> MultisetTypeInfo<C> getInfoFor(TypeInformation<C> componentInfo);\n}", "des": "A TypeInformation for the Multiset types of the Java API."}
{"index": 1366, "repo": "flink-core-1.17.1", "code": "interface MutableObjectIterator<E> {\n\t// Gets the next element from the collection.\n\tE next();\n\t// Gets the next element from the collection.\n\tE next(E reuse);\n}", "des": "A simple iterator interface. The key differences to the Iterator are It has two distinct next(), where one variant allows to pass an object that may be reused, if the type is mutable. It consolidates the logic in a single next() function, rather than splitting it over two different functions such as hasNext() and next()"}
{"index": 1367, "repo": "flink-core-1.17.1", "code": "interface NormalizableKey<T> {\n\t// Writes a normalized key for the given record into the target byte array, starting at the specified position an writing exactly the given number of bytes.\n\tvoid copyNormalizedKey(MemorySegment memory, int offset, int len);\n\t// Gets the maximal length of normalized keys that the data type would produce to determine the order of instances solely by the normalized key.\n\tint getMaxNormalizedKeyLen();\n}", "des": "The base interface for normalizable keys. Normalizable keys can create a binary representation of themselves that is byte-wise comparable. The byte-wise comparison of two normalized keys proceeds until all bytes are compared or two bytes at the corresponding positions are not equal. If two corresponding byte values are not equal, the lower byte value indicates the lower key. If both normalized keys are byte-wise identical, the actual key may have to be looked at to determine which one is actually lower."}
{"index": 1368, "repo": "flink-core-1.17.1", "code": "class NoWatermarksGenerator<E> {\n\t// Called for every event, allows the watermark generator to examine and remember the event timestamps, or to emit a watermark based on the event itself.\n\tvoid onEvent(E event, long eventTimestamp, WatermarkOutput output);\n\t// Called periodically, and might emit a new watermark, or not.\n\tvoid onPeriodicEmit(WatermarkOutput output);\n}", "des": "An implementation of a WatermarkGenerator that generates no Watermarks."}
{"index": 1369, "repo": "flink-core-1.17.1", "code": "class NumberSequenceIterator {\n\tlong getCurrent();\n\t// The maximum number of splits into which this iterator can be split up.\n\tint getMaximumNumberOfSplits();\n\tlong getTo();\n\tboolean hasNext();\n\tLong next();\n\tvoid remove();\n\t// Splits this iterator into a number disjoint iterators.\n\tNumberSequenceIterator[] split(int numPartitions);\n}", "des": "The NumberSequenceIterator is an iterator that returns a sequence of numbers (as Long)s. The iterator is splittable (as defined by SplittableIterator, i.e., it can be divided into multiple iterators that each return a subsequence of the number sequence."}
{"index": 1370, "repo": "flink-core-1.17.1", "code": "class NumberSequenceSource.NumberSequenceSplit {\n\tlong from();\n\t// Gets the iterator over the elements of this split.\n\tNumberSequenceIterator getIterator();\n\t// Converts an iterator (that may have returned some elements already) back into a source split.\n\tIteratorSourceSplit<Long,NumberSequenceIterator> getUpdatedSplitForIterator(NumberSequenceIterator iterator);\n\t// Get the split id of this source split.\n\tString splitId();\n\tlong to();\n}", "des": "A split of the source, representing a number sub-sequence."}
{"index": 1371, "repo": "flink-core-1.17.1", "code": "class OptionalUtils {\n\t// Returns the first Optional which is present.\n\tstatic <T> Optional<T> firstPresent(Optional<T>... opts);\n\t// Converts the given Optional into a Stream.\n\tstatic <T> java.util.stream.Stream<T> stream(Optional<T> opt);\n}", "des": "Utilities for working with Optional."}
{"index": 1372, "repo": "flink-core-1.17.1", "code": "enum Order {\n\tString getShortName();\n\t// Checks, if this enum constant represents in fact an order.\n\tboolean isOrdered();\n\t// \n\tstatic Order valueOf(String name);\n\t// ,  \n\tstatic Order[] values();\n}", "des": "Enumeration representing order. May represent no order, an ascending order or a descending order."}
{"index": 1373, "repo": "flink-core-1.17.1", "code": "interface OutputFormat<IT> {\n\t// Method that marks the end of the life-cycle of parallel output instance.\n\tvoid close();\n\t// Configures this output format.\n\tvoid configure(Configuration parameters);\n\t// Opens a parallel instance of the output format to store the result of its parallel instance.\n\tdefault void open(OutputFormat.InitializationContext context);\n\t// Adds a record to the output.\n\tvoid writeRecord(IT record);\n}", "des": "The base interface for outputs that consumes records. The output format describes how to store the final records, for example in a file."}
{"index": 1374, "repo": "flink-core-1.17.1", "code": "interface OutputFormat.InitializationContext {\n\t// Gets the attempt number of this parallel subtask.\n\tint getAttemptNumber();\n\t// Gets the parallelism with which the parallel task runs.\n\tint getNumTasks();\n\t// Gets the number of this parallel subtask.\n\tint getTaskNumber();\n}", "des": "The context exposes some runtime info for initializing output format."}
{"index": 1375, "repo": "flink-core-1.17.1", "code": "interface PipelineExecutorFactory {\n\t// Instantiates an PipelineExecutor compatible with the provided configuration.\n\tPipelineExecutor getExecutor(Configuration configuration);\n\t// Returns the name of the executor that this factory creates.\n\tString getName();\n\t// Returns true if this factory is compatible with the options in the provided configuration, false otherwise.\n\tboolean isCompatibleWith(Configuration configuration);\n}", "des": "A factory for selecting and instantiating the adequate PipelineExecutor based on a provided Configuration."}
{"index": 1376, "repo": "flink-core-1.17.1", "code": "interface PipelineExecutorServiceLoader {\n\t// Loads the PipelineExecutorFactory which is compatible with the provided configuration.\n\tPipelineExecutorFactory getExecutorFactory(Configuration configuration);\n\t// Loads and returns a stream of the names of all available executors.\n\tjava.util.stream.Stream<String> getExecutorNames();\n}", "des": "An interface to be implemented by the entity responsible for finding the correct PipelineExecutor to execute a given Pipeline."}
{"index": 1377, "repo": "flink-core-1.17.1", "code": "enum PipelineOptions.VertexDescriptionMode {\n\t// \n\tstatic PipelineOptions.VertexDescriptionMode valueOf(String name);\n\t// ,  \n\tstatic PipelineOptions.VertexDescriptionMode[] values();\n}", "des": "The mode how we organize description of a vertex."}
{"index": 1378, "repo": "flink-core-1.17.1", "code": "interface Plugin {\n\t// Optional method for plugins to pick up settings from the configuration.\n\tdefault void configure(Configuration config);\n\t// Helper method to get the class loader used to load the plugin.\n\tdefault ClassLoader getClassLoader();\n}", "des": "Interface for plugins. Plugins typically extend this interface in their SPI and the concrete implementations of a service then implement the SPI contract."}
{"index": 1379, "repo": "flink-core-1.17.1", "code": "class PluginFileSystemFactory {\n\t// Optional method for plugins to pick up settings from the configuration.\n\tvoid configure(Configuration config);\n\t// Creates a new file system for the given file system URI.\n\tFileSystem create(URI fsUri);\n\t// Helper method to get the class loader used to load the plugin.\n\tClassLoader getClassLoader();\n\t// Gets the scheme of the file system created by this factory.\n\tString getScheme();\n\tstatic PluginFileSystemFactory of(FileSystemFactory inner);\n}", "des": "A wrapper around FileSystemFactory that ensures the plugin classloader is used for all FileSystem operations."}
{"index": 1380, "repo": "flink-core-1.17.1", "code": "class PrintSinkOutputWriter<IN> {\n\tvoid close();\n\t// Called on checkpoint or end of input so that the writer to flush all pending data for at-least-once.\n\tvoid flush(boolean endOfInput);\n\tvoid open(int subtaskIndex, int numParallelSubtasks);\n\tvoid write(IN record);\n\t// Adds an element to the writer.\n\tvoid write(IN element, SinkWriter.Context context);\n}", "des": "Print sink output writer for DataStream and DataSet print API."}
{"index": 1381, "repo": "flink-core-1.17.1", "code": "interface ProcessingTimeService {\n\t// Returns the current processing time.\n\tlong getCurrentProcessingTime();\n\t// Registers a task to be executed when (processing) time is timestamp.\n\tScheduledFuture<?> registerTimer(long timestamp, ProcessingTimeService.ProcessingTimeCallback target);\n}", "des": "A service that allows to get the current processing time and register timers that will execute the given ProcessingTimeService.ProcessingTimeCallback when firing."}
{"index": 1382, "repo": "flink-core-1.17.1", "code": "enum ProcessorArchitecture.MemoryAddressSize {\n\t// \n\tstatic ProcessorArchitecture.MemoryAddressSize valueOf(String name);\n\t// ,  \n\tstatic ProcessorArchitecture.MemoryAddressSize[] values();\n}", "des": "The memory address size of the processor."}
{"index": 1383, "repo": "flink-core-1.17.1", "code": "interface RateLimiter {\n\t// Returns a future that is completed once another event would not exceed the rate limit.\n\tCompletionStage<Void> acquire();\n\t// Notifies this RateLimiter that the checkpoint with the given checkpointId completed and was committed.\n\tdefault void notifyCheckpointComplete(long checkpointId);\n}", "des": "The interface to rate limit execution of methods."}
{"index": 1384, "repo": "flink-core-1.17.1", "code": "interface ReadableConfig {\n\t// Reads a value using the metadata included in ConfigOption.\n\t<T> T get(ConfigOption<T> option);\n\t// Reads a value using the metadata included in ConfigOption.\n\t<T> Optional<T> getOptional(ConfigOption<T> option);\n}", "des": "Read access to a configuration object. Allows reading values described with meta information included in ConfigOption."}
{"index": 1385, "repo": "flink-core-1.17.1", "code": "interface ReadOnlyBroadcastState<K,V> {\n\t// Returns whether there exists the given mapping.\n\tboolean contains(K key);\n\t// Returns the current value associated with the given key.\n\tV get(K key);\n\t// Returns an immutable Iterable over the entries in the state.\n\tIterable<Map.Entry<K,V>> immutableEntries();\n}", "des": "A read-only view of the BroadcastState."}
{"index": 1386, "repo": "flink-core-1.17.1", "code": "class RecoverableFsDataOutputStream {\n\t// Closes this stream.\n\tabstract void close();\n\t// Closes the stream, ensuring persistence of all data (similar to FSDataOutputStream.sync()).\n\tabstract RecoverableFsDataOutputStream.Committer closeForCommit();\n\t// Ensures all data so far is persistent (similar to FSDataOutputStream.sync()) and returns a handle to recover the stream at the current position.\n\tabstract RecoverableWriter.ResumeRecoverable persist();\n}", "des": "An output stream to a file system that can be recovered at well defined points. The stream initially writes to hidden files or temp files and only creates the target file once it is closed and \"committed\"."}
{"index": 1387, "repo": "flink-core-1.17.1", "code": "interface RecoverableFsDataOutputStream.Committer {\n\t// Commits the file, making it visible.\n\tvoid commit();\n\t// Commits the file, making it visible.\n\tvoid commitAfterRecovery();\n\t// Gets a recoverable object to recover the committer.\n\tRecoverableWriter.CommitRecoverable getRecoverable();\n}", "des": "A committer can publish the file of a stream that was closed. The Committer can be recovered via a RecoverableWriter.CommitRecoverable."}
{"index": 1388, "repo": "flink-core-1.17.1", "code": "enum ReduceOperatorBase.CombineHint {\n\t// \n\tstatic ReduceOperatorBase.CombineHint valueOf(String name);\n\t// ,  \n\tstatic ReduceOperatorBase.CombineHint[] values();\n}", "des": "An enumeration of hints, optionally usable to tell the system exactly how to execute the combiner phase of a reduce. (Note: The final reduce phase (after combining) is currently always executed by a sort-based strategy.)"}
{"index": 1389, "repo": "flink-core-1.17.1", "code": "interface RefCounted {\n\t// Decreases the reference counter.\n\tboolean release();\n\t// Increases the reference counter.\n\tvoid retain();\n}", "des": "Interface to simply add reference counting functionality."}
{"index": 1390, "repo": "flink-core-1.17.1", "code": "class RefCountedFile {\n\tFile getFile();\n\tint getReferenceCounter();\n\t// Decreases the reference counter.\n\tboolean release();\n\t// Increases the reference counter.\n\tvoid retain();\n}", "des": "A reference counted file which is deleted as soon as no caller holds a reference to the wrapped File."}
{"index": 1391, "repo": "flink-core-1.17.1", "code": "class RefCountedFSOutputStream {\n\t// Gets the underlying File that allows to read the contents of the file.\n\tabstract File getInputFile();\n\t// Checks if the file is closed for writes.\n\tabstract boolean isClosed();\n}", "des": "A FSDataOutputStream with the RefCounted functionality."}
{"index": 1392, "repo": "flink-core-1.17.1", "code": "class ReplicatingInputSplitAssigner {\n\t// Returns the next input split that shall be consumed.\n\tInputSplit getNextInputSplit(String host, int taskId);\n\t// Return the splits to assigner if the task failed to process it.\n\tvoid returnInputSplit(List<InputSplit> splits, int taskId);\n}", "des": "Assigns each InputSplit to each requesting parallel instance. This causes the input to be fully replicated, i.e., each parallel instance consumes the full input."}
{"index": 1393, "repo": "flink-core-1.17.1", "code": "class RichAggregateFunction<IN,ACC,OUT> {\n\t// Adds the given input value to the given accumulator, returning the new accumulator value.\n\tabstract ACC add(IN value, ACC accumulator);\n\t// Creates a new accumulator, starting a new aggregate.\n\tabstract ACC createAccumulator();\n\t// Gets the result of the aggregation from the accumulator.\n\tabstract OUT getResult(ACC accumulator);\n\t// Merges two accumulators, returning an accumulator with the merged state.\n\tabstract ACC merge(ACC a, ACC b);\n}", "des": "Rich variant of the AggregateFunction. As a RichFunction, it gives access to the RuntimeContext and provides setup and teardown methods: RichFunction.open(org.apache.flink.configuration.Configuration) and RichFunction.close()."}
{"index": 1394, "repo": "flink-core-1.17.1", "code": "class RichInputFormat<OT,T extends InputSplit> {\n\t// Closes this InputFormat instance.\n\tvoid closeInputFormat();\n\tRuntimeContext getRuntimeContext();\n\t// Opens this InputFormat instance.\n\tvoid openInputFormat();\n\tvoid setRuntimeContext(RuntimeContext t);\n}", "des": "An abstract stub implementation for Rich input formats. Rich formats have access to their runtime execution context via getRuntimeContext()."}
{"index": 1395, "repo": "flink-core-1.17.1", "code": "enum RowKind {\n\t// Creates a RowKind from the given byte value.\n\tstatic RowKind fromByteValue(byte value);\n\t// Returns a short string representation of this RowKind.\n\tString shortString();\n\t// Returns the byte value representation of this RowKind.\n\tbyte toByteValue();\n\t// \n\tstatic RowKind valueOf(String name);\n\t// ,  \n\tstatic RowKind[] values();\n}", "des": "Lists all kinds of changes that a row can describe in a changelog."}
{"index": 1396, "repo": "flink-core-1.17.1", "code": "class RowUtils {\n\t// Compares two Lists of Row for deep equality.\n\tstatic boolean compareRows(List<Row> l1, List<Row> l2);\n\t// Compares two Lists of Row for deep equality.\n\tstatic boolean compareRows(List<Row> l1, List<Row> l2, boolean ignoreOrder);\n\t// Internal utility for creating a row in static named-position field mode.\n\tstatic Row createRowWithNamedPositions(RowKind kind, Object[] fieldByPosition, LinkedHashMap<String,Integer> positionByName);\n}", "des": "Utilities to deal with Row instances."}
{"index": 1397, "repo": "flink-core-1.17.1", "code": "enum RuntimeExecutionMode {\n\t// \n\tstatic RuntimeExecutionMode valueOf(String name);\n\t// ,  \n\tstatic RuntimeExecutionMode[] values();\n}", "des": "Runtime execution mode of DataStream programs. Among other things, this controls task scheduling, network shuffle behavior, and time semantics. Some operations will also change their record emission behaviour based on the configured execution mode."}
{"index": 1398, "repo": "flink-core-1.17.1", "code": "enum SavepointFormatType {\n\t// Returns the description for the enum constant.\n\tInlineElement getDescription();\n\t// \n\tstatic SavepointFormatType valueOf(String name);\n\t// ,  \n\tstatic SavepointFormatType[] values();\n}", "des": "Describes the binary format in which a savepoint should be taken."}
{"index": 1399, "repo": "flink-core-1.17.1", "code": "enum SchedulerExecutionMode {\n\t// \n\tstatic SchedulerExecutionMode valueOf(String name);\n\t// ,  \n\tstatic SchedulerExecutionMode[] values();\n}", "des": "Enum for controlling whether REACTIVE mode is enabled or not."}
{"index": 1400, "repo": "flink-core-1.17.1", "code": "interface SerializationSchema<T> {\n\t// Initialization method for the schema.\n\tdefault void open(SerializationSchema.InitializationContext context);\n\t// Serializes the incoming element to a specified type.\n\tbyte[] serialize(T element);\n}", "des": "The serialization schema describes how to turn a data object into a different serialized representation. Most data sinks (for example Apache Kafka) require the data to be handed to them in a specific format (for example as byte strings)."}
{"index": 1401, "repo": "flink-core-1.17.1", "code": "interface SerializationSchema.InitializationContext {\n\t// Returns the metric group for the parallel subtask of the source that runs this SerializationSchema.\n\torg.apache.flink.metrics.MetricGroup getMetricGroup();\n\t// Gets the UserCodeClassLoader to load classes that are not in system's classpath, but are part of the jar file of a user job.\n\tUserCodeClassLoader getUserCodeClassLoader();\n}", "des": "A contextual information provided for SerializationSchema.open(InitializationContext) method. It can be used to: Register user metrics via getMetricGroup() Access the user code class loader."}
{"index": 1402, "repo": "flink-core-1.17.1", "code": "class SerializedListAccumulator<T> {\n\tvoid add(T value);\n\tvoid add(T value, TypeSerializer<T> serializer);\n\t// Duplicates the accumulator.\n\tSerializedListAccumulator<T> clone();\n\tstatic <T> List<T> deserializeList(ArrayList<byte[]> data, TypeSerializer<T> serializer);\n\tArrayList<byte[]> getLocalValue();\n\t// Used by system internally to merge the collected parts of an accumulator at the end of the job.\n\tvoid merge(Accumulator<T,ArrayList<byte[]>> other);\n\t// Reset the local value.\n\tvoid resetLocal();\n}", "des": "This accumulator stores a collection of objects in serialized form, so that the stored objects are not affected by modifications to the original objects."}
{"index": 1403, "repo": "flink-core-1.17.1", "code": "class SerializedValue<T> {\n\tT deserializeValue(ClassLoader loader);\n\tboolean equals(Object obj);\n\t// Constructs serialized value from serialized data.\n\tstatic <T> SerializedValue<T> fromBytes(byte[] serializedData);\n\t// Returns byte array for serialized data.\n\tbyte[] getByteArray();\n}", "des": "This class is used to transfer (via serialization) objects whose classes are not available in the system class loader. When those objects are deserialized without access to their special class loader, the deserialization fails with a ClassNotFoundException."}
{"index": 1404, "repo": "flink-core-1.17.1", "code": "class ShortValueParser {\n\t// Returns an instance of the parsed value type.\n\tShortValue createValue();\n\t// Gets the parsed field.\n\tShortValue getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, ShortValue reusable);\n}", "des": "Parses a decimal text field into a ShortValue. Only characters '1' to '0' and '-' are allowed."}
{"index": 1405, "repo": "flink-core-1.17.1", "code": "class ShutdownHookUtil {\n\t// Adds a shutdown hook to the JVM and returns the Thread, which has been registered.\n\tstatic Thread addShutdownHook(AutoCloseable service, String serviceName, org.slf4j.Logger logger);\n\t// Adds a shutdown hook to the JVM.\n\tstatic boolean addShutdownHookThread(Thread shutdownHook, String serviceName, org.slf4j.Logger logger);\n\t// Removes a shutdown hook from the JVM.\n\tstatic void removeShutdownHook(Thread shutdownHook, String serviceName, org.slf4j.Logger logger);\n}", "des": "Utils class for dealing with JVM shutdown hooks."}
{"index": 1406, "repo": "flink-core-1.17.1", "code": "class SimpleUserCodeClassLoader {\n\t// Obtains the actual class loader.\n\tClassLoader asClassLoader();\n\tstatic SimpleUserCodeClassLoader create(ClassLoader classLoader);\n\t// Registers a release hook which is being executed before the user code class loader is being released.\n\tvoid registerReleaseHookIfAbsent(String releaseHookName, Runnable releaseHook);\n}", "des": "Simple UserCodeClassLoader implementation which assumes that the provided class loader will never be released and, hence, will never execute the release hooks."}
{"index": 1407, "repo": "flink-core-1.17.1", "code": "interface SimpleVersionedSerializer<E> {\n\t// De-serializes the given data (bytes) which was serialized with the scheme of the indicated version.\n\tE deserialize(int version, byte[] serialized);\n\t// Gets the version with which this serializer serializes.\n\tint getVersion();\n\t// Serializes the given object.\n\tbyte[] serialize(E obj);\n}", "des": "A simple serializer interface for versioned serialization."}
{"index": 1408, "repo": "flink-core-1.17.1", "code": "interface SinkWriter<InputT> {\n\t// Called on checkpoint or end of input so that the writer to flush all pending data for at-least-once.\n\tvoid flush(boolean endOfInput);\n\t// Adds an element to the writer.\n\tvoid write(InputT element, SinkWriter.Context context);\n\t// Adds a watermark to the writer.\n\tdefault void writeWatermark(Watermark watermark);\n}", "des": "The SinkWriter is responsible for writing data."}
{"index": 1409, "repo": "flink-core-1.17.1", "code": "interface SinkWriter.Context {\n\t// Returns the current event-time watermark.\n\tlong currentWatermark();\n\t// Returns the timestamp of the current input record or null if the element does not have an assigned timestamp.\n\tLong timestamp();\n}", "des": "Context that SinkWriter.write(InputT, org.apache.flink.api.connector.sink2.SinkWriter.Context) can use for getting additional data about an input record."}
{"index": 1410, "repo": "flink-core-1.17.1", "code": "interface SourceOutput<T> {\n\t// Emit a record without a timestamp.\n\tvoid collect(T record);\n\t// Emit a record with a timestamp.\n\tvoid collect(T record, long timestamp);\n}", "des": "The SourceOutput is the gateway for a SourceReader) to emit the produced records and watermarks."}
{"index": 1411, "repo": "flink-core-1.17.1", "code": "class SplittableIterator<T> {\n\t// The maximum number of splits into which this iterator can be split up.\n\tabstract int getMaximumNumberOfSplits();\n\t// Splits this iterator into n partitions and returns the i-th partition out of those.\n\tIterator<T> getSplit(int num, int numPartitions);\n\t// Splits this iterator into a number disjoint iterators.\n\tabstract Iterator<T>[] split(int numPartitions);\n}", "des": "Abstract base class for iterators that can split themselves into multiple disjoint iterators. The union of these iterators returns the original iterator values."}
{"index": 1412, "repo": "flink-core-1.17.1", "code": "enum StateDescriptor.Type {\n\t// \n\tstatic StateDescriptor.Type valueOf(String name);\n\t// ,  \n\tstatic StateDescriptor.Type[] values();\n}", "des": "An enumeration of the types of supported states. Used to identify the state type when writing and restoring checkpoints and savepoints."}
{"index": 1413, "repo": "flink-core-1.17.1", "code": "enum StateTtlConfig.StateVisibility {\n\t// \n\tstatic StateTtlConfig.StateVisibility valueOf(String name);\n\t// ,  \n\tstatic StateTtlConfig.StateVisibility[] values();\n}", "des": "This option configures whether expired user value can be returned or not."}
{"index": 1414, "repo": "flink-core-1.17.1", "code": "enum StateTtlConfig.TtlTimeCharacteristic {\n\t// \n\tstatic StateTtlConfig.TtlTimeCharacteristic valueOf(String name);\n\t// ,  \n\tstatic StateTtlConfig.TtlTimeCharacteristic[] values();\n}", "des": "This option configures time scale to use for ttl."}
{"index": 1415, "repo": "flink-core-1.17.1", "code": "enum StateTtlConfig.UpdateType {\n\t// \n\tstatic StateTtlConfig.UpdateType valueOf(String name);\n\t// ,  \n\tstatic StateTtlConfig.UpdateType[] values();\n}", "des": "This option value configures when to update last access timestamp which prolongs state TTL."}
{"index": 1416, "repo": "flink-core-1.17.1", "code": "class StringParser {\n\t// Returns an instance of the parsed value type.\n\tString createValue();\n\tvoid enableQuotedStringParsing(byte quoteCharacter);\n\t// Gets the parsed field.\n\tString getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, String reusable);\n}", "des": "Converts a variable length field of a byte array into a String. The byte contents between delimiters is interpreted as an ASCII string. The string may be quoted in double quotes. For quoted strings, whitespaces (space and tab) leading and trailing before and after the quotes are removed."}
{"index": 1417, "repo": "flink-core-1.17.1", "code": "class StringValueParser {\n\t// Returns an instance of the parsed value type.\n\tStringValue createValue();\n\tvoid enableQuotedStringParsing(byte quoteCharacter);\n\t// Gets the parsed field.\n\tStringValue getLastResult();\n\t// Each parser's logic should be implemented inside this method\n\tint parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, StringValue reusable);\n}", "des": "Converts a variable length field of a byte array into a StringValue. The byte contents between delimiters is interpreted as an ASCII string. The string may be quoted in double quotes. For quoted strings, whitespaces (space and tab) leading and trailing before and after the quotes are removed."}
{"index": 1418, "repo": "flink-core-1.17.1", "code": "class StringValueUtils {\n\t// Replaces all non-word characters in a string by a given character.\n\tstatic void replaceNonWordChars(StringValue string, char replacement);\n\t// Converts the given StringValue into a lower case variant.\n\tstatic void toLowerCase(StringValue string);\n}", "des": "Utility class for efficient operations on StringValue."}
{"index": 1419, "repo": "flink-core-1.17.1", "code": "class StringValueUtils.WhitespaceTokenizer {\n\t// Gets the next token from the string.\n\tboolean next(StringValue target);\n\t// Sets the string to be tokenized and resets the state of the tokenizer.\n\tvoid setStringToTokenize(StringValue string);\n}", "des": "A tokenizer for string values that uses whitespace characters as token delimiters. The tokenizer is designed to have a resettable state and operate on mutable objects, sparing object allocation and garbage collection overhead."}
{"index": 1420, "repo": "flink-core-1.17.1", "code": "class SystemClock {\n\t// Gets the current absolute time, in milliseconds.\n\tlong absoluteTimeMillis();\n\tstatic SystemClock getInstance();\n\t// Gets the current relative time, in milliseconds.\n\tlong relativeTimeMillis();\n\t// Gets the current relative time, in nanoseconds.\n\tlong relativeTimeNanos();\n}", "des": "A clock that returns the time of the system / process."}
{"index": 1421, "repo": "flink-core-1.17.1", "code": "enum TextElement.TextStyle {\n\t// \n\tstatic TextElement.TextStyle valueOf(String name);\n\t// ,  \n\tstatic TextElement.TextStyle[] values();\n}", "des": "Styles that can be applied to TextElement e.g. code, bold etc."}
{"index": 1422, "repo": "flink-core-1.17.1", "code": "interface ThrowingRunnable<E extends Throwable> {\n\t// The work method.\n\tvoid run();\n\t// Converts a ThrowingRunnable into a Runnable which throws all checked exceptions as unchecked.\n\tstatic Runnable unchecked(ThrowingRunnable<?> throwingRunnable);\n}", "des": "Similar to a Runnable, this interface is used to capture a block of code to be executed. In contrast to Runnable, this interface allows throwing checked exceptions."}
{"index": 1423, "repo": "flink-core-1.17.1", "code": "class TimeUtils {\n\t// Pretty prints the duration as a lowest granularity unit that does not lose precision.\n\tstatic String formatWithHighestUnit(java.time.Duration duration);\n\tstatic String getStringInMillis(java.time.Duration duration);\n\t// Parse the given string to a java Duration.\n\tstatic java.time.Duration parseDuration(String text);\n\t// Translates Time to Duration.\n\tstatic java.time.Duration toDuration(Time time);\n}", "des": "Collection of utilities about time intervals."}
{"index": 1424, "repo": "flink-core-1.17.1", "code": "interface TriConsumerWithException<S,T,U,E extends Throwable> {\n\t// Performs this operation on the given arguments.\n\tvoid accept(S s, T t, U u);\n\t// Convert a TriConsumerWithException into a TriConsumer.\n\tstatic <A,B,C> TriConsumer<A,B,C> unchecked(TriConsumerWithException<A,B,C,?> triConsumerWithException);\n}", "des": "A checked extension of the TriConsumer interface."}
{"index": 1425, "repo": "flink-core-1.17.1", "code": "interface TriFunctionWithException<S,T,U,R,E extends Throwable> {\n\t// Applies this function to the given arguments.\n\tR apply(S s, T t, U u);\n\t// Convert at TriFunctionWithException into a TriFunction.\n\tstatic <A,B,C,D> TriFunction<A,B,C,D> unchecked(TriFunctionWithException<A,B,C,D,?> triFunctionWithException);\n}", "des": "Function which takes three arguments."}
{"index": 1426, "repo": "flink-core-1.17.1", "code": "class Tuple0 {\n\t// Shallow tuple copy.\n\tTuple0 copy();\n\t// Deep equality for tuples by calling equals() on the tuple members.\n\tboolean equals(Object o);\n\t// Gets the number of field in the tuple (the tuple arity).\n\tint getArity();\n\t// Gets the field at the specified position.\n\t<T> T getField(int pos);\n\t// Sets the field at the specified position.\n\t<T> void setField(T value, int pos);\n}", "des": "A tuple with 0 fields."}
{"index": 1427, "repo": "flink-core-1.17.1", "code": "class TypeInformationSerializationSchema<T> {\n\t// Deserializes the byte message.\n\tT deserialize(byte[] message);\n\t// Gets the data type (as a TypeInformation) produced by this function or input format.\n\tTypeInformation<T> getProducedType();\n\t// This schema never considers an element to signal end-of-stream, so this method returns always false.\n\tboolean isEndOfStream(T nextElement);\n\t// Serializes the incoming element to a specified type.\n\tbyte[] serialize(T element);\n}", "des": "A serialization and deserialization schema that uses Flink's serialization stack to transform typed from and to byte arrays."}
{"index": 1428, "repo": "flink-core-1.17.1", "code": "class TypePairComparator<T1,T2> {\n\tabstract int compareToReference(T2 candidate);\n\t// Checks, whether the given candidate instance is equal to the reference instance, with respect to this comparator's equality definition.\n\tabstract boolean equalToReference(T2 candidate);\n\t// Sets the reference for comparisons.\n\tabstract void setReference(T1 reference);\n}", "des": "This interface defines the method required by the runtime to use data types in join-like operations. In such operations, instances of different data types are compared for equality with respect to certain attributes, such as join keys."}
{"index": 1429, "repo": "flink-core-1.17.1", "code": "class UnmodifiableConfiguration {\n\tvoid addAll(Configuration other);\n\t// Adds all entries from the given configuration into this configuration.\n\tvoid addAll(Configuration other, String prefix);\n\t// Adds all entries in this Configuration to the given Properties.\n\tvoid addAllToProperties(Properties props);\n\t// Removes given config option from the configuration.\n\t<T> boolean removeConfig(ConfigOption<T> configOption);\n}", "des": "Unmodifiable version of the Configuration class."}
{"index": 1430, "repo": "flink-core-1.17.1", "code": "interface UserCodeClassLoader {\n\t// Obtains the actual class loader.\n\tClassLoader asClassLoader();\n\t// Registers a release hook which is being executed before the user code class loader is being released.\n\tvoid registerReleaseHookIfAbsent(String releaseHookName, Runnable releaseHook);\n}", "des": "UserCodeClassLoader allows to register release hooks for a user code class loader."}
{"index": 1431, "repo": "flink-core-1.17.1", "code": "class ValueSerializer.ValueSerializerSnapshot<T extends Value> {\n\t// Create a serializer that is able to serialize the generic type typeClass.\n\tprotected TypeSerializer<T> createSerializer(Class<T> typeClass);\n\t// Gets the type class from the corresponding serializer.\n\tprotected Class<T> getTypeClass(ValueSerializer serializer);\n\t// Gets the serializer's class.\n\tprotected Class<?> serializerClass();\n}", "des": "ValueSerializer snapshot class."}
{"index": 1432, "repo": "flink-core-1.17.1", "code": "interface ValueState<T> {\n\t// Updates the operator state accessible by value() to the given value.\n\tvoid update(T value);\n\t// Returns the current value for the state.\n\tT value();\n}", "des": "State interface for partitioned single-value state. The value can be retrieved or updated."}
{"index": 1433, "repo": "flink-core-1.17.1", "code": "class VersionedIOReadableWritable {\n\tOptional<String> getAdditionalDetailsForIncompatibleVersion(int readVersion);\n\t// Returns the compatible version values.\n\tint[] getCompatibleVersions();\n\t// Returns the found serialization version.\n\tint getReadVersion();\n\t// Reads the object's internal data from the given data input view.\n\tvoid read(DataInputView in);\n\t// Writes the object's internal data to the given data output view.\n\tvoid write(DataOutputView out);\n}", "des": "This is the abstract base class for IOReadableWritable which allows to differentiate between serialization versions. Concrete subclasses should typically override the write(DataOutputView) and read(DataInputView), thereby calling super to ensure version checking."}
{"index": 1434, "repo": "flink-core-1.17.1", "code": "interface Visitor<T extends Visitable<T>> {\n\t// Method that is invoked after all child nodes or descendant nodes were visited.\n\tvoid postVisit(T visitable);\n\t// Method that is invoked on the visit before visiting and child nodes or descendant nodes.\n\tboolean preVisit(T visitable);\n}", "des": "A visitor encapsulates functionality that is applied to each node in the process of a traversal of a tree or DAG."}
{"index": 1435, "repo": "flink-core-1.17.1", "code": "class Watermark {\n\tboolean equals(Object o);\n\t// Formats the timestamp of this watermark, assuming it is a millisecond timestamp.\n\tString getFormattedTimestamp();\n\t// Returns the timestamp associated with this Watermark.\n\tlong getTimestamp();\n}", "des": "Watermarks are the progress indicators in the data streams. A watermark signifies that no events with a timestamp smaller or equal to the watermark's time will occur after the water. A watermark with timestamp T indicates that the stream's event time has progressed to time T."}
{"index": 1436, "repo": "flink-core-1.17.1", "code": "interface WatermarkGenerator<T> {\n\t// Called for every event, allows the watermark generator to examine and remember the event timestamps, or to emit a watermark based on the event itself.\n\tvoid onEvent(T event, long eventTimestamp, WatermarkOutput output);\n\t// Called periodically, and might emit a new watermark, or not.\n\tvoid onPeriodicEmit(WatermarkOutput output);\n}", "des": "The WatermarkGenerator generates watermarks either based on events or periodically (in a fixed interval)."}
{"index": 1437, "repo": "flink-core-1.17.1", "code": "interface WatermarkOutput {\n\t// Emits the given watermark.\n\tvoid emitWatermark(Watermark watermark);\n\t// Marks this output as active, meaning that downstream operations should wait for watermarks from this output.\n\tvoid markActive();\n\t// Marks this output as idle, meaning that downstream operations do not wait for watermarks from this output.\n\tvoid markIdle();\n}", "des": "An output for watermarks. The output accepts watermarks and idleness (inactivity) status."}
{"index": 1438, "repo": "flink-core-1.17.1", "code": "class WatermarksWithIdleness<T> {\n\t// Called for every event, allows the watermark generator to examine and remember the event timestamps, or to emit a watermark based on the event itself.\n\tvoid onEvent(T event, long eventTimestamp, WatermarkOutput output);\n\t// Called periodically, and might emit a new watermark, or not.\n\tvoid onPeriodicEmit(WatermarkOutput output);\n}", "des": "A WatermarkGenerator that adds idleness detection to another WatermarkGenerator. If no events come within a certain time (timeout duration) then this generator marks the stream as idle, until the next watermark is generated."}
{"index": 1439, "repo": "flink-core-1.17.1", "code": "class WrappingRuntimeException {\n\t// Recursively unwraps this WrappingRuntimeException and its causes, getting the first non wrapping exception.\n\tThrowable unwrap();\n\t// Ensures that any throwable can be thrown as a checked exception by potentially wrapping it.\n\tstatic RuntimeException wrapIfNecessary(Throwable throwable);\n}", "des": "A runtime exception that is explicitly used to wrap non-runtime exceptions."}
{"index": 1440, "repo": "flink-core-1.17.1", "code": "class XZInputStreamFactory {\n\t// Creates a InflaterInputStream that wraps the given input stream.\n\torg.apache.commons.compress.compressors.xz.XZCompressorInputStream create(InputStream in);\n\t// Lists a collection of typical file extensions (e.g., \"gz\", \"gzip\") that are associated with the compression algorithm in the InflaterInputStream T.\n\tCollection<String> getCommonFileExtensions();\n\tstatic XZInputStreamFactory getInstance();\n}", "des": "Factory for XZ decompressors."}
{"index": 1441, "repo": "flink-core-1.17.1", "code": "class ZStandardInputStreamFactory {\n\t// Creates a InflaterInputStream that wraps the given input stream.\n\torg.apache.commons.compress.compressors.zstandard.ZstdCompressorInputStream create(InputStream in);\n\t// Lists a collection of typical file extensions (e.g., \"gz\", \"gzip\") that are associated with the compression algorithm in the InflaterInputStream T.\n\tCollection<String> getCommonFileExtensions();\n\tstatic ZStandardInputStreamFactory getInstance();\n}", "des": "Factory for ZStandard decompressors."}
{"index": 1442, "repo": "pdfbox-3.0.0-beta1", "code": "Class AbstractXReference {\n\t// Compares this object with the specified object for order.\n\tint compareTo(XReferenceEntry xReferenceEntry);\n\t// Returns the value for the first column of the crossreference stream entry.\n\tlong getFirstColumnValue();\n\t// Returns the XReferenceType of this crossreference stream entry.\n\tXReferenceType getType();\n}", "des": "An extending class represents an entry, as it can be found in a PDF's crossreference stream (PDFXRefStream). Such an entry shall locate a PDF object/resource in a PDF document."}
{"index": 1443, "repo": "pdfbox-3.0.0-beta1", "code": "Class AppearanceStyle {\n\t// Set the font to be used for text formatting.\n\tvoid setFont(PDFont font);\n\t// Set the font size to be used for formatting.\n\tvoid setFontSize(float fontSize);\n}", "des": "Define styling attributes to be used for text formatting."}
{"index": 1444, "repo": "pdfbox-3.0.0-beta1", "code": "Class AppendRectangleToPath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "re Appends a rectangle to the path."}
{"index": 1445, "repo": "pdfbox-3.0.0-beta1", "code": "Class AxialShadingContext {\n\tvoid dispose();\n\t// Returns the coords values.\n\tfloat[] getCoords();\n\t// Returns the domain values.\n\tfloat[] getDomain();\n\t// Returns the extend values.\n\tboolean[] getExtend();\n\t// Returns the function.\n\tPDFunction getFunction();\n\tRaster getRaster(int x, int y, int w, int h);\n}", "des": "AWT PaintContext for axial shading. Performance improvement done as part of GSoC2014, Tilman Hausherr is the mentor."}
{"index": 1446, "repo": "pdfbox-3.0.0-beta1", "code": "Class BeginInlineImage {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "BI Begins an inline image."}
{"index": 1447, "repo": "pdfbox-3.0.0-beta1", "code": "Class BeginMarkedContentSequence {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "BMC : Begins a marked-content sequence."}
{"index": 1448, "repo": "pdfbox-3.0.0-beta1", "code": "Class BeginMarkedContentSequenceWithProperties {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "BDC : Begins a marked-content sequence with property list."}
{"index": 1449, "repo": "pdfbox-3.0.0-beta1", "code": "Class BeginText {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "BT: Begin text."}
{"index": 1450, "repo": "pdfbox-3.0.0-beta1", "code": "Class BuiltInEncoding {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "A font's built-in encoding."}
{"index": 1451, "repo": "pdfbox-3.0.0-beta1", "code": "Class CIDFontMapping {\n\t// Returns a TrueType font when isCIDFont() is true, otherwise null.\n\torg.apache.fontbox.FontBoxFont getTrueTypeFont();\n\t// Returns true if this is a CID font.\n\tboolean isCIDFont();\n}", "des": "A CIDFontMapping is a kind of FontMapping which allows for an additional TrueTypeFont substitute to be provided if a CID font is not available."}
{"index": 1452, "repo": "pdfbox-3.0.0-beta1", "code": "Class ClipEvenOddRule {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "W* Set clipping path using even odd rule."}
{"index": 1453, "repo": "pdfbox-3.0.0-beta1", "code": "Class ClipNonZeroRule {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "W Set the clipping path using non zero winding rule."}
{"index": 1454, "repo": "pdfbox-3.0.0-beta1", "code": "Class CloseAndStrokePath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "s: close and stroke the path."}
{"index": 1455, "repo": "pdfbox-3.0.0-beta1", "code": "Class CloseFillEvenOddAndStrokePath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "b* Close, fill and stroke the path with even-odd winding rule."}
{"index": 1456, "repo": "pdfbox-3.0.0-beta1", "code": "Class CloseFillNonZeroAndStrokePath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "b Close, fill and stroke the path with non-zero winding rule."}
{"index": 1457, "repo": "pdfbox-3.0.0-beta1", "code": "Class ClosePath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "h Close the path."}
{"index": 1458, "repo": "pdfbox-3.0.0-beta1", "code": "Class CompressParameters {\n\t// Returns the number of objects, that can be contained in compressed object streams.\n\tint getObjectStreamSize();\n\t// Indicates whether the creation of compressed object streams is enabled or not.\n\tboolean isCompress();\n}", "des": "An instance of this class centralizes and provides the configuration for a PDF compression."}
{"index": 1459, "repo": "pdfbox-3.0.0-beta1", "code": "Class Concatenate {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "cm: Concatenate matrix to current transformation matrix."}
{"index": 1460, "repo": "pdfbox-3.0.0-beta1", "code": "Class ContentStreamWriter {\n\t// Writes a single operand token.\n\tvoid writeToken(COSBase base);\n\t// Writes a single operator token.\n\tvoid writeToken(Operator op);\n\t// This will write out the list of tokens to the stream.\n\tvoid writeTokens(List<?> tokens);\n\t// Writes a series of tokens followed by a new line.\n\tvoid writeTokens(Object... tokens);\n}", "des": "A class that will take a list of tokens and write out a stream with them."}
{"index": 1461, "repo": "pdfbox-3.0.0-beta1", "code": "Class COSDocumentState {\n\t// Returns true, if the documents parsing is completed and it may be updated.\n\tboolean isAcceptingUpdates();\n\t// Sets the parsing state of the document.\n\tvoid setParsing(boolean parsing);\n}", "des": "An instance of COSDocumentState collects all known states a COSDocument may have and shall allow their evaluation."}
{"index": 1462, "repo": "pdfbox-3.0.0-beta1", "code": "Class COSFloat {\n\t// Visitor pattern double dispatch method.\n\tvoid accept(ICOSVisitor visitor);\n\tboolean equals(Object o);\n\t// The value of the float object that this one wraps.\n\tfloat floatValue();\n\t// This will get the integer value of this object.\n\tint intValue();\n\t// This will get the long value of this object.\n\tlong longValue();\n\t// This will output this string as a PDF object.\n\tvoid writePDF(OutputStream output);\n}", "des": "This class represents a floating point number in a PDF document."}
{"index": 1463, "repo": "pdfbox-3.0.0-beta1", "code": "Class COSNull {\n\t// Visitor pattern double dispatch method.\n\tvoid accept(ICOSVisitor visitor);\n\t// This will output this string as a PDF object.\n\tvoid writePDF(OutputStream output);\n}", "des": "This class represents a null PDF object."}
{"index": 1464, "repo": "pdfbox-3.0.0-beta1", "code": "Class COSNumber {\n\t// This will get the float value of this number.\n\tabstract float floatValue();\n\t// This factory method will get the appropriate number object.\n\tstatic COSNumber get(String number);\n\t// This will get the integer value of this number.\n\tabstract int intValue();\n\t// This will get the long value of this number.\n\tabstract long longValue();\n}", "des": "This class represents an abstract number in a PDF document."}
{"index": 1465, "repo": "pdfbox-3.0.0-beta1", "code": "Class COSObjectKey {\n\tint compareTo(COSObjectKey other);\n\t// Calculate the internal hash value for the given object number and generation number.\n\tstatic long computeInternalHash(long num, int gen);\n\tboolean equals(Object obj);\n\t// This will get the object generation number.\n\tint getGeneration();\n\t// This will get the object number.\n\tlong getNumber();\n\t// The index within a compressed object stream.\n\tint getStreamIndex();\n}", "des": "Object representing the physical reference to an indirect pdf object."}
{"index": 1466, "repo": "pdfbox-3.0.0-beta1", "code": "Class COSUpdateState {\n\t// Returns the originDocumentState, that is linked to the managed updateInfo.\n\tCOSDocumentState getOriginDocumentState();\n\t// Returns the actual updated state of the managed updateInfo.\n\tboolean isUpdated();\n\t// Links the given COSDocumentState to the updated state of the managed updateInfo.\n\tvoid setOriginDocumentState(COSDocumentState originDocumentState);\n}", "des": "A COSUpdateState instance manages update states for a COSUpdateInfo. Such states are used to create a COSIncrement for the incremental saving of a COSDocument."}
{"index": 1467, "repo": "pdfbox-3.0.0-beta1", "code": "Class COSWriterObjectStream {\n\t// Returns all COSObjectKeys, that shall be added to the object stream, when writeObjectsToStream(COSStream) is called.\n\tList<COSObjectKey> getPreparedKeys();\n\t// Prepares the given COSObject to be written to this object stream, using the given COSObjectKey as it's ID for indirect references.\n\tvoid prepareStreamObject(COSObjectKey key, COSBase object);\n\t// Writes all prepared COSObjects to the given COSStream.\n\tCOSStream writeObjectsToStream(COSStream stream);\n}", "des": "An instance of this class represents an object stream, that compresses a number of COSObjects in a stream. It may be added to the top level container of a written PDF document in place of the compressed objects. The document's PDFXRefStream must be adapted accordingly."}
{"index": 1468, "repo": "pdfbox-3.0.0-beta1", "code": "Class CurveTo {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "c Append curved segment to path."}
{"index": 1469, "repo": "pdfbox-3.0.0-beta1", "code": "Class CurveToReplicateFinalPoint {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "y Append curved segment to path with final point replicated."}
{"index": 1470, "repo": "pdfbox-3.0.0-beta1", "code": "Class CurveToReplicateInitialPoint {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "v Append curved segment to path with the initial point replicated."}
{"index": 1471, "repo": "pdfbox-3.0.0-beta1", "code": "Class DecodeResult {\n\t// Return a default DecodeResult.\n\tstatic DecodeResult createDefault();\n\t// Returns the embedded JPX color space, if any.\n\tPDJPXColorSpace getJPXColorSpace();\n\t// Returns the stream parameters, repaired using the embedded stream data.\n\tCOSDictionary getParameters();\n}", "des": "The result of a filter decode operation. Allows information such as color space to be extracted from image streams, and for stream parameters to be repaired during reading."}
{"index": 1472, "repo": "pdfbox-3.0.0-beta1", "code": "Class DictionaryEncoding {\n\t// Returns the base encoding.\n\tEncoding getBaseEncoding();\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the Differences array.\n\tMap<Integer,String> getDifferences();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "This will perform the encoding from a dictionary."}
{"index": 1473, "repo": "pdfbox-3.0.0-beta1", "code": "Class DrawObject {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Do: Draws an XObject."}
{"index": 1474, "repo": "pdfbox-3.0.0-beta1", "code": "Class DrawObject {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "Do: Draws an XObject."}
{"index": 1475, "repo": "pdfbox-3.0.0-beta1", "code": "Class DrawObject {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Do: Draws an XObject."}
{"index": 1476, "repo": "pdfbox-3.0.0-beta1", "code": "Class EndMarkedContentSequence {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "EMC : Ends a marked-content sequence begun by BMC or BDC."}
{"index": 1477, "repo": "pdfbox-3.0.0-beta1", "code": "Class EndPath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "n End the path."}
{"index": 1478, "repo": "pdfbox-3.0.0-beta1", "code": "Class EndText {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "ET: End text."}
{"index": 1479, "repo": "pdfbox-3.0.0-beta1", "code": "Class ExecutionContext {\n\t// Returns the operator set used by this execution context.\n\tOperators getOperators();\n\t// Returns the stack used by this execution context.\n\tStack<Object> getStack();\n\t// Pops a value of type int from the stack.\n\tint popInt();\n\t// Pops a number (int or real) from the stack.\n\tNumber popNumber();\n\t// Pops a number from the stack and returns it as a real value.\n\tfloat popReal();\n}", "des": "Makes up the execution context, holding the available operators and the execution stack."}
{"index": 1480, "repo": "pdfbox-3.0.0-beta1", "code": "Interface ExternalSigningSupport {\n\t// Get PDF content to be signed.\n\tInputStream getContent();\n\t// Set CMS signature bytes to PDF.\n\tvoid setSignature(byte[] signature);\n}", "des": "Interface for external signature creation scenarios. It contains method for retrieving PDF data to be sign and setting created CMS signature to the PDF."}
{"index": 1481, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFAnnotationCaret {\n\t// This will retrieve the fringe.\n\tPDRectangle getFringe();\n\t// This will retrieve the symbol that shall be associated with the caret.\n\tString getSymbol();\n\t// This will set the fringe rectangle.\n\tvoid setFringe(PDRectangle fringe);\n\t// This will set the symbol that shall be associated with the caret.\n\tvoid setSymbol(String symbol);\n}", "des": "This represents a Caret FDF annotation."}
{"index": 1482, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFAnnotationCircle {\n\t// This will get the fringe.\n\tPDRectangle getFringe();\n\t// This will retrieve the interior color of the drawn area.\n\tColor getInteriorColor();\n\t// This will set the fringe rectangle.\n\tvoid setFringe(PDRectangle fringe);\n\t// This will set interior color of the drawn area.\n\tvoid setInteriorColor(Color color);\n}", "des": "This represents a Circle FDF annotation."}
{"index": 1483, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFAnnotationInk {\n\t// Get the paths making up the freehand \"scribble\".\n\tList<float[]> getInkList();\n\t// Set the paths making up the freehand \"scribble\".\n\tvoid setInkList(List<float[]> inklist);\n}", "des": "This represents a Ink FDF annotation."}
{"index": 1484, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFAnnotationPolygon {\n\t// This will get interior color of the drawn area.\n\tColor getInteriorColor();\n\t// This will get the coordinates of the vertices.\n\tfloat[] getVertices();\n\t// This will set interior color of the drawn area.\n\tvoid setInteriorColor(Color color);\n\t// This will set the coordinates of the vertices.\n\tvoid setVertices(float[] vertices);\n}", "des": "This represents a Polygon FDF annotation."}
{"index": 1485, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFAnnotationSquare {\n\t// This will get the fringe.\n\tPDRectangle getFringe();\n\t// This will retrieve the interior color of the drawn area.\n\tColor getInteriorColor();\n\t// This will set the fringe rectangle.\n\tvoid setFringe(PDRectangle fringe);\n\t// This will set interior color of the drawn area.\n\tvoid setInteriorColor(Color color);\n}", "des": "This represents a Square FDF annotation."}
{"index": 1486, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFAnnotationTextMarkup {\n\t// Get the coordinates of individual words or group of words.\n\tfloat[] getCoords();\n\t// Set the coordinates of individual words or group of words.\n\tvoid setCoords(float[] coords);\n}", "des": "This abstract class is used as a superclass for the different FDF annotations with text markup attributes."}
{"index": 1487, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFNamedPageReference {\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// This will get the file specification of this reference.\n\tPDFileSpecification getFileSpecification();\n\t// This will get the name of the referenced page.\n\tString getName();\n\t// This will set the file specification for this named page reference.\n\tvoid setFileSpecification(PDFileSpecification fs);\n\t// This will set the name of the referenced page.\n\tvoid setName(String name);\n}", "des": "This represents an FDF named page reference that is part of the FDF field."}
{"index": 1488, "repo": "pdfbox-3.0.0-beta1", "code": "Class FDFPage {\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// This will get the FDF page info object.\n\tFDFPageInfo getPageInfo();\n\t// This will get a list of FDFTemplage objects that describe the named pages that serve as templates.\n\tList<FDFTemplate> getTemplates();\n\t// This will set the page info.\n\tvoid setPageInfo(FDFPageInfo info);\n\t// A list of FDFTemplate objects.\n\tvoid setTemplates(List<FDFTemplate> templates);\n}", "des": "This represents an FDF page that is part of the FDF document."}
{"index": 1489, "repo": "pdfbox-3.0.0-beta1", "code": "Class FillEvenOddAndStrokePath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "B* Fill and then stroke the path, using the even-odd rule to determine the region to fill."}
{"index": 1490, "repo": "pdfbox-3.0.0-beta1", "code": "Class FillEvenOddRule {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "f* Fill path using even odd rule."}
{"index": 1491, "repo": "pdfbox-3.0.0-beta1", "code": "Class FillNonZeroAndStrokePath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "B Fill and then stroke the path, using the nonzero winding number rule to determine the region to fill."}
{"index": 1492, "repo": "pdfbox-3.0.0-beta1", "code": "Class FillNonZeroRule {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "f Fill path using non zero winding rule."}
{"index": 1493, "repo": "pdfbox-3.0.0-beta1", "code": "Class FilterFactory {\n\t// Returns a filter instance given its COSName.\n\tFilter getFilter(COSName filterName);\n\t// Returns a filter instance given its name as a string.\n\tFilter getFilter(String filterName);\n}", "des": "Factory for Filter classes."}
{"index": 1494, "repo": "pdfbox-3.0.0-beta1", "code": "Class FontCache {\n\t// Adds the given FontBox font to the cache.\n\tvoid addFont(FontInfo info, org.apache.fontbox.FontBoxFont font);\n\t// Returns the FontBox font associated with the given FontInfo.\n\torg.apache.fontbox.FontBoxFont getFont(FontInfo info);\n}", "des": "An in-memory cache for system fonts. This allows PDFBox to manage caching for a FontProvider. PDFBox is free to purge this cache at will."}
{"index": 1495, "repo": "pdfbox-3.0.0-beta1", "code": "Enum FontFormat {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FontFormat valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FontFormat[] values();\n}", "des": "Font file format."}
{"index": 1496, "repo": "pdfbox-3.0.0-beta1", "code": "Class FontMappers {\n\t// Returns the singleton FontMapper instance.\n\tstatic FontMapper instance();\n\t// Sets the singleton FontMapper instance.\n\tstatic void set(FontMapper fontMapper);\n}", "des": "FontMapper factory class."}
{"index": 1497, "repo": "pdfbox-3.0.0-beta1", "code": "Class FontMapping<T extends org.apache.fontbox.FontBoxFont> {\n\t// Returns the mapped, FontBox font.\n\tT getFont();\n\t// Returns true if the mapped font is a fallback, i.e.\n\tboolean isFallback();\n}", "des": "A font mapping from a PDF font to a FontBox font."}
{"index": 1498, "repo": "pdfbox-3.0.0-beta1", "code": "Class FontProvider {\n\t// Returns a list of information about fonts on the system.\n\tabstract List<? extends FontInfo> getFontInfo();\n\t// Returns a string containing debugging information.\n\tabstract String toDebugString();\n}", "des": "External font service provider interface."}
{"index": 1499, "repo": "pdfbox-3.0.0-beta1", "code": "Class FreeXReference {\n\t// Returns the COSObjectKey of the object, that is described by this crossreference stream entry.\n\tCOSObjectKey getReferencedKey();\n\t// Returns the value for the second column of the crossreference stream entry.\n\tlong getSecondColumnValue();\n\t// Returns the value for the third column of the crossreference stream entry.\n\tlong getThirdColumnValue();\n}", "des": "A class representing a free reference in a PDF's crossreference stream (PDFXRefStream)."}
{"index": 1500, "repo": "pdfbox-3.0.0-beta1", "code": "Enum ImageType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ImageType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ImageType[] values();\n}", "des": "Image type for rendering."}
{"index": 1501, "repo": "pdfbox-3.0.0-beta1", "code": "Class InstructionSequence {\n\t// Adds a bool value.\n\tvoid addBoolean(boolean value);\n\t// Adds an int value.\n\tvoid addInteger(int value);\n\t// Add a name (ex.\n\tvoid addName(String name);\n\t// Adds a proc (sub-sequence of instructions).\n\tvoid addProc(InstructionSequence child);\n\t// Adds a real value.\n\tvoid addReal(float value);\n\t// Executes the instruction sequence.\n\tvoid execute(ExecutionContext context);\n}", "des": "Represents an instruction sequence, a combination of values, operands and nested procedures."}
{"index": 1502, "repo": "pdfbox-3.0.0-beta1", "code": "Class JPXFilter {\n\t// Decodes data, producing the original non-encoded data.\n\tDecodeResult decode(InputStream encoded, OutputStream decoded, COSDictionary parameters, int index);\n\t// Decodes data, with optional DecodeOptions.\n\tDecodeResult decode(InputStream encoded, OutputStream decoded, COSDictionary parameters, int index, DecodeOptions options);\n\tprotected void encode(InputStream input, OutputStream encoded, COSDictionary parameters);\n}", "des": "Decompress data encoded using the wavelet-based JPEG 2000 standard, reproducing the original data. Requires the Java Advanced Imaging (JAI) Image I/O Tools to be installed from java.net, see jai-imageio. Alternatively you can build from the source available in the jai-imageio-core svn repo. Mac OS X users should download the tar.gz file for linux and unpack it to obtain the required jar files. The .so file can be safely ignored."}
{"index": 1503, "repo": "pdfbox-3.0.0-beta1", "code": "Class LineTo {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "l Append straight line segment to path."}
{"index": 1504, "repo": "pdfbox-3.0.0-beta1", "code": "Class MacExpertEncoding {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "This is an interface to a text encoder."}
{"index": 1505, "repo": "pdfbox-3.0.0-beta1", "code": "Class MacRomanEncoding {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "This is an interface to a text encoder."}
{"index": 1506, "repo": "pdfbox-3.0.0-beta1", "code": "Class MoveText {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Td: Move text position."}
{"index": 1507, "repo": "pdfbox-3.0.0-beta1", "code": "Class MoveTextSetLeading {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "TD: Move text position and set leading."}
{"index": 1508, "repo": "pdfbox-3.0.0-beta1", "code": "Class MoveTo {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "m Begins a new subpath."}
{"index": 1509, "repo": "pdfbox-3.0.0-beta1", "code": "Class NextLine {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "T*: Move to start of next text line."}
{"index": 1510, "repo": "pdfbox-3.0.0-beta1", "code": "Enum OpenMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OpenMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OpenMode[] values();\n}", "des": "This will specify whether to open the destination document in a new window."}
{"index": 1511, "repo": "pdfbox-3.0.0-beta1", "code": "Class OperatorProcessor {\n\t// Check whether all operands list elements are an instance of a specific class.\n\tboolean checkArrayTypesClass(List<COSBase> operands, Class<?> clazz);\n\t// Returns the processing context.\n\tprotected PDFStreamEngine getContext();\n\t// Returns the name of this operator, e.g.\n\tabstract String getName();\n\t// Process the operator.\n\tabstract void process(Operator operator, List<COSBase> operands);\n}", "des": "Processes a PDF operator."}
{"index": 1512, "repo": "pdfbox-3.0.0-beta1", "code": "Enum Orientation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Orientation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Orientation[] values();\n}", "des": "Orientation of printed pages."}
{"index": 1513, "repo": "pdfbox-3.0.0-beta1", "code": "Enum Overlay.Position {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Overlay.Position valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Overlay.Position[] values();\n}", "des": "Possible location of the overlaid pages: foreground or background."}
{"index": 1514, "repo": "pdfbox-3.0.0-beta1", "code": "Class PageDrawerParameters {\n\tRenderDestination getDestination();\n\tfloat getImageDownscalingOptimizationThreshold();\n\t// Returns the page.\n\tPDPage getPage();\n\tRenderingHints getRenderingHints();\n\t// Returns whether to allow subsampling of images.\n\tboolean isSubsamplingAllowed();\n}", "des": "Parameters for a PageDrawer. This class ensures allows PDFRenderer and PageDrawer to share private implementation data in a future-proof manner, while still allowing end-users to create their own subclasses of PageDrawer."}
{"index": 1515, "repo": "pdfbox-3.0.0-beta1", "code": "Class PageExtractor {\n\t// This will take a document and extract the desired pages into a new document.\n\tPDDocument extract();\n\t// Gets the last page number (inclusive) to be extracted.\n\tint getEndPage();\n\t// Gets the first page number to be extracted.\n\tint getStartPage();\n\t// Sets the last page number to be extracted.\n\tvoid setEndPage(int endPage);\n\t// Sets the first page number to be extracted.\n\tvoid setStartPage(int startPage);\n}", "des": "This class will extract one or more sequential pages and create a new document."}
{"index": 1516, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PageLayout {\n\tstatic PageLayout fromString(String value);\n\t// Returns the string value, as used in a PDF file.\n\tString stringValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PageLayout valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PageLayout[] values();\n}", "des": "A name object specifying the page layout shall be used when the document is opened."}
{"index": 1517, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PageMode {\n\tstatic PageMode fromString(String value);\n\t// Returns the string value, as used in a PDF file.\n\tString stringValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PageMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PageMode[] values();\n}", "des": "A name object specifying how the document shall be displayed when opened."}
{"index": 1518, "repo": "pdfbox-3.0.0-beta1", "code": "Class Parser.AbstractSyntaxHandler {\n\t// Called for a comment.\n\tvoid comment(CharSequence text);\n\t// Indicates that a new line starts.\n\tvoid newLine(CharSequence text);\n\t// Called when whitespace characters are encountered.\n\tvoid whitespace(CharSequence text);\n}", "des": "Abstract base class for a Parser.SyntaxHandler."}
{"index": 1519, "repo": "pdfbox-3.0.0-beta1", "code": "Interface Parser.SyntaxHandler {\n\t// Called for a comment.\n\tvoid comment(CharSequence text);\n\t// Indicates that a new line starts.\n\tvoid newLine(CharSequence text);\n\t// Called when a token is encountered.\n\tvoid token(CharSequence text);\n\t// Called when whitespace characters are encountered.\n\tvoid whitespace(CharSequence text);\n}", "des": "This interface defines all possible syntactic elements of a Type 4 function. It is called by the parser as the function is interpreted."}
{"index": 1520, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDActionGoTo {\n\t// This will get the destination to jump to.\n\tPDDestination getDestination();\n\t// This will set the destination to jump to.\n\tvoid setDestination(PDDestination d);\n}", "des": "This represents a go-to action that can be executed in a PDF document."}
{"index": 1521, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDActionHide {\n\t// A flag indicating whether to hide the annotation or show it\n\tboolean getH();\n\t// The annotation or annotations to be hidden or shown\n\tCOSBase getT();\n\tvoid setH(boolean h);\n\tvoid setT(COSBase t);\n}", "des": "This represents a thread action that can be executed in a PDF document."}
{"index": 1522, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDActionNamed {\n\t// This will get the name of the action to be performed.\n\tString getN();\n\t// This will set the name of the action to be performed.\n\tvoid setN(String name);\n}", "des": "This represents a named action in a PDF document."}
{"index": 1523, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDActionThread {\n\tCOSBase getB();\n\tCOSBase getD();\n\t// This will get the file in which the destination is located.\n\tPDFileSpecification getFile();\n\tvoid setB(COSBase b);\n\tvoid setD(COSBase d);\n\t// This will set the file in which the destination is located.\n\tvoid setFile(PDFileSpecification fs);\n}", "des": "This represents a thread action that can be executed in a PDF document."}
{"index": 1524, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDActionURI {\n\t// This will get the uniform resource identifier to resolve.\n\tString getURI();\n\t// This will specify whether to track the mouse position when the URI is resolved.\n\tvoid setTrackMousePosition(boolean value);\n\t// This will set the uniform resource identifier to resolve, encoded in 7-bit ASCII.\n\tvoid setURI(String uri);\n\t// This will specify whether to track the mouse position when the URI is resolved.\n\tboolean shouldTrackMousePosition();\n}", "des": "This represents a URI action that can be executed in a PDF document."}
{"index": 1525, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDAdditionalActions {\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// Get the F action.\n\tPDAction getF();\n\t// Set the F action.\n\tvoid setF(PDAction action);\n}", "des": "This represents a dictionary of actions that occur due to events."}
{"index": 1526, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDAnnotationPopup {\n\t// This will retrieve the initial state of the annotation, open Or closed (default closed).\n\tboolean getOpen();\n\t// This will retrieve the markup annotation which this popup relates to.\n\tPDAnnotationMarkup getParent();\n\t// This will set the initial state of the annotation, open or closed.\n\tvoid setOpen(boolean open);\n\t// This will set the markup annotation which this popup relates to.\n\tvoid setParent(PDAnnotationMarkup annot);\n}", "des": "This is the class that represents a popup annotation. Introduced in PDF 1.3 specification"}
{"index": 1527, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDAnnotationRubberStamp {\n\t// This will retrieve the name (and hence appearance, AP taking precedence) For this annotation.\n\tString getName();\n\t// This will set the name (and hence appearance, AP taking precedence) For this annotation.\n\tvoid setName(String name);\n}", "des": "This is the class that represents a rubber stamp annotation. Introduced in PDF 1.3 specification"}
{"index": 1528, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDAnnotationTextMarkup {\n\t// This will retrieve the set of quadpoints which encompass the areas of this annotation.\n\tfloat[] getQuadPoints();\n\t// This will set the set of quadpoints which encompass the areas of this annotation.\n\tvoid setQuadPoints(float[] quadPoints);\n}", "des": "This is the abstract class that represents a text markup annotation introduced in the PDF 1.3 specification, except Squiggly lines in 1.4."}
{"index": 1529, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDAppearanceEntry {\n\t// Returns the entry as an appearance stream.\n\tPDAppearanceStream getAppearanceStream();\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// Returns the entry as an appearance subdictionary.\n\tMap<COSName,PDAppearanceStream> getSubDictionary();\n\t// Returns true if this entry is an appearance stream.\n\tboolean isStream();\n\t// Returns true if this entry is an appearance subdictionary.\n\tboolean isSubDictionary();\n}", "des": "An entry in an appearance dictionary. May contain either a single appearance stream or an appearance subdictionary."}
{"index": 1530, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDArtifactMarkedContent {\n\t// Gets the artifact's bounding box (BBox).\n\tPDRectangle getBBox();\n\t// Gets the subtype (Subtype).\n\tString getSubtype();\n\t// Gets the type (Type).\n\tString getType();\n\t// Is the artifact attached to the bottom edge?\n\tboolean isBottomAttached();\n\t// Is the artifact attached to the left edge?\n\tboolean isLeftAttached();\n\t// Is the artifact attached to the right edge?\n\tboolean isRightAttached();\n\t// Is the artifact attached to the top edge?\n\tboolean isTopAttached();\n}", "des": "An artifact marked content."}
{"index": 1531, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDBorderEffectDictionary {\n\t// returns the dictionary.\n\tCOSDictionary getCOSObject();\n\t// This will retrieve the intensity of the applied effect.\n\tfloat getIntensity();\n\t// This will retrieve the border effect, see the STYLE_* constants for valid values.\n\tString getStyle();\n\t// This will set the intensity of the applied effect.\n\tvoid setIntensity(float i);\n\t// This will set the border effect, see the STYLE_* constants for valid values.\n\tvoid setStyle(String s);\n}", "des": "This class represents a PDF /BE entry the border effect dictionary."}
{"index": 1532, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDCheckBox {\n\t// Checks the check box.\n\tvoid check();\n\t// Get the value which sets the check box to the On state.\n\tString getOnValue();\n\t// This will tell if this radio button is currently checked or not.\n\tboolean isChecked();\n\t// Unchecks the check box.\n\tvoid unCheck();\n}", "des": "A check box toggles between two states, on and off."}
{"index": 1533, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDCIEBasedColorSpace {\n\t// Returns the image in this colorspace or null.\n\tBufferedImage toRawImage(WritableRaster raster);\n\t// Returns the (A)RGB equivalent of the given raster.\n\tBufferedImage toRGBImage(WritableRaster raster);\n}", "des": "CIE-based colour spaces specify colours in a way that is independent of the characteristics of any particular output device. They are based on an international standard for colour specification created by the Commission Internationale de l'clairage (CIE)."}
{"index": 1534, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDColor {\n\t// Returns the color space in which this color value is defined.\n\tPDColorSpace getColorSpace();\n\t// Returns the components of this color value.\n\tfloat[] getComponents();\n\t// Returns the pattern name from this color value.\n\tCOSName getPatternName();\n\t// Returns true if this color value is a pattern.\n\tboolean isPattern();\n\t// Returns the color component values as a COS array\n\tCOSArray toCOSArray();\n\t// Returns the packed RGB value for this color, if any.\n\tint toRGB();\n}", "des": "A color value, consisting of one or more color components, or for pattern color spaces, a name and optional color components. Color values are not associated with any given color space. Instances of PDColor are immutable."}
{"index": 1535, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDComboBox {\n\t// Determines if Edit is set.\n\tboolean isEdit();\n\t// Set the Edit bit.\n\tvoid setEdit(boolean edit);\n}", "des": "A combo box consisting of a drop-down list. May be accompanied by an editable text box in which non-predefined values may be entered."}
{"index": 1536, "repo": "pdfbox-3.0.0-beta1", "code": "Interface PDContentStream {\n\t// Returns the bounding box of the contents.\n\tPDRectangle getBBox();\n\t// Returns this stream's content, if any.\n\tInputStream getContents();\n\t// Returns this stream's content, if any.\n\torg.apache.pdfbox.io.RandomAccessRead getContentsForRandomAccess();\n\t// Returns the matrix which transforms from the stream's space to user space.\n\tMatrix getMatrix();\n\t// Returns this stream's resources, if any.\n\tPDResources getResources();\n}", "des": "A content stream."}
{"index": 1537, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDDefaultAttributeObject {\n\t// Gets the attribute names.\n\tList<String> getAttributeNames();\n\t// Gets the attribute value for a given name.\n\tCOSBase getAttributeValue(String attrName);\n\t// Gets the attribute value for a given name.\n\tprotected COSBase getAttributeValue(String attrName, COSBase defaultValue);\n\t// Sets an attribute.\n\tvoid setAttribute(String attrName, COSBase attrValue);\n}", "des": "A default attribute object."}
{"index": 1538, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDDestinationNameTreeNode {\n\t// Method to convert the COS value in the name tree to the PD Model object.\n\tprotected PDPageDestination convertCOSToPD(COSBase base);\n\t// Create a child node object.\n\tprotected PDNameTreeNode<PDPageDestination> createChildNode(COSDictionary dic);\n}", "des": "This class holds all of the name trees that are available at the document level."}
{"index": 1539, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDDeviceNAttributes {\n\t// Returns a map of colorants and their associated Separation color space.\n\tMap<String,PDSeparation> getColorants();\n\t// Returns the underlying COS dictionary.\n\tCOSDictionary getCOSDictionary();\n\t// Returns the DeviceN Process Dictionary, or null if it is missing.\n\tPDDeviceNProcess getProcess();\n\t// Returns true if this is an NChannel (PDF 1.6) color space.\n\tboolean isNChannel();\n\t// Sets the colorant map.\n\tvoid setColorants(Map<String,PDColorSpace> colorants);\n}", "des": "Contains additional information about the components of colour space. Instead of using the alternate color space and tint transform, conforming readers may use custom blending algorithms, along with other information provided in the attributes dictionary."}
{"index": 1540, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDDeviceNProcess {\n\t// Returns the process color space\n\tPDColorSpace getColorSpace();\n\t// Returns the names of the color components.\n\tList<String> getComponents();\n\t// Returns the underlying COS dictionary.\n\tCOSDictionary getCOSDictionary();\n}", "des": "A DeviceN Process Dictionary"}
{"index": 1541, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDDocumentNameDestinationDictionary {\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// Returns the destination corresponding to the parameter.\n\tPDDestination getDestination(String name);\n}", "des": "This encapsulates the \"dictionary of names and corresponding destinations\" for the /Dests entry in the document catalog."}
{"index": 1542, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDDocumentOutline {\n\t// Close this node.\n\tvoid closeNode();\n\tboolean isNodeOpen();\n\t// This will set this node to be open when it is shown in the viewer.\n\tvoid openNode();\n}", "des": "This represents an outline in a pdf document."}
{"index": 1543, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDEmbeddedFilesNameTreeNode {\n\t// Method to convert the COS value in the name tree to the PD Model object.\n\tprotected PDComplexFileSpecification convertCOSToPD(COSBase base);\n\t// Create a child node object.\n\tprotected PDNameTreeNode<PDComplexFileSpecification> createChildNode(COSDictionary dic);\n}", "des": "This class holds all of the name trees that are available at the document level."}
{"index": 1544, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDExternalDataDictionary {\n\t// returns the dictionary.\n\tCOSDictionary getCOSObject();\n\t// returns the subtype of the external data dictionary.\n\tString getSubtype();\n\t// returns the type of the external data dictionary.\n\tString getType();\n\t// This will set the subtype of the external data dictionary.\n\tvoid setSubtype(String subtype);\n}", "des": "This class represents an external data dictionary."}
{"index": 1545, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFileSpecification {\n\t// A file specification can either be a COSString or a COSDictionary.\n\tstatic PDFileSpecification createFS(COSBase base);\n\t// This will get the file name.\n\tabstract String getFile();\n\t// This will set the file name.\n\tabstract void setFile(String file);\n}", "des": "This represents a file specification."}
{"index": 1546, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDFMergerUtility.AcroFormMergeMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDFMergerUtility.AcroFormMergeMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDFMergerUtility.AcroFormMergeMode[] values();\n}", "des": "The mode to use when merging AcroForm between documents: JOIN_FORM_FIELDS_MODE fields with the same fully qualified name will be merged into one with the widget annotations of the merged fields becoming part of the same field. PDFBOX_LEGACY_MODE fields with the same fully qualified name will be renamed and treated as independent. This mode was used in versions of PDFBox up to 2.x."}
{"index": 1547, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDFMergerUtility.DocumentMergeMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDFMergerUtility.DocumentMergeMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDFMergerUtility.DocumentMergeMode[] values();\n}", "des": "The mode to use when merging documents: OPTIMIZE_RESOURCES_MODE Optimizes resource handling such as closing documents early. Not all document elements are merged compared to the PDFBOX_LEGACY_MODE. Currently supported are: Page content and resources PDFBOX_LEGACY_MODE Keeps all files open until the merge has been completed. This is currently necessary to merge documents containing a Structure Tree."}
{"index": 1548, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFObjectStreamParser {\n\t// Parse all compressed objects.\n\tMap<COSObjectKey,COSBase> parseAllObjects();\n\t// Search for/parse the object with the given object number.\n\tCOSBase parseObject(long objectNumber);\n\t// Read all object numbers from the compressed object stream.\n\tMap<Long,Integer> readObjectNumbers();\n}", "des": "This will parse a PDF 1.5 object stream and extract the object with given object number from the stream."}
{"index": 1549, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFontFactory {\n\t// Creates a new PDFont instance with the appropriate subclass.\n\tstatic PDFont createFont(COSDictionary dictionary);\n\t// Creates a new PDFont instance with the appropriate subclass.\n\tstatic PDFont createFont(COSDictionary dictionary, ResourceCache resourceCache);\n}", "des": "Creates the appropriate font subtype based on information in the dictionary."}
{"index": 1550, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFontSetting {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// This will get the font for this font setting.\n\tPDFont getFont();\n\t// This will get the size of the font.\n\tfloat getFontSize();\n\t// This will set the font for this font setting.\n\tvoid setFont(PDFont font);\n\t// This will set the size of the font.\n\tvoid setFontSize(float size);\n}", "des": "This class represents a font setting used for the graphics state. A font setting is a font and a font size. Maybe there is a better name for this?"}
{"index": 1551, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFStreamParser {\n\t// Close the underlying resource.\n\tvoid close();\n\t// This will parse all the tokens in the stream.\n\tList<Object> parse();\n\t// This will parse the next token in the stream.\n\tObject parseNextToken();\n}", "des": "This will parse a PDF byte stream and extract operands and such."}
{"index": 1552, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFTemplateCreator {\n\t// Build a PDF with a visible signature step by step, and return it as a stream.\n\tInputStream buildPDF(PDVisibleSignDesigner properties);\n\t// Returns the PDFTemplateStructure object.\n\tPDFTemplateStructure getPdfStructure();\n}", "des": "Class to build PDF template."}
{"index": 1553, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFunctionType2 {\n\t// Performs exponential interpolation Evaluates the function at the given input.\n\tfloat[] eval(float[] input);\n\t// Returns the C0 values of the function, 0 if empty.\n\tCOSArray getC0();\n\t// Returns the C1 values of the function, 1 if empty.\n\tCOSArray getC1();\n\t// Returns the function type.\n\tint getFunctionType();\n\t// Returns the exponent of the function.\n\tfloat getN();\n}", "des": "This class represents a Type 2 (exponential interpolation) function in a PDF document."}
{"index": 1554, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFunctionType3 {\n\t// Evaluates the function at the given input.\n\tfloat[] eval(float[] input);\n\t// Returns all bounds values as COSArray.\n\tCOSArray getBounds();\n\t// Returns all encode values as COSArray.\n\tCOSArray getEncode();\n\t// Returns all functions values as COSArray.\n\tCOSArray getFunctions();\n\t// Returns the function type.\n\tint getFunctionType();\n}", "des": "This class represents a Type 3 (stitching) function in a PDF document."}
{"index": 1555, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFunctionType4 {\n\t// Evaluates the function at the given input.\n\tfloat[] eval(float[] input);\n\t// Returns the function type.\n\tint getFunctionType();\n}", "des": "This class represents a Type 4 (PostScript calculator) function in a PDF document."}
{"index": 1556, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDFunctionTypeIdentity {\n\t// Evaluates the function at the given input.\n\tfloat[] eval(float[] input);\n\t// Returns the function type.\n\tint getFunctionType();\n\t// Returns all ranges for the output values as COSArray .\n\tprotected COSArray getRangeValues();\n}", "des": "The identity function."}
{"index": 1557, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDImmutableRectangle {\n\t// This will set the lower left x coordinate.\n\tvoid setLowerLeftX(float value);\n\t// This will set the lower left y coordinate.\n\tvoid setLowerLeftY(float value);\n\t// This will set the upper right x coordinate.\n\tvoid setUpperRightX(float value);\n\t// This will set the upper right y coordinate.\n\tvoid setUpperRightY(float value);\n}", "des": "Immutable class for constant sizes."}
{"index": 1558, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDJavascriptNameTreeNode {\n\t// Method to convert the COS value in the name tree to the PD Model object.\n\tprotected PDActionJavaScript convertCOSToPD(COSBase base);\n\t// Create a child node object.\n\tprotected PDNameTreeNode<PDActionJavaScript> createChildNode(COSDictionary dic);\n}", "des": "This class holds all of the name trees that are available at the document level."}
{"index": 1559, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDLineDashPattern {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the dash array.\n\tfloat[] getDashArray();\n\t// Returns the dash phase.\n\tint getPhase();\n}", "des": "A line dash pattern for stroking paths. Instances of PDLineDashPattern are immutable."}
{"index": 1560, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDListAttributeObject {\n\t// Gets the list numbering (ListNumbering).\n\tString getListNumbering();\n\t// Sets the list numbering (ListNumbering).\n\tvoid setListNumbering(String listNumbering);\n}", "des": "A List attribute object."}
{"index": 1561, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDListBox {\n\t// This will get the top index \"TI\" value.\n\tint getTopIndex();\n\t// This will set top index \"TI\" value.\n\tvoid setTopIndex(Integer topIndex);\n}", "des": "A scrollable list box. Contains several text items, one or more of which shall be selected as the field value."}
{"index": 1562, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDMarkedContentReference {\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// Gets the marked content identifier.\n\tint getMCID();\n\t// Gets the page.\n\tPDPage getPage();\n\t// Sets the marked content identifier.\n\tvoid setMCID(int mcid);\n\t// Sets the page.\n\tvoid setPage(PDPage page);\n}", "des": "A marked-content reference."}
{"index": 1563, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDMeasureDictionary {\n\t// This will return the corresponding dictionary.\n\tCOSDictionary getCOSObject();\n\t// returns the subtype of the measure dictionary.\n\tString getSubtype();\n\t// This will return the type of the measure dictionary.\n\tString getType();\n\t// This will set the subtype of the measure dictionary.\n\tprotected void setSubtype(String subtype);\n}", "des": "This class represents a measure dictionary."}
{"index": 1564, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDMetadata {\n\t// Extract the XMP metadata.\n\tInputStream exportXMPMetadata();\n\t// Import an XMP stream into the PDF document.\n\tvoid importXMPMetadata(byte[] xmp);\n}", "des": "This class represents metadata for various objects in a PDF document."}
{"index": 1565, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDNamedDestination {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// This will get the name of the destination.\n\tString getNamedDestination();\n\t// Set the named destination.\n\tvoid setNamedDestination(String dest);\n}", "des": "This represents a destination to a page by referencing it with a name."}
{"index": 1566, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDObjectReference {\n\t// Returns the underlying dictionary.\n\tCOSDictionary getCOSObject();\n\t// Gets a higher-level object for the referenced object.\n\tCOSObjectable getReferencedObject();\n\t// Sets the referenced annotation.\n\tvoid setReferencedObject(PDAnnotation annotation);\n\t// Sets the referenced XObject.\n\tvoid setReferencedObject(PDXObject xobject);\n}", "des": "An object reference."}
{"index": 1567, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDOptionalContentGroup {\n\t// Returns the name of the optional content group.\n\tString getName();\n\tPDOptionalContentGroup.RenderState getRenderState(RenderDestination destination);\n\t// Sets the name of the optional content group.\n\tvoid setName(String name);\n}", "des": "An optional content group (OCG)."}
{"index": 1568, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDOptionalContentMembershipDictionary {\n\t// Get a list of optional content groups.\n\tList<PDPropertyList> getOCGs();\n\t// Get the visibility policy name.\n\tCOSName getVisibilityPolicy();\n\t// Set optional content groups as a list.\n\tvoid setOCGs(List<PDPropertyList> ocgs);\n\t// Sets the visibility policy name.\n\tvoid setVisibilityPolicy(COSName visibilityPolicy);\n}", "des": "An optional content membership dictionary (OCMD)."}
{"index": 1569, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPageAdditionalActions {\n\t// This will get an action to be performed when the page is closed.\n\tPDAction getC();\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// This will get an action to be performed when the page is opened.\n\tPDAction getO();\n\t// This will set an action to be performed when the page is closed.\n\tvoid setC(PDAction c);\n\t// This will set an action to be performed when the page is opened.\n\tvoid setO(PDAction o);\n}", "des": "This class represents a page object's dictionary of actions that occur due to events."}
{"index": 1570, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDPageContentStream.AppendMode {\n\tboolean isOverwrite();\n\tboolean isPrepend();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDPageContentStream.AppendMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDPageContentStream.AppendMode[] values();\n}", "des": "This is to choose what to do with the stream: overwrite, append or prepend."}
{"index": 1571, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPageFitDestination {\n\t// A flag indicating if this page destination should just fit bounding box of the PDF.\n\tboolean fitBoundingBox();\n\t// Set if this page destination should just fit the bounding box.\n\tvoid setFitBoundingBox(boolean fitBoundingBox);\n}", "des": "This represents a destination to a page and the page contents will be magnified to just fit on the screen."}
{"index": 1572, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPageFitHeightDestination {\n\t// A flag indicating if this page destination should just fit bounding box of the PDF.\n\tboolean fitBoundingBox();\n\t// Get the left x coordinate.\n\tint getLeft();\n\t// Set if this page destination should just fit the bounding box.\n\tvoid setFitBoundingBox(boolean fitBoundingBox);\n\t// Set the left x-coordinate, a value of -1 implies that the current x-coordinate will be used.\n\tvoid setLeft(int x);\n}", "des": "This represents a destination to a page at a x location and the height is magnified to just fit on the screen."}
{"index": 1573, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPageFitWidthDestination {\n\t// A flag indicating if this page destination should just fit bounding box of the PDF.\n\tboolean fitBoundingBox();\n\t// Get the top y coordinate.\n\tint getTop();\n\t// Set if this page destination should just fit the bounding box.\n\tvoid setFitBoundingBox(boolean fitBoundingBox);\n\t// Set the top y-coordinate, a value of -1 implies that the current y-coordinate will be used.\n\tvoid setTop(int y);\n}", "des": "This represents a destination to a page at a y location and the width is magnified to just fit on the screen."}
{"index": 1574, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPanose {\n\t// The font family class and subclass ID bytes, given in the sFamilyClass field of the OS/2 table in a TrueType font.\n\tint getFamilyClass();\n\t// Ten bytes for the PANOSE classification number for the font.\n\tPDPanoseClassification getPanose();\n}", "des": "Represents the \"Panose\" entry of a FontDescriptor's Style dictionary. This is a sequence of 12 bytes which contain both the TTF sFamilyClass and PANOSE classification bytes."}
{"index": 1575, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPrintFieldAttributeObject {\n\t// Gets the alternate name of the field (Desc).\n\tString getAlternateName();\n\t// Gets the checked state.\n\tString getCheckedState();\n\t// Gets the role.\n\tString getRole();\n\t// Sets the alternate name of the field (Desc).\n\tvoid setAlternateName(String alternateName);\n\t// Sets the checked state.\n\tvoid setCheckedState(String checkedState);\n\t// Sets the role.\n\tvoid setRole(String role);\n}", "des": "A PrintField attribute object."}
{"index": 1576, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPropertyList {\n\t// Creates a property list from the given dictionary.\n\tstatic PDPropertyList create(COSDictionary dict);\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n}", "des": "A property list is a dictionary containing private information meaningful to the conforming writer creating the marked content."}
{"index": 1577, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDPushButton {\n\t// Returns the default value, if any.\n\tString getDefaultValue();\n\t// This will get the (optional) export values.\n\tList<String> getExportValues();\n\t// Get the values to set individual buttons within a group to the on state.\n\tSet<String> getOnValues();\n\t// Returns the selected value.\n\tString getValue();\n\t// Returns a string representation of the \"V\" entry, or an empty string.\n\tString getValueAsString();\n\t// This will set the export values.\n\tvoid setExportValues(List<String> values);\n}", "des": "A pushbutton is a purely interactive control that responds immediately to user input without retaining a permanent value."}
{"index": 1578, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDRadioButton {\n\t// This will get the selected export values.\n\tList<String> getSelectedExportValues();\n\t// This will get the selected index.\n\tint getSelectedIndex();\n\tboolean isRadiosInUnison();\n\t// From the PDF Spec If set, a group of radio buttons within a radio button field that use the same value for the on state will turn on and off in unison; that is if one is checked, they are all checked.\n\tvoid setRadiosInUnison(boolean radiosInUnison);\n}", "des": "Radio button fields contain a set of related buttons that can each be on or off."}
{"index": 1579, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDRange {\n\t// This will get the underlying array value.\n\tCOSArray getCOSArray();\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// This will get the maximum value of the range.\n\tfloat getMax();\n\t// This will get the minimum value of the range.\n\tfloat getMin();\n\t// This will set the maximum value for the range.\n\tvoid setMax(float max);\n\t// This will set the minimum value for the range.\n\tvoid setMin(float min);\n}", "des": "This class will be used to signify a range. a(min) <= a* <= a(max)"}
{"index": 1580, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDSeedValueMDP {\n\t// Convert this standard java object to a COS dictionary.\n\tCOSDictionary getCOSObject();\n\t// Return the P value.\n\tint getP();\n\t// Set the P value.\n\tvoid setP(int p);\n}", "des": "This MDP dictionary is a part of the seed value dictionary and define if a author signature or a certification signature should be use."}
{"index": 1581, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDSeedValueTimeStamp {\n\t// Convert this standard java object to a COS dictionary.\n\tCOSDictionary getCOSObject();\n\t// Returns the URL.\n\tString getURL();\n\t// Indicates if a timestamp is required.\n\tboolean isTimestampRequired();\n\t// Sets if a timestamp is reuqired or not.\n\tvoid setTimestampRequired(boolean flag);\n\t// Sets the URL.\n\tvoid setURL(String url);\n}", "des": "If exist, it describe where the signature handler can request a RFC3161 timestamp and if it is a must have for the signature."}
{"index": 1582, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDShadingType3 {\n\t// This will return the shading type.\n\tint getShadingType();\n\t// Returns an AWT paint which corresponds to this shading\n\tPaint toPaint(Matrix matrix);\n}", "des": "Resources for a radial shading."}
{"index": 1583, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDSimpleFileSpecification {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// This will get the file name.\n\tString getFile();\n\t// This will set the file name.\n\tvoid setFile(String fileName);\n}", "des": "A file specification that is just a string."}
{"index": 1584, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDStructureElementNameTreeNode {\n\t// Method to convert the COS value in the name tree to the PD Model object.\n\tprotected PDStructureElement convertCOSToPD(COSBase base);\n\t// Create a child node object.\n\tprotected PDNameTreeNode<PDStructureElement> createChildNode(COSDictionary dic);\n}", "des": "todo: JavaDoc"}
{"index": 1585, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDThread {\n\t// This will get the underlying dictionary that this object wraps.\n\tCOSDictionary getCOSObject();\n\t// Get the first bead in the thread, or null if it has not been set yet.\n\tPDThreadBead getFirstBead();\n\t// Get info about the thread, or null if there is nothing.\n\tPDDocumentInformation getThreadInfo();\n\t// This will set the first bead in the thread.\n\tvoid setFirstBead(PDThreadBead bead);\n\t// Set the thread info, can be null.\n\tvoid setThreadInfo(PDDocumentInformation info);\n}", "des": "This a single thread in a PDF document."}
{"index": 1586, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDTransitionDimension {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDTransitionDimension valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDTransitionDimension[] values();\n}", "des": "The dimension in which the specified transition effect shall occur. Only for PDTransitionStyle.Split and PDTransitionStyle.Blinds."}
{"index": 1587, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDTransitionDirection {\n\tCOSBase getCOSBase();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDTransitionDirection valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDTransitionDirection[] values();\n}", "des": "The direction in which the specified transition effect shall moves, expressed in degrees counterclockwise starting from a left-to-right direction. Only for PDTransitionStyle.Wipe, PDTransitionStyle.Glitter, PDTransitionStyle.Fly, PDTransitionStyle.Cover, PDTransitionStyle.Uncover and PDTransitionStyle.Push."}
{"index": 1588, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDTransitionMotion {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDTransitionMotion valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDTransitionMotion[] values();\n}", "des": "The direction of motion for the specified transition effect. Only for PDTransitionStyle.Split, PDTransitionStyle.Blinds and PDTransitionStyle.Fly."}
{"index": 1589, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDTransitionStyle {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDTransitionStyle valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDTransitionStyle[] values();\n}", "des": "The transition style that shall be used when moving to the page from another during a presentation. Ref. table 162 PDF32000-1:2008"}
{"index": 1590, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDTransparencyGroupAttributes {\n\t// Returns the group color space or null if it isn't defined.\n\tPDColorSpace getColorSpace();\n\t// Returns the group color space or null if it isn't defined.\n\tPDColorSpace getColorSpace(PDResources resources);\n\t// Convert this standard java object to a COS object.\n\tCOSDictionary getCOSObject();\n\t// Returns true if this group is isolated.\n\tboolean isIsolated();\n\t// Returns true if this group is a knockout.\n\tboolean isKnockout();\n}", "des": "Transparency group attributes."}
{"index": 1591, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDTristimulus {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the x value of the tristimulus.\n\tfloat getX();\n\t// Returns the y value of the tristimulus.\n\tfloat getY();\n\t// Returns the z value of the tristimulus.\n\tfloat getZ();\n\t// Sets the x value of the tristimulus.\n\tvoid setX(float x);\n\t// Sets the y value of the tristimulus.\n\tvoid setY(float y);\n\t// Sets the z value of the tristimulus.\n\tvoid setZ(float z);\n}", "des": "A tristimulus, or collection of three floating point parameters used for color operations."}
{"index": 1592, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDURIDictionary {\n\t// This will get the base URI to be used in resolving relative URI references.\n\tString getBase();\n\t// Returns the corresponding dictionary.\n\tCOSDictionary getCOSObject();\n\t// This will set the base URI to be used in resolving relative URI references.\n\tvoid setBase(String base);\n}", "des": "This is the implementation of an URI dictionary."}
{"index": 1593, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDUserAttributeObject {\n\t// Adds a user property.\n\tvoid addUserProperty(PDUserProperty userProperty);\n\t// Returns the user properties.\n\tList<PDUserProperty> getOwnerUserProperties();\n\t// Removes a user property.\n\tvoid removeUserProperty(PDUserProperty userProperty);\n\t// Sets the user properties.\n\tvoid setUserProperties(List<PDUserProperty> userProperties);\n\t// Notify a possible change of user properties.\n\tvoid userPropertyChanged(PDUserProperty userProperty);\n}", "des": "A User attribute object."}
{"index": 1594, "repo": "pdfbox-3.0.0-beta1", "code": "Interface PDVectorFont {\n\t// Returns the normalized glyph path for the given character code in a PDF.\n\tGeneralPath getNormalizedPath(int code);\n\t// Returns the glyph path for the given character code.\n\tGeneralPath getPath(int code);\n\t// Returns true if this font contains a glyph for the given character code in a PDF.\n\tboolean hasGlyph(int code);\n}", "des": "A vector outline font, e.g. not Type 3."}
{"index": 1595, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDViewerPreferences.BOUNDARY {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDViewerPreferences.BOUNDARY valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDViewerPreferences.BOUNDARY[] values();\n}", "des": "Enumeration containing all valid values for boundaries."}
{"index": 1596, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDViewerPreferences.DUPLEX {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDViewerPreferences.DUPLEX valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDViewerPreferences.DUPLEX[] values();\n}", "des": "Enumeration containing all valid values for duplex."}
{"index": 1597, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDViewerPreferences.NON_FULL_SCREEN_PAGE_MODE {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDViewerPreferences.NON_FULL_SCREEN_PAGE_MODE valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDViewerPreferences.NON_FULL_SCREEN_PAGE_MODE[] values();\n}", "des": "Enumeration containing all valid values for NonFullScreenPageMode."}
{"index": 1598, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDViewerPreferences.PRINT_SCALING {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDViewerPreferences.PRINT_SCALING valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDViewerPreferences.PRINT_SCALING[] values();\n}", "des": "Enumeration containing all valid values for printscaling."}
{"index": 1599, "repo": "pdfbox-3.0.0-beta1", "code": "Enum PDViewerPreferences.READING_DIRECTION {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PDViewerPreferences.READING_DIRECTION valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PDViewerPreferences.READING_DIRECTION[] values();\n}", "des": "Enumeration containing all valid values for ReadingDirection."}
{"index": 1600, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDXFAResource {\n\t// Get the XFA content as byte array.\n\tbyte[] getBytes();\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Get the XFA content as W3C document.\n\tDocument getDocument();\n}", "des": "An XML Forms Architecture (XFA) resource."}
{"index": 1601, "repo": "pdfbox-3.0.0-beta1", "code": "Class PDXObject {\n\t// Creates a new XObject instance of the appropriate type for the COS stream.\n\tstatic PDXObject createXObject(COSBase base, PDResources resources);\n\t// Returns the stream.\n\tCOSStream getCOSObject();\n\t// Returns the stream.\n\tPDStream getStream();\n}", "des": "An external object, or \"XObject\"."}
{"index": 1602, "repo": "pdfbox-3.0.0-beta1", "code": "Class PublicKeyDecryptionMaterial {\n\t// Returns the certificate contained in the keystore.\n\tX509Certificate getCertificate();\n\t// Returns the password given by the user and that will be used to open the private key.\n\tString getPassword();\n\t// returns The private key that will be used to open the document protection.\n\tKey getPrivateKey();\n}", "des": "This class holds necessary information to decrypt a PDF document protected by the public key security handler. To decrypt such a document, we need: a valid X509 certificate which correspond to one of the recipient of the document the private key corresponding to this certificate the password to decrypt the private key if necessary"}
{"index": 1603, "repo": "pdfbox-3.0.0-beta1", "code": "Class PublicKeyRecipient {\n\t// Returns the access permission granted to the recipient.\n\tAccessPermission getPermission();\n\t// Returns the X509 certificate of the recipient.\n\tX509Certificate getX509();\n\t// Set the access permission granted to the recipient.\n\tvoid setPermission(AccessPermission permissions);\n\t// Set the X509 certificate of the recipient.\n\tvoid setX509(X509Certificate aX509);\n}", "des": "Represents a recipient in the public key protection policy."}
{"index": 1604, "repo": "pdfbox-3.0.0-beta1", "code": "Class PublicKeySecurityHandler {\n\t// Prepare the document for encryption.\n\tvoid prepareDocumentForEncryption(PDDocument doc);\n\t// Prepares everything to decrypt the document.\n\tvoid prepareForDecryption(PDEncryption encryption, COSArray documentIDArray, DecryptionMaterial decryptionMaterial);\n}", "des": "This class implements the public key security handler described in the PDF specification."}
{"index": 1605, "repo": "pdfbox-3.0.0-beta1", "code": "Class RadialShadingContext {\n\tvoid dispose();\n\t// Returns the coords values.\n\tfloat[] getCoords();\n\t// Returns the domain values.\n\tfloat[] getDomain();\n\t// Returns the extend values.\n\tboolean[] getExtend();\n\t// Returns the function.\n\tPDFunction getFunction();\n\tRaster getRaster(int x, int y, int w, int h);\n}", "des": "AWT PaintContext for radial shading. Performance improvement done as part of GSoC2014, Tilman Hausherr is the mentor."}
{"index": 1606, "repo": "pdfbox-3.0.0-beta1", "code": "Enum RenderDestination {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RenderDestination valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RenderDestination[] values();\n}", "des": "Optional content groups are visible depending on the render purpose."}
{"index": 1607, "repo": "pdfbox-3.0.0-beta1", "code": "Enum RenderingIntent {\n\tstatic RenderingIntent fromString(String value);\n\t// Returns the string value, as used in a PDF file.\n\tString stringValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RenderingIntent valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RenderingIntent[] values();\n}", "des": "Rendering intent."}
{"index": 1608, "repo": "pdfbox-3.0.0-beta1", "code": "Class Restore {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Q: Restore the graphics state."}
{"index": 1609, "repo": "pdfbox-3.0.0-beta1", "code": "Class Save {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "q: Save the graphics state."}
{"index": 1610, "repo": "pdfbox-3.0.0-beta1", "code": "Enum Scaling {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Scaling valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Scaling[] values();\n}", "des": "Scale of the image on printed pages."}
{"index": 1611, "repo": "pdfbox-3.0.0-beta1", "code": "Class SecurityProvider {\n\t// Returns the provider to be used for advanced encrypting/decrypting.\n\tstatic Provider getProvider();\n\t// Set the provider to be used for advanced encrypting/decrypting.\n\tstatic void setProvider(Provider provider);\n}", "des": "Singleton which provides a security provider."}
{"index": 1612, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetCharSpacing {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Tc: Set character spacing."}
{"index": 1613, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetColor {\n\t// Returns either the stroking or non-stroking color value.\n\tprotected abstract PDColor getColor();\n\t// Returns either the stroking or non-stroking color space.\n\tprotected abstract PDColorSpace getColorSpace();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n\t// Sets either the stroking or non-stroking color value.\n\tprotected abstract void setColor(PDColor color);\n}", "des": "sc,scn,SC,SCN: Sets the color to use for stroking or non-stroking operations."}
{"index": 1614, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetFlatness {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "i: Set the flatness tolerance."}
{"index": 1615, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetFontAndSize {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Tf: Set text font and size."}
{"index": 1616, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetGraphicsStateParameters {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "gs: Set parameters from graphics state parameter dictionary."}
{"index": 1617, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetLineCapStyle {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "J: Set the line cap style."}
{"index": 1618, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetLineDashPattern {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "d: Set the line dash pattern."}
{"index": 1619, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetLineJoinStyle {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "j: Set the line join style."}
{"index": 1620, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetLineMiterLimit {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "M: Set miter limit."}
{"index": 1621, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetLineWidth {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "w: Set line width."}
{"index": 1622, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetMatrix {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Tm: Set text matrix and text line matrix."}
{"index": 1623, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetNonStrokingColor {\n\t// Returns the non-stroking color.\n\tprotected PDColor getColor();\n\t// Returns the non-stroking color space.\n\tprotected PDColorSpace getColorSpace();\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Sets the non-stroking color.\n\tprotected void setColor(PDColor color);\n}", "des": "sc: Sets the colour to use for non-stroking operations."}
{"index": 1624, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetNonStrokingColorSpace {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "cs: Sets the non-stroking color space."}
{"index": 1625, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetNonStrokingDeviceCMYKColor {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "k: Set the non-stroking colour space to DeviceCMYK and set the colour to use for non-stroking operations."}
{"index": 1626, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetNonStrokingDeviceGrayColor {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "g: Set the non-stroking colour space to DeviceGray and set the gray level to use for non-stroking operations."}
{"index": 1627, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetNonStrokingDeviceRGBColor {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "rg: Set the non-stroking colour space to DeviceRGB and set the colour to use for non-stroking operations."}
{"index": 1628, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetRenderingIntent {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "ri: Set the rendering intent."}
{"index": 1629, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetStrokingColor {\n\t// Returns the stroking color.\n\tprotected PDColor getColor();\n\t// Returns the stroking color space.\n\tprotected PDColorSpace getColorSpace();\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Sets the stroking color.\n\tprotected void setColor(PDColor color);\n}", "des": "SC: Sets the colour to use for stroking stroking operations."}
{"index": 1630, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetStrokingColorSpace {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "CS: Set color space for stroking operations."}
{"index": 1631, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetStrokingDeviceCMYKColor {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "K: Set the stroking colour space to DeviceCMYK and set the colour to use for stroking operations."}
{"index": 1632, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetStrokingDeviceGrayColor {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "G: Set the stroking colour space to DeviceGray and set the gray level to use for stroking operations."}
{"index": 1633, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetStrokingDeviceRGBColor {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// RG Set the stroking colour space to DeviceRGB and set the colour to use for stroking operations.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "RG: Set the stroking colour space to DeviceRGB and set the colour to use for stroking operations."}
{"index": 1634, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetTextHorizontalScaling {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Tz: Set horizontal text scaling."}
{"index": 1635, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetTextLeading {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "TL: Set text leading."}
{"index": 1636, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetTextRenderingMode {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Tr: Set text rendering mode."}
{"index": 1637, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetTextRise {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Ts: Set text rise."}
{"index": 1638, "repo": "pdfbox-3.0.0-beta1", "code": "Class SetWordSpacing {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Tw: Set word spacing."}
{"index": 1639, "repo": "pdfbox-3.0.0-beta1", "code": "Class ShadingFill {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "sh Fills the clipping area with the given shading pattern."}
{"index": 1640, "repo": "pdfbox-3.0.0-beta1", "code": "Class ShowText {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "Tj: Show text."}
{"index": 1641, "repo": "pdfbox-3.0.0-beta1", "code": "Class ShowTextAdjusted {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "TJ: Show text, with position adjustments."}
{"index": 1642, "repo": "pdfbox-3.0.0-beta1", "code": "Class ShowTextLine {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "': Move to the next line and show text."}
{"index": 1643, "repo": "pdfbox-3.0.0-beta1", "code": "Class ShowTextLineAndSpace {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> arguments);\n}", "des": "\": Set word and character spacing, move to next line, and show text."}
{"index": 1644, "repo": "pdfbox-3.0.0-beta1", "code": "Class SigningSupport {\n\tvoid close();\n\t// Get PDF content to be signed.\n\tInputStream getContent();\n\t// Set CMS signature bytes to PDF.\n\tvoid setSignature(byte[] signature);\n}", "des": "Class to be used when creating PDF signatures externally. COSWriter is used to obtain data to be signed and set the resulted CMS signature."}
{"index": 1645, "repo": "pdfbox-3.0.0-beta1", "code": "Class SmallMap<K,V> {\n\tvoid clear();\n\tboolean containsKey(Object key);\n\tboolean containsValue(Object value);\n\tSet<Map.Entry<K,V>> entrySet();\n\tV get(Object key);\n\tboolean isEmpty();\n\t// Returns a set view of the keys contained in this map.\n\tSet<K> keySet();\n\tV put(K key, V value);\n\tvoid putAll(Map<? extends K,? extends V> otherMap);\n\tV remove(Object key);\n\tint size();\n\t// Returns a collection of the values contained in this map.\n\tCollection<V> values();\n}", "des": "Map implementation with a smallest possible memory usage. It should only be used for maps with small number of items (e.g. <30) since most operations have an O(n) complexity. Thus it should be used in cases with large number of map objects, each having only few items."}
{"index": 1646, "repo": "pdfbox-3.0.0-beta1", "code": "Enum Standard14Fonts.FontName {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Standard14Fonts.FontName valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Standard14Fonts.FontName[] values();\n}", "des": "Enum for the names of the 14 standard fonts."}
{"index": 1647, "repo": "pdfbox-3.0.0-beta1", "code": "Class StandardEncoding {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "This is an interface to a text encoder."}
{"index": 1648, "repo": "pdfbox-3.0.0-beta1", "code": "Class StandardProtectionPolicy {\n\t// Returns the owner password.\n\tString getOwnerPassword();\n\t// Returns the access permissions\n\tAccessPermission getPermissions();\n\t// Returns the user password.\n\tString getUserPassword();\n\t// Sets the owner password\n\tvoid setOwnerPassword(String ownerPassword);\n\t// Sets the access permissions\n\tvoid setPermissions(AccessPermission permissions);\n\t// Sets the user password.\n\tvoid setUserPassword(String userPassword);\n}", "des": "The protection policy to add to a document for password-based protection. The following example shows how to protect a PDF document with password. In this example, the document will be protected so that someone opening the document with the user password user_pwd will not be able to modify the document."}
{"index": 1649, "repo": "pdfbox-3.0.0-beta1", "code": "Class StrokePath {\n\t// Returns the name of this operator, e.g.\n\tString getName();\n\t// Process the operator.\n\tvoid process(Operator operator, List<COSBase> operands);\n}", "des": "S Stroke the path."}
{"index": 1650, "repo": "pdfbox-3.0.0-beta1", "code": "Class SymbolEncoding {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "This is an interface to a text encoder."}
{"index": 1651, "repo": "pdfbox-3.0.0-beta1", "code": "Class Type1Encoding {\n\t// Creates an encoding from the given FontBox encoding.\n\tstatic Type1Encoding fromFontBox(org.apache.fontbox.encoding.Encoding encoding);\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "An encoding for a Type 1 font."}
{"index": 1652, "repo": "pdfbox-3.0.0-beta1", "code": "Class Vector {\n\t// Returns the x magnitude.\n\tfloat getX();\n\t// Returns the y magnitude.\n\tfloat getY();\n\t// Returns a new vector scaled by both x and y.\n\tVector scale(float sxy);\n}", "des": "A 2D vector."}
{"index": 1653, "repo": "pdfbox-3.0.0-beta1", "code": "Class WinAnsiEncoding {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "This the win ansi encoding."}
{"index": 1654, "repo": "pdfbox-3.0.0-beta1", "code": "Class XMLUtil {\n\t// This will get the text value of an element.\n\tstatic String getNodeValue(Element node);\n\t// This will parse an XML stream and create a DOM document.\n\tstatic Document parse(InputStream is);\n\t// This will parse an XML stream and create a DOM document.\n\tstatic Document parse(InputStream is, boolean nsAware);\n}", "des": "This class with handle some simple XML operations."}
{"index": 1655, "repo": "pdfbox-3.0.0-beta1", "code": "Enum XReferenceType {\n\t// Returns the numeric representation of this type.\n\tint getNumericValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic XReferenceType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic XReferenceType[] values();\n}", "des": "An instance of this class represents a type for a XReferenceEntry, as it can be found in a PDF's PDFXRefStream."}
{"index": 1656, "repo": "pdfbox-3.0.0-beta1", "code": "Enum XrefTrailerResolver.XRefType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic XrefTrailerResolver.XRefType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic XrefTrailerResolver.XRefType[] values();\n}", "des": "The XRefType of a trailer."}
{"index": 1657, "repo": "pdfbox-3.0.0-beta1", "code": "Class ZapfDingbatsEncoding {\n\t// Convert this standard java object to a COS object.\n\tCOSBase getCOSObject();\n\t// Returns the name of this encoding.\n\tString getEncodingName();\n}", "des": "This is an interface to a text encoder."}
{"index": 1658, "repo": "kafka-clients-3.5.0", "code": "Class AccessControlEntry {\n\tboolean equals(Object o);\n\t// Return the host or `*` for all hosts.\n\tString host();\n\t// Return true if this AclResource has any UNKNOWN components.\n\tboolean isUnknown();\n\t// Return the AclOperation.\n\tAclOperation operation();\n\t// Return the AclPermissionType.\n\tAclPermissionType permissionType();\n\t// Return the principal for this entry.\n\tString principal();\n\t// Create a filter which matches only this AccessControlEntry.\n\tAccessControlEntryFilter toFilter();\n}", "des": "Represents an access control entry. ACEs are a tuple of principal, host, operation, and permissionType. The API for this class is still evolving and we may break compatibility in minor releases, if necessary."}
{"index": 1659, "repo": "kafka-clients-3.5.0", "code": "Class AclDeleteResult.AclBindingDeleteResult {\n\t// Returns ACL binding that matched the delete filter.\n\tAclBinding aclBinding();\n\t// Returns any exception that resulted in failure to delete ACL binding.\n\tOptional<ApiException> exception();\n}", "des": "Delete result for each ACL binding that matched a delete filter."}
{"index": 1660, "repo": "kafka-clients-3.5.0", "code": "Class AdminClient {\n\t// Create a new Admin with the given configuration.\n\tstatic AdminClient create(Map<String,Object> conf);\n\t// Create a new Admin with the given configuration.\n\tstatic AdminClient create(Properties props);\n}", "des": "The base class for in-built admin clients. Client code should use the newer Admin interface in preference to this class. This class may be removed in a later release, but has not be marked as deprecated to avoid unnecessary noise."}
{"index": 1661, "repo": "kafka-clients-3.5.0", "code": "Class AlterClientQuotasOptions {\n\t// Returns whether the request should be validated without altering the configs.\n\tboolean validateOnly();\n\t// Sets whether the request should be validated without altering the configs.\n\tAlterClientQuotasOptions validateOnly(boolean validateOnly);\n}", "des": "Options for Admin.alterClientQuotas(Collection, AlterClientQuotasOptions). The API of this class is evolving, see Admin for details."}
{"index": 1662, "repo": "kafka-clients-3.5.0", "code": "Class AlterClientQuotasResult {\n\t// Returns a future which succeeds only if all quota alterations succeed.\n\tKafkaFuture<Void> all();\n\t// Returns a map from quota entity to a future which can be used to check the status of the operation.\n\tMap<ClientQuotaEntity,KafkaFuture<Void>> values();\n}", "des": "The result of the Admin.alterClientQuotas(Collection, AlterClientQuotasOptions) call. The API of this class is evolving, see Admin for details."}
{"index": 1663, "repo": "kafka-clients-3.5.0", "code": "Class AlterConfigsOptions {\n\t// Return true if the request should be validated without altering the configs.\n\tboolean shouldValidateOnly();\n\t// Set the timeout in milliseconds for this operation or null if the default api timeout for the AdminClient should be used.\n\tAlterConfigsOptions timeoutMs(Integer timeoutMs);\n\t// Set to true if the request should be validated without altering the configs.\n\tAlterConfigsOptions validateOnly(boolean validateOnly);\n}", "des": "Options for Admin.incrementalAlterConfigs(Map) and Admin.alterConfigs(Map). The API of this class is evolving, see Admin for details."}
{"index": 1664, "repo": "kafka-clients-3.5.0", "code": "Class AlterConfigsResult {\n\t// Return a future which succeeds only if all the alter configs operations succeed.\n\tKafkaFuture<Void> all();\n\t// Return a map from resources to futures which can be used to check the status of the operation on each resource.\n\tMap<ConfigResource,KafkaFuture<Void>> values();\n}", "des": "The result of the Admin.alterConfigs(Map) call. The API of this class is evolving, see Admin for details."}
{"index": 1665, "repo": "kafka-clients-3.5.0", "code": "Class AlterConsumerGroupOffsetsResult {\n\t// Return a future which succeeds if all the alter offsets succeed.\n\tKafkaFuture<Void> all();\n\t// Return a future which can be used to check the result for a given partition.\n\tKafkaFuture<Void> partitionResult(TopicPartition partition);\n}", "des": "The result of the Admin.alterConsumerGroupOffsets(String, Map) call. The API of this class is evolving, see AdminClient for details."}
{"index": 1666, "repo": "kafka-clients-3.5.0", "code": "Class AlterPartitionReassignmentsResult {\n\t// Return a future which succeeds only if all the reassignments were successfully initiated.\n\tKafkaFuture<Void> all();\n\t// Return a map from partitions to futures which can be used to check the status of the reassignment.\n\tMap<TopicPartition,KafkaFuture<Void>> values();\n}", "des": "The result of Admin.alterPartitionReassignments(Map, AlterPartitionReassignmentsOptions). The API of this class is evolving. See AdminClient for details."}
{"index": 1667, "repo": "kafka-clients-3.5.0", "code": "Class AlterReplicaLogDirsResult {\n\t// Return a KafkaFuture which succeeds on KafkaFuture.get() if all the replica movement have succeeded.\n\tKafkaFuture<Void> all();\n\t// Return a map from TopicPartitionReplica to KafkaFuture which holds the status of individual replica movement.\n\tMap<TopicPartitionReplica,KafkaFuture<Void>> values();\n}", "des": "The result of Admin.alterReplicaLogDirs(Map, AlterReplicaLogDirsOptions). To retrieve the detailed result per specified TopicPartitionReplica, use values(). To retrieve the overall result only, use all()."}
{"index": 1668, "repo": "kafka-clients-3.5.0", "code": "Class AlterUserScramCredentialsResult {\n\t// Return a future which succeeds only if all the user SCRAM credential alterations succeed.\n\tKafkaFuture<Void> all();\n\t// Return a map from user names to futures, which can be used to check the status of the alteration(s) for each user.\n\tMap<String,KafkaFuture<Void>> values();\n}", "des": "The result of the Admin.alterUserScramCredentials(List) call. The API of this class is evolving, see Admin for details."}
{"index": 1669, "repo": "kafka-clients-3.5.0", "code": "Interface AuthenticationContext {\n\t// Address of the authenticated client\n\tInetAddress clientAddress();\n\t// Name of the listener used for the connection\n\tString listenerName();\n\t// Underlying security protocol of the authentication session.\n\tSecurityProtocol securityProtocol();\n}", "des": "An object representing contextual information from the authentication session. See PlaintextAuthenticationContext, SaslAuthenticationContext and SslAuthenticationContext. This class is only used in the broker."}
{"index": 1670, "repo": "kafka-clients-3.5.0", "code": "Interface AuthorizerServerInfo {\n\t// Returns broker id.\n\tint brokerId();\n\t// Returns cluster metadata for the broker running this authorizer including cluster id.\n\tClusterResource clusterResource();\n\t// Returns the configured early start listeners.\n\tCollection<String> earlyStartListeners();\n\t// Returns endpoints for all listeners including the advertised host and port to which the listener is bound.\n\tCollection<Endpoint> endpoints();\n\t// Returns the inter-broker endpoint.\n\tEndpoint interBrokerEndpoint();\n}", "des": "Runtime broker configuration metadata provided to authorizers during start up."}
{"index": 1671, "repo": "kafka-clients-3.5.0", "code": "Interface ClientQuotaEntity.ConfigEntity {\n\t// Returns the type of this entity.\n\tClientQuotaEntity.ConfigEntityType entityType();\n\t// Returns the name of this entity.\n\tString name();\n}", "des": "Interface representing a quota configuration entity. Quota may be configured at levels that include one or more configuration entities. For example, {user, client-id} quota is represented using two instances of ConfigEntity with entity types USER and CLIENT_ID."}
{"index": 1672, "repo": "kafka-clients-3.5.0", "code": "Enum ClientQuotaEntity.ConfigEntityType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClientQuotaEntity.ConfigEntityType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClientQuotaEntity.ConfigEntityType[] values();\n}", "des": "Entity type of a ClientQuotaEntity.ConfigEntity"}
{"index": 1673, "repo": "kafka-clients-3.5.0", "code": "Enum ClientQuotaType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClientQuotaType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClientQuotaType[] values();\n}", "des": "Types of quotas that may be configured on brokers for client requests."}
{"index": 1674, "repo": "kafka-clients-3.5.0", "code": "Class Config {\n\t// Configuration entries for a resource.\n\tCollection<ConfigEntry> entries();\n\tboolean equals(Object o);\n\t// Get the configuration entry with the provided name or null if there isn't one.\n\tConfigEntry get(String name);\n}", "des": "A configuration object containing the configuration entries for a resource."}
{"index": 1675, "repo": "kafka-clients-3.5.0", "code": "Class ConfigData {\n\t// Returns the data.\n\tMap<String,String> data();\n\t// Returns the TTL (in milliseconds).\n\tLong ttl();\n}", "des": "Configuration data from a ConfigProvider."}
{"index": 1676, "repo": "kafka-clients-3.5.0", "code": "Enum ConfigDef.Importance {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfigDef.Importance valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfigDef.Importance[] values();\n}", "des": "The importance level for a configuration"}
{"index": 1677, "repo": "kafka-clients-3.5.0", "code": "Class ConfigDef.Range {\n\t// A numeric range that checks only the lower bound\n\tstatic ConfigDef.Range atLeast(Number min);\n\t// A numeric range that checks both the upper (inclusive) and lower bound\n\tstatic ConfigDef.Range between(Number min, Number max);\n\t// Perform single configuration validation.\n\tvoid ensureValid(String name, Object o);\n}", "des": "Validation logic for numeric ranges"}
{"index": 1678, "repo": "kafka-clients-3.5.0", "code": "Interface ConfigDef.Recommender {\n\t// The valid values for the configuration given the current configuration values.\n\tList<Object> validValues(String name, Map<String,Object> parsedConfig);\n\t// Set the visibility of the configuration given the current configuration values.\n\tboolean visible(String name, Map<String,Object> parsedConfig);\n}", "des": "This is used by the ConfigDef.validate(Map) to get valid values for a configuration given the current configuration values in order to perform full configuration validation and visibility modification. In case that there are dependencies between configurations, the valid values and visibility for a configuration may change given the values of other configurations."}
{"index": 1679, "repo": "kafka-clients-3.5.0", "code": "Enum ConfigDef.Type {\n\tboolean isSensitive();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfigDef.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfigDef.Type[] values();\n}", "des": "The config types"}
{"index": 1680, "repo": "kafka-clients-3.5.0", "code": "Enum ConfigDef.Width {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfigDef.Width valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfigDef.Width[] values();\n}", "des": "The width of a configuration value"}
{"index": 1681, "repo": "kafka-clients-3.5.0", "code": "Enum ConfigEntry.ConfigSource {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfigEntry.ConfigSource valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfigEntry.ConfigSource[] values();\n}", "des": "Source of configuration entries."}
{"index": 1682, "repo": "kafka-clients-3.5.0", "code": "Class ConfigEntry.ConfigSynonym {\n\tboolean equals(Object o);\n\t// Returns the name of this configuration.\n\tString name();\n\t// Returns the source of this configuration.\n\tConfigEntry.ConfigSource source();\n\t// Returns the value of this configuration, which may be null if the configuration is sensitive.\n\tString value();\n}", "des": "Class representing a configuration synonym of a ConfigEntry."}
{"index": 1683, "repo": "kafka-clients-3.5.0", "code": "Enum ConfigEntry.ConfigType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfigEntry.ConfigType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfigEntry.ConfigType[] values();\n}", "des": "Data type of configuration entry."}
{"index": 1684, "repo": "kafka-clients-3.5.0", "code": "Class ConfigResource {\n\tboolean equals(Object o);\n\t// Returns true if this is the default resource of a resource type.\n\tboolean isDefault();\n\t// Return the resource name.\n\tString name();\n\t// Return the resource type.\n\tConfigResource.Type type();\n}", "des": "A class representing resources that have configs."}
{"index": 1685, "repo": "kafka-clients-3.5.0", "code": "Enum ConfigResource.Type {\n\tstatic ConfigResource.Type forId(byte id);\n\tbyte id();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfigResource.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfigResource.Type[] values();\n}", "des": "Type of resource."}
{"index": 1686, "repo": "kafka-clients-3.5.0", "code": "Class ConfigTransformerResult {\n\t// Returns the transformed data, with variables replaced with corresponding values from the ConfigProvider instances if found.\n\tMap<String,String> data();\n\t// Returns the TTL values (in milliseconds) returned from the ConfigProvider instances for a given set of paths.\n\tMap<String,Long> ttls();\n}", "des": "The result of a transformation from ConfigTransformer."}
{"index": 1687, "repo": "kafka-clients-3.5.0", "code": "Class ConsumerGroupListing {\n\tboolean equals(Object obj);\n\t// Consumer Group Id\n\tString groupId();\n\t// If Consumer Group is simple or not.\n\tboolean isSimpleConsumerGroup();\n\t// Consumer Group state\n\tOptional<ConsumerGroupState> state();\n}", "des": "A listing of a consumer group in the cluster."}
{"index": 1688, "repo": "kafka-clients-3.5.0", "code": "Enum ConsumerGroupState {\n\t// Parse a string into a consumer group state.\n\tstatic ConsumerGroupState parse(String name);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConsumerGroupState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConsumerGroupState[] values();\n}", "des": "The consumer group state."}
{"index": 1689, "repo": "kafka-clients-3.5.0", "code": "Interface ConsumerInterceptor<K,V> {\n\t// This is called when interceptor is closed\n\tvoid close();\n\t// This is called when offsets get committed.\n\tvoid onCommit(Map<TopicPartition,OffsetAndMetadata> offsets);\n\t// This is called just before the records are returned by KafkaConsumer.poll(java.time.Duration)\n\tConsumerRecords<K,V> onConsume(ConsumerRecords<K,V> records);\n}", "des": "A plugin interface that allows you to intercept (and possibly mutate) records received by the consumer. A primary use-case is for third-party components to hook into the consumer applications for custom monitoring, logging, etc."}
{"index": 1690, "repo": "kafka-clients-3.5.0", "code": "Enum ConsumerPartitionAssignor.RebalanceProtocol {\n\tstatic ConsumerPartitionAssignor.RebalanceProtocol forId(byte id);\n\tbyte id();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConsumerPartitionAssignor.RebalanceProtocol valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConsumerPartitionAssignor.RebalanceProtocol[] values();\n}", "des": "The rebalance protocol defines partition assignment and revocation semantics. The purpose is to establish a consistent set of rules that all consumers in a group follow in order to transfer ownership of a partition. ConsumerPartitionAssignor implementors can claim supporting one or more rebalance protocols via the ConsumerPartitionAssignor.supportedProtocols(), and it is their responsibility to respect the rules of those protocols in their ConsumerPartitionAssignor.assign(Cluster, GroupSubscription) implementations. Failures to follow the rules of the supported protocols would lead to runtime error or undefined behavior. The EAGER rebalance protocol requires a consumer to always revoke all its owned partitions before participating in a rebalance event. It therefore allows a complete reshuffling of the assignment. COOPERATIVE rebalance protocol allows a consumer to retain its currently owned partitions before participating in a rebalance event. The assignor should not reassign any owned partitions immediately, but instead may indicate consumers the need for partition revocation so that the revoked partitions can be reassigned to other consumers in the next rebalance event. This is designed for sticky assignment logic which attempts to minimize partition reassignment with cooperative adjustments."}
{"index": 1691, "repo": "kafka-clients-3.5.0", "code": "Class ConsumerRecords<K,V> {\n\t// The number of records for all topics\n\tint count();\n\tstatic <K,V> ConsumerRecords<K,V> empty();\n\tboolean isEmpty();\n\tIterator<ConsumerRecord<K,V>> iterator();\n\t// Get the partitions which have records contained in this record set.\n\tSet<TopicPartition> partitions();\n\t// Get just the records for the given topic\n\tIterable<ConsumerRecord<K,V>> records(String topic);\n\t// Get just the records for the given partition\n\tList<ConsumerRecord<K,V>> records(TopicPartition partition);\n}", "des": "A container that holds the list ConsumerRecord per partition for a particular topic. There is one ConsumerRecord list for every topic partition returned by a Consumer.poll(java.time.Duration) operation."}
{"index": 1692, "repo": "kafka-clients-3.5.0", "code": "Class CreateAclsResult {\n\t// Return a future which succeeds only if all the ACL creations succeed.\n\tKafkaFuture<Void> all();\n\t// Return a map from ACL bindings to futures which can be used to check the status of the creation of each ACL binding.\n\tMap<AclBinding,KafkaFuture<Void>> values();\n}", "des": "The result of the Admin.createAcls(Collection) call. The API of this class is evolving, see Admin for details."}
{"index": 1693, "repo": "kafka-clients-3.5.0", "code": "Class CreatePartitionsResult {\n\t// Return a future which succeeds if all the partition creations succeed.\n\tKafkaFuture<Void> all();\n\t// Return a map from topic names to futures, which can be used to check the status of individual partition creations.\n\tMap<String,KafkaFuture<Void>> values();\n}", "des": "The result of the Admin.createPartitions(Map) call. The API of this class is evolving, see Admin for details."}
{"index": 1694, "repo": "kafka-clients-3.5.0", "code": "Class CumulativeSum {\n\t// Measure this quantity and return the result as a double\n\tdouble measure(MetricConfig config, long now);\n\t// Record the given value\n\tvoid record(MetricConfig config, double value, long now);\n}", "des": "An non-sampled cumulative total maintained over all time. This is a non-sampled version of WindowedSum. See also CumulativeCount if you just want to increment the value by 1 on each recording."}
{"index": 1695, "repo": "kafka-clients-3.5.0", "code": "Class DeleteAclsResult {\n\t// Return a future which succeeds only if all the ACLs deletions succeed, and which contains all the deleted ACLs.\n\tKafkaFuture<Collection<AclBinding>> all();\n\t// Return a map from acl filters to futures which can be used to check the status of the deletions by each filter.\n\tMap<AclBindingFilter,KafkaFuture<DeleteAclsResult.FilterResults>> values();\n}", "des": "The result of the Admin.deleteAcls(Collection) call. The API of this class is evolving, see Admin for details."}
{"index": 1696, "repo": "kafka-clients-3.5.0", "code": "Class DeleteAclsResult.FilterResult {\n\t// Return the deleted ACL binding or null if there was an error.\n\tAclBinding binding();\n\t// Return an exception if the ACL delete was not successful or null if it was.\n\tApiException exception();\n}", "des": "A class containing either the deleted ACL binding or an exception if the delete failed."}
{"index": 1697, "repo": "kafka-clients-3.5.0", "code": "Class DeleteConsumerGroupOffsetsResult {\n\t// Return a future which succeeds only if all the deletions succeed.\n\tKafkaFuture<Void> all();\n\t// Return a future which can be used to check the result for a given partition.\n\tKafkaFuture<Void> partitionResult(TopicPartition partition);\n}", "des": "The result of the Admin.deleteConsumerGroupOffsets(String, Set) call. The API of this class is evolving, see Admin for details."}
{"index": 1698, "repo": "kafka-clients-3.5.0", "code": "Class DeleteConsumerGroupsResult {\n\t// Return a future which succeeds only if all the consumer group deletions succeed.\n\tKafkaFuture<Void> all();\n\t// Return a map from group id to futures which can be used to check the status of individual deletions.\n\tMap<String,KafkaFuture<Void>> deletedGroups();\n}", "des": "The result of the Admin.deleteConsumerGroups(Collection) call. The API of this class is evolving, see Admin for details."}
{"index": 1699, "repo": "kafka-clients-3.5.0", "code": "Class DeleteRecordsResult {\n\t// Return a future which succeeds only if all the records deletions succeed.\n\tKafkaFuture<Void> all();\n\t// Return a map from topic partition to futures which can be used to check the status of individual deletions.\n\tMap<TopicPartition,KafkaFuture<DeletedRecords>> lowWatermarks();\n}", "des": "The result of the Admin.deleteRecords(Map) call. The API of this class is evolving, see Admin for details."}
{"index": 1700, "repo": "kafka-clients-3.5.0", "code": "Class DeleteTopicsOptions {\n\t// Set to true if quota violation should be automatically retried.\n\tDeleteTopicsOptions retryOnQuotaViolation(boolean retryOnQuotaViolation);\n\t// Returns true if quota violation should be automatically retried.\n\tboolean shouldRetryOnQuotaViolation();\n\t// Set the timeout in milliseconds for this operation or null if the default api timeout for the AdminClient should be used.\n\tDeleteTopicsOptions timeoutMs(Integer timeoutMs);\n}", "des": "Options for Admin.deleteTopics(Collection). The API of this class is evolving, see Admin for details."}
{"index": 1701, "repo": "kafka-clients-3.5.0", "code": "Class DeleteTopicsResult {\n\tKafkaFuture<Void> all();\n\t// Use when Admin.deleteTopics(TopicCollection, DeleteTopicsOptions) used a TopicIdCollection\n\tMap<Uuid,KafkaFuture<Void>> topicIdValues();\n\t// Use when Admin.deleteTopics(TopicCollection, DeleteTopicsOptions) used a TopicNameCollection\n\tMap<String,KafkaFuture<Void>> topicNameValues();\n}", "des": "The result of the Admin.deleteTopics(Collection) call. The API of this class is evolving, see Admin for details."}
{"index": 1702, "repo": "kafka-clients-3.5.0", "code": "Class DescribeClusterOptions {\n\t// Specify if authorized operations should be included in the response.\n\tboolean includeAuthorizedOperations();\n\tDescribeClusterOptions includeAuthorizedOperations(boolean includeAuthorizedOperations);\n\t// Set the timeout in milliseconds for this operation or null if the default api timeout for the AdminClient should be used.\n\tDescribeClusterOptions timeoutMs(Integer timeoutMs);\n}", "des": "Options for Admin.describeCluster(). The API of this class is evolving, see Admin for details."}
{"index": 1703, "repo": "kafka-clients-3.5.0", "code": "Class DescribeClusterResult {\n\t// Returns a future which yields authorized operations.\n\tKafkaFuture<Set<AclOperation>> authorizedOperations();\n\t// Returns a future which yields the current cluster id.\n\tKafkaFuture<String> clusterId();\n\t// Returns a future which yields the current controller id.\n\tKafkaFuture<Node> controller();\n\t// Returns a future which yields a collection of nodes.\n\tKafkaFuture<Collection<Node>> nodes();\n}", "des": "The result of the Admin.describeCluster() call. The API of this class is evolving, see Admin for details."}
{"index": 1704, "repo": "kafka-clients-3.5.0", "code": "Class DescribeConfigsResult {\n\t// Return a future which succeeds only if all the config descriptions succeed.\n\tKafkaFuture<Map<ConfigResource,Config>> all();\n\t// Return a map from resources to futures which can be used to check the status of the configuration for each resource.\n\tMap<ConfigResource,KafkaFuture<Config>> values();\n}", "des": "The result of the Admin.describeConfigs(Collection) call. The API of this class is evolving, see Admin for details."}
{"index": 1705, "repo": "kafka-clients-3.5.0", "code": "Class DescribeConsumerGroupsResult {\n\t// Return a future which yields all ConsumerGroupDescription objects, if all the describes succeed.\n\tKafkaFuture<Map<String,ConsumerGroupDescription>> all();\n\t// Return a map from group id to futures which yield group descriptions.\n\tMap<String,KafkaFuture<ConsumerGroupDescription>> describedGroups();\n}", "des": "The result of the KafkaAdminClient.describeConsumerGroups(Collection, DescribeConsumerGroupsOptions)} call. The API of this class is evolving, see Admin for details."}
{"index": 1706, "repo": "kafka-clients-3.5.0", "code": "Class DescribeLogDirsResult {\n\t// Return a future which succeeds only if all the brokers have responded without error.\n\tKafkaFuture<Map<Integer,Map<String,LogDirDescription>>> allDescriptions();\n\t// Return a map from brokerId to future which can be used to check the information of partitions on each individual broker.\n\tMap<Integer,KafkaFuture<Map<String,LogDirDescription>>> descriptions();\n}", "des": "The result of the Admin.describeLogDirs(Collection) call. The API of this class is evolving, see Admin for details."}
{"index": 1707, "repo": "kafka-clients-3.5.0", "code": "Class DescribeReplicaLogDirsResult {\n\t// Return a future which succeeds if log directory information of all replicas are available\n\tKafkaFuture<Map<TopicPartitionReplica,DescribeReplicaLogDirsResult.ReplicaLogDirInfo>> all();\n\t// Return a map from replica to future which can be used to check the log directory information of individual replicas\n\tMap<TopicPartitionReplica,KafkaFuture<DescribeReplicaLogDirsResult.ReplicaLogDirInfo>> values();\n}", "des": "The result of Admin.describeReplicaLogDirs(Collection). The API of this class is evolving, see Admin for details."}
{"index": 1708, "repo": "kafka-clients-3.5.0", "code": "Class DescribeTopicsResult {\n\tKafkaFuture<Map<Uuid,TopicDescription>> allTopicIds();\n\tKafkaFuture<Map<String,TopicDescription>> allTopicNames();\n\t// Use when Admin.describeTopics(TopicCollection, DescribeTopicsOptions) used a TopicIdCollection\n\tMap<Uuid,KafkaFuture<TopicDescription>> topicIdValues();\n\t// Use when Admin.describeTopics(TopicCollection, DescribeTopicsOptions) used a TopicNameCollection\n\tMap<String,KafkaFuture<TopicDescription>> topicNameValues();\n}", "des": "The result of the Admin.describeTopics(Collection) call. The API of this class is evolving, see Admin for details."}
{"index": 1709, "repo": "kafka-clients-3.5.0", "code": "Interface Deserializer<T> {\n\t// Close this deserializer.\n\tdefault void close();\n\t// Configure this class.\n\tdefault void configure(Map<String,?> configs, boolean isKey);\n\t// Deserialize a record value from a byte array into a value or object.\n\tT deserialize(String topic, byte[] data);\n\t// Deserialize a record value from a byte array into a value or object.\n\tdefault T deserialize(String topic, Headers headers, byte[] data);\n}", "des": "An interface for converting bytes to objects. A class that implements this interface is expected to have a constructor with no parameters."}
{"index": 1710, "repo": "kafka-clients-3.5.0", "code": "Class DirectoryConfigProvider {\n\tvoid close();\n\t// Configure this class with the given key-value pairs\n\tvoid configure(Map<String,?> configs);\n\t// Retrieves the data contained in regular files in the directory given by path.\n\tConfigData get(String path);\n\t// Retrieves the data contained in the regular files named by keys in the directory given by path.\n\tConfigData get(String path, Set<String> keys);\n}", "des": "An implementation of ConfigProvider based on a directory of files. Property keys correspond to the names of the regular (i.e. non-directory) files in a directory given by the path parameter. Property values are taken from the file contents corresponding to each key."}
{"index": 1711, "repo": "kafka-clients-3.5.0", "code": "Enum ElectionType {\n\tstatic ElectionType valueOf(byte value);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ElectionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ElectionType[] values();\n}", "des": "Options for Admin.electLeaders(ElectionType, Set, org.apache.kafka.clients.admin.ElectLeadersOptions). The API of this class is evolving, see Admin for details."}
{"index": 1712, "repo": "kafka-clients-3.5.0", "code": "Class ElectLeadersResult {\n\t// Return a future which succeeds if all the topic elections succeed.\n\tKafkaFuture<Void> all();\n\t// Get a future for the topic partitions for which a leader election was attempted.\n\tKafkaFuture<Map<TopicPartition,Optional<Throwable>>> partitions();\n}", "des": "The result of Admin.electLeaders(ElectionType, Set, ElectLeadersOptions) The API of this class is evolving, see Admin for details."}
{"index": 1713, "repo": "kafka-clients-3.5.0", "code": "Class Endpoint {\n\tboolean equals(Object o);\n\t// Returns advertised host name of this endpoint.\n\tString host();\n\t// Returns the listener name of this endpoint.\n\tOptional<String> listenerName();\n\t// Returns the port to which the listener is bound.\n\tint port();\n\t// Returns the security protocol of this endpoint.\n\tSecurityProtocol securityProtocol();\n}", "des": "Represents a broker endpoint."}
{"index": 1714, "repo": "kafka-clients-3.5.0", "code": "Class EnvVarConfigProvider {\n\tvoid close();\n\t// Configure this class with the given key-value pairs\n\tvoid configure(Map<String,?> configs);\n\t// Retrieves the data at the given path.\n\tConfigData get(String path);\n\t// Retrieves the data with the given keys at the given path.\n\tConfigData get(String path, Set<String> keys);\n}", "des": "An implementation of ConfigProvider based on environment variables. Keys correspond to the names of the environment variables, paths are currently not being used. Using an allowlist pattern ALLOWLIST_PATTERN_CONFIG that supports regular expressions, it is possible to limit access to specific environment variables. Default allowlist pattern is \".*\"."}
{"index": 1715, "repo": "kafka-clients-3.5.0", "code": "Class FeatureMetadata {\n\tboolean equals(Object other);\n\t// Returns a map of finalized feature versions.\n\tMap<String,FinalizedVersionRange> finalizedFeatures();\n\t// The epoch for the finalized features.\n\tOptional<Long> finalizedFeaturesEpoch();\n\t// Returns a map of supported feature versions.\n\tMap<String,SupportedVersionRange> supportedFeatures();\n}", "des": "Encapsulates details about finalized as well as supported features. This is particularly useful to hold the result returned by the Admin.describeFeatures(DescribeFeaturesOptions) API."}
{"index": 1716, "repo": "kafka-clients-3.5.0", "code": "Class FileConfigProvider {\n\tvoid close();\n\t// Configure this class with the given key-value pairs\n\tvoid configure(Map<String,?> configs);\n\t// Retrieves the data at the given Properties file.\n\tConfigData get(String path);\n\t// Retrieves the data with the given keys at the given Properties file.\n\tConfigData get(String path, Set<String> keys);\n}", "des": "An implementation of ConfigProvider that represents a Properties file. All property keys and values are stored as cleartext."}
{"index": 1717, "repo": "kafka-clients-3.5.0", "code": "Class Frequency {\n\t// Get the value of this metrics center point.\n\tdouble centerValue();\n\t// Get the name of this metric.\n\tMetricName name();\n}", "des": "Definition of a frequency metric used in a Frequencies compound statistic."}
{"index": 1718, "repo": "kafka-clients-3.5.0", "code": "Interface Histogram.BinScheme {\n\t// Get the number of bins.\n\tint bins();\n\t// Determine the value at the upper range of the specified bin.\n\tdouble fromBin(int bin);\n\t// Determine the 0-based bin number in which the supplied value should be placed.\n\tint toBin(double value);\n}", "des": "An algorithm for determining the bin in which a value is to be placed as well as calculating the upper end of each bin."}
{"index": 1719, "repo": "kafka-clients-3.5.0", "code": "Class Histogram.ConstantBinScheme {\n\t// Get the number of bins.\n\tint bins();\n\t// Determine the value at the upper range of the specified bin.\n\tdouble fromBin(int b);\n\t// Determine the 0-based bin number in which the supplied value should be placed.\n\tint toBin(double x);\n}", "des": "A scheme for calculating the bins where the width of each bin is a constant determined by the range of values and the number of bins."}
{"index": 1720, "repo": "kafka-clients-3.5.0", "code": "Class Histogram.LinearBinScheme {\n\t// Get the number of bins.\n\tint bins();\n\t// Determine the value at the upper range of the specified bin.\n\tdouble fromBin(int b);\n\t// Determine the 0-based bin number in which the supplied value should be placed.\n\tint toBin(double x);\n}", "des": "A scheme for calculating the bins where the width of each bin is one more than the previous bin, and therefore the bin widths are increasing at a linear rate. However, the bin widths are scaled such that the specified range of values will all fit within the bins (e.g., the upper range of the last bin is equal to the maximum value)."}
{"index": 1721, "repo": "kafka-clients-3.5.0", "code": "Interface KafkaPrincipalSerde {\n\t// Deserialize a KafkaPrincipal from byte array.\n\tKafkaPrincipal deserialize(byte[] bytes);\n\t// Serialize a KafkaPrincipal into byte array.\n\tbyte[] serialize(KafkaPrincipal principal);\n}", "des": "Serializer/Deserializer interface for KafkaPrincipal for the purpose of inter-broker forwarding. Any serialization/deserialization failure should raise a SerializationException to be consistent."}
{"index": 1722, "repo": "kafka-clients-3.5.0", "code": "Class ListConsumerGroupOffsetsSpec {\n\tboolean equals(Object o);\n\t// Returns the topic partitions whose offsets are to be listed for a consumer group.\n\tCollection<TopicPartition> topicPartitions();\n\t// Set the topic partitions whose offsets are to be listed for a consumer group.\n\tListConsumerGroupOffsetsSpec topicPartitions(Collection<TopicPartition> topicPartitions);\n}", "des": "Specification of consumer group offsets to list using Admin.listConsumerGroupOffsets(java.util.Map). The API of this class is evolving, see Admin for details."}
{"index": 1723, "repo": "kafka-clients-3.5.0", "code": "Class ListConsumerGroupsOptions {\n\t// If states is set, only groups in these states will be returned by listConsumerGroups() Otherwise, all groups are returned.\n\tListConsumerGroupsOptions inStates(Set<ConsumerGroupState> states);\n\t// Returns the list of States that are requested or empty if no states have been specified\n\tSet<ConsumerGroupState> states();\n}", "des": "Options for Admin.listConsumerGroups(). The API of this class is evolving, see Admin for details."}
{"index": 1724, "repo": "kafka-clients-3.5.0", "code": "Class ListConsumerGroupsResult {\n\t// Returns a future that yields either an exception, or the full set of consumer group listings.\n\tKafkaFuture<Collection<ConsumerGroupListing>> all();\n\t// Returns a future which yields just the errors which occurred.\n\tKafkaFuture<Collection<Throwable>> errors();\n\t// Returns a future which yields just the valid listings.\n\tKafkaFuture<Collection<ConsumerGroupListing>> valid();\n}", "des": "The result of the Admin.listConsumerGroups() call."}
{"index": 1725, "repo": "kafka-clients-3.5.0", "code": "Class ListOffsetsResult {\n\t// Return a future which succeeds only if offsets for all specified partitions have been successfully retrieved.\n\tKafkaFuture<Map<TopicPartition,ListOffsetsResult.ListOffsetsResultInfo>> all();\n\t// Return a future which can be used to check the result for a given partition.\n\tKafkaFuture<ListOffsetsResult.ListOffsetsResultInfo> partitionResult(TopicPartition partition);\n}", "des": "The result of the Admin.listOffsets(Map) call. The API of this class is evolving, see AdminClient for details."}
{"index": 1726, "repo": "kafka-clients-3.5.0", "code": "Class ListTopicsOptions {\n\tboolean equals(Object o);\n\t// Set whether we should list internal topics.\n\tListTopicsOptions listInternal(boolean listInternal);\n\t// Return true if we should list internal topics.\n\tboolean shouldListInternal();\n\t// Set the timeout in milliseconds for this operation or null if the default api timeout for the AdminClient should be used.\n\tListTopicsOptions timeoutMs(Integer timeoutMs);\n}", "des": "Options for Admin.listTopics(). The API of this class is evolving, see Admin for details."}
{"index": 1727, "repo": "kafka-clients-3.5.0", "code": "Class ListTopicsResult {\n\t// Return a future which yields a collection of TopicListing objects.\n\tKafkaFuture<Collection<TopicListing>> listings();\n\t// Return a future which yields a collection of topic names.\n\tKafkaFuture<Set<String>> names();\n\t// Return a future which yields a map of topic names to TopicListing objects.\n\tKafkaFuture<Map<String,TopicListing>> namesToListings();\n}", "des": "The result of the Admin.listTopics() call. The API of this class is evolving, see Admin for details."}
{"index": 1728, "repo": "kafka-clients-3.5.0", "code": "Class ListTransactionsResult {\n\t// Get all transaction listings.\n\tKafkaFuture<Collection<TransactionListing>> all();\n\t// Get all transaction listings in a map which is keyed by the ID of respective broker that is currently managing them.\n\tKafkaFuture<Map<Integer,Collection<TransactionListing>>> allByBrokerId();\n\t// Get a future which returns a map containing the underlying listing future for each broker in the cluster.\n\tKafkaFuture<Map<Integer,KafkaFuture<Collection<TransactionListing>>>> byBrokerId();\n}", "des": "The result of the Admin.listTransactions() call."}
{"index": 1729, "repo": "kafka-clients-3.5.0", "code": "Interface Login {\n\t// Closes this instance.\n\tvoid close();\n\t// Configures this login instance.\n\tvoid configure(Map<String,?> configs, String contextName, Configuration jaasConfiguration, AuthenticateCallbackHandler loginCallbackHandler);\n\t// Performs login for each login module specified for the login context of this instance.\n\tLoginContext login();\n\t// Returns the service name to be used for SASL.\n\tString serviceName();\n\t// Returns the authenticated subject of this login context.\n\tSubject subject();\n}", "des": "Login interface for authentication."}
{"index": 1730, "repo": "kafka-clients-3.5.0", "code": "Class MemberDescription {\n\t// The assignment of the group member.\n\tMemberAssignment assignment();\n\t// The client id of the group member.\n\tString clientId();\n\t// The consumer id of the group member.\n\tString consumerId();\n\tboolean equals(Object o);\n\t// The instance id of the group member.\n\tOptional<String> groupInstanceId();\n\t// The host where the group member is running.\n\tString host();\n}", "des": "A detailed description of a single group instance in the cluster."}
{"index": 1731, "repo": "kafka-clients-3.5.0", "code": "Interface MessageFormatter {\n\t// Closes the formatter\n\tdefault void close();\n\t// Configures the MessageFormatter\n\tdefault void configure(Map<String,?> configs);\n\t// Parses and formats a record for display\n\tvoid writeTo(ConsumerRecord<byte[],byte[]> consumerRecord, PrintStream output);\n}", "des": "This interface allows to define Formatters that can be used to parse and format records read by a Consumer instance for display. The kafka-console-consumer has built-in support for MessageFormatter, via the --formatter flag. Kafka provides a few implementations to display records of internal topics such as __consumer_offsets, __transaction_state and the MirrorMaker2 topics."}
{"index": 1732, "repo": "kafka-clients-3.5.0", "code": "Interface Metric {\n\t// A name for this metric\n\tMetricName metricName();\n\t// The value of the metric, which may be measurable or a non-measurable gauge\n\tObject metricValue();\n}", "des": "A metric tracked for monitoring purposes."}
{"index": 1733, "repo": "kafka-clients-3.5.0", "code": "Class MetricNameTemplate {\n\t// Get the description of the metric.\n\tString description();\n\tboolean equals(Object o);\n\t// Get the name of the group.\n\tString group();\n\t// Get the name of the metric.\n\tString name();\n\t// Get the set of tag names for the metric.\n\tSet<String> tags();\n}", "des": "A template for a MetricName. It contains a name, group, and description, as well as all the tags that will be used to create the mBean name. Tag values are omitted from the template, but are filled in at runtime with their specified values. The order of the tags is maintained, if an ordered set is provided, so that the mBean names can be compared and sorted lexicographically."}
{"index": 1734, "repo": "kafka-clients-3.5.0", "code": "Class OAuthBearerExtensionsValidatorCallback {\n\t// Set the error value for a specific extension key-value pair if validation has failed\n\tvoid error(String invalidExtensionName, String errorMessage);\n\tMap<String,String> ignoredExtensions();\n\tSaslExtensions inputExtensions();\n\tMap<String,String> invalidExtensions();\n\tOAuthBearerToken token();\n\t// Validates a specific extension in the original inputExtensions map\n\tvoid valid(String extensionName);\n\tMap<String,String> validatedExtensions();\n}", "des": "A Callback for use by the SaslServer implementation when it needs to validate the SASL extensions for the OAUTHBEARER mechanism Callback handlers should use the valid(String) method to communicate valid extensions back to the SASL server. Callback handlers should use the error(String, String) method to communicate validation errors back to the SASL Server. As per RFC-7628 (https://tools.ietf.org/html/rfc7628#section-3.1), unknown extensions must be ignored by the server. The callback handler implementation should simply ignore unknown extensions, not calling error(String, String) nor valid(String). Callback handlers should communicate other problems by raising an IOException."}
{"index": 1735, "repo": "kafka-clients-3.5.0", "code": "Interface Partitioner {\n\t// This is called when partitioner is closed.\n\tvoid close();\n\t// Compute the partition for the given record.\n\tint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n}", "des": "Partitioner Interface"}
{"index": 1736, "repo": "kafka-clients-3.5.0", "code": "Class PartitionReassignment {\n\t// The brokers that we are adding this partition to as part of a reassignment.\n\tList<Integer> addingReplicas();\n\t// The brokers that we are removing this partition from as part of a reassignment.\n\tList<Integer> removingReplicas();\n\t// The brokers which this partition currently resides on.\n\tList<Integer> replicas();\n}", "des": "A partition reassignment, which has been listed via Admin.listPartitionReassignments()."}
{"index": 1737, "repo": "kafka-clients-3.5.0", "code": "Class RangeAssignor {\n\tMap<String,List<TopicPartition>> assign(Map<String,Integer> partitionsPerTopic, Map<String,ConsumerPartitionAssignor.Subscription> subscriptions);\n\t// Performs range assignment of the specified partitions for the consumers with the provided subscriptions.\n\tMap<String,List<TopicPartition>> assignPartitions(Map<String,List<PartitionInfo>> partitionsPerTopic, Map<String,ConsumerPartitionAssignor.Subscription> subscriptions);\n\t// Unique name for this assignor (e.g.\n\tString name();\n}", "des": ""}
{"index": 1738, "repo": "kafka-clients-3.5.0", "code": "Class Rate {\n\t// Measure this quantity and return the result as a double\n\tdouble measure(MetricConfig config, long now);\n\t// Record the given value\n\tvoid record(MetricConfig config, double value, long timeMs);\n\tString unitName();\n\tlong windowSize(MetricConfig config, long now);\n}", "des": "The rate of the given quantity. By default this is the total observed over a set of samples from a sampled statistic divided by the elapsed time over the sample windows. Alternative SampledStat implementations can be provided, however, to record the rate of occurrences (e.g. the count of values measured over the time interval) or other such values."}
{"index": 1739, "repo": "kafka-clients-3.5.0", "code": "Interface Reconfigurable {\n\t// Returns the names of configs that may be reconfigured.\n\tSet<String> reconfigurableConfigs();\n\t// Reconfigures this instance with the given key-value pairs.\n\tvoid reconfigure(Map<String,?> configs);\n\t// Validates the provided configuration.\n\tvoid validateReconfiguration(Map<String,?> configs);\n}", "des": "Interface for reconfigurable classes that support dynamic configuration."}
{"index": 1740, "repo": "kafka-clients-3.5.0", "code": "Class RecordsToDelete {\n\t// The offset before which all records will be deleted\n\tlong beforeOffset();\n\t// Delete all the records before the given offset\n\tstatic RecordsToDelete beforeOffset(long offset);\n\tboolean equals(Object o);\n}", "des": "Describe records to delete in a call to Admin.deleteRecords(Map) The API of this class is evolving, see Admin for details."}
{"index": 1741, "repo": "kafka-clients-3.5.0", "code": "Class RemoveMembersFromConsumerGroupResult {\n\t// Returns a future which indicates whether the request was 100% success, i.e.\n\tKafkaFuture<Void> all();\n\t// Returns the selected member future.\n\tKafkaFuture<Void> memberResult(MemberToRemove member);\n}", "des": "The result of the Admin.removeMembersFromConsumerGroup(String, RemoveMembersFromConsumerGroupOptions) call. The API of this class is evolving, see Admin for details."}
{"index": 1742, "repo": "kafka-clients-3.5.0", "code": "Class ReplicaInfo {\n\t// Whether this replica has been created by a AlterReplicaLogDirsRequest but not yet replaced the current replica on the broker.\n\tboolean isFuture();\n\t// The lag of the log's LEO with respect to the partition's high watermark (if it is the current log for the partition) or the current replica's LEO (if it is the future log for the partition).\n\tlong offsetLag();\n\t// The total size of the log segments in this replica in bytes.\n\tlong size();\n}", "des": "A description of a replica on a particular broker."}
{"index": 1743, "repo": "kafka-clients-3.5.0", "code": "Class Resource {\n\tboolean equals(Object o);\n\t// Return true if this Resource has any UNKNOWN components.\n\tboolean isUnknown();\n\t// Return the resource name.\n\tString name();\n\t// Return the resource type.\n\tResourceType resourceType();\n}", "des": "Represents a cluster resource with a tuple of (type, name). The API for this class is still evolving and we may break compatibility in minor releases, if necessary."}
{"index": 1744, "repo": "kafka-clients-3.5.0", "code": "Class RoundRobinPartitioner {\n\t// This is called when partitioner is closed.\n\tvoid close();\n\t// Configure this class with the given key-value pairs\n\tvoid configure(Map<String,?> configs);\n\t// Compute the partition for the given record.\n\tint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n}", "des": "The \"Round-Robin\" partitioner This partitioning strategy can be used when user wants to distribute the writes to all partitions equally. This is the behaviour regardless of record key hash."}
{"index": 1745, "repo": "kafka-clients-3.5.0", "code": "Class SampledStat {\n\tabstract double combine(List<org.apache.kafka.common.metrics.stats.SampledStat.Sample> samples, MetricConfig config, long now);\n\torg.apache.kafka.common.metrics.stats.SampledStat.Sample current(long timeMs);\n\t// Measure this quantity and return the result as a double\n\tdouble measure(MetricConfig config, long now);\n\torg.apache.kafka.common.metrics.stats.SampledStat.Sample oldest(long now);\n\t// Record the given value\n\tvoid record(MetricConfig config, double value, long timeMs);\n}", "des": "A SampledStat records a single scalar value measured over one or more samples. Each sample is recorded over a configurable window. The window can be defined by number of events or elapsed time (or both, if both are given the window is complete when either the event count or elapsed time criterion is met)."}
{"index": 1746, "repo": "kafka-clients-3.5.0", "code": "Class SaslExtensions {\n\t// Creates an \"empty\" instance indicating no SASL extensions.\n\tstatic SaslExtensions empty();\n\t// Implements equals using the reference comparison implementation from Object.equals(Object).\n\tboolean equals(Object o);\n\t// Returns an immutable map of the extension names and their values\n\tMap<String,String> map();\n}", "des": "A simple immutable value object class holding customizable SASL extensions."}
{"index": 1747, "repo": "kafka-clients-3.5.0", "code": "Class SaslExtensionsCallback {\n\t// Returns always non-null SaslExtensions consisting of the extension names and values that are sent by the client to the server in the initial client SASL authentication message.\n\tSaslExtensions extensions();\n\t// Sets the SASL extensions on this callback.\n\tvoid extensions(SaslExtensions extensions);\n}", "des": "Optional callback used for SASL mechanisms if any extensions need to be set in the SASL exchange."}
{"index": 1748, "repo": "kafka-clients-3.5.0", "code": "Class ScramCredential {\n\t// Number of iterations used to process this credential using the SCRAM algorithm.\n\tint iterations();\n\t// Returns the salt used to process this credential using the SCRAM algorithm.\n\tbyte[] salt();\n\t// Server key computed from the client password using the SCRAM algorithm.\n\tbyte[] serverKey();\n\t// Stored key computed from the client password using the SCRAM algorithm.\n\tbyte[] storedKey();\n}", "des": "SCRAM credential class that encapsulates the credential data persisted for each user that is accessible to the server. See RFC rfc5802 for details."}
{"index": 1749, "repo": "kafka-clients-3.5.0", "code": "Class ScramCredentialCallback {\n\t// Returns the SCRAM credential if set on this instance.\n\tScramCredential scramCredential();\n\t// Sets the SCRAM credential for this instance.\n\tvoid scramCredential(ScramCredential scramCredential);\n}", "des": "Callback used for SCRAM mechanisms."}
{"index": 1750, "repo": "kafka-clients-3.5.0", "code": "Class ScramExtensionsCallback {\n\t// Returns map of the extension names and values that are sent by the client to the server in the initial client SCRAM authentication message.\n\tMap<String,String> extensions();\n\t// Sets the SCRAM extensions on this callback.\n\tvoid extensions(Map<String,String> extensions);\n}", "des": "Optional callback used for SCRAM mechanisms if any extensions need to be set in the SASL/SCRAM exchange."}
{"index": 1751, "repo": "kafka-clients-3.5.0", "code": "Enum ScramMechanism {\n\tstatic ScramMechanism fromMechanismName(String mechanismName);\n\tstatic ScramMechanism fromType(byte type);\n\tString mechanismName();\n\tbyte type();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ScramMechanism valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ScramMechanism[] values();\n}", "des": "Representation of a SASL/SCRAM Mechanism."}
{"index": 1752, "repo": "kafka-clients-3.5.0", "code": "Interface SecurityProviderCreator {\n\t// Configure method is used to configure the generator to create the Security Provider\n\tdefault void configure(Map<String,?> config);\n\t// Generate the security provider configured\n\tProvider getProvider();\n}", "des": "An interface for generating security providers."}
{"index": 1753, "repo": "kafka-clients-3.5.0", "code": "Interface Serde<T> {\n\t// Close this serde class, which will close the underlying serializer and deserializer.\n\tdefault void close();\n\t// Configure this class, which will configure the underlying serializer and deserializer.\n\tdefault void configure(Map<String,?> configs, boolean isKey);\n\tDeserializer<T> deserializer();\n\tSerializer<T> serializer();\n}", "des": "The interface for wrapping a serializer and deserializer for the given data type."}
{"index": 1754, "repo": "kafka-clients-3.5.0", "code": "Interface Serializer<T> {\n\t// Close this serializer.\n\tdefault void close();\n\t// Configure this class.\n\tdefault void configure(Map<String,?> configs, boolean isKey);\n\t// Convert data into a byte array.\n\tdefault byte[] serialize(String topic, Headers headers, T data);\n\t// Convert data into a byte array.\n\tbyte[] serialize(String topic, T data);\n}", "des": "An interface for converting objects to bytes. A class that implements this interface is expected to have a constructor with no parameter."}
{"index": 1755, "repo": "kafka-clients-3.5.0", "code": "Enum SslClientAuth {\n\tstatic SslClientAuth forConfig(String key);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SslClientAuth valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SslClientAuth[] values();\n}", "des": "Describes whether the server should require or request client authentication."}
{"index": 1756, "repo": "kafka-clients-3.5.0", "code": "Class StringDeserializer {\n\t// Configure this class.\n\tvoid configure(Map<String,?> configs, boolean isKey);\n\t// Deserialize a record value from a byte array into a value or object.\n\tString deserialize(String topic, byte[] data);\n}", "des": "String encoding defaults to UTF8 and can be customized by setting the property key.deserializer.encoding, value.deserializer.encoding or deserializer.encoding. The first two take precedence over the last."}
{"index": 1757, "repo": "kafka-clients-3.5.0", "code": "Class StringSerializer {\n\t// Configure this class.\n\tvoid configure(Map<String,?> configs, boolean isKey);\n\t// Convert data into a byte array.\n\tbyte[] serialize(String topic, String data);\n}", "des": "String encoding defaults to UTF8 and can be customized by setting the property key.serializer.encoding, value.serializer.encoding or serializer.encoding. The first two take precedence over the last."}
{"index": 1758, "repo": "kafka-clients-3.5.0", "code": "Class TokenBucket {\n\t// Measure this quantity and return the result as a double\n\tdouble measure(MetricConfig config, long timeMs);\n\t// Record the given value\n\tvoid record(MetricConfig config, double value, long timeMs);\n}", "des": "The TokenBucket is a MeasurableStat implementing a token bucket algorithm that is usable within a Sensor. The Quota.bound() defined the refill rate of the bucket while the maximum burst or the maximum number of credits of the bucket is defined by * MetricConfig#timeWindowMs() * Quota#bound(). The quota is considered as exhausted when the amount of remaining credits in the bucket is below zero. The enforcement is done by the Sensor. Token Bucket vs Rate based Quota: The current sampled rate based quota does not cope well with bursty workloads. The issue is that a unique and large sample can hold the average above the quota until it is discarded. Practically, when this happens, one must wait until the sample is expired to bring the rate below the quota even though less time would be theoretically required. As an example, let's imagine that we have: - Quota (Q) = 5 - Samples (S) = 100 - Window (W) = 1s A burst of 560 brings the average rate (R) to 5.6 (560 / 100). The expected throttle time is computed as follow: ((R - Q / Q * S * W)) = ((5.6 - 5) / 5 * 100 * 1) = 12 secs. In practice, the average rate won't go below the quota before the burst is dropped from the samples so one must wait 100s (S * W). The token bucket relies on continuously updated amount of credits. Therefore, it does not suffers from the above issue. The same example would work as follow: - Quota (Q) = 5 - Burst (B) = 5 * 1 * 100 = 500 (Q * S * W) A burst of 560 brings the amount of credits to -60. One must wait 12s (-(-60)/5) to refill the bucket to zero."}
{"index": 1759, "repo": "kafka-clients-3.5.0", "code": "Class TopicDescription {\n\t// authorized operations for this topic, or null if this is not known.\n\tSet<AclOperation> authorizedOperations();\n\tboolean equals(Object o);\n\t// Whether the topic is internal to Kafka.\n\tboolean isInternal();\n\t// The name of the topic.\n\tString name();\n\t// A list of partitions where the index represents the partition id and the element contains leadership and replica information for that partition.\n\tList<TopicPartitionInfo> partitions();\n\tUuid topicId();\n}", "des": "A detailed description of a single topic in the cluster."}
{"index": 1760, "repo": "kafka-clients-3.5.0", "code": "Class TopicListing {\n\t// Whether the topic is internal to Kafka.\n\tboolean isInternal();\n\t// The name of the topic.\n\tString name();\n\t// The id of the topic.\n\tUuid topicId();\n}", "des": "A listing of a topic in the cluster."}
{"index": 1761, "repo": "kafka-clients-3.5.0", "code": "Class TopicPartitionInfo {\n\tboolean equals(Object o);\n\t// Return the in-sync replicas of the partition.\n\tList<Node> isr();\n\t// Return the leader of the partition or null if there is none.\n\tNode leader();\n\t// Return the partition id.\n\tint partition();\n\t// Return the replicas of the partition in the same order as the replica assignment.\n\tList<Node> replicas();\n}", "des": "A class containing leadership, replicas and ISR information for a topic partition."}
{"index": 1762, "repo": "kafka-clients-3.5.0", "code": "Class UUIDDeserializer {\n\t// Configure this class.\n\tvoid configure(Map<String,?> configs, boolean isKey);\n\t// Deserialize a record value from a byte array into a value or object.\n\tUUID deserialize(String topic, byte[] data);\n}", "des": "We are converting the byte array to String before deserializing to UUID. String encoding defaults to UTF8 and can be customized by setting the property key.deserializer.encoding, value.deserializer.encoding or deserializer.encoding. The first two take precedence over the last."}
{"index": 1763, "repo": "kafka-clients-3.5.0", "code": "Class UUIDSerializer {\n\t// Configure this class.\n\tvoid configure(Map<String,?> configs, boolean isKey);\n\t// Convert data into a byte array.\n\tbyte[] serialize(String topic, UUID data);\n}", "des": "We are converting UUID to String before serializing. String encoding defaults to UTF8 and can be customized by setting the property key.deserializer.encoding, value.deserializer.encoding or deserializer.encoding. The first two take precedence over the last."}
{"index": 1764, "repo": "kafka-clients-3.5.0", "code": "Class Value {\n\t// Measure this quantity and return the result as a double\n\tdouble measure(MetricConfig config, long now);\n\t// Record the given value\n\tvoid record(MetricConfig config, double value, long timeMs);\n}", "des": "An instantaneous value."}
{"index": 1765, "repo": "nifi-web-api-0.5.0", "code": "Enum Availability {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Availability valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Availability[] values();\n}", "des": "Where a given controller service or reporting task should run."}
{"index": 1766, "repo": "nifi-web-api-0.5.0", "code": "Interface StandardNiFiWebConfigurationContext.ComponentFacade {\n\t// Gets the component details using the specified request context.\n\tComponentDetails getComponentDetails(NiFiWebRequestContext requestContext);\n\t// Sets the annotation data using the specified request context.\n\tComponentDetails setAnnotationData(NiFiWebConfigurationRequestContext requestContext, String annotationData);\n}", "des": "Facade over accessing different types of NiFi components."}
{"index": 1767, "repo": "hadoop-hdfs-3.3.6", "code": "Enum AclEntryStatusFormat {\n\tint getLength();\n\tstatic int[] toInt(List<org.apache.hadoop.fs.permission.AclEntry> aclEntries);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AclEntryStatusFormat valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AclEntryStatusFormat[] values();\n}", "des": "Class to pack an AclEntry into an integer. An ACL entry is represented by a 32-bit integer in Big Endian format. Note: this format is used both in-memory and on-disk. Changes will be incompatible."}
{"index": 1768, "repo": "hadoop-hdfs-3.3.6", "code": "Interface AuditLogger {\n\t// Called during initialization of the logger.\n\tvoid initialize(org.apache.hadoop.conf.Configuration conf);\n\t// Called to log an audit event.\n\tvoid logAuditEvent(boolean succeeded, String userName, InetAddress addr, String cmd, String src, String dst, org.apache.hadoop.fs.FileStatus stat);\n}", "des": "Interface defining an audit logger."}
{"index": 1769, "repo": "hadoop-hdfs-3.3.6", "code": "Class BlockAliasMap<T extends BlockAlias> {\n\tabstract void close();\n\t// Returns a reader to the alias map.\n\tabstract BlockAliasMap.Reader<T> getReader(BlockAliasMap.Reader.Options opts, String blockPoolID);\n\t// Returns the writer for the alias map.\n\tabstract BlockAliasMap.Writer<T> getWriter(BlockAliasMap.Writer.Options opts, String blockPoolID);\n\t// Refresh the alias map.\n\tabstract void refresh();\n}", "des": "An abstract class used to read and write block maps for provided blocks."}
{"index": 1770, "repo": "hadoop-hdfs-3.3.6", "code": "Class CancelCommand {\n\t// Executes the Client Calls.\n\tvoid execute(org.apache.commons.cli.CommandLine cmd);\n\t// Gets extended help for this command.\n\tvoid printHelp();\n}", "des": "Cancels a running plan."}
{"index": 1771, "repo": "hadoop-hdfs-3.3.6", "code": "Interface ClusterConnector {\n\t// Returns info about the connector.\n\tString getConnectorInfo();\n\t// getNodes function returns a list of DiskBalancerDataNodes.\n\tList<DiskBalancerDataNode> getNodes();\n}", "des": "ClusterConnector interface hides all specifics about how we communicate to the HDFS cluster. This interface returns data in classes that diskbalancer understands."}
{"index": 1772, "repo": "hadoop-hdfs-3.3.6", "code": "Enum Content {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Content valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Content[] values();\n}", "des": "The content types such as file, directory and symlink to be computed."}
{"index": 1773, "repo": "hadoop-hdfs-3.3.6", "code": "Enum CorruptReplicasMap.Reason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CorruptReplicasMap.Reason valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CorruptReplicasMap.Reason[] values();\n}", "des": "The corruption reason code"}
{"index": 1774, "repo": "hadoop-hdfs-3.3.6", "code": "Enum DataNodeLayoutVersion.Feature {\n\tLayoutVersion.FeatureInfo getInfo();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DataNodeLayoutVersion.Feature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DataNodeLayoutVersion.Feature[] values();\n}", "des": "Enums for features that change the layout version. To add a new layout version: Define a new enum constant with a short enum name, the new layout version and description of the added feature. When adding a layout version with an ancestor that is not same as its immediate predecessor, use the constructor where a specific ancestor can be passed."}
{"index": 1775, "repo": "hadoop-hdfs-3.3.6", "code": "Class DefaultINodeAttributesProvider {\n\torg.apache.hadoop.hdfs.server.namenode.INodeAttributes getAttributes(String[] pathElements, org.apache.hadoop.hdfs.server.namenode.INodeAttributes inode);\n\t// Initialize the provider.\n\tvoid start();\n\t// Shutdown the provider.\n\tvoid stop();\n}", "des": "A default implementation of the INodeAttributesProvider"}
{"index": 1776, "repo": "hadoop-hdfs-3.3.6", "code": "Class DiskBalancer.VolumePair {\n\tboolean equals(Object o);\n\t// Gets desitnation volume base path.\n\tString getDestVolBasePath();\n\t// Gets destination volume UUID.\n\tString getDestVolUuid();\n\t// Gets source volume base path.\n\tString getSourceVolBasePath();\n\t// Gets source volume UUID.\n\tString getSourceVolUuid();\n}", "des": "Holds source and dest volumes UUIDs and their BasePaths that disk balancer will be operating against."}
{"index": 1777, "repo": "hadoop-hdfs-3.3.6", "code": "Enum DiskBalancerException.Result {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DiskBalancerException.Result valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DiskBalancerException.Result[] values();\n}", "des": "Results returned by the RPC layer of DiskBalancer."}
{"index": 1778, "repo": "hadoop-hdfs-3.3.6", "code": "Class ExecuteCommand {\n\t// Executes the Client Calls.\n\tvoid execute(org.apache.commons.cli.CommandLine cmd);\n\t// Gets extended help for this command.\n\tvoid printHelp();\n}", "des": "executes a given plan."}
{"index": 1779, "repo": "hadoop-hdfs-3.3.6", "code": "Enum ExitStatus {\n\tint getExitCode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExitStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExitStatus[] values();\n}", "des": "Exit status - The values associated with each exit status is directly mapped to the process's exit code in command line."}
{"index": 1780, "repo": "hadoop-hdfs-3.3.6", "code": "Class FileDiff {\n\t// Compare diffs with snapshot ID.\n\tint compareTo(Integer that);\n\tvoid destroyAndCollectSnapshotBlocks(INode.BlocksMapUpdateInfo collectedBlocks);\n\torg.apache.hadoop.hdfs.server.blockmanagement.BlockInfo[] getBlocks();\n\tlong getFileSize();\n\tint getSnapshotId();\n\t// Copy block references into the snapshot up to the current fileSize.\n\tvoid setBlocks(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo[] blocks);\n}", "des": "The difference of an INodeFile between two snapshots."}
{"index": 1781, "repo": "hadoop-hdfs-3.3.6", "code": "Enum FileIoProvider.OPERATION {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileIoProvider.OPERATION valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileIoProvider.OPERATION[] values();\n}", "des": "Lists the types of file system operations. Passed to the IO hooks so implementations can choose behavior based on specific operations."}
{"index": 1782, "repo": "hadoop-hdfs-3.3.6", "code": "Class FsDatasetSpi.Factory<D extends org.apache.hadoop.hdfs.server.datanode.fsdataset.FsDatasetSpi<?>> {\n\tstatic FsDatasetSpi.Factory<?> getFactory(org.apache.hadoop.conf.Configuration conf);\n\t// Does the factory create simulated objects?\n\tboolean isSimulated();\n\t// Create a new object.\n\tabstract D newInstance(org.apache.hadoop.hdfs.server.datanode.DataNode datanode, org.apache.hadoop.hdfs.server.datanode.DataStorage storage, org.apache.hadoop.conf.Configuration conf);\n}", "des": "A factory for creating FsDatasetSpi objects."}
{"index": 1783, "repo": "hadoop-hdfs-3.3.6", "code": "Class FsDatasetSpi.FsVolumeReferences {\n\tvoid close();\n\t// Get the volume for a given index.\n\tFsVolumeSpi get(int index);\n\t// Get the reference for a given index.\n\tFsVolumeReference getReference(int index);\n\tIterator<FsVolumeSpi> iterator();\n\t// Get the number of volumes.\n\tint size();\n}", "des": "It behaviors as an unmodifiable list of FsVolume. Individual FsVolume can be obtained by using get(int). This also holds the reference counts for these volumes. It releases all the reference counts in close()."}
{"index": 1784, "repo": "hadoop-hdfs-3.3.6", "code": "Class FSEditLogLoader.PositionTrackingInputStream {\n\t// Disable limit.\n\tvoid clearLimit();\n\tlong getPos();\n\tvoid mark(int limit);\n\tint read();\n\tint read(byte[] data);\n\tint read(byte[] data, int offset, int length);\n\tvoid reset();\n\t// Set a limit.\n\tvoid setLimit(long limit);\n\tlong skip(long amt);\n}", "des": "Stream wrapper that keeps track of the current stream position. This stream also allows us to set a limit on how many bytes we can read without getting an exception."}
{"index": 1785, "repo": "hadoop-hdfs-3.3.6", "code": "Class FSImageFormatPBSnapshot.Loader {\n\t// The sequence of the ref node in refList must be strictly the same with the sequence in fsimage\n\tvoid loadINodeReferenceSection(InputStream in);\n\t// Load the snapshot diff section from fsimage.\n\tvoid loadSnapshotDiffSection(InputStream in);\n\t// Load the snapshots section from fsimage.\n\tvoid loadSnapshotSection(InputStream in);\n}", "des": "Loading snapshot related information from protobuf based FSImage"}
{"index": 1786, "repo": "hadoop-hdfs-3.3.6", "code": "Enum FSImageFormatProtobuf.SectionName {\n\tstatic FSImageFormatProtobuf.SectionName fromString(String name);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FSImageFormatProtobuf.SectionName valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FSImageFormatProtobuf.SectionName[] values();\n}", "des": "Supported section name. The order of the enum determines the order of loading."}
{"index": 1787, "repo": "hadoop-hdfs-3.3.6", "code": "Enum FsVolumeImpl.BlockDirFilter {\n\tboolean accept(File dir, String name);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FsVolumeImpl.BlockDirFilter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FsVolumeImpl.BlockDirFilter[] values();\n}", "des": "Filter for block file names stored on the file system volumes."}
{"index": 1788, "repo": "hadoop-hdfs-3.3.6", "code": "Interface FsVolumeReference {\n\t// Decrease the reference count of the volume.\n\tvoid close();\n\t// Returns the underlying volume object.\n\tFsVolumeSpi getVolume();\n}", "des": "This holds volume reference count as AutoClosable resource. It increases the reference count by one in the constructor, and decreases the reference count by one in close()."}
{"index": 1789, "repo": "hadoop-hdfs-3.3.6", "code": "Class FsVolumeSpi.ScanInfo {\n\tint compareTo(FsVolumeSpi.ScanInfo b);\n\tboolean equals(Object o);\n\t// Returns the block data file.\n\tFile getBlockFile();\n\t// Returns the block ID.\n\tlong getBlockId();\n\t// Return the length of the data block.\n\tlong getBlockLength();\n\tFileRegion getFileRegion();\n\tlong getGenStamp();\n\t// Returns the block meta data file or null if there isn't one.\n\tFile getMetaFile();\n\t// Returns the volume that contains the block that this object describes.\n\tFsVolumeSpi getVolume();\n}", "des": "Tracks the files and other information related to a block on the disk Missing file is indicated by setting the corresponding member to null. Because millions of these structures may be created, we try to save memory here. So instead of storing full paths, we store path suffixes. The block file, if it exists, will have a path like this: / So we don't need to store the volume path, since we already know what the volume is. The metadata file, if it exists, will have a path like this: /_.meta So if we have a block file, there isn't any need to store the block path again. The accessor functions take care of these manipulations."}
{"index": 1790, "repo": "hadoop-hdfs-3.3.6", "code": "Class GreedyPlanner {\n\t// Computes Steps to make a DiskBalancerVolumeSet Balanced.\n\tvoid balanceVolumeSet(DiskBalancerDataNode node, DiskBalancerVolumeSet vSet, NodePlan plan);\n\t// Computes a node plan for the given node.\n\tNodePlan plan(DiskBalancerDataNode node);\n}", "des": "Greedy Planner is a simple planner that computes the largest possible move at any point of time given a volumeSet."}
{"index": 1791, "repo": "hadoop-hdfs-3.3.6", "code": "Class HdfsDtFetcher {\n\t// Returns Token object via FileSystem, null if bad argument.\n\torg.apache.hadoop.security.token.Token<?> addDelegationTokens(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.security.Credentials creds, String renewer, String url);\n\t// Returns the service name for HDFS, which is also a valid URL prefix.\n\torg.apache.hadoop.io.Text getServiceName();\n\tboolean isTokenRequired();\n}", "des": "DtFetcher is an interface which permits the abstraction and separation of delegation token fetch implementaions across different packages and compilation units. Resolution of fetcher impl will be done at runtime."}
{"index": 1792, "repo": "hadoop-hdfs-3.3.6", "code": "Enum HdfsServerConstants.BlockUCState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HdfsServerConstants.BlockUCState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HdfsServerConstants.BlockUCState[] values();\n}", "des": "States, which a block can go through while it is under construction."}
{"index": 1793, "repo": "hadoop-hdfs-3.3.6", "code": "Enum HdfsServerConstants.NamenodeRole {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HdfsServerConstants.NamenodeRole valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HdfsServerConstants.NamenodeRole[] values();\n}", "des": "Defines the NameNode role."}
{"index": 1794, "repo": "hadoop-hdfs-3.3.6", "code": "Enum HdfsServerConstants.NodeType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HdfsServerConstants.NodeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HdfsServerConstants.NodeType[] values();\n}", "des": "Type of the node"}
{"index": 1795, "repo": "hadoop-hdfs-3.3.6", "code": "Enum HdfsServerConstants.RollingUpgradeStartupOption {\n\tstatic String getAllOptionString();\n\tString getOptionString();\n\tboolean matches(HdfsServerConstants.StartupOption option);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HdfsServerConstants.RollingUpgradeStartupOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HdfsServerConstants.RollingUpgradeStartupOption[] values();\n}", "des": "Startup options for rolling upgrade."}
{"index": 1796, "repo": "hadoop-hdfs-3.3.6", "code": "Class HelpCommand {\n\t// Executes the Client Calls.\n\tvoid execute(org.apache.commons.cli.CommandLine cmd);\n\t// Gets extended help for this command.\n\tvoid printHelp();\n}", "des": "Help Command prints out detailed help about each command."}
{"index": 1797, "repo": "hadoop-hdfs-3.3.6", "code": "Class INode.BlocksMapUpdateInfo {\n\t// Add a to-be-deleted block into the toDeleteList\n\tvoid addDeleteBlock(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo toDelete);\n\tvoid addUpdateReplicationFactor(org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo block, short targetRepl);\n\t// Clear toDeleteList\n\tvoid clear();\n\tList<org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo> getToDeleteList();\n\tList<INode.BlocksMapUpdateInfo.UpdatedReplicationInfo> toUpdateReplicationInfo();\n}", "des": "Information used for updating the blocksMap when deleting files."}
{"index": 1798, "repo": "hadoop-hdfs-3.3.6", "code": "Class INodeMap {\n\t// Clear the map\n\tvoid clear();\n\t// Get the INode with the given id from the map.\n\torg.apache.hadoop.hdfs.server.namenode.INode get(long id);\n\tIterator<org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields> getMapIterator();\n\t// Add an INode into the INode map.\n\tvoid put(org.apache.hadoop.hdfs.server.namenode.INode inode);\n\t// Remove a INode from the map.\n\tvoid remove(org.apache.hadoop.hdfs.server.namenode.INode inode);\n\tint size();\n}", "des": "Storing all the INodes and maintaining the mapping between INode ID and INode."}
{"index": 1799, "repo": "hadoop-hdfs-3.3.6", "code": "Class INodeReference.WithCount {\n\t// Increment and then return the reference count.\n\tvoid addReference(INodeReference ref);\n\t// Return the last WithName reference if there is any, null otherwise.\n\tINodeReference.WithName getLastWithName();\n\tINodeReference getParentRef(int snapshotId);\n\tint getReferenceCount();\n\t// Decrement and then return the reference count.\n\tvoid removeReference(INodeReference ref);\n}", "des": "An anonymous reference with reference count."}
{"index": 1800, "repo": "hadoop-hdfs-3.3.6", "code": "Interface JournalNodeMXBean {\n\t// Get list of the clusters of JournalNode's journals as one JournalNode may support multiple clusters.\n\tdefault List<String> getClusterIds();\n\t// Get host and port of JournalNode.\n\tdefault String getHostAndPort();\n\t// Get status information (e.g., whether formatted) of JournalNode's journals.\n\tString getJournalsStatus();\n\t// Gets the version of Hadoop.\n\tdefault String getVersion();\n}", "des": "This is the JMX management interface for JournalNode information"}
{"index": 1801, "repo": "hadoop-hdfs-3.3.6", "code": "Class JsonNodeConnector {\n\t// Returns info about the connector.\n\tString getConnectorInfo();\n\t// getNodes function connects to a cluster definition file and returns nodes defined in that file.\n\tList<DiskBalancerDataNode> getNodes();\n}", "des": "A connector that understands JSON data cluster models."}
{"index": 1802, "repo": "hadoop-hdfs-3.3.6", "code": "Enum LayoutVersion.Feature {\n\tLayoutVersion.FeatureInfo getInfo();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LayoutVersion.Feature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LayoutVersion.Feature[] values();\n}", "des": "Enums for features that change the layout version before rolling upgrade is supported. To add a new layout version: Define a new enum constant with a short enum name, the new layout version and description of the added feature. When adding a layout version with an ancestor that is not same as its immediate predecessor, use the constructor where a specific ancestor can be passed."}
{"index": 1803, "repo": "hadoop-hdfs-3.3.6", "code": "Class LayoutVersion.FeatureInfo {\n\t// Accessor method for feature ancestor layout version\n\tint getAncestorLayoutVersion();\n\t// Accessor method for feature description\n\tString getDescription();\n\t// Accessor method for feature layout version\n\tint getLayoutVersion();\n\t// Accessor method for feature minimum compatible layout version.\n\tint getMinimumCompatibleLayoutVersion();\n\tLayoutVersion.LayoutFeature[] getSpecialFeatures();\n\tboolean isReservedForOldRelease();\n}", "des": "Feature information."}
{"index": 1804, "repo": "hadoop-hdfs-3.3.6", "code": "Class LevelDBFileRegionAliasMap {\n\tvoid close();\n\torg.apache.hadoop.conf.Configuration getConf();\n\t// Returns a reader to the alias map.\n\tBlockAliasMap.Reader<FileRegion> getReader(BlockAliasMap.Reader.Options opts, String blockPoolID);\n\t// Returns the writer for the alias map.\n\tBlockAliasMap.Writer<FileRegion> getWriter(BlockAliasMap.Writer.Options opts, String blockPoolID);\n\t// Refresh the alias map.\n\tvoid refresh();\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "A LevelDB based implementation of BlockAliasMap."}
{"index": 1805, "repo": "hadoop-hdfs-3.3.6", "code": "Class MetricsLoggerTask {\n\t// Make the metrics logger async and add all pre-existing appenders to the async appender.\n\tstatic void makeMetricsLoggerAsync(org.apache.commons.logging.Log metricsLog);\n\t// Write metrics to the metrics appender when invoked.\n\tvoid run();\n}", "des": "MetricsLoggerTask can be used as utility to dump metrics to log."}
{"index": 1806, "repo": "hadoop-hdfs-3.3.6", "code": "Class MovedBlocks<L> {\n\t// remove old blocks\n\tvoid cleanup();\n\tboolean contains(org.apache.hadoop.hdfs.protocol.Block block);\n\t// add a block thus marking a block to be moved\n\tvoid put(MovedBlocks.Locations<L> block);\n}", "des": "This window makes sure to keep blocks that have been moved within a fixed time interval (default is 1.5 hour). Old window has blocks that are older; Current window has blocks that are more recent; Cleanup method triggers the check if blocks in the old window are more than the fixed time interval. If yes, purge the old window and then move blocks in current window to old window."}
{"index": 1807, "repo": "hadoop-hdfs-3.3.6", "code": "Class MovedBlocks.Locations<L> {\n\t// add a location\n\tvoid addLocation(L loc);\n\t// clean block locations\n\tvoid clearLocations();\n\torg.apache.hadoop.hdfs.protocol.Block getBlock();\n\tList<L> getLocations();\n\tlong getNumBytes();\n\tboolean isLocatedOn(L loc);\n}", "des": "A class for keeping track of a block and its locations"}
{"index": 1808, "repo": "hadoop-hdfs-3.3.6", "code": "Enum NameNode.OperationCategory {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NameNode.OperationCategory valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NameNode.OperationCategory[] values();\n}", "des": "Categories of operations supported by the namenode."}
{"index": 1809, "repo": "hadoop-hdfs-3.3.6", "code": "Enum NameNodeLayoutVersion.Feature {\n\tLayoutVersion.FeatureInfo getInfo();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NameNodeLayoutVersion.Feature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NameNodeLayoutVersion.Feature[] values();\n}", "des": "Enums for features that change the layout version. To add a new layout version: Define a new enum constant with a short enum name, the new layout version and description of the added feature. When adding a layout version with an ancestor that is not same as its immediate predecessor, use the constructor where a specific ancestor can be passed. Specify a minimum compatible layout version. The minimum compatible layout version is the earliest prior version to which a downgrade is possible after initiating rolling upgrade. If the feature cannot satisfy compatibility with any prior version, then set its minimum compatible lqyout version to itself to indicate that downgrade is impossible. Satisfying compatibility might require adding logic to the new feature to reject operations or handle them differently while rolling upgrade is in progress. In general, it's possible to satisfy compatiblity for downgrade if the new feature just involves adding new edit log ops. Deeper structural changes, such as changing the way we place files in the metadata directories, might be incompatible. Feature implementations should strive for compatibility, because it's in the best interest of our users to support downgrade."}
{"index": 1810, "repo": "hadoop-hdfs-3.3.6", "code": "Enum NNStorage.NameNodeDirType {\n\torg.apache.hadoop.hdfs.server.common.Storage.StorageDirType getStorageDirType();\n\tboolean isOfType(org.apache.hadoop.hdfs.server.common.Storage.StorageDirType type);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NNStorage.NameNodeDirType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NNStorage.NameNodeDirType[] values();\n}", "des": "Implementation of StorageDirType specific to namenode storage A Storage directory could be of type IMAGE which stores only fsimage, or of type EDITS which stores edits or of type IMAGE_AND_EDITS which stores both fsimage and edits."}
{"index": 1811, "repo": "hadoop-hdfs-3.3.6", "code": "Enum NNStorage.NameNodeFile {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NNStorage.NameNodeFile valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NNStorage.NameNodeFile[] values();\n}", "des": "The filenames used for storing the images."}
{"index": 1812, "repo": "hadoop-hdfs-3.3.6", "code": "Class PlanCommand {\n\t// Runs the plan command.\n\tvoid execute(org.apache.commons.cli.CommandLine cmd);\n\t// Gets extended help for this command.\n\tvoid printHelp();\n}", "des": "Class that implements Plan Command."}
{"index": 1813, "repo": "hadoop-hdfs-3.3.6", "code": "Class QueryCommand {\n\t// Executes the Client Calls.\n\tvoid execute(org.apache.commons.cli.CommandLine cmd);\n\t// Gets extended help for this command.\n\tvoid printHelp();\n}", "des": "Gets the current status of disk balancer command."}
{"index": 1814, "repo": "hadoop-hdfs-3.3.6", "code": "Enum Quota {\n\t// Is quota violated? The quota is violated if quota is set and usage > quota.\n\tstatic boolean isViolated(long quota, long usage);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Quota valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Quota[] values();\n}", "des": "Quota types."}
{"index": 1815, "repo": "hadoop-hdfs-3.3.6", "code": "Class ReplicaBeingWritten {\n\tboolean equals(Object o);\n\t// Get the replica state\n\tHdfsServerConstants.ReplicaState getState();\n\t// Get the number of bytes that are visible to readers\n\tlong getVisibleLength();\n}", "des": "This class represents replicas being written. Those are the replicas that are created in a pipeline initiated by a dfs client."}
{"index": 1816, "repo": "hadoop-hdfs-3.3.6", "code": "Class ReportCommand {\n\t// Executes the Client Calls.\n\tvoid execute(org.apache.commons.cli.CommandLine cmd);\n\t// Prints the help message.\n\tvoid printHelp();\n}", "des": "Executes the report command. This command will report volume information for a specific DataNode or top X DataNode(s) benefiting from running DiskBalancer. This is done by reading the cluster info, sorting the DiskbalancerNodes by their NodeDataDensity and printing out the info."}
{"index": 1817, "repo": "hadoop-hdfs-3.3.6", "code": "Interface SnapshotStatsMXBean {\n\t// Return the list of snapshots\n\tSnapshotInfo.Bean[] getSnapshots();\n\t// Return the list of snapshottable directories\n\torg.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.Bean[] getSnapshottableDirectories();\n}", "des": "This is an interface used to retrieve statistic information related to snapshots"}
{"index": 1818, "repo": "hadoop-hdfs-3.3.6", "code": "Class VolumeScanner {\n\t// Disallow the scanner from scanning the given block pool.\n\tvoid disableBlockPoolId(String bpid);\n\t// Allow the scanner to scan the given block pool.\n\tvoid enableBlockPoolId(String bpid);\n\tvoid markSuspectBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock block);\n\tvoid printStats(StringBuilder p);\n\tvoid run();\n\t// Shut down this scanner.\n\tvoid shutdown();\n}", "des": "VolumeScanner scans a single volume. Each VolumeScanner has its own thread."}
{"index": 1819, "repo": "hadoop-hdfs-3.3.6", "code": "Class WebImageViewer {\n\tvoid close();\n\t// Get the listening port.\n\tint getPort();\n\t// Start WebImageViewer.\n\tvoid initServer(String fsimage);\n\t// Start WebImageViewer and wait until the thread is interrupted.\n\tvoid start(String fsimage);\n}", "des": "WebImageViewer loads a fsimage and exposes read-only WebHDFS API for its namespace."}
{"index": 1820, "repo": "hadoop-hdfs-3.3.6", "code": "Enum XAttrFormat {\n\tint getLength();\n\tstatic String getName(int record);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic XAttrFormat valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic XAttrFormat[] values();\n}", "des": "Class to pack XAttrs into byte[]. Note: this format is used both in-memory and on-disk. Changes will be incompatible."}
{"index": 1821, "repo": "hadoop-hdfs-3.3.6", "code": "Class XMLUtils.Stanza {\n\t// Add an entry to a stanza.\n\tvoid addChild(String name, XMLUtils.Stanza child);\n\t// Pull an entry from a stanza.\n\tList<XMLUtils.Stanza> getChildren(String name);\n\tString getValue();\n\t// Pull a string entry from a stanza.\n\tString getValue(String name);\n\t// Pull a string entry from a stanza, or null.\n\tString getValueOrNull(String name);\n\t// Discover if a stanza has a given entry.\n\tboolean hasChildren(String name);\n\tvoid setValue(String value);\n}", "des": "Represents a bag of key-value pairs encountered during parsing an XML file."}
{"index": 1822, "repo": "lucene-analyzers-kuromoji-8.11.2", "code": "Enum BinaryDictionary.ResourceScheme {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BinaryDictionary.ResourceScheme valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BinaryDictionary.ResourceScheme[] values();\n}", "des": "Used to specify where (dictionary) resources get loaded from."}
{"index": 1823, "repo": "lucene-analyzers-kuromoji-8.11.2", "code": "Class CSVUtil {\n\t// Parse CSV line\n\tstatic String[] parse(String line);\n\t// Quote and escape input value for CSV\n\tstatic String quoteEscape(String original);\n}", "des": "Utility class for parsing CSV text"}
{"index": 1824, "repo": "lucene-analyzers-kuromoji-8.11.2", "code": "Enum DictionaryBuilder.DictionaryFormat {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DictionaryBuilder.DictionaryFormat valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DictionaryBuilder.DictionaryFormat[] values();\n}", "des": "Format of the dictionary."}
{"index": 1825, "repo": "lucene-analyzers-kuromoji-8.11.2", "code": "Enum JapaneseTokenizer.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JapaneseTokenizer.Mode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JapaneseTokenizer.Mode[] values();\n}", "des": "Tokenization mode: this determines how the tokenizer handles compound and unknown words."}
{"index": 1826, "repo": "lucene-analyzers-kuromoji-8.11.2", "code": "Enum JapaneseTokenizer.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JapaneseTokenizer.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JapaneseTokenizer.Type[] values();\n}", "des": "Token type reflecting the original source of this token"}
{"index": 1827, "repo": "lucene-analyzers-kuromoji-8.11.2", "code": "Class ToStringUtil {\n\t// Get the english form of inflected form\n\tstatic String getInflectedFormTranslation(String s);\n\t// Get the english form of inflection type\n\tstatic String getInflectionTypeTranslation(String s);\n\t// Get the english form of a POS tag\n\tstatic String getPOSTranslation(String s);\n\t// Romanize katakana with modified hepburn\n\tstatic void getRomanization(Appendable builder, CharSequence s);\n\t// Romanize katakana with modified hepburn\n\tstatic String getRomanization(String s);\n}", "des": "Utility class for english translations of morphological data, used only for debugging."}
{"index": 1828, "repo": "lucene-analyzers-kuromoji-8.11.2", "code": "Class UnknownDictionary {\n\tCharacterDefinition getCharacterDefinition();\n\t// Get inflection form of tokens\n\tString getInflectionForm(int wordId);\n\t// Get inflection type of tokens\n\tString getInflectionType(int wordId);\n\tstatic UnknownDictionary getInstance();\n\t// Get reading of tokens\n\tString getReading(int wordId, char[] surface, int off, int len);\n\tint lookup(char[] text, int offset, int len);\n}", "des": "Dictionary for unknown-word handling."}
{"index": 1829, "repo": "nifi-framework-api-1.22.0", "code": "Interface ComponentAuthorizable {\n\t// The identifier of the underlying component.\n\tString getIdentifier();\n\t// The identifier of the ProcessGroup this component belongs to.\n\tString getProcessGroupIdentifier();\n}", "des": "Not all Authorizables are components, however all ComponentAuthorizable's are components. This ensures that they will have an identifier and a ProcessGroup identifier."}
{"index": 1830, "repo": "nifi-framework-api-1.22.0", "code": "Interface ContentRepositoryContext {\n\t// Provides a EventReporter for ContentRepository that is used to emit bulletins.\n\tEventReporter getEventReporter();\n\t// Provides a ResourceClaimManager for ContentRepository that is to be used for interacting with ContentClaims.\n\tResourceClaimManager getResourceClaimManager();\n}", "des": "Initialization context for ContentRepository."}
{"index": 1831, "repo": "nifi-framework-api-1.22.0", "code": "Enum DropFlowFileState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DropFlowFileState valueOf(String name);\n\tstatic DropFlowFileState valueOfDescription(String description);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DropFlowFileState[] values();\n}", "des": "Represents the state that a Drop FlowFile request is in"}
{"index": 1832, "repo": "nifi-framework-api-1.22.0", "code": "Enum ListFlowFileState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ListFlowFileState valueOf(String name);\n\tstatic ListFlowFileState valueOfDescription(String description);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ListFlowFileState[] values();\n}", "des": "Represents the state that a List FlowFile Request is in"}
{"index": 1833, "repo": "nifi-framework-api-1.22.0", "code": "Interface NiFiWebConfigurationRequestContext {\n\t// The revision to include in the request.\n\tRevision getRevision();\n\t// Returns whether the node disconnection is acknowledged.\n\tdefault boolean isDisconnectionAcknowledged();\n}", "des": "Contextual details required to make a configuration request from a UI extension."}
{"index": 1834, "repo": "nifi-framework-api-1.22.0", "code": "Interface NiFiWebRequestContext {\n\tUiExtensionType getExtensionType();\n\t// The id of the component.\n\tString getId();\n\t// The request protocol scheme (http or https).\n\tString getScheme();\n}", "des": "Contextual details required to make a request from a UI extension."}
{"index": 1835, "repo": "nifi-framework-api-1.22.0", "code": "Interface NonComponentConfigurationContext {\n\tString getIdentifier();\n\t// Returns all properties the configuration context contains regardless of whether a value has been set for them or not.\n\tMap<String,String> getProperties();\n\t// Returns the value of the provided property.\n\tString getProperty(String property);\n}", "des": "Shared interface for various feature-specific configuration contexts which allows common code to handle property retrieval without awareness of the specific implementation."}
{"index": 1836, "repo": "nifi-framework-api-1.22.0", "code": "Enum PollStrategy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PollStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PollStrategy[] values();\n}", "des": "Represents a strategy that how to poll the queue."}
{"index": 1837, "repo": "nifi-framework-api-1.22.0", "code": "Enum RequestAction {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RequestAction valueOf(String name);\n\tstatic RequestAction valueOfValue(String action);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RequestAction[] values();\n}", "des": "Actions a user/entity can take on a resource."}
{"index": 1838, "repo": "nifi-framework-api-1.22.0", "code": "Interface Resource {\n\t// The identifier for this resource.\n\tString getIdentifier();\n\t// The name of this resource.\n\tString getName();\n\t// The description of this resource that may be safely used in messages to the client.\n\tString getSafeDescription();\n}", "des": "Resource in an authorization request."}
{"index": 1839, "repo": "nifi-framework-api-1.22.0", "code": "Interface ResourceClaim {\n\t// Provides the natural ordering for ResourceClaim objects.\n\tdefault int compareTo(ResourceClaim other);\n\tString getContainer();\n\tString getId();\n\tString getSection();\n\t// Indicates whether or not the Resource Claim is in use.\n\tboolean isInUse();\n\tboolean isLossTolerant();\n\tboolean isWritable();\n}", "des": ""}
{"index": 1840, "repo": "nifi-framework-api-1.22.0", "code": "Enum SortColumn {\n\tint compare(FlowFileSummary o1, FlowFileSummary o2);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SortColumn valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SortColumn[] values();\n}", "des": "Specifies which column to sort on when performing a Listing of FlowFiles via FlowFileQueue#listFlowFiles(String, SortColumn, SortDirection)"}
{"index": 1841, "repo": "nifi-framework-api-1.22.0", "code": "Enum SortDirection {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SortDirection valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SortDirection[] values();\n}", "des": "Specifies the order in which FlowFiles should be sorted when performing a listing of FlowFiles via the FlowFileQueue#listFlowFiles(String, SortColumn, SortDirection) method"}
{"index": 1842, "repo": "nifi-framework-api-1.22.0", "code": "Enum UiExtensionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic UiExtensionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic UiExtensionType[] values();\n}", "des": "Types of UI extensions. Since a UI extension could support multiple types of custom UIs it will need to include the type so the framework can appropriate understand and process the request (recording actions in the audit database, replicating a request throughout the cluster to the appropriate endpoints, etc)."}
{"index": 1843, "repo": "nifi-framework-api-1.22.0", "code": "Class User.Builder {\n\tUser build();\n\t// Sets the identifier of the builder.\n\tUser.Builder identifier(String identifier);\n\t// Sets the identifier of the builder with a UUID generated from the specified seed string.\n\tUser.Builder identifierGenerateFromSeed(String seed);\n\t// Sets the identifier of the builder to a random UUID.\n\tUser.Builder identifierGenerateRandom();\n\t// Sets the identity of the builder.\n\tUser.Builder identity(String identity);\n}", "des": "Builder for Users."}
{"index": 1844, "repo": "nifi-framework-api-1.22.0", "code": "Interface UserAndGroups {\n\t// Retrieves the groups for the user, or null if the user is unknown or has no groups.\n\tSet<Group> getGroups();\n\t// Retrieves the user, or null if the user is unknown\n\tUser getUser();\n}", "des": "A holder object to provide atomic access to a user and their groups."}
{"index": 1845, "repo": "nifi-framework-api-1.22.0", "code": "Enum UserContextKeys {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic UserContextKeys valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic UserContextKeys[] values();\n}", "des": "Constants for keys that can be passed in the AuthorizationRequest user context Map."}
{"index": 1846, "repo": "nifi-framework-api-1.22.0", "code": "Interface UserGroupProviderInitializationContext {\n\t// The identifier of the UserGroupProvider.\n\tString getIdentifier();\n\t// The lookup for accessing other configured UserGroupProviders.\n\tUserGroupProviderLookup getUserGroupProviderLookup();\n}", "des": "Initialization content for UserGroupProviders."}
{"index": 1847, "repo": "nifi-framework-api-1.22.0", "code": "Interface UsersAndAccessPolicies {\n\t// Retrieves the set of access policies for a given resource and action.\n\tAccessPolicy getAccessPolicy(String resourceIdentifier, RequestAction action);\n\t// Retrieves the groups for a given user identity.\n\tSet<Group> getGroups(String userIdentity);\n\t// Retrieves a user by an identity string.\n\tUser getUser(String identity);\n}", "des": "A holder object to provide atomic access to policies for a given resource and users by identity. Implementations must ensure consistent access to the data backing this instance."}
{"index": 1848, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum AbstractMapOperator.Counter {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AbstractMapOperator.Counter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AbstractMapOperator.Counter[] values();\n}", "des": "Counter."}
{"index": 1849, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface AcidOutputFormat<K extends org.apache.hadoop.io.WritableComparable,V> {\n\t// Create a raw writer for ACID events.\n\tFileSinkOperator.RecordWriter getRawRecordWriter(org.apache.hadoop.fs.Path path, AcidOutputFormat.Options options);\n\t// Create a RecordUpdater for inserting, updating, or deleting records.\n\tRecordUpdater getRecordUpdater(org.apache.hadoop.fs.Path path, AcidOutputFormat.Options options);\n}", "des": "An extension for OutputFormats that want to implement ACID transactions."}
{"index": 1850, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class AcidUtils.OrcAcidVersion {\n\tstatic org.apache.hadoop.fs.Path getVersionFilePath(org.apache.hadoop.fs.Path deltaOrBase);\n\t// Inlucde current acid version in file footer.\n\tstatic void setAcidVersionInDataFile(Writer writer);\n\t// This creates a version file in deltaOrBaseDir\n\tstatic void writeVersionFile(org.apache.hadoop.fs.Path deltaOrBaseDir, org.apache.hadoop.fs.FileSystem fs);\n}", "des": "Logic related to versioning acid data format. An ACID_FORMAT file is written to each base/delta/delete_delta dir written by a full acid write or compaction. This is the primary mechanism for versioning acid data. Each individual ORC file written stores the current version as a user property in ORC footer. All data files produced by Acid write should have this (starting with Hive 3.0), including those written by compactor. This is more for sanity checking in case someone moved the files around or something like that. Methods for getting/reading the version from files were moved to test class TestTxnCommands which is the only place they are used, in order to keep devs out of temptation, since they access the FileSystem which is expensive."}
{"index": 1851, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class AcidUtils.ParsedDelta {\n\t// Returns the files from the delta directory.\n\tList<org.apache.hadoop.hive.shims.HadoopShims.HdfsFileStatusWithId> getFiles(org.apache.hadoop.fs.FileSystem fs, Ref<Boolean> useFileIds);\n\t// Files w/o Acid meta columns embedded in the file.\n\tboolean isRawFormat();\n}", "des": "In addition to AcidUtils.ParsedDeltaLight this knows if the data is in raw format, i.e. doesn't have acid metadata columns embedded in the files. To determine this in some cases requires looking at the footer of the data file which can be expensive so if this info is not needed AcidUtils.ParsedDeltaLight should be used."}
{"index": 1852, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class AckTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "AckTask. Add the repl dump/ repl load complete acknowledgement."}
{"index": 1853, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum AlterTableType {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AlterTableType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AlterTableType[] values();\n}", "des": "Enumeration of alter table command types."}
{"index": 1854, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class AppMasterEventOperator {\n\t// Operator specific close routine.\n\tvoid closeOp(boolean abort);\n\tString getName();\n\tstatic String getOperatorName();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\tprotected void initDataBuffer(boolean skipPruning);\n\t// Operator specific initialization.\n\tvoid initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "AppMasterEventOperator sends any rows it receives to the Tez AM. This can be used to control execution dynamically."}
{"index": 1855, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ArchiveUtils.PartSpecInfo {\n\t// Extract partial prefix specification from table and key-value map\n\tstatic ArchiveUtils.PartSpecInfo create(Table tbl, Map<String,String> partSpec);\n\t// Creates path where partitions matching prefix should lie in filesystem\n\torg.apache.hadoop.fs.Path createPath(Table tbl);\n\t// Generates name for prefix partial partition specification.\n\tString getName();\n}", "des": "PartSpecInfo keeps fields and values extracted from partial partition info which is prefix of the full info."}
{"index": 1856, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class AtlasDumpTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "Atlas Metadata Replication Dump Task."}
{"index": 1857, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class AtlasLoadTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "Atlas Metadata Replication Load Task."}
{"index": 1858, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class AWSSecretsManagerSecretSource {\n\t// Clean the resources in the class.\n\tvoid close();\n\t// This load the secret from aws-secrets manager.\n\tString getSecret(URI uri);\n\t// The scheme string which this implementation will handle.\n\tString getURIScheme();\n}", "des": "Implementation of SecretSource which loads secrets from AWS Secrets Manager. The format of the uri is \"aws-sm:///{key-name-or-arn}\" It uses aws secrets cache sdk to fetch and refresh the secret, the environment must be setup so that the default client can load the secret else it will fail. It expects the secret fetched to be a json string with \"password\" as the key for password, this is default for redshift, rds or external database configs. It does not make use of any other fields."}
{"index": 1859, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class BucketizedHiveRecordReader<K extends org.apache.hadoop.io.WritableComparable,V extends org.apache.hadoop.io.Writable> {\n\tK createKey();\n\tV createValue();\n\t// Close this InputSplit to future operations.\n\tvoid doClose();\n\tboolean doNext(K key, V value);\n\tlong getPos();\n\tfloat getProgress();\n\t// Get the record reader for the next chunk in this BucketizedHiveRecordReader.\n\tprotected boolean initNextRecordReader();\n}", "des": "BucketizedHiveRecordReader is a wrapper on a list of RecordReader. It behaves similar as HiveRecordReader while it wraps a list of RecordReader from one file."}
{"index": 1860, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface BytesBytesMultiHashMap.KvSource {\n\t// Provide updated value for state byte for a key.\n\tbyte updateStateByte(Byte previousValue);\n\t// Write key into output.\n\tvoid writeKey(ByteStream.RandomAccessOutput dest);\n\t// Write value into output.\n\tvoid writeValue(ByteStream.RandomAccessOutput dest);\n}", "des": "The source of keys and values to put into hashtable; avoids byte copying."}
{"index": 1861, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class BytesBytesMultiHashMap.Result {\n\tWriteBuffers.ByteSegmentRef first();\n\t// Lets go of any references to a hash map.\n\tvoid forget();\n\t// Return the thread-safe read position.\n\tWriteBuffers.Position getReadPos();\n\tboolean hasRows();\n\tboolean isSingleRow();\n\tWriteBuffers.ByteSegmentRef next();\n\t// Set internal values for reading the values after finding a key.\n\tvoid set(BytesBytesMultiHashMap hashMap, long firstOffset, boolean hasList, long offsetAfterListRecordKeyLen);\n}", "des": "The result of looking up a key in the multi-hash map. This object can read through the 0, 1, or more values found for the key."}
{"index": 1862, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CacheTableHelper {\n\t// Populates the cache for the given table pairs.\n\tvoid populateCache(List<org.apache.commons.lang3.tuple.Pair<String,String>> tables, HiveConf conf, HiveTxnManager txnMgr);\n\t// Populates the cache for the given table pairs associated with a viewName.\n\tvoid populateCacheForView(List<org.apache.commons.lang3.tuple.Pair<String,String>> tables, HiveConf conf, HiveTxnManager txnMgr, String dbName, String viewName);\n}", "des": "Class to help populate the cache at the beginning of query analysis. We would like to minimize the number of calls to fetch validWriteIdLists from the metastore. HMS has an API to request this object for multiple tables within one call, and this class uses that API. The sole purpose of this class is to help populate the HMS query cache. Nothing is returned from the public methods. In this way, if another method attempts to fetch a validWriteIdList, the SessionHiveMetaStoreClient query cache will contain the information. Because this class is only responsible for cache population, it is not a requirement for a caller to supply all the tables necessary for the query. It is also not a requirement for the tables to be part of the query. Of course, the query qill benefit if those conditions were true, but if the table is not in the cache, a later call fetching the writeids will hit the HMS server and will not fail. One tricky aspect to this class is that if a view is passed in, we want to fetch the validWriteIdLists for the underlying tables. At the beginning of the query, it is impossible to know the underlying tables without contacting HMS. In order to handle the underlying tables to the views, we keep a cache that holds our best guess. If we see a view in any query, we set up a server-wide cache that tracks the underlying tables to the view. If the view doesn't change, then this information will be accurate and allow us to fetch the underlying tables on our next query. If the view does change and the underlying tables are different, our fetch won't retrieve the correct information. But that's ok...remember what was said earlier that it is not a requirement for the tables to be part of the query. Later on in the query, this class will be called on the view level via the populateCacheForView call. At that point, if something changed, it will populate the cache with the newly detected tables. It will also change the underying table information for the view to optimize the next query using the view."}
{"index": 1863, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CastDecimalToDecimal {\n\t// Convert input decimal value to a decimal with a possibly different precision and scale, at position i in the respective vectors.\n\tprotected void convert(DecimalColumnVector outputColVector, DecimalColumnVector inputColVector, int i);\n\t// Cast decimal(p1, s1) to decimal(p2, s2).\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\tString vectorExpressionParameters();\n}", "des": "Cast a decimal to a decimal, accounting for precision and scale changes. If other functions besides cast need to take a decimal in and produce a decimal, you can subclass this class or convert it to a superclass, and implement different methods for each operation. If that's done, the convert() method should be renamed to func() for consistency with other similar super classes such as FuncLongToDecimal."}
{"index": 1864, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CastStringToDecimal {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\t// Convert input string to a decimal, at position i in the respective vectors.\n\tprotected void func(DecimalColumnVector outputColVector, BytesColumnVector inputColVector, int i);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\tString vectorExpressionParameters();\n}", "des": "Cast a string to a decimal. If other functions besides cast need to take a string in and produce a decimal, you can subclass this class or convert it to a superclass, and implement different \"func()\" methods for each operation."}
{"index": 1865, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CastStringToDouble {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\t// Convert input string to a double, at position i in the respective vectors.\n\tprotected void func(DoubleColumnVector outputColVector, BytesColumnVector inputColVector, int batchIndex);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\tString vectorExpressionParameters();\n}", "des": "Cast a string to a double. If other functions besides cast need to take a string in and produce a long, you can subclass this class or convert it to a superclass, and implement different \"func()\" methods for each operation."}
{"index": 1866, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CastStringToLong {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\t// Convert input string to a long, at position i in the respective vectors.\n\tprotected void func(LongColumnVector outputColVector, BytesColumnVector inputColVector, int batchIndex);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\tvoid transientInit(org.apache.hadoop.conf.Configuration conf);\n\tString vectorExpressionParameters();\n}", "des": "Cast a string to a long. If other functions besides cast need to take a string in and produce a long, you can subclass this class or convert it to a superclass, and implement different \"func()\" methods for each operation."}
{"index": 1867, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum CBOFallbackStrategy {\n\tabstract boolean allowsRetry();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CBOFallbackStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CBOFallbackStrategy[] values();\n}", "des": "A strategy defining when CBO fallbacks to the legacy optimizer."}
{"index": 1868, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CBOPlan {\n\tASTNode getAst();\n\t// Returns an error message if this plan can not be a definition of a Materialized view which is an input of Calcite based materialized view query rewrite.\n\tString getInvalidAutomaticRewritingMaterializationReason();\n\t// Root node of plan.\n\torg.apache.calcite.rel.RelNode getPlan();\n}", "des": "Wrapper of Calcite plan."}
{"index": 1869, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CollectOperator {\n\tString getName();\n\tstatic String getOperatorName();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Decides whether two operators are logically the same.\n\tboolean logicalEquals(Operator other);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n\tvoid retrieve(InspectableObject result);\n}", "des": "Buffers rows emitted by other operators."}
{"index": 1870, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum ColStatsProcessor.ColumnStatsField {\n\tString getFieldName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ColStatsProcessor.ColumnStatsField valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ColStatsProcessor.ColumnStatsField[] values();\n}", "des": "Enumeration of column stats fields that can currently be computed. Each one has a field name associated."}
{"index": 1871, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ColumnStatsUpdateTask {\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "ColumnStatsUpdateTask implementation. For example, ALTER TABLE src_stat UPDATE STATISTICS for column key SET ('numDVs'='1111','avgColLen'='1.111'); For another example, ALTER TABLE src_stat_part PARTITION(partitionId=100) UPDATE STATISTICS for column value SET ('maxColLen'='4444','avgColLen'='44.4');"}
{"index": 1872, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CompileLock {\n\tvoid close();\n\t// Releases the compile lock.\n\tvoid release();\n\t// Acquires the compile lock.\n\tboolean tryAcquire();\n}", "des": "Encapsulates HS2 compile lock logic."}
{"index": 1873, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum CompressionKind {\n\torg.apache.orc.CompressionKind getUnderlying();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompressionKind valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompressionKind[] values();\n}", "des": "An enumeration that lists the generic compression algorithms that can be applied to ORC files. This is a shim to help users while we migrate to the org.apache.orc package."}
{"index": 1874, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface Consumer<T> {\n\t// Some data has been produced.\n\tvoid consumeData(T data);\n\t// No more data will be produced; done.\n\tvoid setDone();\n\t// No more data will be produced; error during production.\n\tvoid setError(Throwable t);\n}", "des": "Data consumer; an equivalent of a data queue for an asynchronous data producer."}
{"index": 1875, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Context.Operation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Context.Operation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Context.Operation[] values();\n}", "des": "These ops require special handling in various places (note that Insert into Acid table is in OTHER category)"}
{"index": 1876, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CopyTask {\n\tprotected int copyOnePath(org.apache.hadoop.fs.Path fromPath, org.apache.hadoop.fs.Path toPath);\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "CopyTask implementation."}
{"index": 1877, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface CounterLimit {\n\t// Return cloned copy of this counter limit\n\tCounterLimit clone();\n\t// Get the threshold value for the counter\n\tlong getLimit();\n\t// Get the name of the counter.\n\tString getName();\n}", "des": "Counter limit interface for defining counter name and its limit exceeding which action defined in trigger will get executed."}
{"index": 1878, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CreateMacroDesc {\n\tExprNodeDesc getBody();\n\t// For explaining only.\n\tString getBodyString();\n\tList<String> getColumnNames();\n\tList<TypeInfo> getColumnTypes();\n\t// For explaining only.\n\tList<String> getColumnTypeStrings();\n\tString getName();\n}", "des": "DDL task description for CREATE TEMPORARY MACRO commands."}
{"index": 1879, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CuckooSetBytes {\n\tvoid insert(byte[] x);\n\t// Insert all values in the input array into the set.\n\tvoid load(byte[][] a);\n\t// Return true if and only if the value in byte array b beginning at start and ending at start+len is present in the set.\n\tboolean lookup(byte[] b, int start, int len);\n}", "des": "A high-performance set implementation used to support fast set membership testing, using Cuckoo hashing. This is used to support fast tests of the form column IN ( list-of-values ) For details on the algorithm, see R. Pagh and F. F. Rodler, \"Cuckoo Hashing,\" Elsevier Science preprint, Dec. 2003. http://www.itu.dk/people/pagh/papers/cuckoo-jour.pdf."}
{"index": 1880, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CuckooSetDouble {\n\t// Insert a single value into the set.\n\tvoid insert(double x);\n\t// Insert all values in the input array into the set.\n\tvoid load(double[] a);\n\t// Return true if and only if the value x is present in the set.\n\tboolean lookup(double x);\n}", "des": "A high-performance set implementation used to support fast set membership testing, using Cuckoo hashing. This is used to support fast tests of the form column IN ( list-of-values ) For double, we simply layer over the implementation for long. Double.doubleToRawLongBits is used to convert a 64-bit double to a 64-bit long with bit-for-bit fidelity."}
{"index": 1881, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CuckooSetLong {\n\tvoid insert(long x);\n\t// Insert all values in the input array into the set.\n\tvoid load(long[] a);\n\t// Return true if and only if the value x is present in the set.\n\tboolean lookup(long x);\n}", "des": "A high-performance set implementation used to support fast set membership testing, using Cuckoo hashing. This is used to support fast tests of the form column IN ( list-of-values ) For details on the algorithm, see R. Pagh and F. F. Rodler, \"Cuckoo Hashing,\" Elsevier Science preprint, Dec. 2003. http://www.itu.dk/people/pagh/papers/cuckoo-jour.pdf."}
{"index": 1882, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class CustomCounterLimit {\n\t// Return cloned copy of this counter limit\n\tCounterLimit clone();\n\tboolean equals(Object other);\n\t// Get the threshold value for the counter\n\tlong getLimit();\n\t// Get the name of the counter.\n\tString getName();\n}", "des": "Custom counters with limits (this will only work if the execution engine exposes this counter)"}
{"index": 1883, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DDLTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n\tboolean requireLock();\n}", "des": "DDLTask implementation."}
{"index": 1884, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColAddDecimal64Column {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnArithmeticDecimal64Column.txt, which covers decimal64 arithmetic expressions between columns."}
{"index": 1885, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColAddDecimal64Scalar {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnArithmeticDecimal64Scalar.txt, which covers decimal64 arithmetic expressions between a column and a scalar."}
{"index": 1886, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColDivideDecimal64Column {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnArithmeticDecimal64Column.txt, which covers decimal64 arithmetic expressions between columns."}
{"index": 1887, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColDivideDecimal64Scalar {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnDivideDecimal64Scalar.txt, which covers decimal64 arithmetic expressions between a column and a scalar."}
{"index": 1888, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColMultiplyDecimal64Column {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnArithmeticDecimal64Column.txt, which covers decimal64 arithmetic expressions between columns."}
{"index": 1889, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColMultiplyDecimal64Scalar {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnArithmeticDecimal64Scalar.txt, which covers decimal64 arithmetic expressions between a column and a scalar."}
{"index": 1890, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColSubtractDecimal64Column {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnArithmeticDecimal64Column.txt, which covers decimal64 arithmetic expressions between columns."}
{"index": 1891, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ColSubtractDecimal64Scalar {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ColumnArithmeticDecimal64Scalar.txt, which covers decimal64 arithmetic expressions between a column and a scalar."}
{"index": 1892, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ScalarAddDecimal64Column {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ScalarArithmeticDecimal64Column.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1893, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ScalarMultiplyDecimal64Column {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ScalarArithmeticDecimal64Column.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1894, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Decimal64ScalarSubtractDecimal64Column {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// By default vector expressions do not handle decimal64 types and should be converted into Decimal types if its output cannot handle Decimal64.\n\tboolean shouldConvertDecimal64ToDecimal();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template Decimal64ScalarArithmeticDecimal64Column.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1895, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DefaultGraphWalker {\n\t// Dispatch the current operator.\n\tvoid dispatch(Node nd, Stack<Node> ndStack);\n\t// Returns dispatch result\n\t<T> T dispatchAndReturn(Node nd, Stack<Node> ndStack);\n\tprotected Set<Node> getDispatchedList();\n\t// starting point for walking.\n\tvoid startWalking(Collection<Node> startNodes, HashMap<Node,Object> nodeOutput);\n\t// walk the current operator and its descendants.\n\tprotected void walk(Node nd);\n}", "des": "base class for operator graph walker this class takes list of starting ops and walks them one by one. it maintains list of walked operators (dispatchedList) and a list of operators that are discovered but not yet dispatched"}
{"index": 1896, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DependencyCollectionTask {\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "DependencyCollectionTask. Exists for the sole purpose of reducing the number of dependency edges in the task graph."}
{"index": 1897, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DirCopyTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "DirCopyTask, mainly to be used to copy External table data."}
{"index": 1898, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColAddDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 1899, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColAddDoubleScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 1900, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColAddLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 1901, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColAddLongScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 1902, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColModuloDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnDivideColumn.txt, which covers division and modulo expressions between columns."}
{"index": 1903, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColModuloLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnDivideColumn.txt, which covers division and modulo expressions between columns."}
{"index": 1904, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColMultiplyDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 1905, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColMultiplyDoubleScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 1906, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColMultiplyLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 1907, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColMultiplyLongScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 1908, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColSubtractDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 1909, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColSubtractDoubleScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 1910, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColSubtractLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 1911, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColSubtractLongScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 1912, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleColUnaryMinusChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnUnaryMinus.txt, which covers unary negation operator."}
{"index": 1913, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleScalarAddDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1914, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleScalarAddLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1915, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleScalarMultiplyDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1916, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleScalarMultiplyLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1917, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleScalarSubtractDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1918, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DoubleScalarSubtractLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 1919, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class DummyStoreOperator {\n\tString getName();\n\tstatic String getOperatorName();\n\tInspectableObject getResult();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n\tvoid reset();\n}", "des": "For SortMerge joins, this is a dummy operator, which stores the row for the small table before it reaches the sort merge join operator. Consider a query like: select * from (subq1 --> has a filter) join (subq2 --> has a filter) on some key Let us assume that subq1 is the small table (either specified by the user or inferred automatically). Since there can be multiple buckets/partitions for the table corresponding to subq1 given a file in subq2, a priority queue is present in SMBMapJoinOperator to scan the various buckets and fetch the least row (corresponding to the join key). The tree corresponding to subq1 needs to be evaluated in order to compute the join key (since the select list for the join key can move across different object inspectors). Therefore the following operator tree is created: TableScan (subq1) --> Select --> Filter --> DummyStore \\ \\ SMBJoin / / TableScan (subq2) --> Select --> Filter In order to fetch the row with the least join key from the small table, the row from subq1 is partially processed, and stored in DummyStore. For the actual processing of the join, SMBJoin (child of DummyStore) is processed for the transformed row. Note that in the absence of support for joins for sub-queries, this was not needed, since all transformations were done after SMBJoin, or for the small tables, nothing could have been present between TableScan and SMBJoin."}
{"index": 1920, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Entity.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Entity.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Entity.Type[] values();\n}", "des": "The type of the entity."}
{"index": 1921, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface ErrorHeuristic {\n\t// Examine the hive query, job configuration, and the lines from the task log seen so far though processLogLine() and generate a possible cause/solution.\n\tErrorAndSolution getErrorAndSolution();\n\t// Initialize this error heuristic.\n\tvoid init(String query, org.apache.hadoop.mapred.JobConf jobConf);\n\t// Process the given log line.\n\tvoid processLogLine(String line);\n}", "des": "Classes implementing ErrorHeuristic are able to generate a possible cause and solution for Hive jobs that have failed by examining the query, task log files, and the job configuration. A class implementing ErrorHeuristic should only detect one type of error."}
{"index": 1922, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum EsriFieldType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EsriFieldType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EsriFieldType[] values();\n}", "des": "Enumeration of Esri field types. These are not upper cased as they are a direct string representation of what would is in the JSON"}
{"index": 1923, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface Expression {\n\t// Return cloned copy of this expression.\n\tExpression clone();\n\t// Evaluate current value against this expression.\n\tboolean evaluate(long current);\n\t// Return counter limit\n\tCounterLimit getCounterLimit();\n\t// Return predicate defined in the expression.\n\tExpression.Predicate getPredicate();\n}", "des": "Expression that is defined in triggers. Most expressions will get triggered only after exceeding a limit. As a result, only greater than (>) expression is supported."}
{"index": 1924, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprNodeColumnEvaluator {\n\t// Evaluate value\n\tprotected Object _evaluate(Object row, int version);\n\t// Initialize should be called once and only once.\n\tObjectInspector initialize(ObjectInspector rowInspector);\n}", "des": "This evaluator gets the column from the row object."}
{"index": 1925, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprNodeConstantEvaluator {\n\t// Evaluate value\n\tprotected Object _evaluate(Object row, int version);\n\t// Initialize should be called once and only once.\n\tObjectInspector initialize(ObjectInspector rowInspector);\n}", "des": "ExprNodeConstantEvaluator."}
{"index": 1926, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprNodeDynamicValueEvaluator {\n\t// Evaluate value\n\tprotected Object _evaluate(Object row, int version);\n\t// Initialize should be called once and only once.\n\tObjectInspector initialize(ObjectInspector rowInspector);\n}", "des": "ExprNodeDynamicEvaluator."}
{"index": 1927, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprNodeEvaluatorHead {\n\t// Evaluate value\n\tprotected Object _evaluate(Object row, int version);\n\t// Initialize should be called once and only once.\n\tObjectInspector initialize(ObjectInspector rowInspector);\n}", "des": "Increases version number of each evaluations for correct caching"}
{"index": 1928, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprNodeEvaluatorRef {\n\t// Evaluate value\n\tprotected Object _evaluate(Object row, int version);\n\t// Initialize should be called once and only once.\n\tObjectInspector initialize(ObjectInspector rowInspector);\n}", "des": "Returns evaluation result of other evaluator"}
{"index": 1929, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprNodeFieldEvaluator {\n\t// Evaluate value\n\tprotected Object _evaluate(Object row, int version);\n\t// Initialize should be called once and only once.\n\tObjectInspector initialize(ObjectInspector rowInspector);\n}", "des": "This Evaluator can evaluate s.f for s as both struct and list of struct. If s is struct, then s.f is the field. If s is list of struct, then s.f is the list of struct field."}
{"index": 1930, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprProcCtx {\n\t// Gets the input operator.\n\tOperator<? extends OperatorDesc> getInputOperator();\n\t// Gets the lineage context.\n\tLineageCtx getLineageCtx();\n\tRowSchema getSchema();\n}", "des": "The processor context for the lineage information. This contains the lineage context and the column info and operator information that is being used for the current expression."}
{"index": 1931, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ExprProcFactory {\n\t// Generates the partition pruner for the expression tree.\n\tstatic ExprNodeDesc genPruner(String tabAlias, ExprNodeDesc pred);\n\t// Instantiate column processor.\n\tstatic SemanticNodeProcessor getColumnProcessor();\n}", "des": "Expression processor factory for partition pruning. Each processor tries to convert the expression subtree into a partition pruning expression. This expression is then used to figure out whether a particular partition should be scanned or not. * Refactor: Move main logic to PrunerExpressionOperatorFactory. ExprProcFactory extends it to reuse logic. Any other pruner can reuse it by creating a class extending from PrunerExpressionOperatorFactory. Only specific logic is in genPruner(..) which is in its own class like ExprProcFactory."}
{"index": 1932, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum FileSinkOperator.Counter {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileSinkOperator.Counter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileSinkOperator.Counter[] values();\n}", "des": "Counters."}
{"index": 1933, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class FileSystemCounterLimit {\n\t// Return cloned copy of this counter limit\n\tCounterLimit clone();\n\tboolean equals(Object other);\n\t// Get the threshold value for the counter\n\tlong getLimit();\n\t// Get the name of the counter.\n\tString getName();\n}", "des": "File system specific counters with defined limits"}
{"index": 1934, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class FilterPredicateLeafBuilder {\n\t// Build filter predicate with multiple constants\n\torg.apache.parquet.filter2.predicate.FilterPredicate buildPredicate(PredicateLeaf.Operator op, List<Object> literals, String columnName, TypeInfo columnType);\n\t// Build predicate with a single constant\n\tabstract org.apache.parquet.filter2.predicate.FilterPredicate buildPredict(PredicateLeaf.Operator op, Object constant, String columnName, TypeInfo columnType);\n}", "des": "The base class for building parquet supported filter predicate in primary types."}
{"index": 1935, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface FlatFileInputFormat.SerializationContext<S> {\n\t// Produces the specific class to deserialize.\n\tClass<? extends S> getRealClass();\n\t// An Serialization object for objects of type S.\n\torg.apache.hadoop.io.serializer.Serialization<S> getSerialization();\n}", "des": "An implementation of SerializationContext is responsible for looking up the Serialization implementation for the given RecordReader. Potentially based on the Configuration or some other mechanism The SerializationFactory does not give this functionality since: 1. Requires Serialization implementations to be specified in the Configuration a-priori (although same as setting a SerializationContext) 2. Does not lookup the actual subclass being deserialized. e.g., for Serializable does not have a way of configuring the actual Java class being serialized/deserialized."}
{"index": 1936, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class FlatFileInputFormat.SerializationContextFromConf<S> {\n\torg.apache.hadoop.conf.Configuration getConf();\n\t// Produces the specific class to deserialize.\n\tClass<S> getRealClass();\n\t// Looks up and instantiates the Serialization Object Important to note here that we are not relying on the Hadoop SerializationFactory part of the Serialization framework.\n\torg.apache.hadoop.io.serializer.Serialization<S> getSerialization();\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "An implementation of FlatFileInputFormat.SerializationContext that reads the Serialization class and specific subclass to be deserialized from the JobConf."}
{"index": 1937, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum FunctionUtils.FunctionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FunctionUtils.FunctionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FunctionUtils.FunctionType[] values();\n}", "des": "Function type, for permanent functions. Currently just JAVA, though we could support Groovy later on."}
{"index": 1938, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum FunctionUtils.UDFClassType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FunctionUtils.UDFClassType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FunctionUtils.UDFClassType[] values();\n}", "des": "Enum type to describe what kind of UDF implementation class"}
{"index": 1939, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFAverage {\n\t// The intermediate sum field has 10 more integer digits with the same scale.\n\tstatic DecimalTypeInfo deriveSumFieldTypeInfo(int precision, int scale);\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo paramInfo);\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(TypeInfo[] parameters);\n}", "des": "GenericUDAFAverage."}
{"index": 1940, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFBloomFilter {\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo info);\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(TypeInfo[] parameters);\n}", "des": "Generic UDF to generate Bloom Filter"}
{"index": 1941, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFComputeStats.GenericUDAFDateStatsEvaluator {\n\t// Get a new aggregation object.\n\tGenericUDAFEvaluator.AggregationBuffer getNewAggregationBuffer();\n\tprotected DateObjectInspector getValueObjectInspector();\n\tprotected DateObjectInspector getValueObjectInspector(PrimitiveTypeInfo typeInfo);\n\t// Reset the aggregation.\n\tvoid reset(GenericUDAFEvaluator.AggregationBuffer agg);\n}", "des": "GenericUDAFDateStatsEvaluator High/low value will be saved in stats DB as long value representing days since epoch."}
{"index": 1942, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFComputeStats.GenericUDAFDoubleStatsEvaluator {\n\t// Get a new aggregation object.\n\tGenericUDAFEvaluator.AggregationBuffer getNewAggregationBuffer();\n\tprotected DoubleObjectInspector getValueObjectInspector();\n\tprotected DoubleObjectInspector getValueObjectInspector(PrimitiveTypeInfo typeInfo);\n\t// Reset the aggregation.\n\tvoid reset(GenericUDAFEvaluator.AggregationBuffer agg);\n}", "des": "GenericUDAFDoubleStatsEvaluator."}
{"index": 1943, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFComputeStats.GenericUDAFLongStatsEvaluator {\n\t// Get a new aggregation object.\n\tGenericUDAFEvaluator.AggregationBuffer getNewAggregationBuffer();\n\tprotected LongObjectInspector getValueObjectInspector();\n\tprotected LongObjectInspector getValueObjectInspector(PrimitiveTypeInfo typeInfo);\n\t// Reset the aggregation.\n\tvoid reset(GenericUDAFEvaluator.AggregationBuffer agg);\n}", "des": "GenericUDAFLongStatsEvaluator."}
{"index": 1944, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFComputeStats.GenericUDAFTimestampStatsEvaluator {\n\t// Get a new aggregation object.\n\tGenericUDAFEvaluator.AggregationBuffer getNewAggregationBuffer();\n\tprotected TimestampObjectInspector getValueObjectInspector();\n\tprotected TimestampObjectInspector getValueObjectInspector(PrimitiveTypeInfo typeInfo);\n\t// Reset the aggregation.\n\tvoid reset(GenericUDAFEvaluator.AggregationBuffer agg);\n}", "des": "GenericUDAFTimestampStatsEvaluator High/low value will be saved in stats DB as long value representing seconds since epoch."}
{"index": 1945, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFCount {\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo paramInfo);\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(TypeInfo[] parameters);\n}", "des": "This class implements the COUNT aggregation function as in SQL."}
{"index": 1946, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum GenericUDAFEvaluator.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GenericUDAFEvaluator.Mode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GenericUDAFEvaluator.Mode[] values();\n}", "des": "Mode."}
{"index": 1947, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFExceptionInVertex {\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo paramInfo);\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(TypeInfo[] parameters);\n}", "des": "This class implements the UDAF which can throw an exception in arbitrary aggregating vertex (typically reducer) / task / task attempt."}
{"index": 1948, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface GenericUDAFParameterInfo {\n\tObjectInspector[] getParameterObjectInspectors();\n\t// Returns true if the UDAF invocation was done via the wildcard syntax FUNCTION(*).\n\tboolean isAllColumns();\n\t// Returns true if the UDAF invocation was qualified with DISTINCT keyword.\n\tboolean isDistinct();\n\t// The flag to indicate if the UDAF invocation was from the windowing function call or not.\n\tboolean isWindowing();\n\tboolean respectNulls();\n}", "des": "A callback interface used in conjunction with GenericUDAFResolver2 interface that allows for a more extensible and flexible means of discovering the parameter types provided for UDAF invocation. Apart from allowing the function implementation to discover the TypeInfo of any types provided in the invocation, this also allows the implementation to determine if the parameters were qualified using DISTINCT. If no parameters were specified explicitly, it allows the function implementation to test if the invocation used the wildcard syntax such as FUNCTION(*)."}
{"index": 1949, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDAFSum {\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(GenericUDAFParameterInfo info);\n\t// Get the evaluator for the parameter types.\n\tGenericUDAFEvaluator getEvaluator(TypeInfo[] parameters);\n\tstatic PrimitiveObjectInspector.PrimitiveCategory getReturnType(TypeInfo type);\n}", "des": "GenericUDAFSum."}
{"index": 1950, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFAbs {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFAbs."}
{"index": 1951, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFAddMonths {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFAddMonths. Add a number of months to the date. The time part of the string will be ignored."}
{"index": 1952, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFArray {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFArray."}
{"index": 1953, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFArrayContains {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFArrayContains."}
{"index": 1954, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFAssertTrue {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFAssertTrue"}
{"index": 1955, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFBaseCompare {\n\tprotected void checkConversionAllowed(ObjectInspector argOI, ObjectInspector compareOI);\n\tInteger compare(GenericUDF.DeferredObject[] arguments);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\tprotected PrimitiveObjectInspectorUtils.PrimitiveGrouping primitiveGroupOf(ObjectInspector oi);\n\t// Returns whether the operator can handle operands with the specified category.\n\tprotected boolean supportsCategory(ObjectInspector.Category c);\n}", "des": "GenericUDF Base Class for operations."}
{"index": 1956, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFBaseNwayCompare {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Base class for comparison UDF's (Greatest and Least)."}
{"index": 1957, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFCardinalityViolation {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Function intended to fail. It is used in query parts which should not return anything, and thus mark the problem."}
{"index": 1958, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFCase {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Returns the StatEstimator for the given UDF instance.\n\tStatEstimator getStatEstimator();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDF Class for SQL construct \"CASE a WHEN b THEN c [ELSE f] END\". NOTES: 1. a and b should be compatible, or an exception will be thrown. 2. c and f should be compatible types, or an exception will be thrown."}
{"index": 1959, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFCastFormat {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "CAST( AS FORMAT ). Vector expressions: CastDateToCharWithFormat, CastDateToStringWithFormat, CastDateToVarCharWithFormat, CastTimestampToCharWithFormat, CastTimestampToStringWithFormat, CastTimestampToVarCharWithFormat. Could not use @VectorizedExpressions annotation because e.g. CastXToCharWithFormat, CastXToStringWithFormat, CastXToVarCharWithFormat would have same description."}
{"index": 1960, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFCbrt {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFCbrt."}
{"index": 1961, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFCoalesce {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Returns the StatEstimator for the given UDF instance.\n\tStatEstimator getStatEstimator();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDF Class for SQL construct \"COALESCE(a, b, c)\". NOTES: 1. a, b and c should have the same TypeInfo, or an exception will be thrown."}
{"index": 1962, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFConcat {\n\tObject binaryEvaluate(GenericUDF.DeferredObject[] arguments);\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\tString stringEvaluate(GenericUDF.DeferredObject[] arguments);\n}", "des": "GenericUDFConcat."}
{"index": 1963, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFConcatWS {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\tprotected boolean isStringOrVoidType(ObjectInspector oi);\n}", "des": "Generic UDF for string function CONCAT_WS(sep, [string | array(string)]+). This mimics the function from MySQL http://dev.mysql.com/doc/refman/5.0/en/string-functions.html# function_concat-ws"}
{"index": 1964, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFCurrentAuthorizer {\n\t// Some information may be set during initialize() which needs to be saved when the UDF is copied.\n\tvoid copyToNewInstance(Object newInstance);\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDF to determine the current authorizer (class name of the authorizer) This is intended for internal usage only. This function is not a deterministic function, but a runtime constant. The return value is constant within a query but can be different between queries"}
{"index": 1965, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFDate {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFDate."}
{"index": 1966, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFDateAdd {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFDateAdd. Add a number of days to the date. The time part of the string will be ignored. NOTE: This is a subset of what MySQL offers as: http://dev.mysql.com/doc/refman /5.1/en/date-and-time-functions.html#function_date-add"}
{"index": 1967, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFDateDiff {\n\t// Evaluate the GenericUDF with the arguments.\n\torg.apache.hadoop.io.IntWritable evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFDateDiff. Calculate the difference in the number of days. The time part of the string will be ignored. If dateString1 is earlier than dateString2, then the result can be negative."}
{"index": 1968, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFDateFormat {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFDateFormat. converts a date/timestamp/string to a value of string in the format specified by the java date format"}
{"index": 1969, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFDatetimeLegacyHybridCalendar {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFDatetimeLegacyHybridCalendar."}
{"index": 1970, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFDeserialize {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFDeserializeString."}
{"index": 1971, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFElt {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Generic UDF for string function ELT(N,str1,str2,str3,...). This mimics the function from MySQL http://dev.mysql.com/doc/refman/5.1/en/string-functions.html#function_elt"}
{"index": 1972, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFEnforceConstraint {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFAbs."}
{"index": 1973, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFEpochMilli {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFEpochMilli."}
{"index": 1974, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFFactorial {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFFactorial"}
{"index": 1975, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFField {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFField."}
{"index": 1976, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFFormatNumber {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Generic UDF for format_number function FORMAT_NUMBER(X, D or F). This is supposed to function like MySQL's FORMAT, http://dev.mysql.com/doc/refman/5.1/en/string-functions.html# function_format"}
{"index": 1977, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFFromUnixTime {\n\t// Additionally setup GenericUDF with MapredContext before initializing.\n\tvoid configure(MapredContext context);\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFFromUnixTime."}
{"index": 1978, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFGrouping {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDF grouping"}
{"index": 1979, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFIf {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Returns the StatEstimator for the given UDF instance.\n\tStatEstimator getStatEstimator();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "IF(expr1,expr2,expr3) If expr1 is TRUE (expr1 <> 0 and expr1 <> NULL) then IF() returns expr2; otherwise it returns expr3. IF() returns a numeric or string value, depending on the context in which it is used."}
{"index": 1980, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFIn {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFIn Example usage: SELECT key FROM src WHERE key IN (\"238\", \"1\"); From MySQL page on IN(): To comply with the SQL standard, IN returns NULL not only if the expression on the left hand side is NULL, but also if no match is found in the list and one of the expressions in the list is NULL. Also noteworthy: type conversion behavior is different from MySQL. With expr IN expr1, expr2... in MySQL, exprN will each be converted into the same type as expr. In the Hive implementation, all expr(N) will be converted into a common type for conversion consistency with other UDF's, and to prevent conversions from a big type to a small type (e.g. int to tinyint)"}
{"index": 1981, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFInBloomFilter {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDF to lookup a value in BloomFilter"}
{"index": 1982, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFIndex {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFIndex."}
{"index": 1983, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFInFile {\n\t// Some information may be set during initialize() which needs to be saved when the UDF is copied.\n\tvoid copyToNewInstance(Object newInstance);\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tString[] getRequiredFiles();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "IN_FILE(str, filename) returns true if 'str' appears in the file specified by 'filename'. A string is considered to be in the file if it that string appears as a line in the file. If either argument is NULL then NULL is returned."}
{"index": 1984, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFInitCap {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFInitCap."}
{"index": 1985, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFInstr {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Generic UDF for string function INSTR(str,substr[,pos[,occurrence]]). This extends the function from MySQL http://dev.mysql.com/doc/refman/5.1/en/string-functions.html#function_instr and mimics the function from Oracle https://docs.oracle.com/database/121/SQLRF/functions089.htm#SQLRF00651"}
{"index": 1986, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFInternalInterval {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDF Class for support of \"INTERVAL (expression) (DAY|YEAR|...)\"."}
{"index": 1987, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFJsonRead {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Parses a json string representation into a Hive struct."}
{"index": 1988, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFLastDay {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\tprotected Date lastDay(Date d);\n}", "des": "GenericUDFLastDay. Returns the last day of the month which the date belongs to. The time part of the date will be ignored."}
{"index": 1989, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFLength {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFLength."}
{"index": 1990, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFLevenshtein {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFLevenshtein. This function calculates the Levenshtein distance between two strings. Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (i.e. insertions, deletions or substitutions) required to change one word into the other. It is named after Vladimir Levenshtein, who considered this distance in 1965"}
{"index": 1991, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFLikeAll {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFLikeAll is return true if a text(column value) matches to all patterns Example usage: SELECT key FROM src WHERE key like all ('%ab%', 'a%','b%','abc'); LIKE ALL returns true if test matches all patterns patternN. Returns NULL if the expression on the left hand side is NULL or if one of the patterns in the list is NULL."}
{"index": 1992, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFLikeAny {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFLikeAll is return true if a text(column value) matches to any patterns Example usage: SELECT key FROM src WHERE key like any ('%ab%', 'a%','b%','abc'); like ANY returns true if test matches any patterns patternN. Returns NULL if the expression on the left hand side is NULL or if one of the patterns in the list is NULL."}
{"index": 1993, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFLocate {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Generic UDF for string function LOCATE(substr, str), LOCATE(substr, str, start). This mimcs the function from MySQL http://dev.mysql.com/doc/refman/5.1/en/string-functions.html#function_locate"}
{"index": 1994, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFLower {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFLower."}
{"index": 1995, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFMap {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFMap."}
{"index": 1996, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFMapKeys {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFMapKeys."}
{"index": 1997, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFMapValues {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFMapValues."}
{"index": 1998, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFMonthsBetween {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\tprotected int getDayPartInSec(Calendar cal);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFMonthsBetween."}
{"index": 1999, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFMurmurHash {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDF Class for computing murmurhash values."}
{"index": 2000, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFNDVComputeBitVector {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFNDVComputeBitVector. The ndv_compute_bit_vector function can be used on top of compute_bit_vector aggregate function to extract an estimate of the ndv from it."}
{"index": 2001, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFNextDay {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\tprotected int getIntDayOfWeek(String dayOfWeek);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\tprotected Date nextDay(Date d, int dayOfWeek);\n}", "des": "GenericUDFNextDay. Returns the first date which is later than start_date and named as indicated"}
{"index": 2002, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFNullif {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDF Class for SQL construct \"nullif(a,b)\"."}
{"index": 2003, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPAnd {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDF Class for computing and."}
{"index": 2004, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPEqual {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n\t// Returns whether the operator can handle operands with the specified category.\n\tprotected boolean supportsCategory(ObjectInspector.Category c);\n}", "des": "GenericUDF Class for operation EQUAL."}
{"index": 2005, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPEqualNS {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDF Class for operation EQUALNS."}
{"index": 2006, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPEqualOrGreaterThan {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Some functions like comparisons may be affected by appearing order of arguments.\n\tGenericUDF flip();\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDF Class for operation EqualOrGreaterThan."}
{"index": 2007, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPEqualOrLessThan {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Some functions like comparisons may be affected by appearing order of arguments.\n\tGenericUDF flip();\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDF Class for operation EqualOrLessThan."}
{"index": 2008, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPGreaterThan {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Some functions like comparisons may be affected by appearing order of arguments.\n\tGenericUDF flip();\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDF Class for operation GreaterThan."}
{"index": 2009, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPLessThan {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Some functions like comparisons may be affected by appearing order of arguments.\n\tGenericUDF flip();\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDF Class for operation LessThan."}
{"index": 2010, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPNot {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFOPNot."}
{"index": 2011, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPNotEqual {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n\t// Returns whether the operator can handle operands with the specified category.\n\tprotected boolean supportsCategory(ObjectInspector.Category c);\n}", "des": "GenericUDF Class for operation Not EQUAL."}
{"index": 2012, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPNotNull {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDFOPNotNull."}
{"index": 2013, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPNull {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDFOPNull."}
{"index": 2014, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPOr {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\t// Gets the negative function of the current one.\n\tGenericUDF negative();\n}", "des": "GenericUDF Class for computing or."}
{"index": 2015, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFOPPlus {\n\t// Instantiate date-time/interval version of the arithmetic UDF\n\tprotected GenericUDF instantiateDTIUDF();\n\t// Instantiate numeric version of the arithmetic UDF\n\tprotected GenericUDFBaseNumeric instantiateNumericUDF();\n}", "des": "The reason that we list evaluate methods with all numeric types is for both better performance and type checking (so we know int + int is still an int instead of a double); otherwise a single method that takes (Number a, Number b) and use a.doubleValue() == b.doubleValue() is enough. The case of int + double will be handled by implicit type casting using UDFRegistry.implicitConvertable method."}
{"index": 2016, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFPrintf {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Generic UDF for printf function printf(String format, Obj... args)."}
{"index": 2017, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFQuarter {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFQuarter. Returns the quarter of the year for date, in the range 1 to 4."}
{"index": 2018, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFQuote {\n\t// Evaluate the GenericUDF with the arguments.\n\torg.apache.hadoop.io.Text evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Source for GenericUDFQuote."}
{"index": 2019, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFReflect {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\tprotected String functionName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "A simple generic udf to call java static functions via reflection."}
{"index": 2020, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFReflect2 {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\tprotected String functionName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "A simple generic udf to call java functions via reflection."}
{"index": 2021, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFRegExp {\n\t// Additionally setup GenericUDF with MapredContext before initializing.\n\tvoid configure(MapredContext context);\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDF to extract a specific group identified by a java regex. Note that if a regexp has a backslash ('\\'), then need to specify '\\\\' For example, regexp_extract('100-200', '(\\\\d+)-(\\\\d+)', 1) will return '100'"}
{"index": 2022, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFRestrictInformationSchema {\n\t// Some information may be set during initialize() which needs to be saved when the UDF is copied.\n\tvoid copyToNewInstance(Object newInstance);\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDF to determine whether to enforce restriction of information schema. This is intended for internal usage only. This function is not a deterministic function, but a runtime constant. The return value is constant within a query but can be different between queries"}
{"index": 2023, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSentences {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFSentences: splits a natural language chunk of text into sentences and words."}
{"index": 2024, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSha2 {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFSha2."}
{"index": 2025, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSize {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFSize."}
{"index": 2026, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSortArray {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Generic UDF for array sort SORT_ARRAY(array(obj1, obj2, obj3...))."}
{"index": 2027, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSortArrayByField {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Generic UDF for tuple array sort by desired field[s] with [ordering(ASC or DESC)] SORT_ARRAY_BY(array(obj1, obj2, obj3...),'f1','f2',..,['ASC','DESC'])."}
{"index": 2028, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSplit {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFSplit."}
{"index": 2029, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSQCountCheck {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFSQCountCheck."}
{"index": 2030, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFStringToMap {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFStringToMap."}
{"index": 2031, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFStringToPrivilege {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFStringToPrivs."}
{"index": 2032, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFStructField {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "The class shouldn't be used, and only to align the implementation of vectorization UDF for struct field."}
{"index": 2033, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSubstringIndex {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFSubstringIndex."}
{"index": 2034, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFSurrogateKey {\n\t// Additionally setup GenericUDF with MapredContext before initializing.\n\tvoid configure(MapredContext context);\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\tvoid setWriteId(long writeId);\n}", "des": "This function is not a deterministic function, and not a runtime constant. The return value is sequence within a query with a unique staring point based on write_id and task_id"}
{"index": 2035, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFTimestamp {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\tboolean isIntToTimestampInSeconds();\n}", "des": "GenericUDFTimestamp Example usage: ... CAST( as TIMESTAMP) ... Creates a TimestampWritableV2 object using PrimitiveObjectInspectorConverter"}
{"index": 2036, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFToDate {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFToDate"}
{"index": 2037, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFToIntervalDayTime {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFIntervalDayTime Example usage: ... CAST( as INTERVAL DAY TO SECOND) ... Creates a HiveIntervalDayTimeWritable object using PrimitiveObjectInspectorConverter"}
{"index": 2038, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFToIntervalYearMonth {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFIntervalYearMonth Example usage: ... CAST( as INTERVAL YEAR TO MONTH) ... Creates a HiveIntervalYearMonthWritable object using PrimitiveObjectInspectorConverter"}
{"index": 2039, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFToTimestampLocalTZ {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tTypeInfo getTypeInfo();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n\t// Add data to UDF prior to initialization.\n\tvoid setTypeInfo(TypeInfo typeInfo);\n}", "des": "Convert from string to TIMESTAMP WITH LOCAL TIME ZONE."}
{"index": 2040, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFTranslate {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "TRANSLATE(string input, string from, string to) is an equivalent function to translate in PostGresSQL. See explain extended annotation below to read more about how this UDF works"}
{"index": 2041, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFTumbledWindow {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "Tumbling windows are a series of fixed-sized, non-overlapping and contiguous time intervals. Tumbling windows are inclusive start exclusive end. By default the beginning instant of fist window is Epoch 0 Thu Jan 01 00:00:00 1970 UTC. Optionally users may provide a different origin as a timestamp arg3. This an example of series of window with an interval of 5 seconds and origin Epoch 0 Thu Jan 01 00:00:00 1970 UTC: interval 1 interval 2 interval 3 Jan 01 00:00:00 Jan 01 00:00:05 Jan 01 00:00:10 0 -------------- 4 : 5 --------------- 9: 10 --------------- 14 This UDF rounds timestamp agr1 to the beginning of window interval where it belongs to."}
{"index": 2042, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFUpper {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFUpper."}
{"index": 2043, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFUtils {\n\tstatic TypeInfo deriveInType(List<ExprNodeDesc> children);\n\t// Finds any occurence of subtext from text in the backing buffer.\n\tstatic int findText(org.apache.hadoop.io.Text text, org.apache.hadoop.io.Text subtext, int start);\n\t// Return an ordinal from an integer.\n\tstatic String getOrdinal(int i);\n\t// Checks if b is the first byte of a UTF-8 character.\n\tstatic boolean isUtfStartByte(byte b);\n}", "des": "Util functions for GenericUDF classes."}
{"index": 2044, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFValidateAcidSortOrder {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDFValidateAcidSortOrder."}
{"index": 2045, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDFWhen {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\t// Returns the StatEstimator for the given UDF instance.\n\tStatEstimator getStatEstimator();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "GenericUDF Class for SQL construct \"CASE WHEN a THEN b WHEN c THEN d [ELSE f] END\". NOTES: 1. a and c should be boolean, or an exception will be thrown. 2. b, d and f should be common types, or an exception will be thrown."}
{"index": 2046, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFExplode {\n\t// Called to notify the UDTF that there are no more rows to process.\n\tvoid close();\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] args);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] o);\n}", "des": "GenericUDTFExplode."}
{"index": 2047, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFGetSplits2 {\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] arguments);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] arguments);\n}", "des": "GenericUDTFGetSplits2 - Memory efficient version of GenericUDTFGetSplits. It separates out information like schema and planBytes[] which is common to all the splits. This produces output in following format."}
{"index": 2048, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFGetSQLSchema {\n\t// Called to notify the UDTF that there are no more rows to process.\n\tvoid close();\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] arguments);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] arguments);\n}", "des": "GenericUDTFGetSQLSchema."}
{"index": 2049, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFJSONTuple {\n\t// Called to notify the UDTF that there are no more rows to process.\n\tvoid close();\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] args);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] o);\n}", "des": "GenericUDTFJSONTuple: this"}
{"index": 2050, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFParseUrlTuple {\n\t// Called to notify the UDTF that there are no more rows to process.\n\tvoid close();\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] args);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] o);\n}", "des": "GenericUDTFParseUrlTuple: this"}
{"index": 2051, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFPosExplode {\n\t// Called to notify the UDTF that there are no more rows to process.\n\tvoid close();\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] args);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] o);\n}", "des": "PosExplode."}
{"index": 2052, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFReplicateRows {\n\t// Called to notify the UDTF that there are no more rows to process.\n\tvoid close();\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] args);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] args);\n}", "des": "Takes a row of data and repeats n times."}
{"index": 2053, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenericUDTFStack {\n\t// Called to notify the UDTF that there are no more rows to process.\n\tvoid close();\n\t// Initialize this GenericUDTF.\n\tStructObjectInspector initialize(ObjectInspector[] args);\n\t// Give a set of arguments for the UDTF to process.\n\tvoid process(Object[] args);\n}", "des": "Takes a row of size k of data and splits it into n rows of data. For example, if n is 3 then the rest of the arguments are split in order into 3 rows, each of which has k/3 columns in it (the first emitted row has the first k/3, the second has the second, etc). If n does not divide k then the remaining columns are padded with NULLs."}
{"index": 2054, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class GenTezWorkWalker {\n\t// starting point for walking.\n\tvoid startWalking(Collection<Node> startNodes, HashMap<Node,Object> nodeOutput);\n\t// Walk the given operator.\n\tprotected void walk(Node nd);\n}", "des": "Walks the operator tree in DFS fashion."}
{"index": 2055, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum GroupByDesc.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GroupByDesc.Mode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GroupByDesc.Mode[] values();\n}", "des": "Mode."}
{"index": 2056, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface HiveDriverRunHook {\n\t// Invoked after Hive performs any processing of a command, just before a response is returned to the entity calling the Driver.\n\tvoid postDriverRun(HiveDriverRunHookContext hookContext);\n\t// Invoked before Hive begins any processing of a command in the Driver, notably before compilation and any customizable performance logging.\n\tvoid preDriverRun(HiveDriverRunHookContext hookContext);\n}", "des": "HiveDriverRunHook allows Hive to be extended with custom logic for processing commands."}
{"index": 2057, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class HiveFunctionInfo {\n\t// Get a new GenericUDF object for the function.\n\tGenericUDF getGenericUDF();\n\t// Get a new GenericUDTF object for the function.\n\tGenericUDTF getGenericUDTF();\n}", "des": "FunctionInfo implementation for Hive."}
{"index": 2058, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HiveHistory.Keys {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveHistory.Keys valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveHistory.Keys[] values();\n}", "des": "Keys."}
{"index": 2059, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HiveHistory.RecordTypes {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveHistory.RecordTypes valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveHistory.RecordTypes[] values();\n}", "des": "RecordTypes."}
{"index": 2060, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class HiveHooks {\n\t// Add the hook corresponding to the specific hook type.\n\tvoid addHook(HookContext.HookType type, Object hook);\n\tList getHooks(HookContext.HookType type);\n\t// Get all hooks corresponding to the specific hook type.\n\t<T> List<T> getHooks(HookContext.HookType type, Class<T> clazz);\n}", "des": "Loads and stores different kinds of hooks, provides addHook(HookContext.HookType, Object)} to add hook alone or getHooks(HookContext.HookType, Class) to get all hooks corresponding to the specific hook type."}
{"index": 2061, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface HiveMetastoreAuthorizationProvider {\n\t// Authorize metastore authorization api call.\n\tvoid authorizeAuthorizationApiInvocation();\n\tHivePolicyProvider getHivePolicyProvider();\n\t// Allows invoker of HiveMetaStoreAuthorizationProvider to send in a hive metastore handler that can be used to make calls to test whether or not authorizations can/will succeed.\n\tvoid setMetaStoreHandler(IHMSHandler handler);\n}", "des": "HiveMetastoreAuthorizationProvider : An extension of HiveAuthorizationProvider that is intended to be called from the metastore-side. It will be invoked by AuthorizationPreEventListener."}
{"index": 2062, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HiveMetaStoreClientWithLocalCache.KeyType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveMetaStoreClientWithLocalCache.KeyType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveMetaStoreClientWithLocalCache.KeyType[] values();\n}", "des": "KeyType is used to differentiate the request types. More types can be added in future. We added the unique classes that are part of the key for each request as well as the class of the value stored in the cache: At initialization time, they will be registered within the size estimator, which will be used to estimate the size of the objects within the cache."}
{"index": 2063, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HiveOperationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveOperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveOperationType[] values();\n}", "des": "List of hive operations types."}
{"index": 2064, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HivePrivilegeObject.HivePrivilegeObjectType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HivePrivilegeObject.HivePrivilegeObjectType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HivePrivilegeObject.HivePrivilegeObjectType[] values();\n}", "des": "Note that GLOBAL, PARTITION, COLUMN fields are populated only for Hive's old default authorization mode. When the authorization manager is an instance of HiveAuthorizerFactory, these types are not used."}
{"index": 2065, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HivePrivilegeObject.HivePrivObjectActionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HivePrivilegeObject.HivePrivObjectActionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HivePrivilegeObject.HivePrivObjectActionType[] values();\n}", "des": "When HiveOperationType is QUERY, this action type is set so that it is possible to determine if the action type on this object is an INSERT or INSERT_OVERWRITE"}
{"index": 2066, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class HivePrivilegeObjectUtils {\n\t// Convert list of dbnames into list of HivePrivilegeObject\n\tstatic List<HivePrivilegeObject> getHivePrivDbObjects(List<String> dbList);\n\t// Convert list of dcnames into list of HivePrivilegeObject\n\tstatic List<HivePrivilegeObject> getHivePrivDcObjects(List<String> dcList);\n}", "des": "Utility functions for working with HivePrivilegeObject"}
{"index": 2067, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HiveRelOptMaterialization.RewriteAlgorithm {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveRelOptMaterialization.RewriteAlgorithm valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveRelOptMaterialization.RewriteAlgorithm[] values();\n}", "des": "Enumeration of Materialized view query rewrite algorithms."}
{"index": 2068, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HiveResourceACLs.AccessResult {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveResourceACLs.AccessResult valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveResourceACLs.AccessResult[] values();\n}", "des": "Privilege access result."}
{"index": 2069, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum HiveResourceACLs.Privilege {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveResourceACLs.Privilege valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveResourceACLs.Privilege[] values();\n}", "des": "Privilege types."}
{"index": 2070, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface HiveSemanticAnalyzerHook {\n\t// Invoked after Hive performs its own semantic analysis on a statement (including optimization).\n\tvoid postAnalyze(HiveSemanticAnalyzerHookContext context, List<Task<?>> rootTasks);\n\t// Invoked before Hive performs its own semantic analysis on a statement.\n\tASTNode preAnalyze(HiveSemanticAnalyzerHookContext context, ASTNode ast);\n}", "des": "HiveSemanticAnalyzerHook allows Hive to be extended with custom logic for semantic analysis of QL statements. This interface and any Hive internals it exposes are currently \"limited private and evolving\" (unless otherwise stated elsewhere) and intended mainly for use by the Howl project."}
{"index": 2071, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class HiveTableName {\n\t// Accepts qualified name which is in the form of table, dbname.tablename or catalog.dbname.tablename and returns a TableName.\n\tstatic TableName of(String dbTableName);\n\t// Get a TableName object based on a Table.\n\tstatic TableName of(Table table);\n\t// Set a @Table object's table and db names based on the provided string.\n\tstatic Table setFrom(String dbTable, Table table);\n}", "des": "A utility class for TableName."}
{"index": 2072, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class HybridHashTableConf {\n\t// Check if a partition should be spilled directly on creation\n\tboolean doSpillOnCreation(int partitionId);\n\tList<HybridHashTableContainer> getLoadedContainerList();\n\tint getNextSpillPartition();\n\tint getNumberOfPartitions();\n\tvoid setNextSpillPartition(int nextSpillPartition);\n\tvoid setNumberOfPartitions(int numberOfPartitions);\n\t// Spill one in-memory partition from tail for all previously loaded HybridHashTableContainers.\n\tlong spill();\n}", "des": "This conf class is a wrapper of a list of HybridHashTableContainers and some common info shared among them, which is used in n-way join (multiple small tables are involved)."}
{"index": 2073, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class JoinCondTypeCheckProcFactory<T> {\n\t// Factory method to get ColumnExprProcessor.\n\tprotected TypeCheckProcFactory.ColumnExprProcessor getColumnExprProcessor();\n\t// Factory method to get DefaultExprProcessor.\n\tprotected TypeCheckProcFactory.DefaultExprProcessor getDefaultExprProcessor();\n}", "des": "TODO: 1. Could we use combined RR instead of list of RR ? 2. Use Column Processing from TypeCheckProcFactory 3. Why not use GB expr ?"}
{"index": 2074, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum JoinOperator.SkewkeyTableCounter {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JoinOperator.SkewkeyTableCounter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JoinOperator.SkewkeyTableCounter[] values();\n}", "des": "SkewkeyTableCounter."}
{"index": 2075, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum JoinType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JoinType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JoinType[] values();\n}", "des": "JoinType."}
{"index": 2076, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum JoinUtil.JoinResult {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JoinUtil.JoinResult valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JoinUtil.JoinResult[] values();\n}", "des": "Represents the join result between two tables"}
{"index": 2077, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class JsonFileStorageFormatDescriptor {\n\t// Return the name of the input format as a string\n\tString getInputFormat();\n\t// Return the set of names this storage format is known as.\n\tSet<String> getNames();\n\t// Return the name of the output format as a string\n\tString getOutputFormat();\n\t// Return the name of the serde as a string or null\n\tString getSerde();\n}", "des": "A storage format descriptor class to support \"STORED AS JSONFILE\" syntax."}
{"index": 2078, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class KeyValueInputMerger {\n\t// Cleanup references\n\tvoid clean();\n\tObject getCurrentKey();\n\tObject getCurrentValue();\n\tboolean next();\n\t// Set the IOContext reference so that input path can be changed.\n\tvoid setIOCxt(IOContext ioCxt);\n}", "des": "A KeyValuesReader implementation that returns a sorted stream of key-values by doing a sorted merge of the key-value in LogicalInputs. Tags are in the last byte of the key, so no special handling for tags is required. Uses a priority queue to pick the KeyValuesReader of the input that is next in sort order."}
{"index": 2079, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface KeyValuesAdapter {\n\t// Get the key for current record\n\tObject getCurrentKey();\n\t// Get the values for the current record\n\tIterable<Object> getCurrentValues();\n\t// Move to the next record\n\tboolean next();\n}", "des": "Key-values interface for the Reader used by ReduceRecordSource"}
{"index": 2080, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class KeyValuesFromKeyValue {\n\t// Get the key for current record\n\tObject getCurrentKey();\n\t// Get the values for the current record\n\tIterable<Object> getCurrentValues();\n\t// Move to the next record\n\tboolean next();\n}", "des": "Provides a key/values (note the plural values) interface out of a KeyValueReader, needed by ReduceRecordSource when reading input from a key/value source."}
{"index": 2081, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class KeyValuesFromKeyValues {\n\t// Get the key for current record\n\tObject getCurrentKey();\n\t// Get the values for the current record\n\tIterable<Object> getCurrentValues();\n\t// Move to the next record\n\tboolean next();\n}", "des": "Provides a key/values interface out of a KeyValuesReader for use by ReduceRecordSource."}
{"index": 2082, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LateralViewForwardOperator {\n\tString getName();\n\tstatic String getOperatorName();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Decides whether two operators are logically the same.\n\tboolean logicalEquals(Operator other);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "LateralViewForwardOperator. This operator sits at the head of the operator DAG for a lateral view. This does nothing, but it aids the predicate push down during traversal to identify when a lateral view occurs."}
{"index": 2083, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LBExprProcFactory {\n\t// Generates the list bucketing pruner for the expression tree.\n\tstatic ExprNodeDesc genPruner(String tabAlias, ExprNodeDesc pred, Partition part);\n\t// Instantiate column processor.\n\tstatic SemanticNodeProcessor getColumnProcessor();\n}", "des": "Expression processor factory for list bucketing pruning. Each processor tries to convert the expression subtree into a list bucketing pruning expression. This expression is then used to figure out which skewed value to be used"}
{"index": 2084, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LBOpPartitionWalkerCtx {\n\t// Return parse context.\n\tParseContext getParseContext();\n\t// Return partitions.\n\tPrunedPartitionList getPartitions();\n\t// Set partitions.\n\tvoid setPartitions(PrunedPartitionList partitions);\n}", "des": "Context used by list bucketing pruner to get all partitions"}
{"index": 2085, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LimitDesc {\n\tint getLeastRows();\n\tint getLimit();\n\tLimitDesc.LimitOperatorExplainVectorization getLimitVectorization();\n\t// not to print the offset if it is 0 we need to turn null.\n\tInteger getOffset();\n\t// The default implementation delegates to Object.equals(Object).\n\tboolean isSame(OperatorDesc other);\n\tvoid setLeastRows(int leastRows);\n\tvoid setLimit(int limit);\n\tvoid setOffset(Integer offset);\n}", "des": "LimitDesc."}
{"index": 2086, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LineageCtx {\n\t// Gets the dependency index.\n\tLineageCtx.Index getIndex();\n\t// Gets the new dependency type by comparing the old dependency type and the current dependency type.\n\tstatic LineageInfo.DependencyType getNewDependencyType(LineageInfo.DependencyType old_type, LineageInfo.DependencyType curr_type);\n\t// Gets the parse context.\n\tParseContext getParseCtx();\n}", "des": "This class contains the lineage context that is passed while walking the operator tree in Lineage. The context contains the LineageInfo structure that is passed to the pre-execution hooks."}
{"index": 2087, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LineageInfo {\n\tTreeSet<String> getInputTableList();\n\t// parses given query and gets the lineage info.\n\tvoid getLineageInfo(String query, Context ctx);\n\tTreeSet<String> getOutputTableList();\n\tstatic void main(String[] args);\n\t// Implements the process method for the NodeProcessor interface.\n\tObject process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx, Object... nodeOutputs);\n}", "des": "This class prints out the lineage info. It takes sql as input and prints lineage info. Currently this prints only input and output tables for a given sql. Later we can expand to add join tables etc."}
{"index": 2088, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum LineageInfo.DependencyType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LineageInfo.DependencyType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LineageInfo.DependencyType[] values();\n}", "des": "Enum to track dependency. This enum has the following values: 1. SIMPLE - Indicates that the column is derived from another table column with no transformations e.g. T2.c1 = T1.c1. 2. EXPRESSION - Indicates that the column is derived from a UDF, UDAF, UDTF or set operations like union on columns on other tables e.g. T2.c1 = T1.c1 + T3.c1. 4. SCRIPT - Indicates that the column is derived from the output of a user script through a TRANSFORM, MAP or REDUCE syntax or from the output of a PTF chain execution."}
{"index": 2089, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LineageLogger {\n\t// Based on the final select operator, find out all the target columns.\n\tstatic List<LineageLogger.Edge> getEdges(QueryPlan plan, LineageCtx.Index index);\n\t// Get all the vertices of all edges.\n\tstatic Set<LineageLogger.Vertex> getVertices(List<LineageLogger.Edge> edges);\n\tvoid run(HookContext hookContext);\n}", "des": "Implementation of a post execute hook that logs lineage info to a log file."}
{"index": 2090, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum LineageLogger.Edge.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LineageLogger.Edge.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LineageLogger.Edge.Type[] values();\n}", "des": "The types of Edge."}
{"index": 2091, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum LineageLogger.Vertex.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LineageLogger.Vertex.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LineageLogger.Vertex.Type[] values();\n}", "des": "A type in lineage."}
{"index": 2092, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ListBucketingPruner {\n\t// Prunes to the directories which match the skewed keys in where clause.\n\tstatic org.apache.hadoop.fs.Path[] prune(ParseContext ctx, Partition part, ExprNodeDesc pruner);\n\t// All transformation steps implement this interface.\n\tParseContext transform(ParseContext pctx);\n}", "des": "The transformation step that does list bucketing pruning."}
{"index": 2093, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ListSinkOperator {\n\tString getName();\n\tint getNumRows();\n\tstatic String getOperatorName();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Decides whether two operators are logically the same.\n\tboolean logicalEquals(Operator other);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n\tvoid reset(List res);\n}", "des": "For fetch task with operator tree, row read from FetchOperator is processed via operator tree and finally arrives to this operator."}
{"index": 2094, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LlapObjectCache {\n\tvoid release(String key);\n\t// Removes the specified key from the object cache.\n\tvoid remove(String key);\n\t// Retrieve object from cache.\n\t<T> T retrieve(String key);\n\t// Retrieve object from cache.\n\t<T> T retrieve(String key, Callable<T> fn);\n\t// Retrieve object from cache asynchronously.\n\t<T> Future<T> retrieveAsync(String key, Callable<T> fn);\n}", "des": "LlapObjectCache. Llap implementation for the shared object cache."}
{"index": 2095, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColAddDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 2096, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColAddDoubleScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 2097, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColAddLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 2098, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColAddLongScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 2099, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColModuloDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnDivideColumn.txt, which covers division and modulo expressions between columns."}
{"index": 2100, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColModuloLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnDivideColumn.txt, which covers division and modulo expressions between columns."}
{"index": 2101, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColMultiplyDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 2102, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColMultiplyDoubleScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 2103, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColMultiplyLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 2104, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColMultiplyLongScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 2105, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColSubtractDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 2106, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColSubtractDoubleScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 2107, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColSubtractLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticColumn.txt, which covers binary arithmetic expressions between columns."}
{"index": 2108, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColSubtractLongScalarChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnArithmeticScalar.txt, which covers binary arithmetic expressions between a column and a scalar."}
{"index": 2109, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongColUnaryMinusChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ColumnUnaryMinus.txt, which covers unary negation operator."}
{"index": 2110, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongScalarAddDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 2111, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongScalarAddLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 2112, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongScalarMultiplyDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 2113, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongScalarMultiplyLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 2114, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongScalarSubtractDoubleColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 2115, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class LongScalarSubtractLongColumnChecked {\n\t// This is the primary method to implement expression logic.\n\tvoid evaluate(VectorizedRowBatch batch);\n\tVectorExpressionDescriptor.Descriptor getDescriptor();\n\t// A vector expression which implements a checked execution to account for overflow handling should override this method and return true.\n\tboolean supportsCheckedExecution();\n\tString vectorExpressionParameters();\n}", "des": "Generated from template ScalarArithmeticColumn.txt. Implements a vectorized arithmetic operator with a scalar on the left and a column vector on the right. The result is output to an output column vector."}
{"index": 2116, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class MapAggrMemErrorHeuristic {\n\t// Examine the hive query, job configuration, and the lines from the task log seen so far though processLogLine() and generate a possible cause/solution.\n\tErrorAndSolution getErrorAndSolution();\n\t// Initialize this error heuristic.\n\tvoid init(String query, org.apache.hadoop.mapred.JobConf conf);\n}", "des": "Detects out-of-memory errors when hash tables in map-based aggregation group by queries take up too much memory. Conditions to check 1. The query contains a group by. 2. Map-side aggregation is turned on. 3. There is a out of memory exception in the log."}
{"index": 2117, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class MemoryInfo {\n\t// Get the Container max Memory value in bytes.\n\tlong getMaxExecutorMemory();\n\t// Returns True when in LLAP execution mode.\n\tboolean isLlap();\n\t// Returns True when in TEZ execution mode.\n\tboolean isTez();\n}", "des": "Contains information about executor memory, various memory thresholds used for join conversions etc. based on execution engine."}
{"index": 2118, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class MergeFileTask {\n\tboolean checkFatalErrors(org.apache.hadoop.mapred.Counters ctrs, StringBuilder errMsg);\n\t// start a new map-reduce job to do the merge, almost the same as ExecDriver.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n\tvoid initialize(QueryState queryState, QueryPlan queryPlan, TaskQueue taskQueue, Context context);\n\tvoid logPlanProgress(SessionState ss);\n\tboolean requireLock();\n}", "des": "Task for fast merging of ORC and RC files."}
{"index": 2119, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Metadata.ReplicationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Metadata.ReplicationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Metadata.ReplicationType[] values();\n}", "des": "Type of replication."}
{"index": 2120, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class MetricsQueryLifeTimeHook {\n\t// Invoked after a query compilation.\n\tvoid afterCompile(QueryLifeTimeHookContext ctx, boolean hasError);\n\t// Invoked after a query finishes its execution.\n\tvoid afterExecution(QueryLifeTimeHookContext ctx, boolean hasError);\n\t// Invoked before a query enters the compilation phase.\n\tvoid beforeCompile(QueryLifeTimeHookContext ctx);\n\t// Invoked before a query enters the execution phase.\n\tvoid beforeExecution(QueryLifeTimeHookContext ctx);\n}", "des": "LifeTimeHook gathering metrics for the query lifecycle if the metrics are enabled"}
{"index": 2121, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class MoveTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n\tboolean hasFollowingStatsTask();\n\tboolean isLocal();\n\tvoid logMessage(LoadTableDesc tbd);\n}", "des": "MoveTask implementation."}
{"index": 2122, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class NanoTimeUtils {\n\t// Converts a timestamp from the specified timezone to UTC and returns its representation in NanoTime.\n\tstatic NanoTime getNanoTime(Timestamp ts, ZoneId sourceZone, boolean legacyConversion);\n\tstatic Timestamp getTimestamp(NanoTime nt, ZoneId targetZone);\n\t// Converts a nanotime representation in UTC, to a timestamp in the specified timezone.\n\tstatic Timestamp getTimestamp(NanoTime nt, ZoneId targetZone, boolean legacyConversion);\n}", "des": "Utilities for converting from java.sql.Timestamp to parquet timestamp. This utilizes the Jodd library."}
{"index": 2123, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class NonSyncDataOutputBuffer {\n\t// Returns the current contents of the buffer.\n\tbyte[] getData();\n\t// Returns the length of the valid data currently in the buffer.\n\tint getLength();\n\t// Resets the buffer to empty.\n\tNonSyncDataOutputBuffer reset();\n\tvoid write(byte[] b, int off, int len);\n\t// Writes bytes from a DataInput directly into the buffer.\n\tvoid write(DataInput in, int length);\n\tvoid write(int b);\n}", "des": "A thread-not-safe version of Hadoop's DataOutputBuffer, which removes all synchronized modifiers."}
{"index": 2124, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ObjectCache {\n\tvoid release(String key);\n\t// Removes the specified key from the object cache.\n\tvoid remove(String key);\n\t// Retrieve object from cache.\n\t<T> T retrieve(String key);\n\t// Retrieve object from cache.\n\t<T> T retrieve(String key, Callable<T> fn);\n\t// Retrieve object from cache asynchronously.\n\t<T> Future<T> retrieveAsync(String key, Callable<T> fn);\n}", "des": "ObjectCache. Simple implementation on MR we don't have a means to reuse Objects between runs of the same task, this acts as a local cache."}
{"index": 2125, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface ObjectCache {\n\tvoid release(String key);\n\t// Removes the specified key from the object cache.\n\tvoid remove(String key);\n\t// Retrieve object from cache.\n\t<T> T retrieve(String key);\n\t// Retrieve object from cache.\n\t<T> T retrieve(String key, Callable<T> fn);\n\t// Retrieve object from cache asynchronously.\n\t<T> Future<T> retrieveAsync(String key, Callable<T> fn);\n}", "des": "ObjectCache. Interface for maintaining objects associated with a task."}
{"index": 2126, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ObjectCacheFactory {\n\t// Returns the appropriate cache\n\tstatic ObjectCache getCache(org.apache.hadoop.conf.Configuration conf, String queryId, boolean isPlanCache);\n\t// Returns the appropriate cache\n\tstatic ObjectCache getCache(org.apache.hadoop.conf.Configuration conf, String queryId, boolean isPlanCache, boolean llapCacheAlwaysEnabled);\n\tstatic void removeLlapQueryCache(String queryId);\n}", "des": "ObjectCacheFactory returns the appropriate cache depending on settings in the hive conf."}
{"index": 2127, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Operation2Privilege {\n\tstatic Set<HiveOperationType> getOperationTypes();\n\t// Get the privileges required for this operation (hiveOpType) on hive object (hObj) when its IOType is ioType.\n\tstatic RequiredPrivileges getRequiredPrivs(HiveOperationType hiveOpType, HivePrivilegeObject hObj, Operation2Privilege.IOType ioType);\n\t// Some operations are tagged as requiring admin privileges, ignoring any object that might be checked on it.\n\tstatic boolean isAdminPrivOperation(HiveOperationType hiveOpType);\n}", "des": "Mapping of operation to its required input and output privileges"}
{"index": 2128, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class OperationLog {\n\t// Close this OperationLog when operation is closed.\n\tvoid close();\n\tstatic OperationLog.LoggingLevel getLoggingLevel(String mode);\n\tOperationLog.LoggingLevel getOpLoggingLevel();\n\t// Read operation execution logs from log file\n\tList<String> readOperationLog(boolean isFetchFirst, long maxRows);\n}", "des": "OperationLog wraps the actual operation log file, and provides interface for accessing, reading, writing, and removing the file."}
{"index": 2129, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Operator.Counter {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Operator.Counter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Operator.Counter[] values();\n}", "des": "Counters."}
{"index": 2130, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Operator.State {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Operator.State valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Operator.State[] values();\n}", "des": "State."}
{"index": 2131, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Optimizer {\n\tParseContext getPctx();\n\t// Create the list of transformations.\n\tvoid initialize(HiveConf hiveConf);\n\t// Invoke all the transformations one-by-one, and alter the query plan.\n\tParseContext optimize();\n\tvoid setPctx(ParseContext pctx);\n}", "des": "Implementation of the optimizer."}
{"index": 2132, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class OrcFileMergeOperator {\n\t// Operator specific close routine.\n\tvoid closeOp(boolean abort);\n\tString getName();\n\tstatic String getOperatorName();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "Fast file merge operator for ORC files."}
{"index": 2133, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum PlanUtils.ExpressionTypes {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PlanUtils.ExpressionTypes valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PlanUtils.ExpressionTypes[] values();\n}", "des": "ExpressionTypes."}
{"index": 2134, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum PrivilegeScope {\n\tshort getMode();\n\tvoid setMode(short mode);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PrivilegeScope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PrivilegeScope[] values();\n}", "des": "PrivilegeScope describes a hive defined privilege's scope (global/database/table/column). For example some hive privileges are db-level only, some are global, and some are table only."}
{"index": 2135, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ProactiveEviction.Request {\n\tMap<String,Map<String,Set<LinkedHashMap<String,String>>>> getEntities();\n\t// Request often times only contains tables/partitions of 1 DB only.\n\tString getSingleDbName();\n\tboolean isEmpty();\n\t// Match a CacheTag to this eviction request.\n\tboolean isTagMatch(CacheTag cacheTag);\n\t// Translate to Protobuf requests.\n\tList<org.apache.hadoop.hive.llap.daemon.rpc.LlapDaemonProtocolProtos.EvictEntityRequestProto> toProtoRequests();\n}", "des": "Holds information on entities: DB name(s), table name(s), partitions."}
{"index": 2136, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class PrunerExpressionOperatorFactory {\n\t// Instantiate default expression processor.\n\tstatic SemanticNodeProcessor getDefaultExprProcessor();\n\t// Instantiate field processor.\n\tstatic SemanticNodeProcessor getFieldProcessor();\n\t// Instantiate generic function processor.\n\tstatic SemanticNodeProcessor getGenericFuncProcessor();\n}", "des": "Expression processor factory for pruning. Each processor tries to convert the expression subtree into a pruning expression. It can be used for partition prunner and list bucketing pruner."}
{"index": 2137, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class PrunerExpressionOperatorFactory.ColumnExprProcessor {\n\t// Generic process for all ops that don't have specific implementations.\n\tObject process(Node nd, Stack<Node> stack, NodeProcessorCtx procCtx, Object... nodeOutputs);\n\t// Process column desc.\n\tprotected abstract ExprNodeDesc processColumnDesc(NodeProcessorCtx procCtx, ExprNodeColumnDesc cd);\n}", "des": "Processor for column expressions."}
{"index": 2138, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class PrunerUtils {\n\t// Walk expression tree for pruner generation.\n\tstatic Map<Node,Object> walkExprTree(ExprNodeDesc pred, NodeProcessorCtx ctx, SemanticNodeProcessor colProc, SemanticNodeProcessor fieldProc, SemanticNodeProcessor genFuncProc, SemanticNodeProcessor defProc);\n\t// Walk operator tree for pruner generation.\n\tstatic void walkOperatorTree(ParseContext pctx, NodeProcessorCtx opWalkerCtx, SemanticNodeProcessor filterProc, SemanticNodeProcessor defaultProc);\n}", "des": "General utility common functions for the Pruner to do optimization."}
{"index": 2139, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class PTFRowContainer<Row extends List<Object>> {\n\t// add a row into the RowContainer\n\tvoid addRow(Row t);\n\t// Remove all elements in the RowContainer.\n\tvoid clearRows();\n\tvoid close();\n\tstatic TableDesc createTableDesc(StructObjectInspector oI);\n\tRow first();\n\tRow getAt(int rowIdx);\n\tRow next();\n}", "des": "Extends the RowContainer functionality to provide random access getAt(i). It extends RowContainer behavior in the following ways: You must continue to call first to signal the transition from writing to the Container to reading from it. As rows are being added, positions at which a spill occurs is captured as a BlockInfo object. At this point it captures the offset in the File at which the current Block will be written. When first is called: we associate with each BlockInfo the File Split that it occurs in. So in order to read a random row from the Container we do the following: Convert the row index into a block number. This is easy because all blocks are the same size, given by the blockSize The corresponding BlockInfo tells us the Split that this block starts in. Also by looking at the next Block in the BlockInfos list, we know which Split this block ends in. So we arrange to read all the Splits that contain rows for this block. For the first Split we seek to the startOffset that we captured in BlockInfo. So after reading the Splits, all rows in this block are in the 'currentReadBlock' We track the span of the currentReadBlock, using currentReadBlockStartRow,blockSize. So if a row is requested in this span, we don't need to read rows from disk. If the requested row is in the 'last' block; we point the currentReadBlock to the currentWriteBlock; the same as what RowContainer does. the getAt leaves the Container in the same state as a next call; so a getAt and next calls can be interspersed."}
{"index": 2140, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum QBExpr.Opcode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QBExpr.Opcode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QBExpr.Opcode[] values();\n}", "des": "Opcode."}
{"index": 2141, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface QueryLifeTimeHook {\n\t// Invoked after a query compilation.\n\tvoid afterCompile(QueryLifeTimeHookContext ctx, boolean hasError);\n\t// Invoked after a query finishes its execution.\n\tvoid afterExecution(QueryLifeTimeHookContext ctx, boolean hasError);\n\t// Invoked before a query enters the compilation phase.\n\tvoid beforeCompile(QueryLifeTimeHookContext ctx);\n\t// Invoked before a query enters the execution phase.\n\tvoid beforeExecution(QueryLifeTimeHookContext ctx);\n}", "des": "A type of hook which triggers before query compilation and after query execution."}
{"index": 2142, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface QueryLifeTimeHookContext {\n\t// Get the current command.\n\tString getCommand();\n\t// Get the current Hive configuration\n\tHiveConf getHiveConf();\n\t// Get the hook context for query execution.\n\tHookContext getHookContext();\n\t// Set the current command\n\tvoid setCommand(String command);\n\t// Set Hive configuration\n\tvoid setHiveConf(HiveConf conf);\n\t// Set the hook context\n\tvoid setHookContext(HookContext hc);\n}", "des": "Hook context for QueryLifeTimeHook."}
{"index": 2143, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface QueryLifeTimeHookWithParseHooks {\n\t// Invoked after a query parsing.\n\tvoid afterParse(QueryLifeTimeHookContext ctx, boolean hasError);\n\t// Invoked before a query enters the parse phase.\n\tvoid beforeParse(QueryLifeTimeHookContext ctx);\n}", "des": "Extension of QueryLifeTimeHook that has hooks for pre and post parsing of a query."}
{"index": 2144, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class RangerDenyTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "RangerDenyTask. Task to add Ranger Deny Policy"}
{"index": 2145, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class RangerDumpTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "RangerDumpTask. Exports the Ranger security policies to staging directory."}
{"index": 2146, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class RangerLoadTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "RangerLoadTask. Rask to import Ranger authorization policies."}
{"index": 2147, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class RCFile.Writer {\n\t// Append a row of values.\n\tvoid append(org.apache.hadoop.io.Writable val);\n\tvoid close();\n\t// flush a block out without doing anything except compressing the key part.\n\tvoid flushBlock(RCFile.KeyBuffer keyBuffer, RCFile.ValueBuffer valueBuffer, int recordLen, int keyLength, int compressedKeyLen);\n\tlong getLength();\n\t// create a sync point.\n\tvoid sync();\n}", "des": "Write KeyBuffer/ValueBuffer pairs to a RCFile. RCFile's format is compatible with SequenceFile's."}
{"index": 2148, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class RCFileMergeOperator {\n\t// Operator specific close routine.\n\tvoid closeOp(boolean abort);\n\tString getName();\n\tstatic String getOperatorName();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "Fast file merge operator for RC files."}
{"index": 2149, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ReCompileWithoutCBOPlugin {\n\t// Called when the Driver is being initialized The plugin may add hooks/etc to tap into the system.\n\tvoid initialize(Driver driver);\n\t// The plugin should prepare for the recompilation of the query\n\tvoid prepareToReCompile();\n\t// The query has failed.\n\tboolean shouldReCompile(int executionNum);\n}", "des": "Re-compiles the query without CBO"}
{"index": 2150, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum RecordIdentifier.Field {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RecordIdentifier.Field valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RecordIdentifier.Field[] values();\n}", "des": "This is in support of VirtualColumn.ROWID Contains metadata about each field in RecordIdentifier that needs to be part of ROWID which is represented as a struct RecordIdentifier.StructInfo. Each field of RecordIdentifier which should be part of ROWID should be in this enum... which really means that it should be part of VirtualColumn (so make a subclass for rowid)."}
{"index": 2151, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface RecordReader {\n\t// Does the reader have more rows available.\n\tboolean hasNext();\n\t// Read the next row.\n\tObject next(Object previous);\n}", "des": "A row-by-row iterator for ORC files."}
{"index": 2152, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ReExecuteLostAMQueryPlugin {\n\t// Called when the Driver is being initialized The plugin may add hooks/etc to tap into the system.\n\tvoid initialize(Driver driver);\n\t// The query have failed, does this plugin advises to re-execute it again?\n\tboolean shouldReExecute(int executionNum);\n\t// The query has failed; and have been recompiled - does this plugin advises to re-execute it again?\n\tboolean shouldReExecuteAfterCompile(int executionNum, PlanMapper oldPlanMapper, PlanMapper newPlanMapper);\n}", "des": "Re-Executes a query if tez AM failed because of node/container failure."}
{"index": 2153, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ReExecutionDagSubmitPlugin {\n\t// Called when the Driver is being initialized The plugin may add hooks/etc to tap into the system.\n\tvoid initialize(Driver driver);\n\t// The query have failed, does this plugin advises to re-execute it again?\n\tboolean shouldReExecute(int executionNum);\n\t// The query has failed; and have been recompiled - does this plugin advises to re-execute it again?\n\tboolean shouldReExecuteAfterCompile(int executionNum, PlanMapper pm1, PlanMapper pm2);\n}", "des": "Re-Executes a query when DAG submission fails after get session returned successfully. There could be race condition where getSession could return a healthy AM but by the time DAG is submitted the AM could become unhealthy/unreachable (possible DNS or network issues) which can fail tez DAG submission. Since the DAG hasn't started execution yet this failure can be safely restarted/retried."}
{"index": 2154, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum ReplAck {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReplAck valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReplAck[] values();\n}", "des": "ReplAck, used for repl acknowledgement constants."}
{"index": 2155, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ReplStateLogTask {\n\tboolean canExecuteInParallel();\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "ReplStateLogTask. Exists for the sole purpose of reducing the number of dependency edges in the task graph."}
{"index": 2156, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ReplTxnTask {\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\tReplTxnWork.OperationType getOperationType();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "ReplTxnTask. Used for replaying the transaction related events."}
{"index": 2157, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum ReplTxnWork.OperationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReplTxnWork.OperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReplTxnWork.OperationType[] values();\n}", "des": "OperationType. Different kind of events supported for replaying."}
{"index": 2158, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum ReplUtils.MetricName {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReplUtils.MetricName valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReplUtils.MetricName[] values();\n}", "des": "Replication Metrics."}
{"index": 2159, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum ReplUtils.ReplLoadOpType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReplUtils.ReplLoadOpType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReplUtils.ReplLoadOpType[] values();\n}", "des": "Bootstrap REPL LOAD operation type on the examined object based on ckpt state."}
{"index": 2160, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum RootAllocatorFactory {\n\torg.apache.arrow.memory.RootAllocator getOrCreateRootAllocator(long arrowAllocatorLimit);\n\torg.apache.arrow.memory.RootAllocator getRootAllocator(org.apache.hadoop.conf.Configuration conf);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RootAllocatorFactory valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RootAllocatorFactory[] values();\n}", "des": "Thread-safe singleton factory for RootAllocator"}
{"index": 2161, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ScheduledQueryMaintenanceTask {\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n}", "des": "Scheduled query maintenance task. CREATES/ALTERS or DROPs a scheduled query."}
{"index": 2162, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum ScriptOperator.Counter {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ScriptOperator.Counter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ScriptOperator.Counter[] values();\n}", "des": "Counter."}
{"index": 2163, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface SecretSource {\n\t// Get the secret associated with the given URI.\n\tString getSecret(URI uri);\n\t// The scheme string which this implementation will handle.\n\tString getURIScheme();\n}", "des": "Interface representing source of a secret using an uri. The URI scheme is used to match an URI to an implementation scheme. The implementations are discovered and loaded using java service loader. Currenty there isn't a way to initialize or reset a SecretSource after construction. The secret source is expected to be thread-safe."}
{"index": 2164, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum SessionState.ResourceType {\n\tvoid postHook(Set<String> cur, List<String> s);\n\tvoid preHook(Set<String> cur, List<String> s);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SessionState.ResourceType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SessionState.ResourceType[] values();\n}", "des": "ResourceType."}
{"index": 2165, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum SharedWorkOptimizer.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SharedWorkOptimizer.Mode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SharedWorkOptimizer.Mode[] values();\n}", "des": "SharedWorkOptimization strategy modes"}
{"index": 2166, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class SimpleGenericUDAFParameterInfo {\n\tObjectInspector[] getParameterObjectInspectors();\n\t// Returns true if the UDAF invocation was done via the wildcard syntax FUNCTION(*).\n\tboolean isAllColumns();\n\t// Returns true if the UDAF invocation was qualified with DISTINCT keyword.\n\tboolean isDistinct();\n\t// The flag to indicate if the UDAF invocation was from the windowing function call or not.\n\tboolean isWindowing();\n\tboolean respectNulls();\n}", "des": "A simple implementation of GenericUDAFParameterInfo."}
{"index": 2167, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum SnapshotUtils.SnapshotCopyMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SnapshotUtils.SnapshotCopyMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SnapshotUtils.SnapshotCopyMode[] values();\n}", "des": "Specifies the mode of copy when using Snapshots for replication."}
{"index": 2168, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class ST_GeometryRelational {\n\t// Close GenericUDF.\n\tvoid close();\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] args);\n\t// Operators that extend this should return an instance of OperatorSimpleRelation\n\tprotected abstract com.esri.core.geometry.OperatorSimpleRelation getRelationOperator();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] OIs);\n}", "des": "Abstract class that all simple relational tests (contains, touches, ...) extend from"}
{"index": 2169, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface StatsAggregator {\n\t// This method aggregates a given statistic from all tasks (partial stats).\n\tString aggregateStats(String keyPrefix, String statType);\n\t// This method closes the connection to the temporary storage.\n\tboolean closeConnection(StatsCollectionContext scc);\n\t// This method connects to the temporary storage.\n\tboolean connect(StatsCollectionContext scc);\n}", "des": "An interface for any possible implementation for gathering statistics."}
{"index": 2170, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class StatsTask {\n\t// This method is overridden in each Task.\n\tint execute();\n\tString getName();\n\t// Should be overridden to return the type of the specific task among the types in StageType.\n\tStageType getType();\n\tvoid initialize(QueryState queryState, QueryPlan queryPlan, TaskQueue taskQueue, Context context);\n\tstatic ExecutorService newThreadPool(HiveConf conf);\n\tprotected void receiveFeed(Task.FeedType feedType, Object feedValue);\n}", "des": "StatsTask implementation."}
{"index": 2171, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Status {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Status valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Status[] values();\n}", "des": "Enum to define the status."}
{"index": 2172, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface StorageFormatDescriptor {\n\t// Return the name of the input format as a string\n\tString getInputFormat();\n\t// Return the set of names this storage format is known as.\n\tSet<String> getNames();\n\t// Return the name of the output format as a string\n\tString getOutputFormat();\n\t// Return the name of the serde as a string or null\n\tString getSerde();\n}", "des": "Subclasses represent a storage format for the CREATE TABLE ... STORED AS ... command. Subclasses are found via the ServiceLoader facility."}
{"index": 2173, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class StreamUtils {\n\t// Converts stream buffers to disk ranges.\n\tstatic DiskRangeInfo createDiskRangeInfo(EncodedColumnBatch.ColumnStreamData streamBuffer);\n\t// Create SettableUncompressedStream from stream buffer.\n\tstatic SettableUncompressedStream createSettableUncompressedStream(String streamName, EncodedColumnBatch.ColumnStreamData streamBuffer);\n}", "des": "Stream utility."}
{"index": 2174, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class SyslogParser {\n\t// Free the resources used by this parser.\n\tvoid close();\n\t// Read the next Syslog message from the stream.\n\tList<Object> readEvent();\n\tvoid setInputStream(InputStream in);\n}", "des": "A Syslog protocol parser. It should be capable of parsing RFC 3164 (BSD syslog) streams as well as RFC 5424 (defined in 2009.). Adapted from https://github.com/spotify/flume-syslog-source2 and modified it for several assumptions about the way hive logs using syslog format (specifically RFC5424). This implementation also parses structured data, returns all parsed fields as map and also un-escapes messages. This parser also gracefully handles some corner cases where 'msg' can be empty or line can start with '<' but not a valid RFC5424 format etc. Assumption: 1) This parser assumes the linebreaks '\\n' in stack traces for example are replaced by '\\r' to make single line message. The reader will do replacement of '\\r' with '\\n' at the time of read. 2) This parser assumes structured data values are html escaped. So it will html unescape when parsing structured data. (hive writes log lines directly to stderr that look like rfc5424 layout starting with '<' so the expectation from log4j2 is to escape those lines using html escaping). 3) Read event returns List conforming to sys.logs table schema in hive. The schema for sys.logs table is expected to be (facility STRING, severity STRING, version STRING, ts TIMESTAMP, hostname STRING, app_name STRING, proc_id STRING, msg_id STRING, structured_data map, msg BINARY, unmatched BINARY) 4) Timestamps are in UTC This parser is tested with Log4j2's RFC5424 layout generated using the following properties appenders = console appender.console.layout.type = Rfc5424Layout appender.console.layout.appName = ${env:APP_NAME} appender.console.layout.facility = USER appender.console.layout.includeMDC = true appender.console.layout.mdcId = mdc appender.console.layout.messageId = ${env:MSG_ID} appender.console.layout.newLine = true appender.console.layout.newLineEscape = \\\\r appender.console.layout.exceptionPattern = %ex{full} appender.console.layout.loggerfields.type = LoggerFields appender.console.layout.loggerfields.pairs1.type = KeyValuePair appender.console.layout.loggerfields.pairs1.key = level appender.console.layout.loggerfields.pairs1.value = %p appender.console.layout.loggerfields.pairs2.type = KeyValuePair appender.console.layout.loggerfields.pairs2.key = thread appender.console.layout.loggerfields.pairs2.value = %enc{%t} appender.console.layout.loggerfields.pairs3.type = KeyValuePair appender.console.layout.loggerfields.pairs3.key = class appender.console.layout.loggerfields.pairs3.value = %c{2}"}
{"index": 2175, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class TableExport.Paths {\n\t// Access to the dataExportRootDir should only be done via this method since the creation of the directory is delayed until we figure out if we want to write something or not.\n\torg.apache.hadoop.fs.Path dataExportRootDir();\n\t// Access to the metadataExportRootDir should only be done via this method since the creation of the directory is delayed until we figure out if we want to write something or not.\n\torg.apache.hadoop.fs.Path metadataExportRootDir();\n}", "des": "this class is responsible for giving various paths to be used during export along with root export directory creation."}
{"index": 2176, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Task.TaskState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Task.TaskState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Task.TaskState[] values();\n}", "des": "Order of the States here is important as the ordinal values are used determine the progression of taskState over its lifeCycle which is then used to make some decisions in Driver.execute"}
{"index": 2177, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class TaskGraphWalker {\n\t// Dispatch the current operator.\n\tvoid dispatch(Node nd, Stack<Node> ndStack, TaskGraphWalker.TaskGraphWalkerContext walkerCtx);\n\tSet<Node> getDispatchedList();\n\tList<Node> getToWalk();\n\t// starting point for walking.\n\tvoid startWalking(Collection<Node> startNodes, HashMap<Node,Object> nodeOutput);\n\t// walk the current operator and its descendants.\n\tvoid walk(Node nd);\n}", "des": "base class for operator graph walker this class takes list of starting ops and walks them one by one. it maintains list of walked operators (dispatchedList) and a list of operators that are discovered but not yet dispatched"}
{"index": 2178, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class TaskLogProcessor {\n\t// Adds a task log URL for the heuristics to read through.\n\tvoid addTaskAttemptLogUrl(String url);\n\t// Processes the provided task logs using the known error heuristics to get the matching errors.\n\tList<ErrorAndSolution> getErrors();\n\t// Processes the provided task logs to extract stack traces.\n\tList<List<String>> getStackTraces();\n}", "des": "TaskLogProcessor reads the logs from failed task attempts and tries to figure out what the cause of the error was using various heuristics."}
{"index": 2179, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class TezDummyStoreOperator {\n\t// Operator specific close routine.\n\tvoid closeOp(boolean abort);\n\tboolean getFetchDone();\n\t// Unlike the MR counterpoint, on Tez we want processOp to forward the records.\n\tvoid process(Object row, int tag);\n\tvoid setFetchDone(boolean fetchDone);\n}", "des": "A dummy store operator same as the dummy store operator but for tez. This is required so that we don't check for tez everytime before forwarding a record. In tez records flow down from the dummy store operator in processOp phase unlike in map reduce."}
{"index": 2180, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class TimeCounterLimit {\n\t// Return cloned copy of this counter limit\n\tCounterLimit clone();\n\tboolean equals(Object other);\n\t// Get the threshold value for the counter\n\tlong getLimit();\n\t// Get the name of the counter.\n\tString getName();\n}", "des": "Time based counters with limits"}
{"index": 2181, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class TriggerExpression {\n\t// Return cloned copy of this expression.\n\tExpression clone();\n\tboolean equals(Object other);\n\t// Evaluate current value against this expression.\n\tboolean evaluate(long current);\n\t// Return counter limit\n\tCounterLimit getCounterLimit();\n\t// Return predicate defined in the expression.\n\tExpression.Predicate getPredicate();\n}", "des": "Simple trigger expression for a rule."}
{"index": 2182, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class TxnManagerFactory {\n\t// Create a new transaction manager.\n\tHiveTxnManager getTxnManager(HiveConf conf);\n\t// Get the singleton instance of this factory.\n\tstatic TxnManagerFactory getTxnManagerFactory();\n}", "des": "A factory to get an instance of HiveTxnManager. This should always be called rather than building a transaction manager via reflection. This factory will read the configuration file to determine which transaction manager to instantiate. It will stash the chosen transaction manager into the Context object, and subsequently return it from there so that if there are multiple Hive threads running, each will get it's appropriate transaction manager."}
{"index": 2183, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFCrc32 {\n\t// CRC32 for binary\n\torg.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.BytesWritable b);\n\t// CRC32 for string\n\torg.apache.hadoop.io.LongWritable evaluate(org.apache.hadoop.io.Text n);\n}", "des": "UDFCrc32."}
{"index": 2184, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFDayOfMonth {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFDayOfMonth."}
{"index": 2185, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFHex {\n\t// Convert bytes to a hex string\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.BytesWritable b);\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.IntWritable n);\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.LongWritable n);\n\t// Convert every character in s to two hex digits.\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text s);\n}", "des": "UDFHex."}
{"index": 2186, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFHour {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFHour."}
{"index": 2187, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFLog {\n\t// Returns the natural logarithm of \"a\".\n\tprotected DoubleWritable doEvaluate(DoubleWritable a);\n\t// Returns the logarithm of \"a\" with base \"base\".\n\tDoubleWritable evaluate(DoubleWritable base, DoubleWritable a);\n\t// Get the logarithm of the given decimal input with the given decimal base.\n\tDoubleWritable evaluate(HiveDecimalWritable baseWritable, HiveDecimalWritable writable);\n}", "des": "UDFLog."}
{"index": 2188, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFMath {\n\t// For subclass to implement.\n\tprotected abstract DoubleWritable doEvaluate(DoubleWritable a);\n\t// Returns null if the passed in value is and passes on to doEvaluate(DoubleWritable) if not.\n\tDoubleWritable evaluate(DoubleWritable a);\n\t// Convert HiveDecimal to a double and call evaluate() on it.\n\tDoubleWritable evaluate(HiveDecimalWritable writable);\n}", "des": "This class can be used for math based UDFs that only have an evaluate method for doubles. By extending from this class these UDFs will automatically support decimals as well."}
{"index": 2189, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFMd5 {\n\t// Convert bytes to md5\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.BytesWritable b);\n\t// Convert String to md5\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text n);\n}", "des": "UDFMd5."}
{"index": 2190, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFMinute {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFMinute."}
{"index": 2191, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFMonth {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFMonth."}
{"index": 2192, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFSecond {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFSecond."}
{"index": 2193, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFSha1 {\n\t// Convert bytes to SHA-1\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.BytesWritable b);\n\t// Convert String to SHA-1\n\torg.apache.hadoop.io.Text evaluate(org.apache.hadoop.io.Text n);\n}", "des": "UDFSha."}
{"index": 2194, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class UDFYear {\n\t// Evaluate the GenericUDF with the arguments.\n\tObject evaluate(GenericUDF.DeferredObject[] arguments);\n\t// Get the String to be displayed in explain.\n\tString getDisplayString(String[] children);\n\tprotected String getFuncName();\n\t// Initialize this GenericUDF.\n\tObjectInspector initialize(ObjectInspector[] arguments);\n}", "des": "UDFYear."}
{"index": 2195, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Utilities.ReduceField {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Utilities.ReduceField valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Utilities.ReduceField[] values();\n}", "des": "ReduceField: KEY: record key VALUE: record value"}
{"index": 2196, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum Utilities.StreamStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Utilities.StreamStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Utilities.StreamStatus[] values();\n}", "des": "StreamStatus."}
{"index": 2197, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Utils {\n\t// Dumps process heap.\n\tstatic void dumpHeap(String fileName, boolean live);\n\t// Dumps process heap to a file in temp directoty.\n\tstatic void dumpHeapToTmp(String... args);\n\t// Outputs some bytes as hex w/printable characters prints.\n\tstatic String toStringBinary(byte[] b, int off, int len);\n}", "des": "Debug utility methods for Hive."}
{"index": 2198, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Utils {\n\t// Find the first node of a type from ancestor stack, starting from parents.\n\tstatic <T> T findNode(Stack<Node> stack, Class<T> target);\n\t// Gets the nth ancestor (the parent being the 1st ancestor) in the traversal path.\n\tstatic Node getNthAncestor(Stack<Node> st, int n);\n}", "des": "Contains common utility functions to manipulate nodes, walkers etc."}
{"index": 2199, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorAppMasterEventOperator {\n\tVectorizationContext getInputVectorizationContext();\n\tVectorDesc getVectorDesc();\n\t// Operator specific initialization.\n\tvoid initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object data, int tag);\n}", "des": "App Master Event operator implementation."}
{"index": 2200, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorFileSinkArrowOperator {\n\t// Operator specific close routine.\n\tprotected void closeOp(boolean abort);\n\tVectorizationContext getInputVectorizationContext();\n\t// Return the type of the specific operator among the types in OperatorType.\n\tOperatorType getType();\n\tVectorDesc getVectorDesc();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object data, int tag);\n}", "des": "Native Vectorized File Sink operator implementation for Arrow. Assumes output to LlapOutputFormatService"}
{"index": 2201, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorFileSinkOperator {\n\tVectorizationContext getInputVectorizationContext();\n\tVectorDesc getVectorDesc();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object data, int tag);\n}", "des": "File Sink operator implementation."}
{"index": 2202, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorFilterOperator {\n\tVectorizationContext getInputVectorizationContext();\n\tstatic String getOperatorName();\n\tVectorExpression getPredicateExpression();\n\tVectorDesc getVectorDesc();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n\tvoid setFilterCondition(VectorExpression expr);\n}", "des": "Filter operator implementation."}
{"index": 2203, "repo": "hive-exec-4.0.0-alpha-2", "code": "Enum VectorGroupByDesc.ProcessingMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic VectorGroupByDesc.ProcessingMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic VectorGroupByDesc.ProcessingMode[] values();\n}", "des": "GLOBAL No key. All rows --> 1 full aggregation on end of input HASH Rows aggregated in to hash table on group key --> 1 partial aggregation per key (normally, unless there is spilling) MERGE_PARTIAL As first operator in a REDUCER, partial aggregations come grouped from reduce-shuffle --> aggregate the partial aggregations and emit full aggregation on endGroup / closeOp STREAMING Rows come from PARENT operator already grouped --> aggregate the rows and emit full aggregation on key change / closeOp NOTE: Hash can spill partial result rows prematurely if it runs low on memory. NOTE: Streaming has to compare keys where MergePartial gets an endGroup call."}
{"index": 2204, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface VectorizedOrcAcidRowBatchReader.DeleteEventRegistry {\n\t// The close() method can be called externally to signal the implementing classes to free up resources.\n\tvoid close();\n\t// Modifies the passed bitset to indicate which of the rows in the batch have been deleted.\n\tvoid findDeletedRecords(ColumnVector[] cols, int size, BitSet selectedBitSet);\n\tboolean isEmpty();\n}", "des": "An interface that can determine which rows have been deleted from a given vectorized row batch. Implementations of this interface will read the delete delta files and will create their own internal data structures to maintain record ids of the records that got deleted."}
{"index": 2205, "repo": "hive-exec-4.0.0-alpha-2", "code": "Interface VectorKeySeries {\n\tint getCurrentDuplicateCount();\n\tboolean getCurrentHasAnyNulls();\n\tint getCurrentHashCode();\n\tboolean getCurrentIsAllNull();\n\tint getCurrentLogical();\n\t// Move to the next key.\n\tboolean next();\n\t// Position to the beginning of the key series.\n\tvoid positionToFirst();\n\t// Process a non-empty batch of rows and compute a key series.\n\tvoid processBatch(VectorizedRowBatch batch);\n}", "des": "An abstraction of keys within a VectorizedRowBatch. A key is one or more columns. When there is a sequential \"run\" of equal keys, they are collapsed and represented by a duplicate count. The batch of keys (with sequential duplicates collapsed) is called a series. A key can be all null, or a key with no or some nulls. All keys have a duplicate count. A key with no or some nulls has: 1) A hash code. 2) Key values and other value(s) defined by other interfaces. The key series is logically indexed. That is, if batch.selectedInUse is true, the indices will be logical and need to be mapped through batch.selected to get the physical batch indices. Otherwise, the indices are physical batch indices."}
{"index": 2206, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorKeySeriesSerializedImpl<T extends SerializeWrite> {\n\t// Batch compute the hash codes for all the serialized keys.\n\tprotected void computeSerializedHashCodes();\n\tbyte[] getSerializedBytes();\n\tint getSerializedLength();\n\tint getSerializedStart();\n\t// Position to the beginning of the key series.\n\tvoid positionToFirst();\n\tvoid setNextNonNullKey(int nonNullKeyPosition);\n\tboolean validate();\n}", "des": "Implementation of base serialization interface."}
{"index": 2207, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorKeySeriesSingleImpl {\n\tvoid advance(int duplicateCount);\n\t// Move to the next key.\n\tboolean next();\n\t// Position to the beginning of the key series.\n\tvoid positionToFirst();\n\tprotected abstract void setNextNonNullKey(int nonNullKeyPosition);\n\tboolean validate();\n}", "des": "Implementation of when a one key series or a serialized key series is being presented."}
{"index": 2208, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorLimitOperator {\n\tVectorizationContext getInputVectorizationContext();\n\tVectorDesc getVectorDesc();\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "Limit operator implementation Limits the number of rows to be passed on."}
{"index": 2209, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorMapJoinFastBytesHashMultiSetStore.HashMultiSetResult {\n\t// Compare a key with the key positioned with the setKey method.\n\tboolean equalKey(byte[] keyBytes, int keyStart, int keyLength);\n\t// Mark the key matched with equalKey as a match and read the set membership count, if necessary.\n\tvoid setContains();\n\t// Setup for reading the key of an entry with the equalKey method.\n\tvoid setKey(VectorMapJoinFastBytesHashMultiSetStore multiSetStore, long refWord);\n}", "des": "A hash multi-set result that can read the set membership count for the key. It also has support routines for checking the hash code and key equality. It implements the standard map join hash multi-set result interface."}
{"index": 2210, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorMapJoinFastBytesHashSetStore.HashSetResult {\n\t// Compare a key with the key positioned with the setKey method.\n\tboolean equalKey(byte[] keyBytes, int keyStart, int keyLength);\n\t// Mark the key matched with equalKey as a match and read the set membership count, if necessary.\n\tvoid setContains();\n\t// Setup for reading the key of an entry with the equalKey method.\n\tvoid setKey(VectorMapJoinFastBytesHashSetStore setStore, long refWord);\n}", "des": "A hash set result for the key. It also has support routines for checking the hash code and key equality. It implements the standard map join hash set result interface."}
{"index": 2211, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorMapJoinOuterFilteredOperator {\n\t// Operator specific initialization.\n\tvoid initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object data, int tag);\n}", "des": "This is the *NON-NATIVE* vector map join operator for just LEFT OUTER JOIN and filtered. It is a row pass-thru so that super MapJoinOperator can do the outer join filtering properly."}
{"index": 2212, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorReduceSinkEmptyKeyOperator {\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "This class is the UniformHash empty key operator class for native vectorized reduce sink. Since there is no key, we initialize the keyWritable once with an empty value."}
{"index": 2213, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorReduceSinkObjectHashOperator {\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "This class is the object hash (not Uniform Hash) operator class for native vectorized reduce sink. It takes the \"object\" hash code of bucket and/or partition keys (which are often subsets of the reduce key). If the bucket and partition keys are empty, the hash will be a random number."}
{"index": 2214, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VectorReduceSinkUniformHashOperator {\n\t// Operator specific initialization.\n\tprotected void initializeOp(org.apache.hadoop.conf.Configuration hconf);\n\t// Process the row.\n\tvoid process(Object row, int tag);\n}", "des": "This class is uniform hash (common) operator class for native vectorized reduce sink. There are variation operators for Long, String, and MultiKey. And, a special case operator for no key (VectorReduceSinkEmptyKeyOperator)."}
{"index": 2215, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class VertexCounterLimit {\n\t// Return cloned copy of this counter limit\n\tCounterLimit clone();\n\tboolean equals(Object other);\n\t// Get the threshold value for the counter\n\tlong getLimit();\n\t// Get the name of the counter.\n\tString getName();\n}", "des": "Vertex specific counters with limits"}
{"index": 2216, "repo": "hive-exec-4.0.0-alpha-2", "code": "Class Worker {\n\t// Finds the next compaction and executes it.\n\tprotected Boolean findNextCompactionAndExecute(boolean collectGenericStats, boolean collectMrStats);\n\tCompactorMR getMrCompactor();\n\tvoid init(AtomicBoolean stop);\n\t// Check for obsolete directories, and return true if any exist and Cleaner should be run.\n\tstatic boolean needsCleaning(AcidDirectory dir, org.apache.hadoop.hive.metastore.api.StorageDescriptor sd);\n\tvoid run();\n}", "des": "A class to do compactions. This will run in a separate thread. It will spin on the compaction queue and look for new work to do."}
{"index": 2217, "repo": "spring-session-1.3.5.RELEASE", "code": "Interface CookieSerializer {\n\t// Reads all the matching cookies from the HttpServletRequest.\n\tjava.util.List<java.lang.String> readCookieValues(HttpServletRequest request);\n\t// Writes a given CookieSerializer.CookieValue to the provided HttpServletResponse.\n\tvoid writeCookieValue(CookieSerializer.CookieValue cookieValue);\n}", "des": "Strategy for reading and writing a cookie value to the HttpServletResponse."}
{"index": 2218, "repo": "spring-session-1.3.5.RELEASE", "code": "Class CookieSerializer.CookieValue {\n\t// The value to be written.\n\tjava.lang.String getCookieValue();\n\t// Gets the request to use.\n\tHttpServletRequest getRequest();\n\t// Gets the response to write to.\n\tHttpServletResponse getResponse();\n}", "des": "Contains the information necessary to write a value to the HttpServletResponse."}
{"index": 2219, "repo": "spring-session-1.3.5.RELEASE", "code": "Enum HazelcastFlushMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HazelcastFlushMode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HazelcastFlushMode[] values();\n}", "des": "Specifies when to write to the backing Hazelcast instance."}
{"index": 2220, "repo": "spring-session-1.3.5.RELEASE", "code": "Enum RedisFlushMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RedisFlushMode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RedisFlushMode[] values();\n}", "des": "Specifies when to write to the backing Redis instance."}
{"index": 2221, "repo": "spring-session-1.3.5.RELEASE", "code": "Interface RequestResponsePostProcessor {\n\t// Allows customizing the HttpServletRequest.\n\tHttpServletRequest wrapRequest(HttpServletRequest request, HttpServletResponse response);\n\t// Allows customizing the HttpServletResponse.\n\tHttpServletResponse wrapResponse(HttpServletRequest request, HttpServletResponse response);\n}", "des": "Allows customizing the HttpServletRequest and/or the HttpServletResponse."}
{"index": 2222, "repo": "spring-session-1.3.5.RELEASE", "code": "Interface SessionRepository<S extends Session> {\n\t// Creates a new Session that is capable of being persisted by this SessionRepository.\n\tS createSession();\n\t// Deletes the Session with the given Session.getId() or does nothing if the Session is not found.\n\tvoid delete(java.lang.String id);\n\t// Gets the Session by the Session.getId() or null if no Session is found.\n\tS getSession(java.lang.String id);\n\t// Ensures the Session created by createSession() is saved.\n\tvoid save(S session);\n}", "des": "A repository interface for managing Session instances."}
{"index": 2223, "repo": "calcite-linq4j-1.34.0", "code": "Class AbstractNode {\n\tvoid accept(org.apache.calcite.linq4j.tree.ExpressionWriter writer);\n\tNode accept(Shuttle shuttle);\n\tboolean equals(@Nullable Object o);\n\t@Nullable Object evaluate(org.apache.calcite.linq4j.tree.Evaluator evaluator);\n\t// Gets the node type of this Expression.\n\tExpressionType getNodeType();\n\t// Gets the static type of the expression that this Expression represents.\n\tType getType();\n}", "des": "Abstract implementation of Node."}
{"index": 2224, "repo": "calcite-linq4j-1.34.0", "code": "Class Blocks {\n\t// Prepends a statement to a block.\n\tstatic BlockStatement create(Statement statement, BlockStatement block);\n\t// Converts a simple \"{ return expr; }\" block into \"expr\"; otherwise throws.\n\tstatic Expression simple(BlockStatement block);\n\tstatic BlockStatement toBlock(Node body);\n\tstatic BlockStatement toFunctionBlock(Node body);\n}", "des": ""}
{"index": 2225, "repo": "calcite-linq4j-1.34.0", "code": "Class CartesianProductEnumerator<T,E> {\n\t// Closes this enumerable and releases resources.\n\tvoid close();\n\t// Advances the enumerator to the next element of the collection.\n\tboolean moveNext();\n\t// Sets the enumerator to its initial position, which is before the first element in the collection.\n\tvoid reset();\n}", "des": "Enumerator over the cartesian product of enumerators."}
{"index": 2226, "repo": "calcite-linq4j-1.34.0", "code": "Class DelegatingEnumerator<T> {\n\t// Closes this enumerable and releases resources.\n\tvoid close();\n\t// Gets the current element in the collection.\n\tT current();\n\t// Advances the enumerator to the next element of the collection.\n\tboolean moveNext();\n\t// Sets the enumerator to its initial position, which is before the first element in the collection.\n\tvoid reset();\n}", "des": "Simple enumerator that just delegates all calls to the passed enumerator."}
{"index": 2227, "repo": "calcite-linq4j-1.34.0", "code": "Interface Enumerator<T> {\n\t// Closes this enumerable and releases resources.\n\tvoid close();\n\t// Gets the current element in the collection.\n\tT current();\n\t// Advances the enumerator to the next element of the collection.\n\tboolean moveNext();\n\t// Sets the enumerator to its initial position, which is before the first element in the collection.\n\tvoid reset();\n}", "des": "Supports a simple iteration over a collection."}
{"index": 2228, "repo": "calcite-linq4j-1.34.0", "code": "Enum ExpressionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExpressionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExpressionType[] values();\n}", "des": ""}
{"index": 2229, "repo": "calcite-linq4j-1.34.0", "code": "Enum GotoExpressionKind {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GotoExpressionKind valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GotoExpressionKind[] values();\n}", "des": "Specifies what kind of jump a GotoStatement represents."}
{"index": 2230, "repo": "calcite-linq4j-1.34.0", "code": "Enum JoinType {\n\t// Returns whether a join of this type may generate NULL values on the left-hand side.\n\tboolean generatesNullsOnLeft();\n\t// Returns whether a join of this type may generate NULL values on the right-hand side.\n\tboolean generatesNullsOnRight();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JoinType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JoinType[] values();\n}", "des": "Enumeration of join types."}
{"index": 2231, "repo": "calcite-linq4j-1.34.0", "code": "Class MemoryEnumerator<E> {\n\t// Closes this enumerable and releases resources.\n\tvoid close();\n\t// Gets the current element in the collection.\n\tMemoryFactory.Memory<E> current();\n\t// Advances the enumerator to the next element of the collection.\n\tboolean moveNext();\n\t// Sets the enumerator to its initial position, which is before the first element in the collection.\n\tvoid reset();\n}", "des": "Enumerator that keeps some recent and some \"future\" values."}
{"index": 2232, "repo": "calcite-linq4j-1.34.0", "code": "Class Nullness {\n\t// Allows you to treat a nullable type as non-nullable with no assertions.\n\tstatic <T> T castNonNull(T ref);\n\t// Allows you to treat an array of nullable values as an array of non-nullable values.\n\tstatic <T> T[] castNonNullArray(T[] ts);\n\t// Allows you to treat an uninitialized or under-initialization object as initialized with no assertions.\n\tstatic <T> T castToInitialized(T ref);\n}", "des": "The methods in this class allow to cast nullable reference to a non-nullable one. This is an internal class, and it is not meant to be used as a public API."}
{"index": 2233, "repo": "calcite-linq4j-1.34.0", "code": "Enum OpType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OpType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OpType[] values();\n}", "des": "Operator type."}
{"index": 2234, "repo": "calcite-linq4j-1.34.0", "code": "Enum Primitive.Flavor {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Primitive.Flavor valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Primitive.Flavor[] values();\n}", "des": "Whether a type is primitive (e.g. int), a box type for a primitive (e.g. java.lang.Integer), or something else."}
{"index": 2235, "repo": "calcite-linq4j-1.34.0", "code": "Interface RawQueryable<T> {\n\t// Gets the type of the element(s) that are returned when the expression tree associated with this Queryable is executed.\n\tType getElementType();\n\t// Gets the expression tree that is associated with this Queryable.\n\t@Nullable Expression getExpression();\n\t// Gets the query provider that is associated with this data source.\n\tQueryProvider getProvider();\n}", "des": "Core methods that define a Queryable."}
{"index": 2236, "repo": "calcite-linq4j-1.34.0", "code": "Class TransformedEnumerator<F,E> {\n\t// Closes this enumerable and releases resources.\n\tvoid close();\n\t// Gets the current element in the collection.\n\tE current();\n\t// Advances the enumerator to the next element of the collection.\n\tboolean moveNext();\n\t// Sets the enumerator to its initial position, which is before the first element in the collection.\n\tvoid reset();\n\tprotected abstract E transform(F from);\n}", "des": "Enumerator that applies a transform to each value from a backing enumerator."}
{"index": 2237, "repo": "calcite-linq4j-1.34.0", "code": "Class Types.ArrayType {\n\t// Returns whether elements in the array may be null.\n\tboolean componentIsNullable();\n\t// Returns the type of elements in the array.\n\tType getComponentType();\n\t// Returns the maximum cardinality; -1 if there is no maximum.\n\tlong maximumCardinality();\n}", "des": "Array type."}
{"index": 2238, "repo": "calcite-linq4j-1.34.0", "code": "Class Types.MapType {\n\t// Returns the type of keys.\n\tType getKeyType();\n\t// Returns the type of values.\n\tType getValueType();\n\t// Returns whether keys may be null.\n\tboolean keyIsNullable();\n\t// Returns whether values may be null.\n\tboolean valueIsNullable();\n}", "des": "Map type."}
{"index": 2239, "repo": "exoplayer-r2.3.1", "code": "Class Ac3Reader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator generator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, boolean dataAlignmentIndicator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous (E-)AC-3 byte stream and extracts individual samples."}
{"index": 2240, "repo": "exoplayer-r2.3.1", "code": "Class AesCipherDataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] data, int offset, int length);\n}", "des": "A wrapping DataSink that encrypts the data being consumed."}
{"index": 2241, "repo": "exoplayer-r2.3.1", "code": "Class AesCipherDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] data, int offset, int readLength);\n}", "des": "A DataSource that decrypts the data read from an upstream source."}
{"index": 2242, "repo": "exoplayer-r2.3.1", "code": "Class AspectRatioFrameLayout {\n\tprotected void onMeasure(int widthMeasureSpec, int heightMeasureSpec);\n\t// Set the aspect ratio that this view should satisfy.\n\tvoid setAspectRatio(float widthHeightRatio);\n\t// Sets the resize mode.\n\tvoid setResizeMode(int resizeMode);\n}", "des": "A FrameLayout that resizes itself to match a specified aspect ratio."}
{"index": 2243, "repo": "exoplayer-r2.3.1", "code": "Class AssetDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading from a local asset."}
{"index": 2244, "repo": "exoplayer-r2.3.1", "code": "Class AtomicFile {\n\t// Delete the atomic file.\n\tvoid delete();\n\t// Call when you have successfully finished writing to the stream returned by startWrite().\n\tvoid endWrite(java.io.OutputStream str);\n\t// Open the atomic file for reading.\n\tjava.io.InputStream openRead();\n\t// Start a new write operation on the file.\n\tjava.io.OutputStream startWrite();\n}", "des": "A helper class for performing atomic operations on a file by creating a backup file until a write has successfully completed."}
{"index": 2245, "repo": "exoplayer-r2.3.1", "code": "Class AudioCapabilities {\n\tboolean equals(java.lang.Object other);\n\t// Returns the current audio capabilities for the device.\n\tstatic AudioCapabilities getCapabilities(android.content.Context context);\n\t// Returns the maximum number of channels the device can play at the same time.\n\tint getMaxChannelCount();\n\t// Returns whether this device supports playback of the specified audio encoding.\n\tboolean supportsEncoding(int encoding);\n}", "des": "Represents the set of audio formats that a device is capable of playing."}
{"index": 2246, "repo": "exoplayer-r2.3.1", "code": "Class AudioCapabilitiesReceiver {\n\t// Registers the receiver, meaning it will notify the listener when audio capability changes occur.\n\tAudioCapabilities register();\n\t// Unregisters the receiver, meaning it will no longer notify the listener when audio capability changes occur.\n\tvoid unregister();\n}", "des": "Receives broadcast events indicating changes to the device's audio capabilities, notifying a AudioCapabilitiesReceiver.Listener when audio capability changes occur."}
{"index": 2247, "repo": "exoplayer-r2.3.1", "code": "Interface AudioTrack.Listener {\n\t// Called when the audio track has been initialized with a newly generated audio session id.\n\tvoid onAudioSessionId(int audioSessionId);\n\t// Called when the audio track handles a buffer whose timestamp is discontinuous with the last buffer handled since it was reset.\n\tvoid onPositionDiscontinuity();\n\t// Called when the audio track underruns.\n\tvoid onUnderrun(int bufferSize, long bufferSizeMs, long elapsedSinceLastFeedMs);\n}", "des": "Listener for audio track events."}
{"index": 2248, "repo": "exoplayer-r2.3.1", "code": "Class ByteArrayDataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Returns the data written to the sink since the last call to open(DataSpec), or null if open(DataSpec) has never been called.\n\tbyte[] getData();\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] buffer, int offset, int length);\n}", "des": "A DataSink for writing to a byte array."}
{"index": 2249, "repo": "exoplayer-r2.3.1", "code": "Class ByteArrayDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading from a byte array."}
{"index": 2250, "repo": "exoplayer-r2.3.1", "code": "Class C {\n\t// Returns a newly generated AudioTrack session identifier.\n\tstatic int generateAudioSessionIdV21(android.content.Context context);\n\t// Converts a time in milliseconds to the corresponding time in microseconds, preserving TIME_UNSET values.\n\tstatic long msToUs(long timeMs);\n\t// Converts a time in microseconds to the corresponding time in milliseconds, preserving TIME_UNSET values.\n\tstatic long usToMs(long timeUs);\n}", "des": "Defines constants used by the library."}
{"index": 2251, "repo": "exoplayer-r2.3.1", "code": "Interface Cache.Listener {\n\t// Called when a CacheSpan is added to the cache.\n\tvoid onSpanAdded(Cache cache, CacheSpan span);\n\t// Called when a CacheSpan is removed from the cache.\n\tvoid onSpanRemoved(Cache cache, CacheSpan span);\n\t// Called when an existing CacheSpan is accessed, causing it to be replaced.\n\tvoid onSpanTouched(Cache cache, CacheSpan oldSpan, CacheSpan newSpan);\n}", "des": "Listener of Cache events."}
{"index": 2252, "repo": "exoplayer-r2.3.1", "code": "Class CacheDataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] buffer, int offset, int length);\n}", "des": "Writes data into a cache."}
{"index": 2253, "repo": "exoplayer-r2.3.1", "code": "Class CacheDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource that reads and writes a Cache. Requests are fulfilled from the cache when possible. When data is not cached it is requested from an upstream DataSource and written into the cache."}
{"index": 2254, "repo": "exoplayer-r2.3.1", "code": "Interface CacheEvictor {\n\t// Called when cache has been initialized.\n\tvoid onCacheInitialized();\n\t// Called when a writer starts writing to the cache.\n\tvoid onStartFile(Cache cache, java.lang.String key, long position, long maxLength);\n}", "des": "Evicts data from a Cache. Implementations should call Cache.removeSpan(CacheSpan) to evict cache entries based on their eviction policies."}
{"index": 2255, "repo": "exoplayer-r2.3.1", "code": "Class CacheSpan {\n\tint compareTo(CacheSpan another);\n\t// Returns whether this is a hole CacheSpan.\n\tboolean isHoleSpan();\n\t// Returns whether this is an open-ended CacheSpan.\n\tboolean isOpenEnded();\n}", "des": "Defines a span of data that may or may not be cached (as indicated by isCached)."}
{"index": 2256, "repo": "exoplayer-r2.3.1", "code": "Class ChapterFrame {\n\tint describeContents();\n\tboolean equals(java.lang.Object obj);\n\t// Returns the sub-frame at index.\n\tId3Frame getSubFrame(int index);\n\t// Returns the number of sub-frames.\n\tint getSubFrameCount();\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "Chapter information ID3 frame."}
{"index": 2257, "repo": "exoplayer-r2.3.1", "code": "Class ChapterTocFrame {\n\tboolean equals(java.lang.Object obj);\n\t// Returns the sub-frame at index.\n\tId3Frame getSubFrame(int index);\n\t// Returns the number of sub-frames.\n\tint getSubFrameCount();\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "Chapter table of contents ID3 frame."}
{"index": 2258, "repo": "exoplayer-r2.3.1", "code": "Class Chunk {\n\t// Returns the number of bytes that have been loaded.\n\tabstract long bytesLoaded();\n\t// Returns the duration of the chunk in microseconds.\n\tlong getDurationUs();\n}", "des": "An abstract base class for Loader.Loadable implementations that load chunks of data required for the playback of streams."}
{"index": 2259, "repo": "exoplayer-r2.3.1", "code": "Class ChunkIndex {\n\t// Obtains the index of the chunk corresponding to a given time.\n\tint getChunkIndex(long timeUs);\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Maps a seek position in microseconds to a corresponding position (byte offset) in the stream from which data can be provided to the extractor.\n\tlong getPosition(long timeUs);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n}", "des": "Defines chunks of samples within a media stream."}
{"index": 2260, "repo": "exoplayer-r2.3.1", "code": "Class ColorParser {\n\t// Parses a CSS color expression.\n\tstatic int parseCssColor(java.lang.String colorExpression);\n\t// Parses a TTML color expression.\n\tstatic int parseTtmlColor(java.lang.String colorExpression);\n}", "des": "Parser for color expressions found in styling formats, e.g. TTML and CSS."}
{"index": 2261, "repo": "exoplayer-r2.3.1", "code": "Class CompositeSequenceableLoader {\n\t// Attempts to continue loading.\n\tboolean continueLoading(long positionUs);\n\t// Returns the next load time, or C.TIME_END_OF_SOURCE if loading has finished.\n\tlong getNextLoadPositionUs();\n}", "des": "A SequenceableLoader that encapsulates multiple other SequenceableLoaders."}
{"index": 2262, "repo": "exoplayer-r2.3.1", "code": "Class ConditionVariable {\n\t// Blocks until the condition is opened.\n\tvoid block();\n\t// Closes the condition.\n\tboolean close();\n\t// Opens the condition and releases all threads that are blocked.\n\tboolean open();\n}", "des": "A condition variable whose open() and close() methods return whether they resulted in a change of state."}
{"index": 2263, "repo": "exoplayer-r2.3.1", "code": "Class ContainerMediaChunk {\n\t// Returns the number of bytes that have been loaded.\n\tlong bytesLoaded();\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Returns the next chunk index.\n\tint getNextChunkIndex();\n\t// Returns whether the load has been canceled.\n\tboolean isLoadCanceled();\n\t// Returns whether the chunk has been fully loaded.\n\tboolean isLoadCompleted();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A BaseMediaChunk that uses an Extractor to decode sample data."}
{"index": 2264, "repo": "exoplayer-r2.3.1", "code": "Class ContentDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading from a content URI."}
{"index": 2265, "repo": "exoplayer-r2.3.1", "code": "Class DashUtil {\n\t// Loads initialization and index data for the representation and returns the ChunkIndex.\n\tstatic ChunkIndex loadChunkIndex(DataSource dataSource, Representation representation);\n\t// Loads a DASH manifest.\n\tstatic DashManifest loadManifest(DataSource dataSource, java.lang.String manifestUriString);\n\t// Loads initialization data for the representation and returns the sample Format.\n\tstatic Format loadSampleFormat(DataSource dataSource, Representation representation);\n}", "des": "Utility methods for DASH streams."}
{"index": 2266, "repo": "exoplayer-r2.3.1", "code": "Class DataChunk {\n\t// Returns the number of bytes that have been loaded.\n\tlong bytesLoaded();\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Called by load().\n\tprotected abstract void consume(byte[] data, int limit);\n\t// Returns the array in which the data is held.\n\tbyte[] getDataHolder();\n\t// Returns whether the load has been canceled.\n\tboolean isLoadCanceled();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A base class for Chunk implementations where the data should be loaded into a byte[] before being consumed."}
{"index": 2267, "repo": "exoplayer-r2.3.1", "code": "Interface DataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] buffer, int offset, int length);\n}", "des": "A component to which streams of data can be written."}
{"index": 2268, "repo": "exoplayer-r2.3.1", "code": "Interface DataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A component from which streams of data can be read."}
{"index": 2269, "repo": "exoplayer-r2.3.1", "code": "Class DataSourceInputStream {\n\t// Returns the total number of bytes that have been read or skipped.\n\tlong bytesRead();\n\tvoid close();\n\t// Optional call to open the underlying DataSource.\n\tvoid open();\n\tint read();\n\tint read(byte[] buffer);\n\tint read(byte[] buffer, int offset, int length);\n}", "des": "Allows data corresponding to a given DataSpec to be read from a DataSource and consumed through an InputStream."}
{"index": 2270, "repo": "exoplayer-r2.3.1", "code": "Interface Decoder<I,O,E extends java.lang.Exception> {\n\t// Dequeues the next input buffer to be filled and queued to the decoder.\n\tI dequeueInputBuffer();\n\t// Dequeues the next output buffer from the decoder.\n\tO dequeueOutputBuffer();\n\t// Flushes the decoder.\n\tvoid flush();\n\t// Returns the name of the decoder.\n\tjava.lang.String getName();\n\t// Queues an input buffer to the decoder.\n\tvoid queueInputBuffer(I inputBuffer);\n\t// Releases the decoder.\n\tvoid release();\n}", "des": "A media decoder."}
{"index": 2271, "repo": "exoplayer-r2.3.1", "code": "Class DecoderCounters {\n\t// Should be called to ensure counter values are made visible across threads.\n\tvoid ensureUpdated();\n\t// Merges the counts from other into this instance.\n\tvoid merge(DecoderCounters other);\n}", "des": "Maintains decoder event counts, for debugging purposes only."}
{"index": 2272, "repo": "exoplayer-r2.3.1", "code": "Class DecoderInputBuffer {\n\t// Clears the buffer.\n\tvoid clear();\n\t// Ensures that data is large enough to accommodate a write of a given length at its current position.\n\tvoid ensureSpaceForWrite(int length);\n\t// Flips data in preparation for being queued to a decoder.\n\tvoid flip();\n\t// Returns whether the C.BUFFER_FLAG_ENCRYPTED flag is set.\n\tboolean isEncrypted();\n}", "des": "Holds input for a decoder."}
{"index": 2273, "repo": "exoplayer-r2.3.1", "code": "Class DefaultBandwidthMeter {\n\t// Returns the estimated bandwidth in bits/sec, or BandwidthMeter.NO_ESTIMATE if an estimate is not available.\n\tlong getBitrateEstimate();\n\t// Called incrementally during a transfer.\n\tvoid onBytesTransferred(java.lang.Object source, int bytes);\n\t// Called when a transfer ends.\n\tvoid onTransferEnd(java.lang.Object source);\n\t// Called when a transfer starts.\n\tvoid onTransferStart(java.lang.Object source, DataSpec dataSpec);\n}", "des": "Estimates bandwidth by listening to data transfers. The bandwidth estimate is calculated using a SlidingPercentile and is updated each time a transfer ends."}
{"index": 2274, "repo": "exoplayer-r2.3.1", "code": "Class DefaultDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource that supports multiple URI schemes. The supported schemes are: file: For fetching data from a local file (e.g. file:///path/to/media/media.mp4, or just /path/to/media/media.mp4 because the implementation assumes that a URI without a scheme is a local file URI). asset: For fetching data from an asset in the application's apk (e.g. asset:///media.mp4). content: For fetching data from a content URI (e.g. content://authority/path/123). http(s): For fetching data over HTTP and HTTPS (e.g. https://www.something.com/media.mp4), if constructed using DefaultDataSource(Context, TransferListener, String, boolean), or any other schemes supported by a base data source if constructed using DefaultDataSource(Context, TransferListener, DataSource)."}
{"index": 2275, "repo": "exoplayer-r2.3.1", "code": "Interface DefaultDrmSessionManager.EventListener {\n\t// Called each time keys are loaded.\n\tvoid onDrmKeysLoaded();\n\t// Called each time offline keys are removed.\n\tvoid onDrmKeysRemoved();\n\t// Called each time offline keys are restored.\n\tvoid onDrmKeysRestored();\n\t// Called when a drm error occurs.\n\tvoid onDrmSessionManagerError(java.lang.Exception e);\n}", "des": "Listener of DefaultDrmSessionManager events."}
{"index": 2276, "repo": "exoplayer-r2.3.1", "code": "Class DefaultTsPayloadReaderFactory {\n\t// Returns the initial mapping from PIDs to payload readers.\n\tandroid.util.SparseArray<TsPayloadReader> createInitialPayloadReaders();\n\t// Returns a TsPayloadReader for a given stream type and elementary stream information.\n\tTsPayloadReader createPayloadReader(int streamType, TsPayloadReader.EsInfo esInfo);\n}", "des": "Default implementation for TsPayloadReader.Factory."}
{"index": 2277, "repo": "exoplayer-r2.3.1", "code": "Class DrmInitData {\n\tint compare(DrmInitData.SchemeData first, DrmInitData.SchemeData second);\n\tint describeContents();\n\tboolean equals(java.lang.Object obj);\n\t// Retrieves the DrmInitData.SchemeData at a given index.\n\tDrmInitData.SchemeData get(int index);\n\t// Retrieves data for a given DRM scheme, specified by its UUID.\n\tDrmInitData.SchemeData get(java.util.UUID uuid);\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "Initialization data for one or more DRM schemes."}
{"index": 2278, "repo": "exoplayer-r2.3.1", "code": "Interface DrmSessionManager<T extends ExoMediaCrypto> {\n\t// Acquires a DrmSession for the specified DrmInitData.\n\tDrmSession<T> acquireSession(android.os.Looper playbackLooper, DrmInitData drmInitData);\n\t// Releases a DrmSession.\n\tvoid releaseSession(DrmSession<T> drmSession);\n}", "des": "Manages a DRM session."}
{"index": 2279, "repo": "exoplayer-r2.3.1", "code": "Class DtsReader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, boolean dataAlignmentIndicator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous DTS byte stream and extracts individual samples."}
{"index": 2280, "repo": "exoplayer-r2.3.1", "code": "Class EmptySampleStream {\n\t// Returns whether data is available to be read.\n\tboolean isReady();\n\t// Throws an error that's preventing data from being read.\n\tvoid maybeThrowError();\n\t// Attempts to read from the stream.\n\tint readData(FormatHolder formatHolder, DecoderInputBuffer buffer, boolean formatRequired);\n\t// Attempts to skip to the keyframe before the specified time.\n\tvoid skipToKeyframeBefore(long timeUs);\n}", "des": "An empty SampleStream."}
{"index": 2281, "repo": "exoplayer-r2.3.1", "code": "Interface ExtractorOutput {\n\t// Called when all tracks have been identified, meaning no new trackId values will be passed to track(int, int).\n\tvoid endTracks();\n\t// Called when a SeekMap has been extracted from the stream.\n\tvoid seekMap(SeekMap seekMap);\n\t// Called by the Extractor to get the TrackOutput for a specific track.\n\tTrackOutput track(int id, int type);\n}", "des": "Receives stream level data extracted by an Extractor."}
{"index": 2282, "repo": "exoplayer-r2.3.1", "code": "Class FileDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading local files."}
{"index": 2283, "repo": "exoplayer-r2.3.1", "code": "Class FixedTrackSelection {\n\t// Returns the index of the selected track.\n\tint getSelectedIndex();\n\t// Returns optional data associated with the current track selection.\n\tjava.lang.Object getSelectionData();\n\t// Returns the reason for the current track selection.\n\tint getSelectionReason();\n\t// Updates the selected track.\n\tvoid updateSelectedTrack(long bufferedDurationUs);\n}", "des": "A TrackSelection consisting of a single track."}
{"index": 2284, "repo": "exoplayer-r2.3.1", "code": "Class GaplessInfoHolder {\n\t// Returns whether encoderDelay and encoderPadding have been set.\n\tboolean hasGaplessInfo();\n\t// Populates the holder with data parsed from ID3 Metadata.\n\tboolean setFromMetadata(Metadata metadata);\n\t// Populates the holder with data from an MP3 Xing header, if valid and non-zero.\n\tboolean setFromXingHeaderValue(int value);\n}", "des": "Holder for gapless playback information."}
{"index": 2285, "repo": "exoplayer-r2.3.1", "code": "Class HlsMediaPlaylist {\n\t// Returns a playlist identical to this one except for the start time, the discontinuity sequence and hasDiscontinuitySequence values.\n\tHlsMediaPlaylist copyWith(long startTimeUs, int discontinuitySequence);\n\t// Returns a playlist identical to this one except that an end tag is added.\n\tHlsMediaPlaylist copyWithEndTag();\n\tlong getEndTimeUs();\n\t// Returns whether this playlist is newer than other.\n\tboolean isNewerThan(HlsMediaPlaylist other);\n}", "des": "Represents an HLS media playlist."}
{"index": 2286, "repo": "exoplayer-r2.3.1", "code": "Interface HlsPlaylistTracker.PlaylistEventListener {\n\t// Called if an error is encountered while loading a playlist.\n\tvoid onPlaylistBlacklisted(HlsMasterPlaylist.HlsUrl url, long blacklistDurationMs);\n\t// Called a playlist changes.\n\tvoid onPlaylistChanged();\n}", "des": "Called on playlist loading events."}
{"index": 2287, "repo": "exoplayer-r2.3.1", "code": "Class HttpDataSource.BaseFactory {\n\t// Creates a DataSource instance.\n\tHttpDataSource createDataSource();\n\t// Called by createDataSource() to create a HttpDataSource instance.\n\tprotected abstract HttpDataSource createDataSourceInternal(HttpDataSource.RequestProperties defaultRequestProperties);\n\t// Gets the default request properties used by all HttpDataSources created by the factory.\n\tHttpDataSource.RequestProperties getDefaultRequestProperties();\n}", "des": "Base implementation of HttpDataSource.Factory that sets default request properties."}
{"index": 2288, "repo": "exoplayer-r2.3.1", "code": "Interface HttpDataSource.Factory {\n\t// Creates a DataSource instance.\n\tHttpDataSource createDataSource();\n\t// Gets the default request properties used by all HttpDataSources created by the factory.\n\tHttpDataSource.RequestProperties getDefaultRequestProperties();\n}", "des": "A factory for HttpDataSource instances."}
{"index": 2289, "repo": "exoplayer-r2.3.1", "code": "Class Id3Decoder {\n\t// Decodes ID3 tags.\n\tMetadata decode(byte[] data, int size);\n\t// Decodes a Metadata element from the provided input buffer.\n\tMetadata decode(MetadataInputBuffer inputBuffer);\n}", "des": "Decodes ID3 tags."}
{"index": 2290, "repo": "exoplayer-r2.3.1", "code": "Class Id3Reader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, boolean dataAlignmentIndicator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses ID3 data and extracts individual text information frames."}
{"index": 2291, "repo": "exoplayer-r2.3.1", "code": "Class InitializationChunk {\n\t// Returns the number of bytes that have been loaded.\n\tlong bytesLoaded();\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Returns whether the load has been canceled.\n\tboolean isLoadCanceled();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A Chunk that uses an Extractor to decode initialization data for single track."}
{"index": 2292, "repo": "exoplayer-r2.3.1", "code": "Class LibraryLoader {\n\t// Returns whether the underlying libraries are available, loading them if necessary.\n\tboolean isAvailable();\n\t// Overrides the names of the libraries to load.\n\tvoid setLibraries(java.lang.String... libraries);\n}", "des": "Configurable loader for native libraries."}
{"index": 2293, "repo": "exoplayer-r2.3.1", "code": "Interface Loader.Callback<T extends Loader.Loadable> {\n\t// Called when a load has been canceled.\n\tvoid onLoadCanceled(T loadable, long elapsedRealtimeMs, long loadDurationMs, boolean released);\n\t// Called when a load has completed.\n\tvoid onLoadCompleted(T loadable, long elapsedRealtimeMs, long loadDurationMs);\n\t// Called when a load encounters an error.\n\tint onLoadError(T loadable, long elapsedRealtimeMs, long loadDurationMs, java.io.IOException error);\n}", "des": "A callback to be notified of Loader events."}
{"index": 2294, "repo": "exoplayer-r2.3.1", "code": "Interface Loader.Loadable {\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Returns whether the load has been canceled.\n\tboolean isLoadCanceled();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "An object that can be loaded using a Loader."}
{"index": 2295, "repo": "exoplayer-r2.3.1", "code": "Interface LoaderErrorThrower {\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the Loaders default minimum number of retries.\n\tvoid maybeThrowError();\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the specified minimum number of retries.\n\tvoid maybeThrowError(int minRetryCount);\n}", "des": "Conditionally throws errors affecting a Loader."}
{"index": 2296, "repo": "exoplayer-r2.3.1", "code": "Class LoaderErrorThrower.Dummy {\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the Loaders default minimum number of retries.\n\tvoid maybeThrowError();\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the specified minimum number of retries.\n\tvoid maybeThrowError(int minRetryCount);\n}", "des": "A LoaderErrorThrower that never throws."}
{"index": 2297, "repo": "exoplayer-r2.3.1", "code": "Class LongArray {\n\t// Appends a value.\n\tvoid add(long value);\n\t// Returns the value at a specified index.\n\tlong get(int index);\n\t// Returns the current size of the array.\n\tint size();\n\t// Copies the current values into a newly allocated primitive array.\n\tlong[] toArray();\n}", "des": "An append-only, auto-growing long[]."}
{"index": 2298, "repo": "exoplayer-r2.3.1", "code": "Class MappingTrackSelector.SelectionOverride {\n\t// Returns whether this override contains the specified track index.\n\tboolean containsTrack(int track);\n\t// Creates an selection from this override.\n\tTrackSelection createTrackSelection(TrackGroupArray groups);\n}", "des": "A track selection override."}
{"index": 2299, "repo": "exoplayer-r2.3.1", "code": "Class MediaChunk {\n\t// Returns the next chunk index.\n\tint getNextChunkIndex();\n\t// Returns whether the chunk has been fully loaded.\n\tabstract boolean isLoadCompleted();\n}", "des": "An abstract base class for Chunks that contain media samples."}
{"index": 2300, "repo": "exoplayer-r2.3.1", "code": "Interface MediaCodecSelector {\n\t// Selects a decoder to instantiate for a given mime type.\n\tMediaCodecInfo getDecoderInfo(java.lang.String mimeType, boolean requiresSecureDecoder);\n\t// Selects a decoder to instantiate for audio passthrough.\n\tMediaCodecInfo getPassthroughDecoderInfo();\n}", "des": "Selector of MediaCodec instances."}
{"index": 2301, "repo": "exoplayer-r2.3.1", "code": "Interface MediaDrmCallback {\n\t// Executes a key request.\n\tbyte[] executeKeyRequest(java.util.UUID uuid, ExoMediaDrm.KeyRequest request);\n\t// Executes a provisioning request.\n\tbyte[] executeProvisionRequest(java.util.UUID uuid, ExoMediaDrm.ProvisionRequest request);\n}", "des": "Performs ExoMediaDrm key and provisioning requests."}
{"index": 2302, "repo": "exoplayer-r2.3.1", "code": "Class Metadata {\n\tint describeContents();\n\tboolean equals(java.lang.Object obj);\n\t// Returns the entry at the specified index.\n\tMetadata.Entry get(int index);\n\t// Returns the number of metadata entries.\n\tint length();\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "A collection of metadata entries."}
{"index": 2303, "repo": "exoplayer-r2.3.1", "code": "Interface MetadataDecoderFactory {\n\t// Creates a MetadataDecoder for the given Format.\n\tMetadataDecoder createDecoder(Format format);\n\t// Returns whether the factory is able to instantiate a MetadataDecoder for the given Format.\n\tboolean supportsFormat(Format format);\n}", "des": "A factory for MetadataDecoder instances."}
{"index": 2304, "repo": "exoplayer-r2.3.1", "code": "Class MpegAudioHeader {\n\t// Returns the size of the frame associated with header, or C.LENGTH_UNSET if it is invalid.\n\tstatic int getFrameSize(int header);\n\t// Parses headerData, populating header with the parsed data.\n\tstatic boolean populateHeader(int headerData, MpegAudioHeader header);\n}", "des": "An MPEG audio frame header."}
{"index": 2305, "repo": "exoplayer-r2.3.1", "code": "Class ParsingLoadable<T> {\n\t// Returns the number of bytes loaded.\n\tlong bytesLoaded();\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Returns the loaded object, or null if an object has not been loaded.\n\tT getResult();\n\t// Returns whether the load has been canceled.\n\tboolean isLoadCanceled();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A Loader.Loadable for objects that can be parsed from binary data using a ParsingLoadable.Parser."}
{"index": 2306, "repo": "exoplayer-r2.3.1", "code": "Class PesReader {\n\t// Consumes the payload of a TS packet.\n\tvoid consume(ParsableByteArray data, boolean payloadUnitStartIndicator);\n\t// Initializes the payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses PES packet data and extracts samples."}
{"index": 2307, "repo": "exoplayer-r2.3.1", "code": "Class PriorityDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int max);\n}", "des": "A DataSource that can be used as part of a task registered with a PriorityTaskManager."}
{"index": 2308, "repo": "exoplayer-r2.3.1", "code": "Class PriorityTaskManager {\n\t// Register a new task.\n\tvoid add(int priority);\n\t// Blocks until the task is allowed to proceed.\n\tvoid proceed(int priority);\n\t// A non-blocking variant of proceed(int).\n\tboolean proceedNonBlocking(int priority);\n\t// A throwing variant of proceed(int).\n\tvoid proceedOrThrow(int priority);\n\t// Unregister a task.\n\tvoid remove(int priority);\n}", "des": "Allows tasks with associated priorities to control how they proceed relative to one another."}
{"index": 2309, "repo": "exoplayer-r2.3.1", "code": "Class PsshAtomUtil {\n\t// Builds a PSSH atom for a given UUID containing the given scheme specific data.\n\tstatic byte[] buildPsshAtom(java.util.UUID uuid, byte[] data);\n\t// Parses the scheme specific data from a PSSH atom.\n\tstatic byte[] parseSchemeSpecificData(byte[] atom, java.util.UUID uuid);\n\t// Parses the UUID from a PSSH atom.\n\tstatic java.util.UUID parseUuid(byte[] atom);\n}", "des": "Utility methods for handling PSSH atoms."}
{"index": 2310, "repo": "exoplayer-r2.3.1", "code": "Class RandomTrackSelection {\n\t// Returns the index of the selected track.\n\tint getSelectedIndex();\n\t// Returns optional data associated with the current track selection.\n\tjava.lang.Object getSelectionData();\n\t// Returns the reason for the current track selection.\n\tint getSelectionReason();\n\t// Updates the selected track.\n\tvoid updateSelectedTrack(long bufferedDurationUs);\n}", "des": "A TrackSelection whose selected track is updated randomly."}
{"index": 2311, "repo": "exoplayer-r2.3.1", "code": "Class RangedUri {\n\t// Attempts to merge this RangedUri with another and an optional common base uri.\n\tRangedUri attemptMerge(RangedUri other, java.lang.String baseUri);\n\tboolean equals(java.lang.Object obj);\n\t// Returns the resolved Uri represented by the instance.\n\tandroid.net.Uri resolveUri(java.lang.String baseUri);\n\t// Returns the resolved uri represented by the instance as a string.\n\tjava.lang.String resolveUriString(java.lang.String baseUri);\n}", "des": "Defines a range of data located at a reference uri."}
{"index": 2312, "repo": "exoplayer-r2.3.1", "code": "Interface RendererCapabilities {\n\t// Returns the track type that the Renderer handles.\n\tint getTrackType();\n\t// Returns the extent to which the Renderer supports a given format.\n\tint supportsFormat(Format format);\n\t// Returns the extent to which the Renderer supports adapting between supported formats that have different mime types.\n\tint supportsMixedMimeTypeAdaptation();\n}", "des": "Defines the capabilities of a Renderer."}
{"index": 2313, "repo": "exoplayer-r2.3.1", "code": "Interface SampleStream {\n\t// Returns whether data is available to be read.\n\tboolean isReady();\n\t// Throws an error that's preventing data from being read.\n\tvoid maybeThrowError();\n\t// Attempts to read from the stream.\n\tint readData(FormatHolder formatHolder, DecoderInputBuffer buffer, boolean formatRequired);\n\t// Attempts to skip to the keyframe before the specified time.\n\tvoid skipToKeyframeBefore(long timeUs);\n}", "des": "A stream of media samples (and associated format information)."}
{"index": 2314, "repo": "exoplayer-r2.3.1", "code": "Interface SectionPayloadReader {\n\t// Called by a SectionReader when a full section is received.\n\tvoid consume(ParsableByteArray sectionData);\n\t// Initializes the section payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n}", "des": "Reads section data."}
{"index": 2315, "repo": "exoplayer-r2.3.1", "code": "Class SectionReader {\n\t// Consumes the payload of a TS packet.\n\tvoid consume(ParsableByteArray data, boolean payloadUnitStartIndicator);\n\t// Initializes the payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Reads section data packets and feeds the whole sections to a given SectionPayloadReader. Useful information on PSI sections can be found in ISO/IEC 13818-1, section 2.4.4."}
{"index": 2316, "repo": "exoplayer-r2.3.1", "code": "Interface SeekMap {\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Maps a seek position in microseconds to a corresponding position (byte offset) in the stream from which data can be provided to the extractor.\n\tlong getPosition(long timeUs);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n}", "des": "Maps seek positions (in microseconds) to corresponding positions (byte offsets) in the stream."}
{"index": 2317, "repo": "exoplayer-r2.3.1", "code": "Class SeekMap.Unseekable {\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Maps a seek position in microseconds to a corresponding position (byte offset) in the stream from which data can be provided to the extractor.\n\tlong getPosition(long timeUs);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n}", "des": "A SeekMap that does not support seeking."}
{"index": 2318, "repo": "exoplayer-r2.3.1", "code": "Class SegmentBase {\n\t// Returns the RangedUri defining the location of initialization data for a given representation, or null if no initialization data exists.\n\tRangedUri getInitialization(Representation representation);\n\t// Returns the presentation time offset, in microseconds.\n\tlong getPresentationTimeOffsetUs();\n}", "des": "An approximate representation of a SegmentBase manifest element."}
{"index": 2319, "repo": "exoplayer-r2.3.1", "code": "Class SegmentBase.SegmentTemplate {\n\t// Returns the RangedUri defining the location of initialization data for a given representation, or null if no initialization data exists.\n\tRangedUri getInitialization(Representation representation);\n\tint getSegmentCount(long periodDurationUs);\n\t// Returns a RangedUri defining the location of a segment for the given index in the given representation.\n\tRangedUri getSegmentUrl(Representation representation, int sequenceNumber);\n}", "des": "A SegmentBase.MultiSegmentBase that uses a SegmentTemplate to define its segments."}
{"index": 2320, "repo": "exoplayer-r2.3.1", "code": "Interface SequenceableLoader {\n\t// Attempts to continue loading.\n\tboolean continueLoading(long positionUs);\n\t// Returns the next load time, or C.TIME_END_OF_SOURCE if loading has finished.\n\tlong getNextLoadPositionUs();\n}", "des": "A loader that can proceed in approximate synchronization with other loaders."}
{"index": 2321, "repo": "exoplayer-r2.3.1", "code": "Interface SimpleExoPlayer.VideoListener {\n\t// Called when a frame is rendered for the first time since setting the surface, and when a frame is rendered for the first time since a video track was selected.\n\tvoid onRenderedFirstFrame();\n\t// Called each time there's a change in the size of the video being rendered.\n\tvoid onVideoSizeChanged(int width, int height, int unappliedRotationDegrees, float pixelWidthHeightRatio);\n}", "des": "A listener for video rendering information from a SimpleExoPlayer."}
{"index": 2322, "repo": "exoplayer-r2.3.1", "code": "Class SimpleOutputBuffer {\n\t// Clears the buffer.\n\tvoid clear();\n\t// Initializes the buffer.\n\tjava.nio.ByteBuffer init(long timeUs, int size);\n\t// Releases the output buffer for reuse.\n\tvoid release();\n}", "des": "Buffer for SimpleDecoder output."}
{"index": 2323, "repo": "exoplayer-r2.3.1", "code": "Class SingleSampleMediaChunk {\n\t// Returns the number of bytes that have been loaded.\n\tlong bytesLoaded();\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Returns whether the load has been canceled.\n\tboolean isLoadCanceled();\n\t// Returns whether the chunk has been fully loaded.\n\tboolean isLoadCompleted();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A BaseMediaChunk for chunks consisting of a single raw sample."}
{"index": 2324, "repo": "exoplayer-r2.3.1", "code": "Class SlidingPercentile {\n\t// Adds a new weighted value.\n\tvoid addSample(int weight, float value);\n\t// Computes a percentile by integration.\n\tfloat getPercentile(float percentile);\n}", "des": "Calculate any percentile over a sliding window of weighted values. A maximum weight is configured. Once the total weight of the values reaches the maximum weight, the oldest value is reduced in weight until it reaches zero and is removed. This maintains a constant total weight, equal to the maximum allowed, at the steady state."}
{"index": 2325, "repo": "exoplayer-r2.3.1", "code": "Class SpliceInfoSectionReader {\n\t// Called by a SectionReader when a full section is received.\n\tvoid consume(ParsableByteArray sectionData);\n\t// Initializes the section payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n}", "des": "Parses splice info sections as defined by SCTE35."}
{"index": 2326, "repo": "exoplayer-r2.3.1", "code": "Class SsManifest.StreamElement {\n\t// Builds a uri for requesting the specified chunk of the specified track.\n\tandroid.net.Uri buildRequestUri(int track, int chunkIndex);\n\t// Returns the duration of the specified chunk.\n\tlong getChunkDurationUs(int chunkIndex);\n\t// Returns the index of the chunk that contains the specified time.\n\tint getChunkIndex(long timeUs);\n\t// Returns the start time of the specified chunk.\n\tlong getStartTimeUs(int chunkIndex);\n}", "des": "Represents a StreamIndex element."}
{"index": 2327, "repo": "exoplayer-r2.3.1", "code": "Class StandaloneMediaClock {\n\t// Returns the current media position in microseconds.\n\tlong getPositionUs();\n\tvoid setPositionUs(long timeUs);\n\t// Starts the clock.\n\tvoid start();\n\t// Stops the clock.\n\tvoid stop();\n}", "des": "A standalone MediaClock. The clock can be started, stopped and its time can be set and retrieved. When started, this clock is based on SystemClock.elapsedRealtime()."}
{"index": 2328, "repo": "exoplayer-r2.3.1", "code": "Interface Subtitle {\n\t// Retrieve the cues that should be displayed at a given time.\n\tjava.util.List<Cue> getCues(long timeUs);\n\t// Returns the event time at a specified index.\n\tlong getEventTime(int index);\n\t// Returns the number of event times, where events are defined as points in time at which the cues returned by getCues(long) changes.\n\tint getEventTimeCount();\n\t// Returns the index of the first event that occurs after a given time (exclusive).\n\tint getNextEventTimeIndex(long timeUs);\n}", "des": "A subtitle consisting of timed Cues."}
{"index": 2329, "repo": "exoplayer-r2.3.1", "code": "Interface SubtitleDecoderFactory {\n\t// Creates a SubtitleDecoder for the given Format.\n\tSubtitleDecoder createDecoder(Format format);\n\t// Returns whether the factory is able to instantiate a SubtitleDecoder for the given Format.\n\tboolean supportsFormat(Format format);\n}", "des": "A factory for SubtitleDecoder instances."}
{"index": 2330, "repo": "exoplayer-r2.3.1", "code": "Class TeeDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int max);\n}", "des": "Tees data into a DataSink as the data is read."}
{"index": 2331, "repo": "exoplayer-r2.3.1", "code": "Class TimestampAdjusterProvider {\n\t// Returns a TimestampAdjuster suitable for adjusting the pts timestamps contained in a chunk with a given discontinuity sequence.\n\tTimestampAdjuster getAdjuster(int discontinuitySequence);\n\t// Resets the provider.\n\tvoid reset();\n}", "des": "Provides TimestampAdjuster instances for use during HLS playbacks."}
{"index": 2332, "repo": "exoplayer-r2.3.1", "code": "Class TraceUtil {\n\t// Writes a trace message to indicate that a given section of code has begun.\n\tstatic void beginSection(java.lang.String sectionName);\n\t// Writes a trace message to indicate that a given section of code has ended.\n\tstatic void endSection();\n}", "des": "Calls through to Trace methods on supported API levels."}
{"index": 2333, "repo": "exoplayer-r2.3.1", "code": "Class TrackGroup {\n\tboolean equals(java.lang.Object obj);\n\t// Returns the format of the track at a given index.\n\tFormat getFormat(int index);\n\t// Returns the index of the track with the given format in the group.\n\tint indexOf(Format format);\n}", "des": "Defines a group of tracks exposed by a MediaPeriod."}
{"index": 2334, "repo": "exoplayer-r2.3.1", "code": "Class TrackGroupArray {\n\tboolean equals(java.lang.Object obj);\n\t// Returns the group at a given index.\n\tTrackGroup get(int index);\n\t// Returns the index of a group within the array.\n\tint indexOf(TrackGroup group);\n}", "des": "An array of TrackGroups exposed by a MediaPeriod."}
{"index": 2335, "repo": "exoplayer-r2.3.1", "code": "Class TrackSelectionArray {\n\tboolean equals(java.lang.Object obj);\n\t// Returns the selection at a given index.\n\tTrackSelection get(int index);\n\t// Returns the selections in a newly allocated array.\n\tTrackSelection[] getAll();\n}", "des": "The result of a TrackSelector operation."}
{"index": 2336, "repo": "exoplayer-r2.3.1", "code": "Class TrackSelectorResult {\n\t// Returns whether this result is equivalent to other for all renderers.\n\tboolean isEquivalent(TrackSelectorResult other);\n\t// Returns whether this result is equivalent to other for the renderer at the given index.\n\tboolean isEquivalent(TrackSelectorResult other, int index);\n}", "des": "The result of a TrackSelector operation."}
{"index": 2337, "repo": "exoplayer-r2.3.1", "code": "Interface TransferListener<S> {\n\t// Called incrementally during a transfer.\n\tvoid onBytesTransferred(S source, int bytesTransferred);\n\t// Called when a transfer ends.\n\tvoid onTransferEnd(S source);\n\t// Called when a transfer starts.\n\tvoid onTransferStart(S source, DataSpec dataSpec);\n}", "des": "A listener of data transfer events."}
{"index": 2338, "repo": "exoplayer-r2.3.1", "code": "Interface TsPayloadReader {\n\t// Consumes the payload of a TS packet.\n\tvoid consume(ParsableByteArray data, boolean payloadUnitStartIndicator);\n\t// Initializes the payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses TS packet payload data."}
{"index": 2339, "repo": "exoplayer-r2.3.1", "code": "Interface TsPayloadReader.Factory {\n\t// Returns the initial mapping from PIDs to payload readers.\n\tandroid.util.SparseArray<TsPayloadReader> createInitialPayloadReaders();\n\t// Returns a TsPayloadReader for a given stream type and elementary stream information.\n\tTsPayloadReader createPayloadReader(int streamType, TsPayloadReader.EsInfo esInfo);\n}", "des": "Factory of TsPayloadReader instances."}
{"index": 2340, "repo": "exoplayer-r2.3.1", "code": "Class TsPayloadReader.TrackIdGenerator {\n\t// Generates a new set of track and track format ids.\n\tvoid generateNewId();\n\t// Returns the last generated format id, with the format \"programNumber/trackId\".\n\tjava.lang.String getFormatId();\n\t// Returns the last generated track id.\n\tint getTrackId();\n}", "des": "Generates track ids for initializing TsPayloadReaders' TrackOutputs."}
{"index": 2341, "repo": "exoplayer-r2.3.1", "code": "Class UdpDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to length bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A UDP DataSource."}
{"index": 2342, "repo": "exoplayer-r2.3.1", "code": "Class UriUtil {\n\t// Performs relative resolution of a referenceUri with respect to a baseUri.\n\tstatic java.lang.String resolve(java.lang.String baseUri, java.lang.String referenceUri);\n\t// Like resolve(String, String), but returns a Uri instead of a String.\n\tstatic android.net.Uri resolveToUri(java.lang.String baseUri, java.lang.String referenceUri);\n}", "des": "Utility methods for manipulating URIs."}
{"index": 2343, "repo": "exoplayer-r2.3.1", "code": "Class UrlTemplate {\n\t// Constructs a Uri from the template, substituting in the provided arguments.\n\tjava.lang.String buildUri(java.lang.String representationId, int segmentNumber, int bandwidth, long time);\n\t// Compile an instance from the provided template string.\n\tstatic UrlTemplate compile(java.lang.String template);\n}", "des": "A template from which URLs can be built."}
{"index": 2344, "repo": "exoplayer-r2.3.1", "code": "Class VideoFrameReleaseTimeHelper {\n\t// Adjusts a frame release timestamp.\n\tlong adjustReleaseTime(long framePresentationTimeUs, long unadjustedReleaseTimeNs);\n\t// Disables the helper.\n\tvoid disable();\n\t// Enables the helper.\n\tvoid enable();\n\tprotected void onSynced();\n}", "des": "Makes a best effort to adjust frame release timestamps for a smoother visual result."}
{"index": 2345, "repo": "exoplayer-r2.3.1", "code": "Class WebvttParserUtil {\n\t// Reads lines up to and including the next WebVTT cue header.\n\tstatic java.util.regex.Matcher findNextCueHeader(ParsableByteArray input);\n\t// Parses a percentage string.\n\tstatic float parsePercentage(java.lang.String s);\n\t// Parses a WebVTT timestamp.\n\tstatic long parseTimestampUs(java.lang.String timestamp);\n\t// Reads and validates the first line of a WebVTT file.\n\tstatic void validateWebvttHeaderLine(ParsableByteArray input);\n}", "des": "Utility methods for parsing WebVTT data."}
{"index": 2346, "repo": "zookeeper-jute-3.8.2", "code": "Class RccTokenManager {\n\t// Get the next Token.\n\tToken getNextToken();\n\tprotected Token jjFillToken();\n\t// Reinitialise parser.\n\tvoid ReInit(SimpleCharStream stream);\n\t// Reinitialise parser.\n\tvoid ReInit(SimpleCharStream stream, int lexState);\n\t// Set debug output.\n\tvoid setDebugStream(PrintStream ds);\n\t// Switch to specified lex state.\n\tvoid SwitchTo(int lexState);\n}", "des": "Token Manager."}
{"index": 2347, "repo": "zookeeper-jute-3.8.2", "code": "Class Token {\n\t// An optional attribute value of the Token.\n\tObject getValue();\n\tstatic Token newToken(int ofKind);\n\t// Returns a new Token object, by default.\n\tstatic Token newToken(int ofKind, String image);\n}", "des": "Describes the input token stream."}
{"index": 2348, "repo": "nifi-utils-1.22.0", "code": "Class AbstractDemarcator {\n\tvoid close();\n\t// Will extract data token of the provided length from the current buffer starting at the 'mark'.\n\t(package private) byte[] extractDataToken(int length);\n\t// Will fill the current buffer from current 'index' position, expanding it and or shuffling it if necessary.\n\t(package private) void fill();\n\t// Validates prerequisites for constructor arguments\n\tprivate void validate(InputStream is, int maxDataSize, int initialBufferSize);\n}", "des": "Base class for implementing streaming demarcators."}
{"index": 2349, "repo": "nifi-utils-1.22.0", "code": "Enum FragmentAttributes {\n\tstatic FlowFile copyAttributesToOriginal(ProcessSession processSession, FlowFile originalFlowFile, String fragmentId, int fragmentCount);\n\tString key();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FragmentAttributes valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FragmentAttributes[] values();\n}", "des": "This enum class contains flow file attribute keys commonly used among Split processors."}
{"index": 2350, "repo": "nifi-utils-1.22.0", "code": "Class MessageDigestUtils {\n\t// Get Digest using standard algorithm\n\tstatic byte[] getDigest(byte[] bytes);\n\t// Get Digest using standard algorithm\n\tstatic byte[] getDigest(InputStream inputStream);\n\tprivate static MessageDigest getMessageDigest();\n}", "des": "Message Digest Utilities for standardized algorithm use within the framework"}
{"index": 2351, "repo": "nifi-utils-1.22.0", "code": "Class NaiveSearchRingBuffer {\n\t// Add the given byte to the buffer and notify whether or not the byte completes the desired byte sequence.\n\tboolean addAndCompare(byte data);\n\t// Clears the internal buffer so that a new search may begin\n\tvoid clear();\n\tbyte[] getBufferContents();\n\tint getOldestByte();\n\tboolean isFilled();\n}", "des": ""}
{"index": 2352, "repo": "nifi-utils-1.22.0", "code": "Interface Search<T> {\n\t// Establishes the dictionary of terms which will be searched in subsequent search calls.\n\tvoid initializeDictionary(Set<SearchTerm<T>> terms);\n\t// Searches the given input stream for matches between the already specified dictionary and the contents scanned.\n\tSearchState<T> search(InputStream haystack, boolean findAll);\n}", "des": "Defines an interface to search for content given a set of search terms. Any implementation of search must be thread safe."}
{"index": 2353, "repo": "nifi-utils-1.22.0", "code": "Enum SiteToSiteAttributes {\n\tString key();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SiteToSiteAttributes valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SiteToSiteAttributes[] values();\n}", "des": "FlowFile attributes used during site-to-site transfer."}
{"index": 2354, "repo": "nifi-utils-1.22.0", "code": "Enum StandardFlowFileMediaType {\n\t// Get Media Type Definition with type and subtype components\n\tString getMediaType();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StandardFlowFileMediaType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StandardFlowFileMediaType[] values();\n}", "des": "Enumeration of standard Flow File Media Types"}
{"index": 2355, "repo": "nifi-utils-1.22.0", "code": "Class StreamDemarcator {\n\t// Will read the next data token from the InputStream returning null when it reaches the end of the stream.\n\tbyte[] nextToken();\n\t// Validates prerequisites for constructor arguments\n\tprivate void validate(byte[] delimiterBytes);\n}", "des": "The StreamDemarcator class takes an input stream and demarcates it so it could be read (see nextToken()) as individual byte[] demarcated by the provided delimiter (see 'delimiterBytes'). If delimiter is not provided the entire stream will be read into a single token which may result in OutOfMemoryError if stream is too large. The 'maxDataSize' controls the maximum size of the buffer that accumulates a token."}
{"index": 2356, "repo": "nifi-utils-1.22.0", "code": "Interface StringSelector {\n\t// May be used to stop processing subsequent inputs when a result is already available.\n\tboolean found();\n\t// Starts the fluent expression by checking the first string(s).\n\tstatic StringSelector of(String... strings);\n\t// Check the next string(s).\n\tStringSelector or(String... strings);\n}", "des": "Fluent api for checking one or more strings and selecting the first non-empty one. #toString() returns the first encountered non-empty string or \"\"."}
{"index": 2357, "repo": "nifi-utils-1.22.0", "code": "Class TextLineDemarcator {\n\t// Will compute the next offset info for a text line (line terminated by either '\\r', '\\n' or '\\r\\n').\n\tTextLineDemarcator.OffsetInfo nextOffsetInfo();\n\t// Will compute the next offset info for a text line (line terminated by either '\\r', '\\n' or '\\r\\n').\n\tTextLineDemarcator.OffsetInfo nextOffsetInfo(byte[] startsWith);\n}", "des": "Implementation of demarcator of text lines in the provided InputStream. It works similar to the BufferedReader and its BufferedReader.readLine() methods except that it does not create a String representing the text line and instead returns the offset info for the computed text line. See nextOffsetInfo() and nextOffsetInfo(byte[]) for more details."}
{"index": 2358, "repo": "beam-runners-flink_2.10-2.2.0", "code": "Class FlinkRunner {\n\t// Attempts to detect all the resources the class loader has access to.\n\tprotected static List<String> detectClassPathResourcesToStage(ClassLoader classLoader);\n\t// Construct a runner from the provided options.\n\tstatic FlinkRunner fromOptions(PipelineOptions options);\n\t// For testing.\n\tFlinkPipelineOptions getPipelineOptions();\n\tPipelineResult run(Pipeline pipeline);\n}", "des": "A PipelineRunner that executes the operations in the pipeline by first translating them to a Flink Plan and then executing them either locally or on a Flink cluster, depending on the configuration."}
{"index": 2359, "repo": "mahout-core-14.1", "code": "Class AbstractObjectList<T> {\n\t// Appends all of the elements of the specified Collection to the receiver.\n\tvoid addAllOf(Collection<T> collection);\n\t// Inserts all elements of the specified collection before the specified position into the receiver.\n\tvoid beforeInsertAllOf(int index, Collection<T> collection);\n\t// Replaces the part of the receiver starting at from (inclusive) with all the elements of the specified collection.\n\tabstract void replaceFromWith(int from, Collection<T> other);\n}", "des": "Abstract base class for resizable lists holding objects or primitive data types such as int, float, etc.First see the package summary and javadoc tree view to get the broad picture."}
{"index": 2360, "repo": "mahout-core-14.1", "code": "Class Arithmetic {\n\t// Efficiently returns the binomial coefficient, often also referred to as \"n over k\" or \"n choose k\".\n\tstatic double binomial(long n, long k);\n\t// Returns log(k!).\n\tstatic double logFactorial(int k);\n}", "des": "Arithmetic functions."}
{"index": 2361, "repo": "mahout-core-14.1", "code": "Enum BackEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BackEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BackEnum[] values();\n}", "des": "Matrix backends"}
{"index": 2362, "repo": "mahout-core-14.1", "code": "Interface ByteComparator {\n\t// Compares its two arguments for order.\n\tint compare(byte o1, byte o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 2363, "repo": "mahout-core-14.1", "code": "Class Centroid {\n\tvoid addWeight(double newWeight);\n\t// Return a copy of the recipient\n\tCentroid clone();\n\tstatic Centroid create(int key, Vector initialValue);\n\t// Return an empty vector of the same underlying class as the receiver\n\tCentroid like();\n\tvoid update(Vector v);\n\tvoid update(Vector other, double wy);\n}", "des": "A centroid is a weighted vector. We have it delegate to the vector itself for lots of operations to make it easy to use vector search classes and such."}
{"index": 2364, "repo": "mahout-core-14.1", "code": "Interface CharComparator {\n\t// Compares its two arguments for order.\n\tint compare(char o1, char o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 2365, "repo": "mahout-core-14.1", "code": "Class CholeskyDecomposition {\n\tint[] getInversePivot();\n\tMatrix getL();\n\tPivotedMatrix getPermutedL();\n\tint[] getPivot();\n\tboolean isPositiveDefinite();\n\t// Compute inv(L) * z efficiently.\n\tMatrix solveLeft(Matrix z);\n\t// Compute z * inv(L') efficiently\n\tMatrix solveRight(Matrix z);\n}", "des": "Cholesky decomposition shamelessly ported from JAMA."}
{"index": 2366, "repo": "mahout-core-14.1", "code": "Class DenseSymmetricMatrix {\n\t// Return the value at the given indexes, without checking bounds\n\tdouble getQuick(int row, int column);\n\t// Set the value at the given index, without checking bounds\n\tvoid setQuick(int row, int column, double value);\n}", "des": "Economy packaging for a dense symmetric in-core matrix."}
{"index": 2367, "repo": "mahout-core-14.1", "code": "Interface DoubleComparator {\n\t// Compares its two arguments for order.\n\tint compare(double o1, double o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 2368, "repo": "mahout-core-14.1", "code": "Class EigenDecomposition {\n\t// Return the block diagonal eigenvalue matrix\n\tMatrix getD();\n\t// Return the imaginary parts of the eigenvalues\n\tVector getImagEigenvalues();\n\t// Return the real parts of the eigenvalues\n\tVector getRealEigenvalues();\n\t// Return the eigenvector matrix\n\tMatrix getV();\n}", "des": "Eigenvalues and eigenvectors of a real matrix."}
{"index": 2369, "repo": "mahout-core-14.1", "code": "Interface FloatComparator {\n\t// Compares its two arguments for order.\n\tint compare(float o1, float o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 2370, "repo": "mahout-core-14.1", "code": "Class HebbianSolver {\n\t// Uses the SingularVectorVerifier to check for convergence\n\tprotected boolean hasNotConverged(Vector currentPseudoEigen, Matrix corpus, TrainingState state);\n\tstatic void main(String[] args);\n\t// Primary singular vector solving method.\n\tTrainingState solve(Matrix corpus, int desiredRank);\n\tprotected EigenStatus verify(Matrix corpus, Vector currentPseudoEigen);\n}", "des": "The Hebbian solver is an iterative, sparse, singular value decomposition solver, based on the paper Generalized Hebbian Algorithm for Latent Semantic Analysis (2005) by Genevieve Gorrell and Brandyn Webb (a.k.a. Simon Funk). TODO: more description here! For now: read the inline comments, and the comments for the constructors."}
{"index": 2371, "repo": "mahout-core-14.1", "code": "Interface IntComparator {\n\t// Compares its two arguments for order.\n\tint compare(int o1, int o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 2372, "repo": "mahout-core-14.1", "code": "Interface LongComparator {\n\t// Compares its two arguments for order.\n\tint compare(long o1, long o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 2373, "repo": "mahout-core-14.1", "code": "Interface MatrixFlavor {\n\t// Whether matrix is backed by a native system -- such as java memory, lapack/atlas, Magma etc.\n\tBackEnum getBacking();\n\t// Structure flavors\n\tTraversingStructureEnum getStructure();\n\tboolean isDense();\n}", "des": "A set of matrix structure properties that I denote as \"flavor\" (by analogy to quarks)"}
{"index": 2374, "repo": "mahout-core-14.1", "code": "Interface MatrixTimesOps {\n\t// Computes matrix product of (that * this)\n\tMatrix timesLeft(Matrix that);\n\t// computes matrix product of (this * that)\n\tMatrix timesRight(Matrix that);\n}", "des": "Optional interface for optimized matrix multiplications. Some concrete Matrix implementations may mix this in."}
{"index": 2375, "repo": "mahout-core-14.1", "code": "Class Mult {\n\t// Returns the result of the function evaluation.\n\tdouble apply(double a);\n\t// a / constant.\n\tstatic Mult div(double constant);\n\tdouble getMultiplicator();\n\t// a * constant.\n\tstatic Mult mult(double constant);\n\tvoid setMultiplicator(double multiplicator);\n}", "des": "Only for performance tuning of compute intensive linear algebraic computations. Constructs functions that return one of a * constant a / constant a is variable, constant is fixed, but for performance reasons publicly accessible. Intended to be passed to matrix.assign(function) methods."}
{"index": 2376, "repo": "mahout-core-14.1", "code": "Class NegativeBinomial {\n\t// Returns the cumulative distribution function.\n\tdouble cdf(int k);\n\tint nextInt();\n\t// Returns a sample from this distribution.\n\tint nextInt(int r, double p);\n\t// Returns the probability distribution function.\n\tdouble pdf(int k);\n}", "des": "Mostly deprecated until unit tests are in place. Until this time, this class/interface is unsupported."}
{"index": 2377, "repo": "mahout-core-14.1", "code": "Class Normal {\n\t// Returns the cumulative distribution function.\n\tdouble cdf(double x);\n\t// Returns a random number from the distribution.\n\tdouble nextDouble();\n\t// Returns the probability density function.\n\tdouble pdf(double x);\n\t// Sets the uniform random generator internally used.\n\tvoid setRandomGenerator(Random randomGenerator);\n\t// Sets the mean and variance.\n\tvoid setState(double mean, double standardDeviation);\n}", "des": "Implements a normal distribution specified mean and standard deviation."}
{"index": 2378, "repo": "mahout-core-14.1", "code": "Class OldQRDecomposition {\n\t// Generates and returns the (economy-sized) orthogonal factor Q.\n\tMatrix getQ();\n\t// Returns the upper triangular factor, R.\n\tMatrix getR();\n\t// Returns whether the matrix A has full rank.\n\tboolean hasFullRank();\n\t// Least squares solution of A*X = B; returns X.\n\tMatrix solve(Matrix B);\n}", "des": "partially deprecated until unit tests are in place. Until this time, this class/interface is unsupported."}
{"index": 2379, "repo": "mahout-core-14.1", "code": "Class Polynomial {\n\t// Evaluates the given polynomial of degree N at x, assuming coefficient of N is 1.0.\n\tstatic double p1evl(double x, double[] coef, int N);\n\t// Evaluates the given polynomial of degree N at x.\n\tstatic double polevl(double x, double[] coef, int N);\n}", "des": "Polynomial functions."}
{"index": 2380, "repo": "mahout-core-14.1", "code": "Class QRDecomposition {\n\t// Generates and returns the (economy-sized) orthogonal factor Q.\n\tMatrix getQ();\n\t// Returns the upper triangular factor, R.\n\tMatrix getR();\n\t// Returns whether the matrix A has full rank.\n\tboolean hasFullRank();\n\t// Least squares solution of A*X = B; returns X.\n\tMatrix solve(Matrix B);\n}", "des": "For an m x n matrix A with m >= n, the QR decomposition is an m x n orthogonal matrix Q and an n x n upper triangular matrix R so that A = Q*R."}
{"index": 2381, "repo": "mahout-core-14.1", "code": "Class RandomEngine {\n\t// Equivalent to raw().\n\tdouble apply(double dummy);\n\t// Equivalent to nextInt().\n\tint apply(int dummy);\n\tdouble nextDouble();\n\tfloat nextFloat();\n\tabstract int nextInt();\n\tlong nextLong();\n\tdouble raw();\n}", "des": "Abstract base class for uniform pseudo-random number generating engines."}
{"index": 2382, "repo": "mahout-core-14.1", "code": "Interface ShortComparator {\n\t// Compares its two arguments for order.\n\tint compare(short o1, short o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 2383, "repo": "mahout-core-14.1", "code": "Enum TraversingStructureEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TraversingStructureEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TraversingStructureEnum[] values();\n}", "des": "STRUCTURE HINT"}
{"index": 2384, "repo": "mahout-core-14.1", "code": "Class WeightedVector {\n\t// Return a copy of the recipient\n\tWeightedVector clone();\n\tint getIndex();\n\tdouble getWeight();\n\t// Return an empty vector of the same underlying class as the receiver\n\tVector like();\n\tstatic WeightedVector project(Vector v, Vector projection);\n\tstatic WeightedVector project(Vector v, Vector projection, int index);\n\tvoid setIndex(int index);\n\tvoid setWeight(double newWeight);\n}", "des": "Decorates a vector with a floating point weight and an index."}
{"index": 2385, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class CellCounter {\n\t// Sets up the actual job.\n\tstatic org.apache.hadoop.mapreduce.Job createSubmittableJob(org.apache.hadoop.conf.Configuration conf, String[] args);\n\t// Main entry point.\n\tstatic void main(String[] args);\n\tint run(String[] args);\n}", "des": "A job with a a map and reduce phase to count cells in a table. The counter lists the following stats for a given table:"}
{"index": 2386, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class CopyTable {\n\t// Sets up the actual job.\n\torg.apache.hadoop.mapreduce.Job createSubmittableJob(String[] args);\n\t// Main entry point.\n\tstatic void main(String[] args);\n\tint run(String[] args);\n}", "des": "Tool used to copy a table to another one which can be on a different setup. It is also configurable with a start and time as well as a specification of the region server implementation if different from the local cluster."}
{"index": 2387, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class DefaultVisibilityExpressionResolver {\n\t// Convert visibility expression into tags to be serialized.\n\tList<Tag> createVisibilityExpTags(String visExpression);\n\torg.apache.hadoop.conf.Configuration getConf();\n\t// Giving a chance for the initialization.\n\tvoid init();\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "This implementation creates tags by expanding expression using label ordinal. Labels will be serialized in sorted order of it's ordinal."}
{"index": 2388, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class Export {\n\t// Sets up the actual job.\n\tstatic org.apache.hadoop.mapreduce.Job createSubmittableJob(org.apache.hadoop.conf.Configuration conf, String[] args);\n\t// Main entry point.\n\tstatic void main(String[] args);\n\tint run(String[] args);\n}", "des": "Export an HBase table. Writes content to sequence files up in HDFS. Use Import to read it back in again."}
{"index": 2389, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class HRegionPartitioner<KEY,VALUE> {\n\t// Returns the current configuration.\n\torg.apache.hadoop.conf.Configuration getConf();\n\t// Gets the partition number for a given key (hence record) given the total number of partitions i.e.\n\tint getPartition(ImmutableBytesWritable key, VALUE value, int numPartitions);\n\t// Sets the configuration.\n\tvoid setConf(org.apache.hadoop.conf.Configuration configuration);\n}", "des": "This is used to partition the output keys into groups of keys. Keys are grouped according to the regions that currently exist so that each reducer fills a single region so load is distributed."}
{"index": 2390, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class IdentityTableMap {\n\t// Use this before submitting a TableMap job.\n\tstatic void initJob(String table, String columns, Class<? extends TableMap> mapper, org.apache.hadoop.mapred.JobConf job);\n\t// Pass the key, value to reduce\n\tvoid map(ImmutableBytesWritable key, Result value, org.apache.hadoop.mapred.OutputCollector<ImmutableBytesWritable,Result> output, org.apache.hadoop.mapred.Reporter reporter);\n}", "des": "Pass the given key and record as-is to reduce"}
{"index": 2391, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class IdentityTableMapper {\n\t// Use this before submitting a TableMap job.\n\tstatic void initJob(String table, Scan scan, Class<? extends TableMapper> mapper, org.apache.hadoop.mapreduce.Job job);\n\t// Pass the key, value to reduce.\n\tvoid map(ImmutableBytesWritable key, Result value, org.apache.hadoop.mapreduce.Mapper.Context context);\n}", "des": "Pass the given key and record as-is to the reduce phase."}
{"index": 2392, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class MultiTableInputFormat {\n\t// Returns the current configuration.\n\torg.apache.hadoop.conf.Configuration getConf();\n\t// Sets the configuration.\n\tvoid setConf(org.apache.hadoop.conf.Configuration configuration);\n}", "des": "Convert HBase tabular data from multiple scanners into a format that is consumable by Map/Reduce."}
{"index": 2393, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class RoundRobinTableInputFormat {\n\t// Calculates the splits that will serve as input for the map tasks.\n\tList<org.apache.hadoop.mapreduce.InputSplit> getSplits(org.apache.hadoop.mapreduce.JobContext context);\n\t// Pass table name as argument.\n\tstatic void main(String[] args);\n}", "des": "Process the return from super-class TableInputFormat (TIF) so as to undo any clumping of InputSplits around RegionServers. Spread splits broadly to distribute read-load over RegionServers in the cluster. The super-class TIF returns splits in hbase:meta table order. Adjacent or near-adjacent hbase:meta Regions can be hosted on the same RegionServer -- nothing prevents this. This hbase:maeta ordering of InputSplit placement can be lumpy making it so some RegionServers end up hosting lots of InputSplit scans while contemporaneously other RegionServers host few or none. This class does a pass over the return from the super-class to better spread the load. See the below helpful Flipkart blog post for a description and from where the base of this code comes from (with permission)."}
{"index": 2394, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class TableSplit {\n\tint compareTo(TableSplit o);\n\tboolean equals(Object o);\n\t// Returns end row key\n\tbyte[] getEndRow();\n\tlong getLength();\n\tString[] getLocations();\n\t// Returns the region's hostname\n\tString getRegionLocation();\n\t// Returns starting row key\n\tbyte[] getStartRow();\n\t// Returns table name\n\tTableName getTable();\n\t// Returns table name\n\tbyte[] getTableName();\n\tvoid readFields(DataInput in);\n\tvoid write(DataOutput out);\n}", "des": "A table split corresponds to a key range [low, high)"}
{"index": 2395, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class VerifyReplication {\n\t// Sets up the actual job.\n\torg.apache.hadoop.mapreduce.Job createSubmittableJob(org.apache.hadoop.conf.Configuration conf, String[] args);\n\tboolean doCommandLine(String[] args);\n\t// Main entry point.\n\tstatic void main(String[] args);\n\tint run(String[] args);\n}", "des": "This map-only job compares the data from a local table with a remote one. Every cell is compared and must have exactly the same keys (even timestamp) as well as same value. It is possible to restrict the job by time range and families. The peer id that's provided must match the one given when the replication stream was setup."}
{"index": 2396, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Interface VisibilityExpressionResolver {\n\t// Convert visibility expression into tags to be serialized.\n\tList<Tag> createVisibilityExpTags(String visExpression);\n\t// Giving a chance for the initialization.\n\tvoid init();\n}", "des": "Interface to convert visibility expressions into Tags for storing along with Cells in HFiles."}
{"index": 2397, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Class WALPlayer {\n\t// Sets up the actual job.\n\torg.apache.hadoop.mapreduce.Job createSubmittableJob(String[] args);\n\t// Main entry point.\n\tstatic void main(String[] args);\n\tint run(String[] args);\n}", "des": "A tool to replay WAL files as a M/R job. The WAL can be replayed for a set of tables or all tables, and a time range can be provided (in milliseconds). The WAL is filtered to the passed set of tables and the output can optionally be mapped to another set of tables. WAL replay can also generate HFiles for later bulk importing, in that case the WAL is replayed for a single table only."}
{"index": 2398, "repo": "hbase-mapreduce-3.0.0-alpha-4", "code": "Enum WALPlayer.Counter {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WALPlayer.Counter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WALPlayer.Counter[] values();\n}", "des": "Enum for map metrics. Keep it out here rather than inside in the Map inner-class so we can find associated properties."}
{"index": 2399, "repo": "tika-parsers-1.28.5", "code": "Class ArrayNumber {\n\t// This method is used to deserialize the number of array from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of the number of array into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "The class is used to represent the number of the array."}
{"index": 2400, "repo": "tika-parsers-1.28.5", "code": "Class BasicObject {\n\t// Used to return the length of this element.\n\tint deserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// Used to return the length of this element.\n\tprotected abstract int doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// Used to parse byte array to special object.\n\tstatic <T extends BasicObject>T parse(byte[] byteArray, AtomicInteger index, Class<T> clazz);\n\t// Used to serialize item to byte list.\n\tabstract List<Byte> serializeToByteList();\n}", "des": "Base object for FSSHTTPB."}
{"index": 2401, "repo": "tika-parsers-1.28.5", "code": "Class Bit {\n\t// Set a bit value to \"Off\" in the specified byte array with the specified bit position.\n\tstatic void clearBit(byte[] array, long bit);\n\t// Read a bit value from a byte array with the specified bit position.\n\tstatic boolean isBitSet(byte[] array, long bit);\n\t// Set a bit value to \"On\" in the specified byte array with the specified bit position.\n\tstatic void setBit(byte[] array, long bit);\n}", "des": "The class is used to read/set bit value for a byte array"}
{"index": 2402, "repo": "tika-parsers-1.28.5", "code": "Class CellManifestDataElementData {\n\t// Used to return the length of this element.\n\tint deserializeDataElementDataFromByteArray(byte[] byteArray, int startIndex);\n\t// Used to convert the element into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "Cell manifest data element"}
{"index": 2403, "repo": "tika-parsers-1.28.5", "code": "Class ChmBlockInfo {\n\tstatic ChmBlockInfo getChmBlockInfoInstance(DirectoryListingEntry dle, int bytesPerBlock, ChmLzxcControlData clcd, ChmBlockInfo chmBlockInfo);\n\t// Returns the end block index\n\tint getEndBlock();\n\t// Returns the end offset index\n\tint getEndOffset();\n\t// Returns an initial block index\n\tint getIniBlock();\n\t// Returns the start block index\n\tint getStartBlock();\n\t// Returns the start offset index\n\tint getStartOffset();\n\tstatic void main(String[] args);\n}", "des": "A container that contains chm block information such as: i. initial block is using to reset main tree ii. start block is using for knowing where to start iii. end block is using for knowing where to stop iv. start offset is using for knowing where to start reading v. end offset is using for knowing where to stop reading"}
{"index": 2404, "repo": "tika-parsers-1.28.5", "code": "Enum ChmCommons.EntryType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ChmCommons.EntryType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ChmCommons.EntryType[] values();\n}", "des": "Represents entry types: uncompressed, compressed"}
{"index": 2405, "repo": "tika-parsers-1.28.5", "code": "Enum ChmCommons.IntelState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ChmCommons.IntelState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ChmCommons.IntelState[] values();\n}", "des": "Represents intel file states during decompression"}
{"index": 2406, "repo": "tika-parsers-1.28.5", "code": "Enum ChmCommons.LzxState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ChmCommons.LzxState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ChmCommons.LzxState[] values();\n}", "des": "Represents lzx states: started decoding, not started decoding"}
{"index": 2407, "repo": "tika-parsers-1.28.5", "code": "Class ChmExtractor {\n\t// Enumerates chm entities\n\tList<String> enumerateChm();\n\t// Decompresses a chm entry\n\tbyte[] extractChmEntry(DirectoryListingEntry directoryListingEntry);\n\tChmDirectoryListingSet getChmDirList();\n}", "des": "Extracts text from chm file. Enumerates chm entries."}
{"index": 2408, "repo": "tika-parsers-1.28.5", "code": "Class ChmPmgiHeader {\n\t// Returns pmgi free space\n\tlong getFreeSpace();\n\t// Returns pmgi signature if exists\n\tbyte[] getSignature();\n\t// Parses chm accessor\n\tvoid parse(byte[] data, ChmPmgiHeader chmPmgiHeader);\n\t// Sets pmgi free space\n\tprotected void setFreeSpace(long free_space);\n\t// Sets pmgi signature\n\tprotected void setSignature(byte[] signature);\n}", "des": "Description Note: not always exists An index chunk has the following format: 0000: char[4] 'PMGI' 0004: DWORD Length of quickref/free area at end of directory chunk 0008: Directory index entries (to quickref/free area) The quickref area in an PMGI is the same as in an PMGL The format of a directory index entry is as follows: BYTE: length of name BYTEs: name (UTF-8 encoded) ENCINT: directory listing chunk which starts with name Encoded Integers aka ENCINT An ENCINT is a variable-length integer. The high bit of each byte indicates \"continued to the next byte\". Bytes are stored most significant to least significant. So, for example, $EA $15 is (((0xEA&0x7F)<<7)|0x15) = 0x3515."}
{"index": 2409, "repo": "tika-parsers-1.28.5", "code": "Class ChunkingFactory {\n\t// This method is used to create the instance of AbstractChunking.\n\tstatic AbstractChunking createChunkingInstance(byte[] fileContent);\n\t// This method is used to create the instance of AbstractChunking.\n\tstatic AbstractChunking createChunkingInstance(byte[] fileContent, ChunkingMethod chunkingMethod);\n\t// This method is used to create the instance of AbstractChunking.\n\tstatic AbstractChunking createChunkingInstance(IntermediateNodeObject nodeObject);\n}", "des": "This class is used to create instance of AbstractChunking."}
{"index": 2410, "repo": "tika-parsers-1.28.5", "code": "Class Compact64bitInt {\n\t// This method is used to deserialize the Compact64bitInt basic object from the specified byte array and start index.\n\tprotected int doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\tlong getDecodedValue();\n\tint getType();\n\t// This method is used to convert the element of Compact64bitInt basic object into a byte List.\n\tList<Byte> serializeToByteList();\n\tCompact64bitInt setDecodedValue(long decodedValue);\n\tCompact64bitInt setType(int type);\n}", "des": "A 9-byte encoding of values in the range 0x0002000000000000 through 0xFFFFFFFFFFFFFFFF"}
{"index": 2411, "repo": "tika-parsers-1.28.5", "code": "Class CompactID {\n\t// This method is used to deserialize the CompactID object from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of CompactID object into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent the CompactID structrue."}
{"index": 2412, "repo": "tika-parsers-1.28.5", "code": "Class CoreNLPNERecogniser {\n\t// Gets set of entity types recognised by this recogniser\n\tSet<String> getEntityTypes();\n\t// checks if this Named Entity recogniser is available for service\n\tboolean isAvailable();\n\tstatic void main(String[] args);\n\t// recognises names of entities in the text\n\tMap<String,Set<String>> recognise(String text);\n}", "des": "This class offers an implementation of NERecogniser based on CRF classifiers from Stanford CoreNLP. This NER requires additional setup, due to runtime binding to Stanford CoreNLP. See Tika NER Wiki for configuring this recogniser."}
{"index": 2413, "repo": "tika-parsers-1.28.5", "code": "Enum CTAKESAnnotationProperty {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CTAKESAnnotationProperty valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CTAKESAnnotationProperty[] values();\n}", "des": "This enumeration includes the properties that an IdentifiedAnnotation object can provide."}
{"index": 2414, "repo": "tika-parsers-1.28.5", "code": "Enum CTAKESSerializer {\n\tString getClassName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CTAKESSerializer valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CTAKESSerializer[] values();\n}", "des": "Enumeration for types of cTAKES (UIMA) CAS serializer supported by cTAKES. A CAS serializer writes a CAS in the given format."}
{"index": 2415, "repo": "tika-parsers-1.28.5", "code": "Class DataElementData {\n\t// De-serialize data element data from byte array.\n\tabstract int deserializeDataElementDataFromByteArray(byte[] byteArray, int startIndex);\n\t// Serialize item to byte list.\n\tabstract List<Byte> serializeToByteList();\n}", "des": "Base class of data element"}
{"index": 2416, "repo": "tika-parsers-1.28.5", "code": "Class DataElementHash {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies an data element hash stream object"}
{"index": 2417, "repo": "tika-parsers-1.28.5", "code": "Enum DataElementType {\n\tstatic DataElementType fromIntVal(int intVal);\n\tint getIntVal();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DataElementType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DataElementType[] values();\n}", "des": "The enumeration of the data element type"}
{"index": 2418, "repo": "tika-parsers-1.28.5", "code": "Class DataSizeObject {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Data Size Object"}
{"index": 2419, "repo": "tika-parsers-1.28.5", "code": "Class DefaultHtmlMapper {\n\t// Checks whether all content within the given HTML element should be discarded instead of including it in the parse output.\n\tboolean isDiscardElement(String name);\n\t// Normalizes an attribute name.\n\tString mapSafeAttribute(String elementName, String attributeName);\n\t// Maps \"safe\" HTML element names to semantic XHTML equivalents.\n\tString mapSafeElement(String name);\n}", "des": "The default HTML mapping rules in Tika."}
{"index": 2420, "repo": "tika-parsers-1.28.5", "code": "Class EightBytesOfData {\n\t// This method is used to deserialize the EightBytesOfData from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of EightBytesOfData into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent the property contains 8 bytes of data in the PropertySet.rgData stream field."}
{"index": 2421, "repo": "tika-parsers-1.28.5", "code": "Class FileConfig {\n\t// Returns the \"file\" installation folder.\n\tString getFilePath();\n\t// Returns true if the mime option is enabled.\n\tboolean isMimetype();\n\t// Sets the \"file\" installation folder.\n\tvoid setFilePath(String filePath);\n\t// Sets the mime option.\n\tvoid setMimetype(boolean mimetype);\n}", "des": "Configuration for the \"file\" (or file-alternative) command."}
{"index": 2422, "repo": "tika-parsers-1.28.5", "code": "Class FourBytesOfData {\n\t// This method is used to deserialize the FourBytesOfData from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of FourBytesOfData into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent the property contains 4 bytes of data in the PropertySet.rgData stream field."}
{"index": 2423, "repo": "tika-parsers-1.28.5", "code": "Interface HtmlMapper {\n\t// Checks whether all content within the given HTML element should be discarded instead of including it in the parse output.\n\tboolean isDiscardElement(String name);\n\t// Maps \"safe\" HTML attribute names to semantic XHTML equivalents.\n\tString mapSafeAttribute(String elementName, String attributeName);\n\t// Maps \"safe\" HTML element names to semantic XHTML equivalents.\n\tString mapSafeElement(String name);\n}", "des": "HTML mapper used to make incoming HTML documents easier to handle by Tika clients. The HtmlParser looks up an optional HTML mapper from the parse context and uses it to map parsed HTML to \"safe\" XHTML. A client that wants to customize this mapping can place a custom HtmlMapper instance into the parse context."}
{"index": 2424, "repo": "tika-parsers-1.28.5", "code": "Class ID3Tags.ID3Comment {\n\t// Gets the description, if present\n\tString getDescription();\n\t// Gets the language, if present\n\tString getLanguage();\n\t// Gets the text, if present\n\tString getText();\n}", "des": "Represents a comments in ID3 (especially ID3 v2), where are made up of several parts"}
{"index": 2425, "repo": "tika-parsers-1.28.5", "code": "Class IdentityHtmlMapper {\n\t// Checks whether all content within the given HTML element should be discarded instead of including it in the parse output.\n\tboolean isDiscardElement(String name);\n\t// Maps \"safe\" HTML attribute names to semantic XHTML equivalents.\n\tString mapSafeAttribute(String elementName, String attributeName);\n\t// Maps \"safe\" HTML element names to semantic XHTML equivalents.\n\tString mapSafeElement(String name);\n}", "des": "Alternative HTML mapping rules that pass the input HTML as-is without any modifications."}
{"index": 2426, "repo": "tika-parsers-1.28.5", "code": "Interface IProperty {\n\t// This method is used to deserialize the property from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of property into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "The interface of the property in OneNote file."}
{"index": 2427, "repo": "tika-parsers-1.28.5", "code": "Class JCID {\n\t// This method is used to deserialize the JCID object from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of JCID object into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent a JCID"}
{"index": 2428, "repo": "tika-parsers-1.28.5", "code": "Class Latin1StringsParser {\n\t// Returns the minimum size of a character sequence to be extracted.\n\tint getMinSize();\n\tSet<org.apache.tika.mime.MediaType> getSupportedTypes(org.apache.tika.parser.ParseContext arg0);\n\tvoid parse(InputStream stream, ContentHandler handler, org.apache.tika.metadata.Metadata metadata, org.apache.tika.parser.ParseContext context);\n\t// Sets the minimum size of a character sequence to be extracted.\n\tvoid setMinSize(int minSize);\n}", "des": "Parser to extract printable Latin1 strings from arbitrary files with pure java without running any external process. Useful for binary or unknown files, for files without a specific parser and for corrupted ones causing a TikaException as a fallback parser. To enable the parsing of unknown or files without a specific parser with AutoDetectParser:"}
{"index": 2429, "repo": "tika-parsers-1.28.5", "code": "Class LeafNodeObject.IntermediateNodeObjectBuilder {\n\t// This method is used to build intermediate node object from a byte array with a signature\n\tLeafNodeObject Build(byte[] array, SignatureObject signature);\n\t// This method is used to build intermediate node object from an list of object group data element\n\tLeafNodeObject Build(List<ObjectGroupDataElementData> objectGroupList, ObjectGroupObjectData dataObj, ExGuid intermediateGuid);\n}", "des": "The class is used to build a intermediate node object."}
{"index": 2430, "repo": "tika-parsers-1.28.5", "code": "Class MITIENERecogniser {\n\t// Gets set of entity types recognised by this recogniser\n\tSet<String> getEntityTypes();\n\t// checks if this Named Entity recogniser is available for service\n\tboolean isAvailable();\n\t// recognises names of entities in the text\n\tMap<String,Set<String>> recognise(String text);\n}", "des": "This class offers an implementation of NERecogniser based on trained models using state-of-the-art information extraction tools. This NER requires additional setup, due to runtime binding to MIT Information Extraction. See Tika MITIE Wiki for configuring this recogniser."}
{"index": 2431, "repo": "tika-parsers-1.28.5", "code": "Interface NERecogniser {\n\t// gets a set of entity types whose names are recognisable by this\n\tSet<String> getEntityTypes();\n\t// checks if this Named Entity recogniser is available for service\n\tboolean isAvailable();\n\t// call for name recognition action from text\n\tMap<String,Set<String>> recognise(String text);\n}", "des": "Defines a contract for named entity recogniser. The NER contract includes isAvailable(), getEntityTypes() and recognise( String )"}
{"index": 2432, "repo": "tika-parsers-1.28.5", "code": "Class NLTKNERecogniser {\n\t// Gets set of entity types recognised by this recogniser\n\tSet<String> getEntityTypes();\n\t// checks if this Named Entity recogniser is available for service\n\tboolean isAvailable();\n\t// recognises names of entities in the text\n\tMap<String,Set<String>> recognise(String text);\n}", "des": "This class offers an implementation of NERecogniser based on ne_chunk() module of NLTK. This NER requires additional setup, due to Http requests to an endpoint server that runs NLTK. See"}
{"index": 2433, "repo": "tika-parsers-1.28.5", "code": "Class NoData {\n\t// This method is used to deserialize the NoData from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of NoData into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent the property contains no data."}
{"index": 2434, "repo": "tika-parsers-1.28.5", "code": "Class ObjectGroupData {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "The ObjectGroupData class."}
{"index": 2435, "repo": "tika-parsers-1.28.5", "code": "Class ObjectGroupDeclarations {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Object Group Declarations"}
{"index": 2436, "repo": "tika-parsers-1.28.5", "code": "Class ObjectGroupMetadata {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies an object group metadata"}
{"index": 2437, "repo": "tika-parsers-1.28.5", "code": "Class ObjectGroupMetadataDeclarations {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Object Metadata Declaration"}
{"index": 2438, "repo": "tika-parsers-1.28.5", "code": "Class ObjectGroupObjectBLOBDataDeclaration {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "object data BLOB declaration"}
{"index": 2439, "repo": "tika-parsers-1.28.5", "code": "Class ObjectGroupObjectDataBLOBReference {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "object data BLOB reference"}
{"index": 2440, "repo": "tika-parsers-1.28.5", "code": "Class ObjectSpaceObjectPropSet {\n\t// This method is used to deserialize the ObjectSpaceObjectPropSet from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of the ObjectSpaceObjectPropSet into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent a ObjectSpaceObjectPropSet."}
{"index": 2441, "repo": "tika-parsers-1.28.5", "code": "Class ObjectSpaceObjectStreamOfContextIDs {\n\t// This method is used to deserialize the ObjectSpaceObjectStreamOfContextIDs object from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of ObjectSpaceObjectStreamOfContextIDs object into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent a ObjectSpaceObjectStreamOfContextIDs."}
{"index": 2442, "repo": "tika-parsers-1.28.5", "code": "Class ObjectSpaceObjectStreamOfOIDs {\n\t// This method is used to deserialize the ObjectSpaceObjectStreamOfOIDs object from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of ObjectSpaceObjectStreamOfOIDs object into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent a ObjectSpaceObjectStreamOfOIDs."}
{"index": 2443, "repo": "tika-parsers-1.28.5", "code": "Class ObjectSpaceObjectStreamOfOSIDs {\n\t// This method is used to deserialize the ObjectSpaceObjectStreamOfOSIDs object from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of ObjectSpaceObjectStreamOfOSIDs object into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent a ObjectSpaceObjectStreamOfOSIDs."}
{"index": 2444, "repo": "tika-parsers-1.28.5", "code": "Class OneByteOfData {\n\t// This method is used to deserialize the OneByteOfData from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of OneByteOfData into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent the property contains 1 byte of data in the PropertySet.rgData stream field."}
{"index": 2445, "repo": "tika-parsers-1.28.5", "code": "Interface OOXMLExtractor {\n\t// Returns the opened document.\n\torg.apache.poi.ooxml.POIXMLDocument getDocument();\n\t// POIXMLTextExtractor.getMetadataTextExtractor() not yet supported for OOXML by POI.\n\tMetadataExtractor getMetadataExtractor();\n\t// Parses the document into a sequence of XHTML SAX events sent to the given content handler.\n\tvoid getXHTML(ContentHandler handler, org.apache.tika.metadata.Metadata metadata, org.apache.tika.parser.ParseContext context);\n}", "des": "Interface implemented by all Tika OOXML extractors."}
{"index": 2446, "repo": "tika-parsers-1.28.5", "code": "Class OpenNLPNameFinder {\n\t// finds names from given array of tokens\n\tMap<String,Set<String>> findNames(String[] tokens);\n\t// gets a set of entity types whose names are recognisable by this\n\tSet<String> getEntityTypes();\n\t// checks if this Named Entity recogniser is available for service\n\tboolean isAvailable();\n\t// call for name recognition action from text\n\tMap<String,Set<String>> recognise(String text);\n\tstatic String[] tokenize(String text);\n}", "des": "An implementation of NERecogniser that finds names in text using Open NLP Model. This implementation works with only one entity type. For chain this name finder instances, see OpenNLPNERecogniser"}
{"index": 2447, "repo": "tika-parsers-1.28.5", "code": "Class OpenNLPNERecogniser {\n\t// gets a set of entity types whose names are recognisable by this\n\tSet<String> getEntityTypes();\n\t// checks if this Named Entity recogniser is available for service\n\tboolean isAvailable();\n\t// call for name recognition action from text\n\tMap<String,Set<String>> recognise(String text);\n}", "des": "This implementation of NERecogniser chains an array of OpenNLPNameFinders for which NER models are available in classpath. The following models are scanned during initialization via class loader.: Entity TypePath \"ner-person.bin\" \"ner-location.bin\" \"ner-organization.bin\" \"ner-time.bin\" \"ner-date.bin\" \"ner-percentage.bin\" \"ner-money.bin\""}
{"index": 2448, "repo": "tika-parsers-1.28.5", "code": "Class PooledTimeSeriesParser {\n\t// Returns the set of media types supported by this parser when used with the given parse context.\n\tSet<org.apache.tika.mime.MediaType> getSupportedTypes(org.apache.tika.parser.ParseContext context);\n\t// Parses a document stream into a sequence of XHTML SAX events.\n\tvoid parse(InputStream stream, ContentHandler handler, org.apache.tika.metadata.Metadata metadata, org.apache.tika.parser.ParseContext context);\n}", "des": "Uses the Pooled Time Series algorithm + command line tool, to generate a numeric representation of the video suitable for similarity searches."}
{"index": 2449, "repo": "tika-parsers-1.28.5", "code": "Class PropertyID {\n\t// This method is used to deserialize the PropertyID object from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of PropertyID object into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent a PropertyID."}
{"index": 2450, "repo": "tika-parsers-1.28.5", "code": "Class PropertySet {\n\t// This method is used to deserialize the PropertySet from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of PropertySet into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent a PropertySet."}
{"index": 2451, "repo": "tika-parsers-1.28.5", "code": "Class PrtArrayOfPropertyValues {\n\t// This method is used to deserialize the prtArrayOfPropertyValues from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of the prtArrayOfPropertyValues into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "The class is used to represent the prtArrayOfPropertyValues ."}
{"index": 2452, "repo": "tika-parsers-1.28.5", "code": "Class PrtFourBytesOfLengthFollowedByData {\n\t// This method is used to deserialize the prtFourBytesOfLengthFollowedByData from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of prtFourBytesOfLengthFollowedByData into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent the prtFourBytesOfLengthFollowedByData."}
{"index": 2453, "repo": "tika-parsers-1.28.5", "code": "Class RegexNERecogniser {\n\t// finds matching sub groups in text\n\tSet<String> findMatches(String text, Pattern pattern);\n\t// gets a set of entity types whose names are recognisable by this\n\tSet<String> getEntityTypes();\n\tstatic RegexNERecogniser getInstance();\n\t// checks if this Named Entity recogniser is available for service\n\tboolean isAvailable();\n\t// call for name recognition action from text\n\tMap<String,Set<String>> recognise(String text);\n}", "des": "This class offers an implementation of NERecogniser based on Regular Expressions."}
{"index": 2454, "repo": "tika-parsers-1.28.5", "code": "Enum RequestTypes {\n\tint getIntVal();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RequestTypes valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RequestTypes[] values();\n}", "des": "The enumeration of request type."}
{"index": 2455, "repo": "tika-parsers-1.28.5", "code": "Class RevisionManifestObjectGroupReferences {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies a revision manifest object group references, each followed by object group extended GUIDs"}
{"index": 2456, "repo": "tika-parsers-1.28.5", "code": "Class RevisionManifestRootDeclare {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies a revision manifest root declare, each followed by root and object extended GUIDs"}
{"index": 2457, "repo": "tika-parsers-1.28.5", "code": "Class SentimentAnalysisParser {\n\tvoid checkInitialization(org.apache.tika.config.InitializableProblemHandler handler);\n\t// Returns the types supported\n\tSet<org.apache.tika.mime.MediaType> getSupportedTypes(org.apache.tika.parser.ParseContext context);\n\tvoid initialize(Map<String,org.apache.tika.config.Param> params);\n\t// Performs the parse\n\tvoid parse(InputStream stream, ContentHandler handler, org.apache.tika.metadata.Metadata metadata, org.apache.tika.parser.ParseContext context);\n}", "des": "This parser classifies documents based on the sentiment of document. The classifier is powered by Apache OpenNLP's Maximum Entropy Classifier"}
{"index": 2458, "repo": "tika-parsers-1.28.5", "code": "Class SignatureObject {\n\t// Used to de-serialize the element.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Signature Object"}
{"index": 2459, "repo": "tika-parsers-1.28.5", "code": "Class StorageIndexCellMapping {\n\t// Used to de-serialize the items.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies the storage index cell mappings (with cell identifier, cell mapping extended GUID, and cell mapping serial number)"}
{"index": 2460, "repo": "tika-parsers-1.28.5", "code": "Class StorageIndexRevisionMapping {\n\t// Used to de-serialize the items\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies the storage index revision mappings (with revision and revision mapping extended GUIDs, and revision mapping serial number)"}
{"index": 2461, "repo": "tika-parsers-1.28.5", "code": "Class StorageManifestRootDeclare {\n\t// Used to de-serialize the items.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies one or more storage manifest root declare."}
{"index": 2462, "repo": "tika-parsers-1.28.5", "code": "Class StorageManifestSchemaGUID {\n\t// Used to de-serialize the items.\n\tprotected void deserializeItemsFromByteArray(byte[] byteArray, AtomicInteger currentIndex, int lengthOfItems);\n\t// Used to convert the element into a byte List.\n\tprotected int serializeItemsToByteList(List<Byte> byteList);\n}", "des": "Specifies a storage manifest schema GUID"}
{"index": 2463, "repo": "tika-parsers-1.28.5", "code": "Class StreamObjectHeaderEnd16bit {\n\t// This method is used to deserialize the StreamObjectHeaderEnd16bit basic object from the specified byte array and start index.\n\tprotected int doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of StreamObjectHeaderEnd16bit basic object into a byte List.\n\tList<Byte> serializeToByteList();\n\t// This method is used to get the byte value of the 16-bit stream object header End.\n\tshort toUint16();\n}", "des": "An 16-bit header for a compound object would indicate the end of a stream object"}
{"index": 2464, "repo": "tika-parsers-1.28.5", "code": "Class StreamObjectHeaderEnd8bit {\n\t// This method is used to deserialize the StreamObjectHeaderEnd8bit basic object from the specified byte array and start index.\n\tprotected int doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of StreamObjectHeaderEnd8bit basic object into a byte List.\n\tList<Byte> serializeToByteList();\n\t// This method is used to get the byte value of the 8bit stream object header End.\n\tbyte toByte();\n}", "des": "An 8-bit header for a compound object would indicate the end of a stream object"}
{"index": 2465, "repo": "tika-parsers-1.28.5", "code": "Class StreamObjectHeaderStart16bit {\n\t// This method is used to deserialize the StreamObjectHeaderStart16bit basic object from the specified byte array and start index.\n\tprotected int doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of StreamObjectHeaderStart16bit basic object into a byte List.\n\tList<Byte> serializeToByteList();\n\t// This method is used to get the Uint16 value of the 16bit stream object header.\n\tshort ToUint16();\n}", "des": "An 16-bit header for a compound object would indicate the start of a stream object"}
{"index": 2466, "repo": "tika-parsers-1.28.5", "code": "Class StreamObjectHeaderStart32bit {\n\t// This method is used to deserialize the StreamObjectHeaderStart32bit basic object from the specified byte array and start index.\n\tprotected int doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of StreamObjectHeaderStart32bit basic object into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "An 32-bit header for a compound object would indicate the start of a stream object"}
{"index": 2467, "repo": "tika-parsers-1.28.5", "code": "Enum StreamObjectTypeHeaderStart {\n\tstatic StreamObjectTypeHeaderStart fromIntVal(int intVal);\n\tint getIntVal();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StreamObjectTypeHeaderStart valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StreamObjectTypeHeaderStart[] values();\n}", "des": "The enumeration of the stream object type header start"}
{"index": 2468, "repo": "tika-parsers-1.28.5", "code": "Enum StringsEncoding {\n\tchar get();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StringsEncoding valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StringsEncoding[] values();\n}", "des": "Character encoding of the strings that are to be found using the \"strings\" command."}
{"index": 2469, "repo": "tika-parsers-1.28.5", "code": "Class SXSLFPowerPointExtractorDecorator {\n\t// Populates the XHTMLContentHandler object received as parameter.\n\tprotected void buildXHTML(org.apache.tika.sax.XHTMLContentHandler xhtml);\n\t// In PowerPoint files, slides have things embedded in them, and slide drawings which have the images\n\tprotected List<org.apache.poi.openxml4j.opc.PackagePart> getMainDocumentParts();\n}", "des": "SAX/Streaming pptx extractior"}
{"index": 2470, "repo": "tika-parsers-1.28.5", "code": "Class SXWPFWordExtractorDecorator {\n\t// Populates the XHTMLContentHandler object received as parameter.\n\tprotected void buildXHTML(org.apache.tika.sax.XHTMLContentHandler xhtml);\n\t// This returns all items that might contain embedded objects: main document, headers, footers, comments, etc.\n\tprotected List<org.apache.poi.openxml4j.opc.PackagePart> getMainDocumentParts();\n}", "des": "This is an experimental, alternative extractor for docx files. This streams the main document content rather than loading the full document into memory."}
{"index": 2471, "repo": "tika-parsers-1.28.5", "code": "Class TwoBytesOfData {\n\t// This method is used to deserialize the TwoBytesOfData from the specified byte array and start index.\n\tint doDeserializeFromByteArray(byte[] byteArray, int startIndex);\n\t// This method is used to convert the element of TwoBytesOfData into a byte List.\n\tList<Byte> serializeToByteList();\n}", "des": "This class is used to represent the property contains 2 bytes of data in the PropertySet.rgData stream field."}
{"index": 2472, "repo": "tika-parsers-1.28.5", "code": "Class XMPMetadataExtractor {\n\t// Extracts Dublin Core.\n\tstatic void extractDublinCoreSchema(org.apache.xmpbox.XMPMetadata xmp, org.apache.tika.metadata.Metadata metadata);\n\t// Extracts basic schema metadata from XMP.\n\tstatic void extractXMPBasicSchema(org.apache.xmpbox.XMPMetadata xmp, org.apache.tika.metadata.Metadata metadata);\n\t// Parse the XMP Packets.\n\tstatic void parse(InputStream stream, org.apache.tika.metadata.Metadata metadata);\n}", "des": "XMP Metadata Extractor based on Apache XmpBox."}
{"index": 2473, "repo": "tika-parsers-1.28.5", "code": "Class ZipContainerDetector {\n\torg.apache.tika.mime.MediaType detect(InputStream input, org.apache.tika.metadata.Metadata metadata);\n\t// Detects the type of an OfficeOpenXML (OOXML) file from opened Package\n\tstatic org.apache.tika.mime.MediaType detectOfficeOpenXML(org.apache.poi.openxml4j.opc.OPCPackage pkg);\n\t// If this is less than 0, the file will be spooled to disk, and detection will run on the full file.\n\tvoid setMarkLimit(int markLimit);\n}", "des": "A detector that works on Zip documents and other archive and compression formats to figure out exactly what the file is."}
{"index": 2474, "repo": "tink-1.10.0", "code": "Interface Aead {\n\t// Decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// Encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n}", "des": "Interface for Authenticated Encryption with Associated Data (AEAD). Security guarantees"}
{"index": 2475, "repo": "tink-1.10.0", "code": "Interface AeadFactory {\n\t// Creates a new Aead-primitive that uses the key material given in symmetricKey, which must be of length getKeySizeInBytes().\n\tAead createAead(byte[] symmetricKey);\n\t// Returns the size of the AEAD key in bytes.\n\tint getKeySizeInBytes();\n}", "des": "Provides AEAD instances with a specific raw key."}
{"index": 2476, "repo": "tink-1.10.0", "code": "Class AeadKey {\n\t// Returns a Bytes instance which is prefixed to the ciphertext.\n\tabstract Bytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tabstract AeadParameters getParameters();\n}", "des": "Represents functions to encrypt and decrypt data using AEAD."}
{"index": 2477, "repo": "tink-1.10.0", "code": "Class AeadOrDaead {\n\t// Decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// Encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n}", "des": "A wrapper class that provides the functionality of an underlying Aead or Deterministic Aead primitive. This is useful for smoothing out the interface differences between those two primtives for cases where it isn't critical."}
{"index": 2478, "repo": "tink-1.10.0", "code": "Class AeadWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<Aead> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<Aead> getPrimitiveClass();\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tAead wrap(PrimitiveSet<Aead> pset);\n}", "des": "AeadWrapper is the implementation of SetWrapper for the Aead primitive."}
{"index": 2479, "repo": "tink-1.10.0", "code": "Class AesCmacKey {\n\tstatic AesCmacKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns the underlying AES key.\n\tSecretBytes getAesKey();\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns a Bytes instance which is prefixed to every mac tag.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tAesCmacParameters getParameters();\n}", "des": "Represents a key computing AES-CMAC."}
{"index": 2480, "repo": "tink-1.10.0", "code": "Class AesCmacPrfKey {\n\tstatic AesCmacPrfKey create(AesCmacPrfParameters parameters, SecretBytes keyBytes);\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\tSecretBytes getKeyBytes();\n\t// Returns the parameters of this key.\n\tAesCmacPrfParameters getParameters();\n}", "des": "Represents a key computing AES CMAC PRF."}
{"index": 2481, "repo": "tink-1.10.0", "code": "Class AesCtrHmacStreamingKey {\n\tstatic AesCtrHmacStreamingKey create(AesCtrHmacStreamingParameters parameters, SecretBytes initialKeymaterial);\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\tSecretBytes getInitialKeyMaterial();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tAesCtrHmacStreamingParameters getParameters();\n}", "des": "Represents a StreamingAead functions."}
{"index": 2482, "repo": "tink-1.10.0", "code": "Class AesCtrJceCipher {\n\t// Decrypts the ciphertext with counter mode decryption.\n\tbyte[] decrypt(byte[] ciphertext);\n\t// Encrypts the plaintext with counter mode encryption using randomly generated iv.\n\tbyte[] encrypt(byte[] plaintext);\n}", "des": "The primitive implements AES counter mode with random IVs, using JCE. Warning"}
{"index": 2483, "repo": "tink-1.10.0", "code": "Class AesEaxJce {\n\t// Decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// Encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n}", "des": "This class implements the EAX mode using AES."}
{"index": 2484, "repo": "tink-1.10.0", "code": "Class AesEaxKey {\n\tstatic AesEaxKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns the underlying key bytes.\n\tSecretBytes getKeyBytes();\n\t// Returns a Bytes instance which is prefixed to the ciphertext.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tAesEaxParameters getParameters();\n}", "des": "Represents an AES-EAX key used for computing AEAD."}
{"index": 2485, "repo": "tink-1.10.0", "code": "Class AesEaxParameters {\n\tstatic AesEaxParameters.Builder builder();\n\tboolean equals(Object o);\n\tint getIvSizeBytes();\n\tint getKeySizeBytes();\n\tint getTagSizeBytes();\n\t// Returns a variant object.\n\tAesEaxParameters.Variant getVariant();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of an AesEaxKey."}
{"index": 2486, "repo": "tink-1.10.0", "code": "Class AesEaxParameters.Builder {\n\tAesEaxParameters build();\n\t// IV size must be 12 or 16 bytes.\n\tAesEaxParameters.Builder setIvSizeBytes(int ivSizeBytes);\n\t// Accepts key sizes of 16, 24 or 32 bytes.\n\tAesEaxParameters.Builder setKeySizeBytes(int keySizeBytes);\n\t// The tag size accepts values between 0 and 16 bytes.\n\tAesEaxParameters.Builder setTagSizeBytes(int tagSizeBytes);\n\tAesEaxParameters.Builder setVariant(AesEaxParameters.Variant variant);\n}", "des": "Builds a new AesEaxParameters instance."}
{"index": 2487, "repo": "tink-1.10.0", "code": "Class AesGcmFactory {\n\t// Creates a new Aead-primitive that uses the key material given in symmetricKey, which must be of length AeadFactory.getKeySizeInBytes().\n\tAead createAead(byte[] symmetricKey);\n\t// Returns the size of the AEAD key in bytes.\n\tint getKeySizeInBytes();\n}", "des": "An AeadFactory that creates new instances of AES-GCM from raw keys"}
{"index": 2488, "repo": "tink-1.10.0", "code": "Class AesGcmHkdfStreamingKey {\n\tstatic AesGcmHkdfStreamingKey create(AesGcmHkdfStreamingParameters parameters, SecretBytes initialKeymaterial);\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\tSecretBytes getInitialKeyMaterial();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tAesGcmHkdfStreamingParameters getParameters();\n}", "des": "Represents a StreamingAead functions."}
{"index": 2489, "repo": "tink-1.10.0", "code": "Class AesGcmHkdfStreamingParameters {\n\tstatic AesGcmHkdfStreamingParameters.Builder builder();\n\tboolean equals(Object o);\n\t// Returns the size a ciphertext segment has.\n\tint getCiphertextSegmentSizeBytes();\n\t// Returns the size of the AES GCM key which will internally be derived.\n\tint getDerivedAesGcmKeySizeBytes();\n\t// Returns the type of the hash function used in HKDF.\n\tAesGcmHkdfStreamingParameters.HashType getHkdfHashType();\n\t// Returns the size of the initial key material.\n\tint getKeySizeBytes();\n}", "des": "Represents the parameters of a AesGcmHkdfStreamingKey."}
{"index": 2490, "repo": "tink-1.10.0", "code": "Class AesGcmJce {\n\t// On Android KitKat (API level 19) this method does not support non null or non empty associatedData.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// On Android KitKat (API level 19) this method does not support non null or non empty associatedData.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n}", "des": "This primitive implements AesGcm using JCE."}
{"index": 2491, "repo": "tink-1.10.0", "code": "Class AesGcmKey {\n\tstatic AesGcmKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns the underlying key bytes.\n\tSecretBytes getKeyBytes();\n\t// Returns a Bytes instance which is prefixed to the ciphertext.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tAesGcmParameters getParameters();\n}", "des": "Represents an AES-GCM key used for computing AEAD."}
{"index": 2492, "repo": "tink-1.10.0", "code": "Class AesGcmParameters {\n\tstatic AesGcmParameters.Builder builder();\n\tboolean equals(Object o);\n\tint getIvSizeBytes();\n\tint getKeySizeBytes();\n\tint getTagSizeBytes();\n\t// Returns a variant object.\n\tAesGcmParameters.Variant getVariant();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of an AesGcmKey"}
{"index": 2493, "repo": "tink-1.10.0", "code": "Class AesGcmParameters.Builder {\n\tAesGcmParameters build();\n\t// IV size must greater than 0.\n\tAesGcmParameters.Builder setIvSizeBytes(int ivSizeBytes);\n\t// Accepts key sizes of 16, 24 or 32 bytes.\n\tAesGcmParameters.Builder setKeySizeBytes(int keySizeBytes);\n\t// Tag size must be one of the following five values: 128, 120, 112, 104 or 96 bytes\n\tAesGcmParameters.Builder setTagSizeBytes(int tagSizeBytes);\n\tAesGcmParameters.Builder setVariant(AesGcmParameters.Variant variant);\n}", "des": "Builds a new AesGcmParameters instance. The class AesGcmParameters is not responsible for checking if all allowed values for the parameters are implemented and satisfy any potential security policies. Some implementation may not support the full set of parameters at the moment and may restrict them to certain lengths (i.e. key size may be restricted to 16 or 32 bytes)."}
{"index": 2494, "repo": "tink-1.10.0", "code": "Class AesGcmSiv {\n\t// On Android KitKat (API level 19) this method does not support non null or non empty associatedData.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// On Android KitKat (API level 19) this method does not support non null or non empty associatedData.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n}", "des": "This primitive implements AES-GCM-SIV (as defined in RFC 8452) using JCE."}
{"index": 2495, "repo": "tink-1.10.0", "code": "Class AesGcmSivKey {\n\tstatic AesGcmSivKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns the underlying key bytes.\n\tSecretBytes getKeyBytes();\n\t// Returns a Bytes instance which is prefixed to the ciphertext.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tAesGcmSivParameters getParameters();\n}", "des": "Represents an AES-GCM-SIV key used for computing AEAD."}
{"index": 2496, "repo": "tink-1.10.0", "code": "Class AesGcmSivParameters {\n\tstatic AesGcmSivParameters.Builder builder();\n\tboolean equals(Object o);\n\tint getKeySizeBytes();\n\t// Returns a variant object.\n\tAesGcmSivParameters.Variant getVariant();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of an AesGcmSivSivKey"}
{"index": 2497, "repo": "tink-1.10.0", "code": "Class AesSiv {\n\t// Deterministically decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decryptDeterministically(byte[] ciphertext, byte[] associatedData);\n\t// Deterministically encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encryptDeterministically(byte[] plaintext, byte[] associatedData);\n}", "des": "AES-SIV, as described in RFC 5297."}
{"index": 2498, "repo": "tink-1.10.0", "code": "Class AesSivKey {\n\tstatic AesSivKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns the underlying key bytes.\n\tSecretBytes getKeyBytes();\n\t// Returns a Bytes instance which is prefixed to the ciphertext.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tAesSivParameters getParameters();\n}", "des": "Represents an AES--SIV key used for computing deterministic AEAD, as described in https://www.rfc-editor.org/rfc/rfc5297."}
{"index": 2499, "repo": "tink-1.10.0", "code": "Class AesSivParameters {\n\tstatic AesSivParameters.Builder builder();\n\tboolean equals(Object o);\n\tint getKeySizeBytes();\n\t// Returns a variant object.\n\tAesSivParameters.Variant getVariant();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of an AesSivSivKey"}
{"index": 2500, "repo": "tink-1.10.0", "code": "Class AesUtil {\n\t// Pad by adding a 1 bit, then pad with 0 bits to the next block limit.\n\tstatic byte[] cmacPad(byte[] x);\n\t// Multiplies value by x in the finite field GF(2^128) represented using the primitive polynomial x^128 + x^7 + x^2 + x + 1.\n\tstatic byte[] dbl(byte[] value);\n}", "des": "A collection of byte-manipulation functions, and some more specific functions for AES-CMAC / AES-SIV."}
{"index": 2501, "repo": "tink-1.10.0", "code": "Class BigIntegerEncoding {\n\t// Parses a BigInteger from a byte array using unsigned big-endian encoding.\n\tstatic BigInteger fromUnsignedBigEndianBytes(byte[] bytes);\n\t// Encodes a non-negative BigInteger into the minimal two's-complement representation in big-endian byte-order.\n\tstatic byte[] toBigEndianBytes(BigInteger n);\n\t// Encodes a non-negative BigInteger into a byte array of a specified length, using big-endian byte-order.\n\tstatic byte[] toBigEndianBytesOfFixedLength(BigInteger n, int length);\n}", "des": "Helper class with functions that encode and decode non-negative BigInteger to and from byte[]."}
{"index": 2502, "repo": "tink-1.10.0", "code": "Class BinaryKeysetReader {\n\t// Tries to read and return a cleartext Keyset.\n\tKeyset read();\n\t// Tries to read and return an EncryptedKeyset.\n\tEncryptedKeyset readEncrypted();\n\t// Static method to create a BinaryKeysetReader from a byte arrary.\n\tstatic KeysetReader withBytes(byte[] bytes);\n\t// Static method to create a BinaryKeysetReader from an InputStream.\n\tstatic KeysetReader withInputStream(InputStream stream);\n}", "des": "A KeysetReader that can read from some source cleartext or encrypted keysets in proto binary wire format."}
{"index": 2503, "repo": "tink-1.10.0", "code": "Class BinaryKeysetWriter {\n\t// Static method to create a BinaryKeysetWriter that writes to an OutputStream.\n\tstatic KeysetWriter withOutputStream(OutputStream stream);\n\t// Tries to write an EncryptedKeyset to some storage system.\n\tvoid write(EncryptedKeyset keyset);\n\t// Tries to write a Keyset to some storage system.\n\tvoid write(Keyset keyset);\n}", "des": "A KeysetWriter that can write to some source cleartext or encrypted keysets in proto binary wire format."}
{"index": 2504, "repo": "tink-1.10.0", "code": "Class ChaCha20Poly1305 {\n\t// Decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// Encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n}", "des": "ChaCha20Poly1305 AEAD construction, as described in RFC 8439, section 2.8."}
{"index": 2505, "repo": "tink-1.10.0", "code": "Class ChaCha20Poly1305Parameters {\n\tstatic ChaCha20Poly1305Parameters create();\n\tstatic ChaCha20Poly1305Parameters create(ChaCha20Poly1305Parameters.Variant variant);\n\tboolean equals(Object o);\n\t// Returns a variant object.\n\tChaCha20Poly1305Parameters.Variant getVariant();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of an ChaChaPoly1305Key."}
{"index": 2506, "repo": "tink-1.10.0", "code": "Class ChunkedAesCmacImpl {\n\t// Creates an instance of a single Chunked MAC computation.\n\tChunkedMacComputation createComputation();\n\t// Creates an instance of a single Chunked MAC verification.\n\tChunkedMacVerification createVerification(byte[] tag);\n}", "des": "AES-CMAC implementation of the ChunkedMac interface."}
{"index": 2507, "repo": "tink-1.10.0", "code": "Class ChunkedHmacImpl {\n\t// Creates an instance of a single Chunked MAC computation.\n\tChunkedMacComputation createComputation();\n\t// Creates an instance of a single Chunked MAC verification.\n\tChunkedMacVerification createVerification(byte[] tag);\n}", "des": "Class that provides the functionality expressed by the ChunkedMac interface with HMAC."}
{"index": 2508, "repo": "tink-1.10.0", "code": "Interface ChunkedMac {\n\t// Creates an instance of a single Chunked MAC computation.\n\tChunkedMacComputation createComputation();\n\t// Creates an instance of a single Chunked MAC verification.\n\tChunkedMacVerification createVerification(byte[] tag);\n}", "des": "An interface representing Streaming MAC. This interface should only be used for authentication. It should NOT be used for other purposes; for instance, it is not guaranteed that this interface produces pseudorandom bytes."}
{"index": 2509, "repo": "tink-1.10.0", "code": "Interface ChunkedMacComputation {\n\t// Computes a tag for the provided data.\n\tbyte[] computeMac();\n\t// Processes the next chunk of input, represented by ByteBuffer data.\n\tvoid update(ByteBuffer data);\n}", "des": "An interface representing a computation of the Streaming MAC."}
{"index": 2510, "repo": "tink-1.10.0", "code": "Interface ChunkedMacVerification {\n\t// Processes the next chunk of input, represented by ByteBuffer data.\n\tvoid update(ByteBuffer data);\n\t// Verifies that the provided data matches the tag.\n\tvoid verifyMac();\n}", "des": "An interface representing a verification of the Streaming MAC."}
{"index": 2511, "repo": "tink-1.10.0", "code": "Class ChunkedMacWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<ChunkedMac> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<ChunkedMac> getPrimitiveClass();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tChunkedMac wrap(PrimitiveSet<ChunkedMac> primitives);\n}", "des": "ChunkedMacWrapper is the implementation of PrimitiveWrapper for the ChunkedMac primitive."}
{"index": 2512, "repo": "tink-1.10.0", "code": "Class CleartextKeysetHandle {\n\t// Returns a KeysetHandle for keyset.\n\tstatic KeysetHandle fromKeyset(Keyset keyset);\n\tstatic Keyset getKeyset(KeysetHandle keysetHandle);\n\tstatic KeysetHandle read(KeysetReader reader);\n\t// Creates a KeysetHandle from a KeysetReader.\n\tstatic KeysetHandle read(KeysetReader reader, Map<String,String> monitoringAnnotations);\n\t// Serializes and writes the Keyset managed by handle to keysetWriter.\n\tstatic void write(KeysetHandle handle, KeysetWriter keysetWriter);\n}", "des": "Static methods for reading or writing cleartext keysets. WARNING"}
{"index": 2513, "repo": "tink-1.10.0", "code": "Class Config {\n\t// Returns a KeyTypeEntry for Tink key types with the specified properties.\n\tstatic KeyTypeEntry getTinkKeyTypeEntry(String catalogueName, String primitiveName, String keyProtoName, int keyManagerVersion, boolean newKeyAllowed);\n\t// Tries to register key managers according to the specification in config.\n\tstatic void register(RegistryConfig config);\n\t// Tries to register a key manager according to the specification in entry.\n\tstatic void registerKeyType(KeyTypeEntry entry);\n}", "des": "Static methods for handling of Tink configurations."}
{"index": 2514, "repo": "tink-1.10.0", "code": "Interface DeterministicAead {\n\t// Deterministically decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decryptDeterministically(byte[] ciphertext, byte[] associatedData);\n\t// Deterministically encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encryptDeterministically(byte[] plaintext, byte[] associatedData);\n}", "des": "Interface for Deterministic Authenticated Encryption with Associated Data (Deterministic AEAD)."}
{"index": 2515, "repo": "tink-1.10.0", "code": "Class DeterministicAeadKey {\n\t// Returns a Bytes instance which is prefixed to the ciphertext.\n\tabstract Bytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tabstract DeterministicAeadParameters getParameters();\n}", "des": "Represents functions to encrypt and decrypt data deterministically using AEAD."}
{"index": 2516, "repo": "tink-1.10.0", "code": "Class DeterministicAeadWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<DeterministicAead> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<DeterministicAead> getPrimitiveClass();\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tDeterministicAead wrap(PrimitiveSet<DeterministicAead> primitives);\n}", "des": "The implementation of PrimitiveWrapper<DeterministicAead>."}
{"index": 2517, "repo": "tink-1.10.0", "code": "Class EcdsaPrivateKey {\n\tstatic EcdsaPrivateKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns the parameters of this key.\n\tEcdsaParameters getParameters();\n\tSecretBigInteger getPrivateValue();\n\t// Returns the SignaturePublicKey, which contains the verify function of the digital signature primitive.\n\tEcdsaPublicKey getPublicKey();\n}", "des": "Represents a key for computing ECDSA signatures."}
{"index": 2518, "repo": "tink-1.10.0", "code": "Class EcdsaPublicKey {\n\tstatic EcdsaPublicKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns a Bytes instance which is prefixed to every signature.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tEcdsaParameters getParameters();\n\tECPoint getPublicPoint();\n}", "des": "EcdsaPublicKey represents the public portion of ECDSA signature primitive."}
{"index": 2519, "repo": "tink-1.10.0", "code": "Class Ed25519Parameters {\n\t// Creates an instance with NO_PREFIX variant.\n\tstatic Ed25519Parameters create();\n\t// Creates an instance with given variant.\n\tstatic Ed25519Parameters create(Ed25519Parameters.Variant variant);\n\tboolean equals(Object o);\n\t// Returns a variant object.\n\tEd25519Parameters.Variant getVariant();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "This class describes the parameters of an Ed25519Key."}
{"index": 2520, "repo": "tink-1.10.0", "code": "Class Ed25519PrivateKey {\n\tstatic Ed25519PrivateKey create(Ed25519PublicKey publicKey, SecretBytes privateKeyBytes);\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns the parameters of this key.\n\tEd25519Parameters getParameters();\n\tSecretBytes getPrivateKeyBytes();\n\t// Returns the SignaturePublicKey, which contains the verify function of the digital signature primitive.\n\tEd25519PublicKey getPublicKey();\n}", "des": "The key for computing Ed25519 signatures."}
{"index": 2521, "repo": "tink-1.10.0", "code": "Class Ed25519Sign.KeyPair {\n\tbyte[] getPrivateKey();\n\tbyte[] getPublicKey();\n\t// Returns a new KeyPair.\n\tstatic Ed25519Sign.KeyPair newKeyPair();\n\t// Returns a new KeyPair generated from a seed.\n\tstatic Ed25519Sign.KeyPair newKeyPairFromSeed(byte[] secretSeed);\n}", "des": "Defines the KeyPair consisting of a private key and its corresponding public key."}
{"index": 2522, "repo": "tink-1.10.0", "code": "Enum EllipticCurves.CurveType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EllipticCurves.CurveType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EllipticCurves.CurveType[] values();\n}", "des": "Elliptic curve types."}
{"index": 2523, "repo": "tink-1.10.0", "code": "Enum EllipticCurves.EcdsaEncoding {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EllipticCurves.EcdsaEncoding valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EllipticCurves.EcdsaEncoding[] values();\n}", "des": "Ecdsa signature encoding."}
{"index": 2524, "repo": "tink-1.10.0", "code": "Enum EllipticCurves.PointFormatType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EllipticCurves.PointFormatType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EllipticCurves.PointFormatType[] values();\n}", "des": "Point formats."}
{"index": 2525, "repo": "tink-1.10.0", "code": "Class EncryptThenAuthenticate {\n\t// Decrypts ciphertext with associatedData as associated data.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// Encrypts plaintext with associatedData.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n\t// Returns a new EncryptThenAuthenticate instance using AES-CTR and HMAC.\n\tstatic Aead newAesCtrHmac(byte[] aesCtrKey, int ivSize, String hmacAlgorithm, byte[] hmacKey, int tagSize);\n}", "des": "This primitive performs an encrypt-then-Mac operation on plaintext and associated data (ad)."}
{"index": 2526, "repo": "tink-1.10.0", "code": "Enum Enums.HashType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Enums.HashType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Enums.HashType[] values();\n}", "des": "Hash type."}
{"index": 2527, "repo": "tink-1.10.0", "code": "Class EnumTypeProtoConverter<E extends Enum<E>,O> {\n\tstatic <E extends Enum<E>,O>EnumTypeProtoConverter.Builder<E,O> builder();\n\t// Converts protoEnum to the equivalent object enum.\n\tO fromProtoEnum(E protoEnum);\n\t// Converts objectEnum to the equivalent proto enum.\n\tE toProtoEnum(O objectEnum);\n}", "des": "Utility class for bidirectional conversion to and from proto enum types."}
{"index": 2528, "repo": "tink-1.10.0", "code": "Class Hex {\n\t// Decodes a hex string to a byte array.\n\tstatic byte[] decode(String hex);\n\t// Encodes a byte array to hex.\n\tstatic String encode(byte[] bytes);\n}", "des": "Helper methods for encode/decode hex strings."}
{"index": 2529, "repo": "tink-1.10.0", "code": "Class Hkdf {\n\t// Computes symmetric key for ECIES with HKDF from the provided parameters.\n\tstatic byte[] computeEciesHkdfSymmetricKey(byte[] ephemeralPublicKeyBytes, byte[] sharedSecret, String hmacAlgo, byte[] hkdfSalt, byte[] hkdfInfo, int keySizeInBytes);\n\t// Computes an HKDF.\n\tstatic byte[] computeHkdf(String macAlgorithm, byte[] ikm, byte[] salt, byte[] info, int size);\n}", "des": "This class implements HMAC-based Extract-and-Expand Key Derivation Function (HKDF), as described in RFC 5869."}
{"index": 2530, "repo": "tink-1.10.0", "code": "Class HkdfPrfKey {\n\tstatic HkdfPrfKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\tSecretBytes getKeyBytes();\n\t// Returns the parameters of this key.\n\tHkdfPrfParameters getParameters();\n}", "des": "Represents a key computing HKDF PRF."}
{"index": 2531, "repo": "tink-1.10.0", "code": "Class HkdfPrfParameters {\n\tstatic HkdfPrfParameters.Builder builder();\n\tboolean equals(Object o);\n\tHkdfPrfParameters.HashType getHashType();\n\tint getKeySizeBytes();\n\t// Gets the salt value, which defaults to null if not set, as per RFC 5869.\n\tBytes getSalt();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of an HkdfPrfKey."}
{"index": 2532, "repo": "tink-1.10.0", "code": "Class HmacKey {\n\tstatic HmacKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns the underlying key bytes.\n\tSecretBytes getKeyBytes();\n\t// Returns a Bytes instance which is prefixed to every mac tag.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tHmacParameters getParameters();\n}", "des": "Represents a key computing HMAC."}
{"index": 2533, "repo": "tink-1.10.0", "code": "Class HmacPrfKey {\n\tstatic HmacPrfKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\tSecretBytes getKeyBytes();\n\t// Returns the parameters of this key.\n\tHmacPrfParameters getParameters();\n}", "des": "Represents a key computing HMAC PRF."}
{"index": 2534, "repo": "tink-1.10.0", "code": "Class HpkePrivateKey {\n\t// Creates a new HPKE private key.\n\tstatic HpkePrivateKey create(HpkePublicKey publicKey, SecretBytes privateKeyBytes);\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tHpkeParameters getParameters();\n\tSecretBytes getPrivateKeyBytes();\n\tHpkePublicKey getPublicKey();\n}", "des": "Representation of the decryption function for an HPKE hybrid encryption primitive."}
{"index": 2535, "repo": "tink-1.10.0", "code": "Class HpkePublicKeyManager {\n\t// Returns the type URL that identifies the key type of keys managed by this KeyManager.\n\tString getKeyType();\n\t// Returns the version number of this KeyManager.\n\tint getVersion();\n\t// Returns the KeyData.KeyMaterialType for this proto.\n\tKeyData.KeyMaterialType keyMaterialType();\n\t// Parses a serialized key proto.\n\tHpkePublicKey parseKey(com.google.protobuf.ByteString byteString);\n\t// Checks if the given keyProto is a valid key.\n\tvoid validateKey(HpkePublicKey key);\n}", "des": "Key manager that produces new instances of HpkeEncrypt primitive."}
{"index": 2536, "repo": "tink-1.10.0", "code": "Class HybridDecryptWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<HybridDecrypt> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<HybridDecrypt> getPrimitiveClass();\n\t// Register the wrapper within the registry.\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tHybridDecrypt wrap(PrimitiveSet<HybridDecrypt> primitives);\n}", "des": "The implementation of PrimitiveWrapper<HybridDecrypt>."}
{"index": 2537, "repo": "tink-1.10.0", "code": "Class HybridEncryptWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<HybridEncrypt> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<HybridEncrypt> getPrimitiveClass();\n\t// Register the wrapper within the registry.\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tHybridEncrypt wrap(PrimitiveSet<HybridEncrypt> primitives);\n}", "des": "The implementation of PrimitiveWrapper<HybridEncrypt>."}
{"index": 2538, "repo": "tink-1.10.0", "code": "Class HybridPrivateKey {\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns a Bytes instance, which is prefixed to every ciphertext.\n\tBytes getOutputPrefix();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tHybridParameters getParameters();\n\tabstract HybridPublicKey getPublicKey();\n}", "des": "Representation of the decryption function for a hybrid encryption primitive."}
{"index": 2539, "repo": "tink-1.10.0", "code": "Class HybridPublicKey {\n\t// Returns a Bytes instance, which is prefixed to every ciphertext.\n\tabstract Bytes getOutputPrefix();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tabstract HybridParameters getParameters();\n}", "des": "Representation of the encryption function for a hybrid encryption primitive."}
{"index": 2540, "repo": "tink-1.10.0", "code": "Interface IndCpaCipher {\n\t// Decrypts ciphertext.\n\tbyte[] decrypt(byte[] ciphertext);\n\t// Encrypts plaintext.\n\tbyte[] encrypt(byte[] plaintext);\n}", "des": "This interface for symmetric key ciphers that are indistinguishable against chosen-plaintext attacks."}
{"index": 2541, "repo": "tink-1.10.0", "code": "Class InsecureNonceAesGcmJce {\n\t// On Android KitKat (API level 19) this method does not support non null or non empty associatedData.\n\tbyte[] decrypt(byte[] iv, byte[] ciphertext, byte[] associatedData);\n\t// On Android KitKat (API level 19) this method does not support non null or non empty associatedData.\n\tbyte[] encrypt(byte[] iv, byte[] plaintext, byte[] associatedData);\n}", "des": "Insecure version of AesGcmJce that allows the caller to set the IV."}
{"index": 2542, "repo": "tink-1.10.0", "code": "Class InsecureNonceXChaCha20 {\n\t// Decrypts ciphertext using nonce.\n\tbyte[] decrypt(byte[] nonce, byte[] ciphertext);\n\t// Decrypts ciphertext using nonce.\n\tbyte[] decrypt(byte[] nonce, ByteBuffer ciphertext);\n\t// Encrypts plaintext using nonce.\n\tbyte[] encrypt(byte[] nonce, byte[] plaintext);\n\t// Encrypts plaintext using nonce and writes result to output.\n\tvoid encrypt(ByteBuffer output, byte[] nonce, byte[] plaintext);\n}", "des": "InsecureNonceXChaCha20 stream cipher based on https://download.libsodium.org/doc/advanced/xchacha20.html and https://tools.ietf.org/html/draft-arciszewski-xchacha-01."}
{"index": 2543, "repo": "tink-1.10.0", "code": "Class JsonKeysetWriter {\n\t// Static method to create a JsonKeysetWriter that writes to an OutputStream.\n\tstatic KeysetWriter withOutputStream(OutputStream stream);\n\t// Tries to write an EncryptedKeyset to some storage system.\n\tvoid write(EncryptedKeyset keyset);\n\t// Tries to write a Keyset to some storage system.\n\tvoid write(Keyset keyset);\n}", "des": "A KeysetWriter that can write to some source cleartext or encrypted keysets in proto JSON format."}
{"index": 2544, "repo": "tink-1.10.0", "code": "Class JwkSetConverter {\n\t// Converts a Tink KeysetHandle with JWT public keys into a Json Web Key (JWK) set.\n\tstatic String fromPublicKeysetHandle(KeysetHandle handle);\n\t// Converts a Json Web Key (JWK) set with public keys into a Tink KeysetHandle.\n\tstatic KeysetHandle toPublicKeysetHandle(String jwkSet);\n}", "des": "Provides functions to import and export public Json Web Key (JWK) sets."}
{"index": 2545, "repo": "tink-1.10.0", "code": "Class JwtEcdsaParameters {\n\t// If true, tokens without \"kid\" header are allowed when verifying a token.\n\tboolean allowKidAbsent();\n\tstatic JwtEcdsaParameters.Builder builder();\n\tboolean equals(Object o);\n\tJwtEcdsaParameters.Algorithm getAlgorithm();\n\tJwtEcdsaParameters.KidStrategy getKidStrategy();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of a JwtEcdsaPrivateKey or a JwtEcdsaPublicKey."}
{"index": 2546, "repo": "tink-1.10.0", "code": "Class JwtEcdsaPrivateKey {\n\tstatic JwtEcdsaPrivateKey create(JwtEcdsaPublicKey publicKey, SecretBigInteger privateValue);\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tJwtEcdsaParameters getParameters();\n\tSecretBigInteger getPrivateValue();\n\tJwtEcdsaPublicKey getPublicKey();\n}", "des": "Represents a key for computing JWT ECDSA signatures (ES256, ES384, ES512)."}
{"index": 2547, "repo": "tink-1.10.0", "code": "Class JwtEcdsaPublicKey {\n\tstatic JwtEcdsaPublicKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns the \"kid\" to be used for this key (https://www.rfc-editor.org/rfc/rfc7517#section-4.5).\n\tOptional<String> getKid();\n\t// Returns the parameters of this key.\n\tJwtEcdsaParameters getParameters();\n\tECPoint getPublicPoint();\n}", "des": "JwtEcdsaPublicKey represents the public portion of JWT ECDSA keys."}
{"index": 2548, "repo": "tink-1.10.0", "code": "Class JwtHmacKey {\n\tstatic JwtHmacKey.Builder builder();\n\t// Returns true if the key is guaranteed to be equal to other.\n\tboolean equalsKey(Key o);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\tSecretBytes getKeyBytes();\n\t// Returns the \"kid\" to be used for this key.\n\tOptional<String> getKid();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tJwtHmacParameters getParameters();\n}", "des": "Represents a JWT HMAC key to create and verify JWT using HMAC."}
{"index": 2549, "repo": "tink-1.10.0", "code": "Class JwtHmacParameters {\n\t// If true, tokens without \"kid\" header are allowed when verifying a token.\n\tboolean allowKidAbsent();\n\tstatic JwtHmacParameters.Builder builder();\n\tboolean equals(Object o);\n\tJwtHmacParameters.Algorithm getAlgorithm();\n\tint getKeySizeBytes();\n\tJwtHmacParameters.KidStrategy getKidStrategy();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of a JwtHmacKey."}
{"index": 2550, "repo": "tink-1.10.0", "code": "Interface JwtMac {\n\t// Computes a MAC, and encodes the JWT and the MAC in the JWS compact serialization format.\n\tString computeMacAndEncode(RawJwt token);\n\t// Decodes and verifies a JWT in the JWS compact serialization format.\n\tVerifiedJwt verifyMacAndDecode(String compact, JwtValidator validator);\n}", "des": "Interface for authenticating and verifying JWT with JWS MAC, as described in RFC 7519 and RFC 7515. Security guarantees: similar to Mac."}
{"index": 2551, "repo": "tink-1.10.0", "code": "Class JwtMacKey {\n\t// Returns the \"kid\" to be used for this key (https://www.rfc-editor.org/rfc/rfc7517#section-4.5).\n\tabstract Optional<String> getKid();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tabstract JwtMacParameters getParameters();\n}", "des": "Represents a key to compute JWT using symmetric cryptography (i.e., using the JwtMac interface)."}
{"index": 2552, "repo": "tink-1.10.0", "code": "Class JwtSignaturePrivateKey {\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns the \"kid\" to be used for this key (https://www.rfc-editor.org/rfc/rfc7517#section-4.5).\n\tOptional<String> getKid();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tabstract JwtSignatureParameters getParameters();\n\tabstract JwtSignaturePublicKey getPublicKey();\n}", "des": "Represents a key to compute JWT using asymmetric cryptography (i.e., using the JwtPublicKeySign interface)."}
{"index": 2553, "repo": "tink-1.10.0", "code": "Class JwtSignaturePublicKey {\n\t// Returns the \"kid\" to be used for this key (https://www.rfc-editor.org/rfc/rfc7517#section-4.5).\n\tabstract Optional<String> getKid();\n\t// Returns the parameters of this key.\n\tabstract JwtSignatureParameters getParameters();\n}", "des": "Represents a key to verify JWT using asymmetric cryptography (i.e., using the JwtPublicKeyVerify interface)."}
{"index": 2554, "repo": "tink-1.10.0", "code": "Class Key {\n\t// Returns true if the key is guaranteed to be equal to other.\n\tabstract boolean equalsKey(Key other);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tabstract Integer getIdRequirementOrNull();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tabstract Parameters getParameters();\n}", "des": "Represents a cryptographic object."}
{"index": 2555, "repo": "tink-1.10.0", "code": "Class KeyAccess {\n\t// Returns true if the KeyAccess instance grants access to a key's secret\n\tboolean canAccessSecret();\n\t// Returns a KeyAccess instance where canAccessSecret() returns false.\n\tstatic KeyAccess publicAccess();\n}", "des": "An access token for TinkKey. Access to Tink keys is governed by KeyHandle. A TinkKey which does not have a secret should be accessible by tokens generated by KeyAccess.publicAccess(). A TinkKey with a secret should need a token generated by SecretKeyAccess.secretAccess()."}
{"index": 2556, "repo": "tink-1.10.0", "code": "Enum KeyHandle.KeyStatusType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic KeyHandle.KeyStatusType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic KeyHandle.KeyStatusType[] values();\n}", "des": "KeyStatusType is metadata associated to a key which is only meaningful when the key is part of a Keyset. A key's status in the Keyset is either ENABLED (able to perform cryptographic operations), DISABLED (unable to perform operations, but could be re-enabled), or DESTROYED (the key's data is no longer present in the keyset)."}
{"index": 2557, "repo": "tink-1.10.0", "code": "Class KeysDownloader.Builder {\n\tKeysDownloader build();\n\t// Sets the background executor.\n\tKeysDownloader.Builder setExecutor(Executor val);\n\t// Sets the HTTP transport.\n\tKeysDownloader.Builder setHttpTransport(com.google.api.client.http.HttpTransport httpTransport);\n\t// Sets the url which must point to a HTTPS server.\n\tKeysDownloader.Builder setUrl(String val);\n}", "des": "Builder for KeysDownloader."}
{"index": 2558, "repo": "tink-1.10.0", "code": "Class KeysetDeriverWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<KeysetDeriver> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<KeysetDeriver> getPrimitiveClass();\n\t// Registers this wrapper with Tink, allowing to use the primitive.\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tKeysetDeriver wrap(PrimitiveSet<KeysetDeriver> primitiveSet);\n}", "des": "KeysetDeriverWrapper is the implementation of PrimitiveWrapper for the KeysetDeriver primitive."}
{"index": 2559, "repo": "tink-1.10.0", "code": "Class KeysetHandle.Entry {\n\tint getId();\n\t// May return an internal class LegacyProtoKey in case there is no implementation of the corresponding key class yet.\n\tKey getKey();\n\tKeyStatus getStatus();\n\t// Guaranteed to be true in exactly one entry.\n\tboolean isPrimary();\n}", "des": "Represents a single entry in a keyset."}
{"index": 2560, "repo": "tink-1.10.0", "code": "Interface KeysetReader {\n\t// Tries to read and return a cleartext Keyset.\n\tKeyset read();\n\t// Tries to read and return an EncryptedKeyset.\n\tEncryptedKeyset readEncrypted();\n}", "des": "A KeysetReader knows how to read a Keyset or an EncryptedKeyset from some source."}
{"index": 2561, "repo": "tink-1.10.0", "code": "Interface KeysetWriter {\n\t// Tries to write an EncryptedKeyset to some storage system.\n\tvoid write(EncryptedKeyset keyset);\n\t// Tries to write a Keyset to some storage system.\n\tvoid write(Keyset keyset);\n}", "des": "A KeysetWriter knows how to write a Keyset or an EncryptedKeyset to some storage system."}
{"index": 2562, "repo": "tink-1.10.0", "code": "Class KeyStatusTypeProtoConverter {\n\t// Converts a KeyHandle.KeyStatusType proto enum into a KeyHandle.KeyStatusType enum\n\tstatic KeyHandle.KeyStatusType fromProto(KeyStatusType keyStatusTypeProto);\n\t// Converts a KeyHandle.KeyStatusType enum into a KeyHandle.KeyStatusType proto enum\n\tstatic KeyStatusType toProto(KeyHandle.KeyStatusType status);\n}", "des": "Util functions to facilitate conversion between the KeyHandle.KeyStatusType enum and KeyHandle.KeyStatusType proto."}
{"index": 2563, "repo": "tink-1.10.0", "code": "Enum KeyTemplate.OutputPrefixType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic KeyTemplate.OutputPrefixType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic KeyTemplate.OutputPrefixType[] values();\n}", "des": "Tink produces and accepts ciphertexts or signatures that consist of a prefix and a payload. The payload and its format is determined entirely by the primitive, but the prefix has to be one of the following 4 types: Legacy: prefix is 5 bytes, starts with \\x00 and followed by a 4-byte key id that is computed from the key material. Crunchy: prefix is 5 bytes, starts with \\x00 and followed by a 4-byte key id that is generated randomly. Tink : prefix is 5 bytes, starts with \\x01 and followed by 4-byte key id that is generated randomly. Raw : prefix is 0 byte, i.e., empty."}
{"index": 2564, "repo": "tink-1.10.0", "code": "Interface KeyWrap {\n\t// Unwraps a wrapped key.\n\tbyte[] unwrap(byte[] data);\n\t// Wraps some key material data.\n\tbyte[] wrap(byte[] data);\n}", "des": "Interface for symmetric Key wrapping. A key wrap algorithm is a primitive specifically meant for encrypting key material. Primitives implementing the interface may either be deterministic or non-deterministic. The interface is somewhat limited. It does not allow additional data during key wrapping. The security guarantees are not including a multi user setting. The reason for these limitations is that it allows to include KWP, with the plan to allow rotation to other algorithms. Requirements Primitives implementing use key sizes of 128-bits or higher. Key wrapping includes an integrity check. The minimal strength of the integrity check is about 64 bits. In particular, the minimal key strength allows KWP to be included. Key size of the wrapped key. Valid key sizes are in the range 16 .. 4096 bytes. The lower bound assures a low probability of key collisions, and hence allows deterministic key wrappings to be used."}
{"index": 2565, "repo": "tink-1.10.0", "code": "Interface KmsClient {\n\tboolean doesSupport(String keyUri);\n\t// Gets an Aead backed by keyUri.\n\tAead getAead(String keyUri);\n\t// Loads the credentials in credentialPath.\n\tKmsClient withCredentials(String credentialPath);\n\t// Loads the default credentials.\n\tKmsClient withDefaultCredentials();\n}", "des": "A KmsClient knows how to produce primitives backed by keys stored in remote KMS services."}
{"index": 2566, "repo": "tink-1.10.0", "code": "Class KmsClients {\n\t// Adds a client to the list of known KmsClient-objects.\n\tstatic void add(KmsClient client);\n\t// Returns the first KmsClient registered with add(com.google.crypto.tink.KmsClient) that supports keyUri.\n\tstatic KmsClient get(String keyUri);\n\t// Returns the first KmsClient automatically loaded with ServiceLoader that supports keyUri.\n\tstatic KmsClient getAutoLoaded(String keyUri);\n}", "des": "A container for KmsClient-objects that are needed by KeyManager-objects for primitives that use KMS-managed keys."}
{"index": 2567, "repo": "tink-1.10.0", "code": "Class KmsEnvelopeAead {\n\t// Decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// Encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n\tstatic boolean isSupportedDekKeyType(String dekKeyTypeUrl);\n}", "des": "This primitive implements envelope encryption."}
{"index": 2568, "repo": "tink-1.10.0", "code": "Class LegacyProtoKey {\n\t// Returns true if we are sure that the other key is the same.\n\tboolean equalsKey(Key key);\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns a LegacyParametersNotForCreation object.\n\tParameters getParameters();\n\t// Returns the protokeyserialization with which this object was created.\n\tProtoKeySerialization getSerialization(SecretKeyAccess access);\n}", "des": "Implements a Key for legacy types where no actual parser is present."}
{"index": 2569, "repo": "tink-1.10.0", "code": "Class LegacyProtoParameters {\n\tboolean equals(Object o);\n\t// returns the serialization which was used to create this object.\n\tProtoParametersSerialization getSerialization();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Implements a Parameters object for legacy types where no actual Parameters object is present."}
{"index": 2570, "repo": "tink-1.10.0", "code": "Interface Mac {\n\t// Computes message authentication code (MAC) for data.\n\tbyte[] computeMac(byte[] data);\n\t// Verifies whether mac is a correct authentication code (MAC) for data.\n\tvoid verifyMac(byte[] mac, byte[] data);\n}", "des": "Interface for Message Authentication Codes (MAC). Security guarantees"}
{"index": 2571, "repo": "tink-1.10.0", "code": "Class MacKey {\n\t// Returns a Bytes instance which is prefixed to every mac tag.\n\tabstract Bytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tabstract MacParameters getParameters();\n}", "des": "Represents functions to compute and verify a cryptographic MAC."}
{"index": 2572, "repo": "tink-1.10.0", "code": "Enum PemKeyType {\n\t// Reads a single key from reader.\n\tKey readKey(BufferedReader reader);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PemKeyType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PemKeyType[] values();\n}", "des": "PEM key types that Tink supports"}
{"index": 2573, "repo": "tink-1.10.0", "code": "Class Poly1305 {\n\t// Computes Poly1305 MAC over data using key.\n\tstatic byte[] computeMac(byte[] key, byte[] data);\n\t// Verifies Poly1305 over data using key.\n\tstatic void verifyMac(byte[] key, byte[] data, byte[] mac);\n}", "des": "Poly1305 one-time MAC based on RFC 7539."}
{"index": 2574, "repo": "tink-1.10.0", "code": "Class PrfBasedKeyDerivationParameters {\n\tstatic PrfBasedKeyDerivationParameters.Builder builder();\n\tboolean equals(Object o);\n\t// The parameters of the keys which are in the result keyset when the user calls KeysetDeriver.deriveKeyset().\n\tParameters getDerivedKeyParameters();\n\t// The parameters of the PRF used to create randomness from the salt.\n\tPrfParameters getPrfParameters();\n}", "des": "Represents the parameters needed in a PrfBasedKeyDerivationKey."}
{"index": 2575, "repo": "tink-1.10.0", "code": "Class PrfBasedKeyDerivationParameters.Builder {\n\tPrfBasedKeyDerivationParameters build();\n\t// The parameters of the keys which are in the result keyset when the user calls KeysetDeriver.deriveKeyset().\n\tPrfBasedKeyDerivationParameters.Builder setDerivedKeyParameters(Parameters derivedKeyParameters);\n\t// Sets the parameters of the PRF used to create randomness from the salt.\n\tPrfBasedKeyDerivationParameters.Builder setPrfParameters(PrfParameters prfParameters);\n}", "des": "Builds a new PrfBasedKeyDerivationParameters instance."}
{"index": 2576, "repo": "tink-1.10.0", "code": "Class PrfHmacJce {\n\t// Computes the PRF selected by the underlying key on input and returns the first outputLength bytes.\n\tbyte[] compute(byte[] data, int outputLength);\n\t// Given an HmacPrfKey, returns an instance of the Prf interface.\n\tstatic Prf create(HmacPrfKey key);\n\t// Returns the maximum supported tag length.\n\tint getMaxOutputLength();\n}", "des": "Prf implementation using JCE."}
{"index": 2577, "repo": "tink-1.10.0", "code": "Class PrfImpl {\n\t// Computes the PRF selected by the underlying key on input and returns the first outputLength bytes.\n\tbyte[] compute(byte[] input, int outputLength);\n\t// Creates a Prf primitive from a StreamingPrf primitive.\n\tstatic PrfImpl wrap(StreamingPrf prfStreamer);\n}", "des": "Class that implements the Prf primitive by wrapping a StreamingPrf."}
{"index": 2578, "repo": "tink-1.10.0", "code": "Class PrfMac {\n\t// Computes message authentication code (MAC) for data.\n\tbyte[] computeMac(byte[] data);\n\t// Creates an object implementing the Mac interface using an AesCmac underneath.\n\tstatic Mac create(AesCmacKey key);\n\t// Creates an object implementing the Mac interface using an Hmac underneath.\n\tstatic Mac create(HmacKey key);\n\t// Verifies whether mac is a correct authentication code (MAC) for data.\n\tvoid verifyMac(byte[] mac, byte[] data);\n}", "des": "Class that provides the functionality expressed by the Mac primitive using a Prf implementation."}
{"index": 2579, "repo": "tink-1.10.0", "code": "Class PrfSet {\n\t// Convenience method to compute the primary PRF on a given input.\n\tbyte[] computePrimary(byte[] input, int outputLength);\n\t// A map of the PRFs represented by the keys in this keyset.\n\tabstract Map<Integer,Prf> getPrfs();\n\t// Returns the primary ID of the keyset.\n\tabstract int getPrimaryId();\n}", "des": "A Tink Keyset can be converted into a set of PRFs using this primitive. Every key in the keyset corresponds to a PRF in the PRFSet. Every PRF in the set is given an ID, which is the same ID as the key id in the Keyset."}
{"index": 2580, "repo": "tink-1.10.0", "code": "Class PrfSetWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<Prf> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<PrfSet> getPrimitiveClass();\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tPrfSet wrap(PrimitiveSet<Prf> set);\n}", "des": "PrfSetWrapper is the implementation of PrimitiveWrapper for the PrfSet primitive."}
{"index": 2581, "repo": "tink-1.10.0", "code": "Class PrimitiveSet.Entry<P> {\n\t// Returns the full primitive for this entry.\n\tP getFullPrimitive();\n\tbyte[] getIdentifier();\n\tKey getKey();\n\tint getKeyId();\n\tString getKeyType();\n\tOutputPrefixType getOutputPrefixType();\n\tParameters getParameters();\n\t// Returns the primitive for this entry.\n\tP getPrimitive();\n\tKeyStatusType getStatus();\n}", "des": "A single entry in the set. In addition to the actual primitive it holds also some extra information about the primitive."}
{"index": 2582, "repo": "tink-1.10.0", "code": "Interface PrimitiveWrapper<B,P> {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<B> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<P> getPrimitiveClass();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tP wrap(PrimitiveSet<B> primitiveSet);\n}", "des": "Basic interface for wrapping a primitive."}
{"index": 2583, "repo": "tink-1.10.0", "code": "Class PrivateKeyTypeManager<KeyProtoT extends com.google.protobuf.MessageLite,PublicKeyProtoT extends com.google.protobuf.MessageLite> {\n\t// Creates a public key from the given private key.\n\tabstract PublicKeyProtoT getPublicKey(KeyProtoT keyProto);\n\t// Returns the class corresponding to the public key protobuffer.\n\tClass<PublicKeyProtoT> getPublicKeyClass();\n}", "des": "A PrivateKeyManager is like an KeyTypeManager, but additionally has a method to create a public key."}
{"index": 2584, "repo": "tink-1.10.0", "code": "Class ProtoKey {\n\t// A TinkKey should know the KeyTemplate from which it was generated, which in turn specifies the cryptographic algorithm in which the TinkKey should be used.\n\tKeyTemplate getKeyTemplate();\n\tKeyTemplate.OutputPrefixType getOutputPrefixType();\n\tKeyData getProtoKey();\n\t// Returns true if the key contains secret key material, and false otherwise.\n\tboolean hasSecret();\n}", "des": "Wraps the proto KeyData as an implementation of a TinkKey. The underlying KeyData determines whether this ProtoKey has a secret."}
{"index": 2585, "repo": "tink-1.10.0", "code": "Class PublicKeySignWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<PublicKeySign> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<PublicKeySign> getPrimitiveClass();\n\t// Register the wrapper within the registry.\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tPublicKeySign wrap(PrimitiveSet<PublicKeySign> primitives);\n}", "des": "The implementation of PrimitiveWrapper<PublicKeySign>."}
{"index": 2586, "repo": "tink-1.10.0", "code": "Class Random {\n\t// Returns a random byte array of size size.\n\tstatic byte[] randBytes(int size);\n\tstatic int randInt();\n\tstatic int randInt(int max);\n\t// Throws a GeneralSecurityException if the provider is not Conscrypt.\n\tstatic void validateUsesConscrypt();\n}", "des": "Provides secure randomness using SecureRandom."}
{"index": 2587, "repo": "tink-1.10.0", "code": "Class Random {\n\t// Returns a random byte array of size size.\n\tstatic byte[] randBytes(int size);\n\t// Returns a random int.\n\tstatic int randInt();\n\t// Returns a random int between 0 and max-1.\n\tstatic int randInt(int max);\n}", "des": "Provides secure randomness using SecureRandom."}
{"index": 2588, "repo": "tink-1.10.0", "code": "Class RewindableReadableByteChannel {\n\tvoid close();\n\t// Disables the rewinding feature.\n\tvoid disableRewinding();\n\tboolean isOpen();\n\tint read(ByteBuffer dst);\n\t// Rewinds this buffer to the beginning (if rewinding is still enabled).\n\tvoid rewind();\n}", "des": "A wrapper around ReadableByteChannel that provides rewinding feature: it caches the read bytes so that after reading some initial part of the channel, one can \"rewind\" the channel and again read the bytes from the beginning. Once the rewinding feature is not needed any more, it can be disabled via disableRewinding(): this frees the cache memory and forwadrds the subsequent read(java.nio.ByteBuffer)-calls directly to the wrapped channel."}
{"index": 2589, "repo": "tink-1.10.0", "code": "Class SecretBigInteger {\n\t// Returns true if other has the same secret value.\n\tboolean equalsSecretBigInteger(SecretBigInteger other);\n\t// Creates a new SecretBigInteger with the content given in value.\n\tstatic SecretBigInteger fromBigInteger(BigInteger value, SecretKeyAccess access);\n\t// Returns the value wrapped by this object.\n\tBigInteger getBigInteger(SecretKeyAccess access);\n}", "des": "A class storing a secret BigInteger, protecting the value via SecretKeyAccess."}
{"index": 2590, "repo": "tink-1.10.0", "code": "Class SignaturePemKeysetReader {\n\t// Returns a SignaturePemKeysetReader.Builder for SignaturePemKeysetReader.\n\tstatic SignaturePemKeysetReader.Builder newBuilder();\n\t// Tries to read and return a cleartext Keyset.\n\tKeyset read();\n\t// Tries to read and return an EncryptedKeyset.\n\tEncryptedKeyset readEncrypted();\n}", "des": "SignaturePemKeysetReader is a KeysetReader that can read digital signature keys in PEM format (RFC 7468)."}
{"index": 2591, "repo": "tink-1.10.0", "code": "Class SignaturePrivateKey {\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns a Bytes instance which is prefixed to every signature.\n\tBytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tSignatureParameters getParameters();\n\t// Returns the SignaturePublicKey, which contains the verify function of the digital signature primitive.\n\tabstract SignaturePublicKey getPublicKey();\n}", "des": "A SignaturePrivateKey represents a digital signature primitive, which consists of a sign and a verify function."}
{"index": 2592, "repo": "tink-1.10.0", "code": "Class SignaturePublicKey {\n\t// Returns a Bytes instance which is prefixed to every signature.\n\tabstract Bytes getOutputPrefix();\n\t// Returns the parameters of this key.\n\tabstract SignatureParameters getParameters();\n}", "des": "A SignaturePublicKey represents the verification portion of a digital signature primitive."}
{"index": 2593, "repo": "tink-1.10.0", "code": "Class StreamingAeadKey {\n\t// Returns null if this key has no id requirement, otherwise the required id.\n\tInteger getIdRequirementOrNull();\n\t// Returns a Parameters object containing all the information about the key which is not randomly chosen.\n\tabstract StreamingAeadParameters getParameters();\n}", "des": "Represents functions to encrypt and decrypt data using a StreamingAead."}
{"index": 2594, "repo": "tink-1.10.0", "code": "Class StreamingAeadWrapper {\n\t// Returns the primitive class object of the primitive used to create B.\n\tClass<StreamingAead> getInputPrimitiveClass();\n\t// Returns the primitive class object of the primitive managed.\n\tClass<StreamingAead> getPrimitiveClass();\n\tstatic void register();\n\t// Wraps a PrimitiveSet and returns a single instance.\n\tStreamingAead wrap(PrimitiveSet<StreamingAead> primitives);\n}", "des": "StreamingAeadWrapper is the implementation of PrimitiveWrapper for the StreamingAead primitive."}
{"index": 2595, "repo": "tink-1.10.0", "code": "Interface StreamSegmentEncrypter {\n\t// Encrypts the next plaintext segment.\n\tvoid encryptSegment(ByteBuffer plaintext, boolean isLastSegment, ByteBuffer ciphertext);\n\t// Encrypt a segment consisting of two parts.\n\tvoid encryptSegment(ByteBuffer part1, ByteBuffer part2, boolean isLastSegment, ByteBuffer ciphertext);\n\t// Returns the header of the ciphertext stream.\n\tByteBuffer getHeader();\n}", "des": "StreamSegmentEncrypter is a helper class that encrypts individual segments of a stream."}
{"index": 2596, "repo": "tink-1.10.0", "code": "Class TinkBugException {\n\t// Swallows an exception and translates it into a TinkBugException.\n\tstatic void exceptionIsBug(TinkBugException.ThrowingRunnable v);\n\t// Swallows an exception and translates it into a TinkBugException.\n\tstatic <T> T exceptionIsBug(TinkBugException.ThrowingSupplier<T> t);\n}", "des": "An exception to be thrown in case there is a bug in Tink."}
{"index": 2597, "repo": "tink-1.10.0", "code": "Enum TinkFipsUtil.AlgorithmFipsCompatibility {\n\tabstract boolean isCompatible();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TinkFipsUtil.AlgorithmFipsCompatibility valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TinkFipsUtil.AlgorithmFipsCompatibility[] values();\n}", "des": "The status of FIPS compatibility of an algorithm."}
{"index": 2598, "repo": "tink-1.10.0", "code": "Interface TinkKey {\n\t// A TinkKey should know the KeyTemplate from which it was generated, which in turn specifies the cryptographic algorithm in which the TinkKey should be used.\n\tKeyTemplate getKeyTemplate();\n\t// Returns true if the key contains secret key material, and false otherwise.\n\tboolean hasSecret();\n}", "des": "TinkKey represents how Tink views individual keys. In contrast, KeysetHandle only provides access to a Keyset, which represents multiple keys."}
{"index": 2599, "repo": "tink-1.10.0", "code": "Class TinkProtoParametersFormat {\n\t// Parses a byte[] into a parameters object into a byte[] according to Tink's binary format.\n\tstatic Parameters parse(byte[] serializedParameters);\n\t// Serializes a parameters object into a byte[] according to Tink's binary format.\n\tstatic byte[] serialize(Parameters parameters);\n}", "des": "Functions to parse and serialize Parameters in Tink's binary format based on Protobufs."}
{"index": 2600, "repo": "tink-1.10.0", "code": "Class X25519 {\n\t// Returns the 32-byte shared key (i.e., privateKeypeersPublicValue on the curve).\n\tstatic byte[] computeSharedSecret(byte[] privateKey, byte[] peersPublicValue);\n\t// Returns a 32-byte private key for Curve25519.\n\tstatic byte[] generatePrivateKey();\n\t// Returns the 32-byte Diffie-Hellman public value based on the given privateKey (i.e., privateKey[9] on the curve).\n\tstatic byte[] publicFromPrivate(byte[] privateKey);\n}", "des": "Defines the ECDH Curve25519 function, also known as the X25519 function."}
{"index": 2601, "repo": "tink-1.10.0", "code": "Class XChaCha20Poly1305 {\n\t// Decrypts ciphertext with associatedData as associated authenticated data.\n\tbyte[] decrypt(byte[] ciphertext, byte[] associatedData);\n\t// Encrypts plaintext with associatedData as associated authenticated data.\n\tbyte[] encrypt(byte[] plaintext, byte[] associatedData);\n}", "des": "XChaCha20Poly1305 AEAD construction, as described in https://tools.ietf.org/html/draft-arciszewski-xchacha-01."}
{"index": 2602, "repo": "tink-1.10.0", "code": "Class XChaCha20Poly1305Parameters {\n\tstatic XChaCha20Poly1305Parameters create();\n\tstatic XChaCha20Poly1305Parameters create(XChaCha20Poly1305Parameters.Variant variant);\n\tboolean equals(Object o);\n\t// Returns a variant object.\n\tXChaCha20Poly1305Parameters.Variant getVariant();\n\t// Returns true if a key created with the parameters in this object has to have a certain ID when it is in a keyset.\n\tboolean hasIdRequirement();\n}", "des": "Describes the parameters of an XChaChaPoly1305Key."}
{"index": 2603, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Interface Allocator {\n\t// Allocates multiple buffers of a given size.\n\tvoid allocateMultiple(MemoryBuffer[] dest, int size, Allocator.BufferObjectFactory factory);\n\t// Deallocates a memory buffer.\n\tvoid deallocate(MemoryBuffer buffer);\n\t// Maximum allocation size supported by this allocator.\n\tint getMaxAllocation();\n\t// Whether the allocator uses direct buffers.\n\tboolean isDirectAlloc();\n}", "des": "An allocator provided externally to storage classes to allocate MemoryBuffer-s."}
{"index": 2604, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class BloomKFilter.BitSet {\n\t// Number of bits\n\tint bitSize();\n\t// Clear the bit set.\n\tvoid clear();\n\t// Returns true if the bit is set in the specified index.\n\tboolean get(int index);\n\tlong[] getData();\n\t// Combines the two BitArrays using bitwise OR.\n\tvoid putAll(BloomKFilter.BitSet array);\n\t// Sets the bit at specified index.\n\tvoid set(int index);\n}", "des": "Bare metal bit set implementation. For performance reasons, this implementation does not check for index bounds nor expand the bit set size if the specified index is greater than the size."}
{"index": 2605, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class CacheTag.MultiPartitionCacheTag {\n\tint compareTo(CacheTag o);\n\t// Returns the encoded partition desc.\n\tString[] getEncodedPartitionDesc();\n\t// Returns a map of partition keys and values built from the information of this CacheTag.\n\tLinkedHashMap<String,String> getPartitionDescMap();\n\t// Returns a pretty printed String version of the partitionDesc in the format of p1=v1/p2=v2...\n\tString partitionDescToString();\n}", "des": "CacheTag for tables with more than one partition level."}
{"index": 2606, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class CacheTag.PartitionCacheTag {\n\t// Returns the encoded partition desc.\n\tabstract String[] getEncodedPartitionDesc();\n\t// Returns a map of partition keys and values built from the information of this CacheTag.\n\tabstract LinkedHashMap<String,String> getPartitionDescMap();\n\t// Returns a pretty printed String version of the partitionDesc in the format of p1=v1/p2=v2...\n\tabstract String partitionDescToString();\n}", "des": "CacheTag for tables with partitions."}
{"index": 2607, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class CacheTag.SinglePartitionCacheTag {\n\tint compareTo(CacheTag o);\n\t// Returns the encoded partition desc.\n\tString[] getEncodedPartitionDesc();\n\t// Returns a map of partition keys and values built from the information of this CacheTag.\n\tLinkedHashMap<String,String> getPartitionDescMap();\n\t// Returns a pretty printed String version of the partitionDesc in the format of p1=v1/p2=v2...\n\tString partitionDescToString();\n}", "des": "CacheTag for tables with exactly one partition level."}
{"index": 2608, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Enum ColumnVector.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ColumnVector.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ColumnVector.Type[] values();\n}", "des": "The current kinds of column vectors."}
{"index": 2609, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class DateColumnVector {\n\t// Change the calendar to or from proleptic.\n\tvoid changeCalendar(boolean useProleptic, boolean updateData);\n\tString formatDate(int i);\n\t// Detect whether this data is using the proleptic calendar.\n\tboolean isUsingProlepticCalendar();\n\tDateColumnVector setUsingProlepticCalendar(boolean usingProlepticCalendar);\n\t// Shallow copy of the contents of this vector to the other vector; replaces other vector's values.\n\tvoid shallowCopyTo(ColumnVector otherCv);\n}", "des": "This class extends LongColumnVector in order to introduce some date-specific semantics. In DateColumnVector, the elements of vector[] represent the days since 1970-01-01"}
{"index": 2610, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Interface FilterContext {\n\t// Return an int array with the rows that pass the filter.\n\tint[] getSelected();\n\t// Return the number of rows that pass the filter.\n\tint getSelectedSize();\n\t// Is the filter applied?\n\tboolean isSelectedInUse();\n\t// Reset FilterContext variables.\n\tvoid reset();\n}", "des": "A representation of a Filter applied on the rows of a VectorizedRowBatch VectorizedRowBatch. Each FilterContext consists of an array with the ids (int) of rows that are selected by the filter, an integer representing the number of selected rows, and a boolean showing if the filter actually selected any rows."}
{"index": 2611, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class MaterializationSnapshot {\n\t// Returns the json representation of this object.\n\tString asJsonString();\n\tstatic MaterializationSnapshot fromJson(String jsonString);\n\t// Gets the snapshotIds of the MV source tables when the MV was created/last rebuilt\n\tMap<String,SnapshotContext> getTableSnapshots();\n\t// Gets ValidTxnWriteIdList of the MV source tables when the MV was created/last rebuilt\n\tString getValidTxnList();\n}", "des": "Class to store snapshot data of Materialized view source tables. The data represents the state of the source tables when the view was created/last rebuilt."}
{"index": 2612, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Interface Pool.PoolObjectHelper<T> {\n\t// Called to create an object when one cannot be provided.\n\tT create();\n\t// Called before the object is put in the pool (regardless of whether put succeeds).\n\tvoid resetBeforeOffer(T t);\n}", "des": "Object helper for objects stored in the pool."}
{"index": 2613, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Interface PredicateLeaf {\n\t// Get the simple column name.\n\tString getColumnName();\n\t// Get the id of the leaf.\n\tint getId();\n\t// Get the literal half of the predicate leaf.\n\tObject getLiteral();\n\t// For operators with multiple literals (IN and BETWEEN), get the literals.\n\tList<Object> getLiteralList();\n\t// Get the operator for the leaf.\n\tPredicateLeaf.Operator getOperator();\n\t// Get the type of the column and literal by the file format.\n\tPredicateLeaf.Type getType();\n}", "des": "The primitive predicates that form a SearchArgument."}
{"index": 2614, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Enum PredicateLeaf.Operator {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PredicateLeaf.Operator valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PredicateLeaf.Operator[] values();\n}", "des": "The possible operators for predicates. To get the opposites, construct an expression with a not operator."}
{"index": 2615, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Enum PredicateLeaf.Type {\n\t// For all SARG leaves, the values must be the matching class.\n\tClass getValueClass();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PredicateLeaf.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PredicateLeaf.Type[] values();\n}", "des": "The possible types for sargs."}
{"index": 2616, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Interface SearchArgument {\n\t// Evaluate the entire predicate based on the values for the leaf predicates.\n\tSearchArgument.TruthValue evaluate(SearchArgument.TruthValue[] leaves);\n\t// Get the expression tree without the normalization to conjunctive normal form.\n\tExpressionTree getCompactExpression();\n\t// Get the expression tree normalized into conjunctive normal form.\n\tExpressionTree getExpression();\n\t// Get the leaf predicates that are required to evaluate the predicate.\n\tList<PredicateLeaf> getLeaves();\n}", "des": "Primary interface for SearchArgument, which are the subset of predicates that can be pushed down to the RecordReader. Each SearchArgument consists of a series of SearchClauses that must each be true for the row to be accepted by the filter. This requires that the filter be normalized into conjunctive normal form (CNF)."}
{"index": 2617, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class ValidCompactorWriteIdList {\n\t// Indicates whether a given write maps to aborted transaction.\n\tboolean isWriteIdAborted(long writeId);\n\t// Returns org.apache.hadoop.hive.common.ValidWriteIdList.RangeResponse.ALL if all write ids in the range are resolved and RangeResponse.NONE otherwise Streaming ingest may create something like delta_11_20.\n\tValidWriteIdList.RangeResponse isWriteIdRangeValid(long minWriteId, long maxWriteId);\n}", "des": "An implementation of ValidWriteIdList for use by the compactor. Compaction should only include txns up to smallest open txn (exclussive). There may be aborted write ids in the snapshot represented by this ValidCompactorWriteIdList. Thus isWriteIdRangeValid(long, long) returns NONE for any range that includes any unresolved write ids. Any write id above highWatermark is unresolved. These produce the logic we need to assure that the compactor only sees records less than the lowest open write ids when choosing which files to compact, but that it still ignores aborted records when compacting. See org.apache.hadoop.hive.metastore.txn.TxnUtils#createValidCompactTxnList() for proper way to construct this."}
{"index": 2618, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Enum ValidTxnList.RangeResponse {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ValidTxnList.RangeResponse valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ValidTxnList.RangeResponse[] values();\n}", "des": "The response to a range query. NONE means no values in this range match, SOME mean that some do, and ALL means that every value does."}
{"index": 2619, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Enum ValidWriteIdList.RangeResponse {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ValidWriteIdList.RangeResponse valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ValidWriteIdList.RangeResponse[] values();\n}", "des": "The response to a range query. NONE means no values in this range match, SOME mean that some do, and ALL means that every value does."}
{"index": 2620, "repo": "hive-storage-api-4.0.0-alpha-2", "code": "Class VoidColumnVector {\n\tvoid copySelected(boolean selectedInUse, int[] sel, int size, ColumnVector outputColVector);\n\tvoid flatten(boolean selectedInUse, int[] sel, int size);\n\t// Set the element in this column vector from the given input vector.\n\tvoid setElement(int outputElementNum, int inputElementNum, ColumnVector inputColVector);\n\t// Print the value for this column into the given string builder.\n\tvoid stringifyValue(StringBuilder buffer, int row);\n}", "des": "This class represents a void (or no) type column vector. No value vector(s) needed. Always a NULL."}
{"index": 2621, "repo": "iceberg-spark3-0.13.2", "code": "Interface MergeBuilder {\n\t// Creates a scan builder for a row-level operation.\n\torg.apache.spark.sql.connector.read.ScanBuilder asScanBuilder();\n\t// Creates a write builder for a row-level operation.\n\torg.apache.spark.sql.connector.write.WriteBuilder asWriteBuilder();\n}", "des": "An interface for building a scan and a write for a row-level operation."}
{"index": 2622, "repo": "iceberg-spark3-0.13.2", "code": "Enum NullOrdering {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NullOrdering valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NullOrdering[] values();\n}", "des": "A null order used in sorting expressions."}
{"index": 2623, "repo": "iceberg-spark3-0.13.2", "code": "Interface Procedure {\n\t// Executes this procedure.\n\torg.apache.spark.sql.catalyst.InternalRow[] call(org.apache.spark.sql.catalyst.InternalRow args);\n\t// Returns the description of this procedure.\n\tdefault java.lang.String description();\n\t// Returns the type of rows produced by this procedure.\n\torg.apache.spark.sql.types.StructType outputType();\n\t// Returns the input parameters of this procedure.\n\tProcedureParameter[] parameters();\n}", "des": "An interface representing a stored procedure available for execution."}
{"index": 2624, "repo": "iceberg-spark3-0.13.2", "code": "Enum SortDirection {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SortDirection valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SortDirection[] values();\n}", "des": "A sort direction used in sorting expressions."}
{"index": 2625, "repo": "iceberg-spark3-0.13.2", "code": "Interface SortOrder {\n\t// Returns the sort direction.\n\tSortDirection direction();\n\t// Returns the sort expression.\n\torg.apache.spark.sql.connector.expressions.Expression expression();\n\t// Returns the null ordering.\n\tNullOrdering nullOrdering();\n}", "des": "Represents a sort order in the public expression API."}
{"index": 2626, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ArrayBackedTag {\n\t// Returns the tag type\n\tbyte getType();\n\t// Returns The byte array backing this Tag.\n\tbyte[] getValueArray();\n\t// Returns The ByteBuffer containing the value bytes.\n\tByteBuffer getValueByteBuffer();\n\t// Returns Length of actual tag bytes within the backed buffer\n\tint getValueLength();\n\t// Returns Offset of actual tag bytes within the backed buffer\n\tint getValueOffset();\n\t// Return true if the tag is backed by a byte array\n\tboolean hasArray();\n}", "des": "This is a Tag implementation in which value is backed by an on heap byte array."}
{"index": 2627, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class AtomicUtils {\n\t// Updates a AtomicLong which is supposed to maintain the maximum values.\n\tstatic void updateMax(AtomicLong max, long value);\n\t// Updates a AtomicLong which is supposed to maintain the minimum values.\n\tstatic void updateMin(AtomicLong min, long value);\n}", "des": "Utilities related to atomic operations."}
{"index": 2628, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class AvlUtil.AvlTreeIterator<TNode extends AvlUtil.AvlNode> {\n\tboolean hasNext();\n\tTNode next();\n\tvoid remove();\n\t// Reset the iterator, and seeks to the first (min) node of the tree\n\tvoid seekFirst(TNode root);\n\t// Reset the iterator, and seeks to the specified key\n\tvoid seekTo(TNode root, Object key, AvlUtil.AvlKeyComparator<TNode> keyComparator);\n}", "des": "Iterator for the AvlTree"}
{"index": 2629, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class BaseDecoder {\n\t// Advance the scanner 1 cell.\n\tboolean advance();\n\t// Returns the current Cell which may be mutable\n\tCell current();\n\tprotected InputStream getInputStream();\n\t// Extract a Cell.\n\tprotected abstract Cell parseCell();\n}", "des": "TODO javadoc"}
{"index": 2630, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class BaseEncoder {\n\tprotected void checkFlushed();\n\t// Let the implementation decide what to do.\n\tvoid flush();\n\tprotected OutputStream getOuputStream();\n\t// Implementation must copy the entire state of the Cell.\n\tabstract void write(Cell cell);\n}", "des": "TODO javadoc"}
{"index": 2631, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class BoundedDelegatingInputStream {\n\tint available();\n\t// Call the delegate's read() method if the current position is less than the limit.\n\tint read();\n\t// Call the delegate's read(byte[], int, int) method if the current position is less than the limit.\n\tint read(byte[] b, int off, int len);\n\tvoid setDelegate(InputStream in, long limit);\n\t// Call the delegate's skip(long) method.\n\tlong skip(long len);\n}", "des": "This is a stream that will only supply bytes from its delegate up to a certain limit. When there is an attempt to set the position beyond that it will signal that the input is finished."}
{"index": 2632, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ByteBufferArray {\n\t// Creates a sub-array from a given array of ByteBuffers from the given offset to the length specified.\n\tByteBuffer[] asSubByteBuffers(long offset, int len);\n\t// Transfers bytes from this buffers array into the given destination ByteBuff\n\tint read(long offset, ByteBuff dst);\n\t// Transfers bytes from the given source ByteBuff into this buffer array\n\tint write(long offset, ByteBuff src);\n}", "des": "This class manages an array of ByteBuffers with a default size 4MB. These buffers are sequential and could be considered as a large buffer.It supports reading/writing data from this large buffer with a position and offset"}
{"index": 2633, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ByteBufferInputStream {\n\tint available();\n\t// Reads the next byte of data from this input stream.\n\tint read();\n\t// Reads up to next len bytes of data from buffer into passed array(starting from given offset).\n\tint read(byte[] b, int off, int len);\n\t// Skips n bytes of input from this input stream.\n\tlong skip(long n);\n}", "des": "Not thread safe!"}
{"index": 2634, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ByteBufferTag {\n\t// Returns the tag type\n\tbyte getType();\n\t// Return an array containing the value bytes if Tag.hasArray() returns true.\n\tbyte[] getValueArray();\n\t// Returns The ByteBuffer containing the value bytes.\n\tByteBuffer getValueByteBuffer();\n\t// Returns Length of tag value within the backed buffer\n\tint getValueLength();\n\t// Returns Offset of tag value within the backed buffer\n\tint getValueOffset();\n\t// Return true if the tag is backed by a byte array\n\tboolean hasArray();\n}", "des": "This is a Tag implementation in which value is backed by ByteBuffer"}
{"index": 2635, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface ByteBufferWriter {\n\t// Writes len bytes from the specified ByteBuffer starting at offset off\n\tvoid write(ByteBuffer b, int off, int len);\n\t// Writes an int to the underlying output stream as four bytes, high byte first.\n\tvoid writeInt(int i);\n}", "des": "This interface marks a class to support writing ByteBuffers into it."}
{"index": 2636, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ByteBufferWriterOutputStream {\n\tvoid close();\n\tvoid flush();\n\tvoid write(byte[] b, int off, int len);\n\t// Writes len bytes from the specified ByteBuffer starting at offset off to this OutputStream.\n\tvoid write(ByteBuffer b, int off, int len);\n\tvoid write(int b);\n\t// Writes an int to the underlying output stream as four bytes, high byte first.\n\tvoid writeInt(int i);\n}", "des": "When deal with OutputStream which is not ByteBufferWriter type, wrap it with this class. We will have to write offheap ByteBuffer (DBB) data into the OS. This class is having a temp byte array to which we can copy the DBB data for writing to the OS. This is used while writing Cell data to WAL. In case of AsyncWAL, the OS created there is ByteBufferWriter. But in case of FSHLog, the OS passed by DFS client, is not of type ByteBufferWriter. We will need this temp solution until DFS client supports writing ByteBuffer directly to the OS it creates. Note: This class is not thread safe."}
{"index": 2637, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ByteBuffInputStream {\n\tint available();\n\t// Reads the next byte of data from this input stream.\n\tint read();\n\t// Reads up to next len bytes of data from buffer into passed array(starting from given offset).\n\tint read(byte[] b, int off, int len);\n\t// Skips n bytes of input from this input stream.\n\tlong skip(long n);\n}", "des": "Not thread safe!"}
{"index": 2638, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum Cell.Type {\n\tbyte getCode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Cell.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Cell.Type[] values();\n}", "des": "The valid types for user to build the cell. Currently, This is subset of KeyValue.Type."}
{"index": 2639, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum CellBuilderType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CellBuilderType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CellBuilderType[] values();\n}", "des": "Used by CellBuilderFactory and ExtendedCellBuilderFactory. Indicates which memory copy is used in building cell."}
{"index": 2640, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface CellOutputStream {\n\t// Let the implementation decide what to do.\n\tvoid flush();\n\t// Implementation must copy the entire state of the Cell.\n\tvoid write(Cell cell);\n}", "des": "Accepts a stream of Cells. This can be used to build a block of cells during compactions and flushes, or to build a byte[] to send to the client. This could be backed by a List<KeyValue>, but more efficient implementations will append results to a byte[] to eliminate overhead, and possibly encode the cells further."}
{"index": 2641, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface CellScanner {\n\t// Advance the scanner 1 cell.\n\tboolean advance();\n\t// Returns the current Cell which may be mutable\n\tCell current();\n}", "des": "An interface for iterating through a sequence of cells. Similar to Java's Iterator, but without the hasNext() or remove() methods. The hasNext() method is problematic because it may require actually loading the next object, which in turn requires storing the previous object somewhere."}
{"index": 2642, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ChoreService {\n\t// Returns true when the chore is scheduled with the implementer of this interface\n\tboolean isChoreScheduled(ScheduledChore chore);\n\t// Returns true when the service is shutdown and thus cannot be used anymore\n\tboolean isShutdown();\n\t// Returns true when the service is shutdown and all threads have terminated\n\tboolean isTerminated();\n\t// Schedule a chore.\n\tboolean scheduleChore(ScheduledChore chore);\n\t// Shut down the service.\n\tvoid shutdown();\n}", "des": "ChoreService is a service that can be used to schedule instances of ScheduledChore to run periodically while sharing threads. The ChoreService is backed by a ScheduledThreadPoolExecutor whose core pool size changes dynamically depending on the number of ScheduledChore scheduled. All of the threads in the core thread pool of the underlying ScheduledThreadPoolExecutor are set to be daemon threads."}
{"index": 2643, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface CipherProvider {\n\t// Get an Cipher\n\tCipher getCipher(String name);\n\t// Return the provider's name\n\tString getName();\n\t// Return the set of Ciphers supported by this provider\n\tString[] getSupportedCiphers();\n}", "des": "An CipherProvider contributes support for various cryptographic Ciphers."}
{"index": 2644, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class CryptoAES {\n\t// Decrypts input data.\n\tbyte[] unwrap(byte[] data, int offset, int len);\n\t// Encrypts input data.\n\tbyte[] wrap(byte[] data, int offset, int len);\n}", "des": "AES encryption and decryption."}
{"index": 2645, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class CryptoCipherProvider {\n\t// Get an Cipher\n\tCipher getCipher(String name);\n\torg.apache.hadoop.conf.Configuration getConf();\n\tstatic CryptoCipherProvider getInstance();\n\t// Return the provider's name\n\tString getName();\n\t// Return the set of Ciphers supported by this provider\n\tString[] getSupportedCiphers();\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "The default cipher provider. Supports AES via the Commons Crypto."}
{"index": 2646, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface Decryptor {\n\t// Create a stream for decryption\n\tInputStream createDecryptionStream(InputStream in);\n\t// Get the cipher's internal block size\n\tint getBlockSize();\n\t// Get the expected length for the initialization vector\n\tint getIvLength();\n\t// Reset state, reinitialize with the key and iv\n\tvoid reset();\n\t// Set the initialization vector\n\tvoid setIv(byte[] iv);\n\t// Set the secret key\n\tvoid setKey(Key key);\n}", "des": "Decryptors apply a cipher to an InputStream to recover plaintext."}
{"index": 2647, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class DefaultCipherProvider {\n\t// Get an Cipher\n\tCipher getCipher(String name);\n\torg.apache.hadoop.conf.Configuration getConf();\n\tstatic DefaultCipherProvider getInstance();\n\t// Return the provider's name\n\tString getName();\n\t// Return the set of Ciphers supported by this provider\n\tString[] getSupportedCiphers();\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "The default cipher provider. Supports AES via the JCE."}
{"index": 2648, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class DNS {\n\t// Wrapper around DNS.getDefaultHost(String, String), calling DNS.getDefaultHost(String, String, boolean) when available.\n\tstatic String getDefaultHost(String strInterface, String nameserver);\n\t// Get the configured hostname for a given ServerType.\n\tstatic String getHostname(org.apache.hadoop.conf.Configuration conf, DNS.ServerType serverType);\n}", "des": "Wrapper around Hadoop's DNS class to hide reflection."}
{"index": 2649, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface Encryptor {\n\t// Create a stream for encryption\n\tOutputStream createEncryptionStream(OutputStream out);\n\t// Get the cipher's internal block size\n\tint getBlockSize();\n\t// Get the initialization vector\n\tbyte[] getIv();\n\t// Get the expected length for the initialization vector\n\tint getIvLength();\n\t// Reset state, reinitialize with the key and iv\n\tvoid reset();\n\t// Set the initialization vector\n\tvoid setIv(byte[] iv);\n\t// Set the secret key\n\tvoid setKey(Key key);\n}", "des": "Encryptors apply a cipher to an OutputStream to produce ciphertext."}
{"index": 2650, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class EnvironmentEdgeManager {\n\t// Defers to the delegate and calls the EnvironmentEdge.currentTime() method.\n\tstatic long currentTime();\n\t// Retrieves the singleton instance of the EnvironmentEdge that is being managed.\n\tstatic EnvironmentEdge getDelegate();\n\t// Injects the given edge such that it becomes the managed entity.\n\tstatic void injectEdge(EnvironmentEdge edge);\n\t// Resets the managed instance to the default instance: DefaultEnvironmentEdge.\n\tstatic void reset();\n}", "des": "Manages a singleton instance of the environment edge. This class shall implement static versions of the interface EnvironmentEdge, then defer to the delegate on invocation. Original Motivation: The main purpose of the Environment Edge Manager was to have better control over the tests so that they behave the same when run in any system. (Refer: HBASE-2578 - The issue which added the EnvironmentEdgeManager). The idea is to have a central place where time can be assigned in HBase. That makes it easier to inject different implementations of time. The default environment edge is the Java Current Time in millis. The environment edge manager class is designed to be able to plug in a new implementation of time by simply injecting an implementation of EnvironmentEdge interface to EnvironmentEdgeManager"}
{"index": 2651, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ExceptionUtil {\n\t// Returns an InterruptedIOException if t was an interruption, null otherwise\n\tstatic InterruptedIOException asInterrupt(Throwable t);\n\t// Returns true if the throwable comes an interruption, false otherwise.\n\tstatic boolean isInterrupt(Throwable t);\n\t// Throw InterruptedIOException if t was an interruption, nothing otherwise.\n\tstatic void rethrowIfInterrupt(Throwable t);\n}", "des": "This class handles the different interruption classes. It can be: - InterruptedException - InterruptedIOException (inherits IOException); used in IO - ClosedByInterruptException (inherits IOException) - SocketTimeoutException inherits InterruptedIOException but is not a real interruption, so we have to distinguish the case. This pattern is unfortunately common."}
{"index": 2652, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ExponentialMovingAverage<T> {\n\t// Get average execution time of the measured method.\n\tdouble getAverageTime();\n\t// Update the most recent data.\n\tvoid updateMostRecentTime(long elapsed);\n}", "des": "EMA is similar to WeightedMovingAverage in weighted, but the weighting factor decrease exponentially. It brings benefits that it is more sensitive, and can see the trends easily."}
{"index": 2653, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class FileChangeWatcher {\n\t// Returns the current FileChangeWatcher.State.\n\tFileChangeWatcher.State getState();\n\t// Tells the background thread to start.\n\tvoid start();\n\t// Tells the background thread to stop.\n\tvoid stop();\n}", "des": "Instances of this class can be used to watch a directory for file changes. When a file is added to, deleted from, or is modified in the given directory, the callback provided by the user will be called from a background thread. Some things to keep in mind: The callback should be thread-safe. Changes that happen around the time the thread is started may be missed. There is a delay between a file changing and the callback firing. The watch is not recursive - changes to subdirectories will not trigger a callback."}
{"index": 2654, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class HashKey<T> {\n\t// Return The byte at the given position in this HashKey\n\tabstract byte get(int pos);\n\t// Returns The number of bytes in this HashKey\n\tabstract int length();\n}", "des": "Used to calculate the hash Hash algorithms for Bloomfilters."}
{"index": 2655, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum HBaseSemanticAttributes.Operation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HBaseSemanticAttributes.Operation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HBaseSemanticAttributes.Operation[] values();\n}", "des": "These are values used with HBaseSemanticAttributes.DB_OPERATION. They correspond with the implementations of org.apache.hadoop.hbase.client.Operation, as well as org.apache.hadoop.hbase.client.CheckAndMutate, and \"MULTI\", meaning a batch of multiple operations."}
{"index": 2656, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum HBaseSemanticAttributes.ReadType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HBaseSemanticAttributes.ReadType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HBaseSemanticAttributes.ReadType[] values();\n}", "des": "These values represent the different IO read strategies HBase may employ for accessing filesystem data."}
{"index": 2657, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum HBaseSemanticAttributes.RpcSystem {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HBaseSemanticAttributes.RpcSystem valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HBaseSemanticAttributes.RpcSystem[] values();\n}", "des": "These are values used with HBaseSemanticAttributes.RPC_SYSTEM. Only a single value for now; more to come as we add tracing over our gateway components."}
{"index": 2658, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum HConstants.OperationStatusCode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HConstants.OperationStatusCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HConstants.OperationStatusCode[] values();\n}", "des": "Status codes used for return values of bulk operations."}
{"index": 2659, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class HDFSBlocksDistribution.HostAndWeight {\n\t// add weight\n\tvoid addWeight(long weight, long weightForSsd);\n\t// Returns the host name\n\tString getHost();\n\t// Returns the weight\n\tlong getWeight();\n\t// Returns the weight for ssd\n\tlong getWeightForSsd();\n}", "des": "Stores the hostname and weight for that hostname. This is used when determining the physical locations of the blocks making up a region. To make a prioritized list of the hosts holding the most data of a region, this class is used to count the total weight for each host. The weight is currently just the size of the file."}
{"index": 2660, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface HFileBlockDecodingContext {\n\t// Returns HFile meta information\n\tHFileContext getHFileContext();\n\t// Perform all actions that need to be done before the encoder's real decoding process.\n\tvoid prepareDecoding(int onDiskSizeWithoutHeader, int uncompressedSizeWithoutHeader, ByteBuff blockBufferWithoutHeader, ByteBuff onDiskBlock);\n}", "des": "A decoding context that is created by a reader's encoder, and is shared across all of the reader's read operations."}
{"index": 2661, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class HFileBlockDefaultDecodingContext {\n\t// Returns HFile meta information\n\tHFileContext getHFileContext();\n\tTagCompressionContext getTagCompressionContext();\n\t// Perform all actions that need to be done before the encoder's real decoding process.\n\tvoid prepareDecoding(int onDiskSizeWithoutHeader, int uncompressedSizeWithoutHeader, ByteBuff blockBufferWithoutHeader, ByteBuff onDiskBlock);\n\tvoid setTagCompressionContext(TagCompressionContext tagCompressionContext);\n}", "des": "A default implementation of HFileBlockDecodingContext. It assumes the block data section is compressed as a whole."}
{"index": 2662, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class HFileContextAttributesBuilderConsumer {\n\tvoid accept(io.opentelemetry.api.common.AttributesBuilder builder);\n\t// Specify the HBaseSemanticAttributes.ReadType involced in this IO operation.\n\tHFileContextAttributesBuilderConsumer setReadType(HBaseSemanticAttributes.ReadType readType);\n\t// Specify that the ChecksumType should not be included in the attributes.\n\tHFileContextAttributesBuilderConsumer setSkipChecksum(boolean skipChecksum);\n}", "des": ""}
{"index": 2663, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class IncrementingEnvironmentEdge {\n\t// Returns the currentTime.\n\tlong currentTime();\n\t// Increment the time by the given amount\n\tlong incrementTime(long amount);\n}", "des": "Uses an incrementing algorithm instead of the default."}
{"index": 2664, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class JenkinsHash {\n\tstatic Hash getInstance();\n\t// taken from hashlittle() -- hash a variable-length key into a 32-bit value\n\t<T> int hash(HashKey<T> hashKey, int initval);\n\t// Compute the hash of the specified file\n\tstatic void main(String[] args);\n}", "des": "Produces 32-bit hash for hash table lookup."}
{"index": 2665, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class KeyLocker<K> {\n\t// Return a lock for the given key.\n\tReentrantLock acquireLock(K key);\n\t// Acquire locks for a set of keys.\n\tMap<K,Lock> acquireLocks(Set<? extends K> keys);\n}", "des": "A utility class to manage a set of locks. Each lock is identified by a String which serves as a key. Typical usage is:"}
{"index": 2666, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface KeyProvider {\n\t// Retrieve the key for a given key aliase\n\tKey getKey(String alias);\n\t// Retrieve keys for a given set of key aliases\n\tKey[] getKeys(String[] aliases);\n\t// Initialize the key provider\n\tvoid init(String params);\n}", "des": "KeyProvider is a interface to abstract the different methods of retrieving key material from key storage such as Java key store."}
{"index": 2667, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class KeyStoreKeyProvider {\n\tprotected char[] getAliasPassword(String alias);\n\t// Retrieve the key for a given key aliase\n\tKey getKey(String alias);\n\t// Retrieve keys for a given set of key aliases\n\tKey[] getKeys(String[] aliases);\n\t// Initialize the key provider\n\tvoid init(String params);\n\tprotected void load(URI uri);\n\tprotected void processParameter(String name, String value);\n\tprotected void processParameters(URI uri);\n}", "des": "A basic KeyProvider that can resolve keys from a protected KeyStore file on the local filesystem. It is configured with a URI passed in as a String to init(). The URI should have the form:"}
{"index": 2668, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum KeyValue.Type {\n\t// Cannot rely on enum ordinals .\n\tstatic KeyValue.Type codeToType(byte b);\n\tbyte getCode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic KeyValue.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic KeyValue.Type[] values();\n}", "des": "Key type. Has space for other key types to be added later. Cannot rely on enum ordinals . They change if item is removed or moved. Do our own codes."}
{"index": 2669, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class LRUDictionary {\n\t// Adds an entry to the dictionary.\n\tshort addEntry(byte[] data, int offset, int length);\n\t// Flushes the dictionary, empties all values.\n\tvoid clear();\n\t// Finds the index of an entry.\n\tshort findEntry(byte[] data, int offset, int length);\n\t// Finds the index of an entry.\n\tshort findEntry(ByteBuffer data, int offset, int length);\n\t// Gets an entry from the dictionary.\n\tbyte[] getEntry(short idx);\n\tvoid init(int initialSize);\n}", "des": "WALDictionary using an LRU eviction algorithm. Uses a linked list running through a hashtable. Currently has max of 2^15 entries. Will start evicting if exceeds this number The maximum memory we expect this dictionary to take in the worst case is about: (2 ^ 15) * 5 (Regionname, Row key, CF, Column qual, table) * 100 bytes (these are some big names) = ~16MB. If you want to get silly, even at 1kb entries, it maxes out at 160 megabytes."}
{"index": 2670, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class MD5Hash {\n\t// Given a byte array, returns in MD5 hash as a hex string.\n\tstatic String getMD5AsHex(byte[] key);\n\t// Given a byte array, returns its MD5 hash as a hex string.\n\tstatic String getMD5AsHex(byte[] key, int offset, int length);\n}", "des": "Utility class for MD5 MD5 hash produces a 128-bit digest."}
{"index": 2671, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class MovingAverage<T> {\n\t// Get average execution time of the measured method.\n\tabstract double getAverageTime();\n\t// Measure elapsed time of a measurable method.\n\tT measure(TimeMeasurable<T> measurable);\n\t// Mark start time of an execution.\n\tprotected long start();\n\t// Mark end time of an execution, and return its interval.\n\tprotected long stop(long startTime);\n\t// Update the most recent data.\n\tprotected abstract void updateMostRecentTime(long elapsed);\n}", "des": "The purpose of introduction of MovingAverage mainly is to measure execution time of a specific method, which can help us to know its performance fluctuation in response to different machine states or situations, better case, then to act accordingly. In different situation, different MovingAverage algorithm can be used based on needs."}
{"index": 2672, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ObjectPool<K,V> {\n\t// Create a reference associated with the given object\n\tabstract Reference<V> createReference(K key, V obj);\n\t// Returns a shared object associated with the given key, which is identified by the equals method.\n\tV get(K key);\n\t// Get key of the given reference\n\tabstract K getReferenceKey(Reference<V> ref);\n\t// Removes stale references of shared objects from the pool.\n\tvoid purge();\n\t// Returns an estimated count of objects kept in the pool.\n\tint size();\n}", "des": "A thread-safe shared object pool in which object creation is expected to be lightweight, and the objects may be excessively created and discarded."}
{"index": 2673, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class OrderedBlobVar {\n\t// Read an instance of T from the buffer src.\n\tbyte[] decode(PositionedByteRange src);\n\t// Write instance val into buffer dst.\n\tint encode(PositionedByteRange dst, byte[] val);\n\t// Write a subset of val to dst.\n\tint encode(PositionedByteRange dst, byte[] val, int voff, int vlen);\n\t// Inform consumers over what type this DataType operates.\n\tClass<byte[]> encodedClass();\n\t// Inform consumers how long the encoded byte[] will be.\n\tint encodedLength(byte[] val);\n}", "des": "An alternative to OrderedBlob for use by Struct fields that do not terminate the fields list. Built on OrderedBytes.encodeBlobVar(PositionedByteRange, byte[], int, int, Order)."}
{"index": 2674, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class OrderedString {\n\t// Read an instance of T from the buffer src.\n\tString decode(PositionedByteRange src);\n\t// Write instance val into buffer dst.\n\tint encode(PositionedByteRange dst, String val);\n\t// Inform consumers over what type this DataType operates.\n\tClass<String> encodedClass();\n\t// Inform consumers how long the encoded byte[] will be.\n\tint encodedLength(String val);\n}", "des": "A String of variable-length. Built on OrderedBytes.encodeString(PositionedByteRange, String, Order)."}
{"index": 2675, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class Pair<T1,T2> {\n\tboolean equals(Object other);\n\t// Return the first element stored in the pair.\n\tT1 getFirst();\n\t// Return the second element stored in the pair.\n\tT2 getSecond();\n\t// Constructs a new pair, inferring the type via the passed arguments\n\tstatic <T1,T2> Pair<T1,T2> newPair(T1 a, T2 b);\n\t// Replace the first element of the pair.\n\tvoid setFirst(T1 a);\n\t// Replace the second element of the pair.\n\tvoid setSecond(T2 b);\n}", "des": "A generic class for pairs."}
{"index": 2676, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class PairOfSameType<T> {\n\tboolean equals(Object other);\n\t// Return the first element stored in the pair.\n\tT getFirst();\n\t// Return the second element stored in the pair.\n\tT getSecond();\n\tIterator<T> iterator();\n}", "des": "A generic, immutable class for pairs of objects both of type T."}
{"index": 2677, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface PropagatingConfigurationObserver {\n\t// Needs to be called to deregister the children from the manager.\n\tvoid deregisterChildren(ConfigurationManager manager);\n\t// Needs to be called to register the children to the manager.\n\tvoid registerChildren(ConfigurationManager manager);\n}", "des": "This extension to ConfigurationObserver allows the configuration to propagate to the children of the current ConfigurationObserver. This is the preferred way to make a class online configurable because it allows the user to configure the children in a recursive manner automatically."}
{"index": 2678, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class RawBytesFixedLength {\n\t// Read a byte[] from the buffer src.\n\tbyte[] decode(PositionedByteRange src, int length);\n\t// Write val into buff, respecting offset and length.\n\tint encode(PositionedByteRange dst, byte[] val, int voff, int vlen);\n}", "des": "An DataType that encodes fixed-length values encoded using Bytes.putBytes( byte[], int, byte[], int, int). Intended to make it easier to transition away from direct use of Bytes."}
{"index": 2679, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class RawBytesTerminated {\n\t// Read a byte[] from the buffer src.\n\tbyte[] decode(PositionedByteRange src, int length);\n\t// Write val into dst, respecting offset and length.\n\tint encode(PositionedByteRange dst, byte[] val, int voff, int vlen);\n}", "des": "An DataType that encodes variable-length values encoded using Bytes.putBytes(byte[], int, byte[], int, int). Includes a termination marker following the raw byte[] value. Intended to make it easier to transition away from direct use of Bytes."}
{"index": 2680, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface RawCell {\n\t// Check the length of tags.\n\tstatic void checkForTagsLength(int tagsLength);\n\t// Allows cloning the tags in the cell to a new byte[]\n\tdefault byte[] cloneTags();\n\t// Returns A new cell which is having the extra tags also added to it.\n\tstatic Cell createCell(Cell cell, List<Tag> tags);\n\t// Returns the specific tag of the given type\n\tdefault Optional<Tag> getTag(byte type);\n\t// Creates a list of tags in the current cell\n\tdefault Iterator<Tag> getTags();\n}", "des": "An extended version of Cell that allows CPs manipulate Tags."}
{"index": 2681, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class RowColBloomHashKey {\n\t// Return The byte at the given position in this HashKey\n\tbyte get(int offset);\n\t// Returns The number of bytes in this HashKey\n\tint length();\n}", "des": "An hash key for ROWCOL bloom. This assumes the cells to be serialized in the Keyvalue serialization format with Empty column family. Note that the byte representing the family length is considered to be 0"}
{"index": 2682, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class SimpleMovingAverage<T> {\n\t// Get average execution time of the measured method.\n\tdouble getAverageTime();\n\t// Update the most recent data.\n\tvoid updateMostRecentTime(long elapsed);\n}", "des": "SMA measure the overall average execution time of a specific method."}
{"index": 2683, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class SizeCachedByteBufferKeyValue {\n\t// Needed doing 'contains' on List.\n\tboolean equals(Object other);\n\tint getKeyLength();\n\t// Returns Number of row bytes.\n\tshort getRowLength();\n\t// Override by just returning the length for saving cost of method dispatching.\n\tint getSerializedSize();\n\t// Return the approximate 'exclusive deep size' of implementing object.\n\tlong heapSize();\n}", "des": "This Cell is an implementation of ByteBufferExtendedCell where the data resides in off heap/ on heap ByteBuffer"}
{"index": 2684, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class SizeCachedKeyValue {\n\t// Returns Length of key portion.\n\tint getKeyLength();\n\t// Returns Row length\n\tshort getRowLength();\n\t// Override by just returning the length for saving cost of method dispatching.\n\tint getSerializedSize();\n\t// HeapSize implementation We do not count the bytes in the rowCache because it should be empty for a KeyValue in the MemStore.\n\tlong heapSize();\n}", "des": "This class is an extension to KeyValue where rowLen and keyLen are cached. Parsing the backing byte[] every time to get these values will affect the performance. In read path, we tend to read these values many times in Comparator, SQM etc. Note: Please do not use these objects in write path as it will increase the heap space usage. See https://issues.apache.org/jira/browse/HBASE-13448"}
{"index": 2685, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class SizeCachedNoTagsByteBufferKeyValue {\n\t// Needed doing 'contains' on List.\n\tboolean equals(Object other);\n\tint getKeyLength();\n\t// Returns Number of row bytes.\n\tshort getRowLength();\n\t// Return the approximate 'exclusive deep size' of implementing object.\n\tlong heapSize();\n}", "des": "This Cell is an implementation of ByteBufferExtendedCell where the data resides in off heap/ on heap ByteBuffer"}
{"index": 2686, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class SizeCachedNoTagsKeyValue {\n\t// KeyValue format <4 bytes keylength> <4 bytes valuelength> <2 bytes rowlength> <row> <1 byte columnfamilylength> <columnfamily> <columnqualifier> <8 bytes timestamp> <1 byte keytype> <value> <2 bytes tagslength> <tags>\n\tint getSerializedSize(boolean withTags);\n\t// Return the total length of the tag bytes\n\tint getTagsLength();\n\t// Write this cell to an OutputStream in a KeyValue format.\n\tint write(OutputStream out, boolean withTags);\n}", "des": "This class is an extension to ContentSizeCachedKeyValue where there are no tags in Cell. Note: Please do not use these objects in write path as it will increase the heap space usage. See https://issues.apache.org/jira/browse/HBASE-13448"}
{"index": 2687, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class Sleeper {\n\t// Returns the sleep period in milliseconds\n\tint getPeriod();\n\t// If currently asleep, stops sleeping; if not asleep, will skip the next sleep cycle.\n\tvoid skipSleepCycle();\n\t// Sleep for period.\n\tvoid sleep();\n\tvoid sleep(long sleepTime);\n}", "des": "Sleeper for current thread. Sleeps for passed period. Also checks passed boolean and if interrupted, will return if the flag is set (rather than go back to sleep until its sleep time is up)."}
{"index": 2688, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class SoftObjectPool<K,V> {\n\t// Create a reference associated with the given object\n\tReference<V> createReference(K key, V obj);\n\t// Get key of the given reference\n\tK getReferenceKey(Reference<V> ref);\n}", "des": "A SoftReference based shared object pool. The objects are kept in soft references and associated with keys which are identified by the equals method. The objects are created by ObjectFactory on demand. The object creation is expected to be lightweight, and the objects may be excessively created and discarded. Thread safe."}
{"index": 2689, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface Stoppable {\n\t// Returns True if stop(String) has been closed.\n\tboolean isStopped();\n\t// Stop this service.\n\tvoid stop(String why);\n}", "des": "Implementers are Stoppable."}
{"index": 2690, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class StructBuilder {\n\t// Append field to the sequence of accumulated fields.\n\tStructBuilder add(DataType<?> field);\n\t// Reset the sequence of accumulated fields.\n\tStructBuilder reset();\n\t// Retrieve the Struct represented by this.\n\tStruct toStruct();\n}", "des": "A helper for building Struct instances."}
{"index": 2691, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class Superusers {\n\tstatic Collection<String> getSuperGroups();\n\tstatic Collection<String> getSuperUsers();\n\tstatic User getSystemUser();\n\t// Should be called only once to pre-load list of super users and super groups from Configuration.\n\tstatic void initialize(org.apache.hadoop.conf.Configuration conf);\n\t// Check if the current user is a super user\n\tstatic boolean isSuperUser(String user);\n\t// Check if the current user is a super user\n\tstatic boolean isSuperUser(User user);\n}", "des": "Keeps lists of superusers and super groups loaded from HBase configuration, checks if certain user is regarded as superuser."}
{"index": 2692, "repo": "hbase-common-3.0.0-alpha-4", "code": "Interface TagBuilder {\n\t// Build the tag.\n\tTag build();\n\t// Set type of the tag.\n\tTagBuilder setTagType(byte tagType);\n\t// Set the value of the tag.\n\tTagBuilder setTagValue(byte[] tagBytes);\n}", "des": "Builder implementation to create Tag Call setTagValue(byte[]) method to create ArrayBackedTag"}
{"index": 2693, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class ThrottledInputStream {\n\tvoid close();\n\t// Getter for the read-rate from this stream, since creation.\n\tlong getBytesPerSec();\n\t// Getter for the number of bytes read from this stream, since creation.\n\tlong getTotalBytesRead();\n\t// Getter the total time spent in sleep.\n\tlong getTotalSleepTime();\n\tint read();\n\tint read(byte[] b);\n\tint read(byte[] b, int off, int len);\n\t// Read bytes starting from the specified position.\n\tint read(long position, byte[] buffer, int offset, int length);\n}", "des": "The ThrottleInputStream provides bandwidth throttling on a specified InputStream. It is implemented as a wrapper on top of another InputStream instance. The throttling works by examining the number of bytes read from the underlying InputStream from the beginning, and sleep()ing for a time interval if the byte-transfer is found exceed the specified tolerable maximum. (Thus, while the read-rate might exceed the maximum for a given short interval, the average tends towards the specified maximum, overall.)"}
{"index": 2694, "repo": "hbase-common-3.0.0-alpha-4", "code": "Class WeakObjectPool<K,V> {\n\t// Create a reference associated with the given object\n\tReference<V> createReference(K key, V obj);\n\t// Get key of the given reference\n\tK getReferenceKey(Reference<V> ref);\n}", "des": "A WeakReference based shared object pool. The objects are kept in weak references and associated with keys which are identified by the equals method. The objects are created by ObjectPool.ObjectFactory on demand. The object creation is expected to be lightweight, and the objects may be excessively created and discarded. Thread safe."}
{"index": 2695, "repo": "hbase-common-3.0.0-alpha-4", "code": "Enum X509Util.ClientAuth {\n\t// Converts a property value to a ClientAuth enum.\n\tstatic X509Util.ClientAuth fromPropertyValue(String prop);\n\torg.apache.hbase.thirdparty.io.netty.handler.ssl.ClientAuth toNettyClientAuth();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic X509Util.ClientAuth valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic X509Util.ClientAuth[] values();\n}", "des": "Enum specifying the client auth requirement of server-side TLS sockets created by this X509Util. NONE - do not request a client certificate. WANT - request a client certificate, but allow anonymous clients to connect. NEED - require a client certificate, disconnect anonymous clients. If the config property is not set, the default value is NEED."}
{"index": 2696, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class AbstractOAuth2ServiceProvider<S> {\n\t// Returns an API interface allowing the client application to access protected resources on behalf of a user.\n\tabstract S getApi(java.lang.String accessToken);\n\t// Get the service interface for carrying out the \"OAuth dance\" with this provider.\n\tOAuth2Operations getOAuthOperations();\n}", "des": "Base class for ServiceProviders that use the OAuth2 protocol. OAuth2-based ServiceProvider implementations should extend and implement getApi(String)."}
{"index": 2697, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class AccessGrant {\n\t// The access token value.\n\tjava.lang.String getAccessToken();\n\t// The time (in milliseconds since Jan 1, 1970 UTC) when this access grant will expire.\n\tjava.lang.Long getExpireTime();\n\t// The refresh token that can be used to renew the access token.\n\tjava.lang.String getRefreshToken();\n\t// The scope of the access grant.\n\tjava.lang.String getScope();\n}", "des": "OAuth2 access token."}
{"index": 2698, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class AuthorizedRequestToken {\n\t// The request token secret.\n\tjava.lang.String getSecret();\n\t// The request token value.\n\tjava.lang.String getValue();\n\t// The verifier string generated by the provider.\n\tjava.lang.String getVerifier();\n}", "des": "A OAuth 1.0 request token that has been authorized by the user. Constructed after the user grants the consumer application access to their data hosted at the service provider. This is typically achieved by the user clicking \"Allow\" over at the provider's site. The service provider returns a Verifier string in the authorization callback that must also be submitted in the access token request."}
{"index": 2699, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class ConnectionFactory<A> {\n\tabstract Connection<A> createConnection(ConnectionData data);\n\t// Exposes the ApiAdapter to subclasses.\n\tprotected ApiAdapter<A> getApiAdapter();\n\t// The unique id of the provider this factory creates connections to.\n\tjava.lang.String getProviderId();\n\t// Exposes the ServiceProvider instance to subclasses.\n\tprotected ServiceProvider<A> getServiceProvider();\n}", "des": "Base abstraction for factories that construct service provider Connection instances. Encapsulates the differences and knowledge of specific connection implementations, for example, the difference between OAuth1 and OAuth2 based connections."}
{"index": 2700, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class ConnectionKey {\n\tboolean equals(java.lang.Object o);\n\t// The id of the provider as it is registered in the system.\n\tjava.lang.String getProviderId();\n\t// The id of the external provider user representing the remote end of the connection.\n\tjava.lang.String getProviderUserId();\n}", "des": "The unique business key for a Connection instance. A composite key that consists of the providerId (e.g. \"facebook\") plus providerUserId (e.g. \"125660\"). Provides the basis for connection equals() and hashCode()."}
{"index": 2701, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Interface ConnectionValues {\n\t// Sets value mapped to Connection.getDisplayName().\n\tvoid setDisplayName(java.lang.String displayName);\n\t// Sets value mapped to Connection.getImageUrl()\n\tvoid setImageUrl(java.lang.String imageUrl);\n\t// Sets value mapped to Connection.getProfileUrl()\n\tvoid setProfileUrl(java.lang.String profileUrl);\n\t// Sets value mapped to ConnectionKey.getProviderUserId().\n\tvoid setProviderUserId(java.lang.String providerUserId);\n}", "des": "A configuration interface used to set values on a Connection from a specific service provider API instance. setProviderUserId(String) maps to ConnectionKey.getProviderUserId() setDisplayName(String) maps to Connection.getDisplayName() setProfileUrl(String) maps to Connection.getProfileUrl() setImageUrl(String) maps to Connection.getImageUrl()"}
{"index": 2702, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Enum GrantType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GrantType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GrantType[] values();\n}", "des": "OAuth2 supports two types of authorization flow, typically referred to as \"Client-side\" and \"Server-side\". Use of implicit grant is discouraged unless there is no other option available."}
{"index": 2703, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class OAuth1Connection<A> {\n\t// Creates a data transfer object that can be used to persist the state of this connection.\n\tConnectionData createData();\n\tboolean equals(java.lang.Object obj);\n\t// A Java binding to the service provider's native API.\n\tA getApi();\n}", "des": "An OAuth1-based Connection implementation. In general, this implementation is expected to be suitable for all OAuth1-based providers and should not require subclassing. Subclasses of OAuth1ConnectionFactory should be favored to encapsulate details specific to an OAuth1-based provider."}
{"index": 2704, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class OAuth1Parameters {\n\t// The authorization callback url.\n\tjava.lang.String getCallbackUrl();\n\t// Sets the authorization callback url.\n\tvoid setCallbackUrl(java.lang.String callbackUrl);\n}", "des": "Parameters for building an OAuth1 authorize URL."}
{"index": 2705, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Interface OAuth1ServiceProvider<A> {\n\t// Returns an API interface allowing the client application to access protected resources on behalf of a user.\n\tA getApi(java.lang.String accessToken, java.lang.String secret);\n\t// Get the service interface for carrying out the \"OAuth dance\" with this provider.\n\tOAuth1Operations getOAuthOperations();\n}", "des": "A ServiceProvider that uses the OAuth 1.0 protocol."}
{"index": 2706, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Enum OAuth1Version {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OAuth1Version valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OAuth1Version[] values();\n}", "des": "Various versions ofthe OAuth1 Core specification. Used by OAuth1Template to vary behavior its by the configured version."}
{"index": 2707, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class OAuth2Connection<A> {\n\t// Creates a data transfer object that can be used to persist the state of this connection.\n\tConnectionData createData();\n\tboolean equals(java.lang.Object obj);\n\t// A Java binding to the service provider's native API.\n\tA getApi();\n\t// Returns true if this connection has expired.\n\tboolean hasExpired();\n\t// Refresh this connection.\n\tvoid refresh();\n}", "des": "An OAuth2-based Connection implementation. In general, this implementation is expected to be suitable for all OAuth2-based providers and should not require subclassing. Subclasses of OAuth2ConnectionFactory should be favored to encapsulate details specific to an OAuth2-based provider."}
{"index": 2708, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Interface OAuth2ServiceProvider<A> {\n\t// Returns an API interface allowing the client application to access protected resources on behalf of a user.\n\tA getApi(java.lang.String accessToken);\n\t// Get the service interface for carrying out the \"OAuth dance\" with this provider.\n\tOAuth2Operations getOAuthOperations();\n}", "des": "A ServiceProvider that uses the OAuth 2.0 protocol."}
{"index": 2709, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Enum OAuth2Version {\n\tabstract java.lang.String getAuthorizationHeaderValue(java.lang.String accessToken);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OAuth2Version valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OAuth2Version[] values();\n}", "des": "Enum encapsulating the differences between the various versions of the OAuth2 specification."}
{"index": 2710, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class OAuthToken {\n\t// The token secret.\n\tjava.lang.String getSecret();\n\t// The token value.\n\tjava.lang.String getValue();\n}", "des": "Holds an OAuth token and secret. Used for both the request token and access token."}
{"index": 2711, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Enum TokenStrategy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TokenStrategy valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TokenStrategy[] values();\n}", "des": "Strategy enumeration where each value carries an interceptor defining how an access token is carried on API requests."}
{"index": 2712, "repo": "spring-social-core-1.1.6.RELEASE", "code": "Class UserProfile {\n\t// The user's registered email address.\n\tjava.lang.String getEmail();\n\t// The user's registered first name e.g.\n\tjava.lang.String getFirstName();\n\t// The user's id in the provider May be null if not exposed/supported by the provider.\n\tjava.lang.String getId();\n\t// The user's registered last name e.g.\n\tjava.lang.String getLastName();\n\t// The user's registered full name e.g.\n\tjava.lang.String getName();\n\t// The user's registered username e.g.\n\tjava.lang.String getUsername();\n}", "des": "A normalized model representing a service provider user profile. The structure of a \"UserProfile\" varies across providers (see the difference between Facebook and Twitter, for example). That said, there are generally a common set of profile fields that apply across providers. This model provides access to those common fields in an uniform way. This is particularly useful for pre-populating a local application registration form with provider profile data during a provider sign-in attempt."}
{"index": 2713, "repo": "hadoop-azure-3.3.6", "code": "Class AbfsClientThrottlingIntercept {\n\t// Called before the request is sent.\n\tvoid sendingRequest(AbfsRestOperationType operationType, AbfsCounters abfsCounters);\n\t// Updates the metrics for successful and failed read and write operations.\n\tvoid updateMetrics(AbfsRestOperationType operationType, AbfsHttpOperation abfsHttpOperation);\n}", "des": "Throttles Azure Blob File System read and write operations to achieve maximum throughput by minimizing errors. The errors occur when the account ingress or egress limits are exceeded and the server-side throttles requests. Server-side throttling causes the retry policy to be used, but the retry policy sleeps for long periods of time causing the total ingress or egress throughput to be as much as 35% lower than optimal. The retry policy is also after the fact, in that it applies after a request fails. On the other hand, the client-side throttling implemented here happens before requests are made and sleeps just enough to minimize errors, allowing optimal ingress and/or egress throughput."}
{"index": 2714, "repo": "hadoop-azure-3.3.6", "code": "Class AbfsDtFetcher {\n\t// Returns Token object via FileSystem, null if bad argument.\n\torg.apache.hadoop.security.token.Token<?> addDelegationTokens(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.security.Credentials creds, String renewer, String url);\n\t// Get the scheme for this specific fetcher.\n\tprotected String getScheme();\n\t// Returns the service name for the scheme..\n\torg.apache.hadoop.io.Text getServiceName();\n\tboolean isTokenRequired();\n}", "des": "A DT fetcher for Abfs. This is a copy-and-paste of org.apache.hadoop.hdfs.HdfsDtFetcher. It is needed for the `hadoop dtutil` command."}
{"index": 2715, "repo": "hadoop-azure-3.3.6", "code": "Class AbfsPermission {\n\tboolean equals(Object obj);\n\t// Check whether abfs symbolic permission string is a extended Acl\n\tstatic boolean isExtendedAcl(String abfsSymbolicPermission);\n\t// Create a AbfsPermission from a abfs symbolic permission string\n\tstatic AbfsPermission valueOf(String abfsSymbolicPermission);\n}", "des": "The AbfsPermission for AbfsClient."}
{"index": 2716, "repo": "hadoop-azure-3.3.6", "code": "Class AbfsRestOperation {\n\t// Execute a AbfsRestOperation.\n\tvoid execute(TracingContext tracingContext);\n\tList<AbfsHttpHeader> getRequestHeaders();\n\tAbfsHttpOperation getResult();\n\tURL getUrl();\n\tvoid hardSetResult(int httpStatus);\n\t// Checks if there is non-null HTTP response.\n\tboolean hasResult();\n\tboolean isARetriedRequest();\n\t// Sign an operation.\n\tvoid signRequest(AbfsHttpOperation httpOperation, int bytesToSign);\n}", "des": "The AbfsRestOperation for Rest AbfsClient."}
{"index": 2717, "repo": "hadoop-azure-3.3.6", "code": "Enum AbfsRestOperationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AbfsRestOperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AbfsRestOperationType[] values();\n}", "des": "The REST operation type (Read, Append, Other )."}
{"index": 2718, "repo": "hadoop-azure-3.3.6", "code": "Interface AbfsThrottlingIntercept {\n\t// Called before the request is sent.\n\tvoid sendingRequest(AbfsRestOperationType operationType, AbfsCounters abfsCounters);\n\t// Updates the metrics for successful and failed read and write operations.\n\tvoid updateMetrics(AbfsRestOperationType operationType, AbfsHttpOperation abfsHttpOperation);\n}", "des": "An interface for Abfs Throttling Interface."}
{"index": 2719, "repo": "hadoop-azure-3.3.6", "code": "Class AccessTokenProvider {\n\t// returns the AzureADToken cached (or retrieved) by this instance.\n\tAzureADToken getToken();\n\t// Checks if the token is about to expire in the next 5 minutes.\n\tprotected boolean isTokenAboutToExpire();\n\t// the method to fetch the access token.\n\tprotected abstract AzureADToken refreshToken();\n}", "des": "Returns an Azure Active Directory token when requested. The provider can cache the token if it has already retrieved one. If it does, then the provider is responsible for checking expiry and refreshing as needed. In other words, this is is a token cache that fetches tokens when requested, if the cached token has expired."}
{"index": 2720, "repo": "hadoop-azure-3.3.6", "code": "Enum AuthType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AuthType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AuthType[] values();\n}", "des": "Auth Type Enum."}
{"index": 2721, "repo": "hadoop-azure-3.3.6", "code": "Class AzureADAuthenticator.HttpException {\n\tString getBody();\n\tString getContentType();\n\t// Gets Http error status code.\n\tint getHttpErrorCode();\n\tString getMessage();\n\t// Gets http request id .\n\tString getRequestId();\n\tString getUrl();\n}", "des": "This exception class contains the http error code, requestId and error message, it is thrown when AzureADAuthenticator failed to get the Azure Active Directory token."}
{"index": 2722, "repo": "hadoop-azure-3.3.6", "code": "Class CachedSASToken {\n\t// Gets the token if still valid.\n\tString get();\n\t// Updates the cached SAS token and expiry.\n\tvoid update(String token);\n}", "des": "CachedSASToken provides simple utility for managing renewal of SAS tokens used by Input/OutputStream. This enables SAS re-use and reduces calls to the SASTokenProvider."}
{"index": 2723, "repo": "hadoop-azure-3.3.6", "code": "Interface CustomTokenProviderAdaptee {\n\t// Obtain the access token that should be added to https connection's header.\n\tString getAccessToken();\n\t// Obtain expiry time of the token.\n\tDate getExpiryTime();\n\t// Initialize with supported configuration.\n\tvoid initialize(org.apache.hadoop.conf.Configuration configuration, String accountName);\n}", "des": "This interface provides an extensibility model for customizing the acquisition of Azure Active Directory Access Tokens. When \"fs.azure.account.auth.type\" is set to \"Custom\", implementors may use the \"fs.azure.account.oauth.provider.type.{accountName}\" configuration property to specify a class with a custom implementation of CustomTokenProviderAdaptee. This class will be dynamically loaded, initialized, and invoked to provide AAD Access Tokens and their Expiry."}
{"index": 2724, "repo": "hadoop-azure-3.3.6", "code": "Class ExponentialRetryPolicy {\n\t// Returns backoff interval between 80% and 120% of the desired backoff, multiply by 2^n-1 for exponential.\n\tlong getRetryInterval(int retryCount);\n\t// Returns if a request should be retried based on the retry count, current response, and the current strategy.\n\tboolean shouldRetry(int retryCount, int statusCode);\n}", "des": "Retry policy used by AbfsClient."}
{"index": 2725, "repo": "hadoop-azure-3.3.6", "code": "Interface IdentityHandler {\n\t// Perform lookup from Security Group's Object ID to Security Group name.\n\tString lookupForLocalGroupIdentity(String originalIdentity);\n\t// Perform lookup from Service Principal's Object ID to Username.\n\tString lookupForLocalUserIdentity(String originalIdentity);\n}", "des": "IdentityHandler defines the set of methods to support various identity lookup services."}
{"index": 2726, "repo": "hadoop-azure-3.3.6", "code": "Class ListResultSchema {\n\t// * Get the paths value.\n\tList<ListResultEntrySchema> paths();\n\t// Set the paths value.\n\tListResultSchema withPaths(List<ListResultEntrySchema> paths);\n}", "des": "The ListResultSchema model."}
{"index": 2727, "repo": "hadoop-azure-3.3.6", "code": "Class LocalSASKeyGeneratorImpl {\n\t// Implementation to generate SAS Key for a container\n\tURI getContainerSASUri(String accountName, String container);\n\t// Implementation for generation of Relative Path Blob SAS Uri.\n\tURI getRelativeBlobSASUri(String accountName, String container, String relativePath);\n}", "des": "Local SAS Key Generation implementation. This class resides in the same address space as the WASB driver. This class gets typically used for testing purposes."}
{"index": 2728, "repo": "hadoop-azure-3.3.6", "code": "Class MsiTokenProvider {\n\t// Checks if the token is about to expire as per base expiry logic.\n\tprotected boolean isTokenAboutToExpire();\n\t// the method to fetch the access token.\n\tprotected AzureADToken refreshToken();\n}", "des": "Provides tokens based on Azure VM's Managed Service Identity."}
{"index": 2729, "repo": "hadoop-azure-3.3.6", "code": "Enum ReadBufferStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReadBufferStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReadBufferStatus[] values();\n}", "des": "The ReadBufferStatus for Rest AbfsClient"}
{"index": 2730, "repo": "hadoop-azure-3.3.6", "code": "Class RemoteSASKeyGeneratorImpl {\n\t// Interface method to retrieve SAS Key for a container within the storage account.\n\tURI getContainerSASUri(String storageAccount, String container);\n\t// Interface method to retrieve SAS Key for a blob within the container of the storage account.\n\tURI getRelativeBlobSASUri(String storageAccount, String container, String relativePath);\n\tvoid initialize(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Class implementing a RemoteSASKeyGenerator. This class uses the url passed in via the Configuration to make a rest call to generate the required SAS Key."}
{"index": 2731, "repo": "hadoop-azure-3.3.6", "code": "Class RemoteWasbAuthorizerImpl {\n\t// Authorizer API to authorize access in WASB.\n\tboolean authorize(String wasbAbsolutePath, String accessType, String resourceOwner);\n\t// Initializer method\n\tvoid init(org.apache.hadoop.conf.Configuration conf);\n\tvoid updateWasbRemoteCallHelper(WasbRemoteCallHelper helper);\n}", "des": "Class implementing WasbAuthorizerInterface using a remote service that implements the authorization operation. This class expects the url of the remote service to be passed via config."}
{"index": 2732, "repo": "hadoop-azure-3.3.6", "code": "Class RemoteWasbDelegationTokenManager {\n\t// Cancel the delegation token\n\tvoid cancelDelegationToken(org.apache.hadoop.security.token.Token<?> token);\n\t// Get Delegation token\n\torg.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.web.DelegationTokenIdentifier> getDelegationToken(String renewer);\n\t// Renew the delegation token\n\tlong renewDelegationToken(org.apache.hadoop.security.token.Token<?> token);\n}", "des": "Class to manage delegation token operations by making rest call to remote service."}
{"index": 2733, "repo": "hadoop-azure-3.3.6", "code": "Interface SASKeyGeneratorInterface {\n\t// Interface method to retrieve SAS Key for a container within the storage account.\n\tURI getContainerSASUri(String accountName, String container);\n\t// Interface method to retrieve SAS Key for a blob within the container of the storage account.\n\tURI getRelativeBlobSASUri(String accountName, String container, String relativePath);\n}", "des": "Iterface used by AzureNativeFileSysteStore to retrieve SAS Keys for the respective azure storage entity. This interface is expected to be implemented in two modes: 1) Local Mode: In this mode SAS Keys are generated in same address space as the WASB. This will be primarily used for testing purposes. 2) Remote Mode: In this mode SAS Keys are generated in a sepearte process other than WASB and will be communicated via client."}
{"index": 2734, "repo": "hadoop-azure-3.3.6", "code": "Interface SASTokenProvider {\n\t// Invokes the authorizer to obtain a SAS token.\n\tString getSASToken(String account, String fileSystem, String path, String operation);\n\t// Initialize authorizer for Azure Blob File System.\n\tvoid initialize(org.apache.hadoop.conf.Configuration configuration, String accountName);\n}", "des": "Interface to support SAS authorization."}
{"index": 2735, "repo": "hadoop-azure-3.3.6", "code": "Class SendRequestIntercept {\n\t// Binds a new lister to the operation context so the WASB file system can appropriately intercept sends and allow concurrent OOB I/Os.\n\tstatic void bind(com.microsoft.azure.storage.OperationContext opContext);\n\t// Handler which processes the sending request event from Azure SDK.\n\tvoid eventOccurred(com.microsoft.azure.storage.SendingRequestEvent sendEvent);\n}", "des": "Manages the lifetime of binding on the operation contexts to intercept send request events to Azure storage and allow concurrent OOB I/Os."}
{"index": 2736, "repo": "hadoop-azure-3.3.6", "code": "Class TextFileBasedIdentityHandler {\n\t// Perform lookup from Security Group's Object ID to Local Security Group name.\n\tString lookupForLocalGroupIdentity(String originalIdentity);\n\t// Perform lookup from Service Principal's Object ID to Local Username.\n\tString lookupForLocalUserIdentity(String originalIdentity);\n}", "des": "TextFileBasedIdentityHandler is a IdentityHandler implements translation operation which returns identity mapped to AAD identity by loading the mapping file from the configured location. Location of the mapping file should be configured in core-site.xml."}
{"index": 2737, "repo": "hadoop-azure-3.3.6", "code": "Enum Trilean {\n\t// Converts boolean to Trilean.\n\tstatic Trilean getTrilean(boolean isTrue);\n\t// Converts String to Trilean.\n\tstatic Trilean getTrilean(String str);\n\t// Converts the Trilean enum to boolean.\n\tboolean toBoolean();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Trilean valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Trilean[] values();\n}", "des": "Enum to represent 3 values, TRUE, FALSE and UNKNOWN. Can be used where boolean is not enough to hold the information."}
{"index": 2738, "repo": "hadoop-azure-3.3.6", "code": "Enum WasbAuthorizationOperations {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WasbAuthorizationOperations valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WasbAuthorizationOperations[] values();\n}", "des": "Different authorization operations supported in WASB."}
{"index": 2739, "repo": "hadoop-azure-3.3.6", "code": "Interface WasbAuthorizerInterface {\n\t// Authorizer API to authorize access in WASB.\n\tboolean authorize(String wasbAbolutePath, String accessType, String owner);\n\t// Initializer method\n\tvoid init(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Interface to implement authorization support in WASB. API's of this interface will be implemented in the StorageInterface Layer before making calls to Azure Storage."}
{"index": 2740, "repo": "hadoop-azure-3.3.6", "code": "Interface WasbDelegationTokenManager {\n\t// Cancel the delegation token\n\tvoid cancelDelegationToken(org.apache.hadoop.security.token.Token<?> token);\n\t// Get Delegation token\n\torg.apache.hadoop.security.token.Token<org.apache.hadoop.security.token.delegation.web.DelegationTokenIdentifier> getDelegationToken(String renewer);\n\t// Renew the delegation token\n\tlong renewDelegationToken(org.apache.hadoop.security.token.Token<?> token);\n}", "des": "Interface for Managing the Delegation tokens."}
{"index": 2741, "repo": "nifi-api-1.22.0", "code": "Enum Component {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Component valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Component[] values();\n}", "des": "Defines possible components for a given action."}
{"index": 2742, "repo": "nifi-api-1.22.0", "code": "Enum ComponentType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ComponentType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ComponentType[] values();\n}", "des": "An Enumeration for indicating which type of component a Bulletin is associated with"}
{"index": 2743, "repo": "nifi-api-1.22.0", "code": "Interface ConfigurationContext {\n\tString getAnnotationData();\n\t// Returns the component's (ControllerService, ReportingTask, ParameterProvider, e.g.) name\n\tString getName();\n\tMap<PropertyDescriptor,String> getProperties();\n\tString getSchedulingPeriod();\n\t// Returns the amount of time, in the given TimeUnit that will elapsed between the return of one execution of the component's onTrigger method and the time at which the method is invoked again.\n\tLong getSchedulingPeriod(TimeUnit timeUnit);\n}", "des": "This context is passed to ControllerServices and Reporting Tasks in order to expose their configuration to them."}
{"index": 2744, "repo": "nifi-api-1.22.0", "code": "Interface ControllerService {\n\t// Provides the Controller Service with access to objects that may be of use throughout the life of the service.\n\tvoid initialize(ControllerServiceInitializationContext context);\n\t// Indicates whether this controller service, configured with the given ConfigurationContext, stores state.\n\tdefault boolean isStateful(ConfigurationContext context);\n}", "des": ""}
{"index": 2745, "repo": "nifi-api-1.22.0", "code": "Enum ExecutionNode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExecutionNode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExecutionNode[] values();\n}", "des": "Defines the Nodes where a given Component will be scheduled to run."}
{"index": 2746, "repo": "nifi-api-1.22.0", "code": "Enum ExpressionLanguageScope {\n\tString getDescription();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExpressionLanguageScope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExpressionLanguageScope[] values();\n}", "des": "Indicates the scope of expression language on a property descriptor. Scope of the expression language is hierarchical. NONE -> VARIABLE_REGISTRY -> FLOWFILE_ATTRIBUTES When scope is set to FlowFiles attributes, variables are evaluated against attributes of each incoming flow file. If no matching attribute is found, variable registry will be checked. NONE - expression language is not supported VARIABLE_REGISTRY is hierarchically constructed as below: |---- Variables defined at process group level and then, recursively, up | to the higher process group until the root process group. |--- Variables defined in custom properties files through the | nifi.variable.registry.properties property in nifi.properties file. |-- Environment variables defined at JVM level and system properties. FLOWFILE_ATTRIBUTES - will check attributes of each individual flow file"}
{"index": 2747, "repo": "nifi-api-1.22.0", "code": "Interface ExtensionDocumentationWriter {\n\t// Calls initialize on the component.\n\tvoid initialize(ConfigurableComponent component);\n\t// Write the documentation for the given component.\n\tvoid write(ConfigurableComponent component);\n\t// Writes the documentation for the given component.\n\tvoid write(ConfigurableComponent component, Collection<ServiceAPI> provideServices, Map<String,ServiceAPI> propertyServiceAPIs);\n}", "des": "Generates documentation for an instance of a ConfigurableComponent. Please note that while this class lives within the nifi-api, it is provided primarily as a means for documentation components within the NiFi NAR Maven Plugin. Its home is the nifi-api, however, because the API is needed in order to extract the relevant information and the NAR Maven Plugin cannot have a direct dependency on nifi-api (doing so would cause a circular dependency). By having this homed within the nifi-api, the Maven plugin is able to discover the class dynamically and invoke the one or two methods necessary to create the documentation. This is a new capability in 1.9.0 in preparation for the Extension Registry and therefore, you should NOTE WELL: At this time, while this class is part of nifi-api, it is still evolving and may change in a non-backward-compatible manner or even be removed from one incremental release to the next. Use at your own risk!"}
{"index": 2748, "repo": "nifi-api-1.22.0", "code": "Interface ExternalResourceProvider {\n\t// Fetches the resource determined by the descriptor.\n\tInputStream fetchExternalResource(ExternalResourceDescriptor descriptor);\n\t// Initializes the External Resource Provider based on the given set of properties.\n\tvoid initialize(ExternalResourceProviderInitializationContext context);\n\t// Performs a listing of all resources that are available.\n\tCollection<ExternalResourceDescriptor> listResources();\n}", "des": "Represents an external source where the resource files might be acquired from. These external resources might be various: database drivers, different kind of configurations and so on."}
{"index": 2749, "repo": "nifi-api-1.22.0", "code": "Enum FlowFileFilter.FlowFileFilterResult {\n\tboolean isAccept();\n\tboolean isContinue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FlowFileFilter.FlowFileFilterResult valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FlowFileFilter.FlowFileFilterResult[] values();\n}", "des": "Provides a result type to indicate whether or not a FlowFile should be selected"}
{"index": 2750, "repo": "nifi-api-1.22.0", "code": "Enum Operation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Operation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Operation[] values();\n}", "des": "Defines possible operations for a given action."}
{"index": 2751, "repo": "nifi-api-1.22.0", "code": "Interface ParameterProvider {\n\t// Fetches named groups of parameters from an external source.\n\tList<ParameterGroup> fetchParameters(ConfigurationContext context);\n\t// Provides the Parameter Provider with access to objects that may be of use throughout the life of the provider\n\tvoid initialize(ParameterProviderInitializationContext config);\n}", "des": "Defines a provider that is responsible for fetching from an external source Parameters with which a ParameterContext can be populated."}
{"index": 2752, "repo": "nifi-api-1.22.0", "code": "Enum ParameterSensitivity {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ParameterSensitivity valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ParameterSensitivity[] values();\n}", "des": "Indicates the sensitivity of a parameter."}
{"index": 2753, "repo": "nifi-api-1.22.0", "code": "Enum PrimaryNodeState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PrimaryNodeState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PrimaryNodeState[] values();\n}", "des": "Represents a state change that occurred for the Primary Node of a NiFi cluster."}
{"index": 2754, "repo": "nifi-api-1.22.0", "code": "Interface ReportingTask {\n\t// Provides the Reporting Task with access to objects that may be of use throughout the life of the service\n\tvoid initialize(ReportingInitializationContext config);\n\t// Indicates whether this reporting task, configured with the given ReportingContext, stores state.\n\tdefault boolean isStateful(ReportingContext context);\n\t// This method is called on a scheduled interval to allow the Reporting Task to perform its tasks.\n\tvoid onTrigger(ReportingContext context);\n}", "des": "Defines a task that is responsible for reporting status information to external destinations. All implementations of this class must have a default constructor."}
{"index": 2755, "repo": "nifi-api-1.22.0", "code": "Enum ResourceCardinality {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ResourceCardinality valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ResourceCardinality[] values();\n}", "des": "Indicates the cardinality of how many resources can be referenced by a given property."}
{"index": 2756, "repo": "nifi-api-1.22.0", "code": "Enum ScheduledState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ScheduledState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ScheduledState[] values();\n}", "des": "Indicates the valid values for the state of a Triggerable entity with respect to scheduling the entity to run."}
{"index": 2757, "repo": "nifi-api-1.22.0", "code": "Enum SchedulingStrategy {\n\tint getDefaultConcurrentTasks();\n\tString getDefaultSchedulingPeriod();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SchedulingStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SchedulingStrategy[] values();\n}", "des": "Defines a Scheduling Strategy to use when scheduling Components (Ports, Funnels, Processors) to run"}
{"index": 2758, "repo": "nifi-api-1.22.0", "code": "Enum Scope {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Scope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Scope[] values();\n}", "des": "A Scope represents how a NiFi component's state is to be stored and retrieved when running in a cluster."}
{"index": 2759, "repo": "nifi-api-1.22.0", "code": "Interface StateMap {\n\t// Returns the value associated with the given key\n\tString get(String key);\n\t// Each time that a component's state is updated, the state is assigned a new version.\n\tlong getVersion();\n\t// Returns an immutable Map representation of all keys and values for the state of a component.\n\tMap<String,String> toMap();\n}", "des": "Provides a representation of a component's state at some point in time."}
{"index": 2760, "repo": "nifi-api-1.22.0", "code": "Interface StatusAnalytics {\n\t// Get available predictions where the key (String) in the map is the name of the prediction and value (Long) is the value for the prediction\n\tMap<String,Long> getPredictions();\n\t// Get the Query Window used by the analytics instance\n\tQueryWindow getQueryWindow();\n\t// Return if analytics object supports online learning\n\tboolean supportsOnlineLearning();\n}", "des": "The StatusAnalytics interface offers methods for accessing predicted and other values for a single component (Connection instance, e.g.)."}
{"index": 2761, "repo": "nifi-api-1.22.0", "code": "Enum SystemResource {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SystemResource valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SystemResource[] values();\n}", "des": "Represents a system resource."}
{"index": 2762, "repo": "nifi-api-1.22.0", "code": "Interface VariableRegistry {\n\t// Returns the VariableDescriptor for the given key name if it exists.\n\tdefault VariableDescriptor getVariableKey(String name);\n\t// Provides access to a map of variable key/value pairs.\n\tMap<VariableDescriptor,String> getVariableMap();\n\t// Gets the variable value\n\tdefault String getVariableValue(String name);\n\t// Gets the variable value\n\tdefault String getVariableValue(VariableDescriptor descriptor);\n}", "des": "Provides a registry of variables available for use by various components and extension points. This enables components to reference variable names rather than explicit values which can make configurations of those components more portable."}
{"index": 2763, "repo": "preflight-3.0.0-beta1", "code": "Enum ColorSpaceHelperFactory.ColorSpaceRestriction {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ColorSpaceHelperFactory.ColorSpaceRestriction valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ColorSpaceHelperFactory.ColorSpaceRestriction[] values();\n}", "des": "Enum used as argument of methods of this factory to return the right Helper."}
{"index": 2764, "repo": "preflight-3.0.0-beta1", "code": "Enum ColorSpaces {\n\tString getLabel();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ColorSpaces valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ColorSpaces[] values();\n}", "des": "This enum makes ColorSpaces validation easier. Labels represent ColorSpace names as defined in the \"PDF Reference 1.4\"."}
{"index": 2765, "repo": "preflight-3.0.0-beta1", "code": "Class ICCProfileWrapper {\n\t// Call the ICC_ColorSpace.getType method and return the value.\n\tint getColorSpaceType();\n\tstatic ICCProfileWrapper getOrSearchICCProfile(PreflightContext context);\n\tICC_Profile getProfile();\n\t// Return true if the ColourSpace is CMYK\n\tboolean isCMYKColorSpace();\n\t// Return true if the ColourSpace is Gray scale\n\tboolean isGrayColorSpace();\n\t// Return true if the ColourSpace is RGB\n\tboolean isRGBColorSpace();\n}", "des": "This class embeds an instance of java.awt.color.ICC_Profile which represent the ICCProfile defined by the DestOutputItents key of the OutputIntents of the PDF."}
{"index": 2766, "repo": "preflight-3.0.0-beta1", "code": "Class LineAnnotationValidator {\n\t// Return true if the IC field is present in the Annotation dictionary and if the RGB profile is used in the DestOutputProfile of the OutputIntent dictionary.\n\tprotected boolean checkIColors();\n\t// Override this method to check the presence of specific fields\n\tprotected boolean checkSpecificMandatoryFields();\n\t// In addition of the AnnotationValidator.validate() method, this method executes the checkIColors method.\n\tboolean validate();\n}", "des": "Validation class for the LineAnnotation"}
{"index": 2767, "repo": "preflight-3.0.0-beta1", "code": "Class LinkAnnotationValidator {\n\t// Check if the Dest element is authorized according to the A entry\n\tprotected boolean checkDest();\n\t// In addition of the AnnotationValidator.validate() method, this method executes the checkDest method.\n\tboolean validate();\n}", "des": "Validation class for the LinkAnnotation"}
{"index": 2768, "repo": "preflight-3.0.0-beta1", "code": "Class PreflightType3Stream {\n\t// This will parse a type3 stream and create an image from it.\n\tImage createImage();\n\tfloat getWidth();\n\t// This is used to handle an operation.\n\tprotected void processOperator(org.apache.pdfbox.contentstream.operator.Operator operator, List<org.apache.pdfbox.cos.COSBase> operands);\n\tvoid showType3Character(org.apache.pdfbox.pdmodel.font.PDType3CharProc charProc);\n}", "des": "This class is used to parse a glyph of a Type3 font program. If the glyph is parsed without error, the width of the glyph is accessible through the getWidth method."}
{"index": 2769, "repo": "preflight-3.0.0-beta1", "code": "Class SquareCircleAnnotationValidator {\n\t// Return true if the IC field is present in the Annotation dictionary and if the RGB profile is used in the DestOutputProfile of the OutputIntent dictionary.\n\tprotected boolean checkIColors();\n\t// In addition of the AnnotationValidator.validate() method, this method executes the checkIColors method.\n\tboolean validate();\n}", "des": "Validation class for the Square/Circle Annotation"}
{"index": 2770, "repo": "preflight-3.0.0-beta1", "code": "Class WidgetAnnotationValidator {\n\t// The AA field is forbidden for the Widget annotation when the PDF is a PDF/A.\n\tprotected boolean checkAAField();\n\t// In addition of the AnnotationValidator.validate() method, this method executes the checkAAField method.\n\tboolean validate();\n}", "des": "Validation class for the Widget Annotation"}
{"index": 2771, "repo": "preflight-3.0.0-beta1", "code": "Class XObjImageValidator {\n\tprotected void checkAlternates();\n\t// Valid values are 1, 2, 4 and 8, not 16, see here.\n\tprotected void checkBPC();\n\tprotected void checkColorSpaceAndImageMask();\n\tprotected void checkIntent();\n\tprotected void checkInterpolate();\n\t// This method checks if required fields are present.\n\tprotected void checkMandatoryFields();\n\t// Process the validation of the XObject.\n\tvoid validate();\n}", "des": "This class validates XObject with the Image subtype."}
{"index": 2772, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Class CKMSQuantiles {\n\t// Get the estimated value at the specified quantile.\n\tjava.lang.Double get(double q);\n\tCKMSQuantiles.Quantile[] getQuantiles();\n\t// Get all monitored quantiles\n\tjava.util.Collection<java.lang.Double> monitored();\n\t// Add a new value from the stream.\n\tvoid observe(double value);\n\tstatic CKMSQuantiles.Builder quantile(double quantile, double error);\n}", "des": "Modified from: https://github.com/mayconbordin/streaminer/blob/master/src/main/java/org/streaminer/stream/quantile/CKMSQuantiles.java Implementation of the Cormode, Korn, Muthukrishnan, and Srivastava algorithm for streaming calculation of targeted high-percentile epsilon-approximate quantiles. This is a generalization of the earlier work by Greenwald and Khanna (GK), which essentially allows different error bounds on the targeted quantiles, which allows for far more efficient calculation of high-percentiles. See: Cormode, Korn, Muthukrishnan, and Srivastava \"Effective Computation of Biased Quantiles over Data Streams\" in ICDE 2005 Greenwald and Khanna, \"Space-efficient online computation of quantile summaries\" in SIGMOD 2001"}
{"index": 2773, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Interface Counter {\n\t// The cumulative count since this counter was created.\n\tdouble count();\n\tdefault Meter.Type getType();\n\t// Update the counter by one.\n\tvoid increment();\n\t// Update the counter by amount.\n\tvoid increment(double amount);\n}", "des": "Used to measure the rate of change based on calls to increment."}
{"index": 2774, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Interface DistributionSummary {\n\t// The number of times that record has been called since this timer was created.\n\tlong count();\n\tdefault Meter.Type getType();\n\t// Updates the statistics kept by the summary with the specified amount.\n\tvoid record(double amount);\n\t// The total amount of all recorded events since this summary was created.\n\tdouble totalAmount();\n}", "des": "Track the sample distribution of events. An example would be the response sizes for requests hitting and http server."}
{"index": 2775, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Class Frugal2UQuantiles {\n\tjava.lang.Double get(double q);\n\torg.springframework.metrics.instrument.stats.quantile.Frugal2UQuantiles.Quantile[] getQuantiles();\n\t// Get all monitored quantiles\n\tjava.util.Collection<java.lang.Double> monitored();\n\t// Add a sample\n\tvoid observe(double value);\n\tstatic Frugal2UQuantiles.Builder quantile(double quantile, double estimate);\n}", "des": "Modified from: https://github.com/mayconbordin/streaminer/blob/master/src/main/java/org/streaminer/stream/quantile/Frugal2U.java Implementation of the Frugal2U Algorithm. Reference: Ma, Qiang, S. Muthukrishnan, and Mark Sandler. \"Frugal Streaming for Estimating Quantiles.\" Space-Efficient Data Structures, Streams, and Algorithms. Springer Berlin Heidelberg, 2013. 77-96. Available at: http://arxiv.org/abs/1407.1121 Original code: More info: http://blog.aggregateknowledge.com/2013/09/16/sketch-of-the-day-frugal-streaming/"}
{"index": 2776, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Class GKQuantiles {\n\t// Estimates appropriate quantiles (i.e.\n\tjava.lang.Double get(double q);\n\tjava.lang.Integer getCount();\n\t// Get all monitored quantiles\n\tjava.util.Collection<java.lang.Double> monitored();\n\t// Add a sample\n\tvoid observe(double value);\n\tstatic GKQuantiles.Builder quantiles(double... quantiles);\n\tvoid setEpsilon(double epsilon);\n}", "des": "This class is an implementation of the Greenwald-Khanna algorithm for computing epsilon-approximate quantiles of large data sets. In its pure form it is an offline algorithm. But it is used as a black box by many online algorithms for computing epsilon-approximate quantiles on data streams. Our implementation widely adapts the original idea published by Michael Greenwald and Sanjeev Khanna in their paper \"Space-Efficient Online Computation of Quantile Summaries\". Contrary to their idea this implementation uses a list rather than a tree structure to maintain the elements."}
{"index": 2777, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Class Measurement {\n\tboolean equals(java.lang.Object o);\n\t// Name of the measurement, which together with tags form a unique time series.\n\tjava.lang.String getName();\n\t// Tags for the measurement, which together with name form a unique time series.\n\tjava.util.SortedSet<Tag> getTags();\n\t// Value for the measurement.\n\tdouble getValue();\n}", "des": "A measurement sampled from a meter."}
{"index": 2778, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Enum Meter.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Meter.Type valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Meter.Type[] values();\n}", "des": "Custom meters may emit metrics like one of these types without implementing the corresponding interface. For example, a heisen-counter like structure will emit the same metric as a Counter but does not have the same increment-driven API."}
{"index": 2779, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Class PowerOfTwo {\n\t// Rounds the given value to the next power of two that is greater than the value.\n\tstatic int ceilToNext(int value);\n\t// Rounds the given value to the next power of two that is smaller than the value.\n\tstatic double floorToNext(double value);\n\t// Rounds the given value to the next power of two that is smaller than the value.\n\tstatic java.lang.Float floorToNext(java.lang.Float value);\n}", "des": "Copied from https://github.com/mayconbordin/streaminer#quantiles"}
{"index": 2780, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Interface Quantiles {\n\tjava.lang.Double get(double percentile);\n\t// Get all monitored quantiles\n\tjava.util.Collection<java.lang.Double> monitored();\n\t// Add a sample\n\tvoid observe(double value);\n}", "des": "Calculate -quantiles, where 0    1. The -quantile is the observation value that ranks at number *N among N observations. Examples for -quantiles: The 0.5-quantile is known as the median. The 0.95-quantile is the 95th percentile."}
{"index": 2781, "repo": "spring-metrics-0.5.1.RELEASE", "code": "Class WindowSketchQuantiles {\n\tjava.lang.Double get(double q);\n\t// Get all monitored quantiles\n\tjava.util.Collection<java.lang.Double> monitored();\n\t// Add a sample\n\tvoid observe(double value);\n\tstatic WindowSketchQuantiles.Builder quantiles(double... quantiles);\n\t// By default the window size is set to 32768.\n\tvoid setWindowSize(int windowSize);\n}", "des": "Modified from https://github.com/mayconbordin/streaminer#quantiles"}
{"index": 2782, "repo": "mahout-mr-0.13.0", "code": "Class AbstractJDBCIDMigrator {\n\t// Make the mapping aware of the given string IDs.\n\tvoid initialize(Iterable<String> stringIDs);\n\t// Stores the reverse long-to-String mapping in some kind of backing store.\n\tvoid storeMapping(long longID, String stringID);\n\tString toStringID(long longID);\n}", "des": "Implementation which stores the reverse long-to-String mapping in a database. Subclasses can override and configure the class to operate with particular databases by supplying appropriate SQL statements to the constructor."}
{"index": 2783, "repo": "mahout-mr-0.13.0", "code": "Class AveragingPreferenceInferrer {\n\t// Infers the given user's preference value for an item.\n\tfloat inferPreference(long userID, long itemID);\n\t// Triggers \"refresh\" -- whatever that means -- of the implementation.\n\tvoid refresh(Collection<Refreshable> alreadyRefreshed);\n}", "des": ""}
{"index": 2784, "repo": "mahout-mr-0.13.0", "code": "Class Cache<K,V> {\n\t// Clears the cache.\n\tvoid clear();\n\t// Returns cached value for a key.\n\tV get(K key);\n\t// Uncaches any existing value for a given key.\n\tvoid remove(K key);\n\t// Clears all cache entries whose key matches the given predicate.\n\tvoid removeKeysMatching(Cache.MatchPredicate<K> predicate);\n\t// Clears all cache entries whose value matches the given predicate.\n\tvoid removeValueMatching(Cache.MatchPredicate<V> predicate);\n}", "des": ""}
{"index": 2785, "repo": "mahout-mr-0.13.0", "code": "Enum CachingCVB0PerplexityMapper.Counters {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CachingCVB0PerplexityMapper.Counters valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CachingCVB0PerplexityMapper.Counters[] values();\n}", "des": "Hadoop counters for CachingCVB0PerplexityMapper, to aid in debugging."}
{"index": 2786, "repo": "mahout-mr-0.13.0", "code": "Class CachingUserSimilarity {\n\tvoid clearCacheForUser(long userID);\n\t// Triggers \"refresh\" -- whatever that means -- of the implementation.\n\tvoid refresh(Collection<Refreshable> alreadyRefreshed);\n\t// Attaches a PreferenceInferrer to the UserSimilarity implementation.\n\tvoid setPreferenceInferrer(PreferenceInferrer inferrer);\n\t// Returns the degree of similarity, of two users, based on the their preferences.\n\tdouble userSimilarity(long userID1, long userID2);\n}", "des": "Caches the results from an underlying UserSimilarity implementation."}
{"index": 2787, "repo": "mahout-mr-0.13.0", "code": "Class CachingValueEncoder {\n\tprotected abstract int getSeed();\n\t// Provides the unique hash for a particular probe.\n\tprotected int hashForProbe(byte[] originalForm, int dataSize, String name, int probe);\n\t// Sets the number of locations in the feature vector that a value should be in.\n\tvoid setProbes(int probes);\n}", "des": "Provides basic hashing semantics for encoders where the probe locations depend only on the name of the variable."}
{"index": 2788, "repo": "mahout-mr-0.13.0", "code": "Interface Cluster {\n\t// Produce a custom, human-friendly, printable representation of the Cluster.\n\tString asFormatString(String[] bindings);\n\t// Produce a JSON representation of the Cluster.\n\tMap<String,Object> asJson(String[] bindings);\n\t// Get the \"center\" of the Cluster as a Vector\n\tVector getCenter();\n\t// Get the id of the Cluster\n\tint getId();\n\t// Get the \"radius\" of the Cluster as a Vector.\n\tVector getRadius();\n\tboolean isConverged();\n}", "des": "Implementations of this interface have a printable representation and certain attributes that are common across all clustering implementations"}
{"index": 2789, "repo": "mahout-mr-0.13.0", "code": "Class ClusterCountReader {\n\t// Generates a list of all cluster ids by reading the clusters-*-final file.\n\tstatic Map<Integer,Integer> getClusterIDs(org.apache.hadoop.fs.Path clusterOutputPath, org.apache.hadoop.conf.Configuration conf, boolean keyIsClusterId);\n\t// Reads the number of clusters present by reading the clusters-*-final file.\n\tstatic int getNumberOfClusters(org.apache.hadoop.fs.Path clusterOutputPath, org.apache.hadoop.conf.Configuration conf);\n}", "des": "Reads the number of clusters produced by the clustering algorithm."}
{"index": 2790, "repo": "mahout-mr-0.13.0", "code": "Interface ClusteringPolicy {\n\t// Classify the data vector given the classifier's models\n\tVector classify(Vector data, ClusterClassifier prior);\n\t// Close the policy using the classifier's models\n\tvoid close(ClusterClassifier posterior);\n\t// Return a vector of weights for each of the models given those probabilities\n\tVector select(Vector probabilities);\n\t// Update the policy with the given classifier\n\tvoid update(ClusterClassifier posterior);\n}", "des": "A ClusteringPolicy captures the semantics of assignment of points to clusters"}
{"index": 2791, "repo": "mahout-mr-0.13.0", "code": "Class ClusterOutputPostProcessorDriver {\n\tstatic void main(String[] args);\n\t// Post processes the output of clustering algorithms and groups them into respective clusters.\n\tstatic void run(org.apache.hadoop.fs.Path input, org.apache.hadoop.fs.Path output, boolean runSequential);\n\t// CLI to run clustering post processor.\n\tint run(String[] args);\n}", "des": "Post processes the output of clustering algorithms and groups them into respective clusters. Ideal to be used for top down clustering. It can also be used if the clustering output needs to be grouped into their respective clusters."}
{"index": 2792, "repo": "mahout-mr-0.13.0", "code": "Class ContinuousValueEncoder {\n\t// Adds a value to a vector.\n\tvoid addToVector(byte[] originalForm, double weight, Vector data);\n\t// Converts a value into a form that would help a human understand the internals of how the value is being interpreted.\n\tString asString(String originalForm);\n\tprotected int getSeed();\n\tprotected double getWeight(byte[] originalForm, double w);\n}", "des": "Continuous values are stored in fixed randomized location in the feature vector."}
{"index": 2793, "repo": "mahout-mr-0.13.0", "code": "Enum Dataset.Attribute {\n\tboolean isCategorical();\n\tboolean isIgnored();\n\tboolean isLabel();\n\tboolean isNumerical();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Dataset.Attribute valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Dataset.Attribute[] values();\n}", "des": "Attributes type"}
{"index": 2794, "repo": "mahout-mr-0.13.0", "code": "Interface DistanceMeasure {\n\t// Optimized version of distance metric for sparse vectors.\n\tdouble distance(double centroidLengthSquare, Vector centroid, Vector v);\n\t// Returns the distance metric applied to the arguments\n\tdouble distance(Vector v1, Vector v2);\n}", "des": "This interface is used for objects which can determine a distance metric between two points"}
{"index": 2795, "repo": "mahout-mr-0.13.0", "code": "Class ElasticBandPrior {\n\t// Applies the regularization to a coefficient.\n\tdouble age(double oldValue, double generations, double learningRate);\n\t// Returns the log of the probability of a particular coefficient value according to the prior.\n\tdouble logP(double betaIJ);\n\tvoid readFields(DataInput in);\n\tvoid write(DataOutput out);\n}", "des": "Implements a linear combination of L1 and L2 priors. This can give an interesting mixture of sparsity and load-sharing between redundant predictors."}
{"index": 2796, "repo": "mahout-mr-0.13.0", "code": "Class EuclideanDistanceMeasure {\n\t// Optimized version of distance metric for sparse vectors.\n\tdouble distance(double centroidLengthSquare, Vector centroid, Vector v);\n\t// Returns the distance metric applied to the arguments\n\tdouble distance(Vector v1, Vector v2);\n}", "des": "This class implements a Euclidean distance metric by summing the square root of the squared differences between each coordinate."}
{"index": 2797, "repo": "mahout-mr-0.13.0", "code": "Class FilePersistenceStrategy {\n\t// Load a factorization from a persistent store.\n\tFactorization load();\n\t// Write a factorization to a persistent store unless it already contains an identical factorization.\n\tvoid maybePersist(Factorization factorization);\n\tstatic Factorization readBinary(DataInput in);\n\tprotected static void writeBinary(Factorization factorization, DataOutput out);\n}", "des": "Provides a file-based persistent store."}
{"index": 2798, "repo": "mahout-mr-0.13.0", "code": "Class FuzzyKMeansClusteringPolicy {\n\t// Classify the data vector given the classifier's models\n\tVector classify(Vector data, ClusterClassifier prior);\n\t// Close the policy using the classifier's models\n\tvoid close(ClusterClassifier posterior);\n\tvoid readFields(DataInput in);\n\t// Return a vector of weights for each of the models given those probabilities\n\tVector select(Vector probabilities);\n\tvoid write(DataOutput out);\n}", "des": "This is a probability-weighted clustering policy, suitable for fuzzy k-means clustering"}
{"index": 2799, "repo": "mahout-mr-0.13.0", "code": "Class GenericItemSimilarity {\n\tlong[] allSimilarItemIDs(long itemID);\n\t// A bulk-get version of ItemSimilarity.itemSimilarity(long, long).\n\tdouble[] itemSimilarities(long itemID1, long[] itemID2s);\n\t// Returns the similarity between two items.\n\tdouble itemSimilarity(long itemID1, long itemID2);\n\t// Triggers \"refresh\" -- whatever that means -- of the implementation.\n\tvoid refresh(Collection<Refreshable> alreadyRefreshed);\n}", "des": ""}
{"index": 2800, "repo": "mahout-mr-0.13.0", "code": "Class HmmAlgorithms {\n\t// External function to compute a matrix of beta factors\n\tstatic Matrix backwardAlgorithm(HmmModel model, int[] observations, boolean scaled);\n\t// External function to compute a matrix of alpha factors\n\tstatic Matrix forwardAlgorithm(HmmModel model, int[] observations, boolean scaled);\n\t// Viterbi algorithm to compute the most likely hidden sequence for a given model and observed sequence\n\tstatic int[] viterbiAlgorithm(HmmModel model, int[] observations, boolean scaled);\n}", "des": "Class containing implementations of the three major HMM algorithms: forward, backward and Viterbi"}
{"index": 2801, "repo": "mahout-mr-0.13.0", "code": "Class IDReader {\n\tFastIDSet getItemIds();\n\t// Gets a collection of items which should be recommended for a user\n\tFastIDSet getItemsToRecommendForUser(Long userId);\n\tFastIDSet getUserIds();\n\tboolean isItemsFileSpecified();\n\tboolean isUserItemFileSpecified();\n\tboolean isUserItemFilterSpecified();\n\tboolean isUsersFileSpecified();\n\t// Reads user ids and item ids from files specified in a job configuration\n\tvoid readIDs();\n}", "des": "Reads user ids and item ids from files specified in usersFile, itemsFile or userItemFile options in item-based recommender. Composes a list of users and a list of items which can be used by UserVectorSplitterMapper and AggregateAndRecommendReducer."}
{"index": 2802, "repo": "mahout-mr-0.13.0", "code": "Interface IRStatistics {\n\t// See F-measure.\n\tdouble getF1Measure();\n\t// See Fall-Out.\n\tdouble getFallOut();\n\t// See F-measure.\n\tdouble getFNMeasure(double n);\n\t// See Normalized Discounted Cumulative Gain.\n\tdouble getNormalizedDiscountedCumulativeGain();\n\t// See Precision.\n\tdouble getPrecision();\n\tdouble getReach();\n\t// See Recall.\n\tdouble getRecall();\n}", "des": ""}
{"index": 2803, "repo": "mahout-mr-0.13.0", "code": "Interface ItemSimilarity {\n\tlong[] allSimilarItemIDs(long itemID);\n\t// A bulk-get version of itemSimilarity(long, long).\n\tdouble[] itemSimilarities(long itemID1, long[] itemID2s);\n\t// Returns the degree of similarity, of two items, based on the preferences that users have expressed for the items.\n\tdouble itemSimilarity(long itemID1, long itemID2);\n}", "des": ""}
{"index": 2804, "repo": "mahout-mr-0.13.0", "code": "Class L1 {\n\t// Applies the regularization to a coefficient.\n\tdouble age(double oldValue, double generations, double learningRate);\n\t// Returns the log of the probability of a particular coefficient value according to the prior.\n\tdouble logP(double betaIJ);\n\tvoid readFields(DataInput dataInput);\n\tvoid write(DataOutput out);\n}", "des": "Implements the Laplacian or bi-exponential prior. This prior has a strong tendency to set coefficients to zero and thus is useful as an alternative to variable selection. This version implements truncation which prevents a coefficient from changing sign. If a correction would change the sign, the coefficient is truncated to zero. Note that it doesn't matter to have a scale for this distribution because after taking the derivative of the logP, the lambda coefficient used to combine the prior with the observations has the same effect. If we had a scale here, then it would be the same effect as just changing lambda."}
{"index": 2805, "repo": "mahout-mr-0.13.0", "code": "Class L2 {\n\t// Applies the regularization to a coefficient.\n\tdouble age(double oldValue, double generations, double learningRate);\n\t// Returns the log of the probability of a particular coefficient value according to the prior.\n\tdouble logP(double betaIJ);\n\tvoid readFields(DataInput in);\n\tvoid write(DataOutput out);\n}", "des": "Implements the Gaussian prior. This prior has a tendency to decrease large coefficients toward zero, but doesn't tend to set them to exactly zero."}
{"index": 2806, "repo": "mahout-mr-0.13.0", "code": "Enum LLRReducer.Skipped {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LLRReducer.Skipped valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LLRReducer.Skipped[] values();\n}", "des": "Counter to track why a particlar entry was skipped"}
{"index": 2807, "repo": "mahout-mr-0.13.0", "code": "Class MatrixColumnMeansJob.MatrixColumnMeansMapper {\n\t// The column-wise sum is written at the cleanup stage.\n\tvoid cleanup(org.apache.hadoop.mapreduce.Mapper.Context context);\n\t// The mapper computes a running sum of the vectors the task has seen.\n\tvoid map(org.apache.hadoop.io.Writable r, VectorWritable v, org.apache.hadoop.mapreduce.Mapper.Context context);\n\tvoid setup(org.apache.hadoop.mapreduce.Mapper.Context context);\n}", "des": "Mapper for calculation of column-wise mean."}
{"index": 2808, "repo": "mahout-mr-0.13.0", "code": "Class MemoryIDMigrator {\n\t// Make the mapping aware of the given string IDs.\n\tvoid initialize(Iterable<String> stringIDs);\n\t// Stores the reverse long-to-String mapping in some kind of backing store.\n\tvoid storeMapping(long longID, String stringID);\n\tString toStringID(long longID);\n}", "des": "Implementation which stores the reverse long-to-String mapping in memory."}
{"index": 2809, "repo": "mahout-mr-0.13.0", "code": "Class MemoryUtil {\n\t// Logs current heap memory statistics.\n\tstatic void logMemoryStatistics();\n\t// Constructs and starts a memory logger thread with a logging rate of 1000 milliseconds.\n\tstatic void startMemoryLogger();\n\t// Constructs and starts a memory logger thread.\n\tstatic void startMemoryLogger(long rateInMillis);\n\t// Stops the memory logger, if any, started via startMemoryLogger(long) or startMemoryLogger().\n\tstatic void stopMemoryLogger();\n}", "des": "Memory utilities."}
{"index": 2810, "repo": "mahout-mr-0.13.0", "code": "Class ModelDissector {\n\t// Returns the n most important features with their weights, most important category and the top few categories that they affect.\n\tList<ModelDissector.Weight> summary(int n);\n\t// Probes a model to determine the effect of a particular variable.\n\tvoid update(Vector features, Map<String,Set<Integer>> traceDictionary, AbstractVectorClassifier learner);\n}", "des": "Uses sample data to reverse engineer a feature-hashed model. The result gives approximate weights for features and interactions in the original space. The idea is that the hashed encoders have the option of having a trace dictionary. This tells us where each feature is hashed to, or each feature/value combination in the case of word-like values. Using this dictionary, we can put values into a synthetic feature vector in just the locations specified by a single feature or interaction. Then we can push this through a linear part of a model to see the contribution of that input. For any generalized linear model like logistic regression, there is a linear part of the model that allows this. What the ModelDissector does is to accept a trace dictionary and a model in an update method. It figures out the weights for the elements in the trace dictionary and stashes them. Then in a summary method, the biggest weights are returned. This update/flush style is used so that the trace dictionary doesn't have to grow to enormous levels, but instead can be cleared between updates."}
{"index": 2811, "repo": "mahout-mr-0.13.0", "code": "Interface ModelDistribution<O> {\n\t// Return a list of models sampled from the posterior\n\tModel<O>[] sampleFromPosterior(Model<O>[] posterior);\n\t// Return a list of models sampled from the prior\n\tModel<O>[] sampleFromPrior(int howMany);\n}", "des": "A model distribution allows us to sample a model from its prior distribution."}
{"index": 2812, "repo": "mahout-mr-0.13.0", "code": "Class NoPersistenceStrategy {\n\t// Load a factorization from a persistent store.\n\tFactorization load();\n\t// Write a factorization to a persistent store unless it already contains an identical factorization.\n\tvoid maybePersist(Factorization factorization);\n}", "des": "A PersistenceStrategy which does nothing."}
{"index": 2813, "repo": "mahout-mr-0.13.0", "code": "Class NullRescorer<T> {\n\tstatic IDRescorer getItemInstance();\n\tstatic Rescorer<LongPair> getItemItemPairInstance();\n\tstatic IDRescorer getUserInstance();\n\tstatic Rescorer<LongPair> getUserUserPairInstance();\n\t// Returns true to exclude the given thing.\n\tboolean isFiltered(long id);\n\t// Returns true to exclude the given thing.\n\tboolean isFiltered(T thing);\n\tdouble rescore(long id, double originalScore);\n\tdouble rescore(T thing, double originalScore);\n}", "des": ""}
{"index": 2814, "repo": "mahout-mr-0.13.0", "code": "Class OnlineGaussianAccumulator {\n\t// Compute the mean, variance and standard deviation\n\tvoid compute();\n\tdouble getAverageStd();\n\tVector getMean();\n\tdouble getN();\n\tVector getStd();\n\tVector getVariance();\n\t// Observe the vector\n\tvoid observe(Vector x, double weight);\n}", "des": "An online Gaussian statistics accumulator based upon Knuth (who cites Welford) which is declared to be numerically-stable. See http://en.wikipedia.org/wiki/Algorithms_for_calculating_variance"}
{"index": 2815, "repo": "mahout-mr-0.13.0", "code": "Enum PathType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PathType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PathType[] values();\n}", "des": "Used by SequenceFileDirIterable and the like to select whether the input path specifies a directory to list, or a glob pattern."}
{"index": 2816, "repo": "mahout-mr-0.13.0", "code": "Interface PersistenceStrategy {\n\t// Load a factorization from a persistent store.\n\tFactorization load();\n\t// Write a factorization to a persistent store unless it already contains an identical factorization.\n\tvoid maybePersist(Factorization factorization);\n}", "des": "Provides storage for Factorizations"}
{"index": 2817, "repo": "mahout-mr-0.13.0", "code": "Interface PriorFunction {\n\t// Applies the regularization to a coefficient.\n\tdouble age(double oldValue, double generations, double learningRate);\n\t// Returns the log of the probability of a particular coefficient value according to the prior.\n\tdouble logP(double betaIJ);\n}", "des": "A prior is used to regularize the learning algorithm. This allows a trade-off to be made between complexity of the model being learned and the accuracy with which the model fits the training data. There are different definitions of complexity which can be approximated using different priors. For large sparse systems, such as text classification, the L1 prior is often used which favors sparse models."}
{"index": 2818, "repo": "mahout-mr-0.13.0", "code": "Class RunningSumsGaussianAccumulator {\n\t// Compute the mean, variance and standard deviation\n\tvoid compute();\n\tdouble getAverageStd();\n\tVector getMean();\n\tdouble getN();\n\tVector getStd();\n\tVector getVariance();\n\t// Observe the vector\n\tvoid observe(Vector x, double weight);\n}", "des": "An online Gaussian accumulator that uses a running power sums approach as reported on http://en.wikipedia.org/wiki/Standard_deviation Suffers from overflow, underflow and roundoff error but has minimal observe-time overhead"}
{"index": 2819, "repo": "mahout-mr-0.13.0", "code": "Class SpearmanCorrelationSimilarity {\n\t// Triggers \"refresh\" -- whatever that means -- of the implementation.\n\tvoid refresh(Collection<Refreshable> alreadyRefreshed);\n\t// Attaches a PreferenceInferrer to the UserSimilarity implementation.\n\tvoid setPreferenceInferrer(PreferenceInferrer inferrer);\n\t// Returns the degree of similarity, of two users, based on the their preferences.\n\tdouble userSimilarity(long userID1, long userID2);\n}", "des": ""}
{"index": 2820, "repo": "mahout-mr-0.13.0", "code": "Class StaticWordValueEncoder {\n\t// Provides the unique hash for a particular probe.\n\tprotected int hashForProbe(byte[] originalForm, int dataSize, String name, int probe);\n\t// Sets the weighting dictionary to be used by this encoder.\n\tvoid setDictionary(Map<String,Double> dictionary);\n\t// Sets the weight that is to be used for values that do not appear in the dictionary.\n\tvoid setMissingValueWeight(double missingValueWeight);\n\tprotected double weight(byte[] originalForm);\n}", "des": "Encodes a categorical values with an unbounded vocabulary. Values are encoding by incrementing a few locations in the output vector with a weight that is either defaulted to 1 or that is looked up in a weight dictionary. By default, only one probe is used which should be fine but could cause a decrease in the speed of learning because more features will be non-zero. If a large feature vector is used so that the probability of feature collisions is suitably small, then this can be decreased to 1. If a very small feature vector is used, the number of probes should probably be increased to 3."}
{"index": 2821, "repo": "mahout-mr-0.13.0", "code": "Class StringUtils {\n\tstatic String escapeXML(CharSequence input);\n\t// Restores the object from its string representation.\n\tstatic <T> T fromString(String str);\n\t// Converts the object to a one-line string representation\n\tstatic String toString(Object obj);\n}", "des": "Offers two methods to convert an object to a string representation and restore the object given its string representation. Should use Hadoop Stringifier whenever available."}
{"index": 2822, "repo": "mahout-mr-0.13.0", "code": "Class SVDRecommender {\n\t// a preference is estimated by computing the dot-product of the user and item feature vectors\n\tfloat estimatePreference(long userID, long itemID);\n\tList<RecommendedItem> recommend(long userID, int howMany, IDRescorer rescorer, boolean includeKnownItems);\n\t// Refresh the data model and factorization.\n\tvoid refresh(Collection<Refreshable> alreadyRefreshed);\n}", "des": "A Recommender that uses matrix factorization (a projection of users and items onto a feature space)"}
{"index": 2823, "repo": "mahout-mr-0.13.0", "code": "Class TanimotoDistanceMeasure {\n\t// Optimized version of distance metric for sparse vectors.\n\tdouble distance(double centroidLengthSquare, Vector centroid, Vector v);\n\t// Calculates the distance between two vectors.\n\tdouble distance(Vector a, Vector b);\n}", "des": "Tanimoto coefficient implementation. http://en.wikipedia.org/wiki/Jaccard_index"}
{"index": 2824, "repo": "mahout-mr-0.13.0", "code": "Class TasteHadoopUtils {\n\t// Maps a long to an int with range of 0 to Integer.MAX_VALUE-1\n\tstatic int idToIndex(long id);\n\tstatic int readID(String token, boolean usesLongIDs);\n\t// Reads a binary mapping file\n\tstatic OpenIntLongHashMap readIDIndexMap(String idIndexPathStr, org.apache.hadoop.conf.Configuration conf);\n\t// Splits a preference data line into string tokens\n\tstatic String[] splitPrefTokens(CharSequence line);\n}", "des": "Some helper methods for the hadoop-related stuff in org.apache.mahout.cf.taste"}
{"index": 2825, "repo": "mahout-mr-0.13.0", "code": "Class TPrior {\n\t// Applies the regularization to a coefficient.\n\tdouble age(double oldValue, double generations, double learningRate);\n\t// Returns the log of the probability of a particular coefficient value according to the prior.\n\tdouble logP(double betaIJ);\n\tvoid readFields(DataInput in);\n\tvoid write(DataOutput out);\n}", "des": "Provides a t-distribution as a prior."}
{"index": 2826, "repo": "mahout-mr-0.13.0", "code": "Class UniformPrior {\n\t// Applies the regularization to a coefficient.\n\tdouble age(double oldValue, double generations, double learningRate);\n\t// Returns the log of the probability of a particular coefficient value according to the prior.\n\tdouble logP(double betaIJ);\n\tvoid readFields(DataInput dataInput);\n\tvoid write(DataOutput dataOutput);\n}", "des": "A uniform prior. This is an improper prior that corresponds to no regularization at all."}
{"index": 2827, "repo": "mahout-mr-0.13.0", "code": "Interface UserSimilarity {\n\t// Attaches a PreferenceInferrer to the UserSimilarity implementation.\n\tvoid setPreferenceInferrer(PreferenceInferrer inferrer);\n\t// Returns the degree of similarity, of two users, based on the their preferences.\n\tdouble userSimilarity(long userID1, long userID2);\n}", "des": ""}
{"index": 2828, "repo": "mahout-mr-0.13.0", "code": "Class WeightedEuclideanDistanceMeasure {\n\t// Optimized version of distance metric for sparse vectors.\n\tdouble distance(double centroidLengthSquare, Vector centroid, Vector v);\n\t// Returns the distance metric applied to the arguments\n\tdouble distance(Vector p1, Vector p2);\n}", "des": "This class implements a Euclidean distance metric by summing the square root of the squared differences between each coordinate, optionally adding weights."}
{"index": 2829, "repo": "mahout-mr-0.13.0", "code": "Class WeightedManhattanDistanceMeasure {\n\t// Optimized version of distance metric for sparse vectors.\n\tdouble distance(double centroidLengthSquare, Vector centroid, Vector v);\n\t// Returns the distance metric applied to the arguments\n\tdouble distance(Vector p1, Vector p2);\n}", "des": "This class implements a \"Manhattan distance\" metric by summing the absolute values of the difference between each coordinate, optionally with weights."}
{"index": 2830, "repo": "mahout-mr-0.13.0", "code": "Enum Weighting {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Weighting valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Weighting[] values();\n}", "des": ""}
{"index": 2831, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class AbstractPrimitiveJavaObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Whether the ObjectInspector prefers to return a Primitive Writable Object instead of a Primitive Java Object.\n\tboolean preferWritable();\n}", "des": "An AbstractJavaPrimitiveObjectInspector for a Java object."}
{"index": 2832, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class AbstractPrimitiveLazyObjectInspector<T extends org.apache.hadoop.io.Writable> {\n\t// Return the data in an instance of primitive writable Object.\n\tT getPrimitiveWritableObject(Object o);\n\t// Whether the ObjectInspector prefers to return a Primitive Writable Object instead of a Primitive Java Object.\n\tboolean preferWritable();\n}", "des": "An AbstractPrimitiveLazyObjectInspector for a LazyPrimitive object."}
{"index": 2833, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class AbstractPrimitiveWritableObjectInspector {\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Whether the ObjectInspector prefers to return a Primitive Writable Object instead of a Primitive Java Object.\n\tboolean preferWritable();\n}", "des": "An AbstractWritablePrimitiveObjectInspector for a Writable object."}
{"index": 2834, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class AvroLazyObjectInspector {\n\t// returns null for data = null.\n\tObject getStructFieldData(Object data, StructField f);\n\t// returns null for data = null.\n\tList<Object> getStructFieldsDataAsList(Object data);\n\t// Set the reader schema for the AvroLazyObjectInspector to the given schema\n\tvoid setReaderSchema(org.apache.avro.Schema readerSchema);\n\t// Set the AvroSchemaRetriever for the AvroLazyObjectInspector to the given class\n\tvoid setSchemaRetriever(AvroSchemaRetriever schemaRetriever);\n}", "des": "Lazy objectinspector for avro serialization"}
{"index": 2835, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class AvroSchemaRetriever {\n\t// Possible offset associated with schema.\n\tint getOffset();\n\t// Retrieve the reader avro schema from the given source\n\torg.apache.avro.Schema retrieveReaderSchema(Object source);\n\t// Retrieve the writer avro schema from the given source\n\tabstract org.apache.avro.Schema retrieveWriterSchema(Object source);\n}", "des": "Retrieves the avro schema from the given source. \"Source\" is a little loose term here in the sense it can range from being an HDFS url location pointing to the schema or it can be even as simple as a properties file with a simple key-value mapping to the schema. For cases where the schema is a part of the serialized data itself, \"Source\" would refer to the data bytes from which the schema has to retrieved."}
{"index": 2836, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum AvroSerdeUtils.AvroTableProperties {\n\tString getPropName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AvroSerdeUtils.AvroTableProperties valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AvroSerdeUtils.AvroTableProperties[] values();\n}", "des": "Enum container for all avro table properties. If introducing a new avro-specific table property, add it here. Putting them in an enum rather than separate strings allows them to be programmatically grouped and referenced together."}
{"index": 2837, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum BinaryEncoding {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BinaryEncoding valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BinaryEncoding[] values();\n}", "des": "Enums describing the available String->Bytes encoding available for JSON parsing. This base-64 variant is what most people would think of \"the standard\" Base64 encoding for JSON: the specific MIME content transfer encoding. The Raw String encoding produces an array of bytes by reading the JSON value as a String and transforming it using Java's String getBytes() method."}
{"index": 2838, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class ColumnarSerDe {\n\t// Initialize the SerDe.\n\tvoid initialize(org.apache.hadoop.conf.Configuration configuration, Properties tableProperties, Properties partitionProperties);\n\t// Serialize a row of data.\n\torg.apache.hadoop.io.Writable serialize(Object obj, ObjectInspector objInspector);\n}", "des": "ColumnarSerDe is used for columnar based storage supported by RCFile. ColumnarSerDe differentiate from LazySimpleSerDe in: (1) ColumnarSerDe uses a ColumnarStruct as its lazy Object (2) ColumnarSerDe initialize ColumnarStruct's field directly. But under the field level, it works like LazySimpleSerDe"}
{"index": 2839, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class ColumnarStruct {\n\t// create the lazy object for this field\n\tprotected LazyObjectBase createLazyObjectBase(ObjectInspector objectInspector);\n\t// Check if the object is null and return the length of the stream\n\tprotected int getLength(ObjectInspector objectInspector, ByteArrayRef cachedByteArrayRef, int start, int fieldLen);\n}", "des": "ColumnarStruct is different from LazyStruct in that ColumnarStruct's field Object get parsed at its initialize time when call ColumnarStructBase.init(BytesRefArrayWritable cols), while LazyStruct parse fields in a lazy way."}
{"index": 2840, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface DateObjectInspector {\n\t// Get the Java Primitive object.\n\tDate getPrimitiveJavaObject(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tDateWritableV2 getPrimitiveWritableObject(Object o);\n}", "des": "A DateObjectInspector inspects an Object representing a Date."}
{"index": 2841, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface Deserializer {\n\t// Deserialize an object out of a Writable blob.\n\tObject deserialize(org.apache.hadoop.io.Writable blob);\n\t// Get the object inspector that can be used to navigate through the internal structure of the Object returned from deserialize(...).\n\tObjectInspector getObjectInspector();\n}", "des": "HiveDeserializer is used to deserialize the data from hadoop Writable to a custom java object that can be of any type that the developer wants. HiveDeserializer also provides the ObjectInspector which can be used to inspect the internal structure of the object (that is returned by deserialize function). All deserializers should extend the abstract class AbstractDeserializer. The interface is necessary for SerDes to be able to implement both Serializer and Deserializer."}
{"index": 2842, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface HiveDecimalObjectInspector {\n\t// Get the Java Primitive object.\n\tHiveDecimal getPrimitiveJavaObject(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tHiveDecimalWritable getPrimitiveWritableObject(Object o);\n}", "des": "A DecimalObjectInspector inspects an Object representing a HiveDecimal."}
{"index": 2843, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface HiveIntervalDayTimeObjectInspector {\n\t// Get the Java Primitive object.\n\tHiveIntervalDayTime getPrimitiveJavaObject(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tHiveIntervalDayTimeWritable getPrimitiveWritableObject(Object o);\n}", "des": "A HiveIntervalObjectInspector inspects an Object representing an Interval."}
{"index": 2844, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface HiveIntervalYearMonthObjectInspector {\n\t// Get the Java Primitive object.\n\tHiveIntervalYearMonth getPrimitiveJavaObject(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tHiveIntervalYearMonthWritable getPrimitiveWritableObject(Object o);\n}", "des": "A HiveIntervalObjectInspector inspects an Object representing a year-month Interval."}
{"index": 2845, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum HiveJsonReader.Feature {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveJsonReader.Feature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveJsonReader.Feature[] values();\n}", "des": "Enumeration that defines all on/off features for this reader. COL_INDEX_PARSING PRIMITIVE_TO_WRITABLE IGNORE_UNKNOWN_FIELDS"}
{"index": 2846, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum HiveJsonWriter.Feature {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveJsonWriter.Feature valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveJsonWriter.Feature[] values();\n}", "des": "Enumeration that defines all on/off features for this writer."}
{"index": 2847, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class InputByteBuffer {\n\t// Return the bytes in hex format.\n\tString dumpHex();\n\t// Returns the underlying byte array.\n\tbyte[] getData();\n\tint getEnd();\n\tboolean isEof();\n\tbyte read();\n\t// Read one byte from the byte buffer.\n\tbyte read(boolean invert);\n\t// Reset the byte buffer to the given byte range.\n\tvoid reset(byte[] data, int start, int end);\n\t// Set the current position.\n\tvoid seek(int position);\n\t// Return the current position.\n\tint tell();\n}", "des": "This class is much more efficient than ByteArrayInputStream because none of the methods are synchronized."}
{"index": 2848, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class InstanceCache<SeedObject,Instance> {\n\tprotected abstract Instance makeInstance(SeedObject hv, Set<SeedObject> seenSchemas);\n\t// Retrieve (or create if it doesn't exist) the correct Instance for this SeedObject\n\tInstance retrieve(SeedObject hv);\n\t// Retrieve (or create if it doesn't exist) the correct Instance for this SeedObject using 'seenSchemas' to resolve circular references\n\tInstance retrieve(SeedObject hv, Set<SeedObject> seenSchemas);\n}", "des": "Cache for objects whose creation only depends on some other set of objects and therefore can be used against other equivalent versions of those objects. Essentially memoizes instance creation."}
{"index": 2849, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaBooleanObjectInspector {\n\t// Create an object with the value.\n\tObject create(boolean value);\n\t// Get the boolean data.\n\tboolean get(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, boolean value);\n}", "des": "A JavaBooleanObjectInspector inspects a Java Boolean Object."}
{"index": 2850, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaByteObjectInspector {\n\t// Create an object with the value.\n\tObject create(byte value);\n\t// Get the byte data.\n\tbyte get(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, byte value);\n}", "des": "A JavaByteObjectInspector inspects a Java Byte Object."}
{"index": 2851, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaDateObjectInspector {\n\tObject create(Date value);\n\tDate get(Object o);\n\t// Get the Java Primitive object.\n\tDate getPrimitiveJavaObject(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tDateWritableV2 getPrimitiveWritableObject(Object o);\n\tObject set(Object o, Date value);\n\tObject set(Object o, DateWritableV2 d);\n}", "des": "A JavaDateObjectInspector inspects a Java Date Object."}
{"index": 2852, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaDoubleObjectInspector {\n\t// Create an object with the value.\n\tObject create(double value);\n\t// Get the double data.\n\tdouble get(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, double value);\n}", "des": "A JavaDoubleObjectInspector inspects a Java Double Object."}
{"index": 2853, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaFloatObjectInspector {\n\t// Create an object with the value.\n\tObject create(float value);\n\t// Get the float data.\n\tfloat get(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, float value);\n}", "des": "A JavaFloatObjectInspector inspects a Java Float Object."}
{"index": 2854, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaIntObjectInspector {\n\t// Create an object with the value.\n\tObject create(int value);\n\t// Get the int data.\n\tint get(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, int value);\n}", "des": "A JavaIntObjectInspector inspects a Java Integer Object."}
{"index": 2855, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaLongObjectInspector {\n\t// Create an object with the value.\n\tObject create(long value);\n\t// Get the long data.\n\tlong get(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, long value);\n}", "des": "A JavaLongObjectInspector inspects a Java Long Object."}
{"index": 2856, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class JavaShortObjectInspector {\n\t// Create an object with the value.\n\tObject create(short value);\n\t// Get the short data.\n\tshort get(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tObject getPrimitiveWritableObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, short value);\n}", "des": "A JavaShortObjectInspector inspects a Java Short Object."}
{"index": 2857, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyArray {\n\t// Returns the List of actual primitive objects.\n\tList<Object> getList();\n\t// Returns the actual primitive object at the index position inside the array represented by this LazyObject.\n\tObject getListElementObject(int index);\n\t// Returns -1 for null array.\n\tint getListLength();\n\t// Set the row data for this LazyArray.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n}", "des": "LazyArray stores an array of Lazy Objects. LazyArray does not deal with the case of a NULL array. That is handled by the parent LazyObject."}
{"index": 2858, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryArray {\n\t// Returns the List of actual primitive objects.\n\tList<Object> getList();\n\t// Returns the actual primitive object at the index position inside the array represented by this LazyBinaryObject.\n\tObject getListElementObject(int index);\n\t// Returns the array size.\n\tint getListLength();\n\t// Set the row data for this LazyBinaryArray.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n}", "des": "LazyBinaryArray is serialized as follows: start A b b b b b b end bytes[] -> |--------|---|---|---|---| ... |---|---| Section A is the null-bytes. Suppose the list has N elements, then there are (N+7)/8 bytes used as null-bytes. Each bit corresponds to an element and it indicates whether that element is null (0) or not null (1). After A, all b(s) represent the elements of the list. Each of them is again a LazyBinaryObject."}
{"index": 2859, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryColumnarSerDe {\n\t// Initialize the SerDe.\n\tvoid initialize(org.apache.hadoop.conf.Configuration configuration, Properties tableProperties, Properties partitionProperties);\n\t// Serialize an object by navigating inside the Object with the ObjectInspector.\n\torg.apache.hadoop.io.Writable serialize(Object obj, ObjectInspector objInspector);\n}", "des": "LazyBinaryColumnarSerDe. This serde combines elements of columnar serde and lazybinary serde to produce a serde which serializes columns into a BytesRefArrayWritable in a compact binary format and which is deserialized in a lazy, i.e. on-demand fashion."}
{"index": 2860, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryFactory {\n\tstatic ObjectInspector createColumnarStructInspector(List<String> columnNames, List<TypeInfo> columnTypes);\n\t// Create a hierarchical LazyBinaryObject based on the given typeInfo.\n\tstatic LazyBinaryObject createLazyBinaryObject(ObjectInspector oi);\n\t// Create a lazy binary primitive class given the type name.\n\tstatic LazyBinaryPrimitive<?,?> createLazyBinaryPrimitiveClass(PrimitiveObjectInspector oi);\n}", "des": "LazyBinaryFactory."}
{"index": 2861, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryListObjectInspector {\n\t// returns null for data = null.\n\tList<?> getList(Object data);\n\t// returns null for null list, out-of-the-range index.\n\tObject getListElement(Object data, int index);\n\t// returns -1 for data = null.\n\tint getListLength(Object data);\n}", "des": "ObjectInspector for LazyBinaryList."}
{"index": 2862, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryMapObjectInspector {\n\t// returns null for data = null.\n\tMap<?,?> getMap(Object data);\n\t// returns -1 for NULL map.\n\tint getMapSize(Object data);\n\tObject getMapValueElement(Object data, Object key);\n}", "des": "ObjectInspector for LazyBinaryMap."}
{"index": 2863, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryNonPrimitive<OI extends ObjectInspector> {\n\t// If the LazyObjectBase is a primitive Object, then deserialize it and return the actual primitive Object.\n\tObject getObject();\n\t// Set the data for this LazyObjectBase.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n}", "des": "LazyBinaryNonPrimitive."}
{"index": 2864, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinarySerDe2 {\n\t// Initialize the SerDe with configuration and table information.\n\tvoid initialize(org.apache.hadoop.conf.Configuration configuration, Properties tableProperties, Properties partitionProperties);\n\t// Serialize an object to a byte buffer in a binary compact way.\n\torg.apache.hadoop.io.Writable serialize(Object obj, ObjectInspector objInspector);\n}", "des": "Subclass of LazyBinarySerDe with faster serialization, initializing a serializer based on the row columns rather than checking the ObjectInspector category/primitiveType for every value. This appears to be around 3x faster than the LazyBinarySerDe serialization."}
{"index": 2865, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryStruct {\n\t// Get one field out of the struct.\n\tObject getField(int fieldID);\n\t// Get the values of the fields as an ArrayList.\n\tArrayList<Object> getFieldsAsList();\n\t// If the LazyObjectBase is a primitive Object, then deserialize it and return the actual primitive Object.\n\tObject getObject();\n\t// Returns the serialized size of the object.\n\tlong getRawDataSerializedSize();\n\t// Set the data for this LazyObjectBase.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n}", "des": "LazyBinaryStruct is serialized as follows: start A B A B A B end bytes[] -> |-----|---------|--- ... ---|-----|---------| Section A is one null-byte, corresponding to eight struct fields in Section B. Each bit indicates whether the corresponding field is null (0) or not null (1). Each field is a LazyBinaryObject. Following B, there is another section A and B. This pattern repeats until the all struct fields are serialized."}
{"index": 2866, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryStructObjectInspector {\n\t// returns null for data = null.\n\tObject getStructFieldData(Object data, StructField fieldRef);\n\tStructField getStructFieldRef(int index);\n\t// returns null for data = null.\n\tList<Object> getStructFieldsDataAsList(Object data);\n}", "des": "ObjectInspector for LazyBinaryStruct."}
{"index": 2867, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryUnion {\n\t// Get the set field out of the union.\n\tObject getField();\n\t// If the LazyObjectBase is a primitive Object, then deserialize it and return the actual primitive Object.\n\tObject getObject();\n\t// Returns the serialized size of the object.\n\tlong getRawDataSerializedSize();\n\t// Get the set field's tag\n\tbyte getTag();\n\t// Set the data for this LazyObjectBase.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n}", "des": "LazyBinaryUnion is serialized as follows: start TAG FIELD end bytes[] -> |-----|---------|--- ... ---|-----|---------| Section TAG is one byte, corresponding to tag of set union field FIELD is a LazyBinaryObject corresponding to set union field value."}
{"index": 2868, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBinaryUnionObjectInspector {\n\t// Return the field based on the tag value associated with the Object.\n\tObject getField(Object o);\n\t// Return the tag of the object.\n\tbyte getTag(Object o);\n}", "des": "ObjectInspector for LazyBinaryUnion."}
{"index": 2869, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyBooleanObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the boolean data.\n\tboolean get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\tboolean isExtendedLiteral();\n\tvoid setExtendedLiteral(boolean extendedLiteral);\n}", "des": "A WritableBooleanObjectInspector inspects a BooleanWritable Object."}
{"index": 2870, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyByteObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the byte data.\n\tbyte get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n}", "des": "A WritableByteObjectInspector inspects a ByteWritable Object."}
{"index": 2871, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyDate {\n\t// Initializes LazyDate object by interpreting the input bytes as a SQL date string.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n\t// Writes a Date in SQL date format to the output stream.\n\tstatic void writeUTF8(OutputStream out, DateWritableV2 d);\n}", "des": "LazyDate. Serializes and deserializes a Date in the SQL date format YYYY-MM-DD"}
{"index": 2872, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyDateObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the Java Primitive object.\n\tDate getPrimitiveJavaObject(Object o);\n}", "des": "A WritableDateObjectInspector inspects a DateWritableV2 Object."}
{"index": 2873, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyDoubleObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the double data.\n\tdouble get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n}", "des": "A WritableDoubleObjectInspector inspects a DoubleWritable Object."}
{"index": 2874, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyFloatObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the float data.\n\tfloat get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n}", "des": "A FloatObjectInspector inspects a FloatWritable Object."}
{"index": 2875, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyIntObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the int data.\n\tint get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n}", "des": "A WritableIntObjectInspector inspects a IntWritable Object."}
{"index": 2876, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyLongObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the long data.\n\tlong get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n}", "des": "A WritableLongObjectInspector inspects a LongWritable Object."}
{"index": 2877, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyObject<OI extends ObjectInspector> {\n\tprotected OI getInspector();\n\t// Returns the primitive object represented by this LazyObject.\n\tObject getObject();\n\t// Set the data for this LazyObjectBase.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n\tprotected void setInspector(OI oi);\n\t// called for null binary, hbase columns, for example\n\tvoid setNull();\n}", "des": "LazyObject stores an object in a range of bytes in a byte[]. A LazyObject can represent any primitive object or hierarchical object like array, map or struct."}
{"index": 2878, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyShortObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the short data.\n\tshort get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n}", "des": "A WritableShortObjectInspector inspects a ShortWritable Object."}
{"index": 2879, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyStringObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\tbyte getEscapeChar();\n\t// Get the String representation of the data.\n\tString getPrimitiveJavaObject(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\torg.apache.hadoop.io.Text getPrimitiveWritableObject(Object o);\n\tboolean isEscaped();\n}", "des": "A WritableStringObjectInspector inspects a Text Object."}
{"index": 2880, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyTimestamp {\n\tTimestampWritableV2 getWritableObject();\n\t// Initializes LazyTimestamp object by interpreting the input bytes as a JDBC timestamp string\n\tvoid init(ByteArrayRef bytes, int start, int length);\n\t// Writes a Timestamp in JDBC timestamp format to the output stream\n\tstatic void writeUTF8(OutputStream out, TimestampWritableV2 i);\n}", "des": "LazyTimestamp. Serializes and deserializes a Timestamp in the JDBC timestamp format YYYY-MM-DD HH:MM:SS.[fff...]"}
{"index": 2881, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyUnion {\n\t// Get the field out of the union.\n\tObject getField();\n\t// Get the tag of the union\n\tbyte getTag();\n\t// Set the row data for this LazyUnion.\n\tvoid init(ByteArrayRef bytes, int start, int length);\n}", "des": "LazyObject for storing a union. The field of a union can be primitive or non-primitive."}
{"index": 2882, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class LazyVoidObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n}", "des": "A WritableVoidObjectInspector inspects a NullWritable Object."}
{"index": 2883, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface ListObjectInspector {\n\t// returns null for data = null.\n\tList<?> getList(Object data);\n\t// returns null for null list, out-of-the-range index.\n\tObject getListElement(Object data, int index);\n\tObjectInspector getListElementObjectInspector();\n\t// returns -1 for data = null.\n\tint getListLength(Object data);\n}", "des": "ListObjectInspector."}
{"index": 2884, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class ListTypeInfo {\n\tboolean equals(Object other);\n\t// The Category of this TypeInfo.\n\tObjectInspector.Category getCategory();\n\tTypeInfo getListElementTypeInfo();\n\t// A String representation of the TypeInfo.\n\tString getTypeName();\n\t// For java serialization use only.\n\tvoid setListElementTypeInfo(TypeInfo listElementTypeInfo);\n}", "des": "A List Type has homogeneous elements. All elements of the List has the same TypeInfo which is returned by getListElementTypeInfo. Always use the TypeInfoFactory to create new TypeInfo objects, instead of directly creating an instance of this class."}
{"index": 2885, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface MapObjectInspector {\n\t// returns null for data = null.\n\tMap<?,?> getMap(Object data);\n\tObjectInspector getMapKeyObjectInspector();\n\t// returns -1 for NULL map.\n\tint getMapSize(Object data);\n\tObject getMapValueElement(Object data, Object key);\n\tObjectInspector getMapValueObjectInspector();\n}", "des": "MapObjectInspector."}
{"index": 2886, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class MapTypeInfo {\n\tboolean equals(Object other);\n\t// The Category of this TypeInfo.\n\tObjectInspector.Category getCategory();\n\tTypeInfo getMapKeyTypeInfo();\n\tTypeInfo getMapValueTypeInfo();\n\t// A String representation of the TypeInfo.\n\tString getTypeName();\n\t// For java serialization use only.\n\tvoid setMapKeyTypeInfo(TypeInfo mapKeyTypeInfo);\n\t// For java serialization use only.\n\tvoid setMapValueTypeInfo(TypeInfo mapValueTypeInfo);\n}", "des": "A Map Type has homogeneous keys and homogeneous values. All keys of the Map have the same TypeInfo, which is returned by getMapKeyTypeInfo(); and all values of the Map has the same TypeInfo, which is returned by getMapValueTypeInfo(). Always use the TypeInfoFactory to create new TypeInfo objects, instead of directly creating an instance of this class."}
{"index": 2887, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class MetadataListStructObjectInspector {\n\tstatic MetadataListStructObjectInspector getInstance(List<String> columnNames);\n\tstatic MetadataListStructObjectInspector getInstance(List<String> columnNames, List<String> columnComments);\n\t// returns null for data = null.\n\tObject getStructFieldData(Object data, StructField fieldRef);\n\t// returns null for data = null.\n\tList<Object> getStructFieldsDataAsList(Object data);\n}", "des": "StructObjectInspector works on struct data that is stored as a Java List or Java Array object. Basically, the fields are stored sequentially in the List object. The names of the struct fields and the internal structure of the struct fields are specified in the ctor of the StructObjectInspector."}
{"index": 2888, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface ObjectInspector {\n\t// An ObjectInspector must inherit from one of the following interfaces if getCategory() returns: PRIMITIVE: PrimitiveObjectInspector LIST: ListObjectInspector MAP: MapObjectInspector STRUCT: StructObjectInspector.\n\tObjectInspector.Category getCategory();\n\t// Returns the name of the data type that is inspected by this ObjectInspector.\n\tString getTypeName();\n}", "des": "ObjectInspector helps us to look into the internal structure of a complex object. A (probably configured) ObjectInspector instance stands for a specific type and a specific way to store the data of that type in the memory. For native java Object, we can directly access the internal structure through member fields and methods. ObjectInspector is a way to delegate that functionality away from the Object, so that we have more control on the behavior of those actions. An efficient implementation of ObjectInspector should rely on factory, so that we can make sure the same ObjectInspector only has one instance. That also makes sure hashCode() and equals() methods of java.lang.Object directly works for ObjectInspector as well."}
{"index": 2889, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum ObjectInspector.Category {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ObjectInspector.Category valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ObjectInspector.Category[] values();\n}", "des": "Category."}
{"index": 2890, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum ObjectInspectorFactory.ObjectInspectorOptions {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ObjectInspectorFactory.ObjectInspectorOptions valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ObjectInspectorFactory.ObjectInspectorOptions[] values();\n}", "des": "ObjectInspectorOptions describes what ObjectInspector to use. JAVA is to use pure JAVA reflection. THRIFT is to use JAVA reflection and filter out __isset fields, PROTOCOL_BUFFERS filters out has*. New ObjectInspectorOptions can be added here when available. We choose to use a single HashMap objectInspectorCache to cache all situations for efficiency and code simplicity. And we don't expect a case that a user need to create 2 or more different types of ObjectInspectors for the same Java type."}
{"index": 2891, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum ObjectInspectorUtils.NullValueOption {\n\tint getCmpReturnValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ObjectInspectorUtils.NullValueOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ObjectInspectorUtils.NullValueOption[] values();\n}", "des": "This enum controls how we interpret null value when compare two objects. MINVALUE means treating null value as the minimum value. MAXVALUE means treating null value as the maximum value."}
{"index": 2892, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum ObjectInspectorUtils.ObjectInspectorCopyOption {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ObjectInspectorUtils.ObjectInspectorCopyOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ObjectInspectorUtils.ObjectInspectorCopyOption[] values();\n}", "des": "This enum controls how we copy primitive objects. DEFAULT means choosing the most efficient way between JAVA and WRITABLE. JAVA means converting all primitive objects to java primitive objects. WRITABLE means converting all primitive objects to writable objects."}
{"index": 2893, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum PrimitiveObjectInspector.PrimitiveCategory {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PrimitiveObjectInspector.PrimitiveCategory valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PrimitiveObjectInspector.PrimitiveCategory[] values();\n}", "des": "The primitive types supported by Hive."}
{"index": 2894, "repo": "hive-serde-4.0.0-alpha-2", "code": "Enum PrimitiveObjectInspectorUtils.PrimitiveGrouping {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PrimitiveObjectInspectorUtils.PrimitiveGrouping valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PrimitiveObjectInspectorUtils.PrimitiveGrouping[] values();\n}", "des": "Provide a general grouping for each primitive data type."}
{"index": 2895, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class PrimitiveTypeInfo {\n\tboolean equals(Object obj);\n\t// Returns the category of this TypeInfo.\n\tObjectInspector.Category getCategory();\n\tPrimitiveObjectInspector.PrimitiveCategory getPrimitiveCategory();\n\tClass<?> getPrimitiveJavaClass();\n\tPrimitiveObjectInspectorUtils.PrimitiveTypeEntry getPrimitiveTypeEntry();\n\tClass<?> getPrimitiveWritableClass();\n\t// A String representation of the TypeInfo.\n\tString getTypeName();\n\tvoid setTypeName(String typeName);\n}", "des": "There are limited number of Primitive Types. All Primitive Types are defined by TypeInfoFactory.isPrimitiveClass(). Always use the TypeInfoFactory to create new TypeInfo objects, instead of directly creating an instance of this class."}
{"index": 2896, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class ReflectionStructObjectInspector.MyField {\n\t// Get the comment for the field.\n\tString getFieldComment();\n\t// Get the fieldID for the field.\n\tint getFieldID();\n\t// Get the name of the field.\n\tString getFieldName();\n\t// Get the ObjectInspector for the field.\n\tObjectInspector getFieldObjectInspector();\n}", "des": "MyField."}
{"index": 2897, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SerDe {\n\t// Returns statistics collected when (de)serializing.\n\tSerDeStats getSerDeStats();\n\t// Adds SerDe specific configurations to job conf.\n\tdefault void handleJobLevelConfiguration(HiveConf conf);\n}", "des": "A Hive Serializer/Deserializer."}
{"index": 2898, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface Serializer {\n\t// Returns the Writable class that would be returned by the serialize method.\n\tClass<? extends org.apache.hadoop.io.Writable> getSerializedClass();\n\t// Serialize an object by navigating inside the Object with the ObjectInspector.\n\torg.apache.hadoop.io.Writable serialize(Object obj, ObjectInspector objInspector);\n}", "des": "HiveSerializer is used to serialize data to a Hadoop Writable object. The serialize In addition to the interface below."}
{"index": 2899, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableBooleanObjectInspector {\n\t// Create an object with the value.\n\tObject create(boolean value);\n\t// Set the object with the value.\n\tObject set(Object o, boolean value);\n}", "des": "A SettableBooleanObjectInspector can set a boolean value to an object."}
{"index": 2900, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableByteObjectInspector {\n\t// Create an object with the value.\n\tObject create(byte value);\n\t// Set the object with the value.\n\tObject set(Object o, byte value);\n}", "des": "A SettableByteObjectInspector can set a byte value to an object."}
{"index": 2901, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableDoubleObjectInspector {\n\t// Create an object with the value.\n\tObject create(double value);\n\t// Set the object with the value.\n\tObject set(Object o, double value);\n}", "des": "A SettableDoubleObjectInspector can set a double value to an object."}
{"index": 2902, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableFloatObjectInspector {\n\t// Create an object with the value.\n\tObject create(float value);\n\t// Set the object with the value.\n\tObject set(Object o, float value);\n}", "des": "A SettableFloatObjectInspector can set a float value to an object."}
{"index": 2903, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableIntObjectInspector {\n\t// Create an object with the value.\n\tObject create(int value);\n\t// Set the object with the value.\n\tObject set(Object o, int value);\n}", "des": "A SettableIntObjectInspector can set an int value to an object."}
{"index": 2904, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableListObjectInspector {\n\t// Create a list with the given size.\n\tObject create(int size);\n\t// Resize the list.\n\tObject resize(Object list, int newSize);\n\t// Set the element at index.\n\tObject set(Object list, int index, Object element);\n}", "des": "SettableListObjectInspector."}
{"index": 2905, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableLongObjectInspector {\n\t// Create an object with the value.\n\tObject create(long value);\n\t// Set the object with the value.\n\tObject set(Object o, long value);\n}", "des": "A SettableLongObjectInspector can set a long value to an object."}
{"index": 2906, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableMapObjectInspector {\n\t// Clear the map.\n\tObject clear(Object map);\n\t// Create an empty map.\n\tObject create();\n\t// Add a key-value pair to the map.\n\tObject put(Object map, Object key, Object value);\n\t// Remove a key-value pair from the map.\n\tObject remove(Object map, Object key);\n}", "des": "SettableMapObjectInspector."}
{"index": 2907, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableShortObjectInspector {\n\t// Create an object with the value.\n\tObject create(short value);\n\t// Set the object with the value.\n\tObject set(Object o, short value);\n}", "des": "A SettableShortObjectInspector can set a short value to an object."}
{"index": 2908, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface SettableStringObjectInspector {\n\t// Create an object with the value.\n\tObject create(String value);\n\t// Create an object with the value.\n\tObject create(org.apache.hadoop.io.Text value);\n\t// Set the object with the value.\n\tObject set(Object o, String value);\n\t// Set the object with the value.\n\tObject set(Object o, org.apache.hadoop.io.Text value);\n}", "des": "A SettableStringObjectInspector can set a string value to an object."}
{"index": 2909, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class SettableStructObjectInspector {\n\t// Create a struct which is not null, but all its fields are null.\n\tabstract Object create();\n\tboolean isSettable();\n\t// Modify the value of a field.\n\tabstract Object setStructFieldData(Object struct, StructField field, Object fieldValue);\n}", "des": "SettableStructObjectInspector."}
{"index": 2910, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface StringObjectInspector {\n\t// Get the String representation of the data.\n\tString getPrimitiveJavaObject(Object o);\n\t// Get the Text representation of the data.\n\torg.apache.hadoop.io.Text getPrimitiveWritableObject(Object o);\n}", "des": "A StringObjectInspector inspects an Object representing a String."}
{"index": 2911, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface StructField {\n\t// Get the comment for the field.\n\tString getFieldComment();\n\t// Get the fieldID for the field.\n\tint getFieldID();\n\t// Get the name of the field.\n\tString getFieldName();\n\t// Get the ObjectInspector for the field.\n\tObjectInspector getFieldObjectInspector();\n}", "des": "Classes implementing this interface are considered to represent a field of a struct for this serde package."}
{"index": 2912, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class StructObjectInspector {\n\t// Returns all the fields.\n\tabstract List<? extends StructField> getAllStructFieldRefs();\n\t// returns null for data = null.\n\tabstract Object getStructFieldData(Object data, StructField fieldRef);\n\t// Look up a field.\n\tabstract StructField getStructFieldRef(String fieldName);\n\t// returns null for data = null.\n\tabstract List<Object> getStructFieldsDataAsList(Object data);\n\tboolean isSettable();\n}", "des": "StructObjectInspector."}
{"index": 2913, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class TeradataBinaryDataInputStream {\n\t// Read CHAR(N).\n\tString readChar(int totalLength);\n\t// Read DATE.\n\tDate readDate();\n\t// Read DECIMAL(P, S).\n\tHiveDecimal readDecimal(int scale, int byteNum);\n\t// Read TIMESTAMP(P).\n\tTimestamp readTimestamp(Integer byteNum);\n\t// Read VARBYTE(N).\n\tbyte[] readVarbyte();\n\t// Read VARCHAR(N).\n\tString readVarchar();\n}", "des": "The TeradataBinaryDataInputStream is used to handle the Teradata binary format input for record. Since the TD binary format uses little-endian to handle the SHORT, INT, LONG, DOUBLE and etc. while the Hadoop uses big-endian, We extend SwappedDataInputStream to handle these types and extend to handle the Teradata specific types like VARCHAR, CHAR, TIMESTAMP, DATE..."}
{"index": 2914, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class ThriftByteStreamTypedSerDe {\n\t// Deserialize an object out of a Writable blob.\n\tObject deserialize(org.apache.hadoop.io.Writable field);\n\tprotected ObjectInspectorFactory.ObjectInspectorOptions getObjectInspectorOptions();\n\t// Initialize the SerDe.\n\tvoid initialize(org.apache.hadoop.conf.Configuration configuration, Properties tableProperties, Properties partitionProperties);\n}", "des": "ThriftByteStreamTypedSerDe."}
{"index": 2915, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class TypeInfo {\n\tboolean accept(TypeInfo other);\n\tabstract boolean equals(Object o);\n\t// The Category of this TypeInfo.\n\tabstract ObjectInspector.Category getCategory();\n\t// String representing the qualified type name.\n\tString getQualifiedName();\n\t// A String representation of the TypeInfo.\n\tabstract String getTypeName();\n}", "des": "Stores information about a type. Always use the TypeInfoFactory to create new TypeInfo objects. We support 8 categories of types: 1. Primitive objects (String, Number, etc) 2. List objects (a list of objects of a single type) 3. Map objects (a map from objects of one type to objects of another type) 4. Struct objects (a list of fields with names and their own types) 5. Union objects 6. Decimal objects 7. Char objects 8. Varchar objects"}
{"index": 2916, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface UnionObject {\n\t// Get the Object.\n\tObject getObject();\n\t// Get the tag of the union.\n\tbyte getTag();\n}", "des": "The UnionObject. It has tag followed by the object it is holding."}
{"index": 2917, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface UnionObjectInspector {\n\t// Return the field based on the tag associated with the Object.\n\tObject getField(Object o);\n\t// Returns the array of ObjectInspectors that are for each of the tags.\n\tList<ObjectInspector> getObjectInspectors();\n\t// Return the tag of the object.\n\tbyte getTag(Object o);\n}", "des": "UnionObjectInspector works on union data that is stored as UnionObject. It holds the list of the object inspectors corresponding to each type of the object the Union can hold. UnionObjectInspector."}
{"index": 2918, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class UnionStructObjectInspector.MyField {\n\t// Get the comment for the field.\n\tString getFieldComment();\n\t// Get the fieldID for the field.\n\tint getFieldID();\n\t// Get the name of the field.\n\tString getFieldName();\n\t// Get the ObjectInspector for the field.\n\tObjectInspector getFieldObjectInspector();\n}", "des": "MyField."}
{"index": 2919, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class UnionTypeInfo {\n\tboolean equals(Object other);\n\tList<TypeInfo> getAllUnionObjectTypeInfos();\n\t// The Category of this TypeInfo.\n\tObjectInspector.Category getCategory();\n\t// A String representation of the TypeInfo.\n\tString getTypeName();\n\t// For java serialization use only.\n\tvoid setAllUnionObjectTypeInfos(List<TypeInfo> allUnionObjectTypeInfos);\n}", "des": "UnionTypeInfo represents the TypeInfo of an union. A union holds only one field of the specified fields at any point of time. The fields, a Union can hold, can have the same or different TypeInfo. Always use the TypeInfoFactory to create new TypeInfo objects, instead of directly creating an instance of this class."}
{"index": 2920, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableBooleanObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Create an object with the value.\n\tObject create(boolean value);\n\t// Get the boolean data.\n\tboolean get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, boolean value);\n}", "des": "A WritableBooleanObjectInspector inspects a BooleanWritable Object."}
{"index": 2921, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableByteObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Create an object with the value.\n\tObject create(byte value);\n\t// Get the byte data.\n\tbyte get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, byte value);\n}", "des": "A WritableByteObjectInspector inspects a ByteWritable Object."}
{"index": 2922, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableDateObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\tObject create(Date d);\n\t// Get the Java Primitive object.\n\tDate getPrimitiveJavaObject(Object o);\n\t// Return the data in an instance of primitive writable Object.\n\tDateWritableV2 getPrimitiveWritableObject(Object o);\n\tObject set(Object o, Date d);\n\tObject set(Object o, DateWritableV2 d);\n}", "des": "A WritableDateObjectInspector inspects a DateWritableV2 Object."}
{"index": 2923, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableDoubleObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Create an object with the value.\n\tObject create(double value);\n\t// Get the double data.\n\tdouble get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, double value);\n}", "des": "A WritableDoubleObjectInspector inspects a DoubleWritable Object."}
{"index": 2924, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableFloatObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Create an object with the value.\n\tObject create(float value);\n\t// Get the float data.\n\tfloat get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, float value);\n}", "des": "A FloatObjectInspector inspects a FloatWritable Object."}
{"index": 2925, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableIntObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Create an object with the value.\n\tObject create(int value);\n\t// Get the int data.\n\tint get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, int value);\n}", "des": "A WritableIntObjectInspector inspects a IntWritable Object."}
{"index": 2926, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableLongObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Create an object with the value.\n\tObject create(long value);\n\t// Get the long data.\n\tlong get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, long value);\n}", "des": "A WritableLongObjectInspector inspects a LongWritable Object."}
{"index": 2927, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableShortObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\t// Create an object with the value.\n\tObject create(short value);\n\t// Get the short data.\n\tshort get(Object o);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\t// Set the object with the value.\n\tObject set(Object o, short value);\n}", "des": "A WritableShortObjectInspector inspects a ShortWritable Object."}
{"index": 2928, "repo": "hive-serde-4.0.0-alpha-2", "code": "Class WritableVoidObjectInspector {\n\t// Get a copy of the Object in the same class, so the return value can be stored independently of the parameter.\n\tObject copyObject(Object o);\n\tboolean equals(Object obj);\n\t// Get the Java Primitive object.\n\tObject getPrimitiveJavaObject(Object o);\n\tObject getWritableConstantValue();\n}", "des": "A WritableVoidObjectInspector inspects a NullWritable Object. Note that this is also a constant object inspector."}
{"index": 2929, "repo": "hive-serde-4.0.0-alpha-2", "code": "Interface WriteNullsProtocol {\n\t// Was the last primitive read really a NULL.\n\tboolean lastPrimitiveWasNull();\n\t// Write a null.\n\tvoid writeNull();\n}", "des": "An interface for TProtocols that actually write out nulls - This should be for all those that don't actually use fieldids in the written data like TCTLSeparatedProtocol."}
{"index": 2930, "repo": "kafka-streams-3.5.0", "code": "Enum DeserializationExceptionHandler.DeserializationHandlerResponse {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DeserializationExceptionHandler.DeserializationHandlerResponse valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DeserializationExceptionHandler.DeserializationHandlerResponse[] values();\n}", "des": "Enumeration that describes the response from the exception handler."}
{"index": 2931, "repo": "kafka-streams-3.5.0", "code": "Interface EmitStrategy {\n\t// This strategy indicates that the aggregated result for a window will only be emitted when the window closes instead of when there's an update to the window.\n\tstatic EmitStrategy onWindowClose();\n\t// This strategy indicates that the aggregated result for a window will be emitted every time when there's an update to the window instead of when the window closes.\n\tstatic EmitStrategy onWindowUpdate();\n\t// Returns the strategy type\n\tEmitStrategy.StrategyType type();\n}", "des": "This interface controls the strategy that can be used to control how we emit results in a processor."}
{"index": 2932, "repo": "kafka-streams-3.5.0", "code": "Class FailOnInvalidTimestamp {\n\t// Extracts the embedded metadata timestamp from the given ConsumerRecord.\n\tlong extract(org.apache.kafka.clients.consumer.ConsumerRecord<Object,Object> record, long partitionTime);\n\t// Raises an exception on every call.\n\tlong onInvalidTimestamp(org.apache.kafka.clients.consumer.ConsumerRecord<Object,Object> record, long recordTimestamp, long partitionTime);\n}", "des": "Retrieves embedded metadata timestamps from Kafka messages. If a record has a negative (invalid) timestamp value, this extractor raises an exception."}
{"index": 2933, "repo": "kafka-streams-3.5.0", "code": "Enum FailureReason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FailureReason valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FailureReason[] values();\n}", "des": "This enumeration type captures the various top-level reasons that a particular partition of a store would fail to execute a query. Stores should generally respond with a failure message instead of throwing an exception."}
{"index": 2934, "repo": "kafka-streams-3.5.0", "code": "Interface FixedKeyProcessor<KIn,VIn,VOut> {\n\t// Close this processor and clean up any resources.\n\tdefault void close();\n\t// Initialize this processor with the given context.\n\tdefault void init(FixedKeyProcessorContext<KIn,VOut> context);\n\t// Process the record.\n\tvoid process(FixedKeyRecord<KIn,VIn> record);\n}", "des": "A processor of key-value pair records where keys are immutable."}
{"index": 2935, "repo": "kafka-streams-3.5.0", "code": "Interface FixedKeyProcessorContext<KForward,VForward> {\n\t// Forward a record to all child processors.\n\t<K extends KForward,V extends VForward>void forward(FixedKeyRecord<K,V> record);\n\t// Forward a record to the specified child processor.\n\t<K extends KForward,V extends VForward>void forward(FixedKeyRecord<K,V> record, String childName);\n}", "des": "Processor context interface for FixedKeyRecord."}
{"index": 2936, "repo": "kafka-streams-3.5.0", "code": "Enum KafkaStreams.State {\n\tboolean hasCompletedShutdown();\n\tboolean hasNotStarted();\n\tboolean hasStartedOrFinishedShuttingDown();\n\tboolean isRunningOrRebalancing();\n\tboolean isShuttingDown();\n\tboolean isValidTransition(KafkaStreams.State newState);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic KafkaStreams.State valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic KafkaStreams.State[] values();\n}", "des": "Kafka Streams states are the possible state that a Kafka Streams instance can be in. An instance must only be in one state at a time. The expected state transition with the following defined states is:"}
{"index": 2937, "repo": "kafka-streams-3.5.0", "code": "Class KeyQuery<K,V> {\n\t// The key that was specified for this query.\n\tK getKey();\n\t// The flag whether to skip the cache or not during query evaluation.\n\tboolean isSkipCache();\n\t// Specifies that the cache should be skipped during query evaluation.\n\tKeyQuery<K,V> skipCache();\n\t// Creates a query that will retrieve the record identified by key if it exists (or null otherwise).\n\tstatic <K,V> KeyQuery<K,V> withKey(K key);\n}", "des": "Interactive query for retrieving a single record based on its key."}
{"index": 2938, "repo": "kafka-streams-3.5.0", "code": "Class KeyQueryMetadata {\n\t// Get the active Kafka Streams instance for given key.\n\tHostInfo activeHost();\n\tboolean equals(Object obj);\n\t// Get the store partition corresponding to the key.\n\tint partition();\n\t// Get the Kafka Streams instances that host the key as standbys.\n\tSet<HostInfo> standbyHosts();\n}", "des": "Represents all the metadata related to a key, where a particular key resides in a KafkaStreams application. It contains the active HostInfo and a set of standby HostInfos, denoting the instances where the key resides. It also contains the partition number where the key belongs, which could be useful when used in conjunction with other APIs. e.g: Relating with lags for that store partition. NOTE: This is a point in time view. It may change as rebalances happen."}
{"index": 2939, "repo": "kafka-streams-3.5.0", "code": "Interface KeyValueStore<K,V> {\n\t// Delete the value from the store (if there is one).\n\tV delete(K key);\n\t// Update the value associated with this key.\n\tvoid put(K key, V value);\n\t// Update all the given key/value pairs.\n\tvoid putAll(List<KeyValue<K,V>> entries);\n\t// Update the value associated with this key, unless a value is already associated with the key.\n\tV putIfAbsent(K key, V value);\n}", "des": "A key-value store that supports put/get/delete and range queries."}
{"index": 2940, "repo": "kafka-streams-3.5.0", "code": "Class LagInfo {\n\t// Get the current maximum offset on the store partition's changelog topic, that has been successfully written into the store partition's state store.\n\tlong currentOffsetPosition();\n\t// Get the end offset position for this store partition's changelog topic on the Kafka brokers.\n\tlong endOffsetPosition();\n\tboolean equals(Object obj);\n\t// Get the measured lag between current and end offset positions, for this store partition replica\n\tlong offsetLag();\n}", "des": "Encapsulates information about lag, at a store partition replica (active or standby). This information is constantly changing as the tasks process records and thus, they should be treated as simply instantaenous measure of lag."}
{"index": 2941, "repo": "kafka-streams-3.5.0", "code": "Class PositionBound {\n\t// Creates a new PositionBound representing a specific position.\n\tstatic PositionBound at(Position position);\n\tboolean equals(Object o);\n\t// Returns true iff this object specifies that there is no position bound.\n\tboolean isUnbounded();\n\t// Returns the specific position of this bound.\n\tPosition position();\n\t// Creates a new PositionBound representing \"no bound\"\n\tstatic PositionBound unbounded();\n}", "des": "A class bounding the processing state Position during queries. This can be used to specify that a query should fail if the locally available partition isn't caught up to the specified bound. \"Unbounded\" places no restrictions on the current location of the partition."}
{"index": 2942, "repo": "kafka-streams-3.5.0", "code": "Interface Processor<KIn,VIn,KOut,VOut> {\n\t// Close this processor and clean up any resources.\n\tdefault void close();\n\t// Initialize this processor with the given context.\n\tdefault void init(ProcessorContext<KOut,VOut> context);\n\t// Process the record.\n\tvoid process(Record<KIn,VIn> record);\n}", "des": "A processor of key-value pair records."}
{"index": 2943, "repo": "kafka-streams-3.5.0", "code": "Interface ProcessorContext<KForward,VForward> {\n\t// Forward a record to all child processors.\n\t<K extends KForward,V extends VForward>void forward(Record<K,V> record);\n\t// Forward a record to the specified child processor.\n\t<K extends KForward,V extends VForward>void forward(Record<K,V> record, String childName);\n}", "des": "Processor context interface for Record."}
{"index": 2944, "repo": "kafka-streams-3.5.0", "code": "Enum PunctuationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PunctuationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PunctuationType[] values();\n}", "des": "Controls what notion of time is used for punctuation scheduled via ProcessorContext.schedule(Duration, PunctuationType, Punctuator) schedule}: STREAM_TIME - uses \"stream time\", which is advanced by the processing of messages in accordance with the timestamp as extracted by the TimestampExtractor in use. NOTE: Only advanced if messages arrive WALL_CLOCK_TIME - uses system time (the wall-clock time), which is advanced at the polling interval (StreamsConfig.POLL_MS_CONFIG) independent of whether new messages arrive. NOTE: This is best effort only as its granularity is limited by how long an iteration of the processing loop takes to complete"}
{"index": 2945, "repo": "kafka-streams-3.5.0", "code": "Interface QueryableStoreType<T> {\n\t// Called when searching for StateStores to see if they match the type expected by implementors of this interface.\n\tboolean accepts(StateStore stateStore);\n\t// Create an instance of T (usually a facade) that developers can use to query the underlying StateStores.\n\tT create(org.apache.kafka.streams.state.internals.StateStoreProvider storeProvider, String storeName);\n}", "des": "Used to enable querying of custom StateStore types via the KafkaStreams API."}
{"index": 2946, "repo": "kafka-streams-3.5.0", "code": "Interface RocksDBConfigSetter {\n\t// Close any user-constructed objects that inherit from org.rocksdb.RocksObject.\n\tvoid close(String storeName, org.rocksdb.Options options);\n\t// Set the rocks db options for the provided storeName.\n\tvoid setConfig(String storeName, org.rocksdb.Options options, Map<String,Object> configs);\n}", "des": "An interface to that allows developers to customize the RocksDB settings for a given Store. Please read the RocksDB Tuning Guide. Note: if you choose to modify the org.rocksdb.BlockBasedTableConfig you should retrieve a reference to the existing one (rather than create a new BlockBasedTableConfig object) so as to not lose the other default settings. This can be done as BlockBasedTableConfig tableConfig = (BlockBasedTableConfig) options.tableFormatConfig();"}
{"index": 2947, "repo": "kafka-streams-3.5.0", "code": "Interface SessionBytesStoreSupplier {\n\t// The time period for which the SessionStore will retain historic data.\n\tlong retentionPeriod();\n\t// The size of a segment, in milliseconds.\n\tlong segmentIntervalMs();\n}", "des": "A store supplier that can be used to create one or more SessionStore instances. For any stores implementing the SessionStore interface, null value bytes are considered as \"not exist\". This means: null value bytes in put operations should be treated as delete. null value bytes should never be returned in range query results."}
{"index": 2948, "repo": "kafka-streams-3.5.0", "code": "Class SessionWindows {\n\tboolean equals(Object o);\n\tlong gracePeriodMs();\n\t// Return the specified gap for the session windows in milliseconds.\n\tlong inactivityGap();\n\t// Creates a new window specification with the specified inactivity gap.\n\tstatic SessionWindows ofInactivityGapAndGrace(Duration inactivityGap, Duration afterWindowEnd);\n\t// Creates a new window specification with the specified inactivity gap.\n\tstatic SessionWindows ofInactivityGapWithNoGrace(Duration inactivityGap);\n}", "des": "A session based window specification used for aggregating events into sessions."}
{"index": 2949, "repo": "kafka-streams-3.5.0", "code": "Interface StoreSupplier<T extends StateStore> {\n\t// Return a new StateStore instance.\n\tT get();\n\t// Return a String that is used as the scope for metrics recorded by Metered stores.\n\tString metricsScope();\n\t// Return the name of this state store supplier.\n\tString name();\n}", "des": "A state store supplier which can create one or more StateStore instances."}
{"index": 2950, "repo": "kafka-streams-3.5.0", "code": "Enum StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse[] values();\n}", "des": "Enumeration that describes the response from the exception handler."}
{"index": 2951, "repo": "kafka-streams-3.5.0", "code": "Class To {\n\t// Forward the key/value pair to all downstream processors\n\tstatic To all();\n\t// Forward the key/value pair to one of the downstream processors designated by the downstream processor name.\n\tstatic To child(String childName);\n\tboolean equals(Object o);\n\t// Set the timestamp of the output record.\n\tTo withTimestamp(long timestamp);\n}", "des": "This class is used to provide the optional parameters when sending output records to downstream processor using ProcessorContext.forward(Object, Object, To)."}
{"index": 2952, "repo": "kafka-streams-3.5.0", "code": "Enum Topology.AutoOffsetReset {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Topology.AutoOffsetReset valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Topology.AutoOffsetReset[] values();\n}", "des": "Sets the auto.offset.reset configuration when adding a source processor or when creating KStream or KTable via StreamsBuilder."}
{"index": 2953, "repo": "kafka-streams-3.5.0", "code": "Interface TopologyDescription {\n\t// All global stores of the represented topology.\n\tSet<TopologyDescription.GlobalStore> globalStores();\n\t// All sub-topologies of the represented topology.\n\tSet<TopologyDescription.Subtopology> subtopologies();\n}", "des": "A meta representation of a topology."}
{"index": 2954, "repo": "kafka-streams-3.5.0", "code": "Interface TopologyDescription.GlobalStore {\n\tint id();\n\t// The processor node maintaining the global store.\n\tTopologyDescription.Processor processor();\n\t// The source node reading from a \"global\" topic.\n\tTopologyDescription.Source source();\n}", "des": "Represents a global store. Adding a global store results in adding a source node and one stateful processor node. Note, that all added global stores form a single unit (similar to a TopologyDescription.Subtopology) even if different global stores are not connected to each other. Furthermore, global stores are available to all processors without connecting them explicitly, and thus global stores will never be part of any TopologyDescription.Subtopology."}
{"index": 2955, "repo": "kafka-streams-3.5.0", "code": "Interface TopologyDescription.Node {\n\t// The name of the node.\n\tString name();\n\t// The predecessors of this node within a sub-topology.\n\tSet<TopologyDescription.Node> predecessors();\n\t// The successor of this node within a sub-topology.\n\tSet<TopologyDescription.Node> successors();\n}", "des": "A node of a topology. Can be a source, sink, or processor node."}
{"index": 2956, "repo": "kafka-streams-3.5.0", "code": "Interface TopologyDescription.Sink {\n\t// The topic name this sink node is writing to.\n\tString topic();\n\t// The TopicNameExtractor class that this sink node uses to dynamically extract the topic name to write to.\n\tTopicNameExtractor topicNameExtractor();\n}", "des": "A sink node of a topology."}
{"index": 2957, "repo": "kafka-streams-3.5.0", "code": "Interface TopologyDescription.Source {\n\t// The pattern used to match topic names that is reading from.\n\tPattern topicPattern();\n\t// The topic names this source node is reading from.\n\tSet<String> topicSet();\n}", "des": "A source node of a topology."}
{"index": 2958, "repo": "kafka-streams-3.5.0", "code": "Interface TopologyDescription.Subtopology {\n\t// Internally assigned unique ID.\n\tint id();\n\t// All nodes of this sub-topology.\n\tSet<TopologyDescription.Node> nodes();\n}", "des": "A connected sub-graph of a Topology."}
{"index": 2959, "repo": "kafka-streams-3.5.0", "code": "Interface Transformer<K,V,R> {\n\t// Close this transformer and clean up any resources.\n\tvoid close();\n\t// Initialize this transformer.\n\tvoid init(ProcessorContext context);\n\t// Transform the record with the given key and value.\n\tR transform(K key, V value);\n}", "des": "The Transformer interface is for stateful mapping of an input record to zero, one, or multiple new output records (both key and value type can be altered arbitrarily). This is a stateful record-by-record operation, i.e, transform(Object, Object) is invoked individually for each record of a stream and can access and modify a state that is available beyond a single call of transform(Object, Object) (cf. KeyValueMapper for stateless record transformation). Additionally, this Transformer can schedule a method to be called periodically with the provided context."}
{"index": 2960, "repo": "kafka-streams-3.5.0", "code": "Class UsePartitionTimeOnInvalidTimestamp {\n\t// Extracts the embedded metadata timestamp from the given ConsumerRecord.\n\tlong extract(org.apache.kafka.clients.consumer.ConsumerRecord<Object,Object> record, long partitionTime);\n\t// Returns the current stream-time as new timestamp for the record.\n\tlong onInvalidTimestamp(org.apache.kafka.clients.consumer.ConsumerRecord<Object,Object> record, long recordTimestamp, long partitionTime);\n}", "des": "Retrieves embedded metadata timestamps from Kafka messages. If a record has a negative (invalid) timestamp, a new timestamp will be inferred from the current stream-time."}
{"index": 2961, "repo": "kafka-streams-3.5.0", "code": "Interface ValueTransformer<V,VR> {\n\t// Close this transformer and clean up any resources.\n\tvoid close();\n\t// Initialize this transformer.\n\tvoid init(ProcessorContext context);\n\t// Transform the given value to a new value.\n\tVR transform(V value);\n}", "des": "The ValueTransformer interface for stateful mapping of a value to a new value (with possible new type). This is a stateful record-by-record operation, i.e, transform(Object) is invoked individually for each record of a stream and can access and modify a state that is available beyond a single call of transform(Object) (cf. ValueMapper for stateless value transformation). Additionally, this ValueTransformer can schedule a method to be called periodically with the provided context. If ValueTransformer is applied to a KeyValue pair record the record's key is preserved."}
{"index": 2962, "repo": "kafka-streams-3.5.0", "code": "Interface ValueTransformerWithKey<K,V,VR> {\n\t// Close this processor and clean up any resources.\n\tvoid close();\n\t// Initialize this transformer.\n\tvoid init(ProcessorContext context);\n\t// Transform the given [key and] value to a new value.\n\tVR transform(K readOnlyKey, V value);\n}", "des": "The ValueTransformerWithKey interface for stateful mapping of a value to a new value (with possible new type). This is a stateful record-by-record operation, i.e, transform(Object, Object) is invoked individually for each record of a stream and can access and modify a state that is available beyond a single call of transform(Object, Object) (cf. ValueMapper for stateless value transformation). Additionally, this ValueTransformerWithKey can schedule a method to be called periodically with the provided context. Note that the key is read-only and should not be modified, as this can lead to corrupt partitioning. If ValueTransformerWithKey is applied to a KeyValue pair record the record's key is preserved."}
{"index": 2963, "repo": "kafka-streams-3.5.0", "code": "Interface VersionedBytesStore {\n\t// The analog of VersionedKeyValueStore.delete(Object, long).\n\tbyte[] delete(org.apache.kafka.common.utils.Bytes key, long timestamp);\n\t// The analog of VersionedKeyValueStore.get(Object, long).\n\tbyte[] get(org.apache.kafka.common.utils.Bytes key, long asOfTimestamp);\n\t// The analog of VersionedKeyValueStore.put(Object, Object, long).\n\tlong put(org.apache.kafka.common.utils.Bytes key, byte[] value, long timestamp);\n}", "des": "A representation of a versioned key-value store as a KeyValueStore of type . See VersionedBytesStoreSupplier for more."}
{"index": 2964, "repo": "kafka-streams-3.5.0", "code": "Class Window {\n\t// Return the end timestamp of this window.\n\tlong end();\n\t// Return the end time of this window.\n\tInstant endTime();\n\tboolean equals(Object obj);\n\t// Check if the given window overlaps with this window.\n\tabstract boolean overlap(Window other);\n\t// Return the start timestamp of this window.\n\tlong start();\n\t// Return the start time of this window.\n\tInstant startTime();\n}", "des": "A single window instance, defined by its start and end timestamp. Window is agnostic if start/end boundaries are inclusive or exclusive; this is defined by concrete window implementations."}
{"index": 2965, "repo": "kafka-streams-3.5.0", "code": "Interface WindowBytesStoreSupplier {\n\t// Whether or not this store is retaining duplicate keys.\n\tboolean retainDuplicates();\n\t// The time period for which the WindowStore will retain historic data.\n\tlong retentionPeriod();\n\t// The size of the segments (in milliseconds) the store has.\n\tlong segmentIntervalMs();\n\t// The size of the windows (in milliseconds) any store created from this supplier is creating.\n\tlong windowSize();\n}", "des": "A store supplier that can be used to create one or more WindowStore instances of type . For any stores implementing the WindowStore interface, null value bytes are considered as \"not exist\". This means: 1. Null value bytes in put operations should be treated as delete. 2. Null value bytes should never be returned in range query results."}
{"index": 2966, "repo": "kafka-streams-3.5.0", "code": "Class Windowed<K> {\n\tboolean equals(Object obj);\n\t// Return the key of the window.\n\tK key();\n\t// Return the window containing the values associated with this key.\n\tWindow window();\n}", "des": "The result key type of a windowed stream aggregation."}
{"index": 2967, "repo": "kafka-streams-3.5.0", "code": "Class Windows<W extends Window> {\n\t// Return the window grace period (the time to admit out-of-order events after the end of the window.) Delay is defined as (stream_time - record_timestamp).\n\tabstract long gracePeriodMs();\n\t// Return the size of the specified windows in milliseconds.\n\tabstract long size();\n\t// Create all windows that contain the provided timestamp, indexed by non-negative window start timestamps.\n\tabstract Map<Long,W> windowsFor(long timestamp);\n}", "des": "The window specification for fixed size windows that is used to define window boundaries and grace period."}
{"index": 2968, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface Abortable {\n\t// It just call another abort method and the Throwable parameter is null.\n\tdefault void abort(String why);\n\t// Abort the server or client.\n\tvoid abort(String why, Throwable e);\n\t// Check if the server or client was aborted.\n\tboolean isAborted();\n}", "des": "Interface to support the aborting of a given server or client."}
{"index": 2969, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class AbstractClientScanner {\n\t// Used internally accumulating metrics on scan.\n\tScanMetrics getScanMetrics();\n\t// Check and initialize if application wants to collect scan metrics\n\tprotected void initScanMetrics(Scan scan);\n}", "des": "Helper class for custom client scanners."}
{"index": 2970, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class AbstractHBaseSaslRpcClient {\n\t// Release resources used by wrapped saslClient\n\tvoid dispose();\n\tbyte[] evaluateChallenge(byte[] challenge);\n\t// Computes the initial response a client sends to a server to begin the SASL challenge/response handshake.\n\tbyte[] getInitialResponse();\n\tboolean isComplete();\n}", "des": "A utility class that encapsulates SASL logic for RPC client. Copied from org.apache.hadoop.security"}
{"index": 2971, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface AdvancedScanResultConsumer {\n\t// Indicate that there is a heartbeat message but we have not cumulated enough cells to call onNext(Result[], ScanController).\n\tdefault void onHeartbeat(AdvancedScanResultConsumer.ScanController controller);\n\t// Indicate that we have receive some data.\n\tvoid onNext(Result[] results, AdvancedScanResultConsumer.ScanController controller);\n}", "des": "This is the low level API for asynchronous scan."}
{"index": 2972, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface AdvancedScanResultConsumer.ScanController {\n\t// Get the scan cursor if available.\n\tOptional<Cursor> cursor();\n\t// Suspend the scan.\n\tAdvancedScanResultConsumer.ScanResumer suspend();\n\t// Terminate the scan.\n\tvoid terminate();\n}", "des": "Used to suspend or stop a scan, or get a scan cursor if available."}
{"index": 2973, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum AuthMethod {\n\t// Return the SASL mechanism name\n\tString getMechanismName();\n\t// Read from in\n\tstatic AuthMethod read(DataInput in);\n\t// Return the object represented by the code.\n\tstatic AuthMethod valueOf(byte code);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AuthMethod valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AuthMethod[] values();\n\t// Write to out\n\tvoid write(DataOutput out);\n}", "des": "Authentication method"}
{"index": 2974, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BalanceRequest {\n\t// Get a BalanceRequest for a default run of the balancer.\n\tstatic BalanceRequest defaultInstance();\n\t// Returns true if the balancer should run in dry run mode, otherwise false.\n\tboolean isDryRun();\n\t// Returns true if the balancer should execute even if regions are in transition, otherwise false.\n\tboolean isIgnoreRegionsInTransition();\n\t// Create a builder to construct a custom BalanceRequest.\n\tstatic BalanceRequest.Builder newBuilder();\n}", "des": "Encapsulates options for executing a run of the Balancer."}
{"index": 2975, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BalanceRequest.Builder {\n\t// Build the BalanceRequest\n\tBalanceRequest build();\n\t// Updates BalancerRequest to run the balancer in dryRun mode.\n\tBalanceRequest.Builder setDryRun(boolean dryRun);\n\t// Updates BalancerRequest to run the balancer even if there are regions in transition.\n\tBalanceRequest.Builder setIgnoreRegionsInTransition(boolean ignoreRegionsInTransition);\n}", "des": "Builder for constructing a BalanceRequest"}
{"index": 2976, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BalanceResponse {\n\t// The number of moves calculated by the balancer if isBalancerRan() is true.\n\tint getMovesCalculated();\n\t// The number of moves actually executed by the balancer if it ran.\n\tint getMovesExecuted();\n\t// Returns true if the balancer ran, otherwise false.\n\tboolean isBalancerRan();\n\t// Creates a new BalanceResponse.Builder\n\tstatic BalanceResponse.Builder newBuilder();\n}", "des": "Response returned from a balancer invocation"}
{"index": 2977, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BalanceResponse.Builder {\n\t// Build the BalanceResponse\n\tBalanceResponse build();\n\t// Set true if the balancer ran, otherwise false.\n\tBalanceResponse.Builder setBalancerRan(boolean balancerRan);\n\t// Set how many moves were calculated by the balancer.\n\tBalanceResponse.Builder setMovesCalculated(int movesCalculated);\n\t// Set how many of the calculated moves were actually executed by the balancer.\n\tBalanceResponse.Builder setMovesExecuted(int movesExecuted);\n}", "des": "Used in HMaster to build a BalanceResponse for returning results of a balance invocation to callers"}
{"index": 2978, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BatchScanResultCache {\n\t// Add the given results to cache and get valid results back.\n\tResult[] addAndGet(Result[] results, boolean isHeartbeatMessage);\n\t// Clear the cached result if any.\n\tvoid clear();\n\t// Return the number of complete rows.\n\tint numberOfCompleteRows();\n}", "des": "A scan result cache for batched scan, i.e, scan.getBatch() > 0 && !scan.getAllowPartialResults()."}
{"index": 2979, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BigDecimalComparator {\n\tint compareTo(byte[] value, int offset, int length);\n\tint compareTo(ByteBuffer value, int offset, int length);\n\tboolean equals(Object obj);\n\t// Parse a serialized representation of BigDecimalComparator\n\tstatic BigDecimalComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "A BigDecimal comparator which numerical compares against the specified byte array"}
{"index": 2980, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BinaryComparator {\n\tint compareTo(byte[] value, int offset, int length);\n\tint compareTo(ByteBuffer value, int offset, int length);\n\t// Parse a serialized representation of BinaryComparator\n\tstatic BinaryComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "A binary comparator which lexicographically compares against the specified byte array using Bytes.compareTo(byte[], byte[])."}
{"index": 2981, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BinaryComponentComparator {\n\tint compareTo(byte[] value);\n\tint compareTo(byte[] value, int offset, int length);\n\tboolean equals(Object other);\n\t// Parse a serialized representation of BinaryComponentComparator\n\tstatic BinaryComponentComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "A comparator which compares against a specified byte array, but only compares specific portion of the byte array. For the rest it is similar to BinaryComparator."}
{"index": 2982, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BinaryPrefixComparator {\n\tint compareTo(byte[] value, int offset, int length);\n\tint compareTo(ByteBuffer value, int offset, int length);\n\t// Parse a serialized representation of BinaryPrefixComparator\n\tstatic BinaryPrefixComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "A comparator which compares against a specified byte array, but only compares up to the length of this byte array. For the rest it is similar to BinaryComparator."}
{"index": 2983, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BitComparator {\n\tint compareTo(byte[] value, int offset, int length);\n\tint compareTo(ByteBuffer value, int offset, int length);\n\t// Returns the bitwise operator\n\tBitComparator.BitwiseOp getOperator();\n\t// Parse a serialized representation of BitComparator\n\tstatic BitComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "A bit comparator which performs the specified bitwise operation on each of the bytes with the specified byte array. Then returns whether the result is non-zero."}
{"index": 2984, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum BitComparator.BitwiseOp {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BitComparator.BitwiseOp valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BitComparator.BitwiseOp[] values();\n}", "des": "Bit operators."}
{"index": 2985, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class BlockingRpcCallback<R> {\n\t// Returns the parameter passed to run(Object) or null if a null value was passed.\n\tR get();\n\t// Called on completion of the RPC call with the response object, or null in the case of an error.\n\tvoid run(R parameter);\n}", "des": "Simple RpcCallback implementation providing a Future-like get() method, which will block util the instance's run(Object) method has been called. R is the RPC response type that will be passed to the run(Object) method."}
{"index": 2986, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum CatalogReplicaMode {\n\tstatic CatalogReplicaMode fromString(String value);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CatalogReplicaMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CatalogReplicaMode[] values();\n}", "des": ""}
{"index": 2987, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class CellVisibility {\n\t// Returns The visibility expression\n\tString getExpression();\n\t// Helps in quoting authentication Strings.\n\tstatic String quote(byte[] auth);\n\t// Helps in quoting authentication Strings.\n\tstatic String quote(String auth);\n}", "des": "This contains a visibility expression which can be associated with a cell. When it is set with a Mutation, all the cells in that mutation will get associated with this expression. A visibility expression can contain visibility labels combined with logical operators AND(&), OR(|) and NOT(!)"}
{"index": 2988, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class CheckAndMutateResult {\n\t// Returns It is used only for CheckAndMutate operations with Increment/Append.\n\tResult getResult();\n\t// Returns Whether the CheckAndMutate operation is successful or not\n\tboolean isSuccess();\n}", "des": "Represents a result of a CheckAndMutate operation"}
{"index": 2989, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class ClientSnapshotDescriptionUtils {\n\t// Check to make sure that the description of the snapshot requested is valid\n\tstatic void assertSnapshotRequestIsValid(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot);\n\t// Returns a single line (no \\n) representation of snapshot metadata.\n\tstatic String toString(org.apache.hadoop.hbase.shaded.protobuf.generated.SnapshotProtos.SnapshotDescription snapshot);\n}", "des": "Class to help with dealing with a snapshot description on the client side. There is a corresponding class on the server side."}
{"index": 2990, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class ClientTokenUtil {\n\t// Obtain an authentication token for the given user and add it to the user's credentials.\n\tstatic void obtainAndCacheToken(Connection conn, User user);\n\t// Obtain and return an authentication token for the current user.\n\tstatic CompletableFuture<org.apache.hadoop.security.token.Token<AuthenticationTokenIdentifier>> obtainToken(AsyncConnection conn);\n}", "des": "Utility methods for obtaining authentication tokens, that do not require hbase-server."}
{"index": 2991, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class ClusterId {\n\t// Returns A pb instance to represent this instance.\n\torg.apache.hadoop.hbase.shaded.protobuf.generated.ClusterIdProtos.ClusterId convert();\n\t// Returns A ClusterId made from the passed in cid\n\tstatic ClusterId convert(org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterIdProtos.ClusterId cid);\n\t// Parse the serialized representation of the ClusterId\n\tstatic ClusterId parseFrom(byte[] bytes);\n\t// Returns The clusterid serialized using pb w/ pb magic prefix\n\tbyte[] toByteArray();\n}", "des": "The identifier for this cluster. It is serialized to the filesystem and up into zookeeper. This is a container for the id. Also knows how to serialize and deserialize the cluster id."}
{"index": 2992, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum ClusterMetrics.Option {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClusterMetrics.Option valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClusterMetrics.Option[] values();\n}", "des": "Kinds of ClusterMetrics"}
{"index": 2993, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum CompactionState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompactionState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompactionState[] values();\n}", "des": "POJO representing the compaction state"}
{"index": 2994, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum CompactType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompactType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompactType[] values();\n}", "des": "Currently, there are only two compact types: NORMAL means do store files compaction; MOB means do mob files compaction."}
{"index": 2995, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum CompareOperator {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompareOperator valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompareOperator[] values();\n}", "des": "Generic set of comparison operators."}
{"index": 2996, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface ConnectionRegistry {\n\t// Closes this instance and releases any system resources associated with it\n\tvoid close();\n\t// Get the address of active HMaster.\n\tCompletableFuture<ServerName> getActiveMaster();\n\t// Should only be called once.\n\tCompletableFuture<String> getClusterId();\n\t// Return the connection string associated with this registry instance.\n\tString getConnectionString();\n\t// Get the location of meta region(s).\n\tCompletableFuture<RegionLocations> getMetaRegionLocations();\n}", "des": "Registry for meta information needed for connection setup to a HBase cluster. Implementations hold cluster information such as this cluster's id, location of hbase:meta, etc.. Internal use only."}
{"index": 2997, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class ConnectionUtils {\n\tstatic org.apache.hadoop.hbase.client.ScanResultCache createScanResultCache(Scan scan);\n\t// Calculate pause time.\n\tstatic long getPauseTime(long pause, int tries);\n\t// Changes the configuration to set the number of retries needed when using Connection internally, e.g.\n\tstatic void setServerSideHConnectionRetriesConfig(org.apache.hadoop.conf.Configuration c, String sn, org.slf4j.Logger log);\n}", "des": "Utility used by client connections."}
{"index": 2998, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum Consistency {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Consistency valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Consistency[] values();\n}", "des": "Consistency defines the expected consistency level for an operation."}
{"index": 2999, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface Coprocessor {\n\t// Coprocessor endpoints providing protobuf services should override this method.\n\tdefault Iterable<org.apache.hbase.thirdparty.com.google.protobuf.Service> getServices();\n\t// Called by the CoprocessorEnvironment during it's own startup to initialize the coprocessor.\n\tdefault void start(CoprocessorEnvironment env);\n\t// Called by the CoprocessorEnvironment during it's own shutdown to stop the coprocessor.\n\tdefault void stop(CoprocessorEnvironment env);\n}", "des": "Base interface for the 4 coprocessors - MasterCoprocessor, RegionCoprocessor, RegionServerCoprocessor, and WALCoprocessor. Do NOT implement this interface directly. Unless an implementation implements one (or more) of the above mentioned 4 coprocessors, it'll fail to be loaded by any coprocessor host. Example: Building a coprocessor to observe Master operations."}
{"index": 3000, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum Coprocessor.State {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Coprocessor.State valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Coprocessor.State[] values();\n}", "des": "Lifecycle state of a given coprocessor instance."}
{"index": 3001, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface CoprocessorDescriptor {\n\t// Returns the name of the class or interface represented by this object.\n\tString getClassName();\n\t// Returns Path of the jar file.\n\tOptional<String> getJarPath();\n\t// Returns The order to execute this coprocessor\n\tint getPriority();\n\t// Returns Arbitrary key-value parameter pairs passed into the coprocessor.\n\tMap<String,String> getProperties();\n}", "des": "CoprocessorDescriptor contains the details about how to build a coprocessor. This class is a pojo so there are no checks for the details carried by this class. Use CoprocessorDescriptorBuilder to instantiate a CoprocessorDescriptor"}
{"index": 3002, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class CoprocessorRpcUtils.BlockingRpcCallback<R> {\n\t// Returns the parameter passed to run(Object) or null if a null value was passed.\n\tR get();\n\t// Called on completion of the RPC call with the response object, or null in the case of an error.\n\tvoid run(R parameter);\n}", "des": "Simple RpcCallback implementation providing a Future-like BlockingRpcCallback.get() method, which will block util the instance's BlockingRpcCallback.run(Object) method has been called. R is the RPC response type that will be passed to the run(Object) method."}
{"index": 3003, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum Durability {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Durability valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Durability[] values();\n}", "des": "Enum describing the durability guarantees for tables and Mutations Note that the items must be sorted in order of increasing durability"}
{"index": 3004, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class FailedServers {\n\t// Add an address to the list of the failed servers list.\n\tvoid addToFailedServers(Address address, Throwable throwable);\n\t// Check if the server should be considered as bad.\n\tboolean isFailedServer(Address address);\n}", "des": "A class to manage a list of servers that failed recently."}
{"index": 3005, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class FamilyFilter {\n\tstatic Filter createFilterFromArguments(ArrayList<byte[]> filterArguments);\n\tboolean equals(Object obj);\n\t// A way to filter based on the column family, column qualifier and/or the column value.\n\tFilter.ReturnCode filterCell(Cell c);\n\t// Parse the serialized representation of FamilyFilter\n\tstatic FamilyFilter parseFrom(byte[] pbBytes);\n\t// Returns The filter serialized using pb\n\tbyte[] toByteArray();\n}", "des": ""}
{"index": 3006, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum Filter.ReturnCode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Filter.ReturnCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Filter.ReturnCode[] values();\n}", "des": "Return codes for filterValue()."}
{"index": 3007, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum FilterList.Operator {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FilterList.Operator valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FilterList.Operator[] values();\n}", "des": "set operator"}
{"index": 3008, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class GetUserPermissionsRequest {\n\tbyte[] getFamily();\n\tString getNamespace();\n\tbyte[] getQualifier();\n\tTableName getTableName();\n\tString getUserName();\n\t// Build a get global permission request\n\tstatic GetUserPermissionsRequest.Builder newBuilder();\n\t// Build a get namespace permission request\n\tstatic GetUserPermissionsRequest.Builder newBuilder(String namespace);\n\t// Build a get table permission request\n\tstatic GetUserPermissionsRequest.Builder newBuilder(TableName tableName);\n}", "des": "Used by Admin.getUserPermissions(GetUserPermissionsRequest). Represents the params of user permissions needed to get from HBase."}
{"index": 3009, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class HBaseSaslRpcClient {\n\t// Get a SASL wrapped InputStream.\n\tInputStream getInputStream();\n\t// Get a SASL wrapped OutputStream.\n\tOutputStream getOutputStream();\n\tString getSaslQOP();\n\tvoid initCryptoCipher(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.CryptoCipherMeta cryptoCipherMeta, org.apache.hadoop.conf.Configuration conf);\n\t// Do client side SASL authentication with server via the given InputStream and OutputStream\n\tboolean saslConnect(InputStream inS, OutputStream outS);\n}", "des": "A utility class that encapsulates SASL logic for RPC client. Copied from org.apache.hadoop.security"}
{"index": 3010, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class HBaseServerException {\n\t// Returns True if server was considered overloaded when exception was thrown\n\tboolean isServerOverloaded();\n\t// Returns True if the server was considered overloaded when the exception was thrown\n\tstatic boolean isServerOverloaded(Throwable t);\n\t// Necessary for parsing RemoteException on client side\n\tvoid setServerOverloaded(boolean serverOverloaded);\n}", "des": "Base class for exceptions thrown by an HBase server. May contain extra info about the state of the server when the exception was thrown."}
{"index": 3011, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class HRegionLocation {\n\tint compareTo(HRegionLocation o);\n\tboolean equals(Object o);\n\tString getHostname();\n\t// Returns String made of hostname and port formatted as per Addressing.createHostAndPortStr(String, int)\n\tString getHostnamePort();\n\tint getPort();\n\t// Returns regionInfo\n\tRegionInfo getRegion();\n\tlong getSeqNum();\n\tServerName getServerName();\n}", "des": "Data structure to hold RegionInfo and the address for the hosting HRegionServer. Immutable. Comparable, but we compare the 'location' only: i.e. the hostname and port, and *not* the regioninfo. This means two instances are the same if they refer to the same 'location' (the same hostname and port), though they may be carrying different regions. On a big cluster, each client will have thousands of instances of this object, often 100 000 of them if not million. It's important to keep the object size as small as possible. This interface has been marked InterfaceAudience.Public in 0.96 and 0.98."}
{"index": 3012, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum IsolationLevel {\n\tstatic IsolationLevel fromByte(byte vbyte);\n\tstatic IsolationLevel fromBytes(byte[] bytes);\n\tbyte toByte();\n\tbyte[] toBytes();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IsolationLevel valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IsolationLevel[] values();\n}", "des": "Specify Isolation levels in Scan operations."}
{"index": 3013, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum KeepDeletedCells {\n\tstatic KeepDeletedCells getValue(String val);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic KeepDeletedCells valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic KeepDeletedCells[] values();\n}", "des": "Ways to keep cells marked for delete around."}
{"index": 3014, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class LongComparator {\n\tint compareTo(byte[] value, int offset, int length);\n\tint compareTo(ByteBuffer value, int offset, int length);\n\t// Parses a serialized representation of LongComparator\n\tstatic LongComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "A long comparator which numerical compares against the specified byte array"}
{"index": 3015, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum MasterSwitchType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MasterSwitchType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MasterSwitchType[] values();\n}", "des": "Represents the master switch type"}
{"index": 3016, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum MemoryCompactionPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MemoryCompactionPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MemoryCompactionPolicy[] values();\n}", "des": "Enum describing all possible memory compaction policies"}
{"index": 3017, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum MobCompactPartitionPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MobCompactPartitionPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MobCompactPartitionPolicy[] values();\n}", "des": "Enum describing the mob compact partition policy types."}
{"index": 3018, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class NamespacePermission {\n\tboolean equals(Object obj);\n\t// Check if two permission equals regardless of actions.\n\tboolean equalsExceptActions(Object obj);\n\tString getNamespace();\n\t// check if given action is granted in given namespace.\n\tboolean implies(String namespace, Permission.Action action);\n\tprotected String rawExpression();\n\tvoid readFields(DataInput in);\n\tvoid write(DataOutput out);\n}", "des": "Represents an authorization for access for the given namespace."}
{"index": 3019, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class NettyRpcClientConfigHelper {\n\t// The NettyRpcClient will create its own NioEventLoopGroup.\n\tstatic void createEventLoopPerClient(org.apache.hadoop.conf.Configuration conf);\n\t// Set the EventLoopGroup and channel class for AsyncRpcClient.\n\tstatic void setEventLoopConfig(org.apache.hadoop.conf.Configuration conf, org.apache.hbase.thirdparty.io.netty.channel.EventLoopGroup group, Class<? extends org.apache.hbase.thirdparty.io.netty.channel.Channel> channelClass);\n}", "des": "Helper class for passing config to NettyRpcClient."}
{"index": 3020, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface NonceGenerator {\n\t// Returns the nonce group (client ID) of this client manager.\n\tlong getNonceGroup();\n\t// Returns New nonce.\n\tlong newNonce();\n}", "des": "NonceGenerator interface. In general, nonce group is an ID (one per client, or region+client, or whatever) that could be used to reduce collision potential, or be used by compatible server nonce manager to optimize nonce storage and removal. See HBASE-3787."}
{"index": 3021, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class NullComparator {\n\tint compareTo(byte[] value);\n\tint compareTo(byte[] value, int offset, int length);\n\tint compareTo(ByteBuffer value, int offset, int length);\n\tboolean equals(Object obj);\n\t// Parse the serialized representation of NullComparator\n\tstatic NullComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "A binary comparator which lexicographically compares against the specified byte array using Bytes.compareTo(byte[], byte[])."}
{"index": 3022, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class PerClientRandomNonceGenerator {\n\t// Get the singleton nonce generator.\n\tstatic PerClientRandomNonceGenerator get();\n\t// Returns the nonce group (client ID) of this client manager.\n\tlong getNonceGroup();\n\t// Returns New nonce.\n\tlong newNonce();\n}", "des": "NonceGenerator implementation that uses client ID hash + random int as nonce group, and random numbers as nonces."}
{"index": 3023, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class ProtobufMagic {\n\t// Returns True if passed bytes has PB_MAGIC for a prefix.\n\tstatic boolean isPBMagicPrefix(byte[] bytes);\n\t// Returns True if passed bytes has PB_MAGIC for a prefix.\n\tstatic boolean isPBMagicPrefix(byte[] bytes, int offset, int len);\n\t// Returns Length of PB_MAGIC\n\tstatic int lengthOfPBMagic();\n}", "des": "Protobufs utility."}
{"index": 3024, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class QualifierFilter {\n\tstatic Filter createFilterFromArguments(ArrayList<byte[]> filterArguments);\n\tboolean equals(Object obj);\n\t// A way to filter based on the column family, column qualifier and/or the column value.\n\tFilter.ReturnCode filterCell(Cell c);\n\t// Parse a serialized representation of QualifierFilter\n\tstatic QualifierFilter parseFrom(byte[] pbBytes);\n\t// Returns The filter serialized using pb\n\tbyte[] toByteArray();\n}", "des": "This filter is used to filter based on the column qualifier. It takes an operator (equal, greater, not equal, etc) and a byte [] comparator for the column qualifier portion of a key."}
{"index": 3025, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class QuotaRetriever {\n\tvoid close();\n\tIterator<QuotaSettings> iterator();\n\tQuotaSettings next();\n\t// Open a QuotaRetriever with no filter, all the quota settings will be returned.\n\tstatic QuotaRetriever open(org.apache.hadoop.conf.Configuration conf);\n\t// Open a QuotaRetriever with the specified filter.\n\tstatic QuotaRetriever open(org.apache.hadoop.conf.Configuration conf, QuotaFilter filter);\n}", "des": "Scanner to iterate over the quota settings."}
{"index": 3026, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum QuotaScope {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QuotaScope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QuotaScope[] values();\n}", "des": "Describe the Scope of the quota rules. The quota can be enforced at the cluster level or at machine level."}
{"index": 3027, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum QuotaType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QuotaType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QuotaType[] values();\n}", "des": "Describe the Quota Type."}
{"index": 3028, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class RegexStringComparator {\n\tint compareTo(byte[] value, int offset, int length);\n\t// Parse a serialized representation of RegexStringComparator\n\tstatic RegexStringComparator parseFrom(byte[] pbBytes);\n\t// Specifies the Charset to use to convert the row key to a String.\n\tvoid setCharset(Charset charset);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "This comparator is for use with CompareFilter implementations, such as RowFilter, QualifierFilter, and ValueFilter, for filtering based on the value of a given column. Use it to test if a given regular expression matches a cell value in the column."}
{"index": 3029, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum RegexStringComparator.EngineType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RegexStringComparator.EngineType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RegexStringComparator.EngineType[] values();\n}", "des": "Engine implementation type (default=JAVA)"}
{"index": 3030, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class RemoteWithExtrasException {\n\t// Returns null if not set\n\tString getHostname();\n\t// Returns -1 if not set\n\tint getPort();\n\t// Returns True if origin exception was a do not retry type.\n\tboolean isDoNotRetry();\n\t// Returns True if the server was considered overloaded when the exception was thrown.\n\tboolean isServerOverloaded();\n\tIOException unwrapRemoteException();\n}", "des": "A RemoteException with some extra information. If source exception was a DoNotRetryIOException, isDoNotRetry() will return true."}
{"index": 3031, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface RequestController.Checker {\n\t// Checks the data whether it is valid to submit.\n\tRequestController.ReturnCode canTakeRow(HRegionLocation loc, Row row);\n\t// Reset the state of the scheduler when completing the iteration of rows.\n\tvoid reset();\n}", "des": "Picks up the valid data."}
{"index": 3032, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface ResultScanner {\n\t// Closes the scanner and releases any resources it has allocated\n\tvoid close();\n\t// Returns the scan metrics, or null if we do not enable metrics.\n\tScanMetrics getScanMetrics();\n\tdefault Iterator<Result> iterator();\n\t// Grab the next row's worth of values.\n\tResult next();\n\t// Get nbRows rows.\n\tdefault Result[] next(int nbRows);\n\t// Allow the client to renew the scanner's lease on the server.\n\tboolean renewLease();\n}", "des": "Interface for client-side scanning. Go to Table to obtain instances."}
{"index": 3033, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class RotateFile {\n\t// Deletes the two files used for rotating data.\n\tvoid delete();\n\t// Reads the content of the rotate file by selecting the winner file based on the timestamp of the data inside the files.\n\tbyte[] read();\n\t// Writes the given data to the next file in the rotation, with a timestamp calculated based on the previous timestamp and the current time to make sure it is greater than the previous timestamp.\n\tvoid write(byte[] data);\n}", "des": "A file storage which supports atomic update through two files, i.e, rotating. The implementation does not require atomic rename."}
{"index": 3034, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface RowAccess<T> {\n\t// Returns true if there are no elements.\n\tboolean isEmpty();\n\t// Returns the number of elements in this list.\n\tint size();\n}", "des": "Provide a way to access the inner buffer. The purpose is to reduce the elapsed time to move a large number of elements between collections."}
{"index": 3035, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class RowMutations {\n\t// Add a list of mutations\n\tRowMutations add(List<? extends Mutation> mutations);\n\t// Add a mutation\n\tRowMutations add(Mutation mutation);\n\tint getMaxPriority();\n\t// Returns An unmodifiable list of the current mutations.\n\tList<Mutation> getMutations();\n\t// Returns The row.\n\tbyte[] getRow();\n\t// Create a RowMutations with the specified mutations.\n\tstatic RowMutations of(List<? extends Mutation> mutations);\n}", "des": "Performs multiple mutations atomically on a single row. The mutations are performed in the order in which they were added."}
{"index": 3036, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface SaslAuthenticationProvider {\n\t// Returns the attributes which identify how this provider authenticates.\n\tSaslAuthMethod getSaslAuthMethod();\n\t// Returns the name of the type used by the TokenIdentifier.\n\tString getTokenKind();\n}", "des": "Encapsulation of client-side logic to authenticate to HBase via some means over SASL. It is suggested that custom implementations extend the abstract class in the type hierarchy instead of directly implementing this interface (clients have a base class available, but servers presently do not). Implementations of this interface must be unique among each other via the byte returned by SaslAuthMethod.getCode() on getSaslAuthMethod()."}
{"index": 3037, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface ScanResultConsumerBase {\n\t// Indicate that the scan operation is completed normally.\n\tvoid onComplete();\n\t// Indicate that we hit an unrecoverable error and the scan operation is terminated.\n\tvoid onError(Throwable error);\n\t// If scan.isScanMetricsEnabled() returns true, then this method will be called prior to all other methods in this interface to give you the ScanMetrics instance for this scan operation.\n\tdefault void onScanMetricsCreated(ScanMetrics scanMetrics);\n}", "des": "The base interface for scan result consumer."}
{"index": 3038, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum SecurityCapability {\n\tString getName();\n\tint getValue();\n\tstatic SecurityCapability valueOf(int value);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SecurityCapability valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SecurityCapability[] values();\n}", "des": "Available security capabilities"}
{"index": 3039, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class SecurityInfo {\n\t// Adds a security configuration for a new service name.\n\tstatic void addInfo(String serviceName, SecurityInfo securityInfo);\n\t// Returns the security configuration associated with the given service name.\n\tstatic SecurityInfo getInfo(String serviceName);\n\tString getServerPrincipal();\n\torg.apache.hadoop.hbase.shaded.protobuf.generated.AuthenticationProtos.TokenIdentifier.Kind getTokenKind();\n}", "des": "Maps RPC protocol interfaces to required configuration"}
{"index": 3040, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface ServerTask {\n\t// Get the task completion time.\n\tlong getCompletionTime();\n\t// Get the task's description.\n\tString getDescription();\n\t// Get the task start time.\n\tlong getStartTime();\n\t// Get the current state of the task.\n\tServerTask.State getState();\n\t// Get the current status of the task.\n\tString getStatus();\n}", "des": "Information about active monitored server tasks"}
{"index": 3041, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum ServerTask.State {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ServerTask.State valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ServerTask.State[] values();\n}", "des": "Task state"}
{"index": 3042, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum ServerType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ServerType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ServerType[] values();\n}", "des": "Select server type i.e destination for RPC request associated with ring buffer. e.g slow/large log records are maintained by HRegionServer, whereas balancer decisions are maintained by HMaster."}
{"index": 3043, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class Size {\n\tint compareTo(Size other);\n\tboolean equals(Object obj);\n\t// get the value\n\tdouble get();\n\t// get the value which is converted to specified unit.\n\tdouble get(Size.Unit unit);\n\t// get the value\n\tlong getLongValue();\n\t// Returns size unit\n\tSize.Unit getUnit();\n}", "des": "It is used to represent the size with different units. This class doesn't serve for the precise computation."}
{"index": 3044, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum SnapshotType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SnapshotType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SnapshotType[] values();\n}", "des": "POJO representing the snapshot type"}
{"index": 3045, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface SpaceQuotaSnapshotView {\n\t// Returns the limit, in bytes, of the target (e.g.\n\tlong getLimit();\n\t// Returns the status of the quota.\n\tSpaceQuotaSnapshotView.SpaceQuotaStatusView getQuotaStatus();\n\t// Returns the current usage, in bytes, of the target (e.g.\n\tlong getUsage();\n}", "des": "A point-in-time view of a space quota on a table, read only."}
{"index": 3046, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface SpaceQuotaSnapshotView.SpaceQuotaStatusView {\n\t// Returns the violation policy, which may not be presented.\n\tOptional<SpaceViolationPolicy> getPolicy();\n\t// Returns true if the quota is being violated, false otherwise.\n\tboolean isInViolation();\n}", "des": "Encapsulates the state of a quota on a table. The quota may or may not be in violation. If the quota is not in violation, the violation may not be presented. If the quota is in violation, there is guaranteed to be presented."}
{"index": 3047, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum SpaceViolationPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SpaceViolationPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SpaceViolationPolicy[] values();\n}", "des": "Enumeration that represents the action HBase will take when a space quota is violated. The target for a violation policy is either an HBase table or namespace. In the case of a namespace, it is treated as a collection of tables (all tables are subject to the same policy)."}
{"index": 3048, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class SubstringComparator {\n\tint compareTo(byte[] value, int offset, int length);\n\tbyte[] getValue();\n\t// Parse a serialized representation of SubstringComparator\n\tstatic SubstringComparator parseFrom(byte[] pbBytes);\n\t// Returns The comparator serialized using pb\n\tbyte[] toByteArray();\n}", "des": "This comparator is for use with SingleColumnValueFilter, for filtering based on the value of a given column. Use it to test if a given substring appears in a cell value in the column. The comparison is case insensitive."}
{"index": 3049, "repo": "hbase-client-3.0.0-alpha-4", "code": "Interface TableBuilder {\n\t// Create the Table instance.\n\tTable build();\n\t// Set timeout for a whole operation such as get, put or delete.\n\tTableBuilder setOperationTimeout(int timeout);\n\t// Set timeout for each read(get, scan) rpc request.\n\tTableBuilder setReadRpcTimeout(int timeout);\n\t// Set timeout for each rpc request.\n\tTableBuilder setRpcTimeout(int timeout);\n\t// Set timeout for each write(put, delete) rpc request.\n\tTableBuilder setWriteRpcTimeout(int timeout);\n}", "des": "For creating Table instance."}
{"index": 3050, "repo": "hbase-client-3.0.0-alpha-4", "code": "Enum ThrottleType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ThrottleType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ThrottleType[] values();\n}", "des": "Describe the Throttle Type."}
{"index": 3051, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class ValueFilter {\n\tstatic Filter createFilterFromArguments(ArrayList<byte[]> filterArguments);\n\tboolean equals(Object obj);\n\t// A way to filter based on the column family, column qualifier and/or the column value.\n\tFilter.ReturnCode filterCell(Cell c);\n\t// Parse a serialized representation of ValueFilter\n\tstatic ValueFilter parseFrom(byte[] pbBytes);\n\t// Returns The filter serialized using pb\n\tbyte[] toByteArray();\n}", "des": "This filter is used to filter based on column value. It takes an operator (equal, greater, not equal, etc) and a byte [] comparator for the cell value."}
{"index": 3052, "repo": "hbase-client-3.0.0-alpha-4", "code": "Class ZooKeeperHelper {\n\t// Ensure passed zookeeper is connected.\n\tstatic org.apache.zookeeper.ZooKeeper ensureConnectedZooKeeper(org.apache.zookeeper.ZooKeeper zookeeper, int timeout);\n\t// Get a ZooKeeper instance and wait until it connected before returning.\n\tstatic org.apache.zookeeper.ZooKeeper getConnectedZooKeeper(String connectString, int sessionTimeoutMs);\n}", "des": "Methods that help working with ZooKeeper"}
{"index": 3053, "repo": "hudi-client-0.6.0", "code": "Class AbstractAsyncService {\n\tboolean isRunInDaemonMode();\n\tprotected boolean isShutdown();\n\tprotected boolean isShutdownRequested();\n\t// Request shutdown either forcefully or gracefully.\n\tvoid shutdown(boolean force);\n\t// Start the service.\n\tvoid start(Function<Boolean,Boolean> onShutdownCallback);\n\t// Service implementation.\n\tprotected abstract Pair<CompletableFuture,ExecutorService> startService();\n\t// Wait till the service shutdown.\n\tvoid waitForShutdown();\n}", "des": "Base Class for running clean/delta-sync/compaction in separate thread and controlling their life-cycle."}
{"index": 3054, "repo": "hudi-client-0.6.0", "code": "Class AsyncCompactService {\n\t// Enqueues new Pending compaction.\n\tvoid enqueuePendingCompaction(HoodieInstant instant);\n\t// Check whether compactor thread needs to be stopped.\n\tprotected boolean shouldStopCompactor();\n\t// Start Compaction Service.\n\tprotected Pair<CompletableFuture,ExecutorService> startService();\n\t// Wait till outstanding pending compactions reduces to the passed in value.\n\tvoid waitTillPendingCompactionsReducesTo(int numPendingCompactions);\n}", "des": "Async Compactor Service that runs in separate thread. Currently, only one compactor is allowed to run at any time."}
{"index": 3055, "repo": "hudi-client-0.6.0", "code": "Enum BootstrapMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BootstrapMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BootstrapMode[] values();\n}", "des": "Identifies different types of bootstrap."}
{"index": 3056, "repo": "hudi-client-0.6.0", "code": "Class BootstrapSchemaProvider {\n\t// Main API to select avro schema for bootstrapping.\n\torg.apache.avro.Schema getBootstrapSchema(org.apache.spark.api.java.JavaSparkContext jsc, List<Pair<String,List<HoodieFileStatus>>> partitions);\n\t// Select a random file to be used to generate avro schema.\n\tprotected org.apache.avro.Schema getBootstrapSourceSchema(org.apache.spark.api.java.JavaSparkContext jsc, List<Pair<String,List<HoodieFileStatus>>> partitions);\n}", "des": "Bootstrap Schema Provider. Schema provided in config is used. If not available, use schema from Parquet"}
{"index": 3057, "repo": "hudi-client-0.6.0", "code": "Class BoundedPartitionAwareCompactionStrategy {\n\t// Filter the partition paths based on compaction strategy.\n\tList<String> filterPartitionPaths(HoodieWriteConfig writeConfig, List<String> partitionPaths);\n\tstatic Date getDateAtOffsetFromToday(int offset);\n\t// Order and Filter the list of compactions.\n\tList<HoodieCompactionOperation> orderAndFilter(HoodieWriteConfig writeConfig, List<HoodieCompactionOperation> operations, List<HoodieCompactionPlan> pendingCompactionPlans);\n}", "des": "This strategy ensures that the last N partitions are picked up even if there are later partitions created for the table. lastNPartitions is defined as the N partitions before the currentDate. currentDay = 2018/01/01 The table has partitions for 2018/02/02 and 2018/03/03 beyond the currentDay This strategy will pick up the following partitions for compaction : (2018/01/01, allPartitionsInRange[(2018/01/01 - lastNPartitions) to 2018/01/01), 2018/02/02, 2018/03/03)"}
{"index": 3058, "repo": "hudi-client-0.6.0", "code": "Class ConsoleMetricsReporter {\n\tCloseable getReporter();\n\t// Deterministically push out metrics.\n\tvoid report();\n\t// Push out metrics at scheduled intervals.\n\tvoid start();\n\t// Stop this reporter.\n\tvoid stop();\n}", "des": "Hudi Console metrics reporter. Reports the metrics by printing them to the stdout on the console."}
{"index": 3059, "repo": "hudi-client-0.6.0", "code": "Class DatadogMetricsReporter {\n\tCloseable getReporter();\n\t// Deterministically push out metrics.\n\tvoid report();\n\t// Push out metrics at scheduled intervals.\n\tvoid start();\n\t// Stop this reporter.\n\tvoid stop();\n}", "des": "Hudi Datadog metrics reporter."}
{"index": 3060, "repo": "hudi-client-0.6.0", "code": "Class HoodieAppendHandle<T extends HoodieRecordPayload> {\n\t// Determines whether we can accept the incoming records, into the current file.\n\tboolean canWrite(HoodieRecord record);\n\tWriteStatus close();\n\tvoid doAppend();\n\tIOType getIOType();\n\tWriteStatus getWriteStatus();\n\t// Perform the actual writing of the given record into the backing file.\n\tvoid write(HoodieRecord record, Option<org.apache.avro.generic.IndexedRecord> insertValue);\n}", "des": "IO Operation to append data onto an existing file."}
{"index": 3061, "repo": "hudi-client-0.6.0", "code": "Class HoodieGauge<T> {\n\t// Returns the metric's current value.\n\tT getValue();\n\t// Set the metric to a new value.\n\tvoid setValue(T value);\n}", "des": "Similar to Gauge, but metric value can be updated by #setValue(T)."}
{"index": 3062, "repo": "hudi-client-0.6.0", "code": "Class HoodieGlobalBloomIndex<T extends HoodieRecordPayload> {\n\t// This is not global, since we depend on the partitionPath to do the lookup.\n\tboolean isGlobal();\n\t// Tagging for global index should only consider the record key.\n\tprotected org.apache.spark.api.java.JavaRDD<HoodieRecord<T>> tagLocationBacktoRecords(org.apache.spark.api.java.JavaPairRDD<HoodieKey,HoodieRecordLocation> keyLocationPairRDD, org.apache.spark.api.java.JavaRDD<HoodieRecord<T>> recordRDD);\n}", "des": "This filter will only work with hoodie table since it will only load partitions with .hoodie_partition_metadata file in it."}
{"index": 3063, "repo": "hudi-client-0.6.0", "code": "Class HoodieIndexUtils {\n\t// Fetches Pair of partition path and HoodieBaseFiles for interested partitions.\n\tstatic List<Pair<String,HoodieBaseFile>> getLatestBaseFilesForAllPartitions(List<String> partitions, org.apache.spark.api.java.JavaSparkContext jsc, HoodieTable hoodieTable);\n\t// Get tagged record for the passed in HoodieRecord.\n\tstatic HoodieRecord getTaggedRecord(HoodieRecord inputRecord, Option<HoodieRecordLocation> location);\n}", "des": "Hoodie Index Utilities."}
{"index": 3064, "repo": "hudi-client-0.6.0", "code": "Interface HoodieInternalRowFileWriter {\n\tboolean canWrite();\n\t// Closes the HoodieInternalRowFileWriter and may not take in any more writes.\n\tvoid close();\n\t// Writes an InternalRow to the HoodieInternalRowFileWriter.\n\tvoid writeRow(String key, org.apache.spark.sql.catalyst.InternalRow row);\n}", "des": "Abstraction to assist in writing InternalRows to be used in datasource implementation."}
{"index": 3065, "repo": "hudi-client-0.6.0", "code": "Class HoodieInternalRowParquetWriter {\n\tboolean canWrite();\n\t// Closes the HoodieInternalRowFileWriter and may not take in any more writes.\n\tvoid close();\n\t// Writes an InternalRow to the HoodieInternalRowFileWriter.\n\tvoid writeRow(String key, org.apache.spark.sql.catalyst.InternalRow row);\n}", "des": "Parquet's impl of HoodieInternalRowFileWriter to write InternalRows."}
{"index": 3066, "repo": "hudi-client-0.6.0", "code": "Class HoodieRowCreateHandle {\n\tboolean canWrite();\n\t// Closes the HoodieRowCreateHandle and returns an instance of HoodieInternalWriteStatus containing the stats and status of the writes to this handle.\n\tHoodieInternalWriteStatus close();\n\tString getFileName();\n\t// Writes an InternalRow to the underlying HoodieInternalRowFileWriter.\n\tvoid write(org.apache.spark.sql.catalyst.InternalRow record);\n}", "des": "Create handle with InternalRow for datasource implemention of bulk insert."}
{"index": 3067, "repo": "hudi-client-0.6.0", "code": "Class InMemoryMetricsReporter {\n\tCloseable getReporter();\n\t// Deterministically push out metrics.\n\tvoid report();\n\t// Push out metrics at scheduled intervals.\n\tvoid start();\n\t// Stop this reporter.\n\tvoid stop();\n}", "des": "Used for testing."}
{"index": 3068, "repo": "hudi-client-0.6.0", "code": "Enum IOType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IOType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IOType[] values();\n}", "des": "Types of lower level I/O operations done on each file slice."}
{"index": 3069, "repo": "hudi-client-0.6.0", "code": "Class JmxMetricsReporter {\n\tCloseable getReporter();\n\t// Deterministically push out metrics.\n\tvoid report();\n\t// Push out metrics at scheduled intervals.\n\tvoid start();\n\t// Stop this reporter.\n\tvoid stop();\n}", "des": "Implementation of Jmx reporter, which used to report jmx metric."}
{"index": 3070, "repo": "hudi-client-0.6.0", "code": "Class LazyInsertIterable<T extends HoodieRecordPayload> {\n\t// Block computation to be overwritten by sub classes.\n\tprotected List<WriteStatus> computeNext();\n\t// Called once, after all elements are processed.\n\tprotected void end();\n\tprotected CopyOnWriteInsertHandler getInsertHandler();\n\t// Called once, before any elements are processed.\n\tprotected void start();\n}", "des": "Lazy Iterable, that writes a stream of HoodieRecords sorted by the partitionPath, into new files."}
{"index": 3071, "repo": "hudi-client-0.6.0", "code": "Class LazyIterableIterator<I,O> {\n\t// Block computation to be overwritten by sub classes.\n\tprotected abstract O computeNext();\n\t// Called once, after all elements are processed.\n\tprotected abstract void end();\n\tboolean hasNext();\n\tIterator<O> iterator();\n\tO next();\n\tvoid remove();\n\t// Called once, before any elements are processed.\n\tprotected abstract void start();\n}", "des": "(NOTE: Adapted from Apache SystemML) This class is a generic base class for lazy, single pass inputItr classes in order to simplify the implementation of lazy iterators for mapPartitions use cases. Note [SPARK-3369], which gives the reasons for backwards compatibility with regard to the iterable API despite Spark's single pass nature."}
{"index": 3072, "repo": "hudi-client-0.6.0", "code": "Enum ListingBasedRollbackRequest.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ListingBasedRollbackRequest.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ListingBasedRollbackRequest.Type[] values();\n}", "des": "Rollback commands, that trigger a specific handling for rollback."}
{"index": 3073, "repo": "hudi-client-0.6.0", "code": "Class MetricsGraphiteReporter {\n\tCloseable getReporter();\n\t// Deterministically push out metrics.\n\tvoid report();\n\t// Push out metrics at scheduled intervals.\n\tvoid start();\n\t// Stop this reporter.\n\tvoid stop();\n}", "des": "Implementation of Graphite reporter, which connects to the Graphite server, and send metrics to that server."}
{"index": 3074, "repo": "hudi-client-0.6.0", "code": "Class MetricsReporter {\n\tabstract Closeable getReporter();\n\t// Deterministically push out metrics.\n\tabstract void report();\n\t// Push out metrics at scheduled intervals.\n\tabstract void start();\n\t// Stop this reporter.\n\tabstract void stop();\n}", "des": "Interface for implementing a Reporter."}
{"index": 3075, "repo": "hudi-client-0.6.0", "code": "Enum MetricsReporterType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MetricsReporterType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MetricsReporterType[] values();\n}", "des": "Types of the reporter supported, hudi also supports user defined reporter."}
{"index": 3076, "repo": "hudi-client-0.6.0", "code": "Class PrometheusReporter {\n\tCloseable getReporter();\n\t// Deterministically push out metrics.\n\tvoid report();\n\t// Push out metrics at scheduled intervals.\n\tvoid start();\n\t// Stop this reporter.\n\tvoid stop();\n}", "des": "Implementation of Prometheus reporter, which connects to the Http server, and get metrics from that server."}
{"index": 3077, "repo": "hudi-client-0.6.0", "code": "Class UnBoundedPartitionAwareCompactionStrategy {\n\t// Filter the partition paths based on compaction strategy.\n\tList<String> filterPartitionPaths(HoodieWriteConfig writeConfig, List<String> partitionPaths);\n\t// Order and Filter the list of compactions.\n\tList<HoodieCompactionOperation> orderAndFilter(HoodieWriteConfig config, List<HoodieCompactionOperation> operations, List<HoodieCompactionPlan> pendingCompactionWorkloads);\n}", "des": "UnBoundedPartitionAwareCompactionStrategy is a custom UnBounded Strategy. This will filter all the partitions that are eligible to be compacted by a BoundedPartitionAwareCompactionStrategy and return the result. This is done so that a long running UnBoundedPartitionAwareCompactionStrategy does not step over partitions in a shorter running BoundedPartitionAwareCompactionStrategy. Essentially, this is an inverse of the partitions chosen in BoundedPartitionAwareCompactionStrategy"}
{"index": 3078, "repo": "lucene-analyzers-icu-8.11.2", "code": "Class DefaultICUTokenizerConfig {\n\t// true if Han, Hiragana, and Katakana scripts should all be returned as Japanese\n\tboolean combineCJ();\n\t// Return a breakiterator capable of processing a given script.\n\tcom.ibm.icu.text.RuleBasedBreakIterator getBreakIterator(int script);\n\t// Return a token type value for a given script and BreakIterator rule status.\n\tString getType(int script, int ruleStatus);\n}", "des": "Default ICUTokenizerConfig that is generally applicable to many languages."}
{"index": 3079, "repo": "lucene-analyzers-icu-8.11.2", "code": "Class ICUTokenizerConfig {\n\t// true if Han, Hiragana, and Katakana scripts should all be returned as Japanese\n\tabstract boolean combineCJ();\n\t// Return a breakiterator capable of processing a given script.\n\tabstract com.ibm.icu.text.RuleBasedBreakIterator getBreakIterator(int script);\n\t// Return a token type value for a given script and BreakIterator rule status.\n\tabstract String getType(int script, int ruleStatus);\n}", "des": "Class that allows for tailored Unicode Text Segmentation on a per-writing system basis."}
{"index": 3080, "repo": "lucene-analyzers-icu-8.11.2", "code": "Interface ScriptAttribute {\n\t// Get the numeric code for this script value.\n\tint getCode();\n\t// Get the full name.\n\tString getName();\n\t// Get the abbreviated name.\n\tString getShortName();\n\t// Set the numeric code for this script value.\n\tvoid setCode(int code);\n}", "des": "This attribute stores the UTR #24 script value for a token of text."}
{"index": 3081, "repo": "lucene-analyzers-icu-8.11.2", "code": "Class ScriptAttributeImpl {\n\tvoid clear();\n\tvoid copyTo(AttributeImpl target);\n\tboolean equals(Object other);\n\t// Get the numeric code for this script value.\n\tint getCode();\n\t// Get the full name.\n\tString getName();\n\t// Get the abbreviated name.\n\tString getShortName();\n\tvoid reflectWith(AttributeReflector reflector);\n\t// Set the numeric code for this script value.\n\tvoid setCode(int code);\n}", "des": "Implementation of ScriptAttribute that stores the script as an integer."}
{"index": 3082, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Interface BeanLifecycleDecorator<T> {\n\t// Optionally decorate and provide a new instance of a compatible bean for the caller to use instead of the input.\n\tObject decorateBean(Object bean, BeanLifecycleDecorator.Context<T> context);\n\t// Optionally decorate the destruction callback provided, and also return some context that can be used later by the decorateBean(Object, Context) method.\n\tBeanLifecycleDecorator.Context<T> decorateDestructionCallback(Runnable callback);\n}", "des": "A helper interface providing optional decoration of bean instances and their destruction callbacks. Users can supply custom implementations of this strategy if they want tighter control over method invocation on the bean or its destruction callback."}
{"index": 3083, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Class DiscoveredResource {\n\t// Configures the RestOperations to use to execute the traversal and verifying HEAD calls.\n\tvoid setRestOperations(org.springframework.web.client.RestOperations restOperations);\n\t// Verifies the link to the current\n\tvoid verifyOrDiscover();\n}", "des": "A REST resource that is defined by a service reference and a traversal operation within that service."}
{"index": 3084, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Interface DiscoveryClient {\n\t// A human readable description of the implementation, used in HealthIndicator\n\tString description();\n\t// Get all ServiceInstances associated with a particular serviceId\n\tList<ServiceInstance> getInstances(String serviceId);\n\tServiceInstance getLocalServiceInstance();\n\tList<String> getServices();\n}", "des": "DiscoveryClient represents operations commonly available to Discovery service such as Netflix Eureka or consul.io"}
{"index": 3085, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Class LoadBalancedRetryContext {\n\t// Gets the request that is being load balanced.\n\torg.springframework.http.HttpRequest getRequest();\n\t// Gets the service instance used during the retry.\n\tServiceInstance getServiceInstance();\n\t// Sets the request that is being load baalnced.\n\tvoid setRequest(org.springframework.http.HttpRequest request);\n\t// Sets the service instance to use during the retry.\n\tvoid setServiceInstance(ServiceInstance serviceInstance);\n}", "des": "RetryContext for load balanced retries."}
{"index": 3086, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Class LoadBalancerRetryProperties {\n\t// Returns true if the load balancer should retry failed requests.\n\tboolean isEnabled();\n\t// Sets whether the load balancer should retry failed request.\n\tvoid setEnabled(boolean enabled);\n}", "des": "Configuration properties for the LoadBalancerClient."}
{"index": 3087, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Class NoopDiscoveryClient {\n\t// A human readable description of the implementation, used in HealthIndicator\n\tString description();\n\t// Get all ServiceInstances associated with a particular serviceId\n\tList<ServiceInstance> getInstances(String serviceId);\n\tServiceInstance getLocalServiceInstance();\n\tList<String> getServices();\n}", "des": "DiscoveryClient used when no implementations are found on the classpath"}
{"index": 3088, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Interface RemoteResource {\n\t// Returns the Link to the resource in case it is available or null in case it's gone, i.e.\n\torg.springframework.hateoas.Link getLink();\n\t// Discovers the the resource in case it hasn't been yet or became unavailable.\n\tvoid verifyOrDiscover();\n}", "des": "A REST resource that can be discovered and can be either gone or available."}
{"index": 3089, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Interface ScopeCache {\n\t// Clear the cache and return all objects in an unmodifiable collection.\n\tCollection<Object> clear();\n\t// Get the named object from the cache.\n\tObject get(String name);\n\t// Put a value in the cache if the key is not already used.\n\tObject put(String name, Object value);\n\t// Remove the object with this name from the cache.\n\tObject remove(String name);\n}", "des": "A special purpose cache interface specifically for the GenericScope to use to manage cached bean instances. Implementations generally fall into two categories: those that store values \"globally\" (i.e. one instance per key), and those that store potentially multiple instances per key based on context (e.g. via a thread local). All implementations should be thread safe."}
{"index": 3090, "repo": "spring-cloud-commons-parent-1.1.9.RELEASE", "code": "Class StandardScopeCache {\n\t// Clear the cache and return all objects in an unmodifiable collection.\n\tCollection<Object> clear();\n\t// Get the named object from the cache.\n\tObject get(String name);\n\t// Put a value in the cache if the key is not already used.\n\tObject put(String name, Object value);\n\t// Remove the object with this name from the cache.\n\tObject remove(String name);\n}", "des": "A simple cache implementation backed by a concurrent map."}
{"index": 3091, "repo": "nifi-administration-1.22.0", "code": "Enum IdpType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IdpType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IdpType[] values();\n}", "des": "Types of identity providers."}
{"index": 3092, "repo": "nifi-administration-1.22.0", "code": "Class RepositoryUtils {\n\t// Closes the given connection quietly - no logging, no exceptions\n\tstatic void closeQuietly(Connection conn);\n\t// Closes the given result set quietly - no logging, no exceptions\n\tstatic void closeQuietly(ResultSet resultSet);\n\t// Closes the given statement quietly - no logging, no exceptions\n\tstatic void closeQuietly(Statement statement);\n\tstatic void rollback(Connection conn, org.slf4j.Logger logger);\n}", "des": "A utility class for useful methods dealing with the repository"}
{"index": 3093, "repo": "nifi-administration-1.22.0", "code": "Class StandardTransaction {\n\tvoid close();\n\t// Commits the current transaction.\n\tvoid commit();\n\t// Executes the specified action within the current transaction.\n\t<T> T execute(AdministrationAction<T> action);\n\t// Rolls back the current transaction.\n\tvoid rollback();\n}", "des": "Transaction implementation that uses the specified SQL Connection and AuthorityProvider."}
{"index": 3094, "repo": "nifi-administration-1.22.0", "code": "Interface Transaction {\n\t// Commits the current transaction.\n\tvoid commit();\n\t// Executes the specified action within the current transaction.\n\t<T> T execute(AdministrationAction<T> action);\n\t// Rolls back the current transaction.\n\tvoid rollback();\n}", "des": "Defines a transaction."}
{"index": 3095, "repo": "zookeeper-3.8.2", "code": "Enum AddWatchMode {\n\tint getMode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AddWatchMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AddWatchMode[] values();\n}", "des": "Modes available to ZooKeeper.addWatch(String, Watcher, AddWatchMode)"}
{"index": 3096, "repo": "zookeeper-3.8.2", "code": "Class AdHash {\n\t// Add new digest to the hash value maintained in this class.\n\tAdHash addDigest(long digest);\n\tvoid clear();\n\tboolean equals(Object other);\n\t// Return the long value of the hash.\n\tlong getHash();\n\t// Remove the digest from the hash value.\n\tAdHash removeDigest(long digest);\n}", "des": "This incremental hash is used to keep track of the hash of the data tree to that we can quickly validate that things are in sync. See the excellent paper: A New Paradigm for collision-free hashing: Incrementality at reduced cost, M. Bellare and D. Micciancio"}
{"index": 3097, "repo": "zookeeper-3.8.2", "code": "Class AtomicFileOutputStream {\n\t// Close the atomic file, but do not \"commit\" the temporary file on top of the destination.\n\tvoid abort();\n\tvoid close();\n\t// The default write method in FilterOutputStream does not call the write method of its underlying input stream with the same arguments.\n\tvoid write(byte[] b, int off, int len);\n}", "des": "A FileOutputStream that has the property that it will only show up at its destination once it has been entirely written and flushed to disk. While being written, it will use a .tmp suffix. When the output stream is closed, it is flushed, fsynced, and will be moved into place, overwriting any file that already exists at that location. NOTE: on Windows platforms, it will not atomically replace the target file - instead the target file is deleted before this one is moved into place."}
{"index": 3098, "repo": "zookeeper-3.8.2", "code": "Class BitHashSet {\n\tboolean add(Integer elementBit);\n\tint cachedSize();\n\tboolean contains(Integer elementBit);\n\tboolean isEmpty();\n\t// This function is not thread-safe, need to synchronized when iterate through this set.\n\tIterator<Integer> iterator();\n\tboolean remove(Integer elementBit);\n\t// Remove the watches, and return the number of watches being removed.\n\tint remove(Set<Integer> bitSet, BitSet bits);\n\tint size();\n}", "des": "Using BitSet to store all the elements, and use HashSet to cache limited number of elements to find a balance between memory and time complexity. Without HashSet, we need to use O(N) time to get the elements, N is the bit numbers in elementBits. But we need to keep the size small to make sure it doesn't cost too much in memory, there is a trade off between memory and time complexity. Previously, was deciding to dynamically switch between SparseBitSet and HashSet based on the memory consumption, but it will take time to copy data over and may have some herd effect of keep copying data from one data structure to anther. The current solution can do a very good job given most of the paths have limited number of elements."}
{"index": 3099, "repo": "zookeeper-3.8.2", "code": "Class BufferStats {\n\t// Size of the last buffer usage.\n\tint getLastBufferSize();\n\t// Size of the largest buffer usage.\n\tint getMaxBufferSize();\n\t// Size of the smallest buffer usage.\n\tint getMinBufferSize();\n\t// Reset statistics.\n\tvoid reset();\n\t// Updates statistics by setting the last buffer usage size.\n\tvoid setLastBufferSize(int value);\n}", "des": "Provides live statistics about Jute buffer usage in term of proposal and client request size."}
{"index": 3100, "repo": "zookeeper-3.8.2", "code": "Class CircularBuffer<T> {\n\tboolean isEmpty();\n\tboolean isFull();\n\tT peek();\n\tvoid reset();\n\tint size();\n\t// Reads from the buffer in a FIFO manner.\n\tT take();\n\t// Puts elements in the next available index in the array.\n\tvoid write(T element);\n}", "des": "Thread safe FIFO CircularBuffer implementation. When the buffer is full write operation overwrites the oldest element. Fun thing @todo, make this lock free as this is called on every quorum message"}
{"index": 3101, "repo": "zookeeper-3.8.2", "code": "Enum CommandFactory.Command {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CommandFactory.Command valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CommandFactory.Command[] values();\n}", "des": "All Cli Commands."}
{"index": 3102, "repo": "zookeeper-3.8.2", "code": "Class CommandResponse {\n\t// Gets the command name.\n\tString getCommand();\n\t// Gets the error string (may be null).\n\tString getError();\n\t// Adds a key/value pair to this response.\n\tObject put(String key, Object value);\n\t// Adds all key/value pairs in the given map to this response.\n\tvoid putAll(Map<? extends String,?> m);\n\t// Converts this response to a map.\n\tMap<String,Object> toMap();\n}", "des": "A response from running a Command."}
{"index": 3103, "repo": "zookeeper-3.8.2", "code": "Class ContainerManager {\n\t// Manually check the containers.\n\tvoid checkContainers();\n\tprotected Collection<String> getCandidates();\n\tprotected long getElapsed(DataNode node);\n\tprotected long getMinIntervalMs();\n\tprotected void postDeleteRequest(Request request);\n\t// start/restart the timer the runs the check.\n\tvoid start();\n\t// stop the timer if necessary.\n\tvoid stop();\n}", "des": "Manages cleanup of container ZNodes. This class is meant to only be run from the leader. There's no harm in running from followers/observers but that will be extra work that's not needed. Once started, it periodically checks container nodes that have a cversion > 0 and have no children. A delete is attempted on the node. The result of the delete is unimportant. If the proposal fails or the container node is not empty there's no harm."}
{"index": 3104, "repo": "zookeeper-3.8.2", "code": "Class ControlCommand {\n\t// Create a REST command uri.\n\tstatic String createCommandUri(ControlCommand.Action action, String parameter);\n\tControlCommand.Action getAction();\n\tprotected String getParameter();\n\t// Parse a Uri into the required Command action and parameter.\n\tstatic ControlCommand parseUri(String commandUri);\n}", "des": "Set of commands that this controller can execute. Commands are comprised of an action and an optional parameter specific to that action."}
{"index": 3105, "repo": "zookeeper-3.8.2", "code": "Enum ControlCommand.Action {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ControlCommand.Action valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ControlCommand.Action[] values();\n}", "des": "Actions available to the controller"}
{"index": 3106, "repo": "zookeeper-3.8.2", "code": "Class ControllerServerConfig {\n\t// Ensure config is acceptable by filling in default values for any missing quorum configuration (specifically in the case of a single machine ensemble)\n\tvoid ensureComplete();\n\tInetSocketAddress getControllerAddress();\n\tServerConfig getZooKeeperServerConfig();\n\t// Parse a ZooKeeper configuration file\n\tvoid parse(String configFile);\n}", "des": "Config for the ControllerService. Responsible for providing the minimum set of configurations that's required to spin up a single member ensemble."}
{"index": 3107, "repo": "zookeeper-3.8.2", "code": "Interface Counter {\n\t// Increment the value by a given amount.\n\tvoid add(long delta);\n\t// Get the current value held by the counter.\n\tlong get();\n\t// Increment the value by one.\n\tdefault void inc();\n}", "des": "A counter refers to a value which can only increase. Usually the value is reset when the process starts."}
{"index": 3108, "repo": "zookeeper-3.8.2", "code": "Interface CounterSet {\n\t// Increment the value by a given amount for the given key\n\tvoid add(String key, long delta);\n\t// Increment the value by one for the given key\n\tdefault void inc(String key);\n}", "des": "A counter refers to a value which can only increase. Usually the value is reset when the process starts. A CounterSet is a set of Counter grouped by keys."}
{"index": 3109, "repo": "zookeeper-3.8.2", "code": "Enum DatadirCleanupManager.PurgeTaskStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DatadirCleanupManager.PurgeTaskStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DatadirCleanupManager.PurgeTaskStatus[] values();\n}", "des": "Status of the dataDir purge task"}
{"index": 3110, "repo": "zookeeper-3.8.2", "code": "Class DefaultMetricsProvider {\n\t// Configure the provider.\n\tvoid configure(Properties configuration);\n\t// Dumps all metrics as a key-value pair.\n\tvoid dump(BiConsumer<String,Object> sink);\n\t// Provides access to the root context.\n\tMetricsContext getRootContext();\n\t// Reset all values.\n\tvoid resetAllValues();\n\t// Start the provider.\n\tvoid start();\n\t// Releases resources held by the provider. This method must not throw exceptions. This method can be called more than once.\n\tvoid stop();\n}", "des": "Default implementation of MetricsProvider. It does not implement a real hierarchy of contexts, but metrics are flattened in a single namespace. It is mostly useful to make the legacy 4 letter words interface work as expected."}
{"index": 3111, "repo": "zookeeper-3.8.2", "code": "Class DelQuotaCommand {\n\t// this method deletes quota for a node.\n\tstatic boolean delQuota(ZooKeeper zk, String path, StatsTrack quota);\n\tboolean exec();\n\t// parse the command arguments\n\tCliCommand parse(String[] cmdArgs);\n}", "des": "delQuota command for cli"}
{"index": 3112, "repo": "zookeeper-3.8.2", "code": "Enum EphemeralTypeEmulate353 {\n\tstatic EphemeralTypeEmulate353 get(long ephemeralOwner);\n\tstatic long ttlToEphemeralOwner(long ttl);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EphemeralTypeEmulate353 valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EphemeralTypeEmulate353[] values();\n}", "des": "See https://issues.apache.org/jira/browse/ZOOKEEPER-2901 version 3.5.3 introduced bugs associated with how TTL nodes were implemented. version 3.5.4 fixes the problems but makes TTL nodes created in 3.5.3 invalid. EphemeralTypeEmulate353 is a copy of the old - bad - implementation that is provided as a workaround. EphemeralType.TTL_3_5_3_EMULATION_PROPERTY can be used to emulate support of the badly specified TTL nodes."}
{"index": 3113, "repo": "zookeeper-3.8.2", "code": "Enum ExitCode {\n\tint getValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExitCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExitCode[] values();\n}", "des": "Exit code used to exit server"}
{"index": 3114, "repo": "zookeeper-3.8.2", "code": "Enum ExitHandler {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExitHandler valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExitHandler[] values();\n}", "des": "Behaviour of the server in case of internal error. When you are running tests you will use LOG_ONLY, but please take care of using EXIT when runnning in production."}
{"index": 3115, "repo": "zookeeper-3.8.2", "code": "Class ExpiryQueue<E> {\n\tvoid dump(PrintWriter pwriter);\n\t// Returns an unmodifiable view of the expiration time -> elements mapping.\n\tMap<Long,Set<E>> getExpiryMap();\n\tlong getWaitTime();\n\t// Remove the next expired set of elements from expireMap.\n\tSet<E> poll();\n\t// Removes element from the queue.\n\tLong remove(E elem);\n\t// Adds or updates expiration time for element in queue, rounding the timeout to the expiry interval bucketed used by this queue.\n\tLong update(E elem, int timeout);\n}", "des": "ExpiryQueue tracks elements in time sorted fixed duration buckets. It's used by SessionTrackerImpl to expire sessions and NIOServerCnxnFactory to expire connections."}
{"index": 3116, "repo": "zookeeper-3.8.2", "code": "Class FileChangeWatcher {\n\t// Returns the current FileChangeWatcher.State.\n\tFileChangeWatcher.State getState();\n\t// Tells the background thread to start.\n\tvoid start();\n\t// Tells the background thread to stop.\n\tvoid stop();\n}", "des": "Instances of this class can be used to watch a directory for file changes. When a file is added to, deleted from, or is modified in the given directory, the callback provided by the user will be called from a background thread. Some things to keep in mind: The callback should be thread-safe. Changes that happen around the time the thread is started may be missed. There is a delay between a file changing and the callback firing. The watch is not recursive - changes to subdirectories will not trigger a callback."}
{"index": 3117, "repo": "zookeeper-3.8.2", "code": "Class Follower {\n\t// The zxid of the last operation queued\n\tprotected long getLastQueued();\n\tIterable<Map<String,Object>> getSyncedObserversInfo();\n\tInteger getSyncedObserverSize();\n\t// The zxid of the last operation seen\n\tlong getZxid();\n\t// Examine the packet received in qp and dispatch based on its contents.\n\tprotected void processPacket(QuorumPacket qp);\n\tvoid resetObserverConnectionStats();\n\t// Shutdown the Peer\n\tvoid shutdown();\n}", "des": "This class has the control logic for the Follower."}
{"index": 3118, "repo": "zookeeper-3.8.2", "code": "Class FourLetterCommands {\n\t// Return the string representation of the specified command code.\n\tstatic String getCommandString(int command);\n\t// Check if the specified command is enabled.\n\tstatic boolean isEnabled(String command);\n\t// Check if the specified command code is from a known command.\n\tstatic boolean isKnown(int command);\n\tstatic void resetWhiteList();\n}", "des": "This class contains constants for all the four letter commands"}
{"index": 3119, "repo": "zookeeper-3.8.2", "code": "Interface HostProvider {\n\t// The next host to try to connect to.\n\tInetSocketAddress next(long spinDelay);\n\t// Notify the HostProvider of a successful connection.\n\tvoid onConnected();\n\tint size();\n\t// Update the list of servers.\n\tboolean updateServerList(Collection<InetSocketAddress> serverAddresses, InetSocketAddress currentHost);\n}", "des": "A set of hosts a ZooKeeper client should connect to. Classes implementing this interface must guarantee the following: * Every call to next() returns an InetSocketAddress. So the iterator never ends. * The size() of a HostProvider may never be zero. A HostProvider must return resolved InetSocketAddress instances on next() if the next address is resolvable. In that case, it's up to the HostProvider, whether it returns the next resolvable address in the list or return the next one as UnResolved. Different HostProvider could be imagined: * A HostProvider that loads the list of Hosts from an URL or from DNS * A HostProvider that re-resolves the InetSocketAddress after a timeout. * A HostProvider that prefers nearby hosts."}
{"index": 3120, "repo": "zookeeper-3.8.2", "code": "Class JettyAdminServer {\n\t// Set the ZooKeeperServer that will be used to run Commands.\n\tvoid setZooKeeperServer(ZooKeeperServer zkServer);\n\t// Stop the embedded Jetty server.\n\tvoid shutdown();\n\t// Start the embedded Jetty server.\n\tvoid start();\n}", "des": "This class encapsulates a Jetty server for running Commands. Given the default settings, start a ZooKeeper server and visit http://hostname:8080/commands for links to all registered commands. Visiting http://hostname:8080/commands/commandname will execute the associated Command and return the result in the body of the response. Any keyword arguments to the command are specified with URL parameters (e.g., http://localhost:8080/commands/set_trace_mask?traceMask=306)."}
{"index": 3121, "repo": "zookeeper-3.8.2", "code": "Enum KeeperException.Code {\n\t// Get the Code value for a particular integer error code\n\tstatic KeeperException.Code get(int code);\n\t// Get the int value for a particular Code.\n\tint intValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic KeeperException.Code valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic KeeperException.Code[] values();\n}", "des": "Codes which represent the various KeeperException types. This enum replaces the deprecated earlier static final int constants. The old, deprecated, values are in \"camel case\" while the new enum values are in all CAPS."}
{"index": 3122, "repo": "zookeeper-3.8.2", "code": "Class KerberosName {\n\t// Get the configured default realm.\n\tString getDefaultRealm();\n\t// Get the second component of the name.\n\tString getHostName();\n\t// Get the realm of the name.\n\tString getRealm();\n\t// Get the first component of the name.\n\tString getServiceName();\n\t// Get the translation of the principal name into an operating system user name.\n\tString getShortName();\n\tstatic void main(String[] args);\n\t// Set the static configuration to get the rules.\n\tstatic void setConfiguration();\n}", "des": "This class implements parsing and handling of Kerberos principal names. In particular, it splits them apart and translates them down into local operating system names."}
{"index": 3123, "repo": "zookeeper-3.8.2", "code": "Class LearnerMaster {\n\t// diff sync throttler\n\tLearnerSyncThrottler getLearnerDiffSyncThrottler();\n\t// snap sync throttler\n\tLearnerSyncThrottler getLearnerSnapSyncThrottler();\n\tint getMaxConcurrentDiffSyncs();\n\tint getMaxConcurrentSnapSyncs();\n\tvoid setMaxConcurrentDiffSyncs(int maxConcurrentDiffSyncs);\n\tvoid setMaxConcurrentSnapSyncs(int maxConcurrentSnapSyncs);\n}", "des": "interface for keeping Observers in sync"}
{"index": 3124, "repo": "zookeeper-3.8.2", "code": "Class LearnerSyncThrottler {\n\t// Indicates that a new sync is about to be sent.\n\tprotected void beginSync(boolean essential);\n\t// Indicates that a sync has been completed.\n\tvoid endSync();\n\tint getSyncInProgress();\n\tvoid setMaxConcurrentSyncs(int maxConcurrentSyncs);\n}", "des": "Utility class to limit the number of concurrent syncs from a leader to observers and followers or from a follower to observers. LearnerHandler objects should call beginSync(boolean) before sending a sync and endSync() after finishing, successfully or not."}
{"index": 3125, "repo": "zookeeper-3.8.2", "code": "Interface MetricsProvider {\n\t// Configure the provider.\n\tvoid configure(Properties configuration);\n\t// Dumps all metrics as a key-value pair.\n\tvoid dump(BiConsumer<String,Object> sink);\n\t// Provides access to the root context.\n\tMetricsContext getRootContext();\n\t// Reset all values.\n\tvoid resetAllValues();\n\t// Start the provider.\n\tvoid start();\n\t// Releases resources held by the provider. This method must not throw exceptions. This method can be called more than once.\n\tvoid stop();\n}", "des": "A MetricsProvider is a system which collects Metrics and publishes current values to external facilities. The system will create an instance of the configured class using the default constructor, which must be public. After the instantiation of the provider, the system will call configure(java.util.Properties) in order to provide configuration, and then when the system is ready to work it will call start(). Providers can be used both on ZooKeeper servers and on ZooKeeper clients."}
{"index": 3126, "repo": "zookeeper-3.8.2", "code": "Class NetUtils {\n\t// Prefer using the hostname for formatting, but without requesting reverse DNS lookup.\n\tstatic String formatInetAddr(InetSocketAddress addr);\n\t// Separates host and port from given host port string if host port string is enclosed within square bracket.\n\tstatic String[] getIPV6HostAndPort(String hostPort);\n}", "des": "This class contains common utilities for netstuff. Like printing IPv6 literals correctly"}
{"index": 3127, "repo": "zookeeper-3.8.2", "code": "Class NullMetricsProvider {\n\t// Configure the provider.\n\tvoid configure(Properties configuration);\n\t// Dumps all metrics as a key-value pair.\n\tvoid dump(BiConsumer<String,Object> sink);\n\t// Provides access to the root context.\n\tMetricsContext getRootContext();\n\t// Reset all values.\n\tvoid resetAllValues();\n\t// Start the provider.\n\tvoid start();\n\t// Releases resources held by the provider. This method must not throw exceptions. This method can be called more than once.\n\tvoid stop();\n}", "des": "This is a dummy MetricsProvider which does nothing."}
{"index": 3128, "repo": "zookeeper-3.8.2", "code": "Class ObserverRequestProcessor {\n\t// Simply queue the request, which will be processed in FIFO order.\n\tvoid processRequest(Request request);\n\tvoid run();\n\t// Shutdown the processor.\n\tvoid shutdown();\n}", "des": "This RequestProcessor forwards any requests that modify the state of the system to the Leader."}
{"index": 3129, "repo": "zookeeper-3.8.2", "code": "Class OSMXBean {\n\t// Get the number of the maximum file descriptors the system can use.\n\tlong getMaxFileDescriptorCount();\n\t// Get the number of opened filed descriptor for the runtime jvm.\n\tlong getOpenFileDescriptorCount();\n\t// Check if the OS is unix.\n\tboolean getUnix();\n}", "des": "This class is a wrapper for the implementation of com.sun.management.UnixOperatingSystemMXBean It will decide to use the sun api or its own implementation depending on the runtime (vendor) used."}
{"index": 3130, "repo": "zookeeper-3.8.2", "code": "Class PathTrie {\n\t// Add a path to the path trie.\n\tvoid addPath(String path);\n\t// Clear all nodes in the trie.\n\tvoid clear();\n\t// Delete a path from the trie.\n\tvoid deletePath(String path);\n\t// Return true if the given path exists in the trie, otherwise return false; All paths are relative to the root node.\n\tboolean existsNode(String path);\n\t// Return the largest prefix for the input path.\n\tString findMaxPrefix(String path);\n}", "des": "a class that implements prefix matching for components of a filesystem path. the trie looks like a tree with edges mapping to the component of a path. example /ab/bc/cf would map to a trie / ab/ (ab) bc/ / (bc) cf/ (cf)"}
{"index": 3131, "repo": "zookeeper-3.8.2", "code": "Class PathUtils {\n\t// return the top namespace of a znode path\n\tstatic String getTopNamespace(String path);\n\t// Convert Windows path to Unix\n\tstatic String normalizeFileSystemPath(String path);\n\t// Validate the provided znode path string\n\tstatic void validatePath(String path);\n\t// validate the provided znode path string\n\tstatic void validatePath(String path, boolean isSequential);\n}", "des": "Path related utilities"}
{"index": 3132, "repo": "zookeeper-3.8.2", "code": "Class QuorumHierarchical {\n\t// Verifies if a given set is a quorum.\n\tboolean containsQuorum(Set<Long> set);\n\tboolean equals(Object o);\n\tMap<Long,QuorumPeer.QuorumServer> getAllMembers();\n\tMap<Long,QuorumPeer.QuorumServer> getObservingMembers();\n\tlong getVersion();\n\tMap<Long,QuorumPeer.QuorumServer> getVotingMembers();\n\t// Returns the weight of a server.\n\tlong getWeight(long id);\n\tvoid setVersion(long ver);\n}", "des": "This class implements a validator for hierarchical quorums. With this construction, zookeeper servers are split into disjoint groups, and each server has a weight. We obtain a quorum if we get more than half of the total weight of a group for a majority of groups. The configuration of quorums uses two parameters: group and weight. Groups are sets of ZooKeeper servers, and we set a group by passing a colon-separated list of server ids. It is also necessary to assign weights to server. Here is an example of a configuration that creates three groups and assigns a weight of 1 to each server: group.1=1:2:3 group.2=4:5:6 group.3=7:8:9 weight.1=1 weight.2=1 weight.3=1 weight.4=1 weight.5=1 weight.6=1 weight.7=1 weight.8=1 weight.9=1 Note that it is still necessary to define peers using the server keyword."}
{"index": 3133, "repo": "zookeeper-3.8.2", "code": "Class QuorumMaj {\n\t// Verifies if a set is a majority.\n\tboolean containsQuorum(Set<Long> ackSet);\n\tboolean equals(Object o);\n\tMap<Long,QuorumPeer.QuorumServer> getAllMembers();\n\tMap<Long,QuorumPeer.QuorumServer> getObservingMembers();\n\tlong getVersion();\n\tMap<Long,QuorumPeer.QuorumServer> getVotingMembers();\n\t// Returns weight of 1 by default.\n\tlong getWeight(long id);\n\tvoid setVersion(long ver);\n}", "des": "This class implements a validator for majority quorums. The implementation is straightforward."}
{"index": 3134, "repo": "zookeeper-3.8.2", "code": "Enum QuorumPeer.SyncMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QuorumPeer.SyncMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QuorumPeer.SyncMode[] values();\n}", "des": "(Used for monitoring) When peer is in synchronization phase, this shows which synchronization mechanism is being used"}
{"index": 3135, "repo": "zookeeper-3.8.2", "code": "Enum QuorumPeer.ZabState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QuorumPeer.ZabState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QuorumPeer.ZabState[] values();\n}", "des": "(Used for monitoring) shows the current phase of Zab protocol that peer is running."}
{"index": 3136, "repo": "zookeeper-3.8.2", "code": "Class QuorumPeerMain {\n\t// Shutdowns properly the service, this method is not a public API.\n\tvoid close();\n\tprotected QuorumPeer getQuorumPeer();\n\tprotected void initializeAndRun(String[] args);\n\t// To start the replicated server specify the configuration file name on the command line.\n\tstatic void main(String[] args);\n\tvoid runFromConfig(QuorumPeerConfig config);\n}", "des": "Configuration file When the main() method of this class is used to start the program, the first argument is used as a path to the config file, which will be used to obtain configuration information. This file is a Properties file, so keys and values are separated by equals (=) and the key/value pairs are separated by new lines. The following is a general summary of keys used in the configuration file. For full details on this see the documentation in docs/index.html dataDir - The directory where the ZooKeeper data is stored. dataLogDir - The directory where the ZooKeeper transaction log is stored. clientPort - The port used to communicate with clients. tickTime - The duration of a tick in milliseconds. This is the basic unit of time in ZooKeeper. initLimit - The maximum number of ticks that a follower will wait to initially synchronize with a leader. syncLimit - The maximum number of ticks that a follower will wait for a message (including heartbeats) from the leader. server.id - This is the host:port[:port] that the server with the given id will use for the quorum protocol. In addition to the config file. There is a file in the data directory called \"myid\" that contains the server id as an ASCII decimal value."}
{"index": 3137, "repo": "zookeeper-3.8.2", "code": "Class Quotas {\n\t// return the limit quota path associated with this prefix\n\tstatic String limitPath(String path);\n\t// return the quota path associated with this prefix\n\tstatic String quotaPath(String path);\n\t// return the stat quota path associated with this prefix.\n\tstatic String statPath(String path);\n\t// return the real path associated with this quotaPath.\n\tstatic String trimQuotaPath(String quotaPath);\n}", "des": "this class manages quotas and has many other utils for quota"}
{"index": 3138, "repo": "zookeeper-3.8.2", "code": "Class ServiceUtils {\n\t// Force shutdown of the JVM using System.exit.\n\tstatic void requestSystemExit(int code);\n\t// Override system callback.\n\tstatic void setSystemExitProcedure(Consumer<Integer> systemExitProcedure);\n}", "des": "Utilities for service management."}
{"index": 3139, "repo": "zookeeper-3.8.2", "code": "Class SetQuotaCommand {\n\t// this method creates a quota node for the path\n\tstatic boolean createQuota(ZooKeeper zk, String path, StatsTrack quota);\n\tboolean exec();\n\t// parse the command arguments\n\tCliCommand parse(String[] cmdArgs);\n}", "des": "setQuota command for cli"}
{"index": 3140, "repo": "zookeeper-3.8.2", "code": "Class Shell.ShellCommandExecutor {\n\t// Execute the shell command.\n\tvoid execute();\n\t// return an array containing the command name and its parameters\n\tprotected String[] getExecString();\n\t// Get the output of the shell command.\n\tString getOutput();\n\t// Parse the execution result\n\tprotected void parseExecResult(BufferedReader lines);\n}", "des": "A simple shell command executor. ShellCommandExecutorshould be used in cases where the output of the command needs no explicit parsing and where the command, working directory and the environment remains unchanged. The output of the command is stored as-is and is expected to be small."}
{"index": 3141, "repo": "zookeeper-3.8.2", "code": "Class StaticHostProvider {\n\tInetSocketAddress getServerAtCurrentIndex();\n\tInetSocketAddress getServerAtIndex(int i);\n\t// The next host to try to connect to.\n\tInetSocketAddress next(long spinDelay);\n\t// Notify the HostProvider of a successful connection.\n\tvoid onConnected();\n\tint size();\n\t// Update the list of servers.\n\tboolean updateServerList(Collection<InetSocketAddress> serverAddresses, InetSocketAddress currentHost);\n}", "des": "Most simple HostProvider, resolves on every next() call. Please be aware that although this class doesn't do any DNS caching, there're multiple levels of caching already present across the stack like in JVM, OS level, hardware, etc. The best we could do here is to get the most recent address from the underlying system which is considered up-to-date."}
{"index": 3142, "repo": "zookeeper-3.8.2", "code": "Class SyncRequestProcessor {\n\t// used by tests to get the snapcount\n\tstatic int getSnapCount();\n\tvoid processRequest(Request request);\n\tvoid run();\n\t// used by tests to check for changing snapcounts\n\tstatic void setSnapCount(int count);\n\t// used by tests to check for changing snapcounts\n\tstatic void setSnapSizeInBytes(long size);\n\tvoid shutdown();\n}", "des": "This RequestProcessor logs requests to disk. It batches the requests to do the io efficiently. The request is not passed to the next RequestProcessor until its log has been synced to disk. SyncRequestProcessor is used in 3 different cases 1. Leader - Sync request to disk and forward it to AckRequestProcessor which send ack back to itself. 2. Follower - Sync request to disk and forward request to SendAckRequestProcessor which send the packets to leader. SendAckRequestProcessor is flushable which allow us to force push packets to leader. 3. Observer - Sync committed request to disk (received as INFORM packet). It never send ack back to the leader, so the nextProcessor will be null. This change the semantic of txnlog on the observer since it only contains committed txns."}
{"index": 3143, "repo": "zookeeper-3.8.2", "code": "Interface Testable {\n\t// Cause the ZooKeeper instance to behave as if the session expired\n\tvoid injectSessionExpiration();\n\t// Allow an event to be inserted into the event queue\n\tvoid queueEvent(WatchedEvent event);\n}", "des": "Abstraction that exposes various methods useful for testing ZooKeeper"}
{"index": 3144, "repo": "zookeeper-3.8.2", "code": "Interface TxnLog.TxnIterator {\n\t// close files and release the resources\n\tvoid close();\n\tTxnDigest getDigest();\n\t// return the transaction header.\n\tTxnHeader getHeader();\n\t// Get an estimated storage space used to store transaction records that will return by this iterator\n\tlong getStorageSize();\n\t// return the transaction record.\n\tRecord getTxn();\n\t// go to the next transaction record.\n\tboolean next();\n}", "des": "an iterating interface for reading transaction logs."}
{"index": 3145, "repo": "zookeeper-3.8.2", "code": "Class TxnLogProposalIterator {\n\t// Close the files and release the resources which are used for iterating transaction records\n\tvoid close();\n\tboolean hasNext();\n\t// Proposal returned by this iterator has request part set to null, since it is not used for follower sync-up.\n\tLeader.Proposal next();\n\tvoid remove();\n}", "des": "This class provides an iterator interface to access Proposal deserialized from on-disk txnlog. The iterator deserializes one proposal at a time to reduce memory footprint. Note that the request part of the proposal is not initialized and set to null since we don't need it during follower sync-up."}
{"index": 3146, "repo": "zookeeper-3.8.2", "code": "Class WatchDeregistration {\n\t// Returns client path which has specified for unregistering its watcher\n\tString getClientPath();\n\t// Unregistering watcher that was added on path.\n\tMap<Watcher.Event.EventType,Set<Watcher>> unregister(int rc);\n}", "des": "Handles the special case of removing watches which has registered for a client path"}
{"index": 3147, "repo": "zookeeper-3.8.2", "code": "Enum Watcher.Event.EventType {\n\tstatic Watcher.Event.EventType fromInt(int intValue);\n\tint getIntValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Watcher.Event.EventType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Watcher.Event.EventType[] values();\n}", "des": "Enumeration of types of events that may occur on the ZooKeeper"}
{"index": 3148, "repo": "zookeeper-3.8.2", "code": "Enum Watcher.Event.KeeperState {\n\tstatic Watcher.Event.KeeperState fromInt(int intValue);\n\tint getIntValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Watcher.Event.KeeperState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Watcher.Event.KeeperState[] values();\n}", "des": "Enumeration of states the ZooKeeper may be at the event"}
{"index": 3149, "repo": "zookeeper-3.8.2", "code": "Enum Watcher.WatcherType {\n\tstatic Watcher.WatcherType fromInt(int intValue);\n\tint getIntValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Watcher.WatcherType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Watcher.WatcherType[] values();\n}", "des": "Enumeration of types of watchers"}
{"index": 3150, "repo": "zookeeper-3.8.2", "code": "Class WatchesPathReport {\n\t// Gets the session IDs of sessions that have set watches on the given path.\n\tSet<Long> getSessions(String path);\n\t// Checks if the given path has watches set.\n\tboolean hasSessions(String path);\n\t// Converts this report to a map.\n\tMap<String,Set<Long>> toMap();\n}", "des": "A watch report, essentially a mapping of path to session IDs of sessions that have set a watch on that path. This class is immutable."}
{"index": 3151, "repo": "zookeeper-3.8.2", "code": "Class WatchesReport {\n\t// Gets the paths that the given session has set watches on.\n\tSet<String> getPaths(long sessionId);\n\t// Checks if the given session has watches set.\n\tboolean hasPaths(long sessionId);\n\t// Converts this report to a map.\n\tMap<Long,Set<String>> toMap();\n}", "des": "A watch report, essentially a mapping of session ID to paths that the session has set a watch on. This class is immutable."}
{"index": 3152, "repo": "zookeeper-3.8.2", "code": "Class WatchesSummary {\n\t// Gets the number of connections (sessions) that have set watches.\n\tint getNumConnections();\n\t// Gets the number of paths that have watches set on them.\n\tint getNumPaths();\n\t// Gets the total number of watches set.\n\tint getTotalWatches();\n\t// Converts this summary to a map.\n\tMap<String,Object> toMap();\n}", "des": "A summary of watch information. This class is immutable."}
{"index": 3153, "repo": "zookeeper-3.8.2", "code": "Class WorkerService {\n\tvoid join(long shutdownTimeoutMS);\n\t// Schedule work to be done.\n\tvoid schedule(WorkerService.WorkRequest workRequest);\n\t// Schedule work to be done by the thread assigned to this id.\n\tvoid schedule(WorkerService.WorkRequest workRequest, long id);\n\tvoid start();\n\tvoid stop();\n}", "des": "WorkerService is a worker thread pool for running tasks and is implemented using one or more ExecutorServices. A WorkerService can support assignable threads, which it does by creating N separate single thread ExecutorServices, or non-assignable threads, which it does by creating a single N-thread ExecutorService. - NIOServerCnxnFactory uses a non-assignable WorkerService because the socket IO requests are order independent and allowing the ExecutorService to handle thread assignment gives optimal performance. - CommitProcessor uses an assignable WorkerService because requests for a given session must be processed in order. ExecutorService provides queue management and thread restarting, so it's useful even with a single thread."}
{"index": 3154, "repo": "zookeeper-3.8.2", "code": "Class WorkerService.WorkRequest {\n\t// (Optional) If implemented, is called if the service is stopped or unable to schedule the request.\n\tvoid cleanup();\n\t// Must be implemented.\n\tabstract void doWork();\n}", "des": "Callers should implement a class extending WorkRequest in order to schedule work with the service."}
{"index": 3155, "repo": "zookeeper-3.8.2", "code": "Enum X509Util.ClientAuth {\n\t// Converts a property value to a ClientAuth enum.\n\tstatic X509Util.ClientAuth fromPropertyValue(String prop);\n\tio.netty.handler.ssl.ClientAuth toNettyClientAuth();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic X509Util.ClientAuth valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic X509Util.ClientAuth[] values();\n}", "des": "Enum specifying the client auth requirement of server-side TLS sockets created by this X509Util. NONE - do not request a client certificate. WANT - request a client certificate, but allow anonymous clients to connect. NEED - require a client certificate, disconnect anonymous clients. If the config property is not set, the default value is NEED."}
{"index": 3156, "repo": "zookeeper-3.8.2", "code": "Class ZKClientConfig {\n\t// Get the value of the key property as an long.\n\tlong getLong(String key, long defaultValue);\n\t// Now onwards client code will use properties from this class but older clients still be setting properties through system properties.\n\tprotected void handleBackwardCompatibility();\n\t// Returns true if the SASL client is enabled.\n\tboolean isSaslClientEnabled();\n}", "des": "Handles client specific properties"}
{"index": 3157, "repo": "zookeeper-3.8.2", "code": "Class ZooKeeper.WatchRegistration {\n\tprotected abstract Map<String,Set<Watcher>> getWatches(int rc);\n\t// Register the watcher with the set of watches on path.\n\tvoid register(int rc);\n\t// Determine whether the watch should be added based on return code.\n\tprotected boolean shouldAddWatch(int rc);\n}", "des": "Register a watcher for a particular path."}
{"index": 3158, "repo": "zookeeper-3.8.2", "code": "Interface ZooKeeperServerEmbedded {\n\tstatic ZooKeeperServerEmbedded.ZookKeeperServerEmbeddedBuilder builder();\n\t// Shutdown gracefully the server and wait for resources to be released.\n\tvoid close();\n\t// Get a connection string useful for the client.\n\tString getConnectionString();\n\tString getSecureConnectionString();\n\t// Start the server.\n\tvoid start();\n\t// Start the server\n\tvoid start(long startupTimeout);\n}", "des": "This API allows you to start a ZooKeeper server node from Java code"}
{"index": 3159, "repo": "zookeeper-3.8.2", "code": "Class ZooKeeperServerMain {\n\t// Shutdowns properly the service, this method is not a public API.\n\tvoid close();\n\tprotected void initializeAndRun(String[] args);\n\tstatic void main(String[] args);\n\t// Run from a ServerConfig.\n\tvoid runFromConfig(ServerConfig config);\n\tprotected void serverStarted();\n\t// Shutdown the serving instance\n\tprotected void shutdown();\n}", "des": "This class starts and runs a standalone ZooKeeperServer."}
{"index": 3160, "repo": "camel-core-3.0.0-RC1", "code": "Enum Any23Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Any23Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Any23Type[] values();\n}", "des": "Represents the different types of bindy data formats."}
{"index": 3161, "repo": "camel-core-3.0.0-RC1", "code": "Class ASN1DataFormat {\n\tString getClazzName();\n\tBoolean getUsingIterator();\n\t// Name of class to use when unmarshalling\n\tvoid setClazzName(String clazzName);\n\t// If the asn1 file has more then one entry, the setting this option to true, allows to work with the splitter EIP, to split the data using an iterator in a streaming mode.\n\tvoid setUsingIterator(Boolean usingIterator);\n}", "des": "The ASN.1 data format is used for file transfer with telecommunications protocols."}
{"index": 3162, "repo": "camel-core-3.0.0-RC1", "code": "Class BarcodeDataFormat {\n\tString getBarcodeFormat();\n\tInteger getHeight();\n\tString getImageType();\n\tInteger getWidth();\n\t// Barcode format such as QR-Code\n\tvoid setBarcodeFormat(String barcodeFormat);\n\t// Height of the barcode\n\tvoid setHeight(Integer height);\n\t// Image type of the barcode such as png\n\tvoid setImageType(String imageType);\n\t// Width of the barcode\n\tvoid setWidth(Integer width);\n}", "des": "The Barcode data format is used for creating barccode images (such as QR-Code)"}
{"index": 3163, "repo": "camel-core-3.0.0-RC1", "code": "Class Base64DataFormat {\n\tInteger getLineLength();\n\tString getLineSeparator();\n\tBoolean getUrlSafe();\n\t// To specific a maximum line length for the encoded data.\n\tvoid setLineLength(Integer lineLength);\n\t// The line separators to use.\n\tvoid setLineSeparator(String lineSeparator);\n\t// Instead of emitting '+' and '/' we emit '-' and '_' respectively.\n\tvoid setUrlSafe(Boolean urlSafe);\n}", "des": "The Base64 data format is used for base64 encoding and decoding."}
{"index": 3164, "repo": "camel-core-3.0.0-RC1", "code": "Enum BindyType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BindyType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BindyType[] values();\n}", "des": "Represents the different types of bindy data formats."}
{"index": 3165, "repo": "camel-core-3.0.0-RC1", "code": "Enum ClaimCheckOperation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClaimCheckOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClaimCheckOperation[] values();\n}", "des": "Operations for the Claim Check EIP."}
{"index": 3166, "repo": "camel-core-3.0.0-RC1", "code": "Class ConvertBodyDefinition {\n\tString getCharset();\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\tString getType();\n\tClass<?> getTypeClass();\n\t// To use a specific charset when converting\n\tvoid setCharset(String charset);\n\t// The java type to convert to\n\tvoid setType(String type);\n\tvoid setTypeClass(Class<?> typeClass);\n}", "des": "Converts the message body to another type"}
{"index": 3167, "repo": "camel-core-3.0.0-RC1", "code": "Class CustomDataFormat {\n\t// Reference to the custom DataFormat to lookup from the Camel registry.\n\tString getRef();\n\t// Reference to the custom DataFormat to lookup from the Camel registry.\n\tvoid setRef(String ref);\n}", "des": "To use a custom data format implementation that does not come out of the box from Apache Camel."}
{"index": 3168, "repo": "camel-core-3.0.0-RC1", "code": "Class CustomLoadBalancerDefinition {\n\torg.apache.camel.processor.loadbalancer.LoadBalancer getCustomLoadBalancer();\n\tString getRef();\n\t// The custom load balancer to use.\n\tvoid setCustomLoadBalancer(org.apache.camel.processor.loadbalancer.LoadBalancer loadBalancer);\n\t// Refers to the custom load balancer to lookup from the registry\n\tvoid setRef(String ref);\n}", "des": "Custom load balancer"}
{"index": 3169, "repo": "camel-core-3.0.0-RC1", "code": "Class CustomTransformerDefinition {\n\tString getClassName();\n\tString getRef();\n\t// Set a class name of the Transformer\n\tvoid setClassName(String className);\n\t// Set a bean reference of the Transformer\n\tvoid setRef(String ref);\n}", "des": "Represents a CustomTransformer. One of the bean reference (ref) or fully qualified class name (type) of the custom Transformer needs to be specified. TransformerDefinition Transformer"}
{"index": 3170, "repo": "camel-core-3.0.0-RC1", "code": "Class CustomValidatorDefinition {\n\tString getClassName();\n\tString getRef();\n\t// Set a class name of the Validator\n\tvoid setClassName(String className);\n\t// Set a bean reference of the Validator\n\tvoid setRef(String ref);\n}", "des": "Represents a CustomValidator. One of the bean reference (ref) or fully qualified class name (className) of the custom Validator needs to be specified. ValidatorDefinition Validator"}
{"index": 3171, "repo": "camel-core-3.0.0-RC1", "code": "Enum DataFormatClause.Operation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DataFormatClause.Operation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DataFormatClause.Operation[] values();\n}", "des": "DataFormat operations."}
{"index": 3172, "repo": "camel-core-3.0.0-RC1", "code": "Class DataFormatTransformerDefinition {\n\tDataFormatDefinition getDataFormatType();\n\tString getRef();\n\t// The data format to be used\n\tvoid setDataFormatType(DataFormatDefinition dataFormatType);\n\t// Set the reference of the DataFormat.\n\tvoid setRef(String ref);\n}", "des": "Represents a DataFormatTransformer which leverages DataFormat to perform transformation. One of the DataFormat 'ref' or DataFormat 'type' needs to be specified. TransformerDefinition DataFormatTransformer"}
{"index": 3173, "repo": "camel-core-3.0.0-RC1", "code": "Class DescriptionDefinition {\n\tString getLang();\n\tString getText();\n\t// Language, such as en for english.\n\tvoid setLang(String lang);\n\t// The description as human readable text\n\tvoid setText(String text);\n}", "des": "To provide comments about the node."}
{"index": 3174, "repo": "camel-core-3.0.0-RC1", "code": "Interface EndpointConsumerBuilder {\n\t// Builds the url of this endpoint.\n\tString getUri();\n\t// Builds and resolves this endpoint DSL as an endpoint.\n\torg.apache.camel.Endpoint resolve(org.apache.camel.CamelContext context);\n\t// Adds an option to this endpoint.\n\tvoid setProperty(String name, Object value);\n}", "des": "Type-safe endpoint DSL for building consumer endpoints."}
{"index": 3175, "repo": "camel-core-3.0.0-RC1", "code": "Interface EndpointProducerBuilder {\n\t// Builds an expression of this endpoint url.\n\torg.apache.camel.Expression expr();\n\t// Builds the url of this endpoint.\n\tString getUri();\n\t// Builds and resolves this endpoint DSL as an endpoint.\n\torg.apache.camel.Endpoint resolve(org.apache.camel.CamelContext context);\n\t// Adds an option to this endpoint.\n\tvoid setProperty(String name, Object value);\n}", "des": "Type-safe endpoint DSL for building producer endpoints."}
{"index": 3176, "repo": "camel-core-3.0.0-RC1", "code": "Class EndpointTransformerDefinition {\n\tString getRef();\n\tString getUri();\n\t// Set the reference of the Endpoint.\n\tvoid setRef(String ref);\n\t// Set the URI of the Endpoint.\n\tvoid setUri(String uri);\n}", "des": "Represents an endpoint Transformer which leverages camel Endpoint to perform transformation. A ProcessorTransformer will be created internally with a SendProcessor which forwards the message to the specified Endpoint. One of the Endpoint 'ref' or 'uri' needs to be specified. TransformerDefinition ProcessorTransformer"}
{"index": 3177, "repo": "camel-core-3.0.0-RC1", "code": "Class EndpointValidatorDefinition {\n\tString getRef();\n\tString getUri();\n\t// Set the reference of the Endpoint.\n\tvoid setRef(String ref);\n\t// Set the URI of the Endpoint.\n\tvoid setUri(String uri);\n}", "des": "Represents an endpoint Validator which leverages camel validator component such as Validator Component and Bean Validator Component to perform content validation. A ProcessorValidator will be created internally with a SendProcessor which forwards the message to the validator Endpoint. ValidatorDefinition Validator"}
{"index": 3178, "repo": "camel-core-3.0.0-RC1", "code": "Interface ErrorHandlerBuilder {\n\t// Clones this builder so each RouteBuilder has its private builder to use, to avoid changes from one RouteBuilder to influence the others.\n\tErrorHandlerBuilder cloneBuilder();\n\t// Whether this error handler supports transacted exchanges.\n\tboolean supportTransacted();\n}", "des": "A builder of a Error Handler"}
{"index": 3179, "repo": "camel-core-3.0.0-RC1", "code": "Interface ExecutorServiceAwareDefinition<Type extends ProcessorDefinition<?>> {\n\t// Setting the executor service for executing\n\tType executorService(ExecutorService executorService);\n\t// Setting the executor service for executing\n\tdefault Type executorService(Supplier<ExecutorService> executorService);\n\t// Setting the executor service for executing\n\tType executorServiceRef(String executorServiceRef);\n}", "des": "Enables definitions to support concurrency using ExecutorService"}
{"index": 3180, "repo": "camel-core-3.0.0-RC1", "code": "Class ExpressionNodeHelper {\n\t// Determines which ExpressionDefinition describes the given expression best possible.\n\tstatic ExpressionDefinition toExpressionDefinition(org.apache.camel.Expression expression);\n\t// Determines which ExpressionDefinition describes the given predicate best possible.\n\tstatic ExpressionDefinition toExpressionDefinition(org.apache.camel.Predicate predicate);\n}", "des": "Helper for ExpressionNode"}
{"index": 3181, "repo": "camel-core-3.0.0-RC1", "code": "Class FilterDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// Expression to determine if the message should be filtered or not.\n\tvoid setExpression(ExpressionDefinition expression);\n}", "des": "Filter out messages based using a predicate"}
{"index": 3182, "repo": "camel-core-3.0.0-RC1", "code": "Class GlobalOptionDefinition {\n\tString getKey();\n\tString getValue();\n\t// Global option key\n\tvoid setKey(String key);\n\t// Global option value\n\tvoid setValue(String value);\n}", "des": "Models a string key/value pair for configuring some global options on a Camel context such as max debug log length."}
{"index": 3183, "repo": "camel-core-3.0.0-RC1", "code": "Class HL7DataFormat {\n\tObject getParser();\n\tBoolean getValidate();\n\tboolean isValidate();\n\t// To use a custom HL7 parser\n\tvoid setParser(Object parser);\n\t// Whether to validate the HL7 message Is by default true.\n\tvoid setValidate(Boolean validate);\n}", "des": "The HL7 data format can be used to marshal or unmarshal HL7 (Health Care) model objects."}
{"index": 3184, "repo": "camel-core-3.0.0-RC1", "code": "Class IdentifiedType {\n\t// Gets the value of the id property.\n\tString getId();\n\t// Sets the value of the id property.\n\tvoid setId(String value);\n}", "des": "The unique identifier for a bean. The scope of the identifier is the enclosing bean factory."}
{"index": 3185, "repo": "camel-core-3.0.0-RC1", "code": "Class InputTypeDefinition {\n\tString getLabel();\n\tString getShortName();\n\t// Get input type URN.\n\tString getUrn();\n\t// Get if validation is required for this input type.\n\tboolean isValidate();\n\t// Set input type via Java Class.\n\tvoid setJavaClass(Class<?> clazz);\n\t// Set input type URN.\n\tvoid setUrn(String urn);\n\t// Set if validation is required for this input type.\n\tvoid setValidate(boolean validate);\n}", "des": "Set the expected data type of the input message. If the actual message type is different at runtime, camel look for a required Transformer and apply if exists. If validate attribute is true then camel applies Validator as well. Type name consists of two parts, 'scheme' and 'name' connected with ':'. For Java type 'name' is a fully qualified class name. For example java:java.lang.String, json:ABCOrder. It's also possible to specify only scheme part, so that it works like a wildcard. If only 'xml' is specified, all the XML message matches. It's handy to add only one transformer/validator for all the transformation from/to XML."}
{"index": 3186, "repo": "camel-core-3.0.0-RC1", "code": "Class JsonApiDataFormat {\n\tClass<?>[] getDataFormatTypes();\n\tClass<?> getMainFormatType();\n\t// The classes to take into account for the marshalling\n\tvoid setDataFormatTypes(Class<?>[] dataFormatTypes);\n\t// The classes to take into account while unmarshalling\n\tvoid setMainFormatType(Class<?> mainFormatType);\n}", "des": "JsonApi data format is used for marshal and unmarshal Json API object."}
{"index": 3187, "repo": "camel-core-3.0.0-RC1", "code": "Enum JsonLibrary {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JsonLibrary valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JsonLibrary[] values();\n}", "des": "Represents the concrete Json libraries Camel supports."}
{"index": 3188, "repo": "camel-core-3.0.0-RC1", "code": "Class MarshalDefinition {\n\tprotected String description();\n\tDataFormatDefinition getDataFormatType();\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// The data format to be used\n\tvoid setDataFormatType(DataFormatDefinition dataFormatType);\n}", "des": "Marshals data into a specified format for transmission over a transport or component"}
{"index": 3189, "repo": "camel-core-3.0.0-RC1", "code": "Class NoErrorHandlerBuilder {\n\t// Clones this builder so each RouteBuilder has its private builder to use, to avoid changes from one RouteBuilder to influence the others.\n\tErrorHandlerBuilder cloneBuilder();\n\torg.apache.camel.Processor createErrorHandler(org.apache.camel.spi.RouteContext routeContext, org.apache.camel.Processor processor);\n\t// Whether this error handler supports transacted exchanges.\n\tboolean supportTransacted();\n}", "des": "A builder to disable the use of an error handler so that any exceptions are thrown. This not recommended in general, the Dead Letter Channel should be used if you are unsure; however it can be useful sometimes to disable an error handler inside a complex route so that exceptions bubble up to the parent Processor"}
{"index": 3190, "repo": "camel-core-3.0.0-RC1", "code": "Class OnFallbackDefinition {\n\tBoolean getFallbackViaNetwork();\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\tboolean isFallbackViaNetwork();\n\t// Whether the fallback goes over the network.\n\tvoid setFallbackViaNetwork(Boolean fallbackViaNetwork);\n}", "des": "Route to be executed when Hystrix EIP executes fallback"}
{"index": 3191, "repo": "camel-core-3.0.0-RC1", "code": "Interface OtherAttributesAware {\n\t// Adds optional attribute to use as property placeholder\n\tMap<QName,Object> getOtherAttributes();\n\t// Adds optional attribute to use as property placeholder\n\tvoid setOtherAttributes(Map<QName,Object> otherAttributes);\n}", "des": "Models can support being configured with any other attributes to shadow existing options to be used for property placeholders."}
{"index": 3192, "repo": "camel-core-3.0.0-RC1", "code": "Class OutputTypeDefinition {\n\tString getLabel();\n\tString getShortName();\n\t// Get output type URN.\n\tString getUrn();\n\t// Get if validation is required for this output type.\n\tboolean isValidate();\n\t// Set output type via Java Class.\n\tvoid setJavaClass(Class<?> clazz);\n\t// Set output type URN.\n\tvoid setUrn(String urn);\n\t// Set if validation is required for this output type.\n\tvoid setValidate(boolean validate);\n}", "des": "Set the expected data type of the output message. If the actual message type is different at runtime, camel look for a required Transformer and apply if exists. If validate attribute is true then camel applies Validator as well. Type name consists of two parts, 'scheme' and 'name' connected with ':'. For Java type 'name' is a fully qualified class name. For example java:java.lang.String, json:ABCOrder. It's also possible to specify only scheme part, so that it works like a wildcard. If only 'xml' is specified, all the XML message matches. It's handy to add only one transformer/validator for all the XML-Java transformation."}
{"index": 3193, "repo": "camel-core-3.0.0-RC1", "code": "Class PackageScanDefinition {\n\tprotected void clear();\n\tList<String> getExcludes();\n\tList<String> getIncludes();\n\tList<String> getPackages();\n\t// Exclude finding route builder from these java package names.\n\tvoid setExcludes(List<String> excludes);\n\t// Include finding route builder from these java package names.\n\tvoid setIncludes(List<String> includes);\n\t// Sets the java package names to use for scanning for route builder classes\n\tvoid setPackages(List<String> packages);\n}", "des": "Scans for Java RouteBuilder classes in java packages"}
{"index": 3194, "repo": "camel-core-3.0.0-RC1", "code": "Class ProcessDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\torg.apache.camel.Processor getProcessor();\n\tString getRef();\n\tString getShortName();\n\t// Reference to the Processor to lookup in the registry to use.\n\tvoid setRef(String ref);\n}", "des": "Calls a Camel processor"}
{"index": 3195, "repo": "camel-core-3.0.0-RC1", "code": "Class PropertyDefinition {\n\tString getKey();\n\tString getValue();\n\t// Property key\n\tvoid setKey(String key);\n\t// Property value\n\tvoid setValue(String value);\n}", "des": "A key value pair"}
{"index": 3196, "repo": "camel-core-3.0.0-RC1", "code": "Class ProtobufDataFormat {\n\tString getContentTypeFormat();\n\tObject getDefaultInstance();\n\tString getInstanceClass();\n\t// Defines a content type format in which protobuf message will be serialized/deserialized from(to) the Java been.\n\tvoid setContentTypeFormat(String contentTypeFormat);\n\tvoid setDefaultInstance(Object defaultInstance);\n\t// Name of class to use when unarmshalling\n\tvoid setInstanceClass(String instanceClass);\n}", "des": "The Protobuf data format is used for serializing between Java objects and the Google Protobuf protocol."}
{"index": 3197, "repo": "camel-core-3.0.0-RC1", "code": "Class ProxyBuilder {\n\t// Builds the proxy.\n\t<T> T build(Class<T>... interfaceClasses);\n\t// Builds the proxy.\n\t<T> T build(Class<T> interfaceClass);\n\t// Send the proxied message to this endpoint\n\tProxyBuilder endpoint(org.apache.camel.Endpoint endpoint);\n\t// Send the proxied message to this endpoint\n\tProxyBuilder endpoint(String url);\n}", "des": "A build to create Camel proxies."}
{"index": 3198, "repo": "camel-core-3.0.0-RC1", "code": "Class RemoveHeaderDefinition {\n\tString getHeaderName();\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// Name of header to remove\n\tvoid setHeaderName(String headerName);\n}", "des": "Removes a named header from the message"}
{"index": 3199, "repo": "camel-core-3.0.0-RC1", "code": "Class RemovePropertyDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getPropertyName();\n\tString getShortName();\n\t// Name of property to remove\n\tvoid setPropertyName(String propertyName);\n}", "des": "Removes a named property from the message exchange"}
{"index": 3200, "repo": "camel-core-3.0.0-RC1", "code": "Interface RestContainer {\n\t// Returns the RESTs\n\tList<RestDefinition> getRests();\n\t// Sets the RESTs to use\n\tvoid setRests(List<RestDefinition> rests);\n}", "des": "Container to hold Rest."}
{"index": 3201, "repo": "camel-core-3.0.0-RC1", "code": "Enum RestHostNameResolver {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RestHostNameResolver valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RestHostNameResolver[] values();\n}", "des": "To configure the rest hostname resolver"}
{"index": 3202, "repo": "camel-core-3.0.0-RC1", "code": "Enum RestParamType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RestParamType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RestParamType[] values();\n}", "des": "Rest parameter types"}
{"index": 3203, "repo": "camel-core-3.0.0-RC1", "code": "Class RestPropertyDefinition {\n\tString getKey();\n\tString getValue();\n\t// Property key\n\tvoid setKey(String key);\n\t// Property value\n\tvoid setValue(String value);\n}", "des": "A key value pair"}
{"index": 3204, "repo": "camel-core-3.0.0-RC1", "code": "Class RestSecurityApiKey {\n\tRestSecuritiesDefinition end();\n\tBoolean getInHeader();\n\tBoolean getInQuery();\n\tString getName();\n\t// To use header as the location of the API key.\n\tvoid setInHeader(Boolean inHeader);\n\t// To use query parameter as the location of the API key.\n\tvoid setInQuery(Boolean inQuery);\n\t// The name of the header or query parameter to be used.\n\tvoid setName(String name);\n\tRestSecurityApiKey withHeader(String name);\n\tRestSecurityApiKey withQuery(String name);\n}", "des": "Rest security basic auth definition"}
{"index": 3205, "repo": "camel-core-3.0.0-RC1", "code": "Class RestSecurityDefinition {\n\t// Ends the configuration of this security\n\tRestDefinition endSecurityDefinition();\n\tString getDescription();\n\tString getKey();\n\t// A short description for security scheme.\n\tvoid setDescription(String description);\n\t// Key used to refer to this security definition\n\tvoid setKey(String key);\n}", "des": "To specify the rest security definitions using Swagger."}
{"index": 3206, "repo": "camel-core-3.0.0-RC1", "code": "Interface RouteContainer {\n\t// Returns the routes\n\tList<RouteDefinition> getRoutes();\n\t// Sets the routes to use\n\tvoid setRoutes(List<RouteDefinition> routes);\n}", "des": "Container to hold Route."}
{"index": 3207, "repo": "camel-core-3.0.0-RC1", "code": "Enum SagaCompletionMode {\n\tstatic SagaCompletionMode defaultCompletionMode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SagaCompletionMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SagaCompletionMode[] values();\n}", "des": "Enumerates all saga completion modes."}
{"index": 3208, "repo": "camel-core-3.0.0-RC1", "code": "Class SagaOptionDefinition {\n\tExpressionDefinition getExpression();\n\tString getOptionName();\n\t// The expression to be used to determine the value of the option.\n\tvoid setExpression(ExpressionDefinition expression);\n\t// Name of the option.\n\tvoid setOptionName(String optionName);\n}", "des": "Allows to declare options on sagas"}
{"index": 3209, "repo": "camel-core-3.0.0-RC1", "code": "Enum SagaPropagation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SagaPropagation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SagaPropagation[] values();\n}", "des": "Enumerates all saga propagation modes."}
{"index": 3210, "repo": "camel-core-3.0.0-RC1", "code": "Class ScriptDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// Expression to return the transformed message body (the new message body to use)\n\tvoid setExpression(ExpressionDefinition expression);\n}", "des": "Executes a script from a language which does not change the message body."}
{"index": 3211, "repo": "camel-core-3.0.0-RC1", "code": "Class SecurityDefinition {\n\tString getKey();\n\tString getScopes();\n\t// Key used to refer to this security definition\n\tvoid setKey(String key);\n\t// The scopes to allow (separate multiple scopes by comma)\n\tvoid setScopes(String scopes);\n}", "des": "Rest security definition"}
{"index": 3212, "repo": "camel-core-3.0.0-RC1", "code": "Class SetBodyDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// Expression that returns the new body to use\n\tvoid setExpression(ExpressionDefinition expression);\n}", "des": "Sets the contents of the message body"}
{"index": 3213, "repo": "camel-core-3.0.0-RC1", "code": "Class SetExchangePatternDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\torg.apache.camel.ExchangePattern getPattern();\n\tString getShortName();\n\tSetExchangePatternDefinition pattern(org.apache.camel.ExchangePattern pattern);\n\t// Sets the new exchange pattern of the Exchange to be used from this point forward\n\tvoid setPattern(org.apache.camel.ExchangePattern pattern);\n}", "des": "Sets the exchange pattern on the message exchange"}
{"index": 3214, "repo": "camel-core-3.0.0-RC1", "code": "Class SetHeaderDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getName();\n\tString getShortName();\n\t// Expression to return the value of the header\n\tvoid setExpression(ExpressionDefinition expression);\n\t// Name of message header to set a new value The simple language can be used to define a dynamic evaluated header name to be used.\n\tvoid setName(String name);\n}", "des": "Sets the value of a message header"}
{"index": 3215, "repo": "camel-core-3.0.0-RC1", "code": "Class SetPropertyDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getName();\n\tString getShortName();\n\t// Expression to return the value of the message exchange property\n\tvoid setExpression(ExpressionDefinition expression);\n\t// Name of exchange property to set a new value.\n\tvoid setName(String name);\n}", "des": "Sets a named property on the message exchange"}
{"index": 3216, "repo": "camel-core-3.0.0-RC1", "code": "Class SimpleExpression {\n\torg.apache.camel.Expression createExpression(org.apache.camel.CamelContext camelContext);\n\torg.apache.camel.Predicate createPredicate(org.apache.camel.CamelContext camelContext);\n\tString getLanguage();\n\tClass<?> getResultType();\n\tString getResultTypeName();\n\t// Sets the class of the result type (type from output)\n\tvoid setResultType(Class<?> resultType);\n\t// Sets the class name of the result type (type from output)\n\tvoid setResultTypeName(String resultTypeName);\n}", "des": "To use Camels built-in Simple language in Camel expressions or predicates."}
{"index": 3217, "repo": "camel-core-3.0.0-RC1", "code": "Class ThriftDataFormat {\n\tString getContentTypeFormat();\n\tObject getDefaultInstance();\n\tString getInstanceClass();\n\t// Defines a content type format in which thrift message will be serialized/deserialized from(to) the Java been.\n\tvoid setContentTypeFormat(String contentTypeFormat);\n\tvoid setDefaultInstance(Object defaultInstance);\n\t// Name of class to use when unarmshalling\n\tvoid setInstanceClass(String instanceClass);\n}", "des": "The Thrift data format is used for serialization and deserialization of messages using Apache Thrift binary dataformat."}
{"index": 3218, "repo": "camel-core-3.0.0-RC1", "code": "Class TransformDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// Expression to return the transformed message body (the new message body to use)\n\tvoid setExpression(ExpressionDefinition expression);\n}", "des": "Transforms the message body based on an expression"}
{"index": 3219, "repo": "camel-core-3.0.0-RC1", "code": "Class TransformerDefinition {\n\tString getFromType();\n\tString getScheme();\n\tString getToType();\n\t// Set the 'from' data type using Java class.\n\tvoid setFromType(Class<?> clazz);\n\t// Set the 'from' data type name.\n\tvoid setFromType(String from);\n\t// Set a scheme name supported by the transformer.\n\tvoid setScheme(String scheme);\n\t// Set the 'to' data type using Java class.\n\tvoid setToType(Class<?> clazz);\n\t// Set the 'to' data type name.\n\tvoid setToType(String to);\n}", "des": ""}
{"index": 3220, "repo": "camel-core-3.0.0-RC1", "code": "Class UniVocityCsvDataFormat {\n\tString getDelimiter();\n\tString getQuote();\n\tBoolean getQuoteAllFields();\n\tString getQuoteEscape();\n\t// The delimiter of values\n\tvoid setDelimiter(String delimiter);\n\t// The quote symbol.\n\tvoid setQuote(String quote);\n\t// Whether or not all values must be quoted when writing them.\n\tvoid setQuoteAllFields(Boolean quoteAllFields);\n\t// The quote escape symbol\n\tvoid setQuoteEscape(String quoteEscape);\n}", "des": "The uniVocity CSV data format is used for working with CSV (Comma Separated Values) flat payloads."}
{"index": 3221, "repo": "camel-core-3.0.0-RC1", "code": "Class UniVocityFixedWidthDataFormat {\n\tString getPadding();\n\tBoolean getRecordEndsOnNewline();\n\tBoolean getSkipTrailingCharsUntilNewline();\n\t// The padding character.\n\tvoid setPadding(String padding);\n\t// Whether or not the record ends on new line.\n\tvoid setRecordEndsOnNewline(Boolean recordEndsOnNewline);\n\t// Whether or not the trailing characters until new line must be ignored.\n\tvoid setSkipTrailingCharsUntilNewline(Boolean skipTrailingCharsUntilNewline);\n}", "des": "The uniVocity Fixed Length data format is used for working with fixed length flat payloads."}
{"index": 3222, "repo": "camel-core-3.0.0-RC1", "code": "Class UniVocityHeader {\n\tInteger getLength();\n\tString getName();\n\t// Header length\n\tvoid setLength(Integer length);\n\t// Header name\n\tvoid setName(String name);\n}", "des": "To configure headers for UniVocity data formats."}
{"index": 3223, "repo": "camel-core-3.0.0-RC1", "code": "Class UnmarshalDefinition {\n\tprotected String description();\n\tDataFormatDefinition getDataFormatType();\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// The data format to be used\n\tvoid setDataFormatType(DataFormatDefinition dataFormatType);\n}", "des": "Converts the message data received from the wire into a format that Apache Camel processors can consume"}
{"index": 3224, "repo": "camel-core-3.0.0-RC1", "code": "Class ValidateDefinition {\n\t// Returns a label to describe this node such as the expression if some kind of expression node\n\tString getLabel();\n\tString getShortName();\n\t// Expression to use for validation as a predicate.\n\tvoid setExpression(ExpressionDefinition expression);\n}", "des": "Validates a message based on an expression"}
{"index": 3225, "repo": "camel-core-3.0.0-RC1", "code": "Class ValidatorDefinition {\n\tString getType();\n\t// Set the data type using Java class.\n\tvoid setType(Class<?> clazz);\n\t// Set the data type name.\n\tvoid setType(String type);\n}", "des": ""}
{"index": 3226, "repo": "camel-core-3.0.0-RC1", "code": "Enum YAMLLibrary {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic YAMLLibrary valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic YAMLLibrary[] values();\n}", "des": "Represents the concrete Yaml libraries Camel supports."}
{"index": 3227, "repo": "beam-sdks-java-core-2.49.0", "code": "Class AddFields.Inner<T> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<Row> expand(PCollection<T> input);\n\t// Add a new field of the specified type.\n\tAddFields.Inner<T> field(java.lang.String fieldName, Schema.FieldType fieldType);\n\t// Add a new field of the specified type.\n\tAddFields.Inner<T> field(java.lang.String fieldName, Schema.FieldType fieldType, java.lang.Object defaultValue);\n}", "des": "Inner PTransform for AddFields."}
{"index": 3228, "repo": "beam-sdks-java-core-2.49.0", "code": "Class AfterSynchronizedProcessingTime {\n\tboolean equals(@Nullable java.lang.Object obj);\n\t// Subclasses should override this to return the Trigger.getContinuationTrigger() of this Trigger.\n\tprotected Trigger getContinuationTrigger(java.util.List<Trigger> continuationTriggers);\n\t// For internal use only; no backwards-compatibility guarantees.\n\torg.joda.time.Instant getWatermarkThatGuaranteesFiring(BoundedWindow window);\n\tstatic AfterSynchronizedProcessingTime ofFirstElement();\n}", "des": "FOR INTERNAL USE ONLY. A trigger that fires after synchronized processing time has reached the processing time of the first element's arrival."}
{"index": 3229, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ApproximateUnique.Globally<T> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<java.lang.Long> expand(PCollection<T> input);\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n}", "des": "PTransform for estimating the number of distinct elements in a PCollection."}
{"index": 3230, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ApproximateUnique.PerKey<K,V> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<KV<K,java.lang.Long>> expand(PCollection<KV<K,V>> input);\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n}", "des": "PTransform for estimating the number of distinct values associated with each key in a PCollection of KVs."}
{"index": 3231, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface BackOff {\n\t// Gets the number of milliseconds to wait before retrying the operation or STOP to indicate that no retries should be made.\n\tlong nextBackOffMillis();\n\t// Reset to initial state.\n\tvoid reset();\n}", "des": "Back-off policy when retrying an operation."}
{"index": 3232, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface BagState<T> {\n\t// Read the current value, blocking until it is available.\n\tjava.lang.Iterable<T> read();\n\t// Indicate that the value will be read later.\n\tBagState<T> readLater();\n}", "des": "A ReadableState cell containing a bag of values. Items can be added to the bag and the contents read out."}
{"index": 3233, "repo": "beam-sdks-java-core-2.49.0", "code": "Class BlockBasedSource<T> {\n\t// Creates a BlockBasedSource for the specified range in a single file.\n\tprotected abstract BlockBasedSource<T> createForSubrangeOfFile(MatchResult.Metadata metadata, long start, long end);\n\t// Creates a BlockBasedReader.\n\tprotected abstract BlockBasedSource.BlockBasedReader<T> createSingleFileReader(PipelineOptions options);\n}", "des": "A BlockBasedSource is a FileBasedSource where a file consists of blocks of records."}
{"index": 3234, "repo": "beam-sdks-java-core-2.49.0", "code": "Class BlockBasedSource.Block<T> {\n\t// Returns the current record.\n\tabstract T getCurrentRecord();\n\t// Returns the fraction of the block already consumed, if possible, as a value in [0, 1].\n\tabstract double getFractionOfBlockConsumed();\n\t// Reads the next record from the block and returns true iff one exists.\n\tabstract boolean readNextRecord();\n}", "des": "A Block represents a block of records that can be read."}
{"index": 3235, "repo": "beam-sdks-java-core-2.49.0", "code": "Class BucketingFunction {\n\t// Add one sample of value (to bucket) at timeMsSinceEpoch.\n\tvoid add(long timeMsSinceEpoch, long value);\n\t// Return the (bucketized) combined value of all samples.\n\tlong get();\n\t// Is the current result 'significant'? Ie is it drawn from enough buckets or from enough samples?\n\tboolean isSignificant();\n\t// Remove one sample (from bucket) at timeMsSinceEpoch.\n\tvoid remove(long timeMsSinceEpoch);\n}", "des": "Keep track of the minimum/maximum/sum of a set of timestamped long values. For efficiency, bucket values by their timestamp."}
{"index": 3236, "repo": "beam-sdks-java-core-2.49.0", "code": "Class BufferedElementCountingOutputStream {\n\tvoid close();\n\t// Finishes the encoding by flushing any buffered data, and outputting a final count of 0.\n\tvoid finish();\n\tvoid flush();\n\t// Marks that a new element is being output.\n\tvoid markElementStart();\n\tvoid write(byte[] b, int off, int len);\n\tvoid write(int b);\n}", "des": "Provides an efficient encoding for Iterables containing small values by buffering up to bufferSize bytes of data before prefixing the count. Note that each element needs to be encoded in a nested context. See Coder.Context for more details."}
{"index": 3237, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum CannotProvideCoderException.ReasonCode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CannotProvideCoderException.ReasonCode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CannotProvideCoderException.ReasonCode[] values();\n}", "des": "Indicates the reason that Coder inference failed."}
{"index": 3238, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CoderProviders {\n\t// Creates a CoderProvider that always returns the given coder for the specified type.\n\tstatic CoderProvider forCoder(TypeDescriptor<?> type, Coder<?> coder);\n\t// Creates a CoderProvider from a class's static <T> Coder<T> of(TypeDescriptor<T>, List<Coder<?>>) method.\n\tstatic CoderProvider fromStaticMethods(java.lang.Class<?> rawType, java.lang.Class<?> coderClazz);\n}", "des": "Static utility methods for creating and working with CoderProviders."}
{"index": 3239, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CoGbkResultSchema {\n\tboolean equals(@Nullable java.lang.Object obj);\n\t// Returns the index for the given tuple tag, if the tag is present in this schema, -1 if it isn't.\n\tint getIndex(TupleTag<?> tag);\n\t// Returns the tuple tag at the given index.\n\tTupleTag<?> getTag(int index);\n\t// Returns the TupleTagList tuple associated with this schema.\n\tTupleTagList getTupleTagList();\n\tstatic CoGbkResultSchema of(java.util.List<TupleTag<?>> tags);\n\t// Returns the number of columns for this schema.\n\tint size();\n}", "des": "A schema for the results of a CoGroupByKey. This maintains the full set of TupleTags for the results of a CoGroupByKey and facilitates mapping between TupleTags and RawUnionValue tags (which are used as secondary keys in the CoGroupByKey)."}
{"index": 3240, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CoGroup {\n\t// Join all input PCollections using the same args.\n\tstatic CoGroup.Impl join(CoGroup.By clause);\n\t// Specify the following join arguments (including fields to join by_ for the specified PCollection.\n\tstatic CoGroup.Impl join(java.lang.String tag, CoGroup.By clause);\n}", "des": "A transform that performs equijoins across multiple schema PCollections."}
{"index": 3241, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CoGroup.ExpandCrossProduct {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<Row> expand(PCollectionTuple input);\n\t// Select the following fields for the specified PCollection with the specified join args.\n\tCoGroup.ExpandCrossProduct join(java.lang.String tag, CoGroup.By clause);\n}", "des": "A PTransform that calculates the cross-product join."}
{"index": 3242, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CoGroup.Impl {\n\t// Expand the join into individual rows, similar to SQL joins.\n\tCoGroup.ExpandCrossProduct crossProductJoin();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<Row> expand(PCollectionTuple input);\n\t// Select the following fields for the specified PCollection with the specified join args.\n\tCoGroup.Impl join(java.lang.String tag, CoGroup.By clause);\n\tCoGroup.Impl withKeyField(java.lang.String keyFieldName);\n}", "des": "The implementing PTransform."}
{"index": 3243, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CoGroupByKey<K> {\n\t// Returns a CoGroupByKey<K> PTransform.\n\tstatic <K> CoGroupByKey<K> create();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<KV<K,CoGbkResult>> expand(KeyedPCollectionTuple<K> input);\n}", "des": "A PTransform that performs a CoGroupByKey on a tuple of tables. A CoGroupByKey groups results from all tables by like keys into CoGbkResults, from which the results for any specific table can be accessed by the TupleTag supplied with the initial table."}
{"index": 3244, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CollectionCoder<T> {\n\t// Builds an instance of IterableT, this coder's associated Iterable-like subtype, from a list of decoded elements.\n\tprotected java.util.Collection<T> decodeToIterable(java.util.List<T> decodedElements);\n\t// Returns the TypeDescriptor for the type encoded.\n\tTypeDescriptor<java.util.Collection<T>> getEncodedTypeDescriptor();\n\tstatic <T> CollectionCoder<T> of(Coder<T> elemCoder);\n}", "des": "A CollectionCoder encodes Collections in the format of IterableLikeCoder."}
{"index": 3245, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface Combine.AccumulatingCombineFn.Accumulator<InputT,AccumT,OutputT> {\n\t// Adds the given input value to this accumulator, modifying this accumulator.\n\tvoid addInput(InputT input);\n\t// Returns the output value that is the result of combining all the input values represented by this accumulator.\n\tOutputT extractOutput();\n\t// Adds the input values represented by the given accumulator into this accumulator.\n\tvoid mergeAccumulator(AccumT other);\n}", "des": "The type of mutable accumulator values used by this AccumulatingCombineFn."}
{"index": 3246, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Combine.GloballyAsSingletonView<InputT,OutputT> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollectionView<OutputT> expand(PCollection<InputT> input);\n\tCombineFnBase.GlobalCombineFn<? super InputT,?,OutputT> getCombineFn();\n\tint getFanout();\n\tboolean getInsertDefault();\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n}", "des": "Combine.GloballyAsSingletonView<InputT, OutputT> takes a PCollection<InputT> and returns a PCollectionView<OutputT> whose elements are the result of combining all the elements in each window of the input PCollection, using a specified CombineFn<InputT, AccumT, OutputT>. It is common for InputT == OutputT, but not required. Common combining functions include sums, mins, maxes, and averages of numbers, conjunctions and disjunctions of booleans, statistical aggregations, etc."}
{"index": 3247, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Combine.PerKeyWithHotKeyFanout<K,InputT,OutputT> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<KV<K,OutputT>> expand(PCollection<KV<K,InputT>> input);\n\t// Returns the name to use by default for this PTransform (not including the names of any enclosing PTransforms).\n\tprotected java.lang.String getKindString();\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n}", "des": "Like Combine.PerKey, but sharding the combining of hot keys."}
{"index": 3248, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CombineContextFactory {\n\t// Returns a Combine.Context that wraps a StateContext.\n\tstatic CombineWithContext.Context createFromStateContext(StateContext<?> c);\n\t// Returns a fake Combine.Context for tests.\n\tstatic CombineWithContext.Context nullContext();\n}", "des": "Factory that produces Combine.Context based on different inputs."}
{"index": 3249, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CombineWithContext.Context {\n\t// Returns the PipelineOptions specified with the PipelineRunner invoking this KeyedCombineFn.\n\tabstract PipelineOptions getPipelineOptions();\n\t// Returns the value of the side input for the window corresponding to the main input's window in which values are being combined.\n\tabstract <T> T sideInput(PCollectionView<T> view);\n}", "des": "Information accessible to all methods in CombineFnWithContext and KeyedCombineFnWithContext."}
{"index": 3250, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Contextful.Fn.Context {\n\t// Accesses the given side input.\n\t<T> T sideInput(PCollectionView<T> view);\n\t// Convenience wrapper for creating a Contextful.Fn.Context from a DoFn.ProcessContext, to support the common case when a PTransform is invoking the closure from inside a DoFn.\n\tstatic <InputT> Contextful.Fn.Context wrapProcessContext(DoFn.ProcessContext c);\n}", "des": "An accessor for additional capabilities available in Contextful.Fn.apply(InputT, org.apache.beam.sdk.transforms.Contextful.Fn.Context)."}
{"index": 3251, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface Counter {\n\tvoid dec();\n\tvoid dec(long n);\n\t// Increment the counter.\n\tvoid inc();\n\t// Increment the counter by the given amount.\n\tvoid inc(long n);\n}", "des": "A metric that reports a single long value and can be incremented or decremented."}
{"index": 3252, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CountingSource.CounterMark {\n\t// Called by the system to signal that this checkpoint mark has been committed along with all the records which have been read from the UnboundedSource.UnboundedReader since the previous checkpoint was taken.\n\tvoid finalizeCheckpoint();\n\t// Returns the last value emitted by the reader.\n\tlong getLastEmitted();\n\t// Returns the time the reader was started.\n\torg.joda.time.Instant getStartTime();\n}", "des": "The checkpoint for an unbounded CountingSource is simply the last value produced. The associated source object encapsulates the information needed to produce the next value."}
{"index": 3253, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CreateOptions {\n\t// True if the file is expected to not exist.\n\tabstract java.lang.Boolean expectFileToNotExist();\n\t// The file-like resource mime type.\n\tabstract java.lang.String mimeType();\n}", "des": "An abstract class that contains common configuration options for creating resources."}
{"index": 3254, "repo": "beam-sdks-java-core-2.49.0", "code": "Class CustomCoder<T> {\n\t// If this is a Coder for a parameterized type, returns the list of Coders being used for each of the parameters in the same order they appear within the parameterized type's type signature.\n\tjava.util.List<? extends Coder<?>> getCoderArguments();\n\t// Throw Coder.NonDeterministicException if the coding is not deterministic.\n\tvoid verifyDeterministic();\n}", "des": "An abstract base class that implements all methods of Coder except Coder.encode(T, java.io.OutputStream) and Coder.decode(java.io.InputStream)."}
{"index": 3255, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Deduplicate.KeyedValues<K,V> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<KV<K,V>> expand(PCollection<KV<K,V>> input);\n\t// Returns a KeyedValues PTransform like this one but with the specified duration.\n\tDeduplicate.KeyedValues<K,V> withDuration(org.joda.time.Duration duration);\n\t// Returns a KeyedValues PTransform like this one but with the specified time domain.\n\tDeduplicate.KeyedValues<K,V> withTimeDomain(TimeDomain timeDomain);\n}", "des": "Deduplicates keyed values using the key over a specified time domain and threshold. Construct via Deduplicate.keyedValues() ()}."}
{"index": 3256, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Deduplicate.Values<T> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<T> expand(PCollection<T> input);\n\t// Returns a Values PTransform like this one but with the specified duration.\n\tDeduplicate.Values<T> withDuration(org.joda.time.Duration duration);\n\t// Returns a Values PTransform like this one but with the specified time domain.\n\tDeduplicate.Values<T> withTimeDomain(TimeDomain timeDomain);\n}", "des": "Deduplicates values over a specified time domain and threshold. Construct via Deduplicate.values()."}
{"index": 3257, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DefaultFilenamePolicy.ParamsCoder {\n\t// Decodes a value of type T from the given input stream in the given context.\n\tDefaultFilenamePolicy.Params decode(java.io.InputStream inStream);\n\t// Encodes the given value of type T onto the given output stream.\n\tvoid encode(DefaultFilenamePolicy.Params value, java.io.OutputStream outStream);\n\tstatic DefaultFilenamePolicy.ParamsCoder of();\n}", "des": "A Coder for DefaultFilenamePolicy.Params."}
{"index": 3258, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DefaultSchema.DefaultSchemaProvider {\n\t// Given a type, returns a function that converts from a Row object to that type.\n\t<T> SerializableFunction<Row,T> fromRowFunction(TypeDescriptor<T> typeDescriptor);\n\t// Lookup a schema for the given type.\n\t<T> Schema schemaFor(TypeDescriptor<T> typeDescriptor);\n\t// Given a type, return a function that converts that type to a Row object If no schema exists, returns null.\n\t<T> SerializableFunction<T,Row> toRowFunction(TypeDescriptor<T> typeDescriptor);\n}", "des": "SchemaProvider for default schemas. Looks up the provider annotated for a type, and delegates to that provider."}
{"index": 3259, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DelegatingCounter {\n\tvoid dec();\n\tvoid dec(long n);\n\t// The MetricName given to this metric.\n\tMetricName getName();\n\t// Increment the counter.\n\tvoid inc();\n\t// Increment the counter by the given amount.\n\tvoid inc(long n);\n}", "des": "Implementation of Counter that delegates to the instance for the current context."}
{"index": 3260, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DelegatingDistribution {\n\t// The MetricName given to this metric.\n\tMetricName getName();\n\t// Add an observation to this distribution.\n\tvoid update(long value);\n\tvoid update(long sum, long count, long min, long max);\n}", "des": "Implementation of Distribution that delegates to the instance for the current context."}
{"index": 3261, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DelegatingHistogram {\n\t// The MetricName given to this metric.\n\tMetricName getName();\n\t// Add an observation to this histogram.\n\tvoid update(double value);\n}", "des": "Implementation of Histogram that delegates to the instance for the current context."}
{"index": 3262, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum DisplayData.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DisplayData.Type valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DisplayData.Type[] values();\n}", "des": "Display data type."}
{"index": 3263, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Distinct<T> {\n\t// Returns a Distinct<T> PTransform.\n\tstatic <T> Distinct<T> create();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<T> expand(PCollection<T> in);\n\t// Returns a Distinct<T, IdT> PTransform.\n\tstatic <T,IdT> Distinct.WithRepresentativeValues<T,IdT> withRepresentativeValueFn(SerializableFunction<T,IdT> fn);\n}", "des": "Distinct<T> takes a PCollection<T> and returns a PCollection<T> that has all distinct elements of the input. Thus, each element is unique within each window."}
{"index": 3264, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Distinct.WithRepresentativeValues<T,IdT> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<T> expand(PCollection<T> in);\n\t// Return a WithRepresentativeValues PTransform that is like this one, but with the specified output type descriptor.\n\tDistinct.WithRepresentativeValues<T,IdT> withRepresentativeType(TypeDescriptor<IdT> type);\n}", "des": "A Distinct PTransform that uses a SerializableFunction to obtain a representative value for each input element."}
{"index": 3265, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFn<InputT,OutputT> {\n\t// Returns a TypeDescriptor capturing what is known statically about the input type of this DoFn instance's most-derived class.\n\tTypeDescriptor<InputT> getInputTypeDescriptor();\n\t// Returns a TypeDescriptor capturing what is known statically about the output type of this DoFn instance's most-derived class.\n\tTypeDescriptor<OutputT> getOutputTypeDescriptor();\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n}", "des": "The argument to ParDo providing the code to use to process elements of the input PCollection."}
{"index": 3266, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface DoFn.MultiOutputReceiver {\n\t// Returns an DoFn.OutputReceiver for the given tag.\n\t<T> DoFn.OutputReceiver<T> get(TupleTag<T> tag);\n\t// Returns a DoFn.OutputReceiver for publishing Row objects to the given tag.\n\t<T> DoFn.OutputReceiver<Row> getRowReceiver(TupleTag<T> tag);\n}", "des": "Receives tagged output for a multi-output function."}
{"index": 3267, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnInvokers {\n\t// Returns an DoFnInvoker for the given DoFn, using a default choice of DoFnInvokerFactory.\n\tstatic <InputT,OutputT>DoFnInvoker<InputT,OutputT> invokerFor(DoFn<InputT,OutputT> fn);\n\t// Tries to invoke setup on the given DoFn.\n\tstatic <InputT,OutputT>DoFnInvoker<InputT,OutputT> tryInvokeSetupFor(DoFn<InputT,OutputT> fn, PipelineOptions options);\n}", "des": "Static utilities for working with DoFnInvoker."}
{"index": 3268, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSchemaInformation {\n\t// Create an instance.\n\tstatic DoFnSchemaInformation create();\n\t// The schema of the @Element parameter.\n\tabstract java.util.List<SerializableFunction<?,?>> getElementConverters();\n\t// Effective FieldAccessDescriptor applied by DoFn.\n\tabstract FieldAccessDescriptor getFieldAccessDescriptor();\n\tabstract DoFnSchemaInformation.Builder toBuilder();\n}", "des": "Represents information about how a DoFn extracts schemas."}
{"index": 3269, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.BundleMethod {\n\t// Types of optional parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n\t// The type of window expected by this method, if any.\n\tabstract @Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "Describes a DoFn.StartBundle or DoFn.FinishBundle method."}
{"index": 3270, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.GetInitialRestrictionMethod {\n\t// Types of optional parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// Type of the returned restriction.\n\tabstract TypeDescriptor<?> restrictionT();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n\t// The window type used by this method, if any.\n\tabstract @Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "Describes a DoFn.GetInitialRestriction method."}
{"index": 3271, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.GetRestrictionCoderMethod {\n\t// Type of the returned Coder.\n\tabstract TypeDescriptor<?> coderT();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n}", "des": "Describes a DoFn.GetRestrictionCoder method."}
{"index": 3272, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.GetSizeMethod {\n\t// Types of optional parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n\t// The window type used by this method, if any.\n\tabstract @Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "Describes a DoFn.GetSize method."}
{"index": 3273, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.GetWatermarkEstimatorStateCoderMethod {\n\t// Type of the returned Coder.\n\tabstract TypeDescriptor<?> coderT();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n}", "des": "Describes a DoFn.GetRestrictionCoder method."}
{"index": 3274, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.LifecycleMethod {\n\t// Types of optional parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n}", "des": "Describes a DoFn.Setup or DoFn.Teardown method."}
{"index": 3275, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface DoFnSignature.MethodWithExtraParameters {\n\t// Types of optional parameters of the annotated method, in the order they appear.\n\tjava.util.List<DoFnSignature.Parameter> extraParameters();\n\t// Whether this method observes - directly or indirectly - the window that an element resides in.\n\tdefault boolean observesWindow();\n\t// The type of window expected by this method, if any.\n\t@Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "A method delegated to an annotated method of an underlying DoFn that accepts a dynamic list of parameters."}
{"index": 3276, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.NewTrackerMethod {\n\t// Types of optional parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n\t// Type of the returned RestrictionTracker.\n\tabstract TypeDescriptor<?> trackerT();\n\t// The window type used by this method, if any.\n\tabstract @Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "Describes a DoFn.NewTracker method."}
{"index": 3277, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.NewWatermarkEstimatorMethod {\n\t// Types of optional parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n\t// Type of the returned WatermarkEstimator.\n\tabstract TypeDescriptor<?> watermarkEstimatorT();\n\t// The window type used by this method, if any.\n\tabstract @Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "Describes a DoFn.NewWatermarkEstimator method."}
{"index": 3278, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.SplitRestrictionMethod {\n\t// Types of parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n\t// The window type used by this method, if any.\n\tabstract @Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "Describes a DoFn.SplitRestriction method."}
{"index": 3279, "repo": "beam-sdks-java-core-2.49.0", "code": "Class DoFnSignature.TruncateRestrictionMethod {\n\t// Types of parameters of the annotated method, in the order they appear.\n\tabstract java.util.List<DoFnSignature.Parameter> extraParameters();\n\t// The annotated method itself.\n\tabstract java.lang.reflect.Method targetMethod();\n\t// The window type used by this method, if any.\n\tabstract @Nullable TypeDescriptor<? extends BoundedWindow> windowT();\n}", "des": "Describes a DoFn.TruncateRestriction method."}
{"index": 3280, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ElementByteSizeObservableIterable<V,InputT extends ElementByteSizeObservableIterator<V>> {\n\t// Sets the observer, which will observe the iterator returned in the next call to iterator() method.\n\tvoid addObserver(java.util.Observer observer);\n\t// Derived classes override this method to return an iterator for this iterable.\n\tprotected abstract InputT createIterator();\n\t// Returns a new iterator for this iterable.\n\tInputT iterator();\n}", "des": "An abstract class used for iterables that notify observers about size in bytes of their elements, as they are being iterated over."}
{"index": 3281, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum EmptyMatchTreatment {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EmptyMatchTreatment valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EmptyMatchTreatment[] values();\n}", "des": "Options for allowing or disallowing filepatterns that match no resources in FileSystems.match(java.util.List)."}
{"index": 3282, "repo": "beam-sdks-java-core-2.49.0", "code": "Class EncodableThrowable {\n\tboolean equals(java.lang.Object obj);\n\t// Wraps throwable and returns the result.\n\tstatic EncodableThrowable forThrowable(java.lang.Throwable throwable);\n\t// Returns the underlying Throwable.\n\tjava.lang.Throwable throwable();\n}", "des": "A wrapper around a Throwable for use with coders."}
{"index": 3283, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ExplicitShardedFile {\n\t// Discovers all shards of this file.\n\tjava.util.List<java.lang.String> readFilesWithRetries();\n\t// Discovers all shards of this file using the provided Sleeper and BackOff.\n\tjava.util.List<java.lang.String> readFilesWithRetries(Sleeper sleeper, BackOff backOff);\n}", "des": "A sharded file where the file names are simply provided."}
{"index": 3284, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface ExternalTransformBuilder<ConfigT,InputT extends PInput,OutputT extends POutput> {\n\t// Builds the transform after it has been configured.\n\tPTransform<InputT,OutputT> buildExternal(ConfigT configuration);\n\t// List the dependencies needed for this transform.\n\tdefault java.util.Optional<java.util.List<java.lang.String>> getDependencies(ConfigT configuration, PipelineOptions options);\n}", "des": "An interface for building a transform from an externally provided configuration."}
{"index": 3285, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Failure {\n\t// Information about the cause of the failure.\n\tabstract java.lang.String getError();\n\t// Bytes containing the payload which has failed.\n\tabstract byte[] getPayload();\n\tstatic Failure.Builder newBuilder();\n}", "des": "A generic failure of an SQL transform."}
{"index": 3286, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum FieldAccessDescriptor.FieldDescriptor.ListQualifier {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FieldAccessDescriptor.FieldDescriptor.ListQualifier valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FieldAccessDescriptor.FieldDescriptor.ListQualifier[] values();\n}", "des": "Qualifier for a list selector."}
{"index": 3287, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum FieldAccessDescriptor.FieldDescriptor.MapQualifier {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FieldAccessDescriptor.FieldDescriptor.MapQualifier valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FieldAccessDescriptor.FieldDescriptor.MapQualifier[] values();\n}", "des": "Qualifier for a map selector."}
{"index": 3288, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum FieldAccessDescriptor.FieldDescriptor.Qualifier.Kind {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FieldAccessDescriptor.FieldDescriptor.Qualifier.Kind valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FieldAccessDescriptor.FieldDescriptor.Qualifier.Kind[] values();\n}", "des": "The kind of qualifier."}
{"index": 3289, "repo": "beam-sdks-java-core-2.49.0", "code": "Class FieldTypeDescriptors {\n\t// Get a Schema.FieldType from a TypeDescriptor.\n\tstatic Schema.FieldType fieldTypeForJavaType(TypeDescriptor typeDescriptor);\n\t// Get a TypeDescriptor from a Schema.FieldType.\n\tstatic TypeDescriptor javaTypeForFieldType(Schema.FieldType fieldType);\n}", "des": "Utilities for converting between Schema field types and TypeDescriptors that define Java objects which can represent these field types."}
{"index": 3290, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface FieldValueSetter<ObjectT,ValueT> {\n\t// Returns the name of the field.\n\tjava.lang.String name();\n\t// Sets the specified field on object to value.\n\tvoid set(ObjectT object, ValueT value);\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3291, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface FieldValueTypeSupplier {\n\t// Return all the FieldValueTypeInformations.\n\tjava.util.List<FieldValueTypeInformation> get(java.lang.Class<?> clazz);\n\t// Return all the FieldValueTypeInformations.\n\tdefault java.util.List<FieldValueTypeInformation> get(java.lang.Class<?> clazz, Schema schema);\n}", "des": "A naming policy for schema fields. This maps a name from the class (field name or getter name) to the matching field name in the schema."}
{"index": 3292, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum FileBasedSource.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileBasedSource.Mode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileBasedSource.Mode[] values();\n}", "des": "A given FileBasedSource represents a file resource of one of these types."}
{"index": 3293, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum FileIO.ReadMatches.DirectoryTreatment {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileIO.ReadMatches.DirectoryTreatment valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileIO.ReadMatches.DirectoryTreatment[] values();\n}", "des": "Enum to control how directories are handled."}
{"index": 3294, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface FileIO.Sink<ElementT> {\n\t// Flushes the buffered state (if any) before the channel is closed.\n\tvoid flush();\n\t// Initializes writing to the given channel.\n\tvoid open(java.nio.channels.WritableByteChannel channel);\n\t// Appends a single element to the file.\n\tvoid write(ElementT element);\n}", "des": "Specifies how to write elements to individual files in FileIO.write() and FileIO.writeDynamic(). A new instance of FileIO.Sink is created for every file being written."}
{"index": 3295, "repo": "beam-sdks-java-core-2.49.0", "code": "Class FilePatternMatchingShardedFile {\n\t// Discovers all shards of this file.\n\tjava.util.List<java.lang.String> readFilesWithRetries();\n\t// Discovers all shards of this file using the provided Sleeper and BackOff.\n\tjava.util.List<java.lang.String> readFilesWithRetries(Sleeper sleeper, BackOff backOff);\n}", "des": "A sharded file which matches a given file pattern. Note that the file pattern must match at least one file."}
{"index": 3296, "repo": "beam-sdks-java-core-2.49.0", "code": "Class FixedString {\n\tint getLength();\n\t@Nullable java.lang.String getName();\n\t// Return an instance of FixedString with specified string length.\n\tstatic FixedString of(int stringLength);\n\t// Return an instance of FixedString with specified string length.\n\tstatic FixedString of(@Nullable java.lang.String name, int stringLength);\n\t// Convert the Java type used by the base Schema.FieldType to the input type.\n\tjava.lang.String toInputType(java.lang.String base);\n}", "des": "A LogicalType representing a fixed-length string."}
{"index": 3297, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Flatten {\n\t// Returns a PTransform that takes a PCollection<Iterable<T>> and returns a PCollection<T> containing all the elements from all the Iterables.\n\tstatic <T> Flatten.Iterables<T> iterables();\n\t// Returns a PTransform that flattens a PCollectionList into a PCollection containing all the elements of all the PCollections in its input.\n\tstatic <T> Flatten.PCollections<T> pCollections();\n}", "des": "Flatten<T> takes multiple PCollection<T>s bundled into a PCollectionList<T> and returns a single PCollection<T> containing all the elements in all the input PCollections. The name \"Flatten\" suggests taking a list of lists and flattening them into a single list."}
{"index": 3298, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface GroupingState<InputT,OutputT> {\n\t// Add a value to the buffer.\n\tvoid add(InputT value);\n\t// Returns a ReadableState whose ReadableState.read() method will return true if this state is empty at the point when that ReadableState.read() call returns.\n\tReadableState<java.lang.Boolean> isEmpty();\n\t// Indicate that the value will be read later.\n\tGroupingState<InputT,OutputT> readLater();\n}", "des": "A ReadableState cell that combines multiple input values and outputs a single value of a different type."}
{"index": 3299, "repo": "beam-sdks-java-core-2.49.0", "code": "Class GrowableOffsetRangeTracker {\n\t// A representation for the amount of known completed and known remaining work.\n\tRestrictionTracker.Progress getProgress();\n\t// Return the boundedness of the current restriction.\n\tRestrictionTracker.IsBounded isBounded();\n\t// Splits current restriction based on fractionOfRemainder.\n\tSplitResult<OffsetRange> trySplit(double fractionOfRemainder);\n}", "des": "An OffsetRangeTracker for tracking a growable offset range. Long.MAX_VALUE is used as the end of the range to indicate infinity."}
{"index": 3300, "repo": "beam-sdks-java-core-2.49.0", "code": "Class IllegalMutationException {\n\t// The value after the illegal mutation.\n\tjava.lang.Object getNewValue();\n\t// The original value, before the illegal mutation.\n\tjava.lang.Object getSavedValue();\n}", "des": "Thrown when a value appears to have been mutated, but that mutation is forbidden."}
{"index": 3301, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Impulse {\n\t// Create a new Impulse PTransform.\n\tstatic Impulse create();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<byte[]> expand(PBegin input);\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3302, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface JvmInitializer {\n\t// Implement beforeProcessing to run some custom initialization after basic services such as logging, but before data processing begins.\n\tdefault void beforeProcessing(PipelineOptions options);\n\t// Implement onStartup to run some custom initialization immediately after the JVM is launched for pipeline execution.\n\tdefault void onStartup();\n}", "des": "A service interface for defining one-time initialization of the JVM during pipeline execution."}
{"index": 3303, "repo": "beam-sdks-java-core-2.49.0", "code": "Class KeyedPCollectionTuple.TaggedKeyedPCollection<K,V> {\n\t// Returns the underlying PCollection of this TaggedKeyedPCollection.\n\tPCollection<KV<K,V>> getCollection();\n\t// Returns the TupleTag of this TaggedKeyedPCollection.\n\tTupleTag<V> getTupleTag();\n}", "des": "A utility class to help ensure coherence of tag and input PCollection types."}
{"index": 3304, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Keys<K> {\n\t// Returns a Keys<K> PTransform.\n\tstatic <K> Keys<K> create();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<K> expand(PCollection<? extends KV<K,?>> in);\n}", "des": "Keys<K> takes a PCollection of KV<K, V>s and returns a PCollection<K> of the keys."}
{"index": 3305, "repo": "beam-sdks-java-core-2.49.0", "code": "Class KV<K,V> {\n\tboolean equals(@Nullable java.lang.Object other);\n\t// Returns the key of this KV.\n\tK getKey();\n\t// Returns the value of this KV.\n\tV getValue();\n\t// Returns a KV with the given key and value.\n\tstatic <K,V> KV<K,V> of(K key, V value);\n}", "des": "An immutable key/value pair."}
{"index": 3306, "repo": "beam-sdks-java-core-2.49.0", "code": "Class KvSwap<K,V> {\n\t// Returns a KvSwap<K, V> PTransform.\n\tstatic <K,V> KvSwap<K,V> create();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<KV<V,K>> expand(PCollection<KV<K,V>> in);\n}", "des": "KvSwap<K, V> takes a PCollection<KV<K, V>> and returns a PCollection<KV<V, K>>, where all the keys and values have been swapped."}
{"index": 3307, "repo": "beam-sdks-java-core-2.49.0", "code": "Class MatchResult.Metadata {\n\tstatic MatchResult.Metadata.Builder builder();\n\t// An optional checksum to identify the contents of a file.\n\tabstract @Nullable java.lang.String checksum();\n\tabstract boolean isReadSeekEfficient();\n\t// Last modification timestamp in milliseconds since Unix epoch.\n\tabstract long lastModifiedMillis();\n\tabstract ResourceId resourceId();\n\tabstract long sizeBytes();\n}", "des": "MatchResult.Metadata of a matched file."}
{"index": 3308, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum MatchResult.Status {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MatchResult.Status valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MatchResult.Status[] values();\n}", "des": "Status of a MatchResult."}
{"index": 3309, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Materializations {\n\t// For internal use only; no backwards-compatibility guarantees.\n\tstatic <V> Materialization<Materializations.IterableView<V>> iterable();\n\t// For internal use only; no backwards-compatibility guarantees.\n\tstatic <K,V> Materialization<Materializations.MultimapView<K,V>> multimap();\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3310, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface Materializations.MultimapView<K,V> {\n\t// Returns an iterable of all keys.\n\tjava.lang.Iterable<K> get();\n\t// Returns an iterable of all the values for the specified key.\n\tjava.lang.Iterable<V> get(K k);\n}", "des": "Represents the PrimitiveViewT supplied to the ViewFn when it declares to use the multimap materialization."}
{"index": 3311, "repo": "beam-sdks-java-core-2.49.0", "code": "Class MetadataCoder {\n\t// Returns true if this Coder is injective with respect to Object.equals(java.lang.Object).\n\tboolean consistentWithEquals();\n\t// Decodes a value of type T from the given input stream in the given context.\n\tMatchResult.Metadata decode(java.io.InputStream is);\n\t// Encodes the given value of type T onto the given output stream.\n\tvoid encode(MatchResult.Metadata value, java.io.OutputStream os);\n\t// Returns the singleton MetadataCoder instance.\n\tstatic MetadataCoder of();\n}", "des": "A Coder for MatchResult.Metadata."}
{"index": 3312, "repo": "beam-sdks-java-core-2.49.0", "code": "Class MetadataCoderV2 {\n\t// Returns true if this Coder is injective with respect to Object.equals(java.lang.Object).\n\tboolean consistentWithEquals();\n\t// Decodes a value of type T from the given input stream in the given context.\n\tMatchResult.Metadata decode(java.io.InputStream is);\n\t// Encodes the given value of type T onto the given output stream.\n\tvoid encode(MatchResult.Metadata value, java.io.OutputStream os);\n\t// Returns the singleton MetadataCoderV2 instance.\n\tstatic MetadataCoderV2 of();\n}", "des": "A Coder for MatchResult.Metadata that includes MatchResult.Metadata.lastModifiedMillis()."}
{"index": 3313, "repo": "beam-sdks-java-core-2.49.0", "code": "Class MetricKey {\n\tstatic MetricKey create(@Nullable java.lang.String stepName, MetricName metricName);\n\t// The name of the metric.\n\tabstract MetricName metricName();\n\t// The step name that is associated with this metric or Null if none is associated.\n\tabstract @Nullable java.lang.String stepName();\n}", "des": "Metrics are keyed by the step name they are associated with and the name of the metric."}
{"index": 3314, "repo": "beam-sdks-java-core-2.49.0", "code": "Class MetricName {\n\t// The name of this metric.\n\tabstract java.lang.String getName();\n\t// The namespace associated with this metric.\n\tabstract java.lang.String getNamespace();\n\tstatic MetricName named(java.lang.Class<?> namespace, java.lang.String name);\n\tstatic MetricName named(java.lang.String namespace, java.lang.String name);\n}", "des": "The name of a metric consists of a getNamespace() and a getName(). The getNamespace() allows grouping related metrics together and also prevents collisions between multiple metrics with the same name."}
{"index": 3315, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum MoreFutures.ExceptionOrResult.IsException {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MoreFutures.ExceptionOrResult.IsException valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MoreFutures.ExceptionOrResult.IsException[] values();\n}", "des": "Describes whether the result was an exception."}
{"index": 3316, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum MoveOptions.StandardMoveOptions {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MoveOptions.StandardMoveOptions valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MoveOptions.StandardMoveOptions[] values();\n}", "des": "Defines the standard MoveOptions."}
{"index": 3317, "repo": "beam-sdks-java-core-2.49.0", "code": "Class MovingFunction {\n\t// Add value at nowMsSinceEpoch.\n\tvoid add(long nowMsSinceEpoch, long value);\n\t// Return the minimum/maximum/sum of all retained values within samplePeriodMs of nowMsSinceEpoch.\n\tlong get(long nowMsSinceEpoch);\n\t// Is the current result 'significant'? Ie is it drawn from enough buckets or from enough samples?\n\tboolean isSignificant();\n}", "des": "Keep track of the moving minimum/maximum/sum of sampled long values. The minimum/maximum/sum is over at most the user-specified last samplePeriodMs, and is updated every sampleUpdateMs."}
{"index": 3318, "repo": "beam-sdks-java-core-2.49.0", "code": "Class MutationDetectors {\n\t// Creates a new MutationDetector for the provided value that uses the provided Coder to perform deep copies and comparisons by serializing and deserializing values.\n\tstatic <T> MutationDetector forValueWithCoder(T value, Coder<T> coder);\n\t// Creates a new MutationDetector that always succeeds.\n\tstatic MutationDetector noopMutationDetector();\n}", "des": "Static methods for creating and working with MutationDetector."}
{"index": 3319, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Never.NeverTrigger {\n\t// Subclasses should override this to return the Trigger.getContinuationTrigger() of this Trigger.\n\tprotected Trigger getContinuationTrigger(java.util.List<Trigger> continuationTriggers);\n\t// For internal use only; no backwards-compatibility guarantees.\n\torg.joda.time.Instant getWatermarkThatGuaranteesFiring(BoundedWindow window);\n}", "des": "The actual trigger class for Never triggers."}
{"index": 3320, "repo": "beam-sdks-java-core-2.49.0", "code": "Class NonMergingWindowFn<T,W extends BoundedWindow> {\n\t// Returns true if this WindowFn never needs to merge any windows.\n\tboolean isNonMerging();\n\t// Does whatever merging of windows is necessary.\n\tvoid mergeWindows(WindowFn.MergeContext c);\n}", "des": "Abstract base class for WindowFns that do not merge windows."}
{"index": 3321, "repo": "beam-sdks-java-core-2.49.0", "code": "Class NumberedShardedFile {\n\tjava.lang.String getFilePattern();\n\t// Discovers all shards of this file.\n\tjava.util.List<java.lang.String> readFilesWithRetries();\n\t// Discovers all shards of this file using the provided Sleeper and BackOff.\n\tjava.util.List<java.lang.String> readFilesWithRetries(Sleeper sleeper, BackOff backOff);\n}", "des": "Utility methods for working with sharded files. For internal use only; many parameters are just hardcoded to allow existing uses to work OK."}
{"index": 3322, "repo": "beam-sdks-java-core-2.49.0", "code": "Class OneOfType.Value {\n\tboolean equals(@Nullable java.lang.Object o);\n\t// Returns the enumeration that specified which OneOf field is set.\n\tEnumerationType.Value getCaseType();\n\t// Returns the current value of the OneOf.\n\tjava.lang.Object getValue();\n\t// Returns the current value of the OneOf as the destination type.\n\t<T> T getValue(java.lang.Class<T> clazz);\n}", "des": "Represents a single OneOf value. Each object contains an EnumerationType.Value specifying which field is set along with the value of that field."}
{"index": 3323, "repo": "beam-sdks-java-core-2.49.0", "code": "Class PaneInfo.PaneInfoCoder {\n\t// Decodes a value of type T from the given input stream in the given context.\n\tPaneInfo decode(java.io.InputStream inStream);\n\t// Encodes the given value of type T onto the given output stream.\n\tvoid encode(PaneInfo value, java.io.OutputStream outStream);\n\tstatic PaneInfo.PaneInfoCoder of();\n\t// Throw Coder.NonDeterministicException if the coding is not deterministic.\n\tvoid verifyDeterministic();\n}", "des": "A Coder for encoding PaneInfo instances."}
{"index": 3324, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum PaneInfo.Timing {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PaneInfo.Timing valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PaneInfo.Timing[] values();\n}", "des": "Enumerates the possibilities for the timing of this pane firing related to the input and output watermarks for its computation."}
{"index": 3325, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ParDo {\n\t// Extract information on how the DoFn uses schemas.\n\tstatic DoFnSchemaInformation getDoFnSchemaInformation(DoFn<?,?> fn, PCollection<?> input);\n\t// Creates a ParDo PTransform that will invoke the given DoFn function.\n\tstatic <InputT,OutputT>ParDo.SingleOutput<InputT,OutputT> of(DoFn<InputT,OutputT> fn);\n}", "des": "ParDo is the core element-wise transform in Apache Beam, invoking a user-specified function on each of the elements of the input PCollection to produce zero or more output elements, all of which are collected into the output PCollection."}
{"index": 3326, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum PCollection.IsBounded {\n\t// Returns the composed IsBounded property.\n\tPCollection.IsBounded and(PCollection.IsBounded that);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PCollection.IsBounded valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PCollection.IsBounded[] values();\n}", "des": "The enumeration of cases for whether a PCollection is bounded."}
{"index": 3327, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface PCollectionView<T> {\n\t// For internal use only.\n\t@Nullable PCollection<?> getPCollection();\n\t// For internal use only.\n\tWindowMappingFn<?> getWindowMappingFn();\n}", "des": "A PCollectionView<T> is an immutable view of a PCollection as a value of type T that can be accessed as a side input to a ParDo transform."}
{"index": 3328, "repo": "beam-sdks-java-core-2.49.0", "code": "Class PCollectionViews.IterableViewFn2<T> {\n\t// A function to adapt a primitive view type to a desired view type.\n\tjava.lang.Iterable<T> apply(Materializations.IterableView<T> primitiveViewT);\n\t// Gets the materialization of this ViewFn.\n\tMaterialization<Materializations.IterableView<T>> getMaterialization();\n\t// Return the TypeDescriptor describing the output of this fn.\n\tTypeDescriptor<java.lang.Iterable<T>> getTypeDescriptor();\n}", "des": "Implementation which is able to adapt an iterable materialization to a Iterable<T>."}
{"index": 3329, "repo": "beam-sdks-java-core-2.49.0", "code": "Class PCollectionViews.MapViewFn2<K,V> {\n\t// A function to adapt a primitive view type to a desired view type.\n\tjava.util.Map<K,V> apply(Materializations.MultimapView<K,V> primitiveViewT);\n\t// Gets the materialization of this ViewFn.\n\tMaterialization<Materializations.MultimapView<K,V>> getMaterialization();\n\t// Return the TypeDescriptor describing the output of this fn.\n\tTypeDescriptor<java.util.Map<K,V>> getTypeDescriptor();\n}", "des": "Implementation which is able to adapt a multimap materialization to a Map<K, V>."}
{"index": 3330, "repo": "beam-sdks-java-core-2.49.0", "code": "Class PCollectionViews.MultimapViewFn2<K,V> {\n\t// A function to adapt a primitive view type to a desired view type.\n\tjava.util.Map<K,java.lang.Iterable<V>> apply(Materializations.MultimapView<K,V> primitiveViewT);\n\t// Gets the materialization of this ViewFn.\n\tMaterialization<Materializations.MultimapView<K,V>> getMaterialization();\n\t// Return the TypeDescriptor describing the output of this fn.\n\tTypeDescriptor<java.util.Map<K,java.lang.Iterable<V>>> getTypeDescriptor();\n}", "des": "Implementation which is able to adapt a multimap materialization to a Map<K, Iterable<V>>."}
{"index": 3331, "repo": "beam-sdks-java-core-2.49.0", "code": "Class PDone {\n\t// A PDone contains no PValues.\n\tjava.util.Map<TupleTag<?>,PValue> expand();\n\t// Does nothing; there is nothing to finish specifying.\n\tvoid finishSpecifyingOutput(java.lang.String transformName, PInput input, PTransform<?,?> transform);\n\t// Returns the owning Pipeline of this POutput.\n\tPipeline getPipeline();\n\t// Creates a PDone in the given Pipeline.\n\tstatic PDone in(Pipeline pipeline);\n}", "des": "PDone is the output of a PTransform that has a trivial result, such as a WriteFiles."}
{"index": 3332, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface PInput {\n\t// Expands this PInput into a list of its component output PValues.\n\tjava.util.Map<TupleTag<?>,PValue> expand();\n\t// Returns the owning Pipeline of this PInput.\n\tPipeline getPipeline();\n}", "des": "The interface for things that might be input to a PTransform."}
{"index": 3333, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum Pipeline.PipelineVisitor.CompositeBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Pipeline.PipelineVisitor.CompositeBehavior valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Pipeline.PipelineVisitor.CompositeBehavior[] values();\n}", "des": "Control enum for indicating whether or not a traversal should process the contents of a composite transform or not."}
{"index": 3334, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum PipelineOptions.CheckEnabled {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PipelineOptions.CheckEnabled valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PipelineOptions.CheckEnabled[] values();\n}", "des": "Enumeration of the possible states for a given check."}
{"index": 3335, "repo": "beam-sdks-java-core-2.49.0", "code": "Class PipelineOptionsValidator {\n\t// Validates that the passed PipelineOptions conforms to all the validation criteria from the passed in interface.\n\tstatic <T extends PipelineOptions>T validate(java.lang.Class<T> klass, PipelineOptions options);\n\t// Validates that the passed PipelineOptions from command line interface (CLI) conforms to all the validation criteria from the passed in interface.\n\tstatic <T extends PipelineOptions>T validateCli(java.lang.Class<T> klass, PipelineOptions options);\n}", "des": "Validates that the PipelineOptions conforms to all the Validation criteria."}
{"index": 3336, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum PipelineResult.State {\n\tboolean hasReplacementJob();\n\tboolean isTerminal();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PipelineResult.State valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PipelineResult.State[] values();\n}", "des": "Possible job states, for both completed and ongoing jobs."}
{"index": 3337, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface POutput {\n\t// Expands this POutput into a list of its component output PValues.\n\tjava.util.Map<TupleTag<?>,PValue> expand();\n\t// As part of applying the producing PTransform, finalizes this output to make it ready for being used as an input and for running.\n\tvoid finishSpecifyingOutput(java.lang.String transformName, PInput input, PTransform<?,?> transform);\n\t// Returns the owning Pipeline of this POutput.\n\tPipeline getPipeline();\n}", "des": "The interface for things that might be output from a PTransform."}
{"index": 3338, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface ProjectionProducer<T> {\n\t// Actuate a projection pushdown.\n\tT actuateProjectionPushdown(java.util.Map<TupleTag<?>,FieldAccessDescriptor> outputFields);\n\t// Whether this supports projection pushdown.\n\tboolean supportsProjectionPushdown();\n}", "des": "A factory for operations that execute a projection on a Schema-aware PCollection."}
{"index": 3339, "repo": "beam-sdks-java-core-2.49.0", "code": "Class PTransformOverride {\n\t// Gets the PTransformMatcher to identify PTransforms to replace.\n\tabstract PTransformMatcher getMatcher();\n\t// Gets the PTransformOverrideFactory of this override.\n\tabstract PTransformOverrideFactory<?,?,?> getOverrideFactory();\n\tstatic PTransformOverride of(PTransformMatcher matcher, PTransformOverrideFactory<?,?,?> factory);\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3340, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface PValue {\n\t// After building, finalizes this PValue to make it ready for being used as an input to a PTransform.\n\tvoid finishSpecifying(PInput upstreamInput, PTransform<?,?> upstreamTransform);\n\t// Returns the name of this PValue.\n\tjava.lang.String getName();\n}", "des": "For internal use. No backwards compatibility guarantees."}
{"index": 3341, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Read {\n\t// Returns a new Read.Bounded PTransform reading from the given BoundedSource.\n\tstatic <T> Read.Bounded<T> from(BoundedSource<T> source);\n\t// Returns a new Read.Unbounded PTransform reading from the given UnboundedSource.\n\tstatic <T> Read.Unbounded<T> from(UnboundedSource<T,?> source);\n}", "des": "A PTransform for reading from a Source."}
{"index": 3342, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Read.Builder {\n\t// Returns a new Read.Bounded PTransform reading from the given BoundedSource.\n\t<T> Read.Bounded<T> from(BoundedSource<T> source);\n\t// Returns a new Read.Unbounded PTransform reading from the given UnboundedSource.\n\t<T> Read.Unbounded<T> from(UnboundedSource<T,?> source);\n}", "des": "Helper class for building Read transforms."}
{"index": 3343, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface ReadableState<T> {\n\t// Read the current value, blocking until it is available.\n\tT read();\n\t// Indicate that the value will be read later.\n\tReadableState<T> readLater();\n}", "des": "A State that can be read via read()."}
{"index": 3344, "repo": "beam-sdks-java-core-2.49.0", "code": "Class RenameFields.Inner<T> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<Row> expand(PCollection<T> input);\n\t// Rename a specific field.\n\tRenameFields.Inner<T> rename(FieldAccessDescriptor field, java.lang.String newName);\n\t// Rename a specific field.\n\tRenameFields.Inner<T> rename(java.lang.String field, java.lang.String newName);\n}", "des": "The class implementing the actual PTransform."}
{"index": 3345, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum ResolveOptions.StandardResolveOptions {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ResolveOptions.StandardResolveOptions valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ResolveOptions.StandardResolveOptions[] values();\n}", "des": "Defines the standard resolve options."}
{"index": 3346, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ResourceHint {\n\tabstract boolean equals(@Nullable java.lang.Object other);\n\t// Reconciles values of a hint when the hint specified on a transform is also defined in an outer context, for example on a composite transform, or specified in the transform's execution environment.\n\tResourceHint mergeWithOuter(ResourceHint outer);\n\t// Defines how to represent the as bytestring.\n\tabstract byte[] toBytes();\n}", "des": "Provides a definition of a resource hint known to the SDK."}
{"index": 3347, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ResourceIdCoder {\n\t// Returns true if this Coder is injective with respect to Object.equals(java.lang.Object).\n\tboolean consistentWithEquals();\n\t// Decodes a value of type T from the given input stream in the given context.\n\tResourceId decode(java.io.InputStream is);\n\t// Encodes the given value of type T onto the given output stream.\n\tvoid encode(ResourceId value, java.io.OutputStream os);\n\t// Creates a ResourceIdCoder.\n\tstatic ResourceIdCoder of();\n}", "des": "A Coder for ResourceId."}
{"index": 3348, "repo": "beam-sdks-java-core-2.49.0", "code": "Class RestrictionTracker.Progress {\n\t// A representation for the amount of known completed and remaining work.\n\tstatic RestrictionTracker.Progress from(double workCompleted, double workRemaining);\n\t// The known amount of completed work.\n\tabstract double getWorkCompleted();\n\t// The known amount of work remaining.\n\tabstract double getWorkRemaining();\n}", "des": "A representation for the amount of known completed and remaining work. See RestrictionTracker.HasProgress.getProgress() for details."}
{"index": 3349, "repo": "beam-sdks-java-core-2.49.0", "code": "Class RowJson.RowJsonDeserializer {\n\tRow deserialize(com.fasterxml.jackson.core.JsonParser jsonParser, com.fasterxml.jackson.databind.DeserializationContext deserializationContext);\n\t// Creates a deserializer for a Row Schema.\n\tstatic RowJson.RowJsonDeserializer forSchema(Schema schema);\n\t// Sets the behaviour of the deserializer when retrieving null values in the input JSON.\n\tRowJson.RowJsonDeserializer withNullBehavior(RowJson.RowJsonDeserializer.NullBehavior behavior);\n}", "des": "Jackson deserializer for parsing JSON into Rows."}
{"index": 3350, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum RowJson.RowJsonDeserializer.NullBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RowJson.RowJsonDeserializer.NullBehavior valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RowJson.RowJsonDeserializer.NullBehavior[] values();\n}", "des": "An enumeration type for specifying how RowJson.RowJsonDeserializer should expect null values to be represented."}
{"index": 3351, "repo": "beam-sdks-java-core-2.49.0", "code": "Class RowJson.RowJsonSerializer {\n\t// Creates a serializer for a Row Schema.\n\tstatic RowJson.RowJsonSerializer forSchema(Schema schema);\n\tvoid serialize(Row value, com.fasterxml.jackson.core.JsonGenerator gen, com.fasterxml.jackson.databind.SerializerProvider provider);\n\t// Serializer drops nulls on write if set to true instead of writing fieldName: null.\n\tRowJson.RowJsonSerializer withDropNullsOnWrite(java.lang.Boolean dropNullsOnWrite);\n}", "des": "Jackson serializer for converting Rows to JSON."}
{"index": 3352, "repo": "beam-sdks-java-core-2.49.0", "code": "Class RowWithGetters {\n\tboolean equals(@Nullable java.lang.Object o);\n\t// Return the size of data fields.\n\tint getFieldCount();\n\tjava.util.List<FieldValueGetter> getGetters();\n\tjava.lang.Object getGetterTarget();\n\t// Get value by field index, ClassCastException is thrown if schema doesn't match.\n\t<T> T getValue(int fieldIdx);\n\t// Return the list of raw unmodified data values to enable 0-copy code.\n\tjava.util.List<java.lang.Object> getValues();\n}", "des": "A Concrete subclass of Row that delegates to a set of provided FieldValueGetters."}
{"index": 3353, "repo": "beam-sdks-java-core-2.49.0", "code": "Class RowWithStorage {\n\t// Return the size of data fields.\n\tint getFieldCount();\n\t// Get value by field index, ClassCastException is thrown if schema doesn't match.\n\t<T> T getValue(int fieldIdx);\n\t// Return the list of raw unmodified data values to enable 0-copy code.\n\tjava.util.List<java.lang.Object> getValues();\n}", "des": "Concrete subclass of Row that explicitly stores all fields of the row."}
{"index": 3354, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum Schema.EquivalenceNullablePolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Schema.EquivalenceNullablePolicy valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Schema.EquivalenceNullablePolicy[] values();\n}", "des": "Control whether nullable is included in equivalence check."}
{"index": 3355, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface SchemaIO {\n\t// Returns a schema aware reader.\n\tPTransform<PBegin,PCollection<Row>> buildReader();\n\t// Returns a schema aware writer.\n\tPTransform<PCollection<Row>,? extends POutput> buildWriter();\n\t// Returns the schema of the data.\n\tSchema schema();\n}", "des": "An abstraction to create schema capable and aware IOs. The interface is intended to be used in conjunction with the interface SchemaIOProvider."}
{"index": 3356, "repo": "beam-sdks-java-core-2.49.0", "code": "Class SchemaZipFold<T> {\n\t// Accepts two fields, context.parent() is always ROW.\n\tabstract T accept(SchemaZipFold.Context context, java.util.Optional<Schema.Field> left, java.util.Optional<Schema.Field> right);\n\t// Accepts two components, context.parent() is always ROW, MAP, ARRAY or absent.\n\tabstract T accept(SchemaZipFold.Context context, Schema.FieldType left, Schema.FieldType right);\n\t// Accumulate two results together.\n\tabstract T accumulate(T left, T right);\n\tT apply(Schema left, Schema right);\n}", "des": "Visitor that zips schemas, and accepts pairs of fields and their types."}
{"index": 3357, "repo": "beam-sdks-java-core-2.49.0", "code": "Class SchemaZipFold.Context {\n\tstatic SchemaZipFold.Context create(java.util.List<java.lang.String> path, java.util.Optional<Schema.TypeName> parent);\n\t// Type of parent node in a tree.\n\tabstract java.util.Optional<Schema.TypeName> parent();\n\t// Field path from a root of a schema.\n\tabstract java.util.List<java.lang.String> path();\n\tSchemaZipFold.Context withParent(Schema.TypeName parent);\n\tSchemaZipFold.Context withPathPart(java.lang.String part);\n}", "des": "Context referring to a current position in a schema."}
{"index": 3358, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum SdkHarnessOptions.LogLevel {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SdkHarnessOptions.LogLevel valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SdkHarnessOptions.LogLevel[] values();\n}", "des": "The set of log levels that can be used in the SDK harness."}
{"index": 3359, "repo": "beam-sdks-java-core-2.49.0", "code": "Class SinkMetrics {\n\t// Counter of bytes written to a sink.\n\tstatic Counter bytesWritten();\n\t// Counter of elements written to a sink.\n\tstatic Counter elementsWritten();\n}", "des": "Standard Sink Metrics."}
{"index": 3360, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Source<T> {\n\t// Returns the Coder to use for the data read from this source.\n\tCoder<T> getOutputCoder();\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n\t// Checks that this source is valid, before it can be used in a pipeline.\n\tvoid validate();\n}", "des": "Base class for defining input formats and creating a Source for reading the input."}
{"index": 3361, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum SourceTestUtils.ExpectedSplitOutcome {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SourceTestUtils.ExpectedSplitOutcome valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SourceTestUtils.ExpectedSplitOutcome[] values();\n}", "des": "Expected outcome of BoundedSource.BoundedReader.splitAtFraction(double)."}
{"index": 3362, "repo": "beam-sdks-java-core-2.49.0", "code": "Class SplitResult<RestrictionT> {\n\t// Returns the primary restriction.\n\tabstract RestrictionT getPrimary();\n\t// Returns the residual restriction.\n\tabstract RestrictionT getResidual();\n\t// Returns a SplitResult for the specified primary and residual restrictions.\n\tstatic <RestrictionT>SplitResult<RestrictionT> of(RestrictionT primary, RestrictionT residual);\n}", "des": "A representation of a split result."}
{"index": 3363, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface StateContext<W extends BoundedWindow> {\n\t// Returns the PipelineOptions specified with the PipelineRunner.\n\tPipelineOptions getPipelineOptions();\n\t// Returns the value of the side input for the corresponding state window.\n\t<T> T sideInput(PCollectionView<T> view);\n\t// Returns the window corresponding to the state.\n\tW window();\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3364, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface StateSpec<StateT extends State> {\n\t// For internal use only; no backwards-compatibility guarantees.\n\tStateT bind(java.lang.String id, StateBinder binder);\n\t// For internal use only; no backwards-compatibility guarantees.\n\tvoid finishSpecifying();\n\t// For internal use only; no backwards-compatibility guarantees.\n\t<ResultT> ResultT match(StateSpec.Cases<ResultT> cases);\n\t// For internal use only; no backwards-compatibility guarantees.\n\tvoid offerCoders(Coder[] coders);\n}", "des": "A specification of a persistent state cell. This includes information necessary to encode the value and details about the intended access pattern."}
{"index": 3365, "repo": "beam-sdks-java-core-2.49.0", "code": "Class StaticSchemaInference {\n\t// Map a Java field type to a Beam Schema FieldType.\n\tstatic Schema.FieldType fieldFromType(TypeDescriptor type, FieldValueTypeSupplier fieldValueTypeSupplier);\n\t// Infer a schema from a Java class.\n\tstatic Schema schemaFromClass(java.lang.Class<?> clazz, FieldValueTypeSupplier fieldValueTypeSupplier);\n\tstatic java.util.List<FieldValueTypeInformation> sortBySchema(java.util.List<FieldValueTypeInformation> types, Schema schema);\n}", "des": "A set of utilities for inferring a Beam Schema from static Java types."}
{"index": 3366, "repo": "beam-sdks-java-core-2.49.0", "code": "Class StringUtils {\n\t// Converts the given array of bytes into a legal JSON string.\n\tstatic java.lang.String byteArrayToJsonString(byte[] bytes);\n\t// Calculate the Levenshtein distance between two strings.\n\tstatic int getLevenshteinDistance(java.lang.String s, java.lang.String t);\n\t// Converts the given string, encoded using byteArrayToJsonString(byte[]), into a byte array.\n\tstatic byte[] jsonStringToByteArray(java.lang.String string);\n}", "des": "Utilities for working with JSON and other human-readable string formats."}
{"index": 3367, "repo": "beam-sdks-java-core-2.49.0", "code": "Class TaggedPValue {\n\t// Returns the local tag associated with the PValue.\n\tabstract TupleTag<?> getTag();\n\t// Returns the PCollection.\n\tabstract PCollection<?> getValue();\n\tstatic TaggedPValue of(TupleTag<?> tag, PCollection<?> value);\n\tstatic TaggedPValue ofExpandedValue(PCollection<?> value);\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3368, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum TestStream.EventType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TestStream.EventType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TestStream.EventType[] values();\n}", "des": "The types of TestStream.Event that are supported by TestStream."}
{"index": 3369, "repo": "beam-sdks-java-core-2.49.0", "code": "Class TextIO.ReadFiles {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<java.lang.String> expand(PCollection<FileIO.ReadableFile> input);\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n\t// Like Read#withDelimiter.\n\tTextIO.ReadFiles withDelimiter(byte[] delimiter);\n}", "des": "Implementation of TextIO.readFiles()."}
{"index": 3370, "repo": "beam-sdks-java-core-2.49.0", "code": "Class TextIO.Sink {\n\t// Flushes the buffered state (if any) before the channel is closed.\n\tvoid flush();\n\t// Initializes writing to the given channel.\n\tvoid open(java.nio.channels.WritableByteChannel channel);\n\tTextIO.Sink withFooter(java.lang.String footer);\n\tTextIO.Sink withHeader(java.lang.String header);\n\t// Appends a single element to the file.\n\tvoid write(java.lang.String element);\n}", "des": "Implementation of TextIO.sink()."}
{"index": 3371, "repo": "beam-sdks-java-core-2.49.0", "code": "Class TFRecordIO.Sink {\n\t// Flushes the buffered state (if any) before the channel is closed.\n\tvoid flush();\n\t// Initializes writing to the given channel.\n\tvoid open(java.nio.channels.WritableByteChannel channel);\n\t// Appends a single element to the file.\n\tvoid write(byte[] element);\n}", "des": "A FileIO.Sink for use with FileIO.write() and FileIO.writeDynamic()."}
{"index": 3372, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum TimeDomain {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TimeDomain valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TimeDomain[] values();\n}", "des": "TimeDomain specifies whether an operation is based on timestamps of elements or current \"real-world\" time as reported while processing."}
{"index": 3373, "repo": "beam-sdks-java-core-2.49.0", "code": "Class TimestampedValue<V> {\n\t// Returns a new TimestampedValue with the minimum timestamp.\n\tstatic <V> TimestampedValue<V> atMinimumTimestamp(V value);\n\tboolean equals(@Nullable java.lang.Object other);\n\torg.joda.time.Instant getTimestamp();\n\tV getValue();\n\t// Returns a new TimestampedValue with the given value and timestamp.\n\tstatic <V> TimestampedValue<V> of(V value, org.joda.time.Instant timestamp);\n}", "des": "An immutable pair of a value and a timestamp."}
{"index": 3374, "repo": "beam-sdks-java-core-2.49.0", "code": "Class TimestampTransform {\n\t// For internal use only; no backwards-compatibility guarantees.\n\tstatic TimestampTransform alignTo(org.joda.time.Duration period);\n\t// For internal use only; no backwards-compatibility guarantees.\n\tstatic TimestampTransform alignTo(org.joda.time.Duration period, org.joda.time.Instant offset);\n\t// For internal use only; no backwards-compatibility guarantees.\n\tstatic TimestampTransform delay(org.joda.time.Duration delay);\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3375, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Trigger.OnceTrigger {\n\t// Return a trigger to use after a GroupByKey to preserve the intention of this trigger.\n\tTrigger.OnceTrigger getContinuationTrigger();\n\t// For internal use only; no backwards-compatibility guarantees.\n\tboolean mayFinish();\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3376, "repo": "beam-sdks-java-core-2.49.0", "code": "Class TupleTag<V> {\n\tboolean equals(@Nullable java.lang.Object that);\n\t// Returns the id of this TupleTag.\n\tjava.lang.String getId();\n\t// If this TupleTag is tagging output outputIndex of a PTransform, returns the name that should be used by default for the output.\n\tjava.lang.String getOutName(int outIndex);\n\t// Returns a TypeDescriptor capturing what is known statically about the type of this TupleTag instance's most-derived class.\n\tTypeDescriptor<V> getTypeDescriptor();\n}", "des": "A TupleTag is a typed tag to use as the key of a heterogeneously typed tuple, like PCollectionTuple. Its generic type parameter allows tracking the static type of things stored in tuples."}
{"index": 3377, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface ValueProvider<T> {\n\t// Returns the runtime value wrapped by this ValueProvider in case it is isAccessible(), otherwise fails.\n\tT get();\n\t// Whether the contents of this ValueProvider is currently available via get().\n\tboolean isAccessible();\n}", "des": "A ValueProvider abstracts the notion of fetching a value that may or may not be currently available."}
{"index": 3378, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ValueProvider.RuntimeValueProvider<T> {\n\tboolean equals(@Nullable java.lang.Object other);\n\t// Returns the runtime value wrapped by this ValueProvider in case it is ValueProvider.isAccessible(), otherwise fails.\n\tT get();\n\t// Whether the contents of this ValueProvider is currently available via ValueProvider.get().\n\tboolean isAccessible();\n\t// Returns the property name that corresponds to this provider.\n\tjava.lang.String propertyName();\n}", "des": "ValueProvider.RuntimeValueProvider is an implementation of ValueProvider that allows for a value to be provided at execution time rather than at graph construction time."}
{"index": 3379, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ValueProvider.StaticValueProvider<T> {\n\tboolean equals(@Nullable java.lang.Object other);\n\t// Returns the runtime value wrapped by this ValueProvider in case it is ValueProvider.isAccessible(), otherwise fails.\n\tT get();\n\t// Whether the contents of this ValueProvider is currently available via ValueProvider.get().\n\tboolean isAccessible();\n\t// Creates a ValueProvider.StaticValueProvider that wraps the provided value.\n\tstatic <T> ValueProvider.StaticValueProvider<T> of(T value);\n}", "des": "ValueProvider.StaticValueProvider is an implementation of ValueProvider that allows for a static value to be provided."}
{"index": 3380, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Values<V> {\n\t// Returns a Values<V> PTransform.\n\tstatic <V> Values<V> create();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<V> expand(PCollection<? extends KV<?,V>> in);\n}", "des": "Values<V> takes a PCollection of KV<K, V>s and returns a PCollection<V> of the values."}
{"index": 3381, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface ValueState<T> {\n\t// Read the current value, blocking until it is available.\n\tT read();\n\t// Indicate that the value will be read later.\n\tValueState<T> readLater();\n\t// Set the value.\n\tvoid write(T input);\n}", "des": "A ReadableState cell containing a single value."}
{"index": 3382, "repo": "beam-sdks-java-core-2.49.0", "code": "Class VariableBytes {\n\tint getMaxLength();\n\t@Nullable java.lang.String getName();\n\t// Return an instance of VariableBytes with specified max byte array length.\n\tstatic VariableBytes of(int maxByteArrayLength);\n\t// Return an instance of VariableBytes with specified max byte array length.\n\tstatic VariableBytes of(@Nullable java.lang.String name, int maxByteArrayLength);\n\t// Convert the Java type used by the base Schema.FieldType to the input type.\n\tbyte[] toInputType(byte[] base);\n}", "des": "A LogicalType representing a variable-length byte array with specified maximum length."}
{"index": 3383, "repo": "beam-sdks-java-core-2.49.0", "code": "Class VariableString {\n\tint getMaxLength();\n\t@Nullable java.lang.String getName();\n\t// Return an instance of VariableString with specified max string length.\n\tstatic VariableString of(int maxStringLength);\n\t// Return an instance of VariableString with specified max string length.\n\tstatic VariableString of(@Nullable java.lang.String name, int maxStringLength);\n\t// Convert the Java type used by the base Schema.FieldType to the input type.\n\tjava.lang.String toInputType(java.lang.String base);\n}", "des": "A LogicalType representing a variable-length string with specified maximum length."}
{"index": 3384, "repo": "beam-sdks-java-core-2.49.0", "code": "Class View.AsSingleton<T> {\n\t// Returns the default value of this transform, or null if there isn't one.\n\tT defaultValue();\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollectionView<T> expand(PCollection<T> input);\n\t// Returns whether this transform has a default value.\n\tboolean hasDefaultValue();\n\t// Default value to return for windows with no value in them.\n\tView.AsSingleton<T> withDefaultValue(T defaultValue);\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3385, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ViewFn<PrimitiveViewT,ViewT> {\n\t// A function to adapt a primitive view type to a desired view type.\n\tabstract ViewT apply(PrimitiveViewT primitiveViewT);\n\t// Gets the materialization of this ViewFn.\n\tabstract Materialization<PrimitiveViewT> getMaterialization();\n\t// Return the TypeDescriptor describing the output of this fn.\n\tabstract TypeDescriptor<ViewT> getTypeDescriptor();\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3386, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Wait {\n\t// Waits on the given signal collections.\n\tstatic <T> Wait.OnSignal<T> on(java.util.List<PCollection<?>> signals);\n\t// Waits on the given signal collections.\n\tstatic <T> Wait.OnSignal<T> on(PCollection<?>... signals);\n}", "des": "Delays processing of each window in a PCollection until signaled."}
{"index": 3387, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface WatermarkEstimator<WatermarkEstimatorStateT> {\n\t// Return estimated output watermark.\n\torg.joda.time.Instant currentWatermark();\n\t// Get current state of the WatermarkEstimator instance, which can be used to recreate the WatermarkEstimator when processing the restriction.\n\tWatermarkEstimatorStateT getState();\n}", "des": "A WatermarkEstimator which is used for estimating output watermarks of a splittable DoFn. See WatermarkEstimators for commonly used watermark estimators."}
{"index": 3388, "repo": "beam-sdks-java-core-2.49.0", "code": "Class WatermarkEstimators.Manual {\n\t// Return estimated output watermark.\n\torg.joda.time.Instant currentWatermark();\n\t// Get current state of the WatermarkEstimator instance, which can be used to recreate the WatermarkEstimator when processing the restriction.\n\torg.joda.time.Instant getState();\n\t// Sets a timestamp before or at the timestamps of all future elements produced by the associated DoFn.\n\tvoid setWatermark(org.joda.time.Instant watermark);\n}", "des": "Concrete implementation of a ManualWatermarkEstimator."}
{"index": 3389, "repo": "beam-sdks-java-core-2.49.0", "code": "Class WatermarkEstimators.MonotonicallyIncreasing {\n\t// Return estimated output watermark.\n\torg.joda.time.Instant currentWatermark();\n\t// Get current state of the WatermarkEstimator instance, which can be used to recreate the WatermarkEstimator when processing the restriction.\n\torg.joda.time.Instant getState();\n\t// Update watermark estimate with latest output timestamp.\n\tvoid observeTimestamp(org.joda.time.Instant timestamp);\n}", "des": "A watermark estimator that observes timestamps of records output from a DoFn reporting the timestamp of the last element seen as the current watermark."}
{"index": 3390, "repo": "beam-sdks-java-core-2.49.0", "code": "Class WatermarkEstimators.WallTime {\n\t// Return estimated output watermark.\n\torg.joda.time.Instant currentWatermark();\n\t// Get current state of the WatermarkEstimator instance, which can be used to recreate the WatermarkEstimator when processing the restriction.\n\torg.joda.time.Instant getState();\n}", "des": "A watermark estimator that tracks wall time."}
{"index": 3391, "repo": "beam-sdks-java-core-2.49.0", "code": "Interface WatermarkHoldState {\n\t// Return the TimestampCombiner which will be used to determine a watermark hold time given an element timestamp, and to combine watermarks from windows which are about to be merged.\n\tTimestampCombiner getTimestampCombiner();\n\t// Indicate that the value will be read later.\n\tWatermarkHoldState readLater();\n}", "des": "For internal use only; no backwards-compatibility guarantees."}
{"index": 3392, "repo": "beam-sdks-java-core-2.49.0", "code": "Class Window.Assign<T> {\n\t// Override this method to specify how this PTransform should be expanded on the given InputT.\n\tPCollection<T> expand(PCollection<T> input);\n\t@Nullable WindowFn<T,?> getWindowFn();\n\t// Register display data for the given transform or component.\n\tvoid populateDisplayData(DisplayData.Builder builder);\n}", "des": "A Primitive PTransform that assigns windows to elements based on a WindowFn. Pipeline authors should use Window directly instead."}
{"index": 3393, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum Window.ClosingBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Window.ClosingBehavior valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Window.ClosingBehavior[] values();\n}", "des": "Specifies the conditions under which a final pane will be created when a window is permanently closed."}
{"index": 3394, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum Window.OnTimeBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Window.OnTimeBehavior valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Window.OnTimeBehavior[] values();\n}", "des": "Specifies the conditions under which an on-time pane will be created when a window is closed."}
{"index": 3395, "repo": "beam-sdks-java-core-2.49.0", "code": "Class WindowedValue.WindowedValueCoder<T> {\n\t// Returns the value coder.\n\tCoder<T> getValueCoder();\n\t// Returns a new WindowedValueCoder that is a copy of this one, but with a different value coder.\n\tabstract <NewT> WindowedValue.WindowedValueCoder<NewT> withValueCoder(Coder<NewT> valueCoder);\n}", "des": "Abstract class for WindowedValue coder."}
{"index": 3396, "repo": "beam-sdks-java-core-2.49.0", "code": "Enum WindowingStrategy.AccumulationMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WindowingStrategy.AccumulationMode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WindowingStrategy.AccumulationMode[] values();\n}", "des": "The accumulation modes that can be used with windowing."}
{"index": 3397, "repo": "beam-sdks-java-core-2.49.0", "code": "Class WindowMappingFn<TargetWindowT extends BoundedWindow> {\n\t// Returns the window of the side input corresponding to the given window of the main input.\n\tabstract TargetWindowT getSideInputWindow(BoundedWindow mainWindow);\n\t// The maximum distance between the end of any main input window mainWindow and the end of the side input window returned by getSideInputWindow(BoundedWindow)\n\torg.joda.time.Duration maximumLookback();\n}", "des": "A function that takes the windows of elements in a main input and maps them to the appropriate window in a PCollectionView consumed as a side input."}
{"index": 3398, "repo": "beam-sdks-java-core-2.49.0", "code": "Class ZipFiles {\n\t// Zips an entire directory specified by the path.\n\tstatic void zipDirectory(java.io.File sourceDirectory, java.io.File zipFile);\n\t// Zips an entire directory specified by the path.\n\tstatic void zipDirectory(java.io.File sourceDirectory, java.io.OutputStream outputStream);\n\t// Zips an entire directory specified by the path.\n\tstatic void zipDirectoryOverwrite(java.io.File sourceDirectory, java.io.File zipFile);\n}", "des": "Functions for zipping a directory (including a subdirectory) into a ZIP-file or unzipping it again."}
{"index": 3399, "repo": "hadoop-common-3.3.4", "code": "Interface Abortable.AbortableResult {\n\t// Was the stream already closed/aborted?\n\tboolean alreadyClosed();\n\t// Any exception caught during cleanup operations, exceptions whose raising/catching does not change the semantics of the abort.\n\tIOException anyCleanupException();\n}", "des": "Interface for the result of aborts; allows subclasses to extend (IOStatistics etc) or for future enhancements if ever needed."}
{"index": 3400, "repo": "hadoop-common-3.3.4", "code": "Enum AbstractGangliaSink.GangliaConfType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AbstractGangliaSink.GangliaConfType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AbstractGangliaSink.GangliaConfType[] values();\n}", "des": "define enum for various type of conf"}
{"index": 3401, "repo": "hadoop-common-3.3.4", "code": "Enum AbstractGangliaSink.GangliaSlope {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AbstractGangliaSink.GangliaSlope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AbstractGangliaSink.GangliaSlope[] values();\n}", "des": "ganglia slope values which equal the ordinal"}
{"index": 3402, "repo": "hadoop-common-3.3.4", "code": "Class AbstractLaunchableService {\n\t// Propagate the command line arguments.\n\tConfiguration bindArgs(Configuration config, List<String> args);\n\t// Run a service.\n\tint execute();\n}", "des": "Subclass of AbstractService that provides basic implementations of the LaunchableService methods."}
{"index": 3403, "repo": "hadoop-common-3.3.4", "code": "Class AbstractMetric {\n\t// Typically the description corresponds to annotation Metric.about() or the name of the class.\n\tString description();\n\tboolean equals(Object obj);\n\tprotected MetricsInfo info();\n\t// Typically name corresponds to annotation Metric.value() or the name of the class.\n\tString name();\n\t// Get the type of the metric\n\tabstract MetricType type();\n\t// Get the value of the metric\n\tabstract Number value();\n\t// Accept a visitor interface\n\tabstract void visit(MetricsVisitor visitor);\n}", "des": "The immutable metric"}
{"index": 3404, "repo": "hadoop-common-3.3.4", "code": "Class AnnotatedSecurityInfo {\n\t// Get the KerberosInfo for a given protocol.\n\torg.apache.hadoop.security.KerberosInfo getKerberosInfo(Class<?> protocol, Configuration conf);\n\t// Get the TokenInfo for a given protocol.\n\tTokenInfo getTokenInfo(Class<?> protocol, Configuration conf);\n}", "des": "Constructs SecurityInfo from Annotations provided in protocol interface."}
{"index": 3405, "repo": "hadoop-common-3.3.4", "code": "Class ArrayFile.Reader {\n\t// Return the nth value in the file.\n\tWritable get(long n, Writable value);\n\t// Returns the key associated with the most recent call to seek(long), next(Writable), or get(long,Writable).\n\tlong key();\n\t// Read and return the next value in the file.\n\tWritable next(Writable value);\n\t// Positions the reader before its nth value.\n\tvoid seek(long n);\n}", "des": "Provide access to an existing array file."}
{"index": 3406, "repo": "hadoop-common-3.3.4", "code": "Class ArrayPrimitiveWritable {\n\t// Get the original array.\n\tObject get();\n\tClass<?> getComponentType();\n\tClass<?> getDeclaredComponentType();\n\tboolean isDeclaredComponentType(Class<?> componentType);\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\tvoid set(Object value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "This is a wrapper class. It wraps a Writable implementation around an array of primitives (e.g., int[], long[], etc.), with optimized wire format, and without creating new objects per element. This is a wrapper class only; it does not make a copy of the underlying array."}
{"index": 3407, "repo": "hadoop-common-3.3.4", "code": "Class ArrayWritable {\n\tWritable[] get();\n\tClass<? extends Writable> getValueClass();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\tvoid set(Writable[] values);\n\tObject toArray();\n\tString[] toStrings();\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A Writable for arrays containing instances of a class. The elements of this writable must all be instances of the same class. If this writable will be the input for a Reducer, you will need to create a subclass that sets the value to be of the proper type. For example: public class IntArrayWritable extends ArrayWritable { public IntArrayWritable() { super(IntWritable.class); } }"}
{"index": 3408, "repo": "hadoop-common-3.3.4", "code": "Class AutoCloseableLock {\n\t// A wrapper method that makes a call to lock() of the underlying ReentrantLock object.\n\tAutoCloseableLock acquire();\n\t// Attempts to release the lock by making a call to release().\n\tvoid close();\n\t// See ReentrantLock.newCondition().\n\tCondition newCondition();\n\t// A wrapper method that makes a call to unlock() of the underlying ReentrantLock object.\n\tvoid release();\n\t// A wrapper method that makes a call to tryLock() of the underlying Lock object.\n\tboolean tryLock();\n}", "des": "This is a wrap class of a ReentrantLock. Extending AutoCloseable interface such that the users can use a try-with-resource syntax."}
{"index": 3409, "repo": "hadoop-common-3.3.4", "code": "Class AvroRecord.Builder {\n\tAvroRecord build();\n\t// Clears the value of the 'intField' field\n\tAvroRecord.Builder clearIntField();\n\t// Gets the value of the 'intField' field\n\tInteger getIntField();\n\t// Checks whether the 'intField' field has been set\n\tboolean hasIntField();\n\t// Sets the value of the 'intField' field\n\tAvroRecord.Builder setIntField(int value);\n}", "des": "RecordBuilder for AvroRecord instances."}
{"index": 3410, "repo": "hadoop-common-3.3.4", "code": "Class BatchedRemoteIterator<K,E> {\n\t// Return the next list key associated with an element.\n\tabstract K elementToPrevKey(E element);\n\t// Returns true if the iteration has more elements.\n\tboolean hasNext();\n\t// Perform the actual remote request.\n\tabstract BatchedRemoteIterator.BatchedEntries<E> makeRequest(K prevKey);\n\t// Returns the next element in the iteration.\n\tE next();\n}", "des": "A RemoteIterator that fetches elements in batches."}
{"index": 3411, "repo": "hadoop-common-3.3.4", "code": "Interface BatchListingOperations {\n\t// Batched listing API that returns PartialListings for the passed Paths.\n\tRemoteIterator<PartialListing<LocatedFileStatus>> batchedListLocatedStatusIterator(List<Path> paths);\n\t// Batched listing API that returns PartialListings for the passed Paths.\n\tRemoteIterator<PartialListing<FileStatus>> batchedListStatusIterator(List<Path> paths);\n}", "des": "Interface filesystems MAY implement to offer a batched list. If implemented, filesystems SHOULD declare CommonPathCapabilities.FS_EXPERIMENTAL_BATCH_LISTING to be a supported path capability."}
{"index": 3412, "repo": "hadoop-common-3.3.4", "code": "Class BinaryComparable {\n\t// Compare bytes from {#getBytes()}.\n\tint compareTo(BinaryComparable other);\n\t// Compare bytes from {#getBytes()} to those provided.\n\tint compareTo(byte[] other, int off, int len);\n\t// Return true if bytes from {#getBytes()} match.\n\tboolean equals(Object other);\n\t// Return representative byte array for this instance.\n\tabstract byte[] getBytes();\n\t// Return n st bytes 0..n-1 from {#getBytes()} are valid.\n\tabstract int getLength();\n}", "des": "Interface supported by WritableComparable types supporting ordering/permutation by a representative set of bytes."}
{"index": 3413, "repo": "hadoop-common-3.3.4", "code": "Class BlockCompressorStream {\n\tprotected void compress();\n\t// Finishes writing compressed data to the output stream without closing the underlying stream.\n\tvoid finish();\n\t// Write the data provided to the compression codec, compressing no more than the buffer size less the compression overhead as specified during construction for each block.\n\tvoid write(byte[] b, int off, int len);\n}", "des": "A CompressorStream which works with 'block-based' based compression algorithms, as opposed to 'stream-based' compression algorithms. It should be noted that this wrapper does not guarantee that blocks will be sized for the compressor. If the Compressor requires buffering to effect meaningful compression, it is responsible for it."}
{"index": 3414, "repo": "hadoop-common-3.3.4", "code": "Class BooleanWritable {\n\tint compareTo(BooleanWritable o);\n\tboolean equals(Object o);\n\t// Returns the value of the BooleanWritable\n\tboolean get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Set the value of the BooleanWritable\n\tvoid set(boolean value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for booleans."}
{"index": 3415, "repo": "hadoop-common-3.3.4", "code": "Class BufferedIOStatisticsInputStream {\n\t// Return any IOStatistics offered by the inner stream.\n\tIOStatistics getIOStatistics();\n\t// If the inner stream supports StreamCapabilities, forward the probe to it.\n\tboolean hasCapability(String capability);\n}", "des": "An extension of BufferedInputStream which implements IOStatisticsSource and forwards requests for the IOStatistics to the wrapped stream. This should be used when any input stream needs buffering while allowing the inner stream to be a source of statistics. It also implements StreamCapabilities and forwards the probe to the inner stream, if possible."}
{"index": 3416, "repo": "hadoop-common-3.3.4", "code": "Class BufferedIOStatisticsOutputStream {\n\t// Ask the inner stream for their IOStatistics.\n\tIOStatistics getIOStatistics();\n\t// If the inner stream supports StreamCapabilities, forward the probe to it.\n\tboolean hasCapability(String capability);\n\t// If the inner stream is Syncable, flush the buffer and then invoke the inner stream's hflush() operation.\n\tvoid hflush();\n\t// If the inner stream is Syncable, flush the buffer and then invoke the inner stream's hsync() operation.\n\tvoid hsync();\n}", "des": "An extension of BufferedOutputStream which implements IOStatisticsSource and forwards requests for the IOStatistics to the wrapped stream. This should be used when any output stream needs buffering while allowing the inner stream to be a source of statistics. It also implements StreamCapabilities and Syncable and forwards to to the inner stream, if possible."}
{"index": 3417, "repo": "hadoop-common-3.3.4", "code": "Interface ByteBufferPositionedReadable {\n\t// Reads up to buf.remaining() bytes into buf from a given position in the file and returns the number of bytes read.\n\tint read(long position, ByteBuffer buf);\n\t// Reads buf.remaining() bytes into buf from a given position in the file or until the end of the data was reached before the read operation completed.\n\tvoid readFully(long position, ByteBuffer buf);\n}", "des": "Implementers of this interface provide a positioned read API that writes to a ByteBuffer rather than a byte[]."}
{"index": 3418, "repo": "hadoop-common-3.3.4", "code": "Class ByteWritable {\n\t// Compares two ByteWritables.\n\tint compareTo(ByteWritable o);\n\t// Returns true iff o is a ByteWritable with the same value.\n\tboolean equals(Object o);\n\t// Return the value of this ByteWritable.\n\tbyte get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Set the value of this ByteWritable.\n\tvoid set(byte value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for a single byte."}
{"index": 3419, "repo": "hadoop-common-3.3.4", "code": "Class CacheableIPList {\n\t// returns true if the ipAddress is in the IPList.\n\tboolean isIn(String ipAddress);\n\t// Refreshes the ip list\n\tvoid refresh();\n}", "des": "CacheableIPList loads a list of subnets from a file. The list is cached and the cache can be refreshed by specifying cache timeout. A negative value of cache timeout disables any caching. Thread safe."}
{"index": 3420, "repo": "hadoop-common-3.3.4", "code": "Class CloseableReferenceCount {\n\t// Get the current reference count.\n\tint getReferenceCount();\n\t// Return true if the status is currently open.\n\tboolean isOpen();\n\t// Increment the reference count.\n\tvoid reference();\n\t// Mark the status as closed.\n\tint setClosed();\n\t// Decrement the reference count.\n\tboolean unreference();\n\t// Decrement the reference count, checking to make sure that the CloseableReferenceCount is not closed.\n\tvoid unreferenceCheckClosed();\n}", "des": "A closeable object that maintains a reference count. Once the object is closed, attempting to take a new reference will throw ClosedChannelException."}
{"index": 3421, "repo": "hadoop-common-3.3.4", "code": "Class CompressionOutputStream {\n\tvoid close();\n\t// Finishes writing compressed data to the output stream without closing the underlying stream.\n\tabstract void finish();\n\tvoid flush();\n\t// Return any IOStatistics provided by the underlying stream.\n\tIOStatistics getIOStatistics();\n\t// Reset the compression to the initial state.\n\tabstract void resetState();\n\t// Write compressed bytes to the stream.\n\tabstract void write(byte[] b, int off, int len);\n}", "des": "A compression output stream."}
{"index": 3422, "repo": "hadoop-common-3.3.4", "code": "Interface Configurable {\n\t// Return the configuration used by this object.\n\tConfiguration getConf();\n\t// Set the configuration to be used by this object.\n\tvoid setConf(Configuration conf);\n}", "des": "Something that may be configured with a Configuration."}
{"index": 3423, "repo": "hadoop-common-3.3.4", "code": "Class Configuration.IntegerRanges {\n\t// Get range start for the first integer range.\n\tint getRangeStart();\n\tboolean isEmpty();\n\t// Is the given value in the set of ranges\n\tboolean isIncluded(int value);\n\tIterator<Integer> iterator();\n}", "des": "A class that represents a set of positive integer ranges. It parses strings of the form: \"2-3,5,7-\" where ranges are separated by comma and the lower/upper bounds are separated by dash. Either the lower or upper bound may be omitted meaning all values up to or over. So the string above means 2, 3, 5, and 7, 8, 9, ..."}
{"index": 3424, "repo": "hadoop-common-3.3.4", "code": "Class Configured {\n\t// Return the configuration used by this object.\n\tConfiguration getConf();\n\t// Set the configuration to be used by this object.\n\tvoid setConf(Configuration conf);\n}", "des": "Base class for things that may be configured with a Configuration."}
{"index": 3425, "repo": "hadoop-common-3.3.4", "code": "Interface ConsumerRaisingIOE<T> {\n\t// Process the argument.\n\tvoid accept(T t);\n\t// after calling accept(Object), invoke the next consumer in the chain.\n\tdefault ConsumerRaisingIOE<T> andThen(ConsumerRaisingIOE<? super T> next);\n}", "des": "Version of java.util.function.Consumer which raises exceptions."}
{"index": 3426, "repo": "hadoop-common-3.3.4", "code": "Class CredentialShell {\n\t// Return usage string for the command including any summary of subcommands.\n\tString getCommandUsage();\n\tCredentialShell.PasswordReader getPasswordReader();\n\t// Parse the command line arguments and initialize the data.\n\tprotected int init(String[] args);\n\t// Main program.\n\tstatic void main(String[] args);\n\tprotected char[] promptForCredential();\n\tvoid setPasswordReader(CredentialShell.PasswordReader reader);\n}", "des": "This program is the CLI utility for the CredentialProvider facilities in Hadoop."}
{"index": 3427, "repo": "hadoop-common-3.3.4", "code": "Enum DataChecksum.Type {\n\tstatic DataChecksum.Type valueOf(int id);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DataChecksum.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DataChecksum.Type[] values();\n}", "des": "The checksum types"}
{"index": 3428, "repo": "hadoop-common-3.3.4", "code": "Enum DelegatingSSLSocketFactory.SSLChannelMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DelegatingSSLSocketFactory.SSLChannelMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DelegatingSSLSocketFactory.SSLChannelMode[] values();\n}", "des": "Default indicates Ordered, preferred OpenSSL, if failed to load then fall back to Default_JSSE."}
{"index": 3429, "repo": "hadoop-common-3.3.4", "code": "Interface DNSToSwitchMapping {\n\t// Reload all of the cached mappings.\n\tvoid reloadCachedMappings();\n\t// Reload cached mappings on specific nodes.\n\tvoid reloadCachedMappings(List<String> names);\n\t// Resolves a list of DNS-names/IP-addresses and returns back a list of switch information (network paths).\n\tList<String> resolve(List<String> names);\n}", "des": "An interface that must be implemented to allow pluggable DNS-name/IP-address to RackID resolvers."}
{"index": 3430, "repo": "hadoop-common-3.3.4", "code": "Class DoubleWritable {\n\tint compareTo(DoubleWritable o);\n\t// Returns true iff o is a DoubleWritable with the same value.\n\tboolean equals(Object o);\n\tdouble get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\tvoid set(double value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "Writable for Double values."}
{"index": 3431, "repo": "hadoop-common-3.3.4", "code": "Interface DtFetcher {\n\t// Add any number of delegation tokens to Credentials object and return a token instance that is appropriate for aliasing, or null if none.\n\tToken<?> addDelegationTokens(Configuration conf, Credentials creds, String renewer, String url);\n\t// Return a key used to identify the object/service implementation.\n\tText getServiceName();\n\t// Used to allow the service API to indicate whether a token is required.\n\tboolean isTokenRequired();\n}", "des": "DtFetcher is an interface which permits the abstraction and separation of delegation token fetch implementaions across different packages and compilation units. Resolution of fetcher impl will be done at runtime."}
{"index": 3432, "repo": "hadoop-common-3.3.4", "code": "Class DtUtilShell {\n\t// Return usage string for the command including any summary of subcommands.\n\tString getCommandUsage();\n\t// Parse the command line arguments and initialize subcommand.\n\tprotected int init(String[] args);\n\tstatic void main(String[] args);\n}", "des": "DtUtilShell is a set of command line token file management operations."}
{"index": 3433, "repo": "hadoop-common-3.3.4", "code": "Class DurationStatisticSummary {\n\t// Fetch the duration timing summary of success or failure operations from an IO Statistics source.\n\tstatic DurationStatisticSummary fetchDurationSummary(IOStatistics source, String key, boolean success);\n\t// Fetch the duration timing summary from an IOStatistics source.\n\tstatic DurationStatisticSummary fetchSuccessSummary(IOStatistics source, String key);\n\tlong getCount();\n\tString getKey();\n\tlong getMax();\n\tMeanStatistic getMean();\n\tlong getMin();\n\tboolean isSuccess();\n}", "des": "Summary of duration tracking statistics as extracted from an IOStatistics instance."}
{"index": 3434, "repo": "hadoop-common-3.3.4", "code": "Interface DurationTracker {\n\t// Get the duration of an operation as a java Duration instance.\n\tdefault Duration asDuration();\n\t// Finish tracking: update the statistics with the timings.\n\tvoid close();\n\t// The operation failed.\n\tvoid failed();\n}", "des": "Interface to be implemented by objects which can track duration. It extends AutoCloseable to fit into a try-with-resources statement, but then strips out the throws Exception aspect of the signature so it doesn't force code to add extra handling for any failures. If a duration is declared as \"failed()\" then the failure counters will be updated."}
{"index": 3435, "repo": "hadoop-common-3.3.4", "code": "Interface DurationTrackerFactory {\n\t// Initiate a duration tracking operation by creating/returning an object whose close() call will update the statistics.\n\tdefault DurationTracker trackDuration(String key);\n\t// Initiate a duration tracking operation by creating/returning an object whose close() call will update the statistics.\n\tdefault DurationTracker trackDuration(String key, long count);\n}", "des": "Interface for a source of duration tracking. This is intended for uses where it can be passed into classes which update operation durations, without tying those classes to internal implementation details."}
{"index": 3436, "repo": "hadoop-common-3.3.4", "code": "Class ECSchema {\n\tboolean equals(Object o);\n\t// Get the codec name\n\tString getCodecName();\n\t// Get extra options specific to a erasure code.\n\tMap<String,String> getExtraOptions();\n\t// Get required data units count in a coding group\n\tint getNumDataUnits();\n\t// Get required parity units count in a coding group\n\tint getNumParityUnits();\n}", "des": "Erasure coding schema to housekeeper relevant information."}
{"index": 3437, "repo": "hadoop-common-3.3.4", "code": "Class ElasticByteBufferPool {\n\t// Get a new direct ByteBuffer.\n\tByteBuffer getBuffer(boolean direct, int length);\n\t// Release a buffer back to the pool.\n\tvoid putBuffer(ByteBuffer buffer);\n}", "des": "This is a simple ByteBufferPool which just creates ByteBuffers as needed. It also caches ByteBuffers after they're released. It will always return the smallest cached buffer with at least the capacity you request. We don't try to do anything clever here like try to limit the maximum cache size."}
{"index": 3438, "repo": "hadoop-common-3.3.4", "code": "Class ErasureCodeNative {\n\t// Is the native ISA-L library loaded and initialized? Throw exception if not.\n\tstatic void checkNativeCodeLoaded();\n\t// Get the native library name that's available or supported.\n\tstatic String getLibraryName();\n\tstatic String getLoadingFailureReason();\n\t// Are native libraries loaded?\n\tstatic boolean isNativeCodeLoaded();\n\t// Load native library available or supported.\n\tstatic void loadLibrary();\n}", "des": "Erasure code native libraries (for now, Intel ISA-L) related utilities."}
{"index": 3439, "repo": "hadoop-common-3.3.4", "code": "Interface FenceMethod {\n\t// Verify that the given fencing method's arguments are valid.\n\tvoid checkArgs(String args);\n\t// Attempt to fence the target node.\n\tboolean tryFence(HAServiceTarget target, String args);\n}", "des": "A fencing method is a method by which one node can forcibly prevent another node from making continued progress. This might be implemented by killing a process on the other node, by denying the other node's access to shared storage, or by accessing a PDU to cut the other node's power."}
{"index": 3440, "repo": "hadoop-common-3.3.4", "code": "Class FileChecksum {\n\t// Return true if both the algorithms and the values are the same.\n\tboolean equals(Object other);\n\t// The checksum algorithm name\n\tabstract String getAlgorithmName();\n\t// The value of the checksum in bytes\n\tabstract byte[] getBytes();\n\tOptions.ChecksumOpt getChecksumOpt();\n\t// The length of the checksum in bytes\n\tabstract int getLength();\n}", "des": "An abstract class representing file checksums for files."}
{"index": 3441, "repo": "hadoop-common-3.3.4", "code": "Class FileSink {\n\tvoid close();\n\t// Flush any buffered metrics\n\tvoid flush();\n\t// Initialize the plugin\n\tvoid init(org.apache.commons.configuration2.SubsetConfiguration conf);\n\t// Put a metrics record in the sink\n\tvoid putMetrics(MetricsRecord record);\n}", "des": "A metrics sink that writes to a file"}
{"index": 3442, "repo": "hadoop-common-3.3.4", "code": "Enum FileStatus.AttrFlags {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileStatus.AttrFlags valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileStatus.AttrFlags[] values();\n}", "des": "Flags for entity attributes."}
{"index": 3443, "repo": "hadoop-common-3.3.4", "code": "Class FindClass {\n\t// Main entry point.\n\tstatic void main(String[] args);\n\t// Run the class/resource find or load operation\n\tint run(String[] args);\n\t// Change the output streams to be something other than the System.out and System.err streams\n\tstatic void setOutputStreams(PrintStream out, PrintStream err);\n}", "des": "This entry point exists for diagnosing classloader problems: is a class or resource present -and if so, where?"}
{"index": 3444, "repo": "hadoop-common-3.3.4", "code": "Class FloatWritable {\n\t// Compares two FloatWritables.\n\tint compareTo(FloatWritable o);\n\t// Returns true iff o is a FloatWritable with the same value.\n\tboolean equals(Object o);\n\t// Return the value of this FloatWritable.\n\tfloat get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Set the value of this FloatWritable.\n\tvoid set(float value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for floats."}
{"index": 3445, "repo": "hadoop-common-3.3.4", "code": "Class FsShellPermissions.Chmod {\n\t// Must be implemented by commands to process the command line flags and check the bounds of the remaining arguments.\n\tprotected void processOptions(LinkedList<String> args);\n\t// Hook for commands to implement an operation to be applied on each path for the command.\n\tprotected void processPath(org.apache.hadoop.fs.shell.PathData item);\n}", "des": "The pattern is almost as flexible as mode allowed by chmod shell command. The main restriction is that we recognize only rwxXt. To reduce errors we also enforce octal mode specifications of either 3 digits without a sticky bit setting or four digits with a sticky bit setting."}
{"index": 3446, "repo": "hadoop-common-3.3.4", "code": "Class FsShellPermissions.Chown {\n\t// Parse the first argument into an owner and group\n\tprotected void parseOwnerGroup(String ownerStr);\n\t// Must be implemented by commands to process the command line flags and check the bounds of the remaining arguments.\n\tprotected void processOptions(LinkedList<String> args);\n\t// Hook for commands to implement an operation to be applied on each path for the command.\n\tprotected void processPath(org.apache.hadoop.fs.shell.PathData item);\n}", "des": "Used to change owner and/or group of files"}
{"index": 3447, "repo": "hadoop-common-3.3.4", "code": "Class FsStatus {\n\t// Return the capacity in bytes of the file system\n\tlong getCapacity();\n\t// Return the number of remaining bytes on the file system\n\tlong getRemaining();\n\t// Return the number of bytes used on the file system\n\tlong getUsed();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "This class is used to represent the capacity, free and used space on a FileSystem."}
{"index": 3448, "repo": "hadoop-common-3.3.4", "code": "Interface FutureDataInputStreamBuilder {\n\t// Instantiate the object which was being built.\n\tCompletableFuture<FSDataInputStream> build();\n\t// A FileStatus may be provided to the open request.\n\tdefault FutureDataInputStreamBuilder withFileStatus(FileStatus status);\n}", "des": "Builder for input streams and subclasses whose return value is actually a completable future: this allows for better asynchronous operation. To be more generic, FSBuilder.opt(String, int) and FSBuilder.must(String, int) variants provide implementation-agnostic way to customize the builder. Each FS-specific builder implementation can interpret the FS-specific options accordingly, for example: If the option is not related to the file system, the option will be ignored. If the option is must, but not supported by the file system, a IllegalArgumentException will be thrown."}
{"index": 3449, "repo": "hadoop-common-3.3.4", "code": "Class GangliaSink30 {\n\t// The method sends metrics to Ganglia servers.\n\tprotected void emitMetric(String groupName, String name, String type, String value, org.apache.hadoop.metrics2.sink.ganglia.GangliaConf gConf, AbstractGangliaSink.GangliaSlope gSlope);\n\t// Initialize the plugin\n\tvoid init(org.apache.commons.configuration2.SubsetConfiguration conf);\n\t// Put a metrics record in the sink\n\tvoid putMetrics(MetricsRecord record);\n}", "des": "This code supports Ganglia 3.0"}
{"index": 3450, "repo": "hadoop-common-3.3.4", "code": "Class GetGroupsBase {\n\t// Must be overridden by subclasses to get the address where the GetUserMappingsProtocol implementation is running.\n\tprotected abstract InetSocketAddress getProtocolAddress(Configuration conf);\n\t// Get a client of the GetUserMappingsProtocol.\n\tprotected org.apache.hadoop.tools.GetUserMappingsProtocol getUgmProtocol();\n\t// Get the groups for the users given and print formatted output to the PrintStream configured earlier.\n\tint run(String[] args);\n}", "des": "Base class for the HDFS and MR implementations of tools which fetch and display the groups that users belong to."}
{"index": 3451, "repo": "hadoop-common-3.3.4", "code": "Class GraphiteSink {\n\tvoid close();\n\t// Flush any buffered metrics\n\tvoid flush();\n\t// Initialize the plugin\n\tvoid init(org.apache.commons.configuration2.SubsetConfiguration conf);\n\t// Put a metrics record in the sink\n\tvoid putMetrics(MetricsRecord record);\n}", "des": "A metrics sink that writes to a Graphite server"}
{"index": 3452, "repo": "hadoop-common-3.3.4", "code": "Interface GroupMappingServiceProvider {\n\t// Caches the group user information\n\tvoid cacheGroupsAdd(List<String> groups);\n\t// Refresh the cache of groups and user mapping\n\tvoid cacheGroupsRefresh();\n\t// Get all various group memberships of a given user.\n\tList<String> getGroups(String user);\n}", "des": "An interface for the implementation of a user-to-groups mapping service used by Groups."}
{"index": 3453, "repo": "hadoop-common-3.3.4", "code": "Class GzipCodec.GzipOutputStream {\n\tvoid close();\n\t// Finishes writing compressed data to the output stream without closing the underlying stream.\n\tvoid finish();\n\tvoid flush();\n\t// Reset the compression to the initial state.\n\tvoid resetState();\n\t// Write compressed bytes to the stream.\n\tvoid write(byte[] data, int offset, int length);\n\tvoid write(int b);\n}", "des": "A bridge that wraps around a DeflaterOutputStream to make it a CompressionOutputStream."}
{"index": 3454, "repo": "hadoop-common-3.3.4", "code": "Class HardLink {\n\t// Creates a hardlink\n\tstatic void createHardLink(File file, File linkName);\n\t// Creates hardlinks from multiple existing files within one parent directory, into one target directory.\n\tstatic void createHardLinkMult(File parentDir, String[] fileBaseNames, File linkDir);\n\t// Retrieves the number of links to the specified file.\n\tstatic int getLinkCount(File fileName);\n}", "des": "Class for creating hardlinks. Supports Unix/Linux, Windows via winutils , and Mac OS X. The HardLink class was formerly a static inner class of FSUtil, and the methods provided were blatantly non-thread-safe. To enable volume-parallel Update snapshots, we now provide static threadsafe methods that allocate new buffer string arrays upon each call. We also provide an API to hardlink all files in a directory with a single command, which is up to 128 times more efficient - and minimizes the impact of the extra buffer creations."}
{"index": 3455, "repo": "hadoop-common-3.3.4", "code": "Enum HAServiceProtocol.HAServiceState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HAServiceProtocol.HAServiceState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HAServiceProtocol.HAServiceState[] values();\n}", "des": "An HA service may be in active or standby state. During startup, it is in an unknown INITIALIZING state. During shutdown, it is in the STOPPING state and can no longer return to active/standby states."}
{"index": 3456, "repo": "hadoop-common-3.3.4", "code": "Class HashFunction {\n\t// Clears this hash function.\n\tvoid clear();\n\t// Hashes a specified key into several integers.\n\tint[] hash(org.apache.hadoop.util.bloom.Key k);\n}", "des": "Implements a hash object that returns a certain number of hashed values."}
{"index": 3457, "repo": "hadoop-common-3.3.4", "code": "Class IngressPortBasedResolver {\n\t// Identify the Sasl Properties to be used for a connection with a client.\n\tMap<String,String> getServerProperties(InetAddress clientAddress, int ingressPort);\n\t// Set the configuration to be used by this object.\n\tvoid setConf(Configuration conf);\n}", "des": "An implementation of SaslPropertiesResolver. Used on server side, returns SASL properties based on the port the client is connecting to. This should be used along with server side enabling multiple ports TODO: when NN multiple listener is enabled, automatically use this resolver without having to set in config. For configuration, for example if server runs on two ports 9000 and 9001, and we want to specify 9000 to use auth-conf and 9001 to use auth. We need to set the following configuration properties: ingress.port.sasl.configured.ports=9000,9001 ingress.port.sasl.prop.9000=privacy ingress.port.sasl.prop.9001=authentication One note is that, if there is misconfiguration that a port, say, 9002 is given in ingress.port.sasl.configured.ports, but it's sasl prop is not set, a default of QOP of privacy (auth-conf) will be used. In addition, if a port is not given even in ingress.port.sasl.configured.ports, but is being checked in getServerProperties(), the default SASL prop will be returned. Both of these two cases are considered misconfiguration."}
{"index": 3458, "repo": "hadoop-common-3.3.4", "code": "Class Interns {\n\t// Get a metric info object.\n\tstatic MetricsInfo info(String name, String description);\n\t// Get a metrics tag.\n\tstatic MetricsTag tag(MetricsInfo info, String value);\n\t// Get a metrics tag.\n\tstatic MetricsTag tag(String name, String description, String value);\n}", "des": "Helpers to create interned metrics info."}
{"index": 3459, "repo": "hadoop-common-3.3.4", "code": "Class IntWritable {\n\t// Compares two IntWritables.\n\tint compareTo(IntWritable o);\n\t// Returns true iff o is a IntWritable with the same value.\n\tboolean equals(Object o);\n\t// Return the value of this IntWritable.\n\tint get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Set the value of this IntWritable.\n\tvoid set(int value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for ints."}
{"index": 3460, "repo": "hadoop-common-3.3.4", "code": "Interface IOStatistics {\n\t// Map of counters.\n\tMap<String,Long> counters();\n\t// Map of gauges.\n\tMap<String,Long> gauges();\n\t// Map of maximums.\n\tMap<String,Long> maximums();\n\t// Map of meanStatistics.\n\tMap<String,MeanStatistic> meanStatistics();\n\t// Map of minimums.\n\tMap<String,Long> minimums();\n}", "des": "IO Statistics."}
{"index": 3461, "repo": "hadoop-common-3.3.4", "code": "Class KeyProvider.Metadata {\n\tprotected int addVersion();\n\t// Get the algorithm from the cipher.\n\tString getAlgorithm();\n\tMap<String,String> getAttributes();\n\tint getBitLength();\n\tString getCipher();\n\tDate getCreated();\n\tString getDescription();\n\tint getVersions();\n\t// Serialize the metadata to a set of bytes.\n\tprotected byte[] serialize();\n}", "des": "Key metadata that is associated with the key."}
{"index": 3462, "repo": "hadoop-common-3.3.4", "code": "Class KeyProviderDelegationTokenExtension {\n\t// Creates a KeyProviderDelegationTokenExtension using a given KeyProvider.\n\tstatic KeyProviderDelegationTokenExtension createKeyProviderDelegationTokenExtension(KeyProvider keyProvider);\n\t// The service name used as the alias for the token in the credential token map.\n\tString getCanonicalServiceName();\n\t// Unconditionally get a new token with the optional renewer.\n\tToken<?> getDelegationToken(String renewer);\n}", "des": "A KeyProvider extension with the ability to add a renewer's Delegation Tokens to the provided Credentials."}
{"index": 3463, "repo": "hadoop-common-3.3.4", "code": "Interface KeyProviderDelegationTokenExtension.DelegationTokenExtension {\n\t// Cancels the given token.\n\tVoid cancelDelegationToken(Token<?> token);\n\t// Renews the given token.\n\tlong renewDelegationToken(Token<?> token);\n}", "des": "DelegationTokenExtension is a type of Extension that exposes methods needed to work with Delegation Tokens."}
{"index": 3464, "repo": "hadoop-common-3.3.4", "code": "Class KeyShell {\n\t// Return usage string for the command including any summary of subcommands.\n\tString getCommandUsage();\n\t// Parse the command line arguments and initialize the data.\n\tprotected int init(String[] args);\n\t// main() entry point for the KeyShell.\n\tstatic void main(String[] args);\n\tprotected void printException(Exception e);\n}", "des": "This program is the CLI utility for the KeyProvider facilities in Hadoop."}
{"index": 3465, "repo": "hadoop-common-3.3.4", "code": "Class KMSClientProvider.KMSTokenRenewer {\n\t// Cancel the given token\n\tvoid cancel(Token<?> token, Configuration conf);\n\t// Does this renewer handle this kind of token?\n\tboolean handleKind(Text kind);\n\t// Is the given token managed? Only managed tokens may be renewed or cancelled.\n\tboolean isManaged(Token<?> token);\n\t// Renew the given token.\n\tlong renew(Token<?> token, Configuration conf);\n}", "des": "The KMS implementation of TokenRenewer."}
{"index": 3466, "repo": "hadoop-common-3.3.4", "code": "Interface LaunchableService {\n\t// Propagate the command line arguments.\n\tConfiguration bindArgs(Configuration config, List<String> args);\n\t// Run a service.\n\tint execute();\n}", "des": "An interface which services can implement to have their execution managed by the ServiceLauncher."}
{"index": 3467, "repo": "hadoop-common-3.3.4", "code": "Interface LightWeightCache.Entry {\n\t// Get the expiration time.\n\tlong getExpirationTime();\n\t// Set the expiration time.\n\tvoid setExpirationTime(long timeNano);\n}", "des": "Entries of LightWeightCache."}
{"index": 3468, "repo": "hadoop-common-3.3.4", "code": "Interface LightWeightGSet.LinkedElement {\n\t// Get the next element.\n\tLightWeightGSet.LinkedElement getNext();\n\t// Set the next element.\n\tvoid setNext(LightWeightGSet.LinkedElement next);\n}", "des": "Elements of LightWeightGSet."}
{"index": 3469, "repo": "hadoop-common-3.3.4", "code": "Class LocatedFileStatus {\n\t// Compare this FileStatus to another FileStatus\n\tint compareTo(FileStatus o);\n\t// Compare if this object is equal to another object\n\tboolean equals(Object o);\n\t// Get the file's block locations In HDFS, the returned BlockLocation will have different formats for replicated and erasure coded file.\n\tBlockLocation[] getBlockLocations();\n\t// Hook for subclasses to lazily set block locations.\n\tprotected void setBlockLocations(BlockLocation[] locations);\n}", "des": "This class defines a FileStatus that includes a file's block locations."}
{"index": 3470, "repo": "hadoop-common-3.3.4", "code": "Interface LogThrottlingHelper.LogAction {\n\t// Return the number of records encapsulated in this action; that is, the number of times record was called to produce this action, including the current one.\n\tint getCount();\n\t// Return summary information for the value that was recorded at index idx.\n\torg.apache.commons.math3.stat.descriptive.SummaryStatistics getStats(int idx);\n\t// If this is true, the caller should write to its log.\n\tboolean shouldLog();\n}", "des": "An indication of what action the caller should take. If shouldLog() is false, no other action should be taken, and it is an error to try to access any of the summary information. If shouldLog() is true, then the caller should write to its log, and can use the getCount() and getStats(int) methods to determine summary information about what has been recorded into this helper. All summary information in this action only represents LogThrottlingHelper.record(double...) statements which were called after the last time the caller logged something; that is, since the last time a log action was returned with a true value for shouldLog(). Information about the LogThrottlingHelper.record(double...) statement which created this log action is included."}
{"index": 3471, "repo": "hadoop-common-3.3.4", "code": "Class LongWritable {\n\t// Compares two LongWritables.\n\tint compareTo(LongWritable o);\n\t// Returns true iff o is a LongWritable with the same value.\n\tboolean equals(Object o);\n\t// Return the value of this LongWritable.\n\tlong get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Set the value of this LongWritable.\n\tvoid set(long value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for longs."}
{"index": 3472, "repo": "hadoop-common-3.3.4", "code": "Class LongWritable.DecreasingComparator {\n\t// Optimization hook.\n\tint compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2);\n\t// Compare two WritableComparables.\n\tint compare(WritableComparable a, WritableComparable b);\n}", "des": "A decreasing Comparator optimized for LongWritable."}
{"index": 3473, "repo": "hadoop-common-3.3.4", "code": "Class MachineList {\n\t// returns the contents of the MachineList as a Collection<String> .\n\tCollection<String> getCollection();\n\t// Accepts an inet address and return true if address is in the list.\n\tboolean includes(InetAddress address);\n\t// Accepts an ip address and return true if ipAddress is in the list.\n\tboolean includes(String ipAddress);\n}", "des": "Container class which holds a list of ip/host addresses and answers membership queries. Accepts list of ip addresses, ip addreses in CIDR format and/or host addresses."}
{"index": 3474, "repo": "hadoop-common-3.3.4", "code": "Class MapFile {\n\t// Deletes the named map file.\n\tstatic void delete(FileSystem fs, String name);\n\t// This method attempts to fix a corrupt MapFile by re-creating its index.\n\tstatic long fix(FileSystem fs, Path dir, Class<? extends Writable> keyClass, Class<? extends Writable> valueClass, boolean dryrun, Configuration conf);\n\tstatic void main(String[] args);\n\t// Renames an existing map directory.\n\tstatic void rename(FileSystem fs, String oldName, String newName);\n}", "des": "A file-based map from keys to values."}
{"index": 3475, "repo": "hadoop-common-3.3.4", "code": "Class MetricsCache {\n\t// Get the cached record\n\tMetricsCache.Record get(String name, Collection<MetricsTag> tags);\n\t// Update the cache and return the current cache record\n\tMetricsCache.Record update(MetricsRecord mr);\n\t// Update the cache and return the current cached record\n\tMetricsCache.Record update(MetricsRecord mr, boolean includingTags);\n}", "des": "A metrics cache for sinks that don't support sparse updates."}
{"index": 3476, "repo": "hadoop-common-3.3.4", "code": "Class MetricsCache.Record {\n\t// Lookup a metric value\n\tNumber getMetric(String key);\n\t// Lookup a metric instance\n\tAbstractMetric getMetricInstance(String key);\n\t// Lookup a tag value\n\tString getTag(String key);\n\tSet<Map.Entry<String,AbstractMetric>> metricsEntrySet();\n\tSet<Map.Entry<String,String>> tags();\n}", "des": "Cached record"}
{"index": 3477, "repo": "hadoop-common-3.3.4", "code": "Interface MetricsCollector {\n\t// Add a metrics record\n\tMetricsRecordBuilder addRecord(MetricsInfo info);\n\t// Add a metrics record\n\tMetricsRecordBuilder addRecord(String name);\n}", "des": "The metrics collector interface"}
{"index": 3478, "repo": "hadoop-common-3.3.4", "code": "Class MetricsFilter {\n\t// Whether to accept the tags\n\tabstract boolean accepts(Iterable<MetricsTag> tags);\n\t// Whether to accept the record\n\tboolean accepts(MetricsRecord record);\n\t// Whether to accept the tag\n\tabstract boolean accepts(MetricsTag tag);\n\t// Whether to accept the name\n\tabstract boolean accepts(String name);\n}", "des": "The metrics filter interface. The MetricsFilter objects can be used either to filter the metrics from MetricsSources or to filter metrics per MetricsSink."}
{"index": 3479, "repo": "hadoop-common-3.3.4", "code": "Interface MetricsInfo {\n\t// Typically the description corresponds to annotation Metric.about() or the name of the class.\n\tString description();\n\t// Typically name corresponds to annotation Metric.value() or the name of the class.\n\tString name();\n}", "des": "Interface to provide immutable metainfo for metrics."}
{"index": 3480, "repo": "hadoop-common-3.3.4", "code": "Interface MetricsRecord {\n\tString context();\n\tString description();\n\t// Get the metrics of the record\n\tIterable<AbstractMetric> metrics();\n\tString name();\n\t// Get the tags of the record Note: returning a collection instead of iterable as we need to use tags as keys (hence Collection#hashCode etc.) in maps\n\tCollection<MetricsTag> tags();\n\t// Get the timestamp of the metrics\n\tlong timestamp();\n}", "des": "An immutable snapshot of metrics with a timestamp"}
{"index": 3481, "repo": "hadoop-common-3.3.4", "code": "Interface MetricsSink {\n\t// Flush any buffered metrics\n\tvoid flush();\n\t// Put a metrics record in the sink\n\tvoid putMetrics(MetricsRecord record);\n}", "des": "The metrics sink interface."}
{"index": 3482, "repo": "hadoop-common-3.3.4", "code": "Class MetricsSystem.AbstractCallback {\n\t// Called after start()\n\tvoid postStart();\n\t// Called after stop()\n\tvoid postStop();\n\t// Called before start()\n\tvoid preStart();\n\t// Called before stop()\n\tvoid preStop();\n}", "des": "Convenient abstract class for implementing callback interface"}
{"index": 3483, "repo": "hadoop-common-3.3.4", "code": "Interface MetricsSystem.Callback {\n\t// Called after start()\n\tvoid postStart();\n\t// Called after stop()\n\tvoid postStop();\n\t// Called before start()\n\tvoid preStart();\n\t// Called before stop()\n\tvoid preStop();\n}", "des": "The metrics system callback interface (needed for proxies.)"}
{"index": 3484, "repo": "hadoop-common-3.3.4", "code": "Interface MetricsSystemMXBean {\n\tString currentConfig();\n\t// Start the metrics system\n\tvoid start();\n\t// Start metrics MBeans\n\tvoid startMetricsMBeans();\n\t// Stop the metrics system\n\tvoid stop();\n\t// Stop metrics MBeans.\n\tvoid stopMetricsMBeans();\n}", "des": "The JMX interface to the metrics system"}
{"index": 3485, "repo": "hadoop-common-3.3.4", "code": "Class MetricsTag {\n\t// Typically the description corresponds to annotation Metric.about() or the name of the class.\n\tString description();\n\tboolean equals(Object obj);\n\tMetricsInfo info();\n\t// Typically name corresponds to annotation Metric.value() or the name of the class.\n\tString name();\n\t// Get the value of the tag\n\tString value();\n}", "des": "Immutable tag for metrics (for grouping on host/queue/username etc.)"}
{"index": 3486, "repo": "hadoop-common-3.3.4", "code": "Class MutableCounterInt {\n\t// Increment the metric value by 1.\n\tvoid incr();\n\t// Increment the value by a delta\n\tvoid incr(int delta);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder builder, boolean all);\n\tint value();\n}", "des": "A mutable int counter for implementing metrics sources"}
{"index": 3487, "repo": "hadoop-common-3.3.4", "code": "Class MutableCounterLong {\n\t// Increment the metric value by 1.\n\tvoid incr();\n\t// Increment the value by a delta\n\tvoid incr(long delta);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder builder, boolean all);\n\tlong value();\n}", "des": "A mutable long counter"}
{"index": 3488, "repo": "hadoop-common-3.3.4", "code": "Class MutableGauge {\n\t// Decrement the value of the metric by 1\n\tabstract void decr();\n\t// Increment the value of the metric by 1\n\tabstract void incr();\n\tprotected MetricsInfo info();\n}", "des": "The mutable gauge metric interface"}
{"index": 3489, "repo": "hadoop-common-3.3.4", "code": "Class MutableGaugeFloat {\n\t// Decrement the value of the metric by 1\n\tvoid decr();\n\t// Increment the value of the metric by 1\n\tvoid incr();\n\tvoid set(float value);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder builder, boolean all);\n\tfloat value();\n}", "des": "A mutable float gauge."}
{"index": 3490, "repo": "hadoop-common-3.3.4", "code": "Class MutableGaugeInt {\n\t// Decrement the value of the metric by 1\n\tvoid decr();\n\t// decrement by delta\n\tvoid decr(int delta);\n\t// Increment the value of the metric by 1\n\tvoid incr();\n\t// Increment by delta\n\tvoid incr(int delta);\n\t// Set the value of the metric\n\tvoid set(int value);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder builder, boolean all);\n\tint value();\n}", "des": "A mutable int gauge"}
{"index": 3491, "repo": "hadoop-common-3.3.4", "code": "Class MutableGaugeLong {\n\t// Decrement the value of the metric by 1\n\tvoid decr();\n\t// decrement by delta\n\tvoid decr(long delta);\n\t// Increment the value of the metric by 1\n\tvoid incr();\n\t// Increment by delta\n\tvoid incr(long delta);\n\t// Set the value of the metric\n\tvoid set(long value);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder builder, boolean all);\n\tlong value();\n}", "des": "A mutable long gauge"}
{"index": 3492, "repo": "hadoop-common-3.3.4", "code": "Class MutableMetric {\n\tboolean changed();\n\t// Clear the changed flag in the snapshot operations\n\tprotected void clearChanged();\n\t// Set the changed flag in mutable operations\n\tprotected void setChanged();\n\t// Get a snapshot of metric if changed\n\tvoid snapshot(MetricsRecordBuilder builder);\n\t// Get a snapshot of the metric\n\tabstract void snapshot(MetricsRecordBuilder builder, boolean all);\n}", "des": "The mutable metric interface"}
{"index": 3493, "repo": "hadoop-common-3.3.4", "code": "Class MutableQuantiles {\n\tvoid add(long value);\n\t// Get the quantile estimator.\n\tQuantileEstimator getEstimator();\n\tint getInterval();\n\tvoid setEstimator(QuantileEstimator quantileEstimator);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder builder, boolean all);\n\tvoid stop();\n}", "des": "Watches a stream of long values, maintaining online estimates of specific quantiles with provably low error bounds. This is particularly useful for accurate high-percentile (e.g. 95th, 99th) latency metrics."}
{"index": 3494, "repo": "hadoop-common-3.3.4", "code": "Class MutableRates {\n\t// Add a rate sample for a rate metric\n\tvoid add(String name, long elapsed);\n\t// Initialize the registry with all the methods in a protocol so they all show up in the first snapshot.\n\tvoid init(Class<?> protocol);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder rb, boolean all);\n}", "des": "Helper class to manage a group of mutable rate metrics This class synchronizes all accesses to the metrics it contains, so it should not be used in situations where there is high contention on the metrics. MutableRatesWithAggregation is preferable in that situation."}
{"index": 3495, "repo": "hadoop-common-3.3.4", "code": "Class MutableRatesWithAggregation {\n\t// Add a rate sample for a rate metric.\n\tvoid add(String name, long elapsed);\n\t// Initialize the registry with all the methods in a protocol so they all show up in the first snapshot.\n\tvoid init(Class<?> protocol);\n\tvoid init(Class<?> protocol, String prefix);\n\t// Initialize the registry with all rate names passed in.\n\tvoid init(String[] names);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder rb, boolean all);\n}", "des": "Helper class to manage a group of mutable rate metrics. Each thread will maintain a local rate count, and upon snapshot, these values will be aggregated into a global rate. This class should only be used for long running threads, as any metrics produced between the last snapshot and the death of a thread will be lost. This allows for significantly higher concurrency than MutableRates. See HADOOP-24420."}
{"index": 3496, "repo": "hadoop-common-3.3.4", "code": "Class MutableRollingAverages {\n\tvoid add(String name, long value);\n\tvoid close();\n\t// Collects states maintained in ThreadLocal, if any.\n\tvoid collectThreadLocalStates();\n\t// Retrieve a map of metric name -> (aggregate).\n\tMap<String,Double> getStats(long minSamples);\n\t// Use for test only.\n\tvoid setRecordValidityMs(long value);\n\t// Get a snapshot of the metric\n\tvoid snapshot(MetricsRecordBuilder builder, boolean all);\n}", "des": ""}
{"index": 3497, "repo": "hadoop-common-3.3.4", "code": "Class NullGroupsMapping {\n\t// Nothing is returned, so nothing is cached.\n\tvoid cacheGroupsAdd(List<String> groups);\n\t// Nothing is returned, so nothing is cached.\n\tvoid cacheGroupsRefresh();\n\t// Returns an empty list.\n\tList<String> getGroups(String user);\n}", "des": "This class provides groups mapping for UserGroupInformation when the user group information will not be used."}
{"index": 3498, "repo": "hadoop-common-3.3.4", "code": "Class NullWritable {\n\tint compareTo(NullWritable other);\n\tboolean equals(Object other);\n\t// Returns the single instance of this class.\n\tstatic NullWritable get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "Singleton Writable with no data."}
{"index": 3499, "repo": "hadoop-common-3.3.4", "code": "Class OperationDuration {\n\t// Get the duration of an operation as a java Duration instance.\n\tDuration asDuration();\n\t// Update the finished time with the current system time.\n\tvoid finished();\n\t// Return the duration as humanTime(long).\n\tString getDurationString();\n\t// Convert to a human time of minutes:seconds.millis.\n\tstatic String humanTime(long time);\n\t// Evaluate the system time.\n\tprotected long time();\n\t// Get the duration in milliseconds.\n\tlong value();\n}", "des": "Little duration counter."}
{"index": 3500, "repo": "hadoop-common-3.3.4", "code": "Class Options {\n\t// Find the first option of the required class.\n\tstatic <base,T extends base>T getOption(Class<T> cls, base[] opts);\n\t// Prepend some new options to the old options\n\tstatic <T> T[] prependOptions(T[] oldOpts, T... newOpts);\n}", "des": "This class allows generic access to variable length type-safe parameter lists."}
{"index": 3501, "repo": "hadoop-common-3.3.4", "code": "Enum Options.ChecksumCombineMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Options.ChecksumCombineMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Options.ChecksumCombineMode[] values();\n}", "des": "Enum for indicating what mode to use when combining chunk and block checksums to define an aggregate FileChecksum. This should be considered a client-side runtime option rather than a persistent property of any stored metadata, which is why this is not part of ChecksumOpt, which deals with properties of files at rest."}
{"index": 3502, "repo": "hadoop-common-3.3.4", "code": "Enum Options.Rename {\n\tbyte value();\n\tstatic Options.Rename valueOf(byte code);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Options.Rename valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Options.Rename[] values();\n}", "des": "Enum to support the varargs for rename() options"}
{"index": 3503, "repo": "hadoop-common-3.3.4", "code": "Class PartialListing<T extends FileStatus> {\n\t// Partial listing of the path being listed.\n\tList<T> get();\n\t// Path being listed.\n\tPath getListedPath();\n}", "des": "A partial listing of the children of a parent directory. Since it is a partial listing, multiple PartialListing may need to be combined to obtain the full listing of a parent directory."}
{"index": 3504, "repo": "hadoop-common-3.3.4", "code": "Class PathIOException {\n\t// Format: cmd: {operation} `path' {to `target'}: error string\n\tString getMessage();\n\tPath getPath();\n\tPath getTargetPath();\n\t// Optional operation that will preface the path\n\tvoid setOperation(String operation);\n\t// Optional path if the exception involved two paths, ex.\n\tvoid setTargetPath(String targetPath);\n\tPathIOException withFullyQualifiedPath(String fqPath);\n}", "des": "Exceptions based on standard posix/linux style exceptions for path related errors. Returns an exception with the format \"path: standard error string\". This exception corresponds to Error Input/ouput(EIO)"}
{"index": 3505, "repo": "hadoop-common-3.3.4", "code": "Interface PositionedReadable {\n\t// Read up to the specified number of bytes, from a given position within a file, and return the number of bytes read.\n\tint read(long position, byte[] buffer, int offset, int length);\n\t// Read number of bytes equal to the length of the buffer, from a given position within a file.\n\tvoid readFully(long position, byte[] buffer);\n\t// Read the specified number of bytes, from a given position within a file.\n\tvoid readFully(long position, byte[] buffer, int offset, int length);\n}", "des": "Stream that permits positional reading. Implementations are required to implement thread-safe operations; this may be supported by concurrent access to the data, or by using a synchronization mechanism to serialize access. Not all implementations meet this requirement. Those that do not cannot be used as a backing store for some applications, such as Apache HBase. Independent of whether or not they are thread safe, some implementations may make the intermediate state of the system, specifically the position obtained in Seekable.getPos() visible."}
{"index": 3506, "repo": "hadoop-common-3.3.4", "code": "Class PowerShellFencer {\n\t// Verify that the given fencing method's arguments are valid.\n\tvoid checkArgs(String argStr);\n\t// Attempt to fence the target node.\n\tboolean tryFence(HAServiceTarget target, String argsStr);\n}", "des": "Fencer method that uses PowerShell to remotely connect to a machine and kill the required process. This only works in Windows. The argument passed to this fencer should be a unique string in the \"CommandLine\" attribute for the \"java.exe\" process. For example, the full path for the Namenode: \"org.apache.hadoop.hdfs.server.namenode.NameNode\". The administrator can also shorten the name to \"Namenode\" if it's unique."}
{"index": 3507, "repo": "hadoop-common-3.3.4", "code": "Class PrometheusMetricsSink {\n\t// Flush any buffered metrics\n\tvoid flush();\n\t// Initialize the plugin\n\tvoid init(org.apache.commons.configuration2.SubsetConfiguration conf);\n\t// Convert CamelCase based names to lower-case names where the separator is the underscore, to follow prometheus naming conventions.\n\tString prometheusName(String recordName, String metricName);\n\t// Put a metrics record in the sink\n\tvoid putMetrics(MetricsRecord metricsRecord);\n\tvoid writeMetrics(Writer writer);\n}", "des": "Metrics sink for prometheus exporter."}
{"index": 3508, "repo": "hadoop-common-3.3.4", "code": "Interface RawComparable {\n\t// Get the underlying byte array.\n\tbyte[] buffer();\n\t// Get the offset of the first byte in the byte array.\n\tint offset();\n\t// Get the size of the byte range in the byte array.\n\tint size();\n}", "des": "Interface for objects that can be compared through RawComparator. This is useful in places where we need a single object reference to specify a range of bytes in a byte array, such as Comparable or Collections.binarySearch(java.util.List, Object, Comparator) The actual comparison among RawComparable's requires an external RawComparator and it is applications' responsibility to ensure two RawComparable are supposed to be semantically comparable with the same RawComparator."}
{"index": 3509, "repo": "hadoop-common-3.3.4", "code": "Enum ReadOption {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReadOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReadOption[] values();\n}", "des": "Options that can be used when reading from a FileSystem."}
{"index": 3510, "repo": "hadoop-common-3.3.4", "code": "Interface Reconfigurable {\n\t// Return all the properties that can be changed at run time.\n\tCollection<String> getReconfigurableProperties();\n\t// Return whether a given property is changeable at run time.\n\tboolean isPropertyReconfigurable(String property);\n\t// Change a configuration property on this object to the value specified.\n\tvoid reconfigureProperty(String property, String newVal);\n}", "des": "Something whose Configuration can be changed at run time."}
{"index": 3511, "repo": "hadoop-common-3.3.4", "code": "Class ReconfigurationException {\n\t// Get value to which property was supposed to be changed.\n\tString getNewValue();\n\t// Get old value of property that cannot be changed.\n\tString getOldValue();\n\t// Get property that cannot be changed.\n\tString getProperty();\n}", "des": "Exception indicating that configuration property cannot be changed at run time."}
{"index": 3512, "repo": "hadoop-common-3.3.4", "code": "Interface RemoteIterator<E> {\n\t// Returns true if the iteration has more elements.\n\tboolean hasNext();\n\t// Returns the next element in the iteration.\n\tE next();\n}", "des": "An iterator over a collection whose elements need to be fetched remotely"}
{"index": 3513, "repo": "hadoop-common-3.3.4", "code": "Interface RestCsrfPreventionFilter.HttpInteraction {\n\t// Returns the value of a header.\n\tString getHeader(String header);\n\t// Returns the method.\n\tString getMethod();\n\t// Called by the filter after it decides that the request may proceed.\n\tvoid proceed();\n\t// Called by the filter after it decides that the request is a potential CSRF attack and therefore must be rejected.\n\tvoid sendError(int code, String message);\n}", "des": "Defines the minimal API requirements for the filter to execute its filtering logic. This interface exists to facilitate integration in components that do not run within a servlet container and therefore cannot rely on a servlet container to dispatch to the RestCsrfPreventionFilter.doFilter(javax.servlet.ServletRequest, javax.servlet.ServletResponse, javax.servlet.FilterChain) method. Applications that do run inside a servlet container will not need to write code that uses this interface. Instead, they can use typical servlet container configuration mechanisms to insert the filter."}
{"index": 3514, "repo": "hadoop-common-3.3.4", "code": "Enum SaslRpcServer.AuthMethod {\n\t// Return the SASL mechanism name\n\tString getMechanismName();\n\t// Read from in\n\tstatic SaslRpcServer.AuthMethod read(DataInput in);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SaslRpcServer.AuthMethod valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SaslRpcServer.AuthMethod[] values();\n\t// Write to out\n\tvoid write(DataOutput out);\n}", "des": "Authentication method"}
{"index": 3515, "repo": "hadoop-common-3.3.4", "code": "Class ScriptBasedMapping {\n\t// Return the configuration used by this object.\n\tConfiguration getConf();\n\t// Set the configuration to be used by this object.\n\tvoid setConf(Configuration conf);\n}", "des": "This class implements the DNSToSwitchMapping interface using a script configured via the CommonConfigurationKeysPublic.NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY option."}
{"index": 3516, "repo": "hadoop-common-3.3.4", "code": "Interface Seekable {\n\t// Return the current offset from the start of the file\n\tlong getPos();\n\t// Seek to the given offset from the start of the file.\n\tvoid seek(long pos);\n}", "des": "Stream that permits seeking."}
{"index": 3517, "repo": "hadoop-common-3.3.4", "code": "Enum SequenceFile.CompressionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SequenceFile.CompressionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SequenceFile.CompressionType[] values();\n}", "des": "The compression type used to compress key/value pairs in the SequenceFile."}
{"index": 3518, "repo": "hadoop-common-3.3.4", "code": "Class SequenceFile.Metadata {\n\tboolean equals(Object other);\n\tboolean equals(SequenceFile.Metadata other);\n\tText get(Text name);\n\tTreeMap<Text,Text> getMetadata();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\tvoid set(Text name, Text value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "The class encapsulating with the metadata of a file. The metadata of a file is a list of attribute name/value pairs of Text type."}
{"index": 3519, "repo": "hadoop-common-3.3.4", "code": "Interface SequenceFile.ValueBytes {\n\t// Size of stored data.\n\tint getSize();\n\t// Write compressed bytes to outStream.\n\tvoid writeCompressedBytes(DataOutputStream outStream);\n\t// Writes the uncompressed bytes to the outStream.\n\tvoid writeUncompressedBytes(DataOutputStream outStream);\n}", "des": "The interface to 'raw' values of SequenceFiles."}
{"index": 3520, "repo": "hadoop-common-3.3.4", "code": "Enum Service.STATE {\n\t// Get the integer value of a state\n\tint getValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Service.STATE valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Service.STATE[] values();\n}", "des": "Service states"}
{"index": 3521, "repo": "hadoop-common-3.3.4", "code": "Class ServiceOperations {\n\t// Stop a service.\n\tstatic void stop(Service service);\n\t// Stop a service; if it is null do nothing.\n\tstatic Exception stopQuietly(org.slf4j.Logger log, Service service);\n\t// Stop a service; if it is null do nothing.\n\tstatic Exception stopQuietly(org.apache.commons.logging.Log log, Service service);\n\t// Stop a service; if it is null do nothing.\n\tstatic Exception stopQuietly(Service service);\n}", "des": "This class contains a set of methods to work with services, especially to walk them through their lifecycle."}
{"index": 3522, "repo": "hadoop-common-3.3.4", "code": "Class ServiceOperations.ServiceListeners {\n\t// Thread-safe addition of a new listener to the end of a list.\n\tvoid add(ServiceStateChangeListener l);\n\t// Change to a new state and notify all listeners.\n\tvoid notifyListeners(Service service);\n\t// Remove any registration of a listener from the listener list.\n\tboolean remove(ServiceStateChangeListener l);\n\t// Reset the listener list\n\tvoid reset();\n}", "des": "Class to manage a list of ServiceStateChangeListener instances, including a notification loop that is robust against changes to the list during the notification process."}
{"index": 3523, "repo": "hadoop-common-3.3.4", "code": "Class ServiceStateException {\n\t// Convert any exception into a RuntimeException.\n\tstatic RuntimeException convert(String text, Throwable fault);\n\t// Convert any exception into a RuntimeException.\n\tstatic RuntimeException convert(Throwable fault);\n\t// Method to get the exit code.\n\tint getExitCode();\n}", "des": "Exception that can be raised on state change operations, whose exit code can be explicitly set, determined from that of any nested cause, or a default value of LauncherExitCodes.EXIT_SERVICE_LIFECYCLE_EXCEPTION."}
{"index": 3524, "repo": "hadoop-common-3.3.4", "code": "Class SetFile.Reader {\n\t// Read the matching key from a set into key.\n\tWritableComparable get(WritableComparable key);\n\t// Read the next key in a set into key.\n\tboolean next(WritableComparable key);\n\t// Positions the reader at the named key, or if none such exists, at the first entry after the named key.\n\tboolean seek(WritableComparable key);\n}", "des": "Provide access to an existing set file."}
{"index": 3525, "repo": "hadoop-common-3.3.4", "code": "Class Shell.ShellCommandExecutor {\n\tvoid close();\n\t// Execute the shell command.\n\tvoid execute();\n\t// return an array containing the command name and its parameters.\n\tString[] getExecString();\n\t// Get the output of the shell command.\n\tString getOutput();\n\t// Returns the timeout value set for the executor's sub-commands.\n\tlong getTimeoutInterval();\n\t// Parse the execution result\n\tprotected void parseExecResult(BufferedReader lines);\n}", "des": "A simple shell command executor. ShellCommandExecutorshould be used in cases where the output of the command needs no explicit parsing and where the command, working directory and the environment remains unchanged. The output of the command is stored as-is and is expected to be small."}
{"index": 3526, "repo": "hadoop-common-3.3.4", "code": "Class ShellCommandFencer {\n\t// Verify that the given fencing method's arguments are valid.\n\tvoid checkArgs(String args);\n\t// Attempt to fence the target node.\n\tboolean tryFence(HAServiceTarget target, String args);\n}", "des": "Fencing method that runs a shell command. It should be specified in the fencing configuration like: shell(/path/to/my/script.sh arg1 arg2 ...) The string between '(' and ')' is passed directly to a bash shell (cmd.exe on Windows) and may not include any closing parentheses."}
{"index": 3527, "repo": "hadoop-common-3.3.4", "code": "Class ShortWritable {\n\t// Compares two ShortWritable.\n\tint compareTo(ShortWritable o);\n\t// Returns true iff o is a ShortWritable with the same value.\n\tboolean equals(Object o);\n\t// Return the value of this ShortWritable.\n\tshort get();\n\t// read the short value\n\tvoid readFields(DataInput in);\n\t// Set the value of this ShortWritable.\n\tvoid set(short value);\n\t// write short value\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for shorts."}
{"index": 3528, "repo": "hadoop-common-3.3.4", "code": "Class SplitCompressionInputStream {\n\t// After calling createInputStream, the values of start or end might change.\n\tlong getAdjustedEnd();\n\t// After calling createInputStream, the values of start or end might change.\n\tlong getAdjustedStart();\n\tprotected void setEnd(long end);\n\tprotected void setStart(long start);\n}", "des": "An InputStream covering a range of compressed data. The start and end offsets requested by a client may be modified by the codec to fit block boundaries or other algorithm-dependent requirements."}
{"index": 3529, "repo": "hadoop-common-3.3.4", "code": "Enum SplittableCompressionCodec.READ_MODE {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SplittableCompressionCodec.READ_MODE valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SplittableCompressionCodec.READ_MODE[] values();\n}", "des": "During decompression, data can be read off from the decompressor in two modes, namely continuous and blocked. Few codecs (e.g. BZip2) are capable of compressing data in blocks and then decompressing the blocks. In Blocked reading mode codecs inform 'end of block' events to its caller. While in continuous mode, the caller of codecs is unaware about the blocks and uncompressed data is spilled out like a continuous stream."}
{"index": 3530, "repo": "hadoop-common-3.3.4", "code": "Class SshFenceByTcpPort {\n\t// Verify that the argument, if given, in the conf is parseable.\n\tvoid checkArgs(String argStr);\n\t// Attempt to fence the target node.\n\tboolean tryFence(HAServiceTarget target, String argsStr);\n}", "des": "This fencing implementation sshes to the target node and uses fuser to kill the process listening on the service's TCP port. This is more accurate than using \"jps\" since it doesn't require parsing, and will work even if there are multiple service processes running on the same machine."}
{"index": 3531, "repo": "hadoop-common-3.3.4", "code": "Class StatsDSink {\n\tvoid close();\n\t// Flush any buffered metrics\n\tvoid flush();\n\t// Initialize the plugin\n\tvoid init(org.apache.commons.configuration2.SubsetConfiguration conf);\n\t// Put a metrics record in the sink\n\tvoid putMetrics(MetricsRecord record);\n\tvoid writeMetric(String line);\n}", "des": "A metrics sink that writes metrics to a StatsD daemon. This sink will produce metrics of the form '[hostname].servicename.context.name.metricname:value|type' where hostname is optional. This is useful when sending to a daemon that is running on the localhost and will add the hostname to the metric (such as the CollectD StatsD plugin). To configure this plugin, you will need to add the following entries to your hadoop-metrics2.properties file:"}
{"index": 3532, "repo": "hadoop-common-3.3.4", "code": "Class StopWatch {\n\tvoid close();\n\t// The method is used to find out if the StopWatch is started.\n\tboolean isRunning();\n\tlong now();\n\tlong now(TimeUnit timeUnit);\n\t// Reset elapsed time to zero and make the state of stopwatch stop.\n\tStopWatch reset();\n\t// Start to measure times and make the state of stopwatch running.\n\tStopWatch start();\n\t// Stop elapsed time and make the state of stopwatch stop.\n\tStopWatch stop();\n}", "des": "A simplified StopWatch implementation which can measure times in nanoseconds."}
{"index": 3533, "repo": "hadoop-common-3.3.4", "code": "Class StorageStatistics {\n\t// Get the value of a statistic.\n\tabstract Long getLong(String key);\n\t// Get an iterator over all the currently tracked long statistics.\n\tabstract Iterator<StorageStatistics.LongStatistic> getLongStatistics();\n\t// Get the name of this StorageStatistics object.\n\tString getName();\n\tString getScheme();\n\t// Return true if a statistic is being tracked.\n\tabstract boolean isTracked(String key);\n\t// Reset all the statistic data.\n\tabstract void reset();\n}", "des": "StorageStatistics contains statistics data for a FileSystem or FileContext instance."}
{"index": 3534, "repo": "hadoop-common-3.3.4", "code": "Interface Stringifier<T> {\n\t// Closes this object.\n\tvoid close();\n\t// Restores the object from its string representation.\n\tT fromString(String str);\n\t// Converts the object to a string representation\n\tString toString(T obj);\n}", "des": "Stringifier interface offers two methods to convert an object to a string representation and restore the object given its string representation."}
{"index": 3535, "repo": "hadoop-common-3.3.4", "code": "Interface Syncable {\n\t// Flush out the data in client's user buffer.\n\tvoid hflush();\n\t// Similar to posix fsync, flush out the data in client's user buffer all the way to the disk device (but the disk may have it in its cache).\n\tvoid hsync();\n}", "des": "This is the interface for flush/sync operations. Consult the Hadoop filesystem specification for the definition of the semantics of these operations."}
{"index": 3536, "repo": "hadoop-common-3.3.4", "code": "Class TableMapping {\n\t// Return the configuration used by this object.\n\tConfiguration getConf();\n\t// Reload all of the cached mappings.\n\tvoid reloadCachedMappings();\n\t// Set the configuration to be used by this object.\n\tvoid setConf(Configuration conf);\n}", "des": ""}
{"index": 3537, "repo": "hadoop-common-3.3.4", "code": "Class TFile {\n\t// Get names of supported compression algorithms.\n\tstatic String[] getSupportedCompressionAlgorithms();\n\t// Dumping the TFile information.\n\tstatic void main(String[] args);\n\t// Make a raw comparator from a string name.\n\tstatic Comparator<RawComparable> makeComparator(String name);\n}", "des": "A TFile is a container of key-value pairs. Both keys and values are type-less bytes. Keys are restricted to 64KB, value length is not restricted (practically limited to the available disk storage). TFile further provides the following features: Block Compression. Named meta data blocks. Sorted or unsorted keys. Seek by key or by file offset. The memory footprint of a TFile includes the following: Some constant overhead of reading or writing a compressed block. Each compressed block requires one compression/decompression codec for I/O. Temporary space to buffer the key. Temporary space to buffer the value (for TFile.Writer only). Values are chunk encoded, so that we buffer at most one chunk of user data. By default, the chunk buffer is 1MB. Reading chunked value does not require additional memory. TFile index, which is proportional to the total number of Data Blocks. The total amount of memory needed to hold the index can be estimated as (56+AvgKeySize)*NumBlocks. MetaBlock index, which is proportional to the total number of Meta Blocks.The total amount of memory needed to hold the index for Meta Blocks can be estimated as (40+AvgMetaBlockName)*NumMetaBlock."}
{"index": 3538, "repo": "hadoop-common-3.3.4", "code": "Class Token.TrivialRenewer {\n\t// Cancel the given token\n\tvoid cancel(Token<?> token, Configuration conf);\n\tprotected Text getKind();\n\t// Does this renewer handle this kind of token?\n\tboolean handleKind(Text kind);\n\t// Is the given token managed? Only managed tokens may be renewed or cancelled.\n\tboolean isManaged(Token<?> token);\n\t// Renew the given token.\n\tlong renew(Token<?> token, Configuration conf);\n}", "des": "A trivial renewer for token kinds that aren't managed. Sub-classes need to implement getKind for their token kind."}
{"index": 3539, "repo": "hadoop-common-3.3.4", "code": "Class TokenIdentifier {\n\t// Get the bytes for the token identifier\n\tbyte[] getBytes();\n\t// Get the token kind\n\tabstract Text getKind();\n\t// Returns a tracking identifier that can be used to associate usages of a token across multiple client sessions.\n\tString getTrackingId();\n\t// Get the Ugi with the username encoded in the token identifier\n\tabstract UserGroupInformation getUser();\n}", "des": "An identifier that identifies a token, may contain public information about a token, including its kind (or type)."}
{"index": 3540, "repo": "hadoop-common-3.3.4", "code": "Class TokenRenewer {\n\t// Cancel the given token\n\tabstract void cancel(Token<?> token, Configuration conf);\n\t// Does this renewer handle this kind of token?\n\tabstract boolean handleKind(Text kind);\n\t// Is the given token managed? Only managed tokens may be renewed or cancelled.\n\tabstract boolean isManaged(Token<?> token);\n\t// Renew the given token.\n\tabstract long renew(Token<?> token, Configuration conf);\n}", "des": "This is the interface for plugins that handle tokens."}
{"index": 3541, "repo": "hadoop-common-3.3.4", "code": "Class TwoDArrayWritable {\n\tWritable[][] get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\tvoid set(Writable[][] values);\n\tObject toArray();\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A Writable for 2D arrays containing a matrix of instances of a class."}
{"index": 3542, "repo": "hadoop-common-3.3.4", "code": "Enum UserGroupInformation.AuthenticationMethod {\n\tSaslRpcServer.AuthMethod getAuthMethod();\n\tstatic UserGroupInformation.AuthenticationMethod valueOf(SaslRpcServer.AuthMethod authMethod);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic UserGroupInformation.AuthenticationMethod valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic UserGroupInformation.AuthenticationMethod[] values();\n}", "des": "existing types of authentications' methods"}
{"index": 3543, "repo": "hadoop-common-3.3.4", "code": "Class Utils.Version {\n\t// Compare this version with another version.\n\tint compareTo(Utils.Version that);\n\t// Test compatibility.\n\tboolean compatibleWith(Utils.Version other);\n\tboolean equals(Object other);\n\t// Get the major version.\n\tint getMajor();\n\t// Get the minor version.\n\tint getMinor();\n\t// Get the size of the serialized Version object.\n\tstatic int size();\n\t// Write the objec to a DataOutput.\n\tvoid write(DataOutput out);\n}", "des": "A generic Version class. We suggest applications built on top of TFile use this class to maintain version information in their meta blocks. A version number consists of a major version and a minor version. The suggested usage of major and minor version number is to increment major version number when the new storage format is not backward compatible, and increment the minor version otherwise."}
{"index": 3544, "repo": "hadoop-common-3.3.4", "code": "Enum ValueQueue.SyncGenerationPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ValueQueue.SyncGenerationPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ValueQueue.SyncGenerationPolicy[] values();\n}", "des": "Policy to decide how many values to return to client when client asks for \"n\" values and Queue is empty. This decides how many values to return when client calls \"getAtMost\""}
{"index": 3545, "repo": "hadoop-common-3.3.4", "code": "Class VersionedWritable {\n\t// Return the version number of the current implementation.\n\tabstract byte getVersion();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A base class for Writables that provides version checking."}
{"index": 3546, "repo": "hadoop-common-3.3.4", "code": "Class VIntWritable {\n\t// Compares two VIntWritables.\n\tint compareTo(VIntWritable o);\n\t// Returns true iff o is a VIntWritable with the same value.\n\tboolean equals(Object o);\n\t// Return the value of this VIntWritable.\n\tint get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Set the value of this VIntWritable.\n\tvoid set(int value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for integer values stored in variable-length format. Such values take between one and five bytes. Smaller values take fewer bytes."}
{"index": 3547, "repo": "hadoop-common-3.3.4", "code": "Class VLongWritable {\n\t// Compares two VLongWritables.\n\tint compareTo(VLongWritable o);\n\t// Returns true iff o is a VLongWritable with the same value.\n\tboolean equals(Object o);\n\t// Return the value of this LongWritable.\n\tlong get();\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Set the value of this LongWritable.\n\tvoid set(long value);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A WritableComparable for longs in a variable-length format. Such values take between one and five bytes. Smaller values take fewer bytes."}
{"index": 3548, "repo": "hadoop-common-3.3.4", "code": "Class WhitelistBasedResolver {\n\t// Identify the Sasl Properties to be used for a connection with a client.\n\tMap<String,String> getServerProperties(InetAddress clientAddress);\n\tMap<String,String> getServerProperties(String clientAddress);\n\t// Set the configuration to be used by this object.\n\tvoid setConf(Configuration conf);\n}", "des": "An implementation of the SaslPropertiesResolver. Uses a white list of IPs. If the connection's IP address is in the list of IP addresses, the salProperties will be unchanged. If the connection's IP is not in the list of IP addresses, then QOP for the connection will be restricted to \"hadoop.rpc.protection.non-whitelist\" Uses 3 IPList implementations together to form an aggregate whitelist. 1. ConstantIPList - to check against a set of hardcoded IPs 2. Fixed IP List - to check against a list of IP addresses which are specified externally, but will not change over runtime. 3. Variable IP List - to check against a list of IP addresses which are specified externally and could change during runtime. A connection IP address will checked against these 3 IP Lists in the order specified above. Once a match is found , the IP address is determined to be in whitelist. The behavior can be configured using a bunch of configuration parameters."}
{"index": 3549, "repo": "hadoop-common-3.3.4", "code": "Interface Writable {\n\t// Deserialize the fields of this object from in.\n\tvoid readFields(DataInput in);\n\t// Serialize the fields of this object to out.\n\tvoid write(DataOutput out);\n}", "des": "A serializable object which implements a simple, efficient, serialization protocol, based on DataInput and DataOutput."}
{"index": 3550, "repo": "hadoop-common-3.3.4", "code": "Class WritableFactories {\n\t// Define a factory for a class.\n\tstatic WritableFactory getFactory(Class c);\n\t// Create a new instance of a class with a defined factory.\n\tstatic Writable newInstance(Class<? extends Writable> c);\n\t// Create a new instance of a class with a defined factory.\n\tstatic Writable newInstance(Class<? extends Writable> c, Configuration conf);\n\t// Define a factory for a class.\n\tstatic void setFactory(Class c, WritableFactory factory);\n}", "des": "Factories for non-public writables. Defining a factory permits ObjectWritable to be able to construct instances of non-public classes."}
{"index": 3551, "repo": "hadoop-common-3.3.4", "code": "Enum XAttrCodec {\n\t// Decode string representation of a value and check whether it's encoded.\n\tstatic byte[] decodeValue(String value);\n\t// Encode byte[] value to string representation with encoding.\n\tstatic String encodeValue(byte[] value, XAttrCodec encoding);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic XAttrCodec valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic XAttrCodec[] values();\n}", "des": "The value of XAttr is byte[], this class is to covert byte[] to some kind of string representation or convert back. String representation is convenient for display and input. For example display in screen as shell response and json response, input as http or shell parameter."}
{"index": 3552, "repo": "druid-processing-26.0.0", "code": "Class AlwaysHavingSpec {\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "A \"having\" spec that always evaluates to true"}
{"index": 3553, "repo": "druid-processing-26.0.0", "code": "Class AndHavingSpec {\n\tboolean equals(Object o);\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\tList<HavingSpec> getHavingSpecs();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "The logical \"and\" operator for the \"having\" clause."}
{"index": 3554, "repo": "druid-processing-26.0.0", "code": "Class ApplyFunction.BaseFoldFunction {\n\t// Compute the output type of this function for a given lambda and the argument expressions which will be applied as its inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, org.apache.druid.math.expr.LambdaExpr expr, List<Expr> args);\n\t// Returns true if apply function produces an array output.\n\tboolean hasArrayOutput(org.apache.druid.math.expr.LambdaExpr lambdaExpr);\n}", "des": "Base class for family of ApplyFunction which aggregate a scalar or array value given one or more array input Expr arguments and an array or scalar \"accumulator\" argument with an initial value"}
{"index": 3555, "repo": "druid-processing-26.0.0", "code": "Class ApplyFunction.BaseMapFunction {\n\t// Compute the output type of this function for a given lambda and the argument expressions which will be applied as its inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, org.apache.druid.math.expr.LambdaExpr expr, List<Expr> args);\n\t// Returns true if apply function produces an array output.\n\tboolean hasArrayOutput(org.apache.druid.math.expr.LambdaExpr lambdaExpr);\n}", "des": "Base class for \"map\" functions, which are a class of ApplyFunction which take a lambda function that is mapped to the values of an ApplyFunction.IndexableMapLambdaObjectBinding which is created from the outer Expr.ObjectBinding and the values of the array Expr argument(s)"}
{"index": 3556, "repo": "druid-processing-26.0.0", "code": "Class ApplyFunction.CartesianMapLambdaBinding {\n\t// Get value binding for string identifier of IdentifierExpr\n\tObject get(String name);\n\t// Total number of bindings in this binding\n\tint getLength();\n\t// Get the ExpressionType from the backing store for a given identifier (this is likely a column, but could be other things depending on the backing adapter)\n\tExpressionType getType(String name);\n\t// Update index position\n\tApplyFunction.CartesianMapLambdaBinding withIndex(int index);\n}", "des": "ApplyFunction.IndexableMapLambdaObjectBinding for a ApplyFunction.CartesianMapFunction. Lambda argument bindings stored as a cartesian product in the form of a list of lists of objects, where the inner list is the in order list of values for each LambdaExpr argument"}
{"index": 3557, "repo": "druid-processing-26.0.0", "code": "Interface ApplyFunction.IndexableFoldLambdaBinding {\n\t// Update the index and accumulator value\n\tApplyFunction.IndexableFoldLambdaBinding accumulateWithIndex(int index, Object accumulator);\n\tExpressionType getAccumulatorType();\n\t// Total number of bindings in this binding\n\tint getLength();\n}", "des": "Expr.ObjectBinding which can be iterated by an integer index position for ApplyFunction.BaseFoldFunction. Evaluating an IdentifierExpr against these bindings will return the value(s) of the array at the current index for any lambda array identifiers, the value of the 'accumulator' for the lambda accumulator identifier, and fall through to the base Expr.ObjectBinding for all bindings provided by an outer scope."}
{"index": 3558, "repo": "druid-processing-26.0.0", "code": "Interface ApplyFunction.IndexableMapLambdaObjectBinding {\n\t// Total number of bindings in this binding\n\tint getLength();\n\t// Update index position\n\tApplyFunction.IndexableMapLambdaObjectBinding withIndex(int index);\n}", "des": "Expr.ObjectBinding which can be iterated by an integer index position for ApplyFunction.BaseMapFunction. Evaluating an IdentifierExpr against these bindings will return the value(s) of the array at the current index for any lambda identifiers, and fall through to the base Expr.ObjectBinding for all bindings provided by an outer scope."}
{"index": 3559, "repo": "druid-processing-26.0.0", "code": "Class ApplyFunction.MapLambdaBinding {\n\t// Get value binding for string identifier of IdentifierExpr\n\tObject get(String name);\n\t// Total number of bindings in this binding\n\tint getLength();\n\t// Get the ExpressionType from the backing store for a given identifier (this is likely a column, but could be other things depending on the backing adapter)\n\tExpressionType getType(String name);\n\t// Update index position\n\tApplyFunction.MapLambdaBinding withIndex(int index);\n}", "des": "ApplyFunction.IndexableMapLambdaObjectBinding for a ApplyFunction.MapFunction. Lambda argument binding is stored in an object array, retrieving binding values for the lambda identifier returns the value at the current index."}
{"index": 3560, "repo": "druid-processing-26.0.0", "code": "Class ApplyFunction.SettableLambdaBinding {\n\t// Get value binding for string identifier of IdentifierExpr\n\tObject get(String name);\n\t// Get the ExpressionType from the backing store for a given identifier (this is likely a column, but could be other things depending on the backing adapter)\n\tExpressionType getType(String name);\n}", "des": "Simple, mutable, Expr.ObjectBinding for a LambdaExpr which provides a Map for storing arbitrary values to use as values for IdentifierExpr in the body of the lambda that are arguments to the lambda"}
{"index": 3561, "repo": "druid-processing-26.0.0", "code": "Class ArenaMemoryAllocatorFactory {\n\t// Capacity of allocators returned by MemoryAllocatorFactory.newAllocator().\n\tlong allocatorCapacity();\n\t// Returns a new allocator with capacity MemoryAllocatorFactory.allocatorCapacity().\n\tMemoryAllocator newAllocator();\n}", "des": "Creates ArenaMemoryAllocator on each call to newAllocator()."}
{"index": 3562, "repo": "druid-processing-26.0.0", "code": "Class BlockingQueueFrameChannel {\n\t// Create a channel that buffers one frame.\n\tstatic BlockingQueueFrameChannel minimal();\n\t// Returns the readable side of this channel.\n\tReadableFrameChannel readable();\n\t// Returns the writable side of this channel.\n\tWritableFrameChannel writable();\n}", "des": "In-memory channel backed by a limited-capacity Deque. Instances of this class provide a ReadableFrameChannel through readable(), and a WritableFrameChannel through writable(). Instances of this class are used by a single writer and single reader. The writer and reader may run concurrently."}
{"index": 3563, "repo": "druid-processing-26.0.0", "code": "Class BlockingQueueOutputChannelFactory {\n\t// Create a channel pair tagged with a particular partition number.\n\tOutputChannel openChannel(int partitionNumber);\n\t// Create a non-writable, always-empty channel pair tagged with a particular partition number.\n\tOutputChannel openNilChannel(int partitionNumber);\n\t// Create a channel pair tagged with a particular name and a flag to delete the channel data after its read.\n\tPartitionedOutputChannel openPartitionedChannel(String name, boolean deleteAfterRead);\n}", "des": "An OutputChannelFactory that generates BlockingQueueFrameChannel."}
{"index": 3564, "repo": "druid-processing-26.0.0", "code": "Class BlockLayoutColumnarDoublesSerializer {\n\tvoid add(double value);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\tint size();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Serializer that produces BlockLayoutColumnarDoublesSupplier.BlockLayoutColumnarDoubles."}
{"index": 3565, "repo": "druid-processing-26.0.0", "code": "Class BlockLayoutColumnarFloatsSerializer {\n\tvoid add(float value);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\tint size();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Serializer that produces BlockLayoutColumnarFloatsSupplier.BlockLayoutColumnarFloats."}
{"index": 3566, "repo": "druid-processing-26.0.0", "code": "Class BlockLayoutColumnarLongsSerializer {\n\tvoid add(long value);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\tint size();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Serializer that produces BlockLayoutColumnarLongsSupplier.BlockLayoutColumnarLongs."}
{"index": 3567, "repo": "druid-processing-26.0.0", "code": "Class BuildingDimensionRangeShardSpec {\n\tDimensionRangeShardSpec convert(int numCorePartitions);\n\t<T> PartitionChunk<T> createChunk(T obj);\n\tboolean equals(Object o);\n\tint getBucketId();\n\tList<String> getDimensions();\n\tStringTuple getEndTuple();\n\t// Returns the partition ID of this segment.\n\tint getPartitionNum();\n\tStringTuple getStartTuple();\n\t// Get the type name of this ShardSpec.\n\tString getType();\n}", "des": "See BuildingShardSpec for how this class is used."}
{"index": 3568, "repo": "druid-processing-26.0.0", "code": "Class BuildingHashBasedNumberedShardSpec {\n\tHashBasedNumberedShardSpec convert(int numCorePartitions);\n\t<T> PartitionChunk<T> createChunk(T obj);\n\tboolean equals(Object o);\n\tint getBucketId();\n\tint getNumBuckets();\n\tList<String> getPartitionDimensions();\n\tHashPartitionFunction getPartitionFunction();\n\t// Returns the partition ID of this segment.\n\tint getPartitionNum();\n\t// Get the type name of this ShardSpec.\n\tString getType();\n}", "des": "See BuildingShardSpec for how this class is used."}
{"index": 3569, "repo": "druid-processing-26.0.0", "code": "Class BuildingNumberedShardSpec {\n\tNumberedShardSpec convert(int numTotalPartitions);\n\t<T> PartitionChunk<T> createChunk(T obj);\n\tboolean equals(Object o);\n\tint getBucketId();\n\t// Returns the partition ID of this segment.\n\tint getPartitionNum();\n\t// Get the type name of this ShardSpec.\n\tString getType();\n}", "des": "See BuildingShardSpec for how this class is used. This shardSpec has only partitionId which is same as LinearShardSpec. The difference between them is this shardSpec should never be published and so never be used in other places such as Broker timeline."}
{"index": 3570, "repo": "druid-processing-26.0.0", "code": "Class BytesCountingInputEntity {\n\t// Fetches the input entity into the local storage.\n\tInputEntity.CleanableFile fetch(File temporaryDirectory, byte[] fetchBuffer);\n\tInputEntity getBaseInputEntity();\n\t// Returns a retry condition that the caller should retry on.\n\tcom.google.common.base.Predicate<Throwable> getRetryCondition();\n\t// Returns an URI to identify the input entity.\n\tURI getUri();\n\t// Opens an InputStream on the input entity directly.\n\tInputStream open();\n}", "des": "Wrapper around an InputEntity that counts the number of bytes read."}
{"index": 3571, "repo": "druid-processing-26.0.0", "code": "Class CalciteCnfHelper {\n\t// Returns a condition decomposed by AND.\n\tstatic List<Filter> conjunctions(Filter rexPredicate);\n\t// Decomposes a predicate into a list of expressions that are AND'ed together.\n\tstatic void decomposeConjunction(Filter rexPredicate, List<Filter> rexList);\n\tstatic Filter pull(Filter rex);\n}", "des": "All functions in this class were basically adopted from Apache Calcite and modified to use them in Druid. See https://github.com/apache/calcite/blob/branch-1.21/core/src/main/java/org/apache/calcite/rex/RexUtil.java#L1615 for original implementation."}
{"index": 3572, "repo": "druid-processing-26.0.0", "code": "Interface CardinalityVectorProcessor {\n\t// Processor for VectorAggregator.aggregate(ByteBuffer, int, int, int) in byRow = false mode.\n\tvoid aggregate(ByteBuffer buf, int numRows, int[] positions, int[] rows, int positionOffset);\n\t// Processor for VectorAggregator.aggregate(ByteBuffer, int, int, int) in byRow = false mode.\n\tvoid aggregate(ByteBuffer buf, int position, int startRow, int endRow);\n}", "des": "Processor for CardinalityVectorAggregator."}
{"index": 3573, "repo": "druid-processing-26.0.0", "code": "Class CircularBuffer<E> {\n\tvoid add(E item);\n\t// Access object at a given index, starting from the earliest entry added and moving forward.\n\tE get(int index);\n\tE[] getBuffer();\n\t// Access object at a given index, starting from the latest entry added and moving backwards.\n\tE getLatest(int index);\n\tint size();\n}", "des": "A circular buffer that supports random bidirectional access."}
{"index": 3574, "repo": "druid-processing-26.0.0", "code": "Class Closer {\n\t// Closes all Closeable instances that have been added to this Closer.\n\tvoid close();\n\t// Creates a new Closer.\n\tstatic Closer create();\n\t// Registers the given Closeable to be closed when this Closer is closed.\n\t<C extends Closeable>C register(C closeable);\n\t<C extends Closeable>void registerAll(Collection<C> closeables);\n\t// Stores the given throwable and rethrows it.\n\tRuntimeException rethrow(Throwable e);\n}", "des": "A Closeable that collects Closeable resources and closes them all when it is closed. This is intended to approximately emulate the behavior of Java 7's try-with-resources statement in JDK6-compatible code. Running on Java 7, code using this should be approximately equivalent in behavior to the same code written with try-with-resources. Running on Java 6, exceptions that cannot be thrown must be logged rather than being added to the thrown exception as a suppressed exception."}
{"index": 3575, "repo": "druid-processing-26.0.0", "code": "Interface CloudObjectSplitWidget {\n\t// Iterator of descriptors that match a list of prefixes.\n\tIterator<CloudObjectSplitWidget.LocationWithSize> getDescriptorIteratorForPrefixes(List<URI> prefixes);\n\t// Size of an object.\n\tlong getObjectSize(CloudObjectLocation descriptor);\n}", "des": "Helper used by CloudObjectInputSource to implement SplittableInputSource.createSplits(org.apache.druid.data.input.InputFormat, org.apache.druid.data.input.SplitHintSpec)."}
{"index": 3576, "repo": "druid-processing-26.0.0", "code": "Class ClusterByPartition {\n\tboolean equals(Object o);\n\t// Get the ending key for this range.\n\tRowKey getEnd();\n\t// Get the starting key for this range.\n\tRowKey getStart();\n}", "des": "Boundaries of a partition marked by start and end keys. The keys are generally described by a ClusterBy instance that is not referenced here. (It is generally provided contextually.) Often, this object is part of a full partition set represented by ClusterByPartitions."}
{"index": 3577, "repo": "druid-processing-26.0.0", "code": "Interface ClusteredGroupPartitioner {\n\t// Computes and returns a list of contiguous boundaries for independent groups.\n\tint[] computeBoundaries(List<String> columns);\n\tstatic ClusteredGroupPartitioner fromRAC(RowsAndColumns rac);\n\t// Semantically equivalent to computeBoundaries, but returns a list of RowsAndColumns objects instead of just boundary positions.\n\tArrayList<RowsAndColumns> partitionOnBoundaries(List<String> partitionColumns);\n}", "des": "A semantic interface used to partition a data set based on a given set of columns."}
{"index": 3578, "repo": "druid-processing-26.0.0", "code": "Interface Column {\n\t// Asks the Column to return itself as a concrete implementation of a specific interface.\n\t<T> T as(Class<? extends T> clazz);\n\t// Returns the column as a ColumnAccessor.\n\tColumnAccessor toAccessor();\n}", "des": "An interface representing a Column of data. This interface prescribes that a ColumnAccessor must be defined on the column, but also offers an as(java.lang.Class) method to allow for optimized specific implementations of semantically meaningful logic. That is, the expectation is that some things work with Column objects might choose to first ask the Column object to become some other interface. If the Column knows how to do a good job as the requested interface, it can return its own concrete implementation of the interface and run the necessary logic in its own optimized fashion. If the Column instance does not know how to implement the semantic interface, it is expected that the ColumnAccessor will be leveraged to implement whatever logic is required."}
{"index": 3579, "repo": "druid-processing-26.0.0", "code": "Interface ColumnarMultiInts {\n\t// Returns the values at a given row index.\n\tIndexedInts get(int index);\n\t// Returns the values at a given row index.\n\tIndexedInts getUnshared(int index);\n}", "des": "Resource that provides random access to a packed array of short arrays of ints (IndexedInts). Backs up multi-valued DictionaryEncodedColumns."}
{"index": 3580, "repo": "druid-processing-26.0.0", "code": "Interface ColumnIndexCapabilities {\n\t// Indicates if an index is an exact match, or should also be post-filtered with a value matcher.\n\tboolean isExact();\n\t// Indicates if an index can be inverted for use with a 'NOT' filter.\n\tboolean isInvertible();\n\tColumnIndexCapabilities merge(ColumnIndexCapabilities other);\n}", "des": "Sort of like ColumnCapabilities, except for indexes supplied by ColumnIndexSelector, provides information for how query processing may use indexes."}
{"index": 3581, "repo": "druid-processing-26.0.0", "code": "Class ColumnsFilter {\n\t// Accepts all columns.\n\tstatic ColumnsFilter all();\n\t// Check if a column should be included or not.\n\tabstract boolean apply(String column);\n\t// Accepts all columns, except those on a specific list.\n\tstatic ColumnsFilter exclusionBased(Set<String> exclusions);\n\t// Accepts a specific list of columns.\n\tstatic ColumnsFilter inclusionBased(Set<String> inclusions);\n\t// Returns a new filter with a particular column added.\n\tabstract ColumnsFilter plus(String column);\n}", "des": "Used by some InputSourceReader implementations in order to know what columns will need to be read out of the InputRow objects they create. This is meant to be useful as an optimization: if we're reading from a columnar data format, then when a column isn't going to be needed, we shouldn't read it."}
{"index": 3582, "repo": "druid-processing-26.0.0", "code": "Class ComparatorDimensionDictionary<T> {\n\tint add(T originalValue);\n\t// Estimates the size of the dimension value in bytes.\n\tlong estimateSizeOfValue(T value);\n\tint getId(T value);\n\tint getIdForNull();\n\tT getMaxValue();\n\tT getMinValue();\n\tT getValue(int id);\n\tint size();\n\t// Gets the current size of this dictionary in bytes.\n\tlong sizeInBytes();\n\tComparatorSortedDimensionDictionary<T> sort();\n}", "des": "Comparator based DimensionDictionary there are a lot of unused methods in here for now since the only thing this is used for is to build up the unsorted dictionary and then it is converted to a ComparatorSortedDimensionDictionary, but leaving the unused methods in place for now to be basically compatible with the other implementation. This version is not thread-safe since the only current user doesn't use the dictionary for realtime queries, if this changes we need to add a 'ConcurrentComparatorDimensionDictionary'."}
{"index": 3583, "repo": "druid-processing-26.0.0", "code": "Class ComplexFieldWriter {\n\t// Releases resources held by this writer.\n\tvoid close();\n\t// Writes the current selection at the given memory position.\n\tlong writeTo(org.apache.datasketches.memory.WritableMemory memory, long position, long maxSize);\n}", "des": "Wraps a BaseObjectColumnValueSelector and uses ComplexMetricSerde.toBytes(java.lang.Object) to write complex objects. See ComplexFieldReader for format details."}
{"index": 3584, "repo": "druid-processing-26.0.0", "code": "Class ComplexMetrics {\n\tstatic ComplexMetricSerde getSerdeForType(String type);\n\t// Register a serde name -> ComplexMetricSerde mapping.\n\tstatic void registerSerde(String type, ComplexMetricSerde serde);\n\t// Unregister a serde name -> ComplexMetricSerde mapping.\n\tstatic void unregisterSerde(String type);\n}", "des": "ComplexMetrics houses a mapping of serde names to affiliated ComplexMetricSerde objects."}
{"index": 3585, "repo": "druid-processing-26.0.0", "code": "Class ComposingOutputChannelFactory {\n\t// Create a channel pair tagged with a particular partition number.\n\tOutputChannel openChannel(int partitionNumber);\n\t// Create a non-writable, always-empty channel pair tagged with a particular partition number.\n\tOutputChannel openNilChannel(int partitionNumber);\n\t// Create a channel pair tagged with a particular name and a flag to delete the channel data after its read.\n\tPartitionedOutputChannel openPartitionedChannel(String name, boolean deleteAfterRead);\n}", "des": "A channel factory which provides ordered composed channels. The factory encapsulates multiple output channel factories and automatically switches between then when the current factory is 'full' for writes. The reads can also encapsulate multiple readable channels with automatic switching."}
{"index": 3586, "repo": "druid-processing-26.0.0", "code": "Class CompressedColumnarIntsSerializer {\n\tvoid addValue(int val);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Streams array of integers out in the binary format described by CompressedColumnarIntsSupplier"}
{"index": 3587, "repo": "druid-processing-26.0.0", "code": "Enum CompressionFactory.LongEncodingStrategy {\n\tstatic CompressionFactory.LongEncodingStrategy fromString(String name);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompressionFactory.LongEncodingStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompressionFactory.LongEncodingStrategy[] values();\n}", "des": "The compression of decompression of encodings are separated into different enums. EncodingStrategy refers to the strategy used to encode the data, and EncodingFormat refers to the format the data is encoded in. Note there is not necessarily an one-to-one mapping between to two. For instance, the AUTO LongEncodingStrategy scans the data once and decide on which LongEncodingFormat to use based on data property, so it's possible for the EncodingStrategy to write in any of the LongEncodingFormat. On the other hand, there are no LongEncodingStrategy that always write in TABLE LongEncodingFormat since it only works for data with low cardinality."}
{"index": 3588, "repo": "druid-processing-26.0.0", "code": "Class ConcatRowsAndColumns {\n\t// Asks the RowsAndColumns to return itself as a concrete implementation of a specific interface.\n\t<T> T as(Class<T> clazz);\n\t// Finds a column by name.\n\tColumn findColumn(String name);\n\t// The set of column names available from the RowsAndColumns\n\tCollection<String> getColumnNames();\n\t// The number of rows in the RowsAndColumns object\n\tint numRows();\n}", "des": "A RowsAndColumns implementation that effectively concatenates multiple RowsAndColumns objects together."}
{"index": 3589, "repo": "druid-processing-26.0.0", "code": "Class ConcurrentGrouper<KeyType> {\n\t// Aggregate the current row with the provided key.\n\tAggregateResult aggregate(KeyType key, int keyHash);\n\t// Close the grouper and release associated resources.\n\tvoid close();\n\t// Initialize the grouper.\n\tvoid init();\n\t// Check this grouper is initialized or not.\n\tboolean isInitialized();\n\t// Iterate through entries.\n\tCloseableIterator<Grouper.Entry<KeyType>> iterator(boolean sorted);\n\t// Reset the grouper to its initial state.\n\tvoid reset();\n}", "des": "Grouper based around a set of underlying SpillingGrouper instances. Thread-safe."}
{"index": 3590, "repo": "druid-processing-26.0.0", "code": "Interface DataSegmentArchiver {\n\t// Perform an archive task on the segment and return the resulting segment or null if there was no action needed.\n\tDataSegment archive(DataSegment segment);\n\t// Perform the restore from an archived segment and return the resulting segment or null if there was no action\n\tDataSegment restore(DataSegment segment);\n}", "des": "DataSegmentArchiver knows how to archive segments. Since any implementation of DataSegmentArchiver is initialized when an ingestion job starts if a deep storage extension is loaded even when that deep storage is actually not used, implementations should avoid initializing the deep storage client immediately but defer it until the deep storage client is actually used."}
{"index": 3591, "repo": "druid-processing-26.0.0", "code": "Interface DataSegmentKiller {\n\tstatic String descriptorPath(String path);\n\t// Removes segment files (index and metadata) from deep storage.\n\tvoid kill(DataSegment segment);\n\t// Like a nuke.\n\tvoid killAll();\n\t// A more stoic killer who doesn't throw a tantrum if things get messy.\n\tdefault void killQuietly(DataSegment segment);\n}", "des": "DataSegmentKiller knows how to kill segments from the Druid system. Since any implementation of DataSegmentKiller is initialized when an ingestion job starts if a deep storage extension is loaded even when that deep storage is actually not used, implementations should avoid initializing the deep storage client immediately but defer it until the deep storage client is actually used."}
{"index": 3592, "repo": "druid-processing-26.0.0", "code": "Class DefaultBlockingPool<T> {\n\tint getPoolSize();\n\tint maxSize();\n\t// Take resources from the pool, waiting if necessary until the elements of the given number become available.\n\tList<ReferenceCountingResourceHolder<T>> takeBatch(int elementNum);\n\t// Take resources from the pool, waiting up to the specified wait time if necessary for elements of the given number to become available.\n\tList<ReferenceCountingResourceHolder<T>> takeBatch(int elementNum, long timeoutMs);\n}", "des": "Pool that pre-generates objects up to a limit, then permits possibly-blocking \"take\" operations."}
{"index": 3593, "repo": "druid-processing-26.0.0", "code": "Class DelimitedInputFormat {\n\tInputEntityReader createReader(InputRowSchema inputRowSchema, InputEntity source, File temporaryDirectory);\n\t// Trait to indicate that a file can be split into multiple InputSplits.\n\tboolean isSplittable();\n\t// Copied from Guava's Splitter.splitToList(CharSequence).\n\tstatic List<String> splitToList(com.google.common.base.Splitter splitter, String input);\n}", "des": "InputFormat for customized Delimiter Separate Value format of input data (default is TSV)."}
{"index": 3594, "repo": "druid-processing-26.0.0", "code": "Class DelimitedValueReader {\n\t// Returns the number of header lines to skip.\n\tint getNumHeaderLinesToSkip();\n\t// Returns true if the file format needs to process a header line.\n\tboolean needsToProcessHeaderLine();\n\t// Parses the given line into a list of InputRows.\n\tList<InputRow> parseInputRows(String line);\n\t// Processes a header line.\n\tvoid processHeaderLine(String line);\n\t// Converts the given intermediate row into a Map.\n\tList<Map<String,Object>> toMap(String intermediateRow);\n}", "des": "DelimitedValueReader is the reader for Delimitor Separate Value format input data(CSV/TSV)."}
{"index": 3595, "repo": "druid-processing-26.0.0", "code": "Class DictionaryBuilding {\n\t// Creates a forward dictionary (dictionary ID -> value).\n\tstatic <T> List<T> createDictionary();\n\t// Creates a reverse dictionary (value -> dictionary ID).\n\tstatic <T> it.unimi.dsi.fastutil.objects.Object2IntMap<T> createReverseDictionary();\n\t// Estimated footprint of a new entry.\n\tstatic int estimateEntryFootprint(int valueFootprint);\n}", "des": "Utilities for parts of the groupBy engine that need to build dictionaries."}
{"index": 3596, "repo": "druid-processing-26.0.0", "code": "Interface DictionaryEncodedStringValueIndex {\n\tBitmapFactory getBitmapFactory();\n\t// Get the cardinality of the underlying value dictionary\n\tint getCardinality();\n\t// Get the value in the underlying value dictionary of the specified dictionary id\n\tString getValue(int index);\n}", "des": "This exposes a 'raw' view into bitmap value indexes of a string DictionaryEncodedColumn. This allows callers to directly retrieve bitmaps via dictionary ids, as well as access to lower level details of such a column like value lookup and value cardinality. Most filter implementations should likely be using higher level index instead, such as StringValueSetIndex, LexicographicalRangeIndex, NumericRangeIndex, or DruidPredicateIndex"}
{"index": 3597, "repo": "druid-processing-26.0.0", "code": "Class DoubleCardinalityAggregatorColumnSelectorStrategy {\n\tstatic void addDoubleToCollector(HyperLogLogCollector collector, double n);\n\t// Retrieve the current row from dimSelector and add the row values to the hasher.\n\tvoid hashRow(BaseDoubleColumnValueSelector selector, com.google.common.hash.Hasher hasher);\n\t// Retrieve the current row from dimSelector and add the row values to HyperLogLogCollector.\n\tvoid hashValues(BaseDoubleColumnValueSelector selector, HyperLogLogCollector collector);\n}", "des": "If performance of this class appears to be a bottleneck for somebody, one simple way to improve it is to split it into two different classes, one that is used when NullHandling.replaceWithDefault() is false, and one - when it's true, moving this computation out of the tight loop"}
{"index": 3598, "repo": "druid-processing-26.0.0", "code": "Class DoubleFieldWriter {\n\t// Releases resources held by this writer.\n\tvoid close();\n\t// Inverse of transform(double).\n\tstatic double detransform(long bits);\n\t// Transforms a double into a form where it can be compared as unsigned bytes without decoding.\n\tstatic long transform(double n);\n\t// Writes the current selection at the given memory position.\n\tlong writeTo(org.apache.datasketches.memory.WritableMemory memory, long position, long maxSize);\n}", "des": "Wraps a BaseDoubleColumnValueSelector and writes field values. See DoubleFieldReader for format details."}
{"index": 3599, "repo": "druid-processing-26.0.0", "code": "Class DoubleLastVectorAggregator {\n\t// Same as BufferAggregator.get(java.nio.ByteBuffer, int).\n\tObject get(ByteBuffer buf, int position);\n\t// Abstract function which needs to be overridden by subclasses to set the initial value\n\tvoid initValue(ByteBuffer buf, int position);\n}", "des": "Vectorized version of on heap 'last' aggregator for column selectors with type DOUBLE.."}
{"index": 3600, "repo": "druid-processing-26.0.0", "code": "Class DummyBlockingPool<T> {\n\tstatic <T> BlockingPool<T> instance();\n\tint maxSize();\n\t// Take resources from the pool, waiting if necessary until the elements of the given number become available.\n\tList<ReferenceCountingResourceHolder<T>> takeBatch(int elementNum);\n\t// Take resources from the pool, waiting up to the specified wait time if necessary for elements of the given number to become available.\n\tList<ReferenceCountingResourceHolder<T>> takeBatch(int elementNum, long timeoutMs);\n}", "des": "BlockingPool with 0 maxSize, all take*() methods immediately throw UnsupportedOperationException."}
{"index": 3601, "repo": "druid-processing-26.0.0", "code": "Class Either<L,R> {\n\tboolean equals(Object o);\n\t// Returns the error object.\n\tL error();\n\tstatic <L,R> Either<L,R> error(L error);\n\tboolean isError();\n\tboolean isValue();\n\t// Applies a function to this value, if present.\n\t<T> Either<L,T> map(Function<R,T> fn);\n\tstatic <L,R> Either<L,R> value(R value);\n\t// If this Either represents a value, returns it.\n\tR valueOrThrow();\n}", "des": "Encapsulates either an \"error\" or a \"value\". Similar to the Either class in Scala or Haskell, except the possibilities are named \"error\" and \"value\" instead of \"left\" and \"right\"."}
{"index": 3602, "repo": "druid-processing-26.0.0", "code": "Class EncodedKeyComponent<K> {\n\t// Encoded dimension value(s) to be used as a component for a row key.\n\tK getComponent();\n\t// Effective size of the key component in bytes.\n\tlong getEffectiveSizeBytes();\n}", "des": "Represents the encoded component of a row key corresponding to a single dimension. The row key contains a component for each dimension."}
{"index": 3603, "repo": "druid-processing-26.0.0", "code": "Class EntireLayoutColumnarDoublesSerializer {\n\tvoid add(double value);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\tint size();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Serializer that produces EntireLayoutColumnarDoublesSupplier.EntireLayoutColumnarDoubles."}
{"index": 3604, "repo": "druid-processing-26.0.0", "code": "Class EntireLayoutColumnarFloatsSerializer {\n\tvoid add(float value);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\tint size();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Serializer that produces EntireLayoutColumnarFloatsSupplier.EntireLayoutColumnarFloats."}
{"index": 3605, "repo": "druid-processing-26.0.0", "code": "Class EntireLayoutColumnarLongsSerializer {\n\tvoid add(long value);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\tint size();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Serializer that produces EntireLayoutColumnarLongsSupplier.EntireLayoutColumnarLongs."}
{"index": 3606, "repo": "druid-processing-26.0.0", "code": "Class EqualToHavingSpec {\n\t// This method treats internal value as double mainly for ease of test.\n\tboolean equals(Object o);\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\tString getAggregationName();\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\tNumber getValue();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "The \"=\" operator in a \"having\" clause. This is similar to SQL's \"having aggregation = value\", except that in SQL an aggregation is an expression instead of an aggregation name as in Druid."}
{"index": 3607, "repo": "druid-processing-26.0.0", "code": "Class EventMap {\n\t// Convert this EventMap to a builder.\n\tEventMap.Builder asBuilder();\n\t// Returns builder with Fluent API to build EventMap instance using method chaining\n\tstatic EventMap.Builder builder();\n}", "des": "EventMap is a hash map implementation. It can be safely serialzed to JSON using Jackson serializer as it respects the polymorphic annotations on entires (unlike standard Map). The example of polymorphic class is a query interface, where different native query types are resolved by additional field called \"queryType\". This implementation ensures that the annotation on the values are respected during serialization."}
{"index": 3608, "repo": "druid-processing-26.0.0", "code": "Class ExpressionColumnValueSelector {\n\t// Implementations override this.\n\tprotected ExprEval<?> eval();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n}", "des": "Basic expression ColumnValueSelector. Evaluates Expr into ExprEval against Expr.ObjectBinding which are backed by the underlying expression input ColumnValueSelectors"}
{"index": 3609, "repo": "druid-processing-26.0.0", "code": "Class ExpressionLambdaAggregatorInputBindings {\n\tvoid accumulate(ExprEval<?> eval);\n\t// Get value binding for string identifier of IdentifierExpr\n\tObject get(String name);\n\tExprEval<?> getAccumulator();\n\t// Get the ExpressionType from the backing store for a given identifier (this is likely a column, but could be other things depending on the backing adapter)\n\tExpressionType getType(String name);\n\tvoid setAccumulator(ExprEval<?> acc);\n}", "des": "Special Expr.ObjectBinding for use with ExpressionLambdaAggregatorFactory. This value binding holds a value for a special 'accumulator' variable, in addition to the 'normal' bindings to the underlying selector inputs for other identifiers, which allows for easy forward feeding of the results of an expression evaluation to use in the bindings of the next evaluation."}
{"index": 3610, "repo": "druid-processing-26.0.0", "code": "Class ExprMacroTable.BaseScalarMacroFunctionExpr {\n\t// Examine the usage of IdentifierExpr children of an Expr, constructing a Expr.BindingAnalysis\n\tExpr.BindingAnalysis analyzeInputs();\n\tboolean equals(Object o);\n\tList<Expr> getArgs();\n\t// Convert the Expr back into parseable string that when parsed with Parser.parse(String, ExprMacroTable) will produce an equivalent Expr.\n\tString stringify();\n}", "des": "Base class for multi-argument ExprMacroTable.ExprMacro function Expr"}
{"index": 3611, "repo": "druid-processing-26.0.0", "code": "Class ExprMacroTable.BaseScalarUnivariateMacroFunctionExpr {\n\t// Examine the usage of IdentifierExpr children of an Expr, constructing a Expr.BindingAnalysis\n\tExpr.BindingAnalysis analyzeInputs();\n\tboolean equals(Object o);\n\tList<Expr> getArgs();\n\t// Convert the Expr back into parseable string that when parsed with Parser.parse(String, ExprMacroTable) will produce an equivalent Expr.\n\tString stringify();\n}", "des": "Base class for single argument ExprMacroTable.ExprMacro function Expr"}
{"index": 3612, "repo": "druid-processing-26.0.0", "code": "Enum ExprType {\n\t// Value is an array of some other TypeDescriptor\n\tboolean isArray();\n\t// Scalar numeric primitive values.\n\tboolean isNumeric();\n\t// Scalar numeric and string values.\n\tboolean isPrimitive();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExprType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExprType[] values();\n}", "des": "Base 'value' types of Druid expression language, all Expr must evaluate to one of these types."}
{"index": 3613, "repo": "druid-processing-26.0.0", "code": "Interface ExtractionFn {\n\t// The \"extraction\" function.\n\tString apply(long value);\n\t// The \"extraction\" function.\n\tString apply(Object value);\n\t// The \"extraction\" function.\n\tString apply(String value);\n\t// A dim extraction can be of one of two types, renaming or rebucketing.\n\tExtractionFn.ExtractionType getExtractionType();\n\t// Offers information on whether the extraction will preserve the original ordering of the values.\n\tboolean preservesOrdering();\n}", "des": "An ExtractionFn is a function that can be used to transform the values of a column (typically a dimension). Note that ExtractionFn implementations are expected to be Threadsafe. A simple example of the type of operation this enables is the RegexDimExtractionFn which applies a regular expression with a capture group. When the regular expression matches the value of a dimension, the value captured by the group is used for grouping operations instead of the dimension value."}
{"index": 3614, "repo": "druid-processing-26.0.0", "code": "Interface FieldWriter {\n\t// Releases resources held by this writer.\n\tvoid close();\n\t// Writes the current selection at the given memory position.\n\tlong writeTo(org.apache.datasketches.memory.WritableMemory memory, long position, long maxSize);\n}", "des": "Helper used to write field values to row-based frames or RowKey. Most callers should use FrameWriters to build frames from ColumnSelectorFactory, rather than using this interface directly. Not thread-safe."}
{"index": 3615, "repo": "druid-processing-26.0.0", "code": "Class FileOutputChannelFactory {\n\t// Create a channel pair tagged with a particular partition number.\n\tOutputChannel openChannel(int partitionNumber);\n\t// Create a non-writable, always-empty channel pair tagged with a particular partition number.\n\tOutputChannel openNilChannel(int partitionNumber);\n\t// Create a channel pair tagged with a particular name and a flag to delete the channel data after its read.\n\tPartitionedOutputChannel openPartitionedChannel(String name, boolean deleteAfterRead);\n}", "des": "An OutputChannelFactory that generates WritableFrameFileChannel backed by FrameFileWriter."}
{"index": 3616, "repo": "druid-processing-26.0.0", "code": "Class FloatCardinalityAggregatorColumnSelectorStrategy {\n\tstatic void addFloatToCollector(HyperLogLogCollector collector, float n);\n\t// Retrieve the current row from dimSelector and add the row values to the hasher.\n\tvoid hashRow(BaseFloatColumnValueSelector selector, com.google.common.hash.Hasher hasher);\n\t// Retrieve the current row from dimSelector and add the row values to HyperLogLogCollector.\n\tvoid hashValues(BaseFloatColumnValueSelector selector, HyperLogLogCollector collector);\n}", "des": "If performance of this class appears to be a bottleneck for somebody, one simple way to improve it is to split it into two different classes, one that is used when NullHandling.replaceWithDefault() is false, and one - when it's true, moving this computation out of the tight loop"}
{"index": 3617, "repo": "druid-processing-26.0.0", "code": "Class FloatFieldWriter {\n\t// Releases resources held by this writer.\n\tvoid close();\n\t// Inverse of transform(float).\n\tstatic float detransform(int bits);\n\t// Transforms a float into a form where it can be compared as unsigned bytes without decoding.\n\tstatic int transform(float n);\n\t// Writes the current selection at the given memory position.\n\tlong writeTo(org.apache.datasketches.memory.WritableMemory memory, long position, long maxSize);\n}", "des": "Wraps a BaseFloatColumnValueSelector and writes field values. See FloatFieldReader for format details."}
{"index": 3618, "repo": "druid-processing-26.0.0", "code": "Class FloatLastVectorAggregator {\n\t// Same as BufferAggregator.get(java.nio.ByteBuffer, int).\n\tObject get(ByteBuffer buf, int position);\n\t// Abstract function which needs to be overridden by subclasses to set the initial value\n\tvoid initValue(ByteBuffer buf, int position);\n}", "des": "Vectorized version of on heap 'last' aggregator for column selectors with type FLOAT.."}
{"index": 3619, "repo": "druid-processing-26.0.0", "code": "Class FrameChannelBatcher {\n\t// Closes resources used by this worker.\n\tvoid cleanup();\n\t// List of input channels.\n\tList<ReadableFrameChannel> inputChannels();\n\t// List of output channels.\n\tList<WritableFrameChannel> outputChannels();\n\t// Runs some of the algorithm, without blocking, and either returns a value or a set of input channels to wait for.\n\tReturnOrAwait<Pair<List<Frame>,it.unimi.dsi.fastutil.ints.IntSet>> runIncrementally(it.unimi.dsi.fastutil.ints.IntSet readableInputs);\n}", "des": "Processor that reads up to \"maxFrames\" frames from some input channels and combines them into a batch. There may be frames left over in the channels when the worker is done. Returns the batch and the set of channels that have more left to read. This processor does not close its input channels. The caller should do that after all input channels are finished."}
{"index": 3620, "repo": "druid-processing-26.0.0", "code": "Class FrameChannelHashPartitioner {\n\t// Closes resources used by this worker.\n\tvoid cleanup();\n\t// List of input channels.\n\tList<ReadableFrameChannel> inputChannels();\n\t// List of output channels.\n\tList<WritableFrameChannel> outputChannels();\n\t// Runs some of the algorithm, without blocking, and either returns a value or a set of input channels to wait for.\n\tReturnOrAwait<Long> runIncrementally(it.unimi.dsi.fastutil.ints.IntSet readableInputs);\n}", "des": "Processor that hash-partitions rows from any number of input channels, and writes partitioned frames to output channels. Input frames must be FrameType.ROW_BASED, and input signature must be the same as output signature. This processor hashes each row using BaseState.xxHash64(long, long, long) with a seed of HASH_SEED."}
{"index": 3621, "repo": "druid-processing-26.0.0", "code": "Class FrameChannelMerger {\n\t// Closes resources used by this worker.\n\tvoid cleanup();\n\t// List of input channels.\n\tList<ReadableFrameChannel> inputChannels();\n\t// List of output channels.\n\tList<WritableFrameChannel> outputChannels();\n\t// Runs some of the algorithm, without blocking, and either returns a value or a set of input channels to wait for.\n\tReturnOrAwait<Long> runIncrementally(it.unimi.dsi.fastutil.ints.IntSet readableInputs);\n}", "des": "Processor that merges already-sorted inputChannels and writes a fully-sorted stream to a single outputChannel. Frames from input channels must be FrameType.ROW_BASED. Output frames will be row-based as well. For unsorted output, use FrameChannelMixer instead."}
{"index": 3622, "repo": "druid-processing-26.0.0", "code": "Class FrameChannelMixer {\n\t// Closes resources used by this worker.\n\tvoid cleanup();\n\t// List of input channels.\n\tList<ReadableFrameChannel> inputChannels();\n\t// List of output channels.\n\tList<WritableFrameChannel> outputChannels();\n\t// Runs some of the algorithm, without blocking, and either returns a value or a set of input channels to wait for.\n\tReturnOrAwait<Long> runIncrementally(it.unimi.dsi.fastutil.ints.IntSet readableInputs);\n}", "des": "Processor that merges frames from inputChannels into a single outputChannel. No sorting is done: input frames are simply written to the output channel as they come in. For sorted output, use FrameChannelMerger instead."}
{"index": 3623, "repo": "druid-processing-26.0.0", "code": "Interface FrameComparisonWidget {\n\t// Compare a specific row of this frame to a specific row of another frame.\n\tint compare(int row, FrameComparisonWidget otherWidget, int otherRow);\n\t// Compare a specific row of this frame to the provided key.\n\tint compare(int row, RowKey key);\n\t// Whether a particular row has a null field in its comparison key.\n\tboolean isPartiallyNullKey(int row);\n\t// Returns the RowKey corresponding to a particular row.\n\tRowKey readKey(int row);\n}", "des": "Wraps a Frame and provides ways to compare rows of that frame to various other things. Not thread-safe."}
{"index": 3624, "repo": "druid-processing-26.0.0", "code": "Class FrameCursor {\n\tvoid advance();\n\tvoid advanceUninterruptibly();\n\tColumnSelectorFactory getColumnSelectorFactory();\n\t// Returns the current row number.\n\tint getCurrentRow();\n\torg.joda.time.DateTime getTime();\n\tboolean isDone();\n\tboolean isDoneOrInterrupted();\n\tvoid reset();\n\t// Moves this cursor to a particular row number.\n\tvoid setCurrentRow(int rowNumber);\n}", "des": "An implementation of Cursor used by FrameCursorFactory and FrameCursorFactory. Adds the methods getCurrentRow() and setCurrentRow(int) so the cursor can be moved to particular rows."}
{"index": 3625, "repo": "druid-processing-26.0.0", "code": "Class FrameFileFooter {\n\t// Get the last byte for the frame specified.\n\tlong getFrameEndPosition(int frameNumber);\n\tint getNumFrames();\n\tint getNumPartitions();\n\t// First frame of a given partition.\n\tint getPartitionStartFrame(int partition);\n}", "des": "Encapsulation for rame file footer related operations. The footer must be wrapped in a memory object (the memory can be physical or mmaped). Some verifications are also done on the footer to see if it is not corrupted. The schema for footer is as described by FrameFile."}
{"index": 3626, "repo": "druid-processing-26.0.0", "code": "Class FrameFilePartialFetch {\n\t// Future that resolves when it is a good time to request the next chunk of the frame file.\n\tcom.google.common.util.concurrent.ListenableFuture<?> backpressureFuture();\n\t// The exception that was encountered, if isExceptionCaught() is true.\n\tThrowable getExceptionCaught();\n\t// Whether an exception was encountered during response processing.\n\tboolean isExceptionCaught();\n\tboolean isLastFetch();\n}", "des": "Response object for FrameFileHttpResponseHandler. The handler mutates this object on each chunk of a chunked response. When the response is done, this object is returned to the caller."}
{"index": 3627, "repo": "druid-processing-26.0.0", "code": "Class FrameFileWriter {\n\t// Stops writing this file and closes early.\n\tvoid abort();\n\tvoid close();\n\t// Opens a writer for a particular channel.\n\tstatic FrameFileWriter open(WritableByteChannel channel, ByteBuffer compressionBuffer, ByteTracker byteTracker);\n\t// Write a frame.\n\tvoid writeFrame(Frame frame, int partition);\n}", "des": "Writer for FrameFile. See that class for format information."}
{"index": 3628, "repo": "druid-processing-26.0.0", "code": "Interface FrameProcessor<T> {\n\t// Closes resources used by this worker.\n\tvoid cleanup();\n\t// List of input channels.\n\tList<ReadableFrameChannel> inputChannels();\n\t// List of output channels.\n\tList<WritableFrameChannel> outputChannels();\n\t// Runs some of the algorithm, without blocking, and either returns a value or a set of input channels to wait for.\n\tReturnOrAwait<T> runIncrementally(it.unimi.dsi.fastutil.ints.IntSet readableInputs);\n}", "des": "A FrameProcessor is like an incremental version of Runnable that operates on ReadableFrameChannel and WritableFrameChannel. It is designed to enable interleaved non-blocking work on a fixed-size thread pool. Typically, this is done using an instance of FrameProcessorExecutor."}
{"index": 3629, "repo": "druid-processing-26.0.0", "code": "Class FrameWriters {\n\t// Creates a FrameWriterFactory.\n\tstatic FrameWriterFactory makeFrameWriterFactory(FrameType frameType, MemoryAllocatorFactory allocatorFactory, RowSignature signature, List<KeyColumn> sortColumns);\n\t// Returns a copy of \"signature\" with columns rearranged so the provided sortColumns appear as a prefix.\n\tstatic RowSignature sortableSignature(RowSignature signature, List<KeyColumn> keyColumns);\n}", "des": "Outward-facing utility methods for FrameWriterFactory and FrameWriter users."}
{"index": 3630, "repo": "druid-processing-26.0.0", "code": "Class Function.ArrayAddElementFunction {\n\t// Compute the output type of this function for a given set of argument expression inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, List<Expr> args);\n\t// Returns true if function produces an array.\n\tboolean hasArrayOutput();\n}", "des": "Scaffolding for a 2 argument Function which accepts one array and one scalar input and adds the scalar input to the array in some way."}
{"index": 3631, "repo": "druid-processing-26.0.0", "code": "Class Function.ArraysMergeFunction {\n\t// Given a list of arguments to this Function, get the set of arguments that must evaluate to an array value\n\tSet<Expr> getArrayInputs(List<Expr> args);\n\t// Compute the output type of this function for a given set of argument expression inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, List<Expr> args);\n\t// Returns true if function produces an array.\n\tboolean hasArrayOutput();\n}", "des": "Base scaffolding for functions which accept 2 array arguments and combine them in some way"}
{"index": 3632, "repo": "druid-processing-26.0.0", "code": "Class Function.BivariateFunction {\n\t// Evaluate the function, given a list of arguments and a set of bindings to provide values for IdentifierExpr.\n\tExprEval apply(List<Expr> args, Expr.ObjectBinding bindings);\n\tprotected abstract ExprEval eval(ExprEval x, ExprEval y);\n\t// Validate function arguments.\n\tvoid validateArguments(List<Expr> args);\n}", "des": "Base class for a 2 variable input Function implementation"}
{"index": 3633, "repo": "druid-processing-26.0.0", "code": "Class Function.BivariateMathFunction {\n\t// Check if a function can be 'vectorized', for a given set of Expr inputs.\n\tboolean canVectorize(Expr.InputBindingInspector inspector, List<Expr> args);\n\tprotected ExprEval eval(double x, double y);\n\tprotected ExprEval eval(ExprEval x, ExprEval y);\n\tprotected ExprEval eval(long x, long y);\n\t// Compute the output type of this function for a given set of argument expression inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, List<Expr> args);\n}", "des": "Base class for a 2 variable input mathematical Function, with specialized 'eval' implementations that operate on primitive number types"}
{"index": 3634, "repo": "druid-processing-26.0.0", "code": "Class Function.CaseSearchedFunc {\n\t// Evaluate the function, given a list of arguments and a set of bindings to provide values for IdentifierExpr.\n\tExprEval apply(List<Expr> args, Expr.ObjectBinding bindings);\n\t// Compute the output type of this function for a given set of argument expression inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, List<Expr> args);\n\t// Name of the function\n\tString name();\n\t// Validate function arguments.\n\tvoid validateArguments(List<Expr> args);\n}", "des": "\"Searched CASE\" function, similar to CASE WHEN boolean_expr THEN result [ELSE else_result] END in SQL."}
{"index": 3635, "repo": "druid-processing-26.0.0", "code": "Class Function.CaseSimpleFunc {\n\t// Evaluate the function, given a list of arguments and a set of bindings to provide values for IdentifierExpr.\n\tExprEval apply(List<Expr> args, Expr.ObjectBinding bindings);\n\t// Compute the output type of this function for a given set of argument expression inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, List<Expr> args);\n\t// Name of the function\n\tString name();\n\t// Validate function arguments.\n\tvoid validateArguments(List<Expr> args);\n}", "des": "\"Simple CASE\" function, similar to CASE expr WHEN value THEN result [ELSE else_result] END in SQL."}
{"index": 3636, "repo": "druid-processing-26.0.0", "code": "Class Function.UnivariateFunction {\n\t// Evaluate the function, given a list of arguments and a set of bindings to provide values for IdentifierExpr.\n\tExprEval apply(List<Expr> args, Expr.ObjectBinding bindings);\n\tprotected abstract ExprEval eval(ExprEval param);\n\t// Validate function arguments.\n\tvoid validateArguments(List<Expr> args);\n}", "des": "Base class for a single variable input Function implementation"}
{"index": 3637, "repo": "druid-processing-26.0.0", "code": "Class Function.UnivariateMathFunction {\n\t// Check if a function can be 'vectorized', for a given set of Expr inputs.\n\tboolean canVectorize(Expr.InputBindingInspector inspector, List<Expr> args);\n\tprotected ExprEval eval(double param);\n\tprotected ExprEval eval(ExprEval param);\n\tprotected ExprEval eval(long param);\n\t// Compute the output type of this function for a given set of argument expression inputs.\n\tExpressionType getOutputType(Expr.InputBindingInspector inspector, List<Expr> args);\n}", "des": "Base class for a single variable input mathematical Function, with specialized 'eval' implementations that that operate on primitive number types"}
{"index": 3638, "repo": "druid-processing-26.0.0", "code": "Class FunctionalExtraction {\n\t// The \"extraction\" function.\n\tString apply(String value);\n\t// A dim extraction can be of one of two types, renaming or rebucketing.\n\tExtractionFn.ExtractionType getExtractionType();\n\tString getReplaceMissingValueWith();\n\tboolean isInjective();\n\tboolean isRetainMissingValue();\n\t// Offers information on whether the extraction will preserve the original ordering of the values.\n\tboolean preservesOrdering();\n}", "des": "Functional extraction uses a function to find the new value. null values in the range can either retain the domain's value, or replace the null value with \"replaceMissingValueWith\""}
{"index": 3639, "repo": "druid-processing-26.0.0", "code": "Enum GeneratorColumnSchema.ValueDistribution {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GeneratorColumnSchema.ValueDistribution valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GeneratorColumnSchema.ValueDistribution[] values();\n}", "des": "SEQUENTIAL: Generate integer or enumerated values in sequence. Not random. DISCRETE_UNIFORM: Discrete uniform distribution, generates integers or enumerated values. ROUNDED_NORMAL: Discrete distribution that rounds sample values from an underlying normal distribution ZIPF: Discrete Zipf distribution. Lower numbers have higher probability. Can also generate Zipf distribution from a list of enumerated values. LAZY_ZIPF: ZIPF but lazy evaluated for large cardinalities LAZY_DISCRETE_UNIFORM: DISCRETE_UNIFORM but lazy evaluated for large cardinalities ENUMERATED: Discrete distribution, generated from lists of values and associated probabilities. NORMAL: Continuous normal distribution. UNIFORM: Continuous uniform distribution."}
{"index": 3640, "repo": "druid-processing-26.0.0", "code": "Class GenericIndexedBasedComplexColumn {\n\t// Close and release any resources associated with this column.\n\tvoid close();\n\tClass<?> getClazz();\n\tint getLength();\n\t// Return rows in the column.\n\tObject getRowValue(int rowNum);\n\tString getTypeName();\n}", "des": "Implementation of ComplexColumn to be used when complex column serialization is done by using GenericIndexed by using default implementations of \"writeToXXX\" methods in ComplexColumnSerializer"}
{"index": 3641, "repo": "druid-processing-26.0.0", "code": "Interface GenericQueryMetricsFactory {\n\t// Creates a QueryMetrics which doesn't have predefined QueryMetrics subclass.\n\tQueryMetrics<Query<?>> makeMetrics();\n\t// Creates a QueryMetrics for query, which doesn't have predefined QueryMetrics subclass.\n\tQueryMetrics<Query<?>> makeMetrics(Query<?> query);\n}", "des": "This factory is used for DI of custom QueryMetrics implementations for all query types, which don't (yet) need to emit custom dimensions and/or metrics, i. e. they are good with the generic QueryMetrics interface. Implementations could be injected using PolyBind .optionBinder(binder, Key.get(GenericQueryMetricsFactory.class)) .addBinding(\"myCustomGenericQueryMetricsFactory\") .to(MyCustomGenericQueryMetricsFactory.class); And then setting property: druid.query.generic.queryMetricsFactory=myCustomGenericQueryMetricsFactory Unlike QueryMetrics itself, this interface is considered stable and is expected to be injected into custom Query extensions that do not want to worry about the potential instability of QueryMetrics."}
{"index": 3642, "repo": "druid-processing-26.0.0", "code": "Class GlobalDictionaryEncodedFieldColumnWriter<T> {\n\t// Add a value to the unsorted local dictionary and write to an intermediate column\n\tvoid addValue(int row, Object val);\n\t// Open the writer so that addValue(int, Object) can be called\n\tvoid open();\n\tvoid writeLongAndDoubleColumnLength(WritableByteChannel channel, int longLength, int doubleLength);\n\tvoid writeTo(int finalRowCount, FileSmoosher smoosher);\n}", "des": "Base class for writer of global dictionary encoded nested field columns for NestedDataColumnSerializerV4 and NestedDataColumnSerializer. Nested columns are written in multiple passes. The first pass processes the 'raw' nested data with a StructuredDataProcessor which will call addValue(int, Object) for writers of each field which is present. For this type of writer, this entails building a local dictionary (localDictionary)to map into to the global dictionary (globalDictionaryIdLookup) and writes this unsorted localId to an intermediate integer column, intermediateValueWriter."}
{"index": 3643, "repo": "druid-processing-26.0.0", "code": "Class GlobalTableDataSource {\n\t// Query results from Broadcast datasources should not be cached on broker https://github.com/apache/druid/issues/10444\n\tboolean isCacheable(boolean isBroker);\n\t// Returns true if all servers have a full copy of this datasource.\n\tboolean isGlobal();\n}", "des": "TableDataSource variant for globally available 'broadcast' segments. If bound to a JoinableFactory that can create an IndexedTable using DruidBinders.joinableFactoryBinder, this allows optimal usage of segments using this DataSource type in join operations (because they are global), and so can be pushed down to historicals as a JoinDataSource, instead of requiring a subquery join using InlineDataSource to construct an IndexedTable on the fly on the broker. Because it is also a TableDataSource, when queried directly, or on the left hand side of a join, they will be treated as any normal table datasource."}
{"index": 3644, "repo": "druid-processing-26.0.0", "code": "Class GreaterThanHavingSpec {\n\t// This method treats internal value as double mainly for ease of test.\n\tboolean equals(Object o);\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\tString getAggregationName();\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\tNumber getValue();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "The \">\" operator in a \"having\" clause. This is similar to SQL's \"having aggregation > value\", except that an aggregation in SQL is an expression instead of an aggregation name as in Druid."}
{"index": 3645, "repo": "druid-processing-26.0.0", "code": "Enum HashPartitionFunction {\n\tstatic HashPartitionFunction fromString(String type);\n\t// Returns an ID of a hash bucket for the given serializedRow.\n\tabstract int hash(byte[] serializedRow, int numBuckets);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HashPartitionFunction valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HashPartitionFunction[] values();\n}", "des": "An enum of supported hash partition functions. This enum should be updated when we want to use a new function for hash partitioning. All partition functions listed in this enum must be backwards-compatible as the hash function should apply to all segments in the same way no matter what Druid version was used to create those segments. This function is a part of HashBasedNumberedShardSpec which is stored in the metadata store."}
{"index": 3646, "repo": "druid-processing-26.0.0", "code": "Interface HavingSpec {\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "A \"having\" clause that filters aggregated/dimension value. This is similar to SQL's \"having\" clause. HavingSpec objects are *not* thread-safe and must not be used simultaneously by multiple threads."}
{"index": 3647, "repo": "druid-processing-26.0.0", "code": "Class HeapMemoryAllocator {\n\t// Allocates a block of memory of capacity .\n\tOptional<ResourceHolder<org.apache.datasketches.memory.WritableMemory>> allocate(long size);\n\t// Returns the number of bytes available for allocations.\n\tlong available();\n\t// Returns the number of bytes managed by this allocator.\n\tlong capacity();\n\t// Create an allocator that is \"unlimited\", which, of course, means it is limited only by available JVM heap.\n\tstatic HeapMemoryAllocator unlimited();\n}", "des": "Allocator that uses ByteBuffer.allocate(int) to create chunks in the JVM heap."}
{"index": 3648, "repo": "druid-processing-26.0.0", "code": "Class IdMapping {\n\t// Get the substitute index, given the original\n\tint getForwardedId(int id);\n\t// Get the original index, given the substitute\n\tint getReverseId(int id);\n\t// Get the number of values stored in forwardMapping\n\tint getValueCardinality();\n}", "des": "Map some set of dictionary id to a smaller set of dictionaryIds (or... the same if you are wasteful), providing a translation layer between them"}
{"index": 3649, "repo": "druid-processing-26.0.0", "code": "Interface ImmutableBitmap {\n\tdefault org.roaringbitmap.BatchIterator batchIterator();\n\t// Returns true if the bit at position value is set\n\tboolean get(int value);\n\t// Compute the bitwise-and of this bitmap with another bitmap.\n\tImmutableBitmap intersection(ImmutableBitmap otherBitmap);\n\tboolean isEmpty();\n\torg.roaringbitmap.IntIterator iterator();\n\tdefault org.roaringbitmap.PeekableIntIterator peekableIterator();\n\tint size();\n\tbyte[] toBytes();\n}", "des": "This class is meant to represent a simple wrapper around an immutable bitmap class."}
{"index": 3650, "repo": "druid-processing-26.0.0", "code": "Class IncrementalIndexRowHolder {\n\tIncrementalIndexRow get();\n\tlong getLong();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n\tvoid set(IncrementalIndexRow currEntry);\n}", "des": "IncrementalIndexRowHolder is a simple get()/set(org.apache.druid.segment.incremental.IncrementalIndexRow) holder of IncrementalIndexRow. It is used to implement various machinery around IncrementalIndex, e. g. IncrementalIndexColumnSelectorFactory, IncrementalIndexRowIterator, etc. By implementing LongColumnSelector, IncrementalIndexRowHolder plays the role of timestamp column selector, to avoid unneeded level of indirection when timestamp column is selected in IncrementalIndexColumnSelectorFactory.makeColumnValueSelector(String)."}
{"index": 3651, "repo": "druid-processing-26.0.0", "code": "Interface IndexedTable.Index {\n\t// Returns whether keys are unique in this index.\n\tboolean areKeysUnique();\n\t// Returns the list of row numbers corresponding to \"key\" in this index.\n\tit.unimi.dsi.fastutil.ints.IntSortedSet find(Object key);\n\t// Returns the row number corresponding to \"key\" in this index, or NOT_FOUND if the key does not exist in the index.\n\tint findUniqueLong(long key);\n\t// Returns the natural key type for the index.\n\tColumnType keyType();\n}", "des": "Indexes support fast lookups on key columns."}
{"index": 3652, "repo": "druid-processing-26.0.0", "code": "Class InlineJoinableFactory {\n\t// Create a Joinable object.\n\tOptional<Joinable> build(DataSource dataSource, JoinConditionAnalysis condition);\n\t// Returns true if a Joinable **may** be created for a given DataSource, but is not a guarantee that JoinableFactory.build(org.apache.druid.query.DataSource, org.apache.druid.segment.join.JoinConditionAnalysis) will return a non-empty result.\n\tboolean isDirectlyJoinable(DataSource dataSource);\n}", "des": "A JoinableFactory for InlineDataSource. It works by building an IndexedTable. It is not valid to pass any other DataSource type to the \"build\" method."}
{"index": 3653, "repo": "druid-processing-26.0.0", "code": "Class InputBindings.BestEffortInputBindings {\n\t// Get value binding for string identifier of IdentifierExpr\n\tObject get(String name);\n\t// Get the ExpressionType from the backing store for a given identifier (this is likely a column, but could be other things depending on the backing adapter)\n\tExpressionType getType(String name);\n}", "des": "Expr.ObjectBinding backed by a cache populated by ExprEval.bestEffortOf(Object) for when the input type information is totally unknown, for a single row worth of values. The values are cached so that asking for a type and getting the value of some input do not repeat computations. This type is not thread-safe, and not suitable for re-use for processing multiple-rows due to the presence of the result cache."}
{"index": 3654, "repo": "druid-processing-26.0.0", "code": "Interface InputEntity {\n\t// Fetches the input entity into the local storage.\n\tdefault InputEntity.CleanableFile fetch(File temporaryDirectory, byte[] fetchBuffer);\n\t// Returns a retry condition that the caller should retry on.\n\tdefault com.google.common.base.Predicate<Throwable> getRetryCondition();\n\t// Returns an URI to identify the input entity.\n\tURI getUri();\n\t// Opens an InputStream on the input entity directly.\n\tInputStream open();\n}", "des": "InputEntity abstracts an input entity and knows how to read bytes from the given entity. Since the implementations of this interface assume that the given entity is not empty, the InputSources should not create InputEntities for empty entities."}
{"index": 3655, "repo": "druid-processing-26.0.0", "code": "Interface InputSource {\n\t// The types of input sources uses.\n\tdefault Set<String> getTypes();\n\t// Returns true if this inputSource can be processed in parallel using ParallelIndexSupervisorTask.\n\tboolean isSplittable();\n\t// Returns true if this inputSource supports different InputFormats.\n\tboolean needsFormat();\n\t// Creates an InputSourceReader.\n\tInputSourceReader reader(InputRowSchema inputRowSchema, InputFormat inputFormat, File temporaryDirectory);\n}", "des": "InputSource abstracts the storage system where input data is stored. It creates an InputSourceReader to read data from the given input source. The most common use case would be:"}
{"index": 3656, "repo": "druid-processing-26.0.0", "code": "Class IntermediateColumnarLongsSerializer {\n\tvoid add(long value);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\tint size();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Serializer that chooses optimal ColumnarLongs format dymamically, based on the values being written. Unsafe for concurrent use from multiple threads."}
{"index": 3657, "repo": "druid-processing-26.0.0", "code": "Interface IntSet.IntIterator {\n\t// Clone the iterator\n\tIntSet.IntIterator clone();\n\tboolean hasNext();\n\tint next();\n\t// Skips all the elements before the specified element, so that next() gives the given element or, if it does not exist, the element immediately after according to the sorting provided by this set.\n\tvoid skipAllBefore(int element);\n}", "des": "An Iterator-like interface that allows to \"skip\" some elements of the set"}
{"index": 3658, "repo": "druid-processing-26.0.0", "code": "Class JoinPrefixUtils {\n\t// Check if any prefixes in the provided list duplicate or shadow each other.\n\tstatic void checkPrefixesForDuplicatesAndShadowing(List<String> prefixes);\n\tstatic boolean isPrefixedBy(String columnName, String prefix);\n\t// Removes the prefix on columnName.\n\tstatic String unprefix(String columnName, String prefix);\n\t// Checks that \"prefix\" is a valid prefix for a join clause (see JoinableClause.getPrefix()) and, if so, returns it.\n\tstatic String validatePrefix(String prefix);\n}", "des": "Utility class for working with prefixes in join operations"}
{"index": 3659, "repo": "druid-processing-26.0.0", "code": "Class JsonIterator<T> {\n\tvoid close();\n\t// Returns true if there are more objects to be read.\n\tboolean hasNext();\n\t// Retrieves the next deserialized object from the stream of JSON objects.\n\tT next();\n}", "des": "An iterator over an array of JSON objects. Uses ObjectCodec to deserialize regular Java objects."}
{"index": 3660, "repo": "druid-processing-26.0.0", "code": "Class JsonLineReader {\n\t// Returns the number of header lines to skip.\n\tint getNumHeaderLinesToSkip();\n\t// Returns true if the file format needs to process a header line.\n\tboolean needsToProcessHeaderLine();\n\t// Parses the given line into a list of InputRows.\n\tList<InputRow> parseInputRows(String line);\n\t// Processes a header line.\n\tvoid processHeaderLine(String line);\n\t// Converts the given intermediate row into a Map.\n\tList<Map<String,Object>> toMap(String intermediateRow);\n}", "des": "JsonLineReader reads input text line by line and tries to convert each text line to an JSON object. Since each text line is processed indepdently, if any exception is thrown when parsing one text line, exception can be caught by callers to skip current line and continue to process next text line. This also means that each text line should be a well-formed JSON text, pretty-printed format is not allowed"}
{"index": 3661, "repo": "druid-processing-26.0.0", "code": "Class JSONPathParser {\n\t// Returns the fieldNames that we expect to see in parsed Maps, if known, or null otherwise.\n\tList<String> getFieldNames();\n\t// Parse a String into a Map.\n\tMap<String,Object> parseToMap(String input);\n\t// Set the fieldNames that you expect to see in parsed Maps.\n\tvoid setFieldNames(Iterable<String> fieldNames);\n}", "des": "JSON parser class that uses the JsonPath library to access fields via path expressions."}
{"index": 3662, "repo": "druid-processing-26.0.0", "code": "Class JsonReader {\n\t// Creates an iterator of intermediate rows.\n\tprotected CloseableIterator<String> intermediateRowIterator();\n\t// Parses the given intermediate row into a list of InputRows.\n\tprotected List<InputRow> parseInputRows(String intermediateRow);\n\tprotected InputEntity source();\n\t// Converts the given intermediate row into a Map.\n\tprotected List<Map<String,Object>> toMap(String intermediateRow);\n}", "des": "In contrast to JsonLineReader which processes input text line by line independently, this class tries to parse the input text as a whole to an array of objects. The input text can be: 1. a JSON string of an object in a line or multiple lines(such as pretty-printed JSON text) 2. multiple JSON object strings concated by white space character(s) For case 2, what should be noticed is that if an exception is thrown when parsing one JSON string, the rest JSON text will all be ignored For more information, see: https://github.com/apache/druid/pull/10383"}
{"index": 3663, "repo": "druid-processing-26.0.0", "code": "Enum KeyOrder {\n\tboolean sortable();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic KeyOrder valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic KeyOrder[] values();\n}", "des": "Ordering associated with a KeyColumn."}
{"index": 3664, "repo": "druid-processing-26.0.0", "code": "Class LessThanHavingSpec {\n\t// This method treats internal value as double mainly for ease of test.\n\tboolean equals(Object o);\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\tString getAggregationName();\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\tNumber getValue();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "The \"<\" operator in a \"having\" clause. This is similar to SQL's \"having aggregation < value\", except that an aggregation in SQL is an expression instead of an aggregation name as in Druid."}
{"index": 3665, "repo": "druid-processing-26.0.0", "code": "Class LongCardinalityAggregatorColumnSelectorStrategy {\n\tstatic void addLongToCollector(HyperLogLogCollector collector, long n);\n\t// Retrieve the current row from dimSelector and add the row values to the hasher.\n\tvoid hashRow(BaseLongColumnValueSelector selector, com.google.common.hash.Hasher hasher);\n\t// Retrieve the current row from dimSelector and add the row values to HyperLogLogCollector.\n\tvoid hashValues(BaseLongColumnValueSelector selector, HyperLogLogCollector collector);\n}", "des": "If performance of this class appears to be a bottleneck for somebody, one simple way to improve it is to split it into two different classes, one that is used when NullHandling.replaceWithDefault() is false, and one - when it's true, moving this computation out of the tight loop"}
{"index": 3666, "repo": "druid-processing-26.0.0", "code": "Class LongFieldWriter {\n\t// Releases resources held by this writer.\n\tvoid close();\n\t// Reverse the transform(long) function.\n\tstatic long detransform(long bits);\n\t// Transforms a long into a form where it can be compared as unsigned bytes without decoding.\n\tstatic long transform(long n);\n\t// Writes the current selection at the given memory position.\n\tlong writeTo(org.apache.datasketches.memory.WritableMemory memory, long position, long maxSize);\n}", "des": "Wraps a BaseLongColumnValueSelector and writes individual values into rframe rows. See LongFieldReader for format details."}
{"index": 3667, "repo": "druid-processing-26.0.0", "code": "Class LongLastVectorAggregator {\n\t// Same as BufferAggregator.get(java.nio.ByteBuffer, int).\n\tObject get(ByteBuffer buf, int position);\n\t// Abstract function which needs to be overridden by subclasses to set the initial value\n\tvoid initValue(ByteBuffer buf, int position);\n}", "des": "Vectorized version of on heap 'last' aggregator for column selectors with type LONG.."}
{"index": 3668, "repo": "druid-processing-26.0.0", "code": "Interface LookupExtractorFactory {\n\t// This method will be called to stop the LookupExtractor upon Druid process stop.\n\tboolean close();\n\t// This method will be called to drop the LookupExtractor upon explicit user request to coordinator to drop this lookup.\n\tdefault boolean destroy();\n\tLookupIntrospectHandler getIntrospectHandler();\n\t// This method will be called to start the LookupExtractor upon registered Calling start multiple times should return true if successfully started.\n\tboolean start();\n}", "des": "Users of Lookup Extraction need to implement a LookupExtractorFactory supplier of type LookupExtractor. Such factory will manage the state and life cycle of an given lookup. If a LookupExtractorFactory wishes to support idempotent updates, it needs to implement the `replaces` method"}
{"index": 3669, "repo": "druid-processing-26.0.0", "code": "Interface LookupExtractorFactoryContainerProvider {\n\t// Returns a lookup container for the provided lookupName, if it exists.\n\tOptional<LookupExtractorFactoryContainer> get(String lookupName);\n\t// Returns the set of all lookup names that get(java.lang.String) can return containers for.\n\tSet<String> getAllLookupNames();\n}", "des": "Provides LookupExtractorFactoryContainer to query and indexing time dimension transformations. The most important production implementation is LookupReferencesManager."}
{"index": 3670, "repo": "druid-processing-26.0.0", "code": "Class MapIndex {\n\t// Returns whether keys are unique in this index.\n\tboolean areKeysUnique();\n\t// Returns the list of row numbers corresponding to \"key\" in this index.\n\tit.unimi.dsi.fastutil.ints.IntSortedSet find(Object key);\n\t// Returns the row number corresponding to \"key\" in this index, or IndexedTable.Index.NOT_FOUND if the key does not exist in the index.\n\tint findUniqueLong(long key);\n\t// Returns the natural key type for the index.\n\tColumnType keyType();\n}", "des": "An IndexedTable.Index backed by a Map."}
{"index": 3671, "repo": "druid-processing-26.0.0", "code": "Class MappedByteBufferHandler {\n\t// Unmaps the wrapped buffer.\n\tvoid close();\n\t// Returns the wrapped buffer.\n\tMappedByteBuffer get();\n}", "des": "Facilitates using try-with-resources with MappedByteBuffer."}
{"index": 3672, "repo": "druid-processing-26.0.0", "code": "Interface MemoryAllocator {\n\t// Allocates a block of memory of capacity .\n\tOptional<ResourceHolder<org.apache.datasketches.memory.WritableMemory>> allocate(long size);\n\t// Returns the number of bytes available for allocations.\n\tlong available();\n\t// Returns the number of bytes managed by this allocator.\n\tlong capacity();\n}", "des": "Allocator of WritableMemory. Not thread safe."}
{"index": 3673, "repo": "druid-processing-26.0.0", "code": "Interface MemoryAllocatorFactory {\n\t// Capacity of allocators returned by newAllocator().\n\tlong allocatorCapacity();\n\t// Returns a new allocator with capacity allocatorCapacity().\n\tMemoryAllocator newAllocator();\n}", "des": "Factory for MemoryAllocator. Used by FrameWriters.makeFrameWriterFactory(org.apache.druid.frame.FrameType, org.apache.druid.frame.allocation.MemoryAllocatorFactory, org.apache.druid.segment.column.RowSignature, java.util.List) to create FrameWriterFactory."}
{"index": 3674, "repo": "druid-processing-26.0.0", "code": "Interface MutableBitmap {\n\t// Add the specified integer to the bitmap.\n\tvoid add(int entry);\n\t// Empties the content of this bitmap.\n\tvoid clear();\n\t// Return the size in bytes for the purpose of serialization to a ByteBuffer.\n\tint getSizeInBytes();\n\t// Compute the bitwise-or of this bitmap with another bitmap.\n\tvoid or(MutableBitmap mutableBitmap);\n\t// Remove the specified integer to the bitmap.\n\tvoid remove(int entry);\n}", "des": "This class is meant to represent a simple wrapper around a bitmap class."}
{"index": 3675, "repo": "druid-processing-26.0.0", "code": "Class NativeIO {\n\t// Copy from an input stream to a file minimizing cache impact on the destination..\n\tstatic void chunkedCopy(InputStream src, File dest);\n\t// Get system file descriptor (int) from FileDescriptor object.\n\tstatic int getfd(FileDescriptor descriptor);\n\t// Remove pages from the file system page cache when they wont be accessed again\n\tstatic void trySkipCache(int fd, long offset, long len);\n}", "des": "Native I/O operations in order to minimize cache impact."}
{"index": 3676, "repo": "druid-processing-26.0.0", "code": "Class NestedFieldVirtualColumn.RawFieldColumnSelector {\n\tClass<?> classOfObject();\n\tdouble getDouble();\n\tfloat getFloat();\n\tlong getLong();\n\tObject getObject();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n}", "des": "Process the \"raw\" data to extract values with NestedPathFinder.find(Object, List), wrapping the result in StructuredData"}
{"index": 3677, "repo": "druid-processing-26.0.0", "code": "Class NestedFieldVirtualColumn.RawFieldLiteralColumnValueSelector {\n\tClass<?> classOfObject();\n\tdouble getDouble();\n\tfloat getFloat();\n\tlong getLong();\n\tObject getObject();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n}", "des": "Process the \"raw\" data to extract literals with NestedPathFinder.findLiteral(Object, List). Like NestedFieldVirtualColumn.RawFieldColumnSelector but only literals and does not wrap the results in StructuredData."}
{"index": 3678, "repo": "druid-processing-26.0.0", "code": "Class NestedFieldVirtualColumn.RawFieldVectorObjectSelector {\n\t// Returns the current vector size for this cursor.\n\tint getCurrentVectorSize();\n\t// Returns the maximum vector size for this cursor.\n\tint getMaxVectorSize();\n\t// Get the current vector.\n\tObject[] getObjectVector();\n}", "des": "Process the \"raw\" data to extract vectors of values with NestedPathFinder.find(Object, List), wrapping the result in StructuredData"}
{"index": 3679, "repo": "druid-processing-26.0.0", "code": "Class NeverHavingSpec {\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "A \"having\" spec that always evaluates to false"}
{"index": 3680, "repo": "druid-processing-26.0.0", "code": "Class NoErrorResponseTransformStrategy {\n\tboolean equals(Object o);\n\t// Return a function for checking and transforming the error message if needed.\n\tFunction<String,String> getErrorMessageTransformFunction();\n\t// For a given SanitizableException apply the transformation strategy and return the sanitized Exception if the transformation stategy was applied.\n\tException transformIfNeeded(SanitizableException exception);\n}", "des": "Error response transform strategy that does nothing and simply return the same Exception back without any change"}
{"index": 3681, "repo": "druid-processing-26.0.0", "code": "Class NotHavingSpec {\n\tboolean equals(Object o);\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\tHavingSpec getHavingSpec();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "The logical \"not\" operator for the \"having\" clause."}
{"index": 3682, "repo": "druid-processing-26.0.0", "code": "Class Offset {\n\tOffset clone();\n\t// Returns the same offset (\"this\") or a readable \"view\" of this offset, which always returns the same value from ReadableOffset.getOffset(), as this offset.\n\tabstract ReadableOffset getBaseReadableOffset();\n\tabstract void increment();\n\t// Resets the Offset to the position it was created or cloned with.\n\tabstract void reset();\n\tabstract boolean withinBounds();\n}", "des": "The \"mutable\" version of a ReadableOffset. Introduces \"increment()\" and \"withinBounds()\" methods, which are very similar to \"next()\" and \"hasNext()\" on the Iterator interface except increment() does not return a value. This class is not thread-safe, all it's methods, including reset() and clone(), must be called from a single thread. Annotated with SubclassesMustBePublic because Offset occurrences are replaced with a subclass in Historical1SimpleDoubleAggPooledTopNScannerPrototype and HistoricalSingleValueDimSelector1SimpleDoubleAggPooledTopNScannerPrototype during specialization, and specialized version of those prototypes must be able to any subclass of Offset. This interface is the core \"pointer\" interface that is used to create ColumnValueSelectors over historical segments. It's counterpart for incremental index is IncrementalIndexRowHolder."}
{"index": 3683, "repo": "druid-processing-26.0.0", "code": "Interface Operator {\n\t// Convenience method to run an Operator until completion.\n\tstatic void go(Operator op, Operator.Receiver receiver);\n\t// This is the primary workhorse method of an Operator.\n\tCloseable goOrContinue(Closeable continuationObject, Operator.Receiver receiver);\n}", "des": "An Operator interface that intends to have implementations that align relatively closely with the Operators that other databases would also tend to be implemented using. While a lot of Operator interfaces tend to use a pull-based orientation, we use a push-based interface. This is to give us good stacktraces. Because of the organization of the go() method, the stack traces thrown out of an Operator will be 1. All of the go() calls from the top-level Operator down to the leaf Operator, this part of the stacktrace gives visibility into what all of the actions that we expect to happen from the operator chain are 2. All of the push() calls up until the exception happens, this part of the stack trace gives us a view of all of the things that have happened to the data up until the exception was thrown."}
{"index": 3684, "repo": "druid-processing-26.0.0", "code": "Enum Operator.Signal {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Operator.Signal valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Operator.Signal[] values();\n}", "des": "This is the return object from a receiver. It is used to communicate to whatever is pushing the data into the receiver the state of processing. This exists because Operators can sometimes decide that no more results will be needed (e.g. if the result set is being limited), in which case, they need some way to communicate this to downstream processing to effectively \"cancel\" further computation."}
{"index": 3685, "repo": "druid-processing-26.0.0", "code": "Interface OperatorFactory {\n\t// Validates the equivalence of Operators.\n\tboolean validateEquivalent(OperatorFactory other);\n\t// Builds an operator according to the definition of the OperatorFactory and wraps it around the operator passed in to this function.\n\tOperator wrap(Operator op);\n}", "des": "A factory for Operators. This class exists to encapsulate the user-definition of an Operator. I.e. which operator, what fields it should operate on, etc. etc. These Factory objects are then used to combine Operators together and run against concrete data."}
{"index": 3686, "repo": "druid-processing-26.0.0", "code": "Class OperatorSequence {\n\t// Accumulate this sequence using the given accumulator.\n\t<OutType> OutType accumulate(OutType initValue, Accumulator<OutType,RowsAndColumns> accumulator);\n\t// Return a Yielder for accumulated sequence.\n\t<OutType> Yielder<OutType> toYielder(OutType initValue, YieldingAccumulator<OutType,RowsAndColumns> accumulator);\n}", "des": "Provides a sequence on top of Operators."}
{"index": 3687, "repo": "druid-processing-26.0.0", "code": "Class OrHavingSpec {\n\tboolean equals(Object o);\n\t// Evaluates if a given row satisfies the having spec.\n\tboolean eval(ResultRow row);\n\t// Get a byte array used as a cache key.\n\tbyte[] getCacheKey();\n\tList<HavingSpec> getHavingSpecs();\n\t// Informs this HavingSpec that rows passed to \"eval\" will originate from a particular groupBy query.\n\tvoid setQuery(GroupByQuery query);\n}", "des": "The logical \"or\" operator for the \"having\" clause."}
{"index": 3688, "repo": "druid-processing-26.0.0", "code": "Interface OutputChannelFactory {\n\t// Create a channel pair tagged with a particular partition number.\n\tOutputChannel openChannel(int partitionNumber);\n\t// Create a non-writable, always-empty channel pair tagged with a particular partition number.\n\tOutputChannel openNilChannel(int partitionNumber);\n\t// Create a channel pair tagged with a particular name and a flag to delete the channel data after its read.\n\tPartitionedOutputChannel openPartitionedChannel(String name, boolean deleteAfterRead);\n}", "des": "Factory for generating channel pairs for output data from processors."}
{"index": 3689, "repo": "druid-processing-26.0.0", "code": "Interface OverwriteShardSpec {\n\t// The core partition concept is not used with segment locking.\n\tdefault int getNumCorePartitions();\n\t// Returns true if this shardSpec and the given PartialShardSpec share the same partition space.\n\tdefault boolean sharePartitionSpace(PartialShardSpec partialShardSpec);\n\tdefault OverwriteShardSpec withAtomicUpdateGroupSize(int atomicUpdateGroupSize);\n\tOverwriteShardSpec withAtomicUpdateGroupSize(short atomicUpdateGroupSize);\n}", "des": "ShardSpec for non-first-generation segments. This shardSpec is allocated a partitionId between PartitionIds.NON_ROOT_GEN_START_PARTITION_ID and PartitionIds.NON_ROOT_GEN_END_PARTITION_ID."}
{"index": 3690, "repo": "druid-processing-26.0.0", "code": "Interface Parser<K,V> {\n\t// Parse a String into a Map.\n\tMap<K,V> parseToMap(String input);\n\t// This method may or may not get called at the start of reading of every file depending on the type of IndexTasks.\n\tdefault void startFileFromBeginning();\n}", "des": "Class that can parse Strings into Maps. Not thread-safe."}
{"index": 3691, "repo": "druid-processing-26.0.0", "code": "Interface PartialShardSpec {\n\t// Creates a new ShardSpec with given partitionId and numCorePartitions.\n\tShardSpec complete(com.fasterxml.jackson.databind.ObjectMapper objectMapper, int partitionId, int numCorePartitions);\n\t// Returns the class of the shardSpec created by this factory.\n\tClass<? extends ShardSpec> getShardSpecClass();\n\t// Returns true if this partialShardSpec needs a partitionId of a non-root generation.\n\tdefault boolean useNonRootGenerationPartitionSpace();\n}", "des": "This interface is used in the segment allocation protocol when it is coordinated by the Overlord; when appending segments to an existing datasource (either streaming ingestion or batch append) or any case when segment lock is used. The implementations of this interface contain all information of the corresponding ShardSpec except the partition ID. The ingestion tasks send all information required for allocating a new segment using this interface and the Overlord determines the partition ID to create a new segment."}
{"index": 3692, "repo": "druid-processing-26.0.0", "code": "Interface PartitionChunk<T> {\n\t// Determines if this PartitionChunk abuts another PartitionChunk.\n\tboolean abuts(PartitionChunk<T> chunk);\n\t// Returns the partition chunk number of this PartitionChunk.\n\tint getChunkNumber();\n\t// Returns the payload, generally an object that can be used to perform some action against the shard.\n\tT getObject();\n\t// Returns true if this chunk is the end of the partition.\n\tboolean isEnd();\n\t// Returns true if this chunk is the beginning of the partition.\n\tboolean isStart();\n}", "des": "A PartitionChunk represents a chunk of a partitioned(sharded) space. It has knowledge of whether it is the start of the domain of partitions, the end of the domain, if it abuts another partition and where it stands inside of a sorted collection of partitions. The ordering of PartitionChunks is based entirely upon the partition boundaries defined inside the concrete PartitionChunk class. That is, the payload (the object returned by getObject()) should *not* be involved in comparisons between PartitionChunk objects."}
{"index": 3693, "repo": "druid-processing-26.0.0", "code": "Interface PartitionedReadableFrameChannel {\n\t// Releases any resources associated with this readable channel.\n\tvoid close();\n\t// Allows reading a particular partition in the channel\n\tReadableFrameChannel getReadableFrameChannel(int partitionNumber);\n}", "des": "Provides an interface to read a partitioned frame channel. The channel might have frames with multiple partitions in it."}
{"index": 3694, "repo": "druid-processing-26.0.0", "code": "Enum Partitions {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Partitions valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Partitions[] values();\n}", "des": "This enum is used a parameter for several methods in VersionedIntervalTimeline, specifying whether only complete partitions should be considered, or incomplete partitions as well."}
{"index": 3695, "repo": "druid-processing-26.0.0", "code": "Class PossiblyNullColumnValueSelector<T> {\n\tClass<? extends T> classOfObject();\n\tdouble getDouble();\n\tfloat getFloat();\n\tlong getLong();\n\tT getObject();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n}", "des": "A ColumnValueSelector that wraps a base selector but might also generate null values on demand. This is used for \"righty\" joins (see JoinType.isRighty()), which may need to generate nulls on the left-hand side."}
{"index": 3696, "repo": "druid-processing-26.0.0", "code": "Interface Processor {\n\t// Applies the logic of the processor to a RowsAndColumns object\n\tRowsAndColumns process(RowsAndColumns incomingPartition);\n\t// Validates the equivalence of the Processors.\n\tboolean validateEquivalent(Processor otherProcessor);\n}", "des": "A Processor is a bit of logic that processes a single RowsAndColumns object to produce a new RowsAndColumns object. Generally speaking, it is used to add or alter columns in a batch-oriented fashion."}
{"index": 3697, "repo": "druid-processing-26.0.0", "code": "Class ProcFsReader {\n\t// Reads the boot ID from the boot_id path, which is just a UUID.\n\tUUID getBootId();\n\t// Reads the cpuinfo path (example in src/test/resources/cpuinfo) and counts the number of processors.\n\tlong getProcessorCount();\n}", "des": "Fetches data from top-level procfs files for metrics."}
{"index": 3698, "repo": "druid-processing-26.0.0", "code": "Interface QuerySegmentWalker {\n\t// Gets the Queryable for a given interval, the Queryable returned can be any version(s) or partitionNumber(s) such that it represents the interval.\n\t<T> QueryRunner<T> getQueryRunnerForIntervals(Query<T> query, Iterable<org.joda.time.Interval> intervals);\n\t// Gets the Queryable for a given list of SegmentDescriptors.\n\t<T> QueryRunner<T> getQueryRunnerForSegments(Query<T> query, Iterable<SegmentDescriptor> specs);\n}", "des": "An interface for query-handling entry points."}
{"index": 3699, "repo": "druid-processing-26.0.0", "code": "Interface ReadableVectorOffset {\n\t// If \"isContiguous\" is false, this method returns a batch of offsets.\n\tint[] getOffsets();\n\t// If \"isContiguous\" is true, this method returns the start offset of the range.\n\tint getStartOffset();\n\t// Checks if the current batch is a contiguous range or not.\n\tboolean isContiguous();\n}", "des": "Provides a batch of offsets, ostensibly as indexes into an array. A ReadableVectorOffset should be given to classes (e.g. column selector objects) by something which keeps a reference to the base VectorOffset object and increments it."}
{"index": 3700, "repo": "druid-processing-26.0.0", "code": "Class RearrangedRowsAndColumns {\n\t// Asks the RowsAndColumns to return itself as a concrete implementation of a specific interface.\n\t<T> T as(Class<T> clazz);\n\t// Finds a column by name.\n\tColumn findColumn(String name);\n\t// The set of column names available from the RowsAndColumns\n\tCollection<String> getColumnNames();\n\t// The number of rows in the RowsAndColumns object\n\tint numRows();\n}", "des": "This class exists to \"decorate\" a rows and columns such that it pretends to exist in a new ordering."}
{"index": 3701, "repo": "druid-processing-26.0.0", "code": "Class ResponseContext.AbstractKey {\n\t// Returns true if this key can be removed to reduce header size when the header would otherwise be too large.\n\tboolean canDrop();\n\tString getName();\n\t// Whether to return the key, value pair in the response header.\n\tboolean includeInHeader();\n\t// Reads a value of this key from a JSON stream.\n\tObject readValue(com.fasterxml.jackson.core.JsonParser jp);\n}", "des": "Abstract key class which provides most functionality except the type-specific merge logic. Parsing is provided by an associated parse function."}
{"index": 3702, "repo": "druid-processing-26.0.0", "code": "Interface ResponseContext.Key {\n\t// Returns true if this key can be removed to reduce header size when the header would otherwise be too large.\n\tboolean canDrop();\n\tString getName();\n\t// Whether to return the key, value pair in the response header.\n\tboolean includeInHeader();\n\t// Merges two values of type T.\n\tObject mergeValues(Object oldValue, Object newValue);\n\t// Reads a value of this key from a JSON stream.\n\tObject readValue(com.fasterxml.jackson.core.JsonParser jp);\n}", "des": "The base interface of a response context key. Should be implemented by every context key."}
{"index": 3703, "repo": "druid-processing-26.0.0", "code": "Interface RowAdapter<RowType> {\n\t// Returns a function that retrieves the value for column \"columnName\" from rows.\n\tFunction<RowType,Object> columnFunction(String columnName);\n\t// Returns a function that retrieves timestamps from rows.\n\tdefault ToLongFunction<RowType> timestampFunction();\n}", "des": "An adapter between arbitrary types and the needs of callers that want to read specific columns out of those types (treating them as rows)."}
{"index": 3704, "repo": "druid-processing-26.0.0", "code": "Class RowBasedIndexBuilder {\n\t// Add a key to the index.\n\tRowBasedIndexBuilder add(Object key);\n\t// Create the index.\n\tIndexedTable.Index build();\n}", "des": "Utility class for creating IndexedTable.Index instances. Its main role is to decide which kind of implementation to use."}
{"index": 3705, "repo": "druid-processing-26.0.0", "code": "Interface RowIterator {\n\t// Returns a pointer to the current row.\n\tRowPointer getPointer();\n\t// Compares the \"memoized\" data point from the last mark() call with the data point, to which getPointer() currently points.\n\tboolean hasTimeAndDimsChangedSinceMark();\n\t// \"Memoizes\" the data point, to which getPointer() currently points.\n\tvoid mark();\n}", "des": "Extension of TimeAndDimsIterator, specialized for RowPointer instead of TimeAndDimsPointer. Also, RowIterator encapsulates tracking of data point changes between TimeAndDimsIterator.moveToNext() calls via mark() and hasTimeAndDimsChangedSinceMark() methods. This functionality is used in RowCombiningTimeAndDimsIterator, and also internally in MergingRowIterator to reduce the number of comparisons that this class makes. This functionality is added directly to RowIterator interface rather than left to be implemented externally to this interface, because it's inefficient to do the latter with \"generic\" RowIterator, because of TimeAndDimsPointer allocation-free design, that reuses objects. On the other hand, some implementations of RowIterator allow to optimize mark() and hasTimeAndDimsChangedSinceMark()."}
{"index": 3706, "repo": "druid-processing-26.0.0", "code": "Class RowKey {\n\t// Get the backing array for this key (not a copy).\n\tbyte[] array();\n\tstatic RowKey empty();\n\tboolean equals(Object o);\n\t// Estimate number of bytes taken by the key array.\n\tint estimatedObjectSizeBytes();\n\tlong longHashCode();\n\t// Create a key from a byte array.\n\tstatic RowKey wrap(byte[] row);\n}", "des": "Represents a specific sorting or hashing key. Instances of this class wrap a byte array in row-based frame format."}
{"index": 3707, "repo": "druid-processing-26.0.0", "code": "Class RowReader {\n\tint fieldCount();\n\tFieldReader fieldReader(int fieldNumber);\n\t// Read a particular field value as an object.\n\tObject readField(org.apache.datasketches.memory.Memory memory, long rowPosition, long rowLength, int fieldNumber);\n\t// Read an entire row as a list of objects.\n\tList<Object> readRow(org.apache.datasketches.memory.Memory memory, long rowPosition, long rowLength);\n}", "des": "Class for reading rows in the same format as used by FrameType.ROW_BASED. Stateless and immutable. Row format: - 4 bytes * rowLength: field *end* pointers (exclusive), relative to the start of the row, little-endian ints - N bytes * rowLength: fields written by FieldWriter implementations."}
{"index": 3708, "repo": "druid-processing-26.0.0", "code": "Interface RowsAndColumns {\n\t// Asks the RowsAndColumns to return itself as a concrete implementation of a specific interface.\n\t<T> T as(Class<T> clazz);\n\tstatic AppendableRowsAndColumns expectAppendable(RowsAndColumns input);\n\t// Finds a column by name.\n\tColumn findColumn(String name);\n\t// The set of column names available from the RowsAndColumns\n\tCollection<String> getColumnNames();\n\t// The number of rows in the RowsAndColumns object\n\tint numRows();\n}", "des": "An interface representing a chunk of RowsAndColumns. Essentially a RowsAndColumns is just a batch of rows with columns."}
{"index": 3709, "repo": "druid-processing-26.0.0", "code": "Enum RunnerTaskState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RunnerTaskState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RunnerTaskState[] values();\n}", "des": "This includes the state of a task in the task runner not covered by TaskState, this state is not stored in database"}
{"index": 3710, "repo": "druid-processing-26.0.0", "code": "Enum SecondaryPartitionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SecondaryPartitionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SecondaryPartitionType[] values();\n}", "des": "In Druid, ingested data are primarily partitioned based on time range (@link GranularitySpec#getSegmentGranularity), and then secondly partitioned based on the given PartitionsSpec. This enum lists all supported types for the secondary partitioning."}
{"index": 3711, "repo": "druid-processing-26.0.0", "code": "Class SegmentUtils {\n\t// Returns an object whose toString() returns a String with identifiers of the given segments, comma-separated.\n\tstatic Object commaSeparatedIdentifiers(Collection<DataSegment> segments);\n\tstatic int getVersionFromDir(File inDir);\n\tstatic Map<org.joda.time.Interval,List<DataSegment>> groupSegmentsByInterval(Collection<DataSegment> segments);\n\t// Hash the IDs of the given segments based on SHA-256 algorithm.\n\tstatic String hashIds(List<DataSegment> segments);\n}", "des": "Utility methods useful for implementing deep storage extensions."}
{"index": 3712, "repo": "druid-processing-26.0.0", "code": "Class SerializablePairLongStringBufferStore.TransferredBuffer {\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "contains serialized data that is compressed and delta-encoded (Long) It's ready to be transferred to a WritableByteChannel"}
{"index": 3713, "repo": "druid-processing-26.0.0", "code": "Interface Serializer {\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Main interface for \"serializeable something\" in Druid segment serialization."}
{"index": 3714, "repo": "druid-processing-26.0.0", "code": "Class SettableObjectBinding {\n\tMap<String,Object> asMap();\n\t// Get value binding for string identifier of IdentifierExpr\n\tObject get(String name);\n\t// Get the ExpressionType from the backing store for a given identifier (this is likely a column, but could be other things depending on the backing adapter)\n\tExpressionType getType(String name);\n\tSettableObjectBinding withBinding(String name, Object value);\n\tSettableObjectBinding withInspector(Expr.InputBindingInspector inspector);\n}", "des": "Simple map backed object binding"}
{"index": 3715, "repo": "druid-processing-26.0.0", "code": "Class SettableValueDoubleColumnValueSelector {\n\tdouble getDouble();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n\tvoid setValue(double value);\n}", "des": "A BaseDoubleColumnValueSelector impl to return settable double value on calls to BaseDoubleColumnValueSelector.getDouble()"}
{"index": 3716, "repo": "druid-processing-26.0.0", "code": "Class SettableValueFloatColumnValueSelector {\n\tfloat getFloat();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n\tvoid setValue(float value);\n}", "des": "A BaseFloatColumnValueSelector impl to return settable float value on calls to BaseFloatColumnValueSelector.getFloat()"}
{"index": 3717, "repo": "druid-processing-26.0.0", "code": "Class SettableValueLongColumnValueSelector {\n\tlong getLong();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n\tvoid setValue(long value);\n}", "des": "A BaseLongColumnValueSelector impl to return settable long value on calls to BaseLongColumnValueSelector.getLong()"}
{"index": 3718, "repo": "druid-processing-26.0.0", "code": "Class SingleLongInputCachingExpressionColumnValueSelector {\n\t// Implementations override this.\n\tprotected ExprEval<?> eval();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n}", "des": "Like ExpressionColumnValueSelector, but caches the most recently computed value and re-uses it in the case of runs in the underlying column. This is especially useful for the __time column, where we expect runs."}
{"index": 3719, "repo": "druid-processing-26.0.0", "code": "Class SingleMemoryAllocatorFactory {\n\t// Capacity of allocators returned by MemoryAllocatorFactory.newAllocator().\n\tlong allocatorCapacity();\n\t// Returns a new allocator with capacity MemoryAllocatorFactory.allocatorCapacity().\n\tMemoryAllocator newAllocator();\n}", "des": "Wraps a single MemoryAllocator. The same instance is returned on each call to newAllocator(), after validating that it is 100% free. Calling newAllocator() before freeing all previously-allocated memory leads to an IllegalStateException."}
{"index": 3720, "repo": "druid-processing-26.0.0", "code": "Class SingleStringInputCachingExpressionColumnValueSelector {\n\t// Implementations override this.\n\tprotected ExprEval<?> eval();\n\t// Implementations of this method should call inspector.visit() with all fields of this class, which meet two conditions: 1.\n\tvoid inspectRuntimeShape(RuntimeShapeInspector inspector);\n\t// Returns true if the primitive long, double, or float value returned by this selector should be treated as null.\n\tboolean isNull();\n}", "des": "Like ExpressionColumnValueSelector, but caches results for the first CACHE_SIZE dictionary IDs of a string column. Must only be used on selectors with dictionaries."}
{"index": 3721, "repo": "druid-processing-26.0.0", "code": "Class StableLimitingSorter<T> {\n\t// Offer an element to the sorter.\n\tvoid add(T element);\n\t// Drain elements in sorted order (least first).\n\tIterator<T> drain();\n\t// Returns the number of elements currently in the sorter.\n\tint size();\n}", "des": "Simultaneously sorts and limits its input. The sort is stable, meaning that equal elements (as determined by the comparator) will not be reordered. Not thread-safe. Note: this class doesn't have its own unit tests. It is tested along with TopNSequence in \"TopNSequenceTest\"."}
{"index": 3722, "repo": "druid-processing-26.0.0", "code": "Interface StagedSerde<T> {\n\tdefault T deserialize(byte[] bytes);\n\tT deserialize(ByteBuffer byteBuffer);\n\t// Default implementation for when a byte[] is desired.\n\tdefault byte[] serialize(T value);\n\t// Useful method when some computation is necessary to prepare for serialization without actually writing out all the bytes in order to determine the serialized size.\n\tStorableBuffer serializeDelayed(T value);\n}", "des": "StagedSerde is useful when you have objects that have their own internal logic to serialize, but you wish to compose the results of multiple serialized objects into a single ByteBuffer (or wrapped byte[]). Serializers can implement serializeDelayed and return a StorableBuffer. This object allows the serialization to be broken up so that serializers do whatever work is necessary to report how many bytes are needed. The caller can then allocate a large enough byte[], wrap it in a ByteBuffer, and use the StorableBuffer.store() method."}
{"index": 3723, "repo": "druid-processing-26.0.0", "code": "Class StringArrayFieldWriter {\n\t// Releases resources held by this writer.\n\tvoid close();\n\t// Writes the current selection at the given memory position.\n\tlong writeTo(org.apache.datasketches.memory.WritableMemory memory, long position, long maxSize);\n}", "des": "Like StringFieldWriter, but reads arrays from a ColumnValueSelector instead of reading from a DimensionSelector. See StringFieldReader for format details."}
{"index": 3724, "repo": "druid-processing-26.0.0", "code": "Class StringDictionaryEncodedColumn.MultiValueStringVectorObjectSelector {\n\t// Returns the current vector size for this cursor.\n\tint getCurrentVectorSize();\n\t// Returns the maximum vector size for this cursor.\n\tint getMaxVectorSize();\n\t// Get the current vector.\n\tObject[] getObjectVector();\n\tabstract String lookupName(int id);\n}", "des": "Base type for a VectorObjectSelector for a dictionary encoded ColumnType.STRING built around a ColumnarMultiInts. Dictionary not included - BYO dictionary lookup methods."}
{"index": 3725, "repo": "druid-processing-26.0.0", "code": "Class StringDictionaryEncodedColumn.StringVectorObjectSelector {\n\t// Returns the current vector size for this cursor.\n\tint getCurrentVectorSize();\n\t// Returns the maximum vector size for this cursor.\n\tint getMaxVectorSize();\n\t// Get the current vector.\n\tObject[] getObjectVector();\n\tabstract String lookupName(int id);\n}", "des": "Base type for a VectorObjectSelector for a dictionary encoded ColumnType.STRING built around a ColumnarInts. Dictionary not included - BYO dictionary lookup methods."}
{"index": 3726, "repo": "druid-processing-26.0.0", "code": "Class StringDimensionDictionary {\n\t// Whether on-heap size of this dictionary should be computed.\n\tboolean computeOnHeapSize();\n\t// Estimates the size of the dimension value in bytes.\n\tlong estimateSizeOfValue(String value);\n}", "des": "DimensionDictionary for String dimension values."}
{"index": 3727, "repo": "druid-processing-26.0.0", "code": "Class StringFieldWriter {\n\t// Releases resources held by this writer.\n\tvoid close();\n\t// Writes the current selection at the given memory position.\n\tlong writeTo(org.apache.datasketches.memory.WritableMemory memory, long position, long maxSize);\n}", "des": "Wraps a DimensionSelector and writes to rframe rows. See StringFieldReader for format details."}
{"index": 3728, "repo": "druid-processing-26.0.0", "code": "Interface StringValueSetIndex {\n\t// Get an Iterable of ImmutableBitmap corresponding to the specified set of values (if they are contained in the underlying column).\n\tBitmapColumnIndex forSortedValues(SortedSet<String> values);\n\t// Get the ImmutableBitmap corresponding to the supplied value\n\tBitmapColumnIndex forValue(String value);\n}", "des": "Index on individual values, and provides bitmaps for the rows which contain these values"}
{"index": 3729, "repo": "druid-processing-26.0.0", "code": "Class SuperSorter {\n\t// Starts sorting.\n\tcom.google.common.util.concurrent.ListenableFuture<OutputChannels> run();\n\t// Returns a string encapsulating the current state of this object.\n\tString stateString();\n}", "des": "Sorts and partitions a dataset using parallel external merge sort. Input is provided as a set of ReadableFrameChannel and output is provided as OutputChannels. Work is performed on a provided FrameProcessorExecutor. The most central point for SuperSorter logic is the runWorkersIfPossible() method, which determines what needs to be done next based on the current state of the SuperSorter. The logic is: 1) Read input channels into inputBuffer using FrameChannelBatcher, launched via runNextBatcher(), up to a limit of maxChannelsPerProcessor per batcher. 2) Merge and write frames from inputBuffer into FrameFile scratch files using FrameChannelMerger launched via runNextLevelZeroMerger(). 3a) Merge level 0 scratch files into level 1 scratch files using FrameChannelMerger launched from runNextMiddleMerger(), processing up to maxChannelsPerProcessor files per merger. Continue this process through increasing level numbers, with the size of scratch files increasing by a factor of maxChannelsPerProcessor each level. 3b) For the penultimate level, the FrameChannelMerger launched by runNextMiddleMerger() writes partitioned FrameFile scratch files. The penultimate level cannot be written until outputPartitionsFuture resolves, so if it has not resolved yet by this point, the SuperSorter pauses. The SuperSorter resumes and writes the penultimate level's files when the future resolves. 4) Write the final level using FrameChannelMerger launched from runNextUltimateMerger(). Outputs for this level are written to channels provided by outputChannelFactory, rather than scratch files. At all points, higher level processing is preferred over lower-level processing. Writing to final output files is preferred over intermediate, and writing to intermediate files is preferred over reading inputs. These preferences ensure that the amount of data buffered up in memory does not grow too large. Potential future work (things we could optimize if necessary): - Collapse merging to a single level if level zero has one merger, and we want to write one output partition. - Skip batching, and inject directly into level 0, if input channels are already individually fully-sorted. - Combine (for example: aggregate) while merging."}
{"index": 3730, "repo": "druid-processing-26.0.0", "code": "Class SwitchingEmitter {\n\t// Closes all emitters that the SwitchingEmitter uses\n\tvoid close();\n\t// Emit an event.\n\tvoid emit(Event event);\n\t// Triggers this emitter to tell all emitters that this uses to flush.\n\tvoid flush();\n\t// Start the emitter.\n\tvoid start();\n}", "des": "An emitter than that offers the ability to direct an event to multiple emitters based on the event's feed."}
{"index": 3731, "repo": "druid-processing-26.0.0", "code": "Enum TaskLookup.TaskLookupType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TaskLookup.TaskLookupType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TaskLookup.TaskLookupType[] values();\n}", "des": "Task state in the metadata store. Complete tasks are the tasks that have been either succeeded or failed. Active tasks are the tasks that are not complete tasks."}
{"index": 3732, "repo": "druid-processing-26.0.0", "code": "Interface TimeAndDimsIterator {\n\t// Closes any resources, associated with this iterator.\n\tvoid close();\n\t// Returns a pointer to the current data point.\n\tTimeAndDimsPointer getPointer();\n\t// Moves iterator to the next data point.\n\tboolean moveToNext();\n}", "des": "TimeAndDimsIterator (in conjunction with TimeAndDimsPointer) is an Iterator-like abstraction, designed for allocation-free transformation, merging, combining and iteration over a stream of data points. Usage pattern: try (TimeAndDimsIterator iterator = obtainNewTimeAndDimsIteratorFromSomewhere()) { while (iterator.moveToNext()) { TimeAndDimsPointer pointer = iterator.getPointer(); doSomethingWithPointer(pointer); } }"}
{"index": 3733, "repo": "druid-processing-26.0.0", "code": "Interface Transform {\n\t// Returns the field name for this transform.\n\tString getName();\n\t// Returns the names of all columns that this transform is going to read.\n\tSet<String> getRequiredColumns();\n\t// Returns the function for this transform.\n\tRowFunction getRowFunction();\n}", "des": "A row transform that is part of a TransformSpec. Transforms allow adding new fields to input rows. Each one has a \"name\" (the name of the new field) which can be referred to by DimensionSpecs, AggregatorFactories, etc. Each also has a \"row function\", which produces values for this new field based on looking at the entire input row. If a transform has the same name as a field in an input row, then it will shadow the original field. Transforms that shadow fields may still refer to the fields they shadow. This can be used to transform a field \"in-place\". Transforms do have some limitations. They can only refer to fields present in the actual input rows; in particular, they cannot refer to other transforms. And they cannot remove fields, only add them. However, they can shadow a field with another field containing all nulls, which will act similarly to removing the field."}
{"index": 3734, "repo": "druid-processing-26.0.0", "code": "Interface TransformableRowIterator {\n\t// Returns a pointer to the row, that was the current row when RowIterator.mark() was called for the last time.\n\tTimeAndDimsPointer getMarkedPointer();\n\t// Returns a pointer to the current row.\n\tRowPointer getPointer();\n}", "des": "TransformableRowIterator tightens RowIterator.getPointer() contract, that allows to transform iterated rows without allocations on each iterations, and reuse the mechanics of the underlying iterator. See IndexMerger.toMergedIndexRowIterator(org.apache.druid.segment.TransformableRowIterator, int, java.util.List) for an example."}
{"index": 3735, "repo": "druid-processing-26.0.0", "code": "Interface TriConsumer<T,U,V> {\n\t// Performs this operation on the given arguments.\n\tvoid accept(T t, U u, V v);\n\t// Returns a composed TriConsumer that performs, in sequence, this operation followed by the after operation.\n\tdefault TriConsumer<T,U,V> andThen(TriConsumer<? super T,? super U,? super V> after);\n}", "des": "Based on BiConsumer"}
{"index": 3736, "repo": "druid-processing-26.0.0", "code": "Interface TypeDescriptor {\n\t// Value is an array of some other TypeDescriptor\n\tboolean isArray();\n\t// Scalar numeric primitive values.\n\tboolean isNumeric();\n\t// Scalar numeric and string values.\n\tboolean isPrimitive();\n}", "des": "This is a bridge between ValueType and ExprType, so that they can both be used with TypeSignature. This interface assists in classifying the specific enum values that implement this interface into the current type families: 'primitives', 'arrays', and 'complex' types through isPrimitive() and isArray() At some point we should probably consider reworking this into a 'TypeFamily' enum that maps these high level families to specific types. This interface can potentially be removed if the expression processing system is updated to use ColumnType instead of ExpressionType, which would allow ExprType to be removed and this interface merged into ValueType (along with consolidation of several other interfaces, see TypeSignature javadoc for additional details)."}
{"index": 3737, "repo": "druid-processing-26.0.0", "code": "Class UniqueLongArrayIndex {\n\t// Returns whether keys are unique in this index.\n\tboolean areKeysUnique();\n\t// Returns the list of row numbers corresponding to \"key\" in this index.\n\tit.unimi.dsi.fastutil.ints.IntSortedSet find(Object key);\n\t// Returns the row number corresponding to \"key\" in this index, or IndexedTable.Index.NOT_FOUND if the key does not exist in the index.\n\tint findUniqueLong(long key);\n\t// Returns the natural key type for the index.\n\tColumnType keyType();\n}", "des": "An IndexedTable.Index backed by an int array. This is for long-typed keys whose values all fall in a \"reasonable\" range."}
{"index": 3738, "repo": "druid-processing-26.0.0", "code": "Interface URIDataPuller {\n\t// Create a new InputStream based on the URI\n\tInputStream getInputStream(URI uri);\n\t// Returns an abstract \"version\" for the URI.\n\tString getVersion(URI uri);\n\t// Evaluates a Throwable to see if it is recoverable.\n\tcom.google.common.base.Predicate<Throwable> shouldRetryPredicate();\n}", "des": "A URIDataPuller has handlings for URI based data"}
{"index": 3739, "repo": "druid-processing-26.0.0", "code": "Interface VectorCursor {\n\t// Advances the cursor, skipping forward a number of rows equal to the current vector size.\n\tvoid advance();\n\t// Close the cursor and release its resources.\n\tvoid close();\n\t// Returns a vectorized column selector factory.\n\tVectorColumnSelectorFactory getColumnSelectorFactory();\n\t// Returns false if the cursor is readable, true if it has nothing left to read.\n\tboolean isDone();\n\t// Resets the cursor back to its original state.\n\tvoid reset();\n}", "des": "Vectorized cursor used during query execution. VectorCursors are returned by CursorFactory.makeVectorCursor(org.apache.druid.query.filter.Filter, org.joda.time.Interval, org.apache.druid.segment.VirtualColumns, boolean, int, org.apache.druid.query.QueryMetrics<?>) and are created by QueryableIndexCursorSequenceBuilder.buildVectorized(int). Unlike the non-vectorized version, VectorCursor does not have a getTime() method. This is because we are trying to avoid creating needlessly-small vectors when the time granularity is very fine. See VectorCursorGranularizer for a helper that makes it easier for query engines to do their own time granularization. An example of how to use the methods in this class:"}
{"index": 3740, "repo": "druid-processing-26.0.0", "code": "Interface VectorOffset {\n\t// Advances by one batch.\n\tvoid advance();\n\t// Checks if iteration is \"done\", meaning the current batch of offsets is empty, and there are no more coming.\n\tboolean isDone();\n\t// Resets the object back to its original state.\n\tvoid reset();\n}", "des": "The movable version of ReadableVectorOffset."}
{"index": 3741, "repo": "druid-processing-26.0.0", "code": "Interface VectorSizeInspector {\n\t// Returns the current vector size for this cursor.\n\tint getCurrentVectorSize();\n\t// Returns the maximum vector size for this cursor.\n\tint getMaxVectorSize();\n}", "des": "Common interface for vectorized column selectors, matchers, etc, where callers are given the ability to inspect current and maximum vector sizes."}
{"index": 3742, "repo": "druid-processing-26.0.0", "code": "Interface VectorValueSelector {\n\t// Get the current vector, casting to doubles as necessary.\n\tdouble[] getDoubleVector();\n\t// Get the current vector, casting to floats as necessary.\n\tfloat[] getFloatVector();\n\t// Get the current vector, casting to longs as necessary.\n\tlong[] getLongVector();\n\t// Gets a vector of booleans signifying which rows are null and which are not (true for null).\n\tboolean[] getNullVector();\n}", "des": "Vectorized selector for primitive columns."}
{"index": 3743, "repo": "druid-processing-26.0.0", "code": "Class VirtualizedColumnSelectorFactory {\n\t// Returns a RowIdSupplier that allows callers to detect whether the selectors returned by this factory have moved or not.\n\tRowIdSupplier getRowIdSupplier();\n\t// Returns ColumnValueSelector corresponding to the given column name, or NilColumnValueSelector if the column with such name is absent.\n\tColumnValueSelector<?> makeColumnValueSelector(String columnName);\n\tDimensionSelector makeDimensionSelector(DimensionSpec dimensionSpec);\n}", "des": "ColumnSelectorFactory which can create selectors for both virtual and non-virtual columns"}
{"index": 3744, "repo": "druid-processing-26.0.0", "code": "Class VSizeColumnarIntsSerializer {\n\tvoid addValue(int val);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Streams integers out in the binary format described by VSizeColumnarInts"}
{"index": 3745, "repo": "druid-processing-26.0.0", "code": "Class VSizeColumnarMultiIntsSerializer {\n\tvoid addValues(IndexedInts ints);\n\t// Returns the number of bytes, that this Serializer will write to the output _channel_ (not smoosher) on a Serializer.writeTo(java.nio.channels.WritableByteChannel, org.apache.druid.java.util.common.io.smoosh.FileSmoosher) call.\n\tlong getSerializedSize();\n\tvoid open();\n\t// Writes serialized form of this object to the given channel.\n\tvoid writeTo(WritableByteChannel channel, FileSmoosher smoosher);\n}", "des": "Streams arrays of objects out in the binary format described by VSizeColumnarMultiInts."}
{"index": 3746, "repo": "druid-processing-26.0.0", "code": "Class WindowRankProcessor {\n\tboolean isAsPercent();\n\t// Applies the logic of the processor to a RowsAndColumns object\n\tRowsAndColumns process(RowsAndColumns incomingPartition);\n\t// Validates the equivalence of the Processors.\n\tboolean validateEquivalent(Processor otherProcessor);\n}", "des": "This Processor assumes that data has already been sorted for it. It does not re-sort the data and if it is given data that is not in the correct sorted order, its operation is undefined."}
{"index": 3747, "repo": "druid-processing-26.0.0", "code": "Class WrappedImmutableBitSetBitmap {\n\t// Returns true if the bit at position value is set\n\tboolean get(int value);\n\t// Compute the bitwise-and of this bitmap with another bitmap.\n\tImmutableBitmap intersection(ImmutableBitmap otherBitmap);\n\tboolean isEmpty();\n\torg.roaringbitmap.IntIterator iterator();\n\tint size();\n\tbyte[] toBytes();\n\tImmutableBitmap union(ImmutableBitmap otherBitmap);\n}", "des": "WrappedImmutableBitSetBitmap implements ImmutableBitmap for java.util.BitSet"}
{"index": 3748, "repo": "druid-processing-26.0.0", "code": "Interface Yielder<T> {\n\t// Gets the object currently held by this Yielder.\n\tT get();\n\t// Returns true if this is the last Yielder in the chain.\n\tboolean isDone();\n\t// Gets the next Yielder in the chain.\n\tYielder<T> next(T initValue);\n}", "des": "A Yielder is an object that tries to act like the yield() command/continuations in other languages. It's not necessarily good at this job, but it works. I think. Essentially, you can think of a Yielder as a linked list of items where the Yielder gives you access to the current head via get() and it will give you another Yielder representing the next item in the chain via next(). When using a yielder object, a call to yield() on the yielding accumulator will result in a new Yielder being returned whose get() method will return the return value of the accumulator from the call that called yield(). When a call to next() exhausts the underlying data stream without having a yield() call, various implementations of Sequences and Yielders assume that they will receive a Yielder where isDone() is true and get() will return the accumulated value up until that point. Once next is called, there is no guarantee and no requirement that references to old Yielder objects will continue to obey the contract. Yielders are Closeable and *must* be closed in order to prevent resource leaks. Once close() is called, the behavior of the whole chain of Yielders is undefined."}
{"index": 3749, "repo": "hudi-common-0.13.1", "code": "enum ActionType {\n\t// \n\tstatic ActionType valueOf(String name);\n\t// ,  \n\tstatic ActionType[] values();\n}", "des": "The supported action types."}
{"index": 3750, "repo": "hudi-common-0.13.1", "code": "enum ApiMaturityLevel {\n\t// \n\tstatic ApiMaturityLevel valueOf(String name);\n\t// ,  \n\tstatic ApiMaturityLevel[] values();\n}", "des": "Indicates how stable a given API method/class is, so user's can plan and set their expectations accordingly."}
{"index": 3751, "repo": "hudi-common-0.13.1", "code": "enum AvroSchemaCompatibility.SchemaCompatibilityType {\n\t// \n\tstatic AvroSchemaCompatibility.SchemaCompatibilityType valueOf(String name);\n\t// ,  \n\tstatic AvroSchemaCompatibility.SchemaCompatibilityType[] values();\n}", "des": "Identifies the type of a schema compatibility result."}
{"index": 3752, "repo": "hudi-common-0.13.1", "code": "class Base64CodecUtil {\n\t// Decodes data from the input string into using the encoding scheme.\n\tstatic byte[] decode(String encodedString);\n\t// Encodes all bytes from the specified byte array into String using StandardCharsets.UTF_8.\n\tstatic String encode(byte[] data);\n}", "des": "Utils for Base64 encoding and decoding."}
{"index": 3753, "repo": "hudi-common-0.13.1", "code": "class BaseAvroPayload {\n\t// Defines whether this implementation of HoodieRecordPayload could produce HoodieRecord.SENTINEL\n\tboolean canProduceSentinel();\n\tComparable getOrderingVal();\n\t// Defines whether this implementation of HoodieRecordPayload is deleted.\n\tboolean isDeleted(org.apache.avro.Schema schema, Properties props);\n\tprotected boolean isDeleteRecord(org.apache.avro.generic.GenericRecord genericRecord);\n}", "des": "Base class for all AVRO record based payloads, that can be ordered based on a field."}
{"index": 3754, "repo": "hudi-common-0.13.1", "code": "interface BloomFilter {\n\t// Add a key's bytes, representing UTF8-encoded string, to the BloomFilter.\n\tvoid add(byte[] key);\n\t// Add a key represented by a String to the BloomFilter.\n\tvoid add(String key);\n\tBloomFilterTypeCode getBloomFilterTypeCode();\n\t// Tests for key membership.\n\tboolean mightContain(String key);\n\t// Serialize the bloom filter as a string.\n\tString serializeToString();\n}", "des": "A Bloom filter interface."}
{"index": 3755, "repo": "hudi-common-0.13.1", "code": "class BloomFilterFactory {\n\t// Creates a new BloomFilter with the given args.\n\tstatic BloomFilter createBloomFilter(int numEntries, double errorRate, int maxNumberOfEntries, String bloomFilterTypeCode);\n\t// Generate BloomFilter from serialized String.\n\tstatic BloomFilter fromString(String serString, String bloomFilterTypeCode);\n}", "des": "A Factory class to generate different versions of BloomFilter."}
{"index": 3756, "repo": "hudi-common-0.13.1", "code": "enum BloomFilterTypeCode {\n\t// \n\tstatic BloomFilterTypeCode valueOf(String name);\n\t// ,  \n\tstatic BloomFilterTypeCode[] values();\n}", "des": "Bloom filter type codes. Please do not change the order of the entries."}
{"index": 3757, "repo": "hudi-common-0.13.1", "code": "class BooleanWrapper.Builder {\n\tBooleanWrapper build();\n\t// Clears the value of the 'value' field.\n\tBooleanWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tBoolean getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tBooleanWrapper.Builder setValue(boolean value);\n}", "des": "RecordBuilder for BooleanWrapper instances."}
{"index": 3758, "repo": "hudi-common-0.13.1", "code": "class BootstrapIndex.IndexWriter {\n\t// Append bootstrap index entries for next partitions in sorted order.\n\tabstract void appendNextPartition(String partitionPath, List<BootstrapFileMapping> bootstrapFileMappings);\n\t// Writer calls this method before beginning indexing partitions.\n\tabstract void begin();\n\tabstract void close();\n\t// Writer calls this method after appending all partitions to be indexed.\n\tabstract void finish();\n}", "des": "Bootstrap Index Writer Interface."}
{"index": 3759, "repo": "hudi-common-0.13.1", "code": "class BytesWrapper.Builder {\n\tBytesWrapper build();\n\t// Clears the value of the 'value' field.\n\tBytesWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tByteBuffer getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tBytesWrapper.Builder setValue(ByteBuffer value);\n}", "des": "RecordBuilder for BytesWrapper instances."}
{"index": 3760, "repo": "hudi-common-0.13.1", "code": "class CleanMetadataV1MigrationHandler {\n\t// Downgrades metadata of type T from next version to this version.\n\tHoodieCleanMetadata downgradeFrom(HoodieCleanMetadata input);\n\t// Version of Metadata that this class will handle.\n\tInteger getManagedVersion();\n\t// Upgrades metadata of type T from previous version to this version.\n\tHoodieCleanMetadata upgradeFrom(HoodieCleanMetadata input);\n}", "des": "Migration handler for clean metadata in version 1."}
{"index": 3761, "repo": "hudi-common-0.13.1", "code": "class CleanMetadataV2MigrationHandler {\n\t// Downgrades metadata of type T from next version to this version.\n\tHoodieCleanMetadata downgradeFrom(HoodieCleanMetadata input);\n\t// Version of Metadata that this class will handle.\n\tInteger getManagedVersion();\n\t// Upgrades metadata of type T from previous version to this version.\n\tHoodieCleanMetadata upgradeFrom(HoodieCleanMetadata input);\n}", "des": "Migration handler for clean metadata in version 2."}
{"index": 3762, "repo": "hudi-common-0.13.1", "code": "class CleanPlanV1MigrationHandler {\n\t// Downgrades metadata of type T from next version to this version.\n\tHoodieCleanerPlan downgradeFrom(HoodieCleanerPlan plan);\n\t// Version of Metadata that this class will handle.\n\tInteger getManagedVersion();\n\t// Upgrades metadata of type T from previous version to this version.\n\tHoodieCleanerPlan upgradeFrom(HoodieCleanerPlan plan);\n}", "des": "Migration handler for clean plan in version 1."}
{"index": 3763, "repo": "hudi-common-0.13.1", "code": "class CleanPlanV2MigrationHandler {\n\t// Downgrades metadata of type T from next version to this version.\n\tHoodieCleanerPlan downgradeFrom(HoodieCleanerPlan input);\n\t// Version of Metadata that this class will handle.\n\tInteger getManagedVersion();\n\t// Upgrades metadata of type T from previous version to this version.\n\tHoodieCleanerPlan upgradeFrom(HoodieCleanerPlan plan);\n}", "des": "Migration handler for clean plan in version 2."}
{"index": 3764, "repo": "hudi-common-0.13.1", "code": "class ColumnIndexID {\n\t// Get the Base64 encoded version of the ID.\n\tString asBase64EncodedString();\n\t// Get this ID as a byte array.\n\tbyte[] asBytes();\n\t// Get the number of bits representing this ID in memory.\n\tint bits();\n\t// Get the resource name for which this index id is generated.\n\tString getName();\n\t// Get the ID type.\n\tprotected HoodieIndexID.Type getType();\n}", "des": "A stateful Hoodie object ID representing any table column."}
{"index": 3765, "repo": "hudi-common-0.13.1", "code": "class CompactionV1MigrationHandler {\n\t// Downgrades metadata of type T from next version to this version.\n\tHoodieCompactionPlan downgradeFrom(HoodieCompactionPlan input);\n\t// Version of Metadata that this class will handle.\n\tInteger getManagedVersion();\n\t// Upgrades metadata of type T from previous version to this version.\n\tHoodieCompactionPlan upgradeFrom(HoodieCompactionPlan input);\n}", "des": "Compaction V1 has absolute paths as part of compaction operations."}
{"index": 3766, "repo": "hudi-common-0.13.1", "code": "class CompactionV2MigrationHandler {\n\t// Downgrades metadata of type T from next version to this version.\n\tHoodieCompactionPlan downgradeFrom(HoodieCompactionPlan input);\n\t// Version of Metadata that this class will handle.\n\tInteger getManagedVersion();\n\t// Upgrades metadata of type T from previous version to this version.\n\tHoodieCompactionPlan upgradeFrom(HoodieCompactionPlan input);\n}", "des": "With version 2 of compaction plan, paths are no longer absolute."}
{"index": 3767, "repo": "hudi-common-0.13.1", "code": "enum ConfigGroups.Names {\n\t// \n\tstatic ConfigGroups.Names valueOf(String name);\n\t// ,  \n\tstatic ConfigGroups.Names[] values();\n}", "des": "Config group names."}
{"index": 3768, "repo": "hudi-common-0.13.1", "code": "enum ConsistencyGuard.FileVisibility {\n\t// \n\tstatic ConsistencyGuard.FileVisibility valueOf(String name);\n\t// ,  \n\tstatic ConsistencyGuard.FileVisibility[] values();\n}", "des": "File Visibility."}
{"index": 3769, "repo": "hudi-common-0.13.1", "code": "enum ConsistentHashingNode.NodeTag {\n\t// \n\tstatic ConsistentHashingNode.NodeTag valueOf(String name);\n\t// ,  \n\tstatic ConsistentHashingNode.NodeTag[] values();\n}", "des": "Node tag."}
{"index": 3770, "repo": "hudi-common-0.13.1", "code": "class DateWrapper.Builder {\n\tDateWrapper build();\n\t// Clears the value of the 'value' field.\n\tDateWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tInteger getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tDateWrapper.Builder setValue(int value);\n}", "des": "RecordBuilder for DateWrapper instances."}
{"index": 3771, "repo": "hudi-common-0.13.1", "code": "class DecimalWrapper.Builder {\n\tDecimalWrapper build();\n\t// Clears the value of the 'value' field.\n\tDecimalWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tByteBuffer getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tDecimalWrapper.Builder setValue(ByteBuffer value);\n}", "des": "RecordBuilder for DecimalWrapper instances."}
{"index": 3772, "repo": "hudi-common-0.13.1", "code": "enum DisruptorWaitStrategyType {\n\tstatic List<String> getNames();\n\t// \n\tstatic DisruptorWaitStrategyType valueOf(String name);\n\t// ,  \n\tstatic DisruptorWaitStrategyType[] values();\n}", "des": "Enum for the type of waiting strategy in Disruptor Queue."}
{"index": 3773, "repo": "hudi-common-0.13.1", "code": "class DoubleWrapper.Builder {\n\tDoubleWrapper build();\n\t// Clears the value of the 'value' field.\n\tDoubleWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tDouble getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tDoubleWrapper.Builder setValue(double value);\n}", "des": "RecordBuilder for DoubleWrapper instances."}
{"index": 3774, "repo": "hudi-common-0.13.1", "code": "interface EarlyConflictDetectionStrategy {\n\t// Detects and resolves the write conflict if necessary.\n\tvoid detectAndResolveConflictIfNecessary();\n\tboolean hasMarkerConflict();\n\t// Resolves a write conflict.\n\tvoid resolveMarkerConflict(String basePath, String partitionPath, String dataFileName);\n}", "des": "Interface for pluggable strategy of early conflict detection for multiple writers."}
{"index": 3775, "repo": "hudi-common-0.13.1", "code": "class EmptyHoodieRecordPayload {\n\t// This methods is deprecated.\n\tOption<org.apache.avro.generic.IndexedRecord> combineAndGetUpdateValue(org.apache.avro.generic.IndexedRecord currentValue, org.apache.avro.Schema schema);\n\t// This method is deprecated.\n\tOption<org.apache.avro.generic.IndexedRecord> getInsertValue(org.apache.avro.Schema schema);\n\t// This method is deprecated.\n\tEmptyHoodieRecordPayload preCombine(EmptyHoodieRecordPayload oldValue);\n}", "des": "Empty payload used for deletions."}
{"index": 3776, "repo": "hudi-common-0.13.1", "code": "enum EngineProperty {\n\t// \n\tstatic EngineProperty valueOf(String name);\n\t// ,  \n\tstatic EngineProperty[] values();\n}", "des": "Properties specific to each engine, that can be set/obtained from."}
{"index": 3777, "repo": "hudi-common-0.13.1", "code": "enum EngineType {\n\t// \n\tstatic EngineType valueOf(String name);\n\t// ,  \n\tstatic EngineType[] values();\n}", "des": "Hoodie data processing engine."}
{"index": 3778, "repo": "hudi-common-0.13.1", "code": "enum ExecutorType {\n\t// \n\tstatic ExecutorType valueOf(String name);\n\t// ,  \n\tstatic ExecutorType[] values();\n}", "des": "Types of HoodieExecutor."}
{"index": 3779, "repo": "hudi-common-0.13.1", "code": "enum ExternalSpillableMap.DiskMapType {\n\t// \n\tstatic ExternalSpillableMap.DiskMapType valueOf(String name);\n\t// ,  \n\tstatic ExternalSpillableMap.DiskMapType[] values();\n}", "des": "The type of map to use for storing the Key, values on disk after it spills from memory in the ExternalSpillableMap."}
{"index": 3780, "repo": "hudi-common-0.13.1", "code": "class FileBasedInternalSchemaStorageManager {\n\tvoid cleanOldFiles(List<String> validateCommits);\n\t// Get latest history schema string.\n\tString getHistorySchemaStr();\n\t// Get latest history schema string.\n\tString getHistorySchemaStrByGivenValidCommits(List<String> validCommits);\n\t// Get internalSchema by using given versionId\n\tOption<InternalSchema> getSchemaByKey(String versionId);\n\t// Persist history schema str.\n\tvoid persistHistorySchemaStr(String instantTime, String historySchemaStr);\n}", "des": "AbstractInternalSchemaStorageManager implementation based on the schema files."}
{"index": 3781, "repo": "hudi-common-0.13.1", "code": "class FileIndexID {\n\t// Get the Base64 encoded version of the ID.\n\tString asBase64EncodedString();\n\t// Get this ID as a byte array.\n\tbyte[] asBytes();\n\t// Get the number of bits representing this ID in memory.\n\tint bits();\n\t// Get the resource name for which this index id is generated.\n\tString getName();\n\t// Get the ID type.\n\tprotected HoodieIndexID.Type getType();\n}", "des": "Hoodie object ID representing any file."}
{"index": 3782, "repo": "hudi-common-0.13.1", "code": "enum FileSystemViewStorageType {\n\t// \n\tstatic FileSystemViewStorageType valueOf(String name);\n\t// ,  \n\tstatic FileSystemViewStorageType[] values();\n}", "des": "Storage Type used to store/retrieve File system view of a table."}
{"index": 3783, "repo": "hudi-common-0.13.1", "code": "class FloatWrapper.Builder {\n\tFloatWrapper build();\n\t// Clears the value of the 'value' field.\n\tFloatWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tFloat getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tFloatWrapper.Builder setValue(float value);\n}", "des": "RecordBuilder for FloatWrapper instances."}
{"index": 3784, "repo": "hudi-common-0.13.1", "code": "class HashID {\n\tstatic int getXXHash32(byte[] message, int hashSeed);\n\tstatic int getXXHash32(String message, int hashSeed);\n\t// Get the hash value for a byte array and for the desired @HashID.Size.\n\tstatic byte[] hash(byte[] messageBytes, HashID.Size bits);\n\t// Get the hash value for a string message and for the desired @HashID.Size.\n\tstatic byte[] hash(String message, HashID.Size bits);\n}", "des": "A stateless Hash class which generates ID for the desired bit count."}
{"index": 3785, "repo": "hudi-common-0.13.1", "code": "enum HashID.Size {\n\t// Get this Hash size in bits.\n\tint bits();\n\t// Get this Hash size in bytes.\n\tint byteSize();\n\t// \n\tstatic HashID.Size valueOf(String name);\n\t// ,  \n\tstatic HashID.Size[] values();\n}", "des": "Represents HashID size in bits."}
{"index": 3786, "repo": "hudi-common-0.13.1", "code": "class HFileBootstrapIndex {\n\t// Create Bootstrap Index Reader.\n\tBootstrapIndex.IndexReader createReader();\n\t// Create Bootstrap Index Writer.\n\tBootstrapIndex.IndexWriter createWriter(String bootstrapBasePath);\n\t// Drop bootstrap index.\n\tvoid dropIndex();\n\t// Check if bootstrap Index is physically present.\n\tboolean isPresent();\n}", "des": "Maintains mapping from skeleton file id to external bootstrap file. It maintains 2 physical indices. (a) At partition granularity to lookup all indices for each partition. (b) At file-group granularity to lookup bootstrap mapping for an individual file-group. This implementation uses HFile as physical storage of index. FOr the initial run, bootstrap mapping for the entire dataset resides in a single file but care has been taken in naming the index files in the same way as Hudi data files so that we can reuse file-system abstraction on these index files to manage multiple file-groups."}
{"index": 3787, "repo": "hudi-common-0.13.1", "code": "class HFileBootstrapIndex.HFileBootstrapIndexWriter {\n\t// Append bootstrap index entries for next partitions in sorted order.\n\tvoid appendNextPartition(String partitionPath, List<BootstrapFileMapping> bootstrapFileMappings);\n\t// Writer calls this method before beginning indexing partitions.\n\tvoid begin();\n\t// Close Writer Handles.\n\tvoid close();\n\t// Writer calls this method after appending all partitions to be indexed.\n\tvoid finish();\n}", "des": "Bootstrap Index Writer to build bootstrap index."}
{"index": 3788, "repo": "hudi-common-0.13.1", "code": "enum HoodieCDCInferenceCase {\n\t// \n\tstatic HoodieCDCInferenceCase valueOf(String name);\n\t// ,  \n\tstatic HoodieCDCInferenceCase[] values();\n}", "des": "Here define five cdc infer cases. The different cdc infer case will decide which file will be used to extract the change data, and how to do this. AS_IS: For this type, there must be a real cdc log file from which we get the whole/part change data. when `hoodie.table.cdc.supplemental.logging.mode` is HoodieCDCSupplementalLoggingMode.data_before_after, it keeps all the fields about the change data, including `op`, `ts_ms`, `before` and `after`. So read it and return directly, no more other files need to be loaded. when `hoodie.table.cdc.supplemental.logging.mode` is HoodieCDCSupplementalLoggingMode.data_before, it keeps the `op`, the key and the `before` of the changing record. When `op` is equal to 'i' or 'u', need to get the current record from the current base/log file as `after`. when `hoodie.table.cdc.supplemental.logging.mode` is 'op_key', it just keeps the `op` and the key of the changing record. When `op` is equal to 'i', `before` is null and get the current record from the current base/log file as `after`. When `op` is equal to 'u', get the previous record from the previous file slice as `before`, and get the current record from the current base/log file as `after`. When `op` is equal to 'd', get the previous record from the previous file slice as `before`, and `after` is null. BASE_FILE_INSERT: For this type, there must be a base file at the current instant. All the records from this file is new-coming, so we can load this, mark all the records with `i`, and treat them as the value of `after`. The value of `before` for each record is null. BASE_FILE_DELETE: For this type, there must be an empty file at the current instant, but a non-empty base file at the previous instant. First we find this base file that has the same file group and belongs to the previous instant. Then load this, mark all the records with `d`, and treat them as the value of `before`. The value of `after` for each record is null. LOG_FILE: For this type, a normal log file of mor table will be used. First we need to load the previous file slice(including the base file and other log files in the same file group). Then for each record from the log file, get the key of this, and execute the following steps: 1) if the record is deleted, a) if there is a record with the same key in the data loaded, `op` is 'd', 'before' is the record from the data loaded, `after` is null; b) if there is not a record with the same key in the data loaded, just skip. 2) the record is not deleted, a) if there is a record with the same key in the data loaded, `op` is 'u', 'before' is the record from the data loaded, `after` is the current record; b) if there is not a record with the same key in the data loaded, `op` is 'i', 'before' is null, `after` is the current record; REPLACE_COMMIT: For this type, it must be a replacecommit, like INSERT_OVERWRITE and DROP_PARTITION. It drops a whole file group. First we find this file group. Then load this, mark all the records with `d`, and treat them as the value of `before`. The value of `after` for each record is null."}
{"index": 3789, "repo": "hudi-common-0.13.1", "code": "enum HoodieCDCOperation {\n\tString getValue();\n\tstatic HoodieCDCOperation parse(String value);\n\t// \n\tstatic HoodieCDCOperation valueOf(String name);\n\t// ,  \n\tstatic HoodieCDCOperation[] values();\n}", "des": "Enumeration of change log operation."}
{"index": 3790, "repo": "hudi-common-0.13.1", "code": "enum HoodieCDCSupplementalLoggingMode {\n\t// \n\tstatic HoodieCDCSupplementalLoggingMode valueOf(String name);\n\t// ,  \n\tstatic HoodieCDCSupplementalLoggingMode[] values();\n}", "des": "Change log capture supplemental logging mode. The supplemental log is used for accelerating the generation of change log details."}
{"index": 3791, "repo": "hudi-common-0.13.1", "code": "enum HoodieCleaningPolicy {\n\t// \n\tstatic HoodieCleaningPolicy valueOf(String name);\n\t// ,  \n\tstatic HoodieCleaningPolicy[] values();\n}", "des": "Hoodie cleaning policies."}
{"index": 3792, "repo": "hudi-common-0.13.1", "code": "enum HoodieCommandBlock.HoodieCommandBlockTypeEnum {\n\t// \n\tstatic HoodieCommandBlock.HoodieCommandBlockTypeEnum valueOf(String name);\n\t// ,  \n\tstatic HoodieCommandBlock.HoodieCommandBlockTypeEnum[] values();\n}", "des": "Hoodie command block type enum."}
{"index": 3793, "repo": "hudi-common-0.13.1", "code": "interface HoodieConsumer<I,O> {\n\t// Consume records from inner message queue.\n\tvoid consume(I record);\n\t// Notifies implementation that we have exhausted consuming records from queue.\n\tO finish();\n}", "des": "HoodieConsumer is used to consume records/messages from hoodie inner message queue and write into DFS."}
{"index": 3794, "repo": "hudi-common-0.13.1", "code": "class HoodieDynamicBoundedBloomFilter {\n\t// Add a key's bytes, representing UTF8-encoded string, to the BloomFilter.\n\tvoid add(byte[] keyBytes);\n\t// Add a key represented by a String to the BloomFilter.\n\tvoid add(String key);\n\tBloomFilterTypeCode getBloomFilterTypeCode();\n\t// Tests for key membership.\n\tboolean mightContain(String key);\n\t// Serialize the bloom filter as a string.\n\tString serializeToString();\n}", "des": "Hoodie's dynamic bloom bounded bloom filter. This is based largely on Hadoop's DynamicBloomFilter, but with a bound on amount of entries to dynamically expand to. Once the entries added reach the bound, false positive ratio may not be guaranteed."}
{"index": 3795, "repo": "hudi-common-0.13.1", "code": "interface HoodieExecutor<E> {\n\t// Allows to gracefully await the termination of the executor\n\tboolean awaitTermination();\n\t// Main API to 1.\n\tE execute();\n\t// Shuts executor down immediately, cleaning up any allocated resources\n\tvoid shutdownNow();\n}", "des": "HoodieExecutor which orchestrates concurrent producers and consumers communicating."}
{"index": 3796, "repo": "hudi-common-0.13.1", "code": "enum HoodieFailedWritesCleaningPolicy {\n\tboolean isEager();\n\tboolean isLazy();\n\tboolean isNever();\n\t// \n\tstatic HoodieFailedWritesCleaningPolicy valueOf(String name);\n\t// ,  \n\tstatic HoodieFailedWritesCleaningPolicy[] values();\n}", "des": "Policy controlling how to perform cleaning for failed writes."}
{"index": 3797, "repo": "hudi-common-0.13.1", "code": "enum HoodieFileFormat {\n\tString getFileExtension();\n\t// \n\tstatic HoodieFileFormat valueOf(String name);\n\t// ,  \n\tstatic HoodieFileFormat[] values();\n}", "des": "Hoodie file format."}
{"index": 3798, "repo": "hudi-common-0.13.1", "code": "class HoodieHeartbeatUtils {\n\t// Use modification time as last heart beat time.\n\tstatic Long getLastHeartbeatTime(org.apache.hadoop.fs.FileSystem fs, String basePath, String instantTime);\n\t// Whether a heartbeat is expired.\n\tstatic boolean isHeartbeatExpired(String instantTime, long maxAllowableHeartbeatIntervalInMs, org.apache.hadoop.fs.FileSystem fs, String basePath);\n}", "des": "Common utils for Hudi heartbeat"}
{"index": 3799, "repo": "hudi-common-0.13.1", "code": "enum HoodieIndexID.Type {\n\t// \n\tstatic HoodieIndexID.Type valueOf(String name);\n\t// ,  \n\tstatic HoodieIndexID.Type[] values();\n}", "des": "Supported ID types."}
{"index": 3800, "repo": "hudi-common-0.13.1", "code": "enum HoodieInstant.State {\n\t// \n\tstatic HoodieInstant.State valueOf(String name);\n\t// ,  \n\tstatic HoodieInstant.State[] values();\n}", "des": "Instant State."}
{"index": 3801, "repo": "hudi-common-0.13.1", "code": "enum HoodieLogBlock.FooterMetadataType {\n\t// \n\tstatic HoodieLogBlock.FooterMetadataType valueOf(String name);\n\t// ,  \n\tstatic HoodieLogBlock.FooterMetadataType[] values();\n}", "des": "Log Metadata footers abstraction for a HoodieLogBlock WARNING : This enum is serialized as the ordinal. Only add new enums at the end."}
{"index": 3802, "repo": "hudi-common-0.13.1", "code": "enum HoodieLogBlock.HeaderMetadataType {\n\t// \n\tstatic HoodieLogBlock.HeaderMetadataType valueOf(String name);\n\t// ,  \n\tstatic HoodieLogBlock.HeaderMetadataType[] values();\n}", "des": "Log Metadata headers abstraction for a HoodieLogBlock WARNING : This enum is serialized as the ordinal. Only add new enums at the end."}
{"index": 3803, "repo": "hudi-common-0.13.1", "code": "enum HoodieLogBlock.HoodieLogBlockType {\n\tstatic HoodieLogBlock.HoodieLogBlockType fromId(String id);\n\t// \n\tstatic HoodieLogBlock.HoodieLogBlockType valueOf(String name);\n\t// ,  \n\tstatic HoodieLogBlock.HoodieLogBlockType[] values();\n}", "des": "Type of the log block WARNING: This enum is serialized as the ordinal. Only add new enums at the end."}
{"index": 3804, "repo": "hudi-common-0.13.1", "code": "class HoodieLogFileReader {\n\tvoid close();\n\tHoodieLogFile getLogFile();\n\tboolean hasNext();\n\t// hasPrev is not idempotent.\n\tboolean hasPrev();\n\t// Reverse pointer, does not read the block.\n\tlong moveToPrev();\n\tHoodieLogBlock next();\n\t// This is a reverse iterator Note: At any point, an instance of HoodieLogFileReader should either iterate reverse (prev) or forward (next).\n\tHoodieLogBlock prev();\n\tvoid remove();\n}", "des": "Scans a log file and provides block level iterator on the log file Loads the entire block contents in memory Can emit either a DataBlock, CommandBlock, DeleteBlock or CorruptBlock (if one is found)."}
{"index": 3805, "repo": "hudi-common-0.13.1", "code": "interface HoodieLogFormat.Reader {\n\tHoodieLogFile getLogFile();\n\t// Read log file in reverse order and check if prev block is present.\n\tboolean hasPrev();\n\t// Read log file in reverse order and return prev block if present.\n\tHoodieLogBlock prev();\n}", "des": "Reader interface which is an Iterator of HoodieLogBlock."}
{"index": 3806, "repo": "hudi-common-0.13.1", "code": "interface HoodieLogFormat.Writer {\n\t// Append Block to a log file.\n\tAppendResult appendBlock(HoodieLogBlock block);\n\t// Appends the list of blocks to a logfile.\n\tAppendResult appendBlocks(List<HoodieLogBlock> blocks);\n\tlong getCurrentSize();\n\tHoodieLogFile getLogFile();\n}", "des": "Writer interface to allow appending block to this file format."}
{"index": 3807, "repo": "hudi-common-0.13.1", "code": "class HoodieLogFormatReader {\n\tvoid close();\n\tHoodieLogFile getLogFile();\n\tboolean hasNext();\n\t// Read log file in reverse order and check if prev block is present.\n\tboolean hasPrev();\n\tHoodieLogBlock next();\n\t// Read log file in reverse order and return prev block if present.\n\tHoodieLogBlock prev();\n\tvoid remove();\n}", "des": "Hoodie log format reader."}
{"index": 3808, "repo": "hudi-common-0.13.1", "code": "class HoodieLogFormatWriter {\n\t// Append Block to a log file.\n\tAppendResult appendBlock(HoodieLogBlock block);\n\t// Appends the list of blocks to a logfile.\n\tAppendResult appendBlocks(List<HoodieLogBlock> blocks);\n\tvoid close();\n\tlong getCurrentSize();\n\torg.apache.hadoop.fs.FileSystem getFs();\n\tHoodieLogFile getLogFile();\n\tlong getSizeThreshold();\n}", "des": "HoodieLogFormatWriter can be used to append blocks to a log file Use HoodieLogFormat.WriterBuilder to construct."}
{"index": 3809, "repo": "hudi-common-0.13.1", "code": "interface HoodieRecordMerger {\n\t// The kind of merging strategy this recordMerger belongs to.\n\tString getMergingStrategy();\n\t// The record type handled by the current merger.\n\tHoodieRecord.HoodieRecordType getRecordType();\n\t// This method converges combineAndGetUpdateValue and precombine from HoodiePayload.\n\tOption<Pair<HoodieRecord,org.apache.avro.Schema>> merge(HoodieRecord older, org.apache.avro.Schema oldSchema, HoodieRecord newer, org.apache.avro.Schema newSchema, TypedProperties props);\n}", "des": "HoodieMerge defines how to merge two records. It is a stateless component. It can implement the merging logic of HoodieRecord of different engines and avoid the performance consumption caused by the serialization/deserialization of Avro payload."}
{"index": 3810, "repo": "hudi-common-0.13.1", "code": "enum HoodieSyncTableStrategy {\n\t// \n\tstatic HoodieSyncTableStrategy valueOf(String name);\n\t// ,  \n\tstatic HoodieSyncTableStrategy[] values();\n}", "des": "Hoodie table synchronization strategy."}
{"index": 3811, "repo": "hudi-common-0.13.1", "code": "enum HoodieTableQueryType {\n\t// \n\tstatic HoodieTableQueryType valueOf(String name);\n\t// ,  \n\tstatic HoodieTableQueryType[] values();\n}", "des": "Hudi table could be queried in one of the 3 following ways: Snapshot: snapshot of the table at the given (latest if not provided) instant is queried Read Optimized (MOR only): snapshot of the table at the given (latest if not provided) instant is queried, but w/o reading any of the delta-log files (only reading base-files) Incremental: only records added w/in the given time-window (defined by beginning and ending instant) are queried"}
{"index": 3812, "repo": "hudi-common-0.13.1", "code": "enum HoodieTableType {\n\t// \n\tstatic HoodieTableType valueOf(String name);\n\t// ,  \n\tstatic HoodieTableType[] values();\n}", "des": "Type of the Hoodie Table. Currently, 2 types are supported. COPY_ON_WRITE - Performs upserts by versioning entire files, with later versions containing newer value of a record. MERGE_ON_READ - Speeds up upserts, by delaying merge until enough work piles up."}
{"index": 3813, "repo": "hudi-common-0.13.1", "code": "enum HoodieTableVersion {\n\tstatic HoodieTableVersion current();\n\t// \n\tstatic HoodieTableVersion valueOf(String name);\n\t// ,  \n\tstatic HoodieTableVersion[] values();\n\tint versionCode();\n\tstatic HoodieTableVersion versionFromCode(int versionCode);\n}", "des": "Table's version that controls what version of writer/readers can actually read/write to a given table."}
{"index": 3814, "repo": "hudi-common-0.13.1", "code": "enum HoodieTimelineTimeZone {\n\tString getTimeZone();\n\tZoneId getZoneId();\n\t// \n\tstatic HoodieTimelineTimeZone valueOf(String name);\n\t// ,  \n\tstatic HoodieTimelineTimeZone[] values();\n}", "des": "Hoodie TimelineZone."}
{"index": 3815, "repo": "hudi-common-0.13.1", "code": "class HoodieUnMergedLogRecordScanner {\n\t// Returns the builder for HoodieUnMergedLogRecordScanner.\n\tstatic HoodieUnMergedLogRecordScanner.Builder newBuilder();\n\t// Process next deleted record.\n\tprotected void processNextDeletedRecord(DeleteRecord deleteRecord);\n\t// Process next record.\n\tprotected <T> void processNextRecord(HoodieRecord<T> hoodieRecord);\n\t// Scans delta-log files processing blocks\n\tvoid scan();\n\tvoid scan(boolean skipProcessingBlocks);\n}", "des": "A scanner used to scan hoodie unmerged log records."}
{"index": 3816, "repo": "hudi-common-0.13.1", "code": "enum HoodieWrapperFileSystem.MetricName {\n\t// \n\tstatic HoodieWrapperFileSystem.MetricName valueOf(String name);\n\t// ,  \n\tstatic HoodieWrapperFileSystem.MetricName[] values();\n}", "des": "Names for metrics."}
{"index": 3817, "repo": "hudi-common-0.13.1", "code": "class ImmutablePair<L,R> {\n\t// Gets the left element from this pair.\n\tL getLeft();\n\t// Gets the right element from this pair.\n\tR getRight();\n\t// Obtains an immutable pair of from two objects inferring the generic types.\n\tstatic <L,R> ImmutablePair<L,R> of(L left, R right);\n\t// Throws UnsupportedOperationException.\n\tR setValue(R value);\n}", "des": "(NOTE: Adapted from Apache commons-lang3)"}
{"index": 3818, "repo": "hudi-common-0.13.1", "code": "class ImmutableTriple<L,M,R> {\n\t// Gets the left element from this triple.\n\tL getLeft();\n\t// Gets the middle element from this triple.\n\tM getMiddle();\n\t// Gets the right element from this triple.\n\tR getRight();\n\t// Obtains an immutable triple of from three objects inferring the generic types.\n\tstatic <L,M,R> ImmutableTriple<L,M,R> of(L left, M middle, R right);\n}", "des": "(NOTE: Adapted from Apache commons-lang3)"}
{"index": 3819, "repo": "hudi-common-0.13.1", "code": "enum InstantRange.RangeType {\n\t// \n\tstatic InstantRange.RangeType valueOf(String name);\n\t// ,  \n\tstatic InstantRange.RangeType[] values();\n}", "des": "Represents a range type."}
{"index": 3820, "repo": "hudi-common-0.13.1", "code": "class IntWrapper.Builder {\n\tIntWrapper build();\n\t// Clears the value of the 'value' field.\n\tIntWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tInteger getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tIntWrapper.Builder setValue(int value);\n}", "des": "RecordBuilder for IntWrapper instances."}
{"index": 3821, "repo": "hudi-common-0.13.1", "code": "enum IOType {\n\t// \n\tstatic IOType valueOf(String name);\n\t// ,  \n\tstatic IOType[] values();\n}", "des": "Types of lower level I/O operations done on each file slice."}
{"index": 3822, "repo": "hudi-common-0.13.1", "code": "class KeyGenerator {\n\t// Generate a Hoodie Key out of provided generic record.\n\tabstract HoodieKey getKey(org.apache.avro.generic.GenericRecord record);\n\t// Used during bootstrap, to project out only the record key fields from bootstrap source dataset.\n\tList<String> getRecordKeyFieldNames();\n}", "des": "Abstract class to extend for plugging in extraction of HoodieKey from an Avro record."}
{"index": 3823, "repo": "hudi-common-0.13.1", "code": "enum KeyGeneratorType {\n\tstatic List<String> getNames();\n\t// \n\tstatic KeyGeneratorType valueOf(String name);\n\t// ,  \n\tstatic KeyGeneratorType[] values();\n}", "des": "Types of KeyGenerator."}
{"index": 3824, "repo": "hudi-common-0.13.1", "code": "class Lazy<T> {\n\t// Instantiates Lazy in an \"eagerly\" fashion setting it w/ the provided value of type T directly, bypassing lazy initialization sequence\n\tstatic <T> Lazy<T> eagerly(T ref);\n\tT get();\n\t// Executes provided initializer lazily, while providing for \"exactly once\" semantic, to instantiate value of type T being subsequently held by the returned instance of Lazy\n\tstatic <T> Lazy<T> lazily(Supplier<T> initializer);\n}", "des": "Utility implementing lazy semantics in Java"}
{"index": 3825, "repo": "hudi-common-0.13.1", "code": "class LocalRegistry {\n\t// Add value to the metric.\n\tvoid add(String name, long value);\n\t// Clear all metrics.\n\tvoid clear();\n\t// Get all Counter type metrics.\n\tMap<String,Long> getAllCounts(boolean prefixWithRegistryName);\n\t// Increment the metric.\n\tvoid increment(String name);\n\t// Set the value to the metric.\n\tvoid set(String name, long value);\n}", "des": "Registry that tracks metrics local to a single jvm process."}
{"index": 3826, "repo": "hudi-common-0.13.1", "code": "enum LockState {\n\t// \n\tstatic LockState valueOf(String name);\n\t// ,  \n\tstatic LockState[] values();\n}", "des": "Enum to signal the state of the lock."}
{"index": 3827, "repo": "hudi-common-0.13.1", "code": "class LongWrapper.Builder {\n\tLongWrapper build();\n\t// Clears the value of the 'value' field.\n\tLongWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tLong getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tLongWrapper.Builder setValue(long value);\n}", "des": "RecordBuilder for LongWrapper instances."}
{"index": 3828, "repo": "hudi-common-0.13.1", "code": "enum MarkerType {\n\t// \n\tstatic MarkerType valueOf(String name);\n\t// ,  \n\tstatic MarkerType[] values();\n}", "des": "Marker type indicating how markers are stored in the file system."}
{"index": 3829, "repo": "hudi-common-0.13.1", "code": "class MetadataMigrator<T> {\n\t// Migrate metadata to a specific version.\n\tT migrateToVersion(T metadata, int metadataVersion, int targetVersion);\n\t// Upgrade Metadata version to its latest.\n\tT upgradeToLatest(T metadata, int metadataVersion);\n}", "des": "Migrates a specific metadata type stored in .hoodie folder to latest version."}
{"index": 3830, "repo": "hudi-common-0.13.1", "code": "enum MetadataPartitionType {\n\tstatic List<String> allPaths();\n\tint getFileGroupCount();\n\tString getFileIdPrefix();\n\tString getPartitionPath();\n\tvoid setFileGroupCount(int fileGroupCount);\n\t// \n\tstatic MetadataPartitionType valueOf(String name);\n\t// ,  \n\tstatic MetadataPartitionType[] values();\n}", "des": "Partition types for metadata table."}
{"index": 3831, "repo": "hudi-common-0.13.1", "code": "class NoOpBootstrapIndex {\n\t// Create Bootstrap Index Reader.\n\tBootstrapIndex.IndexReader createReader();\n\t// Create Bootstrap Index Writer.\n\tBootstrapIndex.IndexWriter createWriter(String sourceBasePath);\n\t// Drop bootstrap index.\n\tvoid dropIndex();\n\t// Check if bootstrap Index is physically present.\n\tprotected boolean isPresent();\n}", "des": "No Op Bootstrap Index , which is a empty implement and not do anything."}
{"index": 3832, "repo": "hudi-common-0.13.1", "code": "class PartitionIndexID {\n\t// Get the Base64 encoded version of the ID.\n\tString asBase64EncodedString();\n\t// Get this ID as a byte array.\n\tbyte[] asBytes();\n\t// Get the number of bits representing this ID in memory.\n\tint bits();\n\t// Get the resource name for which this index id is generated.\n\tString getName();\n\t// Get the ID type.\n\tprotected HoodieIndexID.Type getType();\n}", "des": "Hoodie object ID representing any partition."}
{"index": 3833, "repo": "hudi-common-0.13.1", "code": "class RewriteAvroPayload {\n\t// This methods is deprecated.\n\tOption<org.apache.avro.generic.IndexedRecord> combineAndGetUpdateValue(org.apache.avro.generic.IndexedRecord currentValue, org.apache.avro.Schema schema);\n\t// This method is deprecated.\n\tOption<org.apache.avro.generic.IndexedRecord> getInsertValue(org.apache.avro.Schema schema);\n\t// This method is deprecated.\n\tRewriteAvroPayload preCombine(RewriteAvroPayload another);\n}", "des": "Default payload used for rewrite use cases where we dont change schema. We dont need to serialize/deserialize avro record in payload."}
{"index": 3834, "repo": "hudi-common-0.13.1", "code": "enum SecondaryIndexType {\n\tbyte getValue();\n\tstatic SecondaryIndexType of(byte indexType);\n\tstatic SecondaryIndexType of(String indexType);\n\t// \n\tstatic SecondaryIndexType valueOf(String name);\n\t// ,  \n\tstatic SecondaryIndexType[] values();\n}", "des": "Type of secondary index."}
{"index": 3835, "repo": "hudi-common-0.13.1", "code": "class SecondaryIndexUtils {\n\t// Parse secondary index str to List\n\tstatic List<HoodieSecondaryIndex> fromJsonString(String jsonStr);\n\tstatic <T> T fromJsonString(String jsonStr, com.fasterxml.jackson.core.type.TypeReference<T> type);\n\tstatic com.fasterxml.jackson.databind.ObjectMapper getObjectMapper();\n\t// Get secondary index metadata for this table\n\tstatic Option<List<HoodieSecondaryIndex>> getSecondaryIndexes(HoodieTableMetaClient metaClient);\n\tstatic String toJsonString(Object value);\n}", "des": "Utils for secondary index."}
{"index": 3836, "repo": "hudi-common-0.13.1", "code": "class SerializationUtils {\n\t// Deserializes a single Object from an array of bytes.\n\tstatic <T> T deserialize(byte[] objectData);\n\t// Serializes an Object to a byte array for storage/serialization.\n\tstatic byte[] serialize(Object obj);\n}", "des": "SerializationUtils class internally uses Kryo serializer for serializing / deserializing objects."}
{"index": 3837, "repo": "hudi-common-0.13.1", "code": "class SimpleBloomFilter {\n\t// Add a key's bytes, representing UTF8-encoded string, to the BloomFilter.\n\tvoid add(byte[] keyBytes);\n\t// Add a key represented by a String to the BloomFilter.\n\tvoid add(String key);\n\tBloomFilterTypeCode getBloomFilterTypeCode();\n\t// Tests for key membership.\n\tboolean mightContain(String key);\n\tvoid readFields(DataInput in);\n\t// Serialize the bloom filter as a string.\n\tString serializeToString();\n\tvoid write(DataOutput out);\n}", "des": "A Simple Bloom filter implementation built on top of BloomFilter."}
{"index": 3838, "repo": "hudi-common-0.13.1", "code": "class SimpleExecutor<I,O,E> {\n\t// Allows to gracefully await the termination of the executor\n\tboolean awaitTermination();\n\t// Consuming records from input iterator directly without any producers and inner message queue.\n\tE execute();\n\t// Shuts executor down immediately, cleaning up any allocated resources\n\tvoid shutdownNow();\n}", "des": "Simple implementation of the HoodieExecutor interface assuming single-writer/single-reader mode allowing it to consume from the input Iterator directly avoiding the need for any internal materialization (ie queueing)."}
{"index": 3839, "repo": "hudi-common-0.13.1", "code": "enum StorageSchemes {\n\tString getScheme();\n\tstatic boolean isAppendSupported(String scheme);\n\tboolean isAtomicCreationSupported();\n\tstatic boolean isAtomicCreationSupported(String scheme);\n\tstatic boolean isSchemeSupported(String scheme);\n\tboolean isWriteTransactional();\n\tstatic boolean isWriteTransactional(String scheme);\n\tboolean supportsAppend();\n\t// \n\tstatic StorageSchemes valueOf(String name);\n\t// ,  \n\tstatic StorageSchemes[] values();\n}", "des": "All the supported storage schemes in Hoodie."}
{"index": 3840, "repo": "hudi-common-0.13.1", "code": "class StringWrapper.Builder {\n\tStringWrapper build();\n\t// Clears the value of the 'value' field.\n\tStringWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tString getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tStringWrapper.Builder setValue(String value);\n}", "des": "RecordBuilder for StringWrapper instances."}
{"index": 3841, "repo": "hudi-common-0.13.1", "code": "interface SyncableFileSystemView {\n\t// Allow View to release resources and close.\n\tvoid close();\n\t// Reset View so that they can be refreshed.\n\tvoid reset();\n\t// Read the latest timeline and refresh the file-system view to match the current state of the file-system.\n\tvoid sync();\n}", "des": "A consolidated file-system view interface exposing both complete slice and basefile only views along with update operations."}
{"index": 3842, "repo": "hudi-common-0.13.1", "code": "class TableChange.BaseColumnChange {\n\tTableChange.BaseColumnChange addPositionChange(String srcName, String dsrName, String orderType);\n\t// Add position change.\n\tTableChange.BaseColumnChange addPositionChange(String srcName, String dsrName, TableChange.ColumnPositionChange.ColumnPositionType orderType);\n\tprotected void checkColModifyIsLegal(String colNeedToModfiy);\n\t// Abstract method.\n\tprotected abstract Integer findIdByFullName(String fullName);\n\tboolean withPositionChange();\n}", "des": "Information of base column changes"}
{"index": 3843, "repo": "hudi-common-0.13.1", "code": "enum TableChange.ColumnChangeID {\n\tString getName();\n\t// \n\tstatic TableChange.ColumnChangeID valueOf(String name);\n\t// ,  \n\tstatic TableChange.ColumnChangeID[] values();\n}", "des": "The action Type of schema change."}
{"index": 3844, "repo": "hudi-common-0.13.1", "code": "interface TableFileSystemView.BaseFileOnlyView {\n\t// Stream all the data file versions grouped by FileId for a given partition.\n\tStream<HoodieBaseFile> getAllBaseFiles(String partitionPath);\n\t// Get the version of data file matching the instant time in the given partition.\n\tOption<HoodieBaseFile> getBaseFileOn(String partitionPath, String instantTime, String fileId);\n}", "des": "Methods to provide a view of base files only."}
{"index": 3845, "repo": "hudi-common-0.13.1", "code": "enum TableServiceType {\n\tString getAction();\n\t// \n\tstatic TableServiceType valueOf(String name);\n\t// ,  \n\tstatic TableServiceType[] values();\n}", "des": "Supported runtime table services."}
{"index": 3846, "repo": "hudi-common-0.13.1", "code": "class TimeMicrosWrapper.Builder {\n\tTimeMicrosWrapper build();\n\t// Clears the value of the 'value' field.\n\tTimeMicrosWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tLong getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tTimeMicrosWrapper.Builder setValue(long value);\n}", "des": "RecordBuilder for TimeMicrosWrapper instances."}
{"index": 3847, "repo": "hudi-common-0.13.1", "code": "class TimestampMicrosWrapper.Builder {\n\tTimestampMicrosWrapper build();\n\t// Clears the value of the 'value' field.\n\tTimestampMicrosWrapper.Builder clearValue();\n\t// Gets the value of the 'value' field.\n\tLong getValue();\n\t// Checks whether the 'value' field has been set.\n\tboolean hasValue();\n\t// Sets the value of the 'value' field.\n\tTimestampMicrosWrapper.Builder setValue(long value);\n}", "des": "RecordBuilder for TimestampMicrosWrapper instances."}
{"index": 3848, "repo": "hudi-common-0.13.1", "code": "enum Type.TypeID {\n\tString getName();\n\t// \n\tstatic Type.TypeID valueOf(String name);\n\t// ,  \n\tstatic Type.TypeID[] values();\n}", "des": "Enums for type names."}
{"index": 3849, "repo": "hudi-common-0.13.1", "code": "class Types.DecimalType {\n\t// We need to override equals because the check intType1 == intType2 can return false.\n\tboolean equals(Object o);\n\tstatic Types.DecimalType get(int precision, int scale);\n\t// Returns whether this DecimalType is tighter than `other`.\n\tboolean isTighterThan(Type.PrimitiveType other);\n\t// Returns whether this DecimalType is wider than `other`.\n\tboolean isWiderThan(Type.PrimitiveType other);\n\tint precision();\n\tint scale();\n\tType.TypeID typeId();\n}", "des": "Decimal primitive type."}
{"index": 3850, "repo": "hudi-common-0.13.1", "code": "class TypeUtils {\n\t// Maps values from the provided Enum's Class into corresponding values, extracted by provided valueMapper\n\tstatic <EnumT extends Enum<EnumT>>Map<String,EnumT> getValueToEnumMap(Class<EnumT> klass, Function<EnumT,String> valueMapper);\n\t// This utility abstracts unsafe type-casting in a way that allows to Search for such type-casts more easily (just searching for usages of this method) Avoid type-cast warnings from the compiler\n\tstatic <T> T unsafeCast(Object o);\n}", "des": "Utils for Java type cast."}
{"index": 3851, "repo": "hudi-common-0.13.1", "code": "interface VersionMigrator<T> {\n\t// Downgrades metadata of type T from next version to this version.\n\tT downgradeFrom(T input);\n\t// Version of Metadata that this class will handle.\n\tInteger getManagedVersion();\n\t// Upgrades metadata of type T from previous version to this version.\n\tT upgradeFrom(T input);\n}", "des": "Responsible for upgrading and downgrading metadata versions for a specific metadata."}
{"index": 3852, "repo": "hudi-common-0.13.1", "code": "enum WriteConcurrencyMode {\n\t// Convert string value to WriteConcurrencyMode.\n\tstatic WriteConcurrencyMode fromValue(String value);\n\tboolean supportsOptimisticConcurrencyControl();\n\t// Getter for write concurrency mode.\n\tString value();\n\t// \n\tstatic WriteConcurrencyMode valueOf(String name);\n\t// ,  \n\tstatic WriteConcurrencyMode[] values();\n}", "des": "Different concurrency modes for write operations."}
{"index": 3853, "repo": "flink-gelly-1.16.2", "code": "class AdamicAdar.Result<T> {\n\tint compareTo(AdamicAdar.Result<T> o);\n\t// Get the Adamic-Adar score, equal to the sum over common neighbors of the inverse logarithm of degree.\n\torg.apache.flink.types.FloatValue getAdamicAdarScore();\n\t// Set the Adamic-Adar score, equal to the sum over common neighbors of the inverse logarithm of degree.\n\tvoid setAdamicAdarScore(org.apache.flink.types.FloatValue adamicAdarScore);\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "A result for the Adamic-Adar algorithm."}
{"index": 3854, "repo": "flink-gelly-1.16.2", "code": "class AnalyticHelper<T> {\n\t// Adds an accumulator by prepending the given name with a random string.\n\t<V,A extends Serializable>void addAccumulator(String name, org.apache.flink.api.common.accumulators.Accumulator<V,A> accumulator);\n\tvoid configure(org.apache.flink.configuration.Configuration parameters);\n\t// Gets the accumulator with the given name.\n\t<A> A getAccumulator(org.apache.flink.api.java.ExecutionEnvironment env, String accumulatorName);\n\tvoid open(int taskNumber, int numTasks);\n}", "des": "A GraphAnalytic computes over a DataSet and returns the results via Flink accumulators. This computation is cheaply performed in a terminating RichOutputFormat."}
{"index": 3855, "repo": "flink-gelly-1.16.2", "code": "class AverageClusteringCoefficient<K extends Comparable<K> & org.apache.flink.types.CopyableValue<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tAverageClusteringCoefficient.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tAverageClusteringCoefficient<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "The average clustering coefficient measures the mean connectedness of a graph. Scores range from 0.0 (no triangles) to 1.0 (complete graph)."}
{"index": 3856, "repo": "flink-gelly-1.16.2", "code": "class AverageClusteringCoefficient<K extends Comparable<K> & org.apache.flink.types.CopyableValue<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tAverageClusteringCoefficient.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tAverageClusteringCoefficient<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "The average clustering coefficient measures the mean connectedness of a graph. Scores range from 0.0 (no triangles) to 1.0 (complete graph)."}
{"index": 3857, "repo": "flink-gelly-1.16.2", "code": "class AverageClusteringCoefficient.Result {\n\tboolean equals(Object obj);\n\t// Get the average clustering coefficient.\n\tdouble getAverageClusteringCoefficient();\n\t// Get the number of vertices.\n\tlong getNumberOfVertices();\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "Wraps global clustering coefficient metrics."}
{"index": 3858, "repo": "flink-gelly-1.16.2", "code": "class AverageClusteringCoefficient.Result {\n\tboolean equals(Object obj);\n\t// Get the average clustering coefficient.\n\tdouble getAverageClusteringCoefficient();\n\t// Get the number of vertices.\n\tlong getNumberOfVertices();\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "Wraps global clustering coefficient metrics."}
{"index": 3859, "repo": "flink-gelly-1.16.2", "code": "interface BinaryResult<K> {\n\t// Get the first vertex ID.\n\tK getVertexId0();\n\t// Get the second vertex ID.\n\tK getVertexId1();\n\t// Set the first vertex ID.\n\tvoid setVertexId0(K vertexId0);\n\t// Set the second vertex ID.\n\tvoid setVertexId1(K vertexId1);\n}", "des": "A GraphAlgorithm result for a pair vertices."}
{"index": 3860, "repo": "flink-gelly-1.16.2", "code": "class BinaryResultBase<K> {\n\t// Get the first vertex ID.\n\tK getVertexId0();\n\t// Get the second vertex ID.\n\tK getVertexId1();\n\t// Set the first vertex ID.\n\tvoid setVertexId0(K vertexId0);\n\t// Set the second vertex ID.\n\tvoid setVertexId1(K vertexId1);\n\t// Output the result after transforming the vertex ID type.\n\t<T> TranslatableResult<T> translate(TranslateFunction<K,T> translator, TranslatableResult<T> reuse, org.apache.flink.util.Collector<TranslatableResult<T>> out);\n}", "des": "Base class for algorithm results for a pair of vertices."}
{"index": 3861, "repo": "flink-gelly-1.16.2", "code": "class ChecksumHashCode<T> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tChecksumHashCode.Checksum getResult();\n\t// All DataSetAnalytic processing must be terminated by an OutputFormat and obtained via accumulators rather than returned by a DataSet.\n\tChecksumHashCode<T> run(org.apache.flink.api.java.DataSet<T> input);\n}", "des": "Convenience method to get the count (number of elements) of a DataSet as well as the checksum (sum over element hashes)."}
{"index": 3862, "repo": "flink-gelly-1.16.2", "code": "class ChecksumHashCode<K,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tChecksumHashCode.Checksum getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tChecksumHashCode<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "Convenience method to get the count (number of elements) of a Graph as well as the checksum (sum over element hashes). The vertex and edge DataSets are processed in a single job and the resultant counts and checksums are merged locally."}
{"index": 3863, "repo": "flink-gelly-1.16.2", "code": "class CirculantGraph.OffsetRange {\n\tint compareTo(CirculantGraph.OffsetRange o);\n\t// Get the offset of the last index in the range.\n\tlong getLastOffset();\n\t// Get the range length.\n\tlong getLength();\n\t// Get the range offset.\n\tlong getOffset();\n\t// Return true if and only if the other range and this range share a common offset ID.\n\tboolean overlaps(CirculantGraph.OffsetRange other);\n}", "des": "Stores the start offset and length configuration for an offset range."}
{"index": 3864, "repo": "flink-gelly-1.16.2", "code": "class Collect<T> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tList<T> getResult();\n\t// All DataSetAnalytic processing must be terminated by an OutputFormat and obtained via accumulators rather than returned by a DataSet.\n\tCollect<T> run(org.apache.flink.api.java.DataSet<T> input);\n}", "des": "Collect the elements of a DataSet into a List."}
{"index": 3865, "repo": "flink-gelly-1.16.2", "code": "class Count<T> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tLong getResult();\n\t// All DataSetAnalytic processing must be terminated by an OutputFormat and obtained via accumulators rather than returned by a DataSet.\n\tCount<T> run(org.apache.flink.api.java.DataSet<T> input);\n}", "des": "Count the number of elements in a DataSet."}
{"index": 3866, "repo": "flink-gelly-1.16.2", "code": "class DataSetAnalyticBase<T,R> {\n\t// Execute the program and return the result.\n\tR execute();\n\t// Execute the program and return the result.\n\tR execute(String jobName);\n\t// All DataSetAnalytic processing must be terminated by an OutputFormat and obtained via accumulators rather than returned by a DataSet.\n\tDataSetAnalyticBase<T,R> run(org.apache.flink.api.java.DataSet<T> input);\n}", "des": "Base class for DataSetAnalytic."}
{"index": 3867, "repo": "flink-gelly-1.16.2", "code": "enum EdgeDirection {\n\t// \n\tstatic EdgeDirection valueOf(String name);\n\t// ,  \n\tstatic EdgeDirection[] values();\n}", "des": "The EdgeDirection is used to select a node's neighborhood by the Graph.groupReduceOnEdges(EdgesFunction, EdgeDirection), Graph.groupReduceOnEdges(EdgesFunctionWithVertexValue, EdgeDirection), Graph.groupReduceOnNeighbors(NeighborsFunction, EdgeDirection), Graph.groupReduceOnNeighbors(NeighborsFunctionWithVertexValue, EdgeDirection), Graph.reduceOnEdges(ReduceEdgesFunction, EdgeDirection) and Graph.reduceOnNeighbors(ReduceNeighborsFunction, EdgeDirection) methods."}
{"index": 3868, "repo": "flink-gelly-1.16.2", "code": "class EdgeMetrics<K extends Comparable<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tEdgeMetrics.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tEdgeMetrics<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "Compute the following edge metrics in a directed graph. - number of triangle triplets - number of rectangle triplets - maximum number of triangle triplets - maximum number of rectangle triplets"}
{"index": 3869, "repo": "flink-gelly-1.16.2", "code": "class EdgeMetrics<K extends Comparable<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tEdgeMetrics.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tEdgeMetrics<K,VV,EV> run(Graph<K,VV,EV> input);\n\t// The degree can be counted from either the edge source or target IDs.\n\tEdgeMetrics<K,VV,EV> setReduceOnTargetId(boolean reduceOnTargetId);\n}", "des": "Compute the following edge metrics in an undirected graph. - number of triangle triplets - number of rectangle triplets - maximum number of triangle triplets - maximum number of rectangle triplets"}
{"index": 3870, "repo": "flink-gelly-1.16.2", "code": "class EdgeMetrics.Result {\n\tboolean equals(Object obj);\n\t// Get the maximum rectangle triplets.\n\tlong getMaximumRectangleTriplets();\n\t// Get the maximum triangle triplets.\n\tlong getMaximumTriangleTriplets();\n\t// Get the number of rectangle triplets.\n\tlong getNumberOfRectangleTriplets();\n\t// Get the number of triangle triplets.\n\tlong getNumberOfTriangleTriplets();\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "Wraps edge metrics."}
{"index": 3871, "repo": "flink-gelly-1.16.2", "code": "class EdgeMetrics.Result {\n\tboolean equals(Object obj);\n\t// Get the maximum rectangle triplets.\n\tlong getMaximumRectangleTriplets();\n\t// Get the maximum triangle triplets.\n\tlong getMaximumTriangleTriplets();\n\t// Get the number of rectangle triplets.\n\tlong getNumberOfRectangleTriplets();\n\t// Get the number of triangle triplets.\n\tlong getNumberOfTriangleTriplets();\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "Wraps edge metrics."}
{"index": 3872, "repo": "flink-gelly-1.16.2", "code": "enum EdgeOrder {\n\t// Returns a bitmask used for marking whether an edge is in the same direction as in the original edge set (FORWARD), is flipped relative to the original edge set (REVERSE), or both (MUTUAL).\n\tbyte getBitmask();\n\t// \n\tstatic EdgeOrder valueOf(String name);\n\t// ,  \n\tstatic EdgeOrder[] values();\n}", "des": "These bitmasks are used by edge-flipping algorithms to mark the edge order relative to the original edge direction."}
{"index": 3873, "repo": "flink-gelly-1.16.2", "code": "class GlobalClusteringCoefficient<K extends Comparable<K> & org.apache.flink.types.CopyableValue<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tGlobalClusteringCoefficient.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tGlobalClusteringCoefficient<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "The global clustering coefficient measures the connectedness of a graph. Scores range from 0.0 (no triangles) to 1.0 (complete graph)."}
{"index": 3874, "repo": "flink-gelly-1.16.2", "code": "class GlobalClusteringCoefficient<K extends Comparable<K> & org.apache.flink.types.CopyableValue<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tGlobalClusteringCoefficient.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tGlobalClusteringCoefficient<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "The global clustering coefficient measures the connectedness of a graph. Scores range from 0.0 (no triangles) to 1.0 (complete graph)."}
{"index": 3875, "repo": "flink-gelly-1.16.2", "code": "class GlobalClusteringCoefficient.Result {\n\tboolean equals(Object obj);\n\t// Get the global clustering coefficient score.\n\tdouble getGlobalClusteringCoefficientScore();\n\t// Get the number of triangles.\n\tlong getNumberOfTriangles();\n\t// Get the number of triplets.\n\tlong getNumberOfTriplets();\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "Wraps global clustering coefficient metrics."}
{"index": 3876, "repo": "flink-gelly-1.16.2", "code": "class GlobalClusteringCoefficient.Result {\n\tboolean equals(Object obj);\n\t// Get the global clustering coefficient score.\n\tdouble getGlobalClusteringCoefficientScore();\n\t// Get the number of triangles.\n\tlong getNumberOfTriangles();\n\t// Get the number of triplets.\n\tlong getNumberOfTriplets();\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "Wraps global clustering coefficient metrics."}
{"index": 3877, "repo": "flink-gelly-1.16.2", "code": "interface GraphAnalytic<K,VV,EV,T> {\n\t// Execute the program and return the result.\n\tT execute();\n\t// Execute the program and return the result.\n\tT execute(String jobName);\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tT getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tGraphAnalytic<K,VV,EV,T> run(Graph<K,VV,EV> input);\n}", "des": "A GraphAnalytic is similar to a GraphAlgorithm but is terminal and results are retrieved via accumulators. A Flink program has a single point of execution. A GraphAnalytic defers execution to the user to allow composing multiple analytics and algorithms into a single program."}
{"index": 3878, "repo": "flink-gelly-1.16.2", "code": "class GraphAnalyticBase<K,VV,EV,T> {\n\t// Execute the program and return the result.\n\tT execute();\n\t// Execute the program and return the result.\n\tT execute(String jobName);\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tGraphAnalytic<K,VV,EV,T> run(Graph<K,VV,EV> input);\n\t// Set the parallelism for this analytic's operators.\n\tGraphAnalyticBase<K,VV,EV,T> setParallelism(int parallelism);\n}", "des": "Base class for GraphAnalytic."}
{"index": 3879, "repo": "flink-gelly-1.16.2", "code": "interface GraphGenerator<K,VV,EV> {\n\t// Generates the configured graph.\n\tGraph<K,VV,EV> generate();\n\t// Override the operator parallelism.\n\tGraphGenerator<K,VV,EV> setParallelism(int parallelism);\n}", "des": "Graph generators shall be - parallelizable, in order to create large datasets - scale-free, generating the same graph regardless of parallelism - thrifty, using as few operators as possible"}
{"index": 3880, "repo": "flink-gelly-1.16.2", "code": "class HITS<K,VV,EV> {\n\t// Merge the other configuration into this algorithm's after the call to GraphAlgorithmWrappingBase.canMergeConfigurationWith(org.apache.flink.graph.utils.proxy.GraphAlgorithmWrappingBase) has checked that the configurations can be merged.\n\tprotected void mergeConfiguration(GraphAlgorithmWrappingBase other);\n\t// The implementation of the algorithm, renamed from GraphAlgorithm.run(Graph).\n\torg.apache.flink.api.java.DataSet<HITS.Result<K>> runInternal(Graph<K,VV,EV> input);\n}", "des": "Hyperlink-Induced Topic Search computes two interdependent scores for every vertex in a directed graph. A good \"hub\" links to good \"authorities\" and good \"authorities\" are linked from good \"hubs\"."}
{"index": 3881, "repo": "flink-gelly-1.16.2", "code": "class HITS.Result<T> {\n\t// Get the authority score.\n\torg.apache.flink.types.DoubleValue getAuthorityScore();\n\t// Get the hub score.\n\torg.apache.flink.types.DoubleValue getHubScore();\n\t// Set the authority score.\n\tvoid setAuthorityScore(org.apache.flink.types.DoubleValue authorityScore);\n\t// Set the hub score.\n\tvoid setHubScore(org.apache.flink.types.DoubleValue hubScore);\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "A result for the HITS algorithm."}
{"index": 3882, "repo": "flink-gelly-1.16.2", "code": "class MessageCombiner<K,Message> {\n\t// Combines messages sent from different vertices to a target vertex.\n\tabstract void combineMessages(MessageIterator<Message> messages);\n\t// Sends the combined message to the target vertex.\n\tvoid sendCombinedMessage(Message combinedMessage);\n}", "des": "The base class for combining messages sent during a VertexCentricIteration."}
{"index": 3883, "repo": "flink-gelly-1.16.2", "code": "class MurmurHash {\n\t// Finalize and return the MurmurHash output.\n\tint hash();\n\t// Process a double value.\n\tMurmurHash hash(double input);\n\t// Process a float value.\n\tMurmurHash hash(float input);\n\t// Process an integer value.\n\tMurmurHash hash(int input);\n\t// Process a long value.\n\tMurmurHash hash(long input);\n\t// Re-initialize the MurmurHash state.\n\tMurmurHash reset();\n}", "des": "A resettable implementation of the 32-bit MurmurHash algorithm."}
{"index": 3884, "repo": "flink-gelly-1.16.2", "code": "enum OptionalBoolean.State {\n\t// \n\tstatic OptionalBoolean.State valueOf(String name);\n\t// ,  \n\tstatic OptionalBoolean.State[] values();\n}", "des": "States for OptionalBoolean."}
{"index": 3885, "repo": "flink-gelly-1.16.2", "code": "class PageRank.Result<T> {\n\t// Get the PageRank score.\n\torg.apache.flink.types.DoubleValue getPageRankScore();\n\t// Set the PageRank score.\n\tvoid setPageRankScore(org.apache.flink.types.DoubleValue pageRankScore);\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "A result for the PageRank algorithm."}
{"index": 3886, "repo": "flink-gelly-1.16.2", "code": "class Simplify<K extends Comparable<K>,VV,EV> {\n\t// First test whether the algorithm configurations can be merged before the call to GraphAlgorithmWrappingBase.mergeConfiguration(org.apache.flink.graph.utils.proxy.GraphAlgorithmWrappingBase).\n\tprotected boolean canMergeConfigurationWith(GraphAlgorithmWrappingBase other);\n\t// The implementation of the algorithm, renamed from GraphAlgorithm.run(Graph).\n\tGraph<K,VV,EV> runInternal(Graph<K,VV,EV> input);\n}", "des": "Add symmetric edges and remove self-loops and duplicate edges from an undirected graph."}
{"index": 3887, "repo": "flink-gelly-1.16.2", "code": "interface TertiaryResult<K> {\n\t// Get the first vertex ID.\n\tK getVertexId0();\n\t// Get the second vertex ID.\n\tK getVertexId1();\n\t// Get the third vertex ID.\n\tK getVertexId2();\n\t// Set the first vertex ID.\n\tvoid setVertexId0(K vertexId0);\n\t// Set the second vertex ID.\n\tvoid setVertexId1(K vertexId1);\n\t// Set the third vertex ID.\n\tvoid setVertexId2(K vertexId2);\n}", "des": "A GraphAlgorithm result for three vertices."}
{"index": 3888, "repo": "flink-gelly-1.16.2", "code": "class TranslateEdgeValues<K,VV,OLD,NEW> {\n\t// First test whether the algorithm configurations can be merged before the call to GraphAlgorithmWrappingBase.mergeConfiguration(org.apache.flink.graph.utils.proxy.GraphAlgorithmWrappingBase).\n\tprotected boolean canMergeConfigurationWith(GraphAlgorithmWrappingBase other);\n\t// The implementation of the algorithm, renamed from GraphAlgorithm.run(Graph).\n\tGraph<K,VV,NEW> runInternal(Graph<K,VV,OLD> input);\n}", "des": "Translate Edge values using the given TranslateFunction."}
{"index": 3889, "repo": "flink-gelly-1.16.2", "code": "class TranslateGraphIds<OLD,NEW,VV,EV> {\n\t// First test whether the algorithm configurations can be merged before the call to GraphAlgorithmWrappingBase.mergeConfiguration(org.apache.flink.graph.utils.proxy.GraphAlgorithmWrappingBase).\n\tprotected boolean canMergeConfigurationWith(GraphAlgorithmWrappingBase other);\n\t// The implementation of the algorithm, renamed from GraphAlgorithm.run(Graph).\n\tGraph<NEW,VV,EV> runInternal(Graph<OLD,VV,EV> input);\n}", "des": "Translate Vertex and Edge IDs of a Graph using the given TranslateFunction."}
{"index": 3890, "repo": "flink-gelly-1.16.2", "code": "class TranslateVertexValues<K,OLD,NEW,EV> {\n\t// First test whether the algorithm configurations can be merged before the call to GraphAlgorithmWrappingBase.mergeConfiguration(org.apache.flink.graph.utils.proxy.GraphAlgorithmWrappingBase).\n\tprotected boolean canMergeConfigurationWith(GraphAlgorithmWrappingBase other);\n\t// The implementation of the algorithm, renamed from GraphAlgorithm.run(Graph).\n\tGraph<K,NEW,EV> runInternal(Graph<K,OLD,EV> input);\n}", "des": "Translate Vertex values using the given TranslateFunction."}
{"index": 3891, "repo": "flink-gelly-1.16.2", "code": "class TriadicCensus<K extends Comparable<K> & org.apache.flink.types.CopyableValue<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tTriadicCensus.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tTriadicCensus<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "A triad is formed by three connected or unconnected vertices in a graph. The triadic census counts the occurrences of each type of triad."}
{"index": 3892, "repo": "flink-gelly-1.16.2", "code": "class TriadicCensus<K extends Comparable<K> & org.apache.flink.types.CopyableValue<K>,VV,EV> {\n\t// This method must be called after the program has executed. 1) \"run\" analytics and algorithms 2) call ExecutionEnvironment.execute() 3) get analytic results\n\tTriadicCensus.Result getResult();\n\t// All GraphAnalytic processing must be terminated by an OutputFormat.\n\tTriadicCensus<K,VV,EV> run(Graph<K,VV,EV> input);\n}", "des": "A triad is formed by three connected or unconnected vertices in a graph. The triadic census counts the occurrences of each type of triad."}
{"index": 3893, "repo": "flink-gelly-1.16.2", "code": "class TriangleListing.Result<T> {\n\t// Get the bitmask indicating the presence of the six potential connecting edges.\n\torg.apache.flink.types.ByteValue getBitmask();\n\tvoid setBitmask(byte bitmask);\n\t// Set the bitmask indicating the presence of the six potential connecting edges.\n\tvoid setBitmask(org.apache.flink.types.ByteValue bitmask);\n\t// A human-readable representation of this value.\n\tString toPrintableString();\n}", "des": "A result for the directed Triangle Listing algorithm."}
{"index": 3894, "repo": "flink-gelly-1.16.2", "code": "interface UnaryResult<K> {\n\t// Get the first vertex ID.\n\tK getVertexId0();\n\t// Set the first vertex ID.\n\tvoid setVertexId0(K vertexId0);\n}", "des": "A GraphAlgorithm result for a single vertex."}
{"index": 3895, "repo": "flink-gelly-1.16.2", "code": "class UnaryResultBase<K> {\n\t// Get the first vertex ID.\n\tK getVertexId0();\n\t// Set the first vertex ID.\n\tvoid setVertexId0(K vertexId0);\n\t// Output the result after transforming the vertex ID type.\n\t<T> TranslatableResult<T> translate(TranslateFunction<K,T> translator, TranslatableResult<T> reuse, org.apache.flink.util.Collector<TranslatableResult<T>> out);\n}", "des": "Base class for algorithm results for a single vertex."}
{"index": 3896, "repo": "flink-gelly-1.16.2", "code": "class ValueArrayFactory {\n\t// Produce a ValueArray for the given Value type.\n\tstatic <T> ValueArray<T> createValueArray(Class<? extends org.apache.flink.types.Value> cls);\n\t// Produce a ValueArray for the given Value type with the given bounded size.\n\tstatic <T> ValueArray<T> createValueArray(Class<? extends org.apache.flink.types.Value> cls, int bytes);\n}", "des": "A factory generator for ValueArray types is necessary because the contained Value types do not currently implement a common interface for creating a ValueArray. Algorithms must instantiate classes at runtime when the type information has been erased."}
{"index": 3897, "repo": "flink-gelly-1.16.2", "code": "class VertexCentricConfiguration {\n\t// Adds a data set as a broadcast set to the compute function.\n\tvoid addBroadcastSet(String name, org.apache.flink.api.java.DataSet<?> data);\n\t// Get the broadcast variables of the compute function.\n\tList<org.apache.flink.api.java.tuple.Tuple2<String,org.apache.flink.api.java.DataSet<?>>> getBcastVars();\n}", "des": "A VertexCentricConfiguration object can be used to set the iteration name and degree of parallelism, to register aggregators and use broadcast sets in the ComputeFunction."}
{"index": 3898, "repo": "freemarker-2.3.32", "code": "Class AllHttpScopesHashModel {\n\t// Gets a TemplateModel from the hash.\n\tTemplateModel get(java.lang.String key);\n\t// Stores a model in the hash so that it doesn't show up in keys() and values() methods.\n\tvoid putUnlistedModel(java.lang.String key, TemplateModel model);\n}", "des": "An extension of SimpleHash that looks up keys in the hash, then in the request, session, and servlet context scopes. Makes \"Application\", \"Session\" and \"Request\" keys largely obsolete, however we keep them for backward compatibility (also, \"Request\" is required for proper operation of JSP taglibs). It is on purpose that we didn't override keys and values methods. That way, only those variables assigned into the hash directly by a subclass of FreemarkerServlet that overrides preTemplateProcess) are discovered as \"page\" variables by the FM JSP PageContext implementation."}
{"index": 3899, "repo": "freemarker-2.3.32", "code": "Class ArrayModel {\n\t// Retrieves the i-th template model in this sequence.\n\tTemplateModel get(int index);\n\t// Tells whether the model is empty.\n\tboolean isEmpty();\n\t// Retrieves a template model iterator that is used to iterate over the elements in this collection.\n\tTemplateModelIterator iterator();\n\tint size();\n}", "des": ""}
{"index": 3900, "repo": "freemarker-2.3.32", "code": "Class Breakpoint {\n\tint compareTo(java.lang.Object o);\n\tboolean equals(java.lang.Object o);\n\t// Returns the line number of the breakpoint\n\tint getLine();\n\t// Returns the template name and the line number separated with a colon\n\tjava.lang.String getLocationString();\n\t// Returns the template name of the breakpoint\n\tjava.lang.String getTemplateName();\n}", "des": "Represents a breakpoint location consisting of a template name and a line number."}
{"index": 3901, "repo": "freemarker-2.3.32", "code": "Class CollectionModel {\n\t// Retrieves the i-th object from the collection, wrapped as a TemplateModel.\n\tTemplateModel get(int index);\n\t// Tells if get(int) will always fail for this object.\n\tboolean getSupportsIndexedAccess();\n\t// Retrieves a template model iterator that is used to iterate over the elements in this collection.\n\tTemplateModelIterator iterator();\n\tint size();\n}", "des": ""}
{"index": 3902, "repo": "freemarker-2.3.32", "code": "Class CSSOutputFormat {\n\t// Returns the MIME type of the output format.\n\tjava.lang.String getMimeType();\n\t// The short name used to refer to this format (like in the #ftl header).\n\tjava.lang.String getName();\n\t// Tells if this output format allows inserting TemplateMarkupOutputModel-s of another output formats into it.\n\tboolean isOutputFormatMixingAllowed();\n}", "des": "Represents the CSS output format (MIME type \"text/css\", name \"CSS\"). This format doesn't support escaping."}
{"index": 3903, "repo": "freemarker-2.3.32", "code": "Class DateModel {\n\t// Returns the date value.\n\tjava.util.Date getAsDate();\n\t// Returns the type of the date.\n\tint getDateType();\n}", "des": "Wraps arbitrary subclass of Date into a reflective model. Beside acting as a TemplateDateModel, you can call all Java methods on these objects as well."}
{"index": 3904, "repo": "freemarker-2.3.32", "code": "Interface DebuggedEnvironment {\n\t// Returns a unique identifier for this environment\n\tlong getId();\n\t// Resumes the processing of the environment in the remote VM after it was stopped on a breakpoint.\n\tvoid resume();\n\t// Stops the processing of the environment after it was stopped on a breakpoint.\n\tvoid stop();\n}", "des": "Represents the debugger-side mirror of a debugged Environment object in the remote VM. This interface extends DebugModel, and the properties of the Environment are exposed as hash keys on it. Specifically, the following keys are supported: \"currentNamespace\", \"dataModel\", \"globalNamespace\", \"knownVariables\", \"mainNamespace\", and \"template\"."}
{"index": 3905, "repo": "freemarker-2.3.32", "code": "Class DeepUnwrap {\n\t// Same as unwrap(TemplateModel), but it doesn't throw exception if it doesn't know how to unwrap the model, but rather returns it as-is.\n\tstatic java.lang.Object permissiveUnwrap(TemplateModel model);\n\t// Unwraps TemplateModel-s recursively.\n\tstatic java.lang.Object unwrap(TemplateModel model);\n}", "des": "Utility methods for unwrapping TemplateModel-s."}
{"index": 3906, "repo": "freemarker-2.3.32", "code": "Class DefaultArrayAdapter {\n\t// Factory method for creating new adapter instances.\n\tstatic DefaultArrayAdapter adapt(java.lang.Object array, ObjectWrapperAndUnwrapper wrapper);\n\t// Retrieves the underlying object, or some other object semantically equivalent to its value narrowed by the class hint.\n\tjava.lang.Object getAdaptedObject(java.lang.Class hint);\n}", "des": "Adapts an array of a non-primitive elements to the corresponding TemplateModel interface(s), most importantly to TemplateHashModelEx. If you aren't wrapping an already existing array, but build a sequence specifically to be used from a template, also consider using SimpleSequence (see comparison there)."}
{"index": 3907, "repo": "freemarker-2.3.32", "code": "Class EnumerationModel {\n\t// Returns Enumeration.hasMoreElements().\n\tboolean getAsBoolean();\n\t// Calls underlying Enumeration.nextElement().\n\tboolean hasNext();\n\t// This allows the enumeration to be used in a <#list> block.\n\tTemplateModelIterator iterator();\n\t// Calls underlying Enumeration.nextElement() and wraps the result.\n\tTemplateModel next();\n}", "des": ""}
{"index": 3908, "repo": "freemarker-2.3.32", "code": "Class EnvironmentSuspendedEvent {\n\t// The environment that was suspended\n\tDebuggedEnvironment getEnvironment();\n\t// The line number in the template where the execution of the environment was suspended.\n\tint getLine();\n\t// The name of the template where the execution of the environment was suspended\n\tjava.lang.String getName();\n}", "des": "Event describing a suspension of an environment (ie because it hit a breakpoint)."}
{"index": 3909, "repo": "freemarker-2.3.32", "code": "Class FileExtensionMatcher {\n\t// Fluid API variation of setCaseInsensitive(boolean)\n\tFileExtensionMatcher caseInsensitive(boolean caseInsensitive);\n\tboolean isCaseInsensitive();\n\tboolean matches(java.lang.String sourceName, java.lang.Object templateSource);\n\t// Sets if the matching will be case insensitive (UNICODE compliant); default is true.\n\tvoid setCaseInsensitive(boolean caseInsensitive);\n}", "des": "Matches the file extension; unlike other matchers, by default case insensitive. A name (a path) is considered to have the given extension exactly if it ends with a dot plus the extension."}
{"index": 3910, "repo": "freemarker-2.3.32", "code": "Class FileNameGlobMatcher {\n\t// Fluid API variation of setCaseInsensitive(boolean)\n\tFileNameGlobMatcher caseInsensitive(boolean caseInsensitive);\n\tboolean isCaseInsensitive();\n\tboolean matches(java.lang.String sourceName, java.lang.Object templateSource);\n\t// Sets if the matching will be case insensitive (UNICODE compliant); default is false.\n\tvoid setCaseInsensitive(boolean caseInsensitive);\n}", "des": "As opposed to PathGlobMatcher, it only compares the \"file name\" part (the part after the last /) of the source name with the given glob. For example, the file name glob *.ftlh matches both foo.ftlh and foo/bar.ftlh. With other words, that file name glob is equivalent with the **/*.ftlh) path glob ( PathGlobMatcher)."}
{"index": 3911, "repo": "freemarker-2.3.32", "code": "Class IteratorModel {\n\t// Returns Iterator.hasNext().\n\tboolean getAsBoolean();\n\t// Calls underlying Iterator.hasNext().\n\tboolean hasNext();\n\t// This allows the iterator to be used in a <#list> block.\n\tTemplateModelIterator iterator();\n\t// Calls underlying Iterator.next() and wraps the result.\n\tTemplateModel next();\n}", "des": ""}
{"index": 3912, "repo": "freemarker-2.3.32", "code": "Class JavaScriptOutputFormat {\n\t// Returns the MIME type of the output format.\n\tjava.lang.String getMimeType();\n\t// The short name used to refer to this format (like in the #ftl header).\n\tjava.lang.String getName();\n\t// Tells if this output format allows inserting TemplateMarkupOutputModel-s of another output formats into it.\n\tboolean isOutputFormatMixingAllowed();\n}", "des": "Represents the JavaScript output format (MIME type \"application/javascript\", name \"JavaScript\"). This format doesn't support escaping."}
{"index": 3913, "repo": "freemarker-2.3.32", "code": "Class JSONOutputFormat {\n\t// Returns the MIME type of the output format.\n\tjava.lang.String getMimeType();\n\t// The short name used to refer to this format (like in the #ftl header).\n\tjava.lang.String getName();\n\t// Tells if this output format allows inserting TemplateMarkupOutputModel-s of another output formats into it.\n\tboolean isOutputFormatMixingAllowed();\n}", "des": "Represents the JSON output format (MIME type \"application/json\", name \"JSON\"). This format doesn't support escaping."}
{"index": 3914, "repo": "freemarker-2.3.32", "code": "Class JythonHashModel {\n\t// Returns either object.__findattr__(\"keys\").__call__() or object.__findattr__(\"keySet\").__call__().\n\tTemplateCollectionModel keys();\n\t// Returns PyObject.__len__().\n\tint size();\n\t// Returns object.__findattr__(\"values\").__call__().\n\tTemplateCollectionModel values();\n}", "des": "Model for Jython dictionaries (PyDictionary and PyStringMap). Note that the basic JythonModel already provides access to the PyObject.__finditem__(String) method. This class only adds TemplateHashModelEx functionality in a somewhat skewed way. One could say it even violates TemplateHashModelEx semantics, as both the returned keys and values are only those from the item mapping, while the get() method works for attributes as well. However, in practice when you ask for dict?keys inside a template, you'll really want to retrieve only items, not attributes so this is considered OK."}
{"index": 3915, "repo": "freemarker-2.3.32", "code": "Class JythonSequenceModel {\n\t// Returns PyObject.__finditem__(int).\n\tTemplateModel get(int index);\n\t// Retrieves a template model iterator that is used to iterate over the elements in this collection.\n\tTemplateModelIterator iterator();\n\t// Returns PyObject.__len__().\n\tint size();\n}", "des": "Model for Jython sequence objects (PySequence descendants)."}
{"index": 3916, "repo": "freemarker-2.3.32", "code": "Class JythonVersionAdapter {\n\t// Returns pyObject.__class__.__name__\n\tabstract java.lang.String getPythonClassName(org.python.core.PyObject pyObject);\n\t// Returns obj instanceof Py[Java]Instance.\n\tabstract boolean isPyInstance(java.lang.Object obj);\n\t// Returns ((PyInstance) py[Java]Instance).__tojava__(java.lang.Object.class).\n\tabstract java.lang.Object pyInstanceToJava(java.lang.Object pyInstance);\n}", "des": "Functions that has a different implementation depending on the Jython version used. This was introduced to work around class-loading errors because of different classes/methods being present in different Jython versions."}
{"index": 3917, "repo": "freemarker-2.3.32", "code": "Class JythonWrapper {\n\t// Sets whether attributes shadow items in wrapped objects.\n\tvoid setAttributesShadowItems(boolean attributesShadowItems);\n\t// Sets whether this wrapper caches model instances.\n\tvoid setUseCache(boolean useCache);\n\t// Coerces a template model into a PyObject.\n\torg.python.core.PyObject unwrap(TemplateModel model);\n\t// Wraps the passed Jython object into a FreeMarker template model.\n\tTemplateModel wrap(java.lang.Object obj);\n}", "des": "An object wrapper that wraps Jython objects into FreeMarker template models and vice versa."}
{"index": 3918, "repo": "freemarker-2.3.32", "code": "Class LegacyDefaultMemberAccessPolicy {\n\t// Returns the ClassMemberAccessPolicy that encapsulates the member access policy for a given class.\n\tClassMemberAccessPolicy forClass(java.lang.Class<?> containingClass);\n\t// If this returns true, we won't invoke the probably more expensive lookup to figure out if Object.toString() (including its overridden variants) is exposed for a given object.\n\tboolean isToStringAlwaysExposed();\n}", "des": "Legacy blacklist based member access policy, used only to keep old behavior, as it can't provide meaningful safety. Do not use it if you allow untrusted users to edit templates! Use WhitelistMemberAccessPolicy then."}
{"index": 3919, "repo": "freemarker-2.3.32", "code": "Class MapKeyValuePairIterator {\n\t// Similar to Iterator.hasNext().\n\tboolean hasNext();\n\t// Similar to Iterator.next().\n\tTemplateHashModelEx2.KeyValuePair next();\n}", "des": "Implementation of TemplateHashModelEx2.KeyValuePairIterator for a TemplateHashModelEx2 that wraps or otherwise uses a Map internally."}
{"index": 3920, "repo": "freemarker-2.3.32", "code": "Interface MemberAccessPolicy {\n\t// Returns the ClassMemberAccessPolicy that encapsulates the member access policy for a given class.\n\tClassMemberAccessPolicy forClass(java.lang.Class<?> contextClass);\n\t// If this returns true, we won't invoke the probably more expensive lookup to figure out if Object.toString() (including its overridden variants) is exposed for a given object.\n\tboolean isToStringAlwaysExposed();\n}", "des": "Implement this to restrict what class members (methods, fields, constructors) are accessible from templates. Note, however, that BeansWrapper and its subclasses doesn't discover all members on the first place, and the MemberAccessPolicy just removes from that set of members, never adds to it. Practically speaking, it's the last filter in the chain."}
{"index": 3921, "repo": "freemarker-2.3.32", "code": "Class MergingTemplateConfigurationFactory {\n\t// Returns (maybe creates) the TemplateConfiguration for the given template source.\n\tTemplateConfiguration get(java.lang.String sourceName, java.lang.Object templateSource);\n\t// Calls TemplateConfiguration.setParentConfiguration(Configuration) on each enclosed TemplateConfiguration and TemplateConfigurationFactory.setConfiguration(Configuration) on each enclosed TemplateConfigurationFactory objects.\n\tprotected void setConfigurationOfChildren(Configuration cfg);\n}", "des": "Returns the merged results of all the child factories. The factories are merged in the order as they were added. null results from the child factories will be ignored. If all child factories return null, the result of this factory will be null too."}
{"index": 3922, "repo": "freemarker-2.3.32", "code": "Class NormalizeNewlines {\n\t// Returns a writer that will be used by the engine to feed the transformation input to the transform.\n\tjava.io.Writer getWriter(java.io.Writer out, java.util.Map args);\n\t// Performs newline normalization on FreeMarker output.\n\tvoid transform(java.io.Reader in, java.io.Writer out);\n}", "des": ""}
{"index": 3923, "repo": "freemarker-2.3.32", "code": "Class NullCacheStorage {\n\tvoid clear();\n\tjava.lang.Object get(java.lang.Object key);\n\t// Always returns 0.\n\tint getSize();\n\t// Returns true if this instance of cache storage is concurrently accessible from multiple threads without synchronization.\n\tboolean isConcurrent();\n\tvoid put(java.lang.Object key, java.lang.Object value);\n\tvoid remove(java.lang.Object key);\n}", "des": "A cache storage that doesn't store anything. Use this if you don't want caching."}
{"index": 3924, "repo": "freemarker-2.3.32", "code": "Interface ObjectWrapperAndUnwrapper {\n\t// Attempts to unwrap a TemplateModel to a plain Java object that's the instance of the given class (or is null).\n\tjava.lang.Object tryUnwrapTo(TemplateModel tm, java.lang.Class<?> targetClass);\n\t// Unwraps a TemplateModel to a plain Java object.\n\tjava.lang.Object unwrap(TemplateModel tm);\n}", "des": "Experimental - subject to change: Adds functionality to ObjectWrapper that creates a plain Java object from a TemplateModel. This is usually implemented by ObjectWrapper-s and reverses ObjectWrapper.wrap(Object). However, an implementation of this interface should make a reasonable effort to \"unwrap\" TemplateModel-s that wasn't the result of object wrapping (such as those created directly in FTL), or which was created by another ObjectWrapper. The author of an ObjectWrapperAndUnwrapper should be aware of the TemplateModelAdapter and WrapperTemplateModel interfaces, which should be used for unwrapping if the TemplateModel implements them."}
{"index": 3925, "repo": "freemarker-2.3.32", "code": "Class OptInTemplateClassResolver {\n\t// Gets a Class based on the class name.\n\tjava.lang.Class resolve(java.lang.String className, Environment env, Template template);\n\t// Extract the template name from the template object which will be matched against the trusted template names and pattern.\n\tprotected java.lang.String safeGetTemplateName(Template template);\n}", "des": "A TemplateClassResolver that resolves only the classes whose name was specified in the constructor."}
{"index": 3926, "repo": "freemarker-2.3.32", "code": "Class OverloadedMethodsModel {\n\t// Invokes the method, passing it the arguments from the list.\n\tjava.lang.Object exec(java.util.List arguments);\n\t// Retrieves the i-th template model in this sequence.\n\tTemplateModel get(int index);\n\tint size();\n}", "des": "Wraps a set of same-name overloaded methods behind TemplateMethodModel interface, like if it was a single method, chooses among them behind the scenes on call-time based on the argument values."}
{"index": 3927, "repo": "freemarker-2.3.32", "code": "Class PathGlobMatcher {\n\t// Fluid API variation of setCaseInsensitive(boolean)\n\tPathGlobMatcher caseInsensitive(boolean caseInsensitive);\n\tboolean isCaseInsensitive();\n\tboolean matches(java.lang.String sourceName, java.lang.Object templateSource);\n\t// Sets if the matching will be case insensitive (UNICODE compliant); default is false.\n\tvoid setCaseInsensitive(boolean caseInsensitive);\n}", "des": "Matches the whole template source name (also known as template source path) with the given glob. Note that the template source name is relative to the template storage root defined by the TemplateLoader; it's not the full path of a file on the file system."}
{"index": 3928, "repo": "freemarker-2.3.32", "code": "Class PlainTextOutputFormat {\n\t// Returns the MIME type of the output format.\n\tjava.lang.String getMimeType();\n\t// The short name used to refer to this format (like in the #ftl header).\n\tjava.lang.String getName();\n\t// Tells if this output format allows inserting TemplateMarkupOutputModel-s of another output formats into it.\n\tboolean isOutputFormatMixingAllowed();\n}", "des": "Represents the plain text output format (MIME type \"text/plain\", name \"plainText\"). This format doesn't support escaping. This format doesn't allow mixing in template output values of other output formats."}
{"index": 3929, "repo": "freemarker-2.3.32", "code": "Class ServletContextHashModel {\n\t// Gets a TemplateModel from the hash.\n\tTemplateModel get(java.lang.String key);\n\t// Returns the underlying servlet.\n\tjavax.servlet.GenericServlet getServlet();\n\tboolean isEmpty();\n}", "des": "TemplateHashModel wrapper for a ServletContext attributes."}
{"index": 3930, "repo": "freemarker-2.3.32", "code": "Class SimpleDate {\n\t// Returns the date value.\n\tjava.util.Date getAsDate();\n\t// Returns the type of the date.\n\tint getDateType();\n}", "des": "A simple implementation of the TemplateDateModel interface. Note that this class is immutable."}
{"index": 3931, "repo": "freemarker-2.3.32", "code": "Class SimpleMethodModel {\n\t// Invokes the method, passing it the arguments from the list.\n\tjava.lang.Object exec(java.util.List arguments);\n\t// Implementation of experimental interface; don't use it, no backward compatibility guarantee!\n\tjava.lang.Object[] explainTypeError(java.lang.Class[] expectedClasses);\n\t// Retrieves the i-th template model in this sequence.\n\tTemplateModel get(int index);\n\tprotected java.lang.reflect.Member getMember();\n\tint size();\n}", "des": "A class that will wrap a reflected method call into a TemplateMethodModel interface. It is used by BeanModel to wrap reflected method calls for non-overloaded methods."}
{"index": 3932, "repo": "freemarker-2.3.32", "code": "Class SimpleObjectWrapper {\n\t// Called if a type other than the simple ones we know about is passed in.\n\tprotected TemplateModel handleUnknownType(java.lang.Object obj);\n\t// Wraps an object to a TemplateModel that exposes the object's \"native\" (usually, Java) API.\n\tTemplateHashModel wrapAsAPI(java.lang.Object obj);\n}", "des": "A restricted object wrapper that will not expose arbitrary object, just those that directly correspond to the TemplateModel sub-interfaces (String, Map and such). If it had to wrap other kind of objects, it will throw exception. It will also block ?api calls on the values it wraps."}
{"index": 3933, "repo": "freemarker-2.3.32", "code": "Class SimpleScalar {\n\t// Returns the String representation of this model.\n\tjava.lang.String getAsString();\n\t// Same as calling the constructor, except that for a null parameter it returns null.\n\tstatic SimpleScalar newInstanceOrNull(java.lang.String s);\n}", "des": "A simple implementation of the TemplateScalarModel interface, using a String. As of version 2.0 this object is immutable."}
{"index": 3934, "repo": "freemarker-2.3.32", "code": "Class SimpleSequence {\n\t// Adds an arbitrary object to the end of this sequence.\n\tvoid add(java.lang.Object obj);\n\t// Returns the item at the specified index of the list.\n\tTemplateModel get(int index);\n\tint size();\n\tSimpleSequence synchronizedWrapper();\n}", "des": "A simple implementation of the TemplateSequenceModel interface, using its own underlying List for storing the list items. If you are wrapping an already existing List or array, you should certainly use DefaultMapAdapter or DefaultArrayAdapter (see comparison below)."}
{"index": 3935, "repo": "freemarker-2.3.32", "code": "Class SoftCacheStorage {\n\tvoid clear();\n\tjava.lang.Object get(java.lang.Object key);\n\t// Returns a close approximation of the number of cache entries.\n\tint getSize();\n\t// Returns true if the underlying Map is a ConcurrentMap.\n\tboolean isConcurrent();\n\tvoid put(java.lang.Object key, java.lang.Object value);\n\tvoid remove(java.lang.Object key);\n}", "des": "Soft cache storage is a cache storage that uses SoftReference objects to hold the objects it was passed, therefore allows the garbage collector to purge the cache when it determines that it wants to free up memory. This class is thread-safe to the extent that its underlying map is. The parameterless constructor uses a thread-safe map since 2.3.24 or Java 5."}
{"index": 3936, "repo": "freemarker-2.3.32", "code": "Class StopException {\n\t// Overrides Throwable.printStackTrace(PrintStream) so that it will include the FTL stack trace.\n\tvoid printStackTrace(java.io.PrintStream ps);\n\t// Overrides Throwable.printStackTrace(PrintWriter) so that it will include the FTL stack trace.\n\tvoid printStackTrace(java.io.PrintWriter pw);\n}", "des": "This exception is thrown when a #stop directive is encountered."}
{"index": 3937, "repo": "freemarker-2.3.32", "code": "Enum StringUtil.JsStringEncCompatibility {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StringUtil.JsStringEncCompatibility valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StringUtil.JsStringEncCompatibility[] values();\n}", "des": "Used as the argument of StringUtil.jsStringEnc(String, JsStringEncCompatibility, JsStringEncQuotation)."}
{"index": 3938, "repo": "freemarker-2.3.32", "code": "Enum StringUtil.JsStringEncQuotation {\n\tchar getSymbol();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StringUtil.JsStringEncQuotation valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StringUtil.JsStringEncQuotation[] values();\n}", "des": "Used as the argument of StringUtil.jsStringEnc(String, JsStringEncCompatibility, JsStringEncQuotation)."}
{"index": 3939, "repo": "freemarker-2.3.32", "code": "Class StrongCacheStorage {\n\tvoid clear();\n\tjava.lang.Object get(java.lang.Object key);\n\t// Returns a close approximation of the number of cache entries.\n\tint getSize();\n\t// Always returns true.\n\tboolean isConcurrent();\n\tvoid put(java.lang.Object key, java.lang.Object value);\n\tvoid remove(java.lang.Object key);\n}", "des": "Strong cache storage is a cache storage that simply wraps a Map. It holds a strong reference to all objects it was passed, therefore prevents the cache from being purged during garbage collection. This class is always thread-safe since 2.3.24, before that if we are running on Java 5 or later."}
{"index": 3940, "repo": "freemarker-2.3.32", "code": "Class TemplateCache.MaybeMissingTemplate {\n\t// When the template was missing, this possibly contains its normalized name.\n\tjava.lang.String getMissingTemplateNormalizedName();\n\t// When the template was missing, this possibly contains the explanation, or null.\n\tjava.lang.String getMissingTemplateReason();\n\t// The Template if it wasn't missing, otherwise null.\n\tTemplate getTemplate();\n}", "des": "Used for the return value of TemplateCache.getTemplate(String, Locale, Object, String, boolean)."}
{"index": 3941, "repo": "freemarker-2.3.32", "code": "Interface TemplateCollectionModelEx {\n\t// Returns if the collection contains any elements.\n\tboolean isEmpty();\n\t// Returns the number items in this collection, or Integer.MAX_VALUE, if there are more than Integer.MAX_VALUE items.\n\tint size();\n}", "des": "\"collection\" template language data type: Adds size/emptiness querybility to TemplateCollectionModel. The added extra operations are provided by all Java Collection-s, and this interface was added to make that accessible for templates too."}
{"index": 3942, "repo": "freemarker-2.3.32", "code": "Interface TemplateDateModel {\n\t// Returns the date value.\n\tjava.util.Date getAsDate();\n\t// Returns the type of the date.\n\tint getDateType();\n}", "des": "\"date\", \"time\" and \"date-time\" template language data types: corresponds to Date. Contrary to Java, FreeMarker distinguishes date (no time part), time and date-time values."}
{"index": 3943, "repo": "freemarker-2.3.32", "code": "Interface TemplateHashModelEx2.KeyValuePairIterator {\n\t// Similar to Iterator.hasNext().\n\tboolean hasNext();\n\t// Similar to Iterator.next().\n\tTemplateHashModelEx2.KeyValuePair next();\n}", "des": "Iterates over the key-value pairs in a hash. This is very similar to an Iterator, but has a fixed item type, can throw TemplateModelException-s, and has no remove() method."}
{"index": 3944, "repo": "freemarker-2.3.32", "code": "Class TemplateLookupResult {\n\t// The source name of the template found (see Template.getSourceName()), or null if isPositive() is false.\n\tabstract java.lang.String getTemplateSourceName();\n\t// Tells if the lookup has found a matching template.\n\tabstract boolean isPositive();\n}", "des": "The return value of TemplateLookupStrategy.lookup(TemplateLookupContext) and similar lookup methods. You usually get one from TemplateLookupContext.lookupWithAcquisitionStrategy(String) or TemplateLookupContext.createNegativeLookupResult(); you can't create instances of this directly."}
{"index": 3945, "repo": "freemarker-2.3.32", "code": "Class TemplateModelListSequence {\n\t// Retrieves the i-th template model in this sequence.\n\tTemplateModel get(int index);\n\t// Returns the original List of TemplateModel-s, so it's not a fully unwrapped value.\n\tjava.lang.Object getWrappedObject();\n\tint size();\n}", "des": "A sequence that wraps a List of TemplateModel-s. It does not copy the original list. It's mostly useful when implementing TemplateMethodModelEx-es that collect items from other TemplateModel-s."}
{"index": 3946, "repo": "freemarker-2.3.32", "code": "Class TemplateNotFoundException {\n\t// The custom lookup condition with which the template was requested, or null if there's no such condition.\n\tjava.lang.Object getCustomLookupCondition();\n\t// The name (path) of the template that wasn't found.\n\tjava.lang.String getTemplateName();\n}", "des": "Thrown when Configuration.getTemplate(String) (or similar) doesn't find a template. This extends FileNotFoundException for backward compatibility, but in fact has nothing to do with files, as FreeMarker can load templates from many other sources."}
{"index": 3947, "repo": "freemarker-2.3.32", "code": "Interface TransformControl {\n\t// Called after the body has been evaluated.\n\tint afterBody();\n\t// Called if any exception occurs during the transform between the TemplateTransformModel.getWriter(java.io.Writer, java.util.Map) call and the Writer.close() call.\n\tvoid onError(java.lang.Throwable t);\n\t// Called before the body is evaluated for the first time.\n\tint onStart();\n}", "des": "An interface that can be implemented by writers returned from TemplateTransformModel.getWriter(java.io.Writer, java.util.Map). The methods on this interfaces are callbacks that will be called by the template engine and that give the writer a chance to better control the evaluation of the transform body. The writer can instruct the engine to skip or to repeat body evaluation, and gets notified about exceptions that are thrown during the body evaluation."}
{"index": 3948, "repo": "freemarker-2.3.32", "code": "Class UndefinedOutputFormat {\n\t// Returns the MIME type of the output format.\n\tjava.lang.String getMimeType();\n\t// The short name used to refer to this format (like in the #ftl header).\n\tjava.lang.String getName();\n\t// Tells if this output format allows inserting TemplateMarkupOutputModel-s of another output formats into it.\n\tboolean isOutputFormatMixingAllowed();\n}", "des": "Represents the output format used when the template output format is undecided. This is the default output format if FreeMarker can't select anything more specific (see Configuration.setTemplateConfigurations(freemarker.cache.TemplateConfigurationFactory)). This format doesn't support auto-escaping (Configuration.setAutoEscapingPolicy(int)). It will print TemplateMarkupOutputModel-s as is (doesn't try to convert them)."}
{"index": 3949, "repo": "freemarker-2.3.32", "code": "Class WrappingTemplateModel {\n\t// Returns the object wrapper instance used by this wrapping template model.\n\tObjectWrapper getObjectWrapper();\n\tvoid setObjectWrapper(ObjectWrapper objectWrapper);\n\t// Wraps the passed object into a template model using this object's object wrapper.\n\tprotected TemplateModel wrap(java.lang.Object obj);\n}", "des": "Convenience base-class for containers that wrap their contained arbitrary Java objects into TemplateModel instances."}
{"index": 3950, "repo": "hive-service-4.0.0-alpha-2", "code": "Class ClassicTableTypeMapping {\n\t// Get all the table types of this mapping\n\tSet<String> getTableTypeNames();\n\t// Map hive's table type name to client's table type\n\tString mapToClientType(String hiveTypeName);\n\t// Map client's table type name to hive's table type\n\tString[] mapToHiveType(String clientTypeName);\n}", "des": "ClassicTableTypeMapping. Classic table type mapping : Managed Table ==> Table External Table ==> Table Virtual View ==> View"}
{"index": 3951, "repo": "hive-service-4.0.0-alpha-2", "code": "Class CompositeService {\n\tprotected void addService(Service service);\n\t// Imply the service not to run new requests from client.\n\tvoid decommission();\n\tCollection<Service> getServices();\n\t// Initialize the service.\n\tvoid init(HiveConf hiveConf);\n\tprotected boolean removeService(Service service);\n\t// Start the service.\n\tvoid start();\n\t// Stop the service.\n\tvoid stop();\n}", "des": "CompositeService."}
{"index": 3952, "repo": "hive-service-4.0.0-alpha-2", "code": "Class CookieSigner {\n\t// Sign the cookie given the string token as input.\n\tString signCookie(String str);\n\t// Verify a signed string and extracts the original string.\n\tString verifyAndExtract(String signedStr);\n}", "des": "The cookie signer generates a signature based on SHA digest and appends it to the cookie value generated at the server side. It uses SHA digest algorithm to sign and verify signatures."}
{"index": 3953, "repo": "hive-service-4.0.0-alpha-2", "code": "Interface DirSearch {\n\t// Executes an arbitrary query.\n\tList<String> executeCustomQuery(String query);\n\t// Finds group's distinguished name.\n\tString findGroupDn(String group);\n\t// Finds groups that contain the specified user.\n\tList<String> findGroupsForUser(String userDn);\n\t// Finds user's distinguished name.\n\tString findUserDn(String user);\n\t// Verifies that specified user is a member of specified group.\n\tboolean isUserMemberOfGroup(String user, String groupDn);\n}", "des": "The object used for executing queries on the Directory Service."}
{"index": 3954, "repo": "hive-service-4.0.0-alpha-2", "code": "Enum FetchOrientation {\n\tstatic FetchOrientation getFetchOrientation(TFetchOrientation tFetchOrientation);\n\tTFetchOrientation toTFetchOrientation();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FetchOrientation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FetchOrientation[] values();\n}", "des": "FetchOrientation."}
{"index": 3955, "repo": "hive-service-4.0.0-alpha-2", "code": "Enum FetchType {\n\tstatic FetchType getFetchType(short tFetchType);\n\tshort toTFetchType();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FetchType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FetchType[] values();\n}", "des": "FetchType indicates the type of fetchResults request. It maps the TFetchType, which is generated from Thrift interface."}
{"index": 3956, "repo": "hive-service-4.0.0-alpha-2", "code": "Enum GetInfoType {\n\tstatic GetInfoType getGetInfoType(TGetInfoType tGetInfoType);\n\tTGetInfoType toTGetInfoType();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GetInfoType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GetInfoType[] values();\n}", "des": "GetInfoType."}
{"index": 3957, "repo": "hive-service-4.0.0-alpha-2", "code": "Class HiveSaml2Client {\n\tstatic HiveSaml2Client get(HiveConf conf);\n\t// Generates a SAML request using the HTTP-Redirect Binding.\n\tvoid setRedirect(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response);\n\tstatic void shutdown();\n\t// Given a response which may contain a SAML Assertion, validates it.\n\tString validate(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response);\n}", "des": "HiveServer2's implementation of SAML2Client. We mostly rely on pac4j to do most of the heavy lifting. This class implements the initialization logic of the underlying SAML2Client using the HiveConf. Also, implements the generation of SAML requests using HTTP-Redirect binding. //TODO: Add support for HTTP-Post binding for SAML request. //TODO Note that this implementation is only to be used when HiveServer2 is not deployed in HA mode. In case of HA mode, we should implement a ReplayCacheProvider such that the ReplayCache is shared between all HS2 instances. Ref: http://www.pac4j.org/docs/clients/saml.html"}
{"index": 3958, "repo": "hive-service-4.0.0-alpha-2", "code": "Class HiveSamlAuthTokenGenerator {\n\tstatic ISAMLAuthTokenGenerator get(HiveConf conf);\n\t// Get the token for a given user and relay state id.\n\tString get(String username, String relayStateKey);\n\tstatic boolean parse(String token, Map<String,String> kv);\n\t// Validate the given token.\n\tString validate(String encodedToken);\n}", "des": "A token is generated when the SAML assertion is successfully validated. This Token is passed back to the client (Jdbc/ODBC Driver) via the browser. This token is presented by the subsequent http request as a bearer token."}
{"index": 3959, "repo": "hive-service-4.0.0-alpha-2", "code": "Interface HiveSessionHookContext {\n\t// Retrieve session conf\n\tHiveConf getSessionConf();\n\t// Retrieve handle for the session\n\tString getSessionHandle();\n\t// The get the username starting the session\n\tString getSessionUser();\n}", "des": "HiveSessionHookContext. Interface passed to the HiveServer2 session hook execution. This enables the hook implementation to access session config, user and session handle"}
{"index": 3960, "repo": "hive-service-4.0.0-alpha-2", "code": "Class HiveSessionHookContextImpl {\n\t// Retrieve session conf\n\tHiveConf getSessionConf();\n\t// Retrieve handle for the session\n\tString getSessionHandle();\n\t// The get the username starting the session\n\tString getSessionUser();\n}", "des": "HiveSessionHookContextImpl. Session hook context implementation which is created by session manager and passed to hook invocation."}
{"index": 3961, "repo": "hive-service-4.0.0-alpha-2", "code": "Class HiveSQLException {\n\t// Converts current object to a TStatus object.\n\tTStatus toTStatus();\n\t// Converts the specified Exception object into a TStatus object.\n\tstatic TStatus toTStatus(Exception e);\n}", "des": "An exception that provides information on a Hive access error or other errors."}
{"index": 3962, "repo": "hive-service-4.0.0-alpha-2", "code": "Class HiveTableTypeMapping {\n\t// Get all the table types of this mapping\n\tSet<String> getTableTypeNames();\n\t// Map hive's table type name to client's table type\n\tString mapToClientType(String hiveTypeName);\n\t// Map client's table type name to hive's table type\n\tString[] mapToHiveType(String clientTypeName);\n}", "des": "HiveTableTypeMapping. Default table type mapping"}
{"index": 3963, "repo": "hive-service-4.0.0-alpha-2", "code": "Class HttpAuthUtils {\n\t// Creates and returns a HS2 cookie token.\n\tstatic String createCookieToken(String clientUserName);\n\tstatic String getKerberosServiceTicket(String principal, String host, String serverHttpUrl, Subject loggedInSubject);\n\t// Parses a cookie token to retrieve client user name.\n\tstatic String getUserNameFromCookieToken(String tokenStr);\n}", "des": "Utility functions for HTTP mode authentication."}
{"index": 3964, "repo": "hive-service-4.0.0-alpha-2", "code": "Interface ISAMLAuthTokenGenerator {\n\t// Get the token for a given user and relay state id.\n\tString get(String username, String relayStateId);\n\t// Validate the given token.\n\tString validate(String token);\n}", "des": "Interface which is used by SAML authentication for the token generation and validation logic. The token generated by the get() method must have enough encoded information to be able to validated it at a later point of time."}
{"index": 3965, "repo": "hive-service-4.0.0-alpha-2", "code": "Class KillQueryZookeeperManager {\n\t// Initialize the service.\n\tvoid init(HiveConf conf);\n\t// Post a kill query request on Zookeeper for the other HS2 instances.\n\tvoid killQuery(String queryIdOrTag, String doAs, boolean doAsAdmin);\n\t// Start the service.\n\tvoid start();\n\t// Stop the service.\n\tvoid stop();\n}", "des": "Kill query coordination service. When service discovery is enabled a local kill query can request a kill on every other HS2 server with the queryId or queryTag and wait for confirmation on denial. The communication is done through Zookeeper."}
{"index": 3966, "repo": "hive-service-4.0.0-alpha-2", "code": "Enum OperationType {\n\tstatic OperationType getOperationType(TOperationType tOperationType);\n\tTOperationType toTOperationType();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OperationType[] values();\n}", "des": "OperationType."}
{"index": 3967, "repo": "hive-service-4.0.0-alpha-2", "code": "Class Query {\n\t// Creates Query Builder.\n\tstatic Query.QueryBuilder builder();\n\t// Returns search controls.\n\tSearchControls getControls();\n\t// Returns search filter.\n\tString getFilter();\n}", "des": "The object that encompasses all components of a Directory Service search query."}
{"index": 3968, "repo": "hive-service-4.0.0-alpha-2", "code": "Class QueryInfoCache {\n\t// Add the live operation's query info into the cache\n\tvoid addLiveQueryInfo(Operation operation);\n\tSet<String> getAllQueryIds();\n\tList<QueryInfo> getHistoricalQueryInfos();\n\tList<QueryInfo> getLiveQueryInfos();\n\tQueryInfo getQueryInfo(String handle);\n\t// Remove the live operation's query info from the liveQueryInfos, and push the query info to the historic query cache if enabled.\n\tvoid removeLiveQueryInfo(Operation operation);\n}", "des": "Cache some SQLOperation information for WebUI"}
{"index": 3969, "repo": "hive-service-4.0.0-alpha-2", "code": "Enum SaslQOP {\n\tstatic SaslQOP fromString(String str);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SaslQOP valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SaslQOP[] values();\n}", "des": "Possible values of SASL quality-of-protection value."}
{"index": 3970, "repo": "hive-service-4.0.0-alpha-2", "code": "Class SearchResultHandler {\n\t// Returns all entries from the search result.\n\tList<String> getAllLdapNames();\n\t// Returns all entries and all attributes for these entries.\n\tList<String> getAllLdapNamesAndAttributes();\n\t// Returns a single entry from the search result.\n\tString getSingleLdapName();\n\t// Allows for custom processing of the search results.\n\tvoid handle(SearchResultHandler.RecordProcessor processor);\n\t// Checks whether search result contains exactly one entry.\n\tboolean hasSingleResult();\n}", "des": "The object that handles Directory Service search results. In most cases it converts search results into a list of names in the namespace."}
{"index": 3971, "repo": "hive-service-4.0.0-alpha-2", "code": "Enum Service.STATE {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Service.STATE valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Service.STATE[] values();\n}", "des": "Service states"}
{"index": 3972, "repo": "hive-service-4.0.0-alpha-2", "code": "Class ThreadWithGarbageCleanup {\n\t// Cache the ThreadLocal RawStore object.\n\tvoid cacheThreadLocalRawStore();\n\t// Add any Thread specific garbage cleanup code here.\n\tvoid finalize();\n}", "des": "A HiveServer2 thread used to construct new server threads. In particular, this thread ensures an orderly cleanup, when killed by its corresponding ExecutorService."}
{"index": 3973, "repo": "hive-service-4.0.0-alpha-2", "code": "Class TypeDescriptor {\n\t// The column size for this type.\n\tInteger getColumnSize();\n\t// The number of fractional digits for this type.\n\tInteger getDecimalDigits();\n\t// Maximum precision for numeric types.\n\tInteger getPrecision();\n\torg.apache.hadoop.hive.serde2.thrift.Type getType();\n\tString getTypeName();\n\tTypeQualifiers getTypeQualifiers();\n\tvoid setTypeQualifiers(TypeQualifiers typeQualifiers);\n\tTTypeDesc toTTypeDesc();\n}", "des": "TypeDescriptor."}
{"index": 3974, "repo": "iceberg-core-1.3.0", "code": "Class DeleteCounter {\n\t// Return the current value of the counter.\n\tlong get();\n\t// Increment the counter by one.\n\tvoid increment();\n}", "des": "A counter to be used to count deletes as they are applied."}
{"index": 3975, "repo": "iceberg-core-1.3.0", "code": "Enum EncryptionAlgorithm {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EncryptionAlgorithm valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EncryptionAlgorithm[] values();\n}", "des": "Algorithm supported for file encryption."}
{"index": 3976, "repo": "iceberg-core-1.3.0", "code": "Interface FileWriter<T,R> {\n\t// Returns the number of bytes that were currently written by this writer.\n\tlong length();\n\t// Returns a result that contains information about written DataFiles or DeleteFiles.\n\tR result();\n\t// Writes rows to a predefined spec/partition.\n\tdefault void write(java.lang.Iterable<T> rows);\n\t// Writes a row to a predefined spec/partition.\n\tvoid write(T row);\n}", "des": "A writer capable of writing files of a single type (i.e. data/delete) to one spec/partition."}
{"index": 3977, "repo": "iceberg-core-1.3.0", "code": "Enum IsolationLevel {\n\tstatic IsolationLevel fromName(java.lang.String levelName);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IsolationLevel valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IsolationLevel[] values();\n}", "des": "An isolation level in a table."}
{"index": 3978, "repo": "iceberg-core-1.3.0", "code": "Interface PartitioningWriter<T,R> {\n\t// Returns a result that contains information about written DataFiles or DeleteFiles.\n\tR result();\n\t// Writes a row to the provided spec/partition.\n\tvoid write(T row, org.apache.iceberg.PartitionSpec spec, org.apache.iceberg.StructLike partition);\n}", "des": "A writer capable of writing files of a single type (i.e. data/delete) to multiple specs and partitions."}
{"index": 3979, "repo": "iceberg-core-1.3.0", "code": "Class Puffin.ReadBuilder {\n\tPuffinReader build();\n\t// Passes known file size to the reader.\n\tPuffin.ReadBuilder withFileSize(long size);\n\t// Passes known footer size to the reader.\n\tPuffin.ReadBuilder withFooterSize(long size);\n}", "des": "A builder for PuffinReader."}
{"index": 3980, "repo": "iceberg-core-1.3.0", "code": "Enum RowLevelOperationMode {\n\tstatic RowLevelOperationMode fromName(java.lang.String modeName);\n\tjava.lang.String modeName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RowLevelOperationMode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RowLevelOperationMode[] values();\n}", "des": "Iceberg supports two ways to modify records in a table: copy-on-write and merge-on-read."}
{"index": 3981, "repo": "iceberg-core-1.3.0", "code": "Interface TaskWriter<T> {\n\t// Close the writer and delete the completed files if possible when aborting.\n\tvoid abort();\n\t// Close the writer and get the completed data and delete files.\n\tWriteResult complete();\n\t// Close the writer and get the completed data files, it requires that the task writer would produce data files only.\n\tdefault org.apache.iceberg.DataFile[] dataFiles();\n\t// Write the row into the data files.\n\tvoid write(T row);\n}", "des": "The writer interface could accept records and provide the generated data files."}
{"index": 3982, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class HBaseMetrics2HadoopMetricsAdapter {\n\t// Iterates over the MetricRegistry and adds them to the collector.\n\tvoid snapshotAllMetrics(MetricRegistry metricRegistry, MetricsCollector collector);\n\t// Iterates over the MetricRegistry and adds them to the builder.\n\tvoid snapshotAllMetrics(MetricRegistry metricRegistry, MetricsRecordBuilder builder);\n}", "des": "This is the adapter from \"HBase Metrics Framework\", implemented in hbase-metrics-api and hbase-metrics modules to the Hadoop Metrics2 framework. This adapter is not a metric source, but a helper to be able to collect all of the Metric's in the MetricRegistry using the MetricsCollector and MetricsRecordBuilder. Some of the code is forked from https://github.com/joshelser/dropwizard-hadoop-metrics2."}
{"index": 3983, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class Interns {\n\t// Get a metric info object\n\tstatic MetricsInfo info(String name, String description);\n\t// Get a metrics tag\n\tstatic MetricsTag tag(MetricsInfo info, String value);\n\t// Get a metrics tag\n\tstatic MetricsTag tag(String name, String description, String value);\n}", "des": "Helpers to create interned metrics info"}
{"index": 3984, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class JmxCacheBuster {\n\t// For JMX to forget about all previously exported metrics.\n\tstatic void clearJmxCache();\n\t// Restarts the stopped service.\n\tstatic void restart();\n\t// Stops the clearing of JMX metrics and restarting the Hadoop metrics system.\n\tstatic void stop();\n}", "des": "JMX caches the beans that have been exported; even after the values are removed from hadoop's metrics system the keys and old values will still remain. This class stops and restarts the Hadoop metrics system, forcing JMX to clear the cache of exported metrics. This class need to be in the o.a.h.metrics2.impl namespace as many of the variables/calls used are package private."}
{"index": 3985, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class JobUtil {\n\t// Initializes the staging directory and returns the qualified path.\n\tstatic org.apache.hadoop.fs.Path getQualifiedStagingDir(org.apache.hadoop.conf.Configuration conf);\n\t// Initializes the staging directory and returns the path.\n\tstatic org.apache.hadoop.fs.Path getStagingDir(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Utility methods to interact with a job."}
{"index": 3986, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class MetricSampleQuantiles {\n\t// Resets the estimator, clearing out all previously inserted items\n\tvoid clear();\n\t// Returns the number of items that the estimator has processed\n\tlong getCount();\n\t// Returns the number of samples kept by the estimator\n\tint getSampleCount();\n\t// Add a new value from the stream.\n\tvoid insert(long v);\n\t// Get a snapshot of the current values of all the tracked quantiles.\n\tMap<MetricQuantile,Long> snapshot();\n}", "des": "Implementation of the Cormode, Korn, Muthukrishnan, and Srivastava algorithm for streaming calculation of targeted high-percentile epsilon-approximate quantiles. This is a generalization of the earlier work by Greenwald and Khanna (GK), which essentially allows different error bounds on the targeted quantiles, which allows for far more efficient calculation of high-percentiles. See: Cormode, Korn, Muthukrishnan, and Srivastava \"Effective Computation of Biased Quantiles over Data Streams\" in ICDE 2005 Greenwald and Khanna, \"Space-efficient online computation of quantile summaries\" in SIGMOD 2001"}
{"index": 3987, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class MutableRangeHistogram {\n\tlong getCount();\n\t// Returns the ranges to be counted\n\tabstract long[] getRanges();\n\t// Returns the type of range histogram size or time\n\tabstract String getRangeType();\n\tvoid snapshot(MetricsRecordBuilder metricsRecordBuilder, boolean all);\n\tvoid updateSnapshotRangeMetrics(MetricsRecordBuilder metricsRecordBuilder, Snapshot snapshot);\n}", "des": "Extended histogram implementation with metric range counters."}
{"index": 3988, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class MutableSizeHistogram {\n\t// Returns the ranges to be counted\n\tlong[] getRanges();\n\t// Returns the type of range histogram size or time\n\tString getRangeType();\n}", "des": "Extended histogram implementation with counters for metric size ranges."}
{"index": 3989, "repo": "hbase-hadoop2-compat-2.5.5-hadoop3", "code": "Class MutableTimeHistogram {\n\t// Returns the ranges to be counted\n\tlong[] getRanges();\n\t// Returns the type of range histogram size or time\n\tString getRangeType();\n}", "des": "Extended histogram implementation with counters for metric time ranges."}
{"index": 3990, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class AbstractAMRMProxyPolicy {\n\t// This method should be invoked to notify the policy about responses being received.\n\tvoid notifyOfResponse(SubClusterId subClusterId, org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse response);\n\t// Overridable validation step for the policy configuration.\n\tvoid validate(WeightedPolicyInfo newPolicyInfo);\n}", "des": "Base abstract class for FederationAMRMProxyPolicy implementations, that provides common validation for reinitialization."}
{"index": 3991, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class AbstractSubClusterResolver {\n\tMap<String,SubClusterId> getNodeToSubCluster();\n\tMap<String,Set<SubClusterId>> getRackToSubClusters();\n\t// Obtain the sub-cluster that a specified node belongs to.\n\tSubClusterId getSubClusterForNode(String nodename);\n\t// Obtain the sub-clusters that have nodes on a specified rack.\n\tSet<SubClusterId> getSubClustersForRack(String rackname);\n}", "des": "Partial implementation of SubClusterResolver, containing basic implementations of the read methods."}
{"index": 3992, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class AddApplicationHomeSubClusterResponse {\n\t// Get the home sub-cluster that this application has been assigned to.\n\tabstract SubClusterId getHomeSubCluster();\n\tstatic AddApplicationHomeSubClusterResponse newInstance(SubClusterId homeSubCluster);\n\t// Set the home sub-cluster that this application has been assigned to.\n\tabstract void setHomeSubCluster(SubClusterId homeSubCluster);\n}", "des": "AddApplicationHomeSubClusterResponse contains the answer from the FederationApplicationHomeSubClusterStore to a request to insert a newly generated applicationId and its owner. The response contains application's home sub-cluster as it is stored in the FederationApplicationHomeSubClusterStore. If a mapping for the application already existed, the SubClusterId in this response will return the existing mapping which might be different from that in the AddApplicationHomeSubClusterRequest."}
{"index": 3993, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class AddApplicationHomeSubClusterResponsePBImpl {\n\tboolean equals(Object other);\n\t// Get the home sub-cluster that this application has been assigned to.\n\tSubClusterId getHomeSubCluster();\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.AddApplicationHomeSubClusterResponseProto getProto();\n\t// Set the home sub-cluster that this application has been assigned to.\n\tvoid setHomeSubCluster(SubClusterId homeSubCluster);\n}", "des": "Protocol buffer based implementation of AddApplicationHomeSubClusterResponse."}
{"index": 3994, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Enum AMRMClientRelayerMetrics.RequestType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AMRMClientRelayerMetrics.RequestType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AMRMClientRelayerMetrics.RequestType[] values();\n}", "des": "Easier classification of request types for logging metrics."}
{"index": 3995, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Interface AppInfoProvider {\n\t// Returns BasicAppInfo object that wraps the collected information about the application.\n\torg.apache.hadoop.yarn.server.webapp.BasicAppInfo getApp(javax.servlet.http.HttpServletRequest req, String appId, String clusterId);\n\t// Returns the node HTTP address.\n\tString getNodeHttpAddress(javax.servlet.http.HttpServletRequest req, String appId, String appAttemptId, String containerId, String clusterId);\n}", "des": "Classes implementing this interface are used in the LogServlet for providing various application related information."}
{"index": 3996, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class DefaultSubClusterResolverImpl {\n\torg.apache.hadoop.conf.Configuration getConf();\n\t// Obtain the sub-cluster that a specified node belongs to.\n\tSubClusterId getSubClusterForNode(String nodename);\n\t// Obtain the sub-clusters that have nodes on a specified rack.\n\tSet<SubClusterId> getSubClustersForRack(String rackname);\n\t// Load the nodes to subCluster mapping from the file.\n\tvoid load();\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Default simple sub-cluster and rack resolver class. This class expects a three-column comma separated file, specified in yarn.federation.machine-list. Each line of the file should be of the format: nodeName, subClusterId, rackName Lines that do not follow this format will be ignored. This resolver only loads the file when load() is explicitly called; it will not react to changes to the file. It is case-insensitive on the rack and node names and ignores leading/trailing whitespace."}
{"index": 3997, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Interface DistributedSchedulingAMProtocol {\n\t// Extends the allocate to wrap the response with additional metadata.\n\tDistributedSchedulingAllocateResponse allocateForDistributedScheduling(DistributedSchedulingAllocateRequest request);\n\t// Extends the registerApplicationMaster to wrap the response with additional metadata.\n\tRegisterDistributedSchedulingAMResponse registerApplicationMasterForDistributedScheduling(org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest request);\n}", "des": ""}
{"index": 3998, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class FederationPolicyStoreInputValidator {\n\t// Quick validation on the input to check some obvious fail conditions (fail fast).\n\tstatic void validate(GetSubClusterPolicyConfigurationRequest request);\n\t// Quick validation on the input to check some obvious fail conditions (fail fast).\n\tstatic void validate(SetSubClusterPolicyConfigurationRequest request);\n}", "des": "Utility class to validate the inputs to FederationPolicyStore, allows a fail fast mechanism for invalid user inputs."}
{"index": 3999, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Interface FederationStateStore {\n\t// Perform any cleanup operations of the StateStore.\n\tvoid close();\n\t// Get the Version of the underlying federation state store client.\n\tVersion getCurrentVersion();\n\t// Initialize the FederationStore.\n\tvoid init(org.apache.hadoop.conf.Configuration conf);\n\t// Load the version information from the federation state store.\n\tVersion loadVersion();\n}", "des": "FederationStore extends the three interfaces used to coordinate the state of a federated cluster: FederationApplicationHomeSubClusterStore, FederationMembershipStateStore, and FederationPolicyStore."}
{"index": 4000, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetApplicationHomeSubClusterRequest {\n\t// Get the ApplicationId representing the unique identifier of the application.\n\tabstract org.apache.hadoop.yarn.api.records.ApplicationId getApplicationId();\n\tstatic GetApplicationHomeSubClusterRequest newInstance(org.apache.hadoop.yarn.api.records.ApplicationId appId);\n\t// Set the ApplicationId representing the unique identifier of the application.\n\tabstract void setApplicationId(org.apache.hadoop.yarn.api.records.ApplicationId applicationId);\n}", "des": "Request class to obtain the home sub-cluster for the specified ApplicationId."}
{"index": 4001, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterInfoRequest {\n\t// Get the SubClusterId representing the unique identifier of the subcluster.\n\tabstract SubClusterId getSubClusterId();\n\tstatic GetSubClusterInfoRequest newInstance(SubClusterId subClusterId);\n\t// Set the SubClusterId representing the unique identifier of the subcluster.\n\tabstract void setSubClusterId(SubClusterId subClusterId);\n}", "des": "Request class to obtain information about a sub-cluster identified by its SubClusterId."}
{"index": 4002, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterInfoRequestPBImpl {\n\tboolean equals(Object other);\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.GetSubClusterInfoRequestProto getProto();\n\t// Get the SubClusterId representing the unique identifier of the subcluster.\n\tSubClusterId getSubClusterId();\n\t// Set the SubClusterId representing the unique identifier of the subcluster.\n\tvoid setSubClusterId(SubClusterId subClusterId);\n}", "des": "Protocol buffer based implementation of GetSubClusterInfoRequest."}
{"index": 4003, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterInfoResponse {\n\t// Get the SubClusterInfo encapsulating the information about the sub-cluster.\n\tabstract SubClusterInfo getSubClusterInfo();\n\tstatic GetSubClusterInfoResponse newInstance(SubClusterInfo subClusterInfo);\n\t// Set the SubClusterInfo encapsulating the information about the sub-cluster.\n\tabstract void setSubClusterInfo(SubClusterInfo subClusterInfo);\n}", "des": "Response to a query with SubClusterInfo about a sub-cluster."}
{"index": 4004, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterInfoResponsePBImpl {\n\tboolean equals(Object other);\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.GetSubClusterInfoResponseProto getProto();\n\t// Get the SubClusterInfo encapsulating the information about the sub-cluster.\n\tSubClusterInfo getSubClusterInfo();\n\t// Set the SubClusterInfo encapsulating the information about the sub-cluster.\n\tvoid setSubClusterInfo(SubClusterInfo subClusterInfo);\n}", "des": "Protocol buffer based implementation of GetSubClusterInfoResponse."}
{"index": 4005, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterPoliciesConfigurationsResponse {\n\t// Get all the policies configured in the system.\n\tabstract List<SubClusterPolicyConfiguration> getPoliciesConfigs();\n\tstatic GetSubClusterPoliciesConfigurationsResponse newInstance(List<SubClusterPolicyConfiguration> policyConfigurations);\n\t// Sets all the policies configured in the system.\n\tabstract void setPoliciesConfigs(List<SubClusterPolicyConfiguration> policyConfigurations);\n}", "des": "GetSubClusterPolicyConfigurationResponse contains the answer from the FederationPolicyStore to a request to get all the policies configured in the system via a SubClusterPolicyConfiguration."}
{"index": 4006, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterPoliciesConfigurationsResponsePBImpl {\n\tboolean equals(Object other);\n\t// Get all the policies configured in the system.\n\tList<SubClusterPolicyConfiguration> getPoliciesConfigs();\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.GetSubClusterPoliciesConfigurationsResponseProto getProto();\n\t// Sets all the policies configured in the system.\n\tvoid setPoliciesConfigs(List<SubClusterPolicyConfiguration> policyConfigurations);\n}", "des": "Protocol buffer based implementation of GetSubClusterPoliciesConfigurationsResponse."}
{"index": 4007, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterPolicyConfigurationRequest {\n\t// Get the name of the queue for which we are requesting a policy configuration.\n\tabstract String getQueue();\n\tstatic GetSubClusterPolicyConfigurationRequest newInstance(String queueName);\n\t// Sets the name of the queue for which we are requesting a policy configuration.\n\tabstract void setQueue(String queueName);\n}", "des": "GetSubClusterPolicyConfigurationRequest is a request to the FederationPolicyStore to get the configuration of a policy for a given queue."}
{"index": 4008, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterPolicyConfigurationRequestPBImpl {\n\tboolean equals(Object other);\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.GetSubClusterPolicyConfigurationRequestProto getProto();\n\t// Get the name of the queue for which we are requesting a policy configuration.\n\tString getQueue();\n\t// Sets the name of the queue for which we are requesting a policy configuration.\n\tvoid setQueue(String queueName);\n}", "des": "Protocol buffer based implementation of GetSubClusterPolicyConfigurationRequest."}
{"index": 4009, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterPolicyConfigurationResponse {\n\t// Get the policy configuration.\n\tabstract SubClusterPolicyConfiguration getPolicyConfiguration();\n\tstatic GetSubClusterPolicyConfigurationResponse newInstance(SubClusterPolicyConfiguration policy);\n\t// Sets the policyConfiguration configuration.\n\tabstract void setPolicyConfiguration(SubClusterPolicyConfiguration policyConfiguration);\n}", "des": "GetSubClusterPolicyConfigurationResponse contains the answer from the FederationPolicyStore to a request to get the information about how a policy should be configured via a SubClusterPolicyConfiguration."}
{"index": 4010, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClusterPolicyConfigurationResponsePBImpl {\n\tboolean equals(Object other);\n\t// Get the policy configuration.\n\tSubClusterPolicyConfiguration getPolicyConfiguration();\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.GetSubClusterPolicyConfigurationResponseProto getProto();\n\t// Sets the policyConfiguration configuration.\n\tvoid setPolicyConfiguration(SubClusterPolicyConfiguration policyConfiguration);\n}", "des": "Protocol buffer based implementation of GetSubClusterPolicyConfigurationResponse."}
{"index": 4011, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClustersInfoRequest {\n\t// Get the flag that indicates whether only active sub-clusters should be returned.\n\tabstract boolean getFilterInactiveSubClusters();\n\tstatic GetSubClustersInfoRequest newInstance(boolean filterInactiveSubClusters);\n\t// Set the flag that indicates whether only active sub-clusters should be returned.\n\tabstract void setFilterInactiveSubClusters(boolean filterInactiveSubClusters);\n}", "des": "Request class to obtain information about all sub-clusters that are participating in federation. If filterInactiveSubClusters is set to true, only active sub-clusters will be returned; otherwise, all sub-clusters will be returned regardless of state. By default, filterInactiveSubClusters is true."}
{"index": 4012, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClustersInfoRequestPBImpl {\n\tboolean equals(Object other);\n\t// Get the flag that indicates whether only active sub-clusters should be returned.\n\tboolean getFilterInactiveSubClusters();\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.GetSubClustersInfoRequestProto getProto();\n\t// Set the flag that indicates whether only active sub-clusters should be returned.\n\tvoid setFilterInactiveSubClusters(boolean filterInactiveSubClusters);\n}", "des": "Protocol buffer based implementation of GetSubClustersInfoRequest."}
{"index": 4013, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class GetSubClustersInfoResponse {\n\t// Get the list of SubClusterInfo representing the information about all sub-clusters that are currently participating in Federation.\n\tabstract List<SubClusterInfo> getSubClusters();\n\tstatic GetSubClustersInfoResponse newInstance(List<SubClusterInfo> subClusters);\n\t// Set the list of SubClusterInfo representing the information about all sub-clusters that are currently participating in Federation.\n\tabstract void setSubClusters(List<SubClusterInfo> subClusters);\n}", "des": "Response to a query with list of SubClusterInfo about all sub-clusters that are currently participating in Federation."}
{"index": 4014, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class HashBasedRouterPolicy {\n\t// Simply picks from alphabetically-sorted active subclusters based on the hash of quey name.\n\tSubClusterId getHomeSubcluster(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext appSubmissionContext, List<SubClusterId> blackListSubClusters);\n\t// This method is invoked to initialize of update the configuration of policies.\n\tvoid reinitialize(FederationPolicyInitializationContext federationPolicyContext);\n}", "des": "This FederationRouterPolicy pick a subcluster based on the hash of the job's queue name. Useful to provide a default behavior when too many queues exist in a system. This also ensures that all jobs belonging to a queue are mapped to the same sub-cluster (likely help with locality)."}
{"index": 4015, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class LoadBasedRouterPolicy {\n\t// Determines the sub-cluster that the user application submission should be routed to.\n\tSubClusterId getHomeSubcluster(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext appSubmissionContext, List<SubClusterId> blacklist);\n\t// This method is invoked to initialize of update the configuration of policies.\n\tvoid reinitialize(FederationPolicyInitializationContext policyContext);\n}", "des": "This implements a simple load-balancing policy. The policy \"weights\" are binary 0/1 values that enable/disable each sub-cluster, and the policy peaks the sub-cluster with the least load to forward this application."}
{"index": 4016, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class LocalityRouterPolicy {\n\t// Determines the sub-cluster that the user application submission should be routed to.\n\tSubClusterId getHomeSubcluster(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext appSubmissionContext, List<SubClusterId> blackListSubClusters);\n\t// This method is invoked to initialize of update the configuration of policies.\n\tvoid reinitialize(FederationPolicyInitializationContext policyContext);\n}", "des": "This policy selects the subcluster depending on the node where the Client wants to run its application. It succeeds if: - There are three AMContainerResourceRequests in the order NODE, RACK, ANY It falls back to WeightedRandomRouterPolicy in case of: - Null or empty AMContainerResourceRequests; - One AMContainerResourceRequests and it has ANY as ResourceName; - The node is in blacklisted SubClusters. It fails if: - The node does not exist and RelaxLocality is False; - We have an invalid number (not 0, 1 or 3) resource requests"}
{"index": 4017, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Enum NodeAction {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NodeAction valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NodeAction[] values();\n}", "des": "The NodeManager is instructed to perform the given action."}
{"index": 4018, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class OpportunisticContainerAllocator.Allocation {\n\t// Get container of the allocation.\n\torg.apache.hadoop.yarn.api.records.Container getContainer();\n\t// Get resource name of the allocation.\n\tString getResourceName();\n}", "des": "This class encapsulates container and resourceName for an allocation."}
{"index": 4019, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class OpportunisticContainerAllocator.ContainerIdGenerator {\n\t// Generates a new long value.\n\tlong generateContainerId();\n\t// This method can reset the generator to a specific value.\n\tvoid resetContainerIdCounter(long containerIdStart);\n}", "des": "A Container Id Generator."}
{"index": 4020, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class RejectRouterPolicy {\n\t// The policy always reject requests.\n\tSubClusterId getHomeSubcluster(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext appSubmissionContext, List<SubClusterId> blackListSubClusters);\n\t// This method is invoked to initialize of update the configuration of policies.\n\tvoid reinitialize(FederationPolicyInitializationContext federationPolicyContext);\n}", "des": "This FederationRouterPolicy simply rejects all incoming requests. This is useful to prevent applications running in a queue to be run anywhere in the federated cluster."}
{"index": 4021, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class RouterPolicyFacade {\n\t// This method provides a wrapper of all policy functionalities for routing .\n\tSubClusterId getHomeSubcluster(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext appSubmissionContext, List<SubClusterId> blackListSubClusters);\n\t// This method flushes all cached configurations and policies.\n\tvoid reset();\n}", "des": "This class provides a facade to the policy subsystem, and handles the lifecycle of policies (e.g., refresh from remote, default behaviors etc.)."}
{"index": 4022, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SCMUploaderCanUploadRequest {\n\t// Get the key of the resource that would be uploaded to the shared cache.\n\tabstract String getResourceKey();\n\t// Set the key of the resource that would be uploaded to the shared cache.\n\tabstract void setResourceKey(String key);\n}", "des": ""}
{"index": 4023, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SCMUploaderCanUploadResponse {\n\t// Get whether or not the node manager can upload the resource to the shared cache.\n\tabstract boolean getUploadable();\n\t// Set whether or not the node manager can upload the resource to the shared cache.\n\tabstract void setUploadable(boolean b);\n}", "des": ""}
{"index": 4024, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SCMUploaderNotifyRequest {\n\t// Get the filename of the resource that was just uploaded to the shared cache.\n\tabstract String getFileName();\n\t// Get the key of the resource that was just uploaded to the shared cache.\n\tabstract String getResourceKey();\n\t// Set the filename of the resource that was just uploaded to the shared cache.\n\tabstract void setFilename(String filename);\n\t// Set the key of the resource that was just uploaded to the shared cache.\n\tabstract void setResourceKey(String key);\n}", "des": ""}
{"index": 4025, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SCMUploaderNotifyResponse {\n\t// Get whether or not the shared cache manager has accepted the notified resource (i.e.\n\tabstract boolean getAccepted();\n\t// Set whether or not the shared cache manager has accepted the notified resource (i.e.\n\tabstract void setAccepted(boolean b);\n}", "des": ""}
{"index": 4026, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Interface SCMUploaderProtocol {\n\t// The method used by the NodeManager's SharedCacheUploadService to request whether a resource can be uploaded.\n\tSCMUploaderCanUploadResponse canUpload(SCMUploaderCanUploadRequest request);\n\t// The method used by the NodeManager's SharedCacheUploadService to notify the shared cache manager of a newly cached resource.\n\tSCMUploaderNotifyResponse notify(SCMUploaderNotifyRequest request);\n}", "des": ""}
{"index": 4027, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SetSubClusterPolicyConfigurationRequest {\n\t// Get the policy configuration assigned to the queue.\n\tabstract SubClusterPolicyConfiguration getPolicyConfiguration();\n\tstatic SetSubClusterPolicyConfigurationRequest newInstance(SubClusterPolicyConfiguration policy);\n\t// Set the policyConfiguration configuration for the queue.\n\tabstract void setPolicyConfiguration(SubClusterPolicyConfiguration policyConfiguration);\n}", "des": "SetSubClusterPolicyConfigurationRequest is a request to the FederationPolicyStore to set the policy configuration corresponding to a queue."}
{"index": 4028, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SetSubClusterPolicyConfigurationRequestPBImpl {\n\tboolean equals(Object other);\n\t// Get the policy configuration assigned to the queue.\n\tSubClusterPolicyConfiguration getPolicyConfiguration();\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.SetSubClusterPolicyConfigurationRequestProto getProto();\n\t// Set the policyConfiguration configuration for the queue.\n\tvoid setPolicyConfiguration(SubClusterPolicyConfiguration policyConfiguration);\n}", "des": "Protocol buffer based implementation of SetSubClusterPolicyConfigurationRequest."}
{"index": 4029, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SubClusterId {\n\tint compareTo(SubClusterId other);\n\tboolean equals(Object obj);\n\t// Get the string identifier of the subcluster which is unique across the federated cluster.\n\tabstract String getId();\n\tstatic SubClusterId newInstance(String subClusterId);\n\t// Set the string identifier of the subcluster which is unique across the federated cluster.\n\tprotected abstract void setId(String subClusterId);\n}", "des": ""}
{"index": 4030, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SubClusterIdPBImpl {\n\t// Get the string identifier of the subcluster which is unique across the federated cluster.\n\tString getId();\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.SubClusterIdProto getProto();\n\t// Set the string identifier of the subcluster which is unique across the federated cluster.\n\tprotected void setId(String subClusterId);\n}", "des": "Protocol buffer based implementation of SubClusterId."}
{"index": 4031, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SubClusterRegisterRequest {\n\t// Get the SubClusterInfo encapsulating the information about the sub-cluster.\n\tabstract SubClusterInfo getSubClusterInfo();\n\tstatic SubClusterRegisterRequest newInstance(SubClusterInfo subClusterInfo);\n\t// Set the SubClusterInfo encapsulating the information about the sub-cluster.\n\tabstract void setSubClusterInfo(SubClusterInfo subClusterInfo);\n}", "des": ""}
{"index": 4032, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class SubClusterRegisterRequestPBImpl {\n\tboolean equals(Object other);\n\torg.apache.hadoop.yarn.federation.proto.YarnServerFederationProtos.SubClusterRegisterRequestProto getProto();\n\t// Get the SubClusterInfo encapsulating the information about the sub-cluster.\n\tSubClusterInfo getSubClusterInfo();\n\t// Set the SubClusterInfo encapsulating the information about the sub-cluster.\n\tvoid setSubClusterInfo(SubClusterInfo subClusterInfo);\n}", "des": "Protocol buffer based implementation of SubClusterRegisterRequest."}
{"index": 4033, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Interface SubClusterResolver {\n\t// Obtain the sub-cluster that a specified node belongs to.\n\tSubClusterId getSubClusterForNode(String nodename);\n\t// Obtain the sub-clusters that have nodes on a specified rack.\n\tSet<SubClusterId> getSubClustersForRack(String rackname);\n\t// Load the nodes to subCluster mapping from the file.\n\tvoid load();\n}", "des": "An utility that helps to determine the sub-cluster that a specified node or rack belongs to. All implementing classes should be thread-safe."}
{"index": 4034, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Enum SubClusterState {\n\t// Convert a string into SubClusterState.\n\tstatic SubClusterState fromString(String x);\n\tboolean isActive();\n\tboolean isFinal();\n\tboolean isUnusable();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SubClusterState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SubClusterState[] values();\n}", "des": ""}
{"index": 4035, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class UniformRandomRouterPolicy {\n\t// Simply picks a random active subCluster to start the AM (this does NOT depend on the weights in the policy).\n\tSubClusterId getHomeSubcluster(org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext appSubmissionContext, List<SubClusterId> blackListSubClusters);\n\t// This method is invoked to initialize of update the configuration of policies.\n\tvoid reinitialize(FederationPolicyInitializationContext policyContext);\n}", "des": "This simple policy picks at uniform random among any of the currently active subclusters. This policy is easy to use and good for testing. NOTE: this is \"almost\" subsumed by the WeightedRandomRouterPolicy. Behavior only diverges when there are active sub-clusters that are not part of the \"weights\", in which case the UniformRandomRouterPolicy send load to them, while WeightedRandomRouterPolicy does not."}
{"index": 4036, "repo": "hadoop-yarn-server-common-3.3.6", "code": "Class ZKClient {\n\t// get data published by the service at the registration address\n\tString getServiceData(String path);\n\t// list the services registered under a path\n\tList<String> listServices(String path);\n\t// register the service to a specific path\n\tvoid registerService(String path, String data);\n\t// unregister the service.\n\tvoid unregisterService(String path);\n}", "des": "ZK Registration Library currently does not use any authorization"}
{"index": 4037, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class FtpInboundChannelAdapterSpec {\n\t// Configure a simple pattern filter (e.g.\n\tFtpInboundChannelAdapterSpec patternFilter(java.lang.String pattern);\n\t// Configure a regex pattern filter (e.g.\n\tFtpInboundChannelAdapterSpec regexFilter(java.lang.String regex);\n}", "des": "A RemoteFileInboundChannelAdapterSpec for a FtpInboundFileSynchronizingMessageSource."}
{"index": 4038, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class ImapMailInboundChannelAdapterSpec {\n\t// A SearchTermStrategy to use.\n\tImapMailInboundChannelAdapterSpec searchTermStrategy(org.springframework.integration.mail.SearchTermStrategy searchTermStrategy);\n\t// A flag to determine if message should be marked as read.\n\tImapMailInboundChannelAdapterSpec shouldMarkMessagesAsRead(boolean shouldMarkMessagesAsRead);\n}", "des": "A MailInboundChannelAdapterSpec for IMAP."}
{"index": 4039, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class ScatterGatherSpec {\n\t// Specify a MessageChannel (optional) which is used internally in the ScatterGatherHandler for gathering (aggregate) results for scattered requests.\n\tScatterGatherSpec gatherChannel(org.springframework.messaging.MessageChannel gatherChannel);\n\t// Specify a timeout (in milliseconds) for the PollableChannel.receive(long) operation to wait for gathering results to output.\n\tScatterGatherSpec gatherTimeout(long gatherTimeout);\n}", "des": "A GenericEndpointSpec extension for the ScatterGatherHandler."}
{"index": 4040, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class Scripts {\n\t// The factory method to produce ScriptSpec based on the Resource.\n\tstatic ScriptSpec script(org.springframework.core.io.Resource scriptResource);\n\t// The factory method to produce ScriptSpec based on the script file location.\n\tstatic ScriptSpec script(java.lang.String scriptLocation);\n}", "des": "The factory for Dynamic Language Scripts (Groovy, Ruby, Python, JavaScript etc.)."}
{"index": 4041, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class SftpInboundChannelAdapterSpec {\n\t// Configure a simple pattern filter (e.g.\n\tSftpInboundChannelAdapterSpec patternFilter(java.lang.String pattern);\n\t// Configure a regex pattern filter (e.g.\n\tSftpInboundChannelAdapterSpec regexFilter(java.lang.String regex);\n}", "des": "A RemoteFileInboundChannelAdapterSpec for a SftpInboundFileSynchronizingMessageSource."}
{"index": 4042, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class SplitterEndpointSpec<S extends org.springframework.integration.splitter.AbstractMessageSplitter> {\n\t// Set the applySequence flag to the specified value.\n\tSplitterEndpointSpec<S> applySequence(boolean applySequence);\n\t// Set delimiters to tokenize String values.\n\tSplitterEndpointSpec<S> delimiters(java.lang.String delimiters);\n}", "des": "A ConsumerEndpointSpec for a AbstractMessageSplitter implementations."}
{"index": 4043, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class Tuple {\n\tboolean equals(java.lang.Object o);\n\tjava.lang.Object get(int index);\n\tjava.util.Iterator<java.lang.Object> iterator();\n\t// Return the number of elements in this Tuple.\n\tint size();\n\t// Turn this Tuple into a plain Object array.\n\tjava.lang.Object[] toArray();\n\t// Turn this Tuple into a plain Object list.\n\tjava.util.List<java.lang.Object> toList();\n}", "des": "A Tuple is an immutable Collection of objects, each of which can be of an arbitrary type."}
{"index": 4044, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class Tuple1<T1> {\n\tboolean equals(java.lang.Object o);\n\tjava.lang.Object get(int index);\n\t// Type-safe way to get the first object of this Tuple.\n\tT1 getT1();\n\t// Turn this Tuple into a plain Object array.\n\tjava.lang.Object[] toArray();\n}", "des": "A tuple that holds a single value."}
{"index": 4045, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class Tuple2<T1,T2> {\n\tboolean equals(java.lang.Object o);\n\tjava.lang.Object get(int index);\n\t// Type-safe way to get the second object of this Tuple.\n\tT2 getT2();\n\t// Turn this Tuple into a plain Object array.\n\tjava.lang.Object[] toArray();\n}", "des": "A tuple that holds two values."}
{"index": 4046, "repo": "spring-integration-java-dsl-1.2.3.RELEASE", "code": "Class Tuples {\n\t// Build an empty Tuple instance.\n\tstatic Tuple empty();\n\t// Create a Tuple1 with the given object.\n\tstatic <T1> Tuple1<T1> of(T1 t1);\n\t// Create a Tuple2 with the given objects.\n\tstatic <T1,T2> Tuple2<T1,T2> of(T1 t1, T2 t2);\n}", "des": "The Tuple factory."}
{"index": 4047, "repo": "tika-server-1.28.5", "code": "Class ProduceTypeResourceComparator {\n\t// Compares the class to handle.\n\tint compare(org.apache.cxf.jaxrs.model.ClassResourceInfo cri1, org.apache.cxf.jaxrs.model.ClassResourceInfo cri2, org.apache.cxf.message.Message message);\n\t// Compares the method to handle.\n\tint compare(org.apache.cxf.jaxrs.model.OperationResourceInfo oper1, org.apache.cxf.jaxrs.model.OperationResourceInfo oper2, org.apache.cxf.message.Message message);\n}", "des": "Resource comparator based to produce type. In an ambiguous call, request handler will be chosen based on the type of data it returns."}
{"index": 4048, "repo": "tika-server-1.28.5", "code": "Class ServerStatusExporter {\n\t// Gets the number of files processed in this cycle.\n\tlong getFilesProcessed();\n\t// Gets the milliseconds passed since last parse started.\n\tlong getMillisSinceLastParseStarted();\n\t// Gets the number of child restart.\n\tint getNumRestarts();\n\t// Gets server id.\n\tString getServerId();\n\t// Gets the current operating status as string.\n\tString getStatus();\n}", "des": "Server status JMX MBean exporter. Abstracts the ServerStatus, allowing only getters on server status. Used for monitoring only."}
{"index": 4049, "repo": "tika-server-1.28.5", "code": "Interface ServerStatusExporterMBean {\n\t// Gets the number of files processed in this cycle.\n\tlong getFilesProcessed();\n\t// Gets the milliseconds passed since last parse started.\n\tlong getMillisSinceLastParseStarted();\n\t// Gets the number of child restart.\n\tint getNumRestarts();\n\t// Gets server id.\n\tString getServerId();\n\t// Gets the current operating status as string.\n\tString getStatus();\n}", "des": "Server status JMX MBean exporter interface. Abstracts the ServerStatus."}
{"index": 4050, "repo": "curator-framework-5.5.0", "code": "Class CircuitBreakingConnectionStateListener {\n\t// Returns true if the circuit is open\n\tboolean isOpen();\n\t// Called when there is a state change in the connection\n\tvoid stateChanged(CuratorFramework client, ConnectionState newState);\n}", "des": ""}
{"index": 4051, "repo": "curator-framework-5.5.0", "code": "Enum ConnectionState {\n\t// Check if this state indicates that Curator has a connection to ZooKeeper\n\tabstract boolean isConnected();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConnectionState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConnectionState[] values();\n}", "des": "Represents state changes in the connection to ZK"}
{"index": 4052, "repo": "curator-framework-5.5.0", "code": "Class ConnectionStateManager {\n\t// Post a state change.\n\tboolean addStateChange(ConnectionState newConnectionState);\n\tboolean blockUntilConnected(int maxWaitTime, TimeUnit units);\n\tvoid close();\n\t// Return the listenable\n\tListenable<ConnectionStateListener> getListenable();\n\tboolean isConnected();\n\t// Change to ConnectionState.SUSPENDED only if not already suspended and not lost\n\tboolean setToSuspended();\n\t// Start the manager\n\tvoid start();\n}", "des": "Used internally to manage connection state"}
{"index": 4053, "repo": "curator-framework-5.5.0", "code": "Interface CuratorTempFramework {\n\t// Stop the client\n\tvoid close();\n\t// Start a get data builder\n\tTempGetDataBuilder getData();\n\t// Start a transaction builder\n\tCuratorTransaction inTransaction();\n}", "des": ""}
{"index": 4054, "repo": "curator-framework-5.5.0", "code": "Class EnsureContainers {\n\t// The first time this method is called, all nodes in the path will be created as containers if needed\n\tvoid ensure();\n\t// Reset so that the next call to ensure() will attempt to create containers\n\tvoid reset();\n}", "des": "Similar to EnsurePath but creates containers."}
{"index": 4055, "repo": "curator-framework-5.5.0", "code": "Interface Listenable<T> {\n\t// Add the given listener.\n\tvoid addListener(T listener);\n\t// Add the given listener.\n\tvoid addListener(T listener, Executor executor);\n\t// Remove the given listener\n\tvoid removeListener(T listener);\n}", "des": "Abstracts a listenable object"}
{"index": 4056, "repo": "curator-framework-5.5.0", "code": "Enum OperationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OperationType[] values();\n}", "des": "Transaction operation types"}
{"index": 4057, "repo": "curator-framework-5.5.0", "code": "Interface RemoveWatchesBuilder {\n\t// Specify the watcher to be removed\n\tRemoveWatchesType remove(CuratorWatcher watcher);\n\t// Specify the watcher to be removed\n\tRemoveWatchesType remove(org.apache.zookeeper.Watcher watcher);\n\t// Specify that all watches should be removed\n\tRemoveWatchesType removeAll();\n}", "des": "Builder to allow watches to be removed"}
{"index": 4058, "repo": "curator-framework-5.5.0", "code": "Class SchemaViolation.ViolatorData {\n\t// The ACLs used in the API or null\n\tList<org.apache.zookeeper.data.ACL> getAcl();\n\t// The data used in the API or null\n\tbyte[] getData();\n\t// The path used in the API or null\n\tString getPath();\n}", "des": "Data about the calling API that violated the schema"}
{"index": 4059, "repo": "curator-framework-5.5.0", "code": "Interface TransactionOp {\n\t// Start a check builder in the transaction\n\tTransactionCheckBuilder<CuratorOp> check();\n\t// Start a create builder in the transaction\n\tTransactionCreateBuilder<CuratorOp> create();\n\t// Start a delete builder in the transaction\n\tTransactionDeleteBuilder<CuratorOp> delete();\n\t// Start a setData builder in the transaction\n\tTransactionSetDataBuilder<CuratorOp> setData();\n}", "des": "Builds operations that can be committed as a transaction via CuratorFramework.transaction()"}
{"index": 4060, "repo": "spring-cloud-aws-messaging-2.2.6.RELEASE", "code": "Enum SqsMessageDeletionPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqsMessageDeletionPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqsMessageDeletionPolicy[] values();\n}", "des": "Defines the policy that must be used for the deletion of SQS messages once they were processed. The deletion policy can be set individually on every listener method using the @SqsListener annotation. The default policy is NO_REDRIVE because it is the safest way to avoid poison messages and have a safe way to avoid the loss of messages (i.e. using a dead letter queue)."}
{"index": 4061, "repo": "spring-data-solr-4.3.15", "code": "Class AbstractFacetAndHighlightQueryDecorator {\n\tFacetOptions getFacetOptions();\n\tHighlightOptions getHighlightOptions();\n\tboolean hasFacetOptions();\n\tboolean hasHighlightOptions();\n\t// Faceting options to apply when executing query\n\t<T extends SolrDataQuery>T setFacetOptions(FacetOptions facetOptions);\n\t// Highlight options to apply when exectuing query\n\t<T extends SolrDataQuery>T setHighlightOptions(HighlightOptions highlightOptions);\n}", "des": "General purpose FacetAndHighlightQuery decorator."}
{"index": 4062, "repo": "spring-data-solr-4.3.15", "code": "Interface Cursor<T> {\n\t// Get the current set cursorMark\n\tSerializable getCursorMark();\n\tlong getPosition();\n\tboolean isClosed();\n\tboolean isOpen();\n\t// Opens the cursor.\n\tCursor<T> open();\n}", "des": "Cursor provides a lazy loading abstraction for fetching documents."}
{"index": 4063, "repo": "spring-data-solr-4.3.15", "code": "Enum DateTimeConverters.DateToJodaDateTimeConverter {\n\torg.joda.time.DateTime convert(Date source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DateTimeConverters.DateToJodaDateTimeConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DateTimeConverters.DateToJodaDateTimeConverter[] values();\n}", "des": "Reading Converter parses Date from SolrDocument to DateTime"}
{"index": 4064, "repo": "spring-data-solr-4.3.15", "code": "Enum DateTimeConverters.DateToLocalDateTimeConverter {\n\torg.joda.time.LocalDateTime convert(Date source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DateTimeConverters.DateToLocalDateTimeConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DateTimeConverters.DateToLocalDateTimeConverter[] values();\n}", "des": "Reading Converter parses Date from SolrDocument to LocalDateTime"}
{"index": 4065, "repo": "spring-data-solr-4.3.15", "code": "Enum DateTimeConverters.JavaDateConverter {\n\tString convert(Date source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DateTimeConverters.JavaDateConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DateTimeConverters.JavaDateConverter[] values();\n}", "des": "Converter used to parse Date to String used for setting SolrQuery query string values"}
{"index": 4066, "repo": "spring-data-solr-4.3.15", "code": "Enum DateTimeConverters.JodaDateTimeConverter {\n\tString convert(org.joda.time.ReadableInstant source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DateTimeConverters.JodaDateTimeConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DateTimeConverters.JodaDateTimeConverter[] values();\n}", "des": "Converter used to parse DateTime to String used for setting SolrQuery query string values"}
{"index": 4067, "repo": "spring-data-solr-4.3.15", "code": "Enum DateTimeConverters.JodaDateTimeToDateConverter {\n\tDate convert(org.joda.time.DateTime source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DateTimeConverters.JodaDateTimeToDateConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DateTimeConverters.JodaDateTimeToDateConverter[] values();\n}", "des": "Writing Converter converts DateTime to Date so it can be used within SolrInputDocument"}
{"index": 4068, "repo": "spring-data-solr-4.3.15", "code": "Enum DateTimeConverters.JodaLocalDateTimeConverter {\n\tString convert(org.joda.time.LocalDateTime source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DateTimeConverters.JodaLocalDateTimeConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DateTimeConverters.JodaLocalDateTimeConverter[] values();\n}", "des": "Converter used to parse LocalDateTime to String used for setting SolrQuery query string values"}
{"index": 4069, "repo": "spring-data-solr-4.3.15", "code": "Enum DateTimeConverters.JodaLocalDateTimeToDateConverter {\n\tDate convert(org.joda.time.LocalDateTime source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DateTimeConverters.JodaLocalDateTimeToDateConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DateTimeConverters.JodaLocalDateTimeToDateConverter[] values();\n}", "des": "Writing Converter converts LocalDateTime to Date so it can be used within SolrInputDocument"}
{"index": 4070, "repo": "spring-data-solr-4.3.15", "code": "Class DefaultSchemaOperations {\n\t// Add given SchemaDefinition.SchemaField.\n\tvoid addField(SchemaDefinition.SchemaField field);\n\t// Get the current schema name.\n\tString getSchemaName();\n\t// Get the current schema version.\n\tDouble getSchemaVersion();\n\t// Read back the SchemaDefinition from server.\n\tSchemaDefinition readSchema();\n\t// Remove the field with given name.\n\tvoid removeField(String name);\n}", "des": "SchemaOperations implementation based on SolrTemplate."}
{"index": 4071, "repo": "spring-data-solr-4.3.15", "code": "Class DelegatingCursor.PartialResult<T> {\n\t// Get items returned from server.\n\tCollection<T> getItems();\n\t// Get the next cursor mark to use.\n\tString getNextCursorMark();\n\tIterator<T> iterator();\n}", "des": "DelegatingCursor.PartialResult provided by a round trip to SolrClient loading data for an iteration. Also holds the cursor mark to use next."}
{"index": 4072, "repo": "spring-data-solr-4.3.15", "code": "Class ExistsFunction {\n\t// Creates new ExistsFunction representing exists(field)\n\tstatic ExistsFunction exists(Field field);\n\t// Creates new ExistsFunction representing exists(function())\n\tstatic ExistsFunction exists(Function function);\n\t// Creates new ExistsFunction representing exists(fieldname)\n\tstatic ExistsFunction exists(String fieldName);\n\t// solr readable representation of function\n\tString getOperation();\n}", "des": "Implementation of exists(field|function)"}
{"index": 4073, "repo": "spring-data-solr-4.3.15", "code": "Interface FacetFieldEntry {\n\t// get the associated Field\n\tField getField();\n\t// The key of the facetEntry\n\tField getKey();\n}", "des": "Entry for facet on field"}
{"index": 4074, "repo": "spring-data-solr-4.3.15", "code": "Interface FacetQueryEntry {\n\t// The key of the facetEntry\n\tString getKey();\n\t// get the associated Query\n\tFilterQuery getQuery();\n}", "des": "Facet Entry for facet via query"}
{"index": 4075, "repo": "spring-data-solr-4.3.15", "code": "Interface Field {\n\t// Create a Field with given alias for the calculated distance.\n\tstatic Field distance(String alias);\n\t// Get the name of the field used in schema.xml of solr server\n\tString getName();\n\t// Create a Field with given name.\n\tstatic Field of(String name);\n\t// Create a Field for the given names.\n\tstatic Field pivot(String... names);\n}", "des": "Defines a Field that can be used within Criteria."}
{"index": 4076, "repo": "spring-data-solr-4.3.15", "code": "Class FieldWithQueryParameters<T extends QueryParameter> {\n\tvoid addQueryParameter(T parameter);\n\t// Get the parameter for given name.\n\tT getQueryParameter(String parameterName);\n\t// Get Collection of all parameters\n\tCollection<T> getQueryParameters();\n\t// Get value of given parameter\n\t<S> S getQueryParameterValue(String parameterName);\n\tboolean hasQueryParameters();\n\tIterator<T> iterator();\n\t// remove parameter with given name\n\tT removeQueryParameter(String parameterName);\n}", "des": "Field that holds additional parameters to provide query hints to solr."}
{"index": 4077, "repo": "spring-data-solr-4.3.15", "code": "Interface FilterQuery {\n\t// Create a new FilterQuery with the given Criteria.\n\tstatic FilterQuery filter(Criteria criteria);\n\t// Create a new FilterQuery applying a geodist function.\n\tstatic FilterQuery geoFilter(String from, Point to);\n}", "des": "Filter Queries are simple solr Queries applied after executing the original query. This corresponds to the fq Parameter within solr."}
{"index": 4078, "repo": "spring-data-solr-4.3.15", "code": "Enum Function.Context.Target {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Function.Context.Target valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Function.Context.Target[] values();\n}", "des": "The actual context target."}
{"index": 4079, "repo": "spring-data-solr-4.3.15", "code": "Enum GeoConverters.DistanceToStringConverter {\n\tString convert(Distance source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GeoConverters.DistanceToStringConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GeoConverters.DistanceToStringConverter[] values();\n}", "des": "Converts a Distance to a solrReadable request parameter."}
{"index": 4080, "repo": "spring-data-solr-4.3.15", "code": "Enum GeoConverters.Point2DToStringConverter {\n\tString convert(Point source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GeoConverters.Point2DToStringConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GeoConverters.Point2DToStringConverter[] values();\n}", "des": "Converts a Point to a solrReadable request parameter."}
{"index": 4081, "repo": "spring-data-solr-4.3.15", "code": "Enum GeoConverters.Point3DToStringConverter {\n\tString convert(Point source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GeoConverters.Point3DToStringConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GeoConverters.Point3DToStringConverter[] values();\n}", "des": "Converts a Point to a solrReadable request parameter."}
{"index": 4082, "repo": "spring-data-solr-4.3.15", "code": "Enum GeoConverters.StringToPointConverter {\n\tPoint convert(String source);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GeoConverters.StringToPointConverter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GeoConverters.StringToPointConverter[] values();\n}", "des": "Converts comma separated string to Point."}
{"index": 4083, "repo": "spring-data-solr-4.3.15", "code": "Interface GroupEntry<T> {\n\t// Group name, the value on which the results were grouped by.\n\tString getGroupValue();\n\t// Results for the current group.\n\tPage<T> getResult();\n}", "des": "Representation of a group in a GroupResult."}
{"index": 4084, "repo": "spring-data-solr-4.3.15", "code": "Interface GroupPage<T> {\n\t// Get a group result done for the given Field.\n\tGroupResult<T> getGroupResult(Field field);\n\t// Get a group result done for the given Function.\n\tGroupResult<T> getGroupResult(Function function);\n\t// Get a group result done for the given Query.\n\tGroupResult<T> getGroupResult(Query query);\n\t// Get a group result with the given name.\n\tGroupResult<T> getGroupResult(String name);\n}", "des": "Representation of a Group result page, holding one GroupResult for each grouping requested on a org.springframework.data.solr.core.query.GroupQuery."}
{"index": 4085, "repo": "spring-data-solr-4.3.15", "code": "Interface GroupResult<T> {\n\t// Group entries.\n\tPage<GroupEntry<T>> getGroupEntries();\n\t// Groups count.\n\tInteger getGroupsCount();\n\t// Matched documents for this group.\n\tint getMatches();\n\t// Grouping result name.\n\tString getName();\n}", "des": "Representation of a group in response to group request (i.e. , , ) will have a GroupResult representation."}
{"index": 4086, "repo": "spring-data-solr-4.3.15", "code": "Class IfFunction {\n\t// solr readable representation of function\n\tString getOperation();\n\tstatic IfFunction.Builder when(Field field);\n\tstatic IfFunction.Builder when(Function function);\n\t// Creates new IfFunction.Builder for creating IfFunction\n\tstatic IfFunction.Builder when(Object condition);\n\tstatic IfFunction.Builder when(String fieldname);\n}", "des": "Implementation of if(value|field|function,trueValue,falseValue)"}
{"index": 4087, "repo": "spring-data-solr-4.3.15", "code": "Class MappingSolrEntityInformation<T,ID> {\n\t// Get the name of the solr collection the entity resides in.\n\tString getCollectionName();\n\t// Get the name of the id attribute.\n\tString getIdAttribute();\n}", "des": "Solr specific implementation of AbstractEntityInformation"}
{"index": 4088, "repo": "spring-data-solr-4.3.15", "code": "Enum Query.Operator {\n\tString asQueryStringRepresentation();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Query.Operator valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Query.Operator[] values();\n}", "des": "Operator to be used for q.op"}
{"index": 4089, "repo": "spring-data-solr-4.3.15", "code": "Interface QueryParser {\n\t// Convert given Query into a SolrQuery executable via SolrClient\n\torg.apache.solr.client.solrj.SolrQuery constructSolrQuery(SolrDataQuery query, Class<?> domainType);\n\t// Get the queryString to use withSolrQuery.setParam(CommonParams.Q, \"queryString\"}\n\tString getQueryString(SolrDataQuery query, Class<?> domainType);\n\t// Register an additional converter for transforming object values to solr readable format\n\tvoid registerConverter(Converter<?,?> converter);\n}", "des": "The QueryParser takes a spring-data-solr Query and returns a SolrQuery. All Query parameters are translated into the according SolrQuery fields. Example: Query query = new SimpleQuery(new Criteria(\"field_1\").is(\"value_1\").and(\"field_2\").startsWith(\"value_2\")).addProjection(\"field_3\").setPageRequest(new PageRequest(0, 10)); Will be parsed to a SolrQuery that outputs the following q=field_1%3Avalue_1+AND+field_2%3Avalue_2*&fl=field_3&start=0&rows=10"}
{"index": 4090, "repo": "spring-data-solr-4.3.15", "code": "Enum RequestMethod {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RequestMethod valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RequestMethod[] values();\n}", "des": "HTTP request types supported by SolrRequest."}
{"index": 4091, "repo": "spring-data-solr-4.3.15", "code": "Interface SchemaOperations {\n\t// Add given SchemaDefinition.SchemaField.\n\tvoid addField(SchemaDefinition.SchemaField field);\n\t// Get the current schema name.\n\tString getSchemaName();\n\t// Get the current schema version.\n\tDouble getSchemaVersion();\n\t// Read back the SchemaDefinition from server.\n\tSchemaDefinition readSchema();\n\t// Remove the field with given name.\n\tvoid removeField(String name);\n}", "des": "Operations interface for executing modification on a managed schema."}
{"index": 4092, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleFacetQuery {\n\t// Add an criteria to the query.\n\t<T extends SolrDataQuery>T addCriteria(Criteria criteria);\n\tCriteria getCriteria();\n\tFacetOptions getFacetOptions();\n\tJoin getJoin();\n\tString getRequestHandler();\n\tboolean hasFacetOptions();\n\t// Faceting options to apply when executing query\n\t<T extends SolrDataQuery>T setFacetOptions(FacetOptions facetOptions);\n\t// Set values for join {@code !\n\tvoid setJoin(Join join);\n\tvoid setRequestHandler(String requestHandler);\n}", "des": "Trivial implementation of FacetQuery"}
{"index": 4093, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleFacetQueryEntry {\n\t// The key of the facetEntry\n\tString getKey();\n\t// get the associated Query\n\tFilterQuery getQuery();\n}", "des": "Trivial implementation of FacetQueryEntry"}
{"index": 4094, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleFilterQuery {\n\t// Add an criteria to the query.\n\t<T extends SolrDataQuery>T addCriteria(Criteria criteria);\n\tCriteria getCriteria();\n\tJoin getJoin();\n\tString getRequestHandler();\n\t// Set values for join {@code !\n\tvoid setJoin(Join join);\n\tvoid setRequestHandler(String requestHandler);\n}", "des": "Trivial implementation of FilterQuery"}
{"index": 4095, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleGroupEntry<T> {\n\t// Group name, the value on which the results were grouped by.\n\tString getGroupValue();\n\t// Results for the current group.\n\tPage<T> getResult();\n}", "des": "Represents a group holding the group value and all beans belonging to the group."}
{"index": 4096, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleGroupResult<T> {\n\t// Group entries.\n\tPage<GroupEntry<T>> getGroupEntries();\n\t// Groups count.\n\tInteger getGroupsCount();\n\t// Matched documents for this group.\n\tint getMatches();\n\t// Grouping result name.\n\tString getName();\n}", "des": "This represents the result of a group command. This can be the result of the following parameter: field, function or query."}
{"index": 4097, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleHighlightQuery {\n\t// Add an criteria to the query.\n\t<T extends SolrDataQuery>T addCriteria(Criteria criteria);\n\tCriteria getCriteria();\n\tHighlightOptions getHighlightOptions();\n\tJoin getJoin();\n\tString getRequestHandler();\n\tboolean hasHighlightOptions();\n\t// Highlight options to apply when exectuing query\n\t<T extends SolrDataQuery>T setHighlightOptions(HighlightOptions highlightOptions);\n\t// Set values for join {@code !\n\tvoid setJoin(Join join);\n\tvoid setRequestHandler(String requestHandler);\n}", "des": "Trivial implementation of HighlightQuery extending SimpleQuery."}
{"index": 4098, "repo": "spring-data-solr-4.3.15", "code": "Class SimplePivotField {\n\tboolean equals(Object obj);\n\t// Get the fields for this pivot.\n\tList<Field> getFields();\n\t// Get the name of the field used in schema.xml of solr server\n\tString getName();\n}", "des": "The most trivial implementation of PivotField."}
{"index": 4099, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleSolrPersistentEntity<T> {\n\t// Get the core's name for this entity.\n\tString getCollectionName();\n\t// Returns the score property of the SolrPersistentEntity.\n\tSolrPersistentProperty getScoreProperty();\n\t// Returns whether the SolrPersistentEntity has an score property.\n\tboolean hasScoreProperty();\n\tvoid setApplicationContext(ApplicationContext applicationContext);\n\tvoid verify();\n}", "des": "Solr specific PersistentEntity implementation holding eg. name of solr core."}
{"index": 4100, "repo": "spring-data-solr-4.3.15", "code": "Class SimpleUpdateField {\n\t// UpdateAction to perform during update\n\tUpdateAction getAction();\n\t// Get value for field\n\tObject getValue();\n\tvoid setValue(Object value);\n}", "des": "Implementation of UpdateField to be used with Update"}
{"index": 4101, "repo": "spring-data-solr-4.3.15", "code": "Class SolrClientUtils {\n\t// Close the SolrClient by calling Closeable.close() or shutdown for the generation 5 libraries.\n\tstatic void close(org.apache.solr.client.solrj.SolrClient solrClient);\n\t// Resolve solr core/collection name for given type.\n\tstatic String resolveSolrCoreName(Class<?> type);\n}", "des": "SolrClientUtils replaces SolrServerUtils from version 1.x"}
{"index": 4102, "repo": "spring-data-solr-4.3.15", "code": "Interface SolrDataQuery {\n\t// Append criteria to query.\n\t<T extends SolrDataQuery>T addCriteria(Criteria criteria);\n\tCriteria getCriteria();\n\tJoin getJoin();\n\t// Set values for join {@code !\n\tvoid setJoin(Join join);\n}", "des": "Common interface for any Query"}
{"index": 4103, "repo": "spring-data-solr-4.3.15", "code": "Interface StatsPage<T> {\n\t// Get the stats result done for the given Field.\n\tFieldStatsResult getFieldStatsResult(Field field);\n\t// Get the stats result done for the field with the given fieldName.\n\tFieldStatsResult getFieldStatsResult(String fieldName);\n\t// Get all field stats results for this page.\n\tMap<String,FieldStatsResult> getFieldStatsResults();\n}", "des": "Representation of a Stats result page, holding one FieldStatsResult for each field statistic requested on a Query through StatsOptions."}
{"index": 4104, "repo": "spring-data-solr-4.3.15", "code": "Interface Update {\n\t// get id field of document to update\n\tValueHoldingField getIdField();\n\t// List of fields and values to update\n\tIterable<UpdateField> getUpdates();\n\t// Document Version _version_\n\tObject getVersion();\n}", "des": "Update one or more fields of a Document without touching the others."}
{"index": 4105, "repo": "spring-data-solr-4.3.15", "code": "Enum UpdateAction {\n\tString getSolrOperation();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic UpdateAction valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic UpdateAction[] values();\n}", "des": "Actions to be performed during an atomic field update."}
{"index": 4106, "repo": "spring-data-solr-4.3.15", "code": "Class ValueCountEntry {\n\t// The value within the field\n\tString getValue();\n\t// The nr of hits for the value\n\tlong getValueCount();\n}", "des": "Implementation of CountEntry"}
{"index": 4107, "repo": "exoplayer-core-2.9.6", "code": "Class Ac3Reader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator generator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous (E-)AC-3 byte stream and extracts individual samples."}
{"index": 4108, "repo": "exoplayer-core-2.9.6", "code": "Class ActionFile {\n\t// Loads DownloadActions from file.\n\tDownloadAction[] load(DownloadAction.Deserializer... deserializers);\n\t// Stores DownloadActions to file.\n\tvoid store(DownloadAction... downloadActions);\n}", "des": "Stores and loads DownloadActions to/from a file."}
{"index": 4109, "repo": "exoplayer-core-2.9.6", "code": "Interface AdsLoader.AdViewProvider {\n\t// Returns an array of views that are shown on top of the ad view group, but that are essential for controlling playback and should be excluded from ad viewability measurements by the AdsLoader (if it supports this).\n\tandroid.view.View[] getAdOverlayViews();\n\t// Returns the ViewGroup on top of the player that will show any ad UI.\n\tandroid.view.ViewGroup getAdViewGroup();\n}", "des": "Provides views for the ad UI."}
{"index": 4110, "repo": "exoplayer-core-2.9.6", "code": "Interface AdsLoader.EventListener {\n\t// Called when the user clicks through an ad (for example, following a 'learn more' link).\n\tdefault void onAdClicked();\n\t// Called when there was an error loading ads.\n\tdefault void onAdLoadError(AdsMediaSource.AdLoadException error, DataSpec dataSpec);\n\t// Called when the ad playback state has been updated.\n\tdefault void onAdPlaybackState(AdPlaybackState adPlaybackState);\n\t// Called when the user taps a non-clickthrough part of an ad.\n\tdefault void onAdTapped();\n}", "des": "Listener for ads loader events. All methods are called on the main thread."}
{"index": 4111, "repo": "exoplayer-core-2.9.6", "code": "Interface AdsMediaSource.MediaSourceFactory {\n\t// Creates a new MediaSource for loading the ad media with the specified uri.\n\tMediaSource createMediaSource(android.net.Uri uri);\n\t// Returns the content types supported by media sources created by this factory.\n\tint[] getSupportedTypes();\n}", "des": "Factory for creating MediaSources to play ad media."}
{"index": 4112, "repo": "exoplayer-core-2.9.6", "code": "Class AesCipherDataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] data, int offset, int length);\n}", "des": "A wrapping DataSink that encrypts the data being consumed."}
{"index": 4113, "repo": "exoplayer-core-2.9.6", "code": "Class AssetDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to readLength bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading from a local asset."}
{"index": 4114, "repo": "exoplayer-core-2.9.6", "code": "Class AtomicFile {\n\t// Delete the atomic file.\n\tvoid delete();\n\t// Call when you have successfully finished writing to the stream returned by startWrite().\n\tvoid endWrite(java.io.OutputStream str);\n\t// Open the atomic file for reading.\n\tjava.io.InputStream openRead();\n\t// Start a new write operation on the file.\n\tjava.io.OutputStream startWrite();\n}", "des": "A helper class for performing atomic operations on a file by creating a backup file until a write has successfully completed."}
{"index": 4115, "repo": "exoplayer-core-2.9.6", "code": "Class AudioCapabilities {\n\tboolean equals(java.lang.Object other);\n\t// Returns the current audio capabilities for the device.\n\tstatic AudioCapabilities getCapabilities(android.content.Context context);\n\t// Returns the maximum number of channels the device can play at the same time.\n\tint getMaxChannelCount();\n\t// Returns whether this device supports playback of the specified audio encoding.\n\tboolean supportsEncoding(int encoding);\n}", "des": "Represents the set of audio formats that a device is capable of playing."}
{"index": 4116, "repo": "exoplayer-core-2.9.6", "code": "Class AudioCapabilitiesReceiver {\n\t// Registers the receiver, meaning it will notify the listener when audio capability changes occur.\n\tAudioCapabilities register();\n\t// Unregisters the receiver, meaning it will no longer notify the listener when audio capability changes occur.\n\tvoid unregister();\n}", "des": "Receives broadcast events indicating changes to the device's audio capabilities, notifying a AudioCapabilitiesReceiver.Listener when audio capability changes occur."}
{"index": 4117, "repo": "exoplayer-core-2.9.6", "code": "Interface AudioFocusManager.PlayerControl {\n\t// Called when a command must be executed on the player.\n\tvoid executePlayerCommand(int playerCommand);\n\t// Called when the volume multiplier on the player should be changed.\n\tvoid setVolumeMultiplier(float volumeMultiplier);\n}", "des": "Interface to allow AudioFocusManager to give commands to a player."}
{"index": 4118, "repo": "exoplayer-core-2.9.6", "code": "Interface AudioListener {\n\t// Called when the audio attributes change.\n\tdefault void onAudioAttributesChanged(AudioAttributes audioAttributes);\n\t// Called when the audio session is set.\n\tdefault void onAudioSessionId(int audioSessionId);\n\t// Called when the volume changes.\n\tdefault void onVolumeChanged(float volume);\n}", "des": "A listener for changes in audio configuration."}
{"index": 4119, "repo": "exoplayer-core-2.9.6", "code": "Interface AudioSink.Listener {\n\t// Called if the audio sink has started rendering audio to a new platform audio session.\n\tvoid onAudioSessionId(int audioSessionId);\n\t// Called when the audio sink handles a buffer whose timestamp is discontinuous with the last buffer handled since it was reset.\n\tvoid onPositionDiscontinuity();\n\t// Called when the audio sink runs out of data.\n\tvoid onUnderrun(int bufferSize, long bufferSizeMs, long elapsedSinceLastFeedMs);\n}", "des": "Listener for audio sink events."}
{"index": 4120, "repo": "exoplayer-core-2.9.6", "code": "Class BaseMediaChunk {\n\t// Returns the index of the first sample in the specified track of the output that will originate from this chunk.\n\tint getFirstSampleIndex(int trackIndex);\n\t// Returns the output most recently passed to init(BaseMediaChunkOutput).\n\tprotected BaseMediaChunkOutput getOutput();\n\t// Initializes the chunk for loading, setting the BaseMediaChunkOutput that will receive samples as they are loaded.\n\tvoid init(BaseMediaChunkOutput output);\n}", "des": "A base implementation of MediaChunk that outputs to a BaseMediaChunkOutput."}
{"index": 4121, "repo": "exoplayer-core-2.9.6", "code": "Class BaseMediaChunkIterator {\n\t// Verifies that the iterator points to a valid element.\n\tprotected void checkInBounds();\n\t// Returns the current index this iterator is pointing to.\n\tprotected long getCurrentIndex();\n\t// Returns whether the iteration has reached the end of the available data.\n\tboolean isEnded();\n\t// Moves the iterator to the next media chunk.\n\tboolean next();\n}", "des": "Base class for MediaChunkIterators. Handles next() and isEnded(), and provides a bounds check for child classes."}
{"index": 4122, "repo": "exoplayer-core-2.9.6", "code": "Class BaseMediaChunkOutput {\n\t// Returns the current absolute write indices of the individual sample queues.\n\tint[] getWriteIndices();\n\t// Sets an offset that will be added to the timestamps (and sub-sample timestamps) of samples subsequently written to the sample queues.\n\tvoid setSampleOffsetUs(long sampleOffsetUs);\n\t// Called to get the TrackOutput for a specific track.\n\tTrackOutput track(int id, int type);\n}", "des": "An output for BaseMediaChunks."}
{"index": 4123, "repo": "exoplayer-core-2.9.6", "code": "Class BinarySearchSeeker.BinarySearchSeekMap {\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Obtains seek points for the specified seek time in microseconds.\n\tSeekMap.SeekPoints getSeekPoints(long timeUs);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n\tlong timeUsToTargetTime(long timeUs);\n}", "des": "A SeekMap implementation that returns the estimated byte location from BinarySearchSeeker.SeekOperationParams.calculateNextSearchBytePosition(long, long, long, long, long, long) for each getSeekPoints(long) query."}
{"index": 4124, "repo": "exoplayer-core-2.9.6", "code": "Interface BinarySearchSeeker.TimestampSeeker {\n\t// Called when a seek operation finishes.\n\tdefault void onSeekFinished();\n\t// Searches a limited window of the provided input for a target timestamp.\n\tBinarySearchSeeker.TimestampSearchResult searchForTimestamp(ExtractorInput input, long targetTimestamp, BinarySearchSeeker.OutputFrameHolder outputFrameHolder);\n}", "des": "A seeker that looks for a given timestamp from an input."}
{"index": 4125, "repo": "exoplayer-core-2.9.6", "code": "Class ByteArrayDataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Returns the data written to the sink since the last call to open(DataSpec), or null if open(DataSpec) has never been called.\n\tbyte[] getData();\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] buffer, int offset, int length);\n}", "des": "A DataSink for writing to a byte array."}
{"index": 4126, "repo": "exoplayer-core-2.9.6", "code": "Class ByteArrayDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to readLength bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading from a byte array."}
{"index": 4127, "repo": "exoplayer-core-2.9.6", "code": "Interface Cache.Listener {\n\t// Called when a CacheSpan is added to the cache.\n\tvoid onSpanAdded(Cache cache, CacheSpan span);\n\t// Called when a CacheSpan is removed from the cache.\n\tvoid onSpanRemoved(Cache cache, CacheSpan span);\n\t// Called when an existing CacheSpan is accessed, causing it to be replaced.\n\tvoid onSpanTouched(Cache cache, CacheSpan oldSpan, CacheSpan newSpan);\n}", "des": "Listener of Cache events."}
{"index": 4128, "repo": "exoplayer-core-2.9.6", "code": "Class CacheDataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Sets whether file descriptors are synced when closing output streams.\n\tvoid experimental_setSyncFileDescriptor(boolean syncFileDescriptor);\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] buffer, int offset, int length);\n}", "des": "Writes data into a cache."}
{"index": 4129, "repo": "exoplayer-core-2.9.6", "code": "Interface CacheDataSource.EventListener {\n\t// Called when bytes have been read from the cache.\n\tvoid onCachedBytesRead(long cacheSizeBytes, long cachedBytesRead);\n\t// Called when the current request ignores cache.\n\tvoid onCacheIgnored(int reason);\n}", "des": "Listener of CacheDataSource events."}
{"index": 4130, "repo": "exoplayer-core-2.9.6", "code": "Interface CacheEvictor {\n\t// Called when cache has been initialized.\n\tvoid onCacheInitialized();\n\t// Called when a writer starts writing to the cache.\n\tvoid onStartFile(Cache cache, java.lang.String key, long position, long maxLength);\n}", "des": "Evicts data from a Cache. Implementations should call Cache.removeSpan(CacheSpan) to evict cache entries based on their eviction policies."}
{"index": 4131, "repo": "exoplayer-core-2.9.6", "code": "Class CacheSpan {\n\tint compareTo(CacheSpan another);\n\t// Returns whether this is a hole CacheSpan.\n\tboolean isHoleSpan();\n\t// Returns whether this is an open-ended CacheSpan.\n\tboolean isOpenEnded();\n}", "des": "Defines a span of data that may or may not be cached (as indicated by isCached)."}
{"index": 4132, "repo": "exoplayer-core-2.9.6", "code": "Interface CameraMotionListener {\n\t// Called when a new camera motion is read.\n\tvoid onCameraMotion(long timeUs, float[] rotation);\n\t// Called when the camera motion track position is reset or the track is disabled.\n\tvoid onCameraMotionReset();\n}", "des": "Listens camera motion."}
{"index": 4133, "repo": "exoplayer-core-2.9.6", "code": "Class Cea708InitializationData {\n\t// Builds binary CEA-708 initialization data.\n\tstatic java.util.List<byte[]> buildData(boolean isWideAspectRatio);\n\t// Returns an object representation of CEA-708 initialization data\n\tstatic Cea708InitializationData fromData(java.util.List<byte[]> initializationData);\n}", "des": "Initialization data for CEA-708 decoders."}
{"index": 4134, "repo": "exoplayer-core-2.9.6", "code": "Class CeaUtil {\n\t// Consumes the unescaped content of an SEI NAL unit, writing the content of any CEA-608 messages as samples to all of the provided outputs.\n\tstatic void consume(long presentationTimeUs, ParsableByteArray seiBuffer, TrackOutput[] outputs);\n\t// Consumes caption data (cc_data), writing the content as samples to all of the provided outputs.\n\tstatic void consumeCcData(long presentationTimeUs, ParsableByteArray ccDataBuffer, TrackOutput[] outputs);\n}", "des": "Utility methods for handling CEA-608/708 messages. Defined in A/53 Part 4:2009."}
{"index": 4135, "repo": "exoplayer-core-2.9.6", "code": "Class ChapterFrame {\n\tint describeContents();\n\tboolean equals(java.lang.Object obj);\n\t// Returns the sub-frame at index.\n\tId3Frame getSubFrame(int index);\n\t// Returns the number of sub-frames.\n\tint getSubFrameCount();\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "Chapter information ID3 frame."}
{"index": 4136, "repo": "exoplayer-core-2.9.6", "code": "Class ChapterTocFrame {\n\tboolean equals(java.lang.Object obj);\n\t// Returns the sub-frame at index.\n\tId3Frame getSubFrame(int index);\n\t// Returns the number of sub-frames.\n\tint getSubFrameCount();\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "Chapter table of contents ID3 frame."}
{"index": 4137, "repo": "exoplayer-core-2.9.6", "code": "Class ChunkIndex {\n\t// Obtains the index of the chunk corresponding to a given time.\n\tint getChunkIndex(long timeUs);\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Obtains seek points for the specified seek time in microseconds.\n\tSeekMap.SeekPoints getSeekPoints(long timeUs);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n}", "des": "Defines chunks of samples within a media stream."}
{"index": 4138, "repo": "exoplayer-core-2.9.6", "code": "Class ColorParser {\n\t// Parses a CSS color expression.\n\tstatic int parseCssColor(java.lang.String colorExpression);\n\t// Parses a TTML color expression.\n\tstatic int parseTtmlColor(java.lang.String colorExpression);\n}", "des": "Parser for color expressions found in styling formats, e.g. TTML and CSS."}
{"index": 4139, "repo": "exoplayer-core-2.9.6", "code": "Class CompositeSequenceableLoader {\n\t// Attempts to continue loading.\n\tboolean continueLoading(long positionUs);\n\t// Returns an estimate of the position up to which data is buffered.\n\tlong getBufferedPositionUs();\n\t// Returns the next load time, or C.TIME_END_OF_SOURCE if loading has finished.\n\tlong getNextLoadPositionUs();\n\t// Re-evaluates the buffer given the playback position.\n\tvoid reevaluateBuffer(long positionUs);\n}", "des": "A SequenceableLoader that encapsulates multiple other SequenceableLoaders."}
{"index": 4140, "repo": "exoplayer-core-2.9.6", "code": "Class ConditionVariable {\n\t// Blocks until the condition is opened.\n\tvoid block();\n\t// Blocks until the condition is opened or until timeout milliseconds have passed.\n\tboolean block(long timeout);\n\t// Closes the condition.\n\tboolean close();\n\t// Opens the condition and releases all threads that are blocked.\n\tboolean open();\n}", "des": "An interruptible condition variable whose open() and close() methods return whether they resulted in a change of state."}
{"index": 4141, "repo": "exoplayer-core-2.9.6", "code": "Class ConstantBitrateSeekMap {\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Obtains seek points for the specified seek time in microseconds.\n\tSeekMap.SeekPoints getSeekPoints(long timeUs);\n\t// Returns the stream time in microseconds for a given position.\n\tlong getTimeUsAtPosition(long position);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n}", "des": "A SeekMap implementation that assumes the stream has a constant bitrate and consists of multiple independent frames of the same size. Seek points are calculated to be at frame boundaries."}
{"index": 4142, "repo": "exoplayer-core-2.9.6", "code": "Class ContainerMediaChunk {\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Returns the next chunk index or C.INDEX_UNSET if it is not known.\n\tlong getNextChunkIndex();\n\t// Returns whether the chunk has been fully loaded.\n\tboolean isLoadCompleted();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A BaseMediaChunk that uses an Extractor to decode sample data."}
{"index": 4143, "repo": "exoplayer-core-2.9.6", "code": "Class ContentDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to readLength bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading from a content URI."}
{"index": 4144, "repo": "exoplayer-core-2.9.6", "code": "Interface ContentMetadata {\n\t// Returns whether the metadata is available.\n\tboolean contains(java.lang.String name);\n\t// Returns a metadata value.\n\tbyte[] get(java.lang.String name, byte[] defaultValue);\n\t// Returns a metadata value.\n\tlong get(java.lang.String name, long defaultValue);\n\t// Returns a metadata value.\n\tjava.lang.String get(java.lang.String name, java.lang.String defaultValue);\n}", "des": "Interface for an immutable snapshot of keyed metadata."}
{"index": 4145, "repo": "exoplayer-core-2.9.6", "code": "Class DataChunk {\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Called by load().\n\tprotected abstract void consume(byte[] data, int limit);\n\t// Returns the array in which the data is held.\n\tbyte[] getDataHolder();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A base class for Chunk implementations where the data should be loaded into a byte[] before being consumed."}
{"index": 4146, "repo": "exoplayer-core-2.9.6", "code": "Class DataSchemeDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to readLength bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading data URLs, as defined by RFC 2397."}
{"index": 4147, "repo": "exoplayer-core-2.9.6", "code": "Interface DataSink {\n\t// Closes the sink.\n\tvoid close();\n\t// Opens the sink to consume the specified data.\n\tvoid open(DataSpec dataSpec);\n\t// Consumes the provided data.\n\tvoid write(byte[] buffer, int offset, int length);\n}", "des": "A component to which streams of data can be written."}
{"index": 4148, "repo": "exoplayer-core-2.9.6", "code": "Class DataSourceInputStream {\n\t// Returns the total number of bytes that have been read or skipped.\n\tlong bytesRead();\n\tvoid close();\n\t// Optional call to open the underlying DataSource.\n\tvoid open();\n\tint read();\n\tint read(byte[] buffer);\n\tint read(byte[] buffer, int offset, int length);\n}", "des": "Allows data corresponding to a given DataSpec to be read from a DataSource and consumed through an InputStream."}
{"index": 4149, "repo": "exoplayer-core-2.9.6", "code": "Interface Decoder<I,O,E extends java.lang.Exception> {\n\t// Dequeues the next input buffer to be filled and queued to the decoder.\n\tI dequeueInputBuffer();\n\t// Dequeues the next output buffer from the decoder.\n\tO dequeueOutputBuffer();\n\t// Flushes the decoder.\n\tvoid flush();\n\t// Returns the name of the decoder.\n\tjava.lang.String getName();\n\t// Queues an input buffer to the decoder.\n\tvoid queueInputBuffer(I inputBuffer);\n\t// Releases the decoder.\n\tvoid release();\n}", "des": "A media decoder."}
{"index": 4150, "repo": "exoplayer-core-2.9.6", "code": "Class DecoderCounters {\n\t// Should be called to ensure counter values are made visible across threads.\n\tvoid ensureUpdated();\n\t// Merges the counts from other into this instance.\n\tvoid merge(DecoderCounters other);\n}", "des": "Maintains decoder event counts, for debugging purposes only."}
{"index": 4151, "repo": "exoplayer-core-2.9.6", "code": "Class DefaultTsPayloadReaderFactory {\n\t// Returns the initial mapping from PIDs to payload readers.\n\tandroid.util.SparseArray<TsPayloadReader> createInitialPayloadReaders();\n\t// Returns a TsPayloadReader for a given stream type and elementary stream information.\n\tTsPayloadReader createPayloadReader(int streamType, TsPayloadReader.EsInfo esInfo);\n}", "des": "Default TsPayloadReader.Factory implementation."}
{"index": 4152, "repo": "exoplayer-core-2.9.6", "code": "Interface Downloader {\n\t// Interrupts any current download operation and prevents future operations from running.\n\tvoid cancel();\n\t// Downloads the media.\n\tvoid download();\n\t// Returns the total number of downloaded bytes.\n\tlong getDownloadedBytes();\n\t// Returns the estimated download percentage, or C.PERCENTAGE_UNSET if no estimate is available.\n\tfloat getDownloadPercentage();\n\t// Removes the media.\n\tvoid remove();\n}", "des": "An interface for stream downloaders."}
{"index": 4153, "repo": "exoplayer-core-2.9.6", "code": "Class DownloaderConstructorHelper {\n\t// Returns a new CacheDataSource instance.\n\tCacheDataSource buildCacheDataSource(boolean offline);\n\t// Returns the Cache instance.\n\tCache getCache();\n\t// Returns a PriorityTaskManager instance.\n\tPriorityTaskManager getPriorityTaskManager();\n}", "des": "A helper class that holds necessary parameters for Downloader construction."}
{"index": 4154, "repo": "exoplayer-core-2.9.6", "code": "Interface DownloadHelper.Callback {\n\t// Called when preparation completes.\n\tvoid onPrepared(DownloadHelper helper);\n\t// Called when preparation fails.\n\tvoid onPrepareError(DownloadHelper helper, java.io.IOException e);\n}", "des": "A callback to be notified when the DownloadHelper is prepared."}
{"index": 4155, "repo": "exoplayer-core-2.9.6", "code": "Interface DownloadManager.Listener {\n\t// Called when there is no active task left.\n\tvoid onIdle(DownloadManager downloadManager);\n\t// Called when all actions have been restored.\n\tvoid onInitialized(DownloadManager downloadManager);\n\t// Called when the state of a task changes.\n\tvoid onTaskStateChanged(DownloadManager downloadManager, DownloadManager.TaskState taskState);\n}", "des": "Listener for DownloadManager events."}
{"index": 4156, "repo": "exoplayer-core-2.9.6", "code": "Interface DrmSessionManager<T extends ExoMediaCrypto> {\n\t// Acquires a DrmSession for the specified DrmInitData.\n\tDrmSession<T> acquireSession(android.os.Looper playbackLooper, DrmInitData drmInitData);\n\t// Returns whether the manager is capable of acquiring a session for the given DrmInitData.\n\tboolean canAcquireSession(DrmInitData drmInitData);\n\t// Releases a DrmSession.\n\tvoid releaseSession(DrmSession<T> drmSession);\n}", "des": "Manages a DRM session."}
{"index": 4157, "repo": "exoplayer-core-2.9.6", "code": "Class DtsReader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous DTS byte stream and extracts individual samples."}
{"index": 4158, "repo": "exoplayer-core-2.9.6", "code": "Class DummyExtractorOutput {\n\t// Called when all tracks have been identified, meaning no new trackId values will be passed to ExtractorOutput.track(int, int).\n\tvoid endTracks();\n\t// Called when a SeekMap has been extracted from the stream.\n\tvoid seekMap(SeekMap seekMap);\n\t// Called by the Extractor to get the TrackOutput for a specific track.\n\tTrackOutput track(int id, int type);\n}", "des": "A dummy ExtractorOutput implementation."}
{"index": 4159, "repo": "exoplayer-core-2.9.6", "code": "Class DummySurface {\n\t// Returns whether the device supports secure dummy surfaces.\n\tstatic boolean isSecureSupported(android.content.Context context);\n\t// Returns a newly created dummy surface.\n\tstatic DummySurface newInstanceV17(android.content.Context context, boolean secure);\n\tvoid release();\n}", "des": "A dummy Surface."}
{"index": 4160, "repo": "exoplayer-core-2.9.6", "code": "Class DvbSubtitleReader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses DVB subtitle data and extracts individual frames."}
{"index": 4161, "repo": "exoplayer-core-2.9.6", "code": "Class EGLSurfaceTexture {\n\t// Returns the wrapped SurfaceTexture.\n\tandroid.graphics.SurfaceTexture getSurfaceTexture();\n\t// Initializes required EGL parameters and creates the SurfaceTexture.\n\tvoid init(int secureMode);\n\tvoid onFrameAvailable(android.graphics.SurfaceTexture surfaceTexture);\n\t// Releases all allocated resources.\n\tvoid release();\n\tvoid run();\n}", "des": "Generates a SurfaceTexture using EGL/GLES functions."}
{"index": 4162, "repo": "exoplayer-core-2.9.6", "code": "Interface ElementaryStreamReader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Extracts individual samples from an elementary media stream, preserving original order."}
{"index": 4163, "repo": "exoplayer-core-2.9.6", "code": "Class EmptySampleStream {\n\t// Returns whether data is available to be read.\n\tboolean isReady();\n\t// Throws an error that's preventing data from being read.\n\tvoid maybeThrowError();\n\t// Attempts to read from the stream.\n\tint readData(FormatHolder formatHolder, DecoderInputBuffer buffer, boolean formatRequired);\n\t// Attempts to skip to the keyframe before the specified position, or to the end of the stream if positionUs is beyond it.\n\tint skipData(long positionUs);\n}", "des": "An empty SampleStream."}
{"index": 4164, "repo": "exoplayer-core-2.9.6", "code": "Class EventDispatcher<T> {\n\t// Adds a listener to the event dispatcher.\n\tvoid addListener(android.os.Handler handler, T eventListener);\n\t// Dispatches an event to all registered listeners.\n\tvoid dispatch(EventDispatcher.Event<T> event);\n\t// Removes a listener from the event dispatcher.\n\tvoid removeListener(T eventListener);\n}", "des": "Event dispatcher which allows listener registration."}
{"index": 4165, "repo": "exoplayer-core-2.9.6", "code": "Class ExoPlayerLibraryInfo {\n\t// Returns a string consisting of registered module names separated by \", \".\n\tstatic java.lang.String registeredModules();\n\t// Registers a module to be returned in the registeredModules() string.\n\tstatic void registerModule(java.lang.String name);\n}", "des": "Information about the ExoPlayer library."}
{"index": 4166, "repo": "exoplayer-core-2.9.6", "code": "Interface ExtractorOutput {\n\t// Called when all tracks have been identified, meaning no new trackId values will be passed to track(int, int).\n\tvoid endTracks();\n\t// Called when a SeekMap has been extracted from the stream.\n\tvoid seekMap(SeekMap seekMap);\n\t// Called by the Extractor to get the TrackOutput for a specific track.\n\tTrackOutput track(int id, int type);\n}", "des": "Receives stream level data extracted by an Extractor."}
{"index": 4167, "repo": "exoplayer-core-2.9.6", "code": "Class FileDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to readLength bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A DataSource for reading local files."}
{"index": 4168, "repo": "exoplayer-core-2.9.6", "code": "Class FlacStreamInfo {\n\t// Returns the bit-rate of the FLAC stream.\n\tint bitRate();\n\t// Returns the duration of the FLAC stream in microseconds.\n\tlong durationUs();\n\t// Returns the approximate number of bytes per frame for the current FLAC stream.\n\tlong getApproxBytesPerFrame();\n\t// Returns the sample index for the sample at given position.\n\tlong getSampleIndex(long timeUs);\n\t// Returns the maximum size for a decoded frame from the FLAC stream.\n\tint maxDecodedFrameSize();\n}", "des": "Holder for FLAC stream info."}
{"index": 4169, "repo": "exoplayer-core-2.9.6", "code": "Class FrameRotationQueue {\n\t// Copies the rotation matrix with the greatest timestamp which is less than or equal to the given timestamp to matrix.\n\tboolean pollRotationMatrix(float[] matrix, long timestampUs);\n\t// Removes all of the rotations and forces rotations to be recentered.\n\tvoid reset();\n\t// Sets a rotation for a given timestamp.\n\tvoid setRotation(long timestampUs, float[] angleAxis);\n}", "des": "This class serves multiple purposes: Queues the rotation metadata extracted from camera motion track. Converts the metadata to rotation matrices in OpenGl coordinate system. Recenters the rotations to componsate the yaw of the initial rotation."}
{"index": 4170, "repo": "exoplayer-core-2.9.6", "code": "Class GaplessInfoHolder {\n\t// Returns whether encoderDelay and encoderPadding have been set.\n\tboolean hasGaplessInfo();\n\t// Populates the holder with data parsed from ID3 Metadata.\n\tboolean setFromMetadata(Metadata metadata);\n\t// Populates the holder with data from an MP3 Xing header, if valid and non-zero.\n\tboolean setFromXingHeaderValue(int value);\n}", "des": "Holder for gapless playback information."}
{"index": 4171, "repo": "exoplayer-core-2.9.6", "code": "Class H262Reader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous H262 byte stream and extracts individual frames."}
{"index": 4172, "repo": "exoplayer-core-2.9.6", "code": "Class H264Reader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous H264 byte stream and extracts individual frames."}
{"index": 4173, "repo": "exoplayer-core-2.9.6", "code": "Class H265Reader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous H.265 byte stream and extracts individual frames."}
{"index": 4174, "repo": "exoplayer-core-2.9.6", "code": "Class HttpDataSource.BaseFactory {\n\t// Creates a DataSource instance.\n\tHttpDataSource createDataSource();\n\t// Called by createDataSource() to create a HttpDataSource instance.\n\tprotected abstract HttpDataSource createDataSourceInternal(HttpDataSource.RequestProperties defaultRequestProperties);\n\t// Gets the default request properties used by all HttpDataSources created by the factory.\n\tHttpDataSource.RequestProperties getDefaultRequestProperties();\n}", "des": "Base implementation of HttpDataSource.Factory that sets default request properties."}
{"index": 4175, "repo": "exoplayer-core-2.9.6", "code": "Interface HttpDataSource.Factory {\n\t// Creates a DataSource instance.\n\tHttpDataSource createDataSource();\n\t// Gets the default request properties used by all HttpDataSources created by the factory.\n\tHttpDataSource.RequestProperties getDefaultRequestProperties();\n}", "des": "A factory for HttpDataSource instances."}
{"index": 4176, "repo": "exoplayer-core-2.9.6", "code": "Class Id3Decoder {\n\t// Decodes ID3 tags.\n\tMetadata decode(byte[] data, int size);\n\t// Decodes a Metadata element from the provided input buffer.\n\tMetadata decode(MetadataInputBuffer inputBuffer);\n}", "des": "Decodes ID3 tags."}
{"index": 4177, "repo": "exoplayer-core-2.9.6", "code": "Class Id3Reader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses ID3 data and extracts individual text information frames."}
{"index": 4178, "repo": "exoplayer-core-2.9.6", "code": "Class InitializationChunk {\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A Chunk that uses an Extractor to decode initialization data for single track."}
{"index": 4179, "repo": "exoplayer-core-2.9.6", "code": "Class LatmReader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses and extracts samples from an AAC/LATM elementary stream."}
{"index": 4180, "repo": "exoplayer-core-2.9.6", "code": "Class LibraryLoader {\n\t// Returns whether the underlying libraries are available, loading them if necessary.\n\tboolean isAvailable();\n\t// Overrides the names of the libraries to load.\n\tvoid setLibraries(java.lang.String... libraries);\n}", "des": "Configurable loader for native libraries."}
{"index": 4181, "repo": "exoplayer-core-2.9.6", "code": "Interface Loader.Callback<T extends Loader.Loadable> {\n\t// Called when a load has been canceled.\n\tvoid onLoadCanceled(T loadable, long elapsedRealtimeMs, long loadDurationMs, boolean released);\n\t// Called when a load has completed.\n\tvoid onLoadCompleted(T loadable, long elapsedRealtimeMs, long loadDurationMs);\n\t// Called when a load encounters an error.\n\tLoader.LoadErrorAction onLoadError(T loadable, long elapsedRealtimeMs, long loadDurationMs, java.io.IOException error, int errorCount);\n}", "des": "A callback to be notified of Loader events."}
{"index": 4182, "repo": "exoplayer-core-2.9.6", "code": "Interface Loader.Loadable {\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "An object that can be loaded using a Loader."}
{"index": 4183, "repo": "exoplayer-core-2.9.6", "code": "Interface LoaderErrorThrower {\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the Loaders default minimum number of retries.\n\tvoid maybeThrowError();\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the specified minimum number of retries.\n\tvoid maybeThrowError(int minRetryCount);\n}", "des": "Conditionally throws errors affecting a Loader."}
{"index": 4184, "repo": "exoplayer-core-2.9.6", "code": "Class LoaderErrorThrower.Dummy {\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the Loaders default minimum number of retries.\n\tvoid maybeThrowError();\n\t// Throws a fatal error, or a non-fatal error if loading is currently backed off and the current Loader.Loadable has incurred a number of errors greater than the specified minimum number of retries.\n\tvoid maybeThrowError(int minRetryCount);\n}", "des": "A LoaderErrorThrower that never throws."}
{"index": 4185, "repo": "exoplayer-core-2.9.6", "code": "Class LocalMediaDrmCallback {\n\t// Executes a key request.\n\tbyte[] executeKeyRequest(java.util.UUID uuid, ExoMediaDrm.KeyRequest request);\n\t// Executes a provisioning request.\n\tbyte[] executeProvisionRequest(java.util.UUID uuid, ExoMediaDrm.ProvisionRequest request);\n}", "des": "A MediaDrmCallback that provides a fixed response to key requests. Provisioning is not supported. This implementation is primarily useful for providing locally stored keys to decrypt ClearKey protected content. It is not suitable for use with Widevine or PlayReady protected content."}
{"index": 4186, "repo": "exoplayer-core-2.9.6", "code": "Class LongArray {\n\t// Appends a value.\n\tvoid add(long value);\n\t// Returns the value at a specified index.\n\tlong get(int index);\n\t// Returns the current size of the array.\n\tint size();\n\t// Copies the current values into a newly allocated primitive array.\n\tlong[] toArray();\n}", "des": "An append-only, auto-growing long[]."}
{"index": 4187, "repo": "exoplayer-core-2.9.6", "code": "Class MediaChunk {\n\t// Returns the next chunk index or C.INDEX_UNSET if it is not known.\n\tlong getNextChunkIndex();\n\t// Returns whether the chunk has been fully loaded.\n\tabstract boolean isLoadCompleted();\n}", "des": "An abstract base class for Chunks that contain media samples."}
{"index": 4188, "repo": "exoplayer-core-2.9.6", "code": "Interface MediaChunkIterator {\n\t// Returns the media end time of the chunk, in microseconds.\n\tlong getChunkEndTimeUs();\n\t// Returns the media start time of the chunk, in microseconds.\n\tlong getChunkStartTimeUs();\n\t// Returns the DataSpec used to load the media chunk.\n\tDataSpec getDataSpec();\n\t// Returns whether the iteration has reached the end of the available data.\n\tboolean isEnded();\n\t// Moves the iterator to the next media chunk.\n\tboolean next();\n}", "des": "Iterator for media chunk sequences."}
{"index": 4189, "repo": "exoplayer-core-2.9.6", "code": "Interface MediaClock {\n\t// Returns the active playback parameters.\n\tPlaybackParameters getPlaybackParameters();\n\t// Returns the current media position in microseconds.\n\tlong getPositionUs();\n\t// Attempts to set the playback parameters and returns the active playback parameters, which may differ from those passed in.\n\tPlaybackParameters setPlaybackParameters(PlaybackParameters playbackParameters);\n}", "des": "Tracks the progression of media time."}
{"index": 4190, "repo": "exoplayer-core-2.9.6", "code": "Interface MediaCodecSelector {\n\t// Returns a list of decoders that can decode media in the specified MIME type, in priority order.\n\tjava.util.List<MediaCodecInfo> getDecoderInfos(java.lang.String mimeType, boolean requiresSecureDecoder);\n\t// Selects a decoder to instantiate for audio passthrough.\n\tMediaCodecInfo getPassthroughDecoderInfo();\n}", "des": "Selector of MediaCodec instances."}
{"index": 4191, "repo": "exoplayer-core-2.9.6", "code": "Interface MediaDrmCallback {\n\t// Executes a key request.\n\tbyte[] executeKeyRequest(java.util.UUID uuid, ExoMediaDrm.KeyRequest request);\n\t// Executes a provisioning request.\n\tbyte[] executeProvisionRequest(java.util.UUID uuid, ExoMediaDrm.ProvisionRequest request);\n}", "des": "Performs ExoMediaDrm key and provisioning requests."}
{"index": 4192, "repo": "exoplayer-core-2.9.6", "code": "Class MediaSource.MediaPeriodId {\n\t// Returns a copy of this period identifier but with newPeriodUid as its period uid.\n\tMediaSource.MediaPeriodId copyWithPeriodUid(java.lang.Object newPeriodUid);\n\tboolean equals(java.lang.Object obj);\n\t// Returns whether this period identifier identifies an ad in an ad group in a period.\n\tboolean isAd();\n}", "des": "Identifier for a MediaPeriod."}
{"index": 4193, "repo": "exoplayer-core-2.9.6", "code": "Class Metadata {\n\tint describeContents();\n\tboolean equals(java.lang.Object obj);\n\t// Returns the entry at the specified index.\n\tMetadata.Entry get(int index);\n\t// Returns the number of metadata entries.\n\tint length();\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "A collection of metadata entries."}
{"index": 4194, "repo": "exoplayer-core-2.9.6", "code": "Interface MetadataDecoderFactory {\n\t// Creates a MetadataDecoder for the given Format.\n\tMetadataDecoder createDecoder(Format format);\n\t// Returns whether the factory is able to instantiate a MetadataDecoder for the given Format.\n\tboolean supportsFormat(Format format);\n}", "des": "A factory for MetadataDecoder instances."}
{"index": 4195, "repo": "exoplayer-core-2.9.6", "code": "Class MpegAudioHeader {\n\t// Returns the size of the frame associated with header, or C.LENGTH_UNSET if it is invalid.\n\tstatic int getFrameSize(int header);\n\t// Parses headerData, populating header with the parsed data.\n\tstatic boolean populateHeader(int headerData, MpegAudioHeader header);\n}", "des": "An MPEG audio frame header."}
{"index": 4196, "repo": "exoplayer-core-2.9.6", "code": "Class MpegAudioReader {\n\t// Consumes (possibly partial) data from the current packet.\n\tvoid consume(ParsableByteArray data);\n\t// Initializes the reader by providing outputs and ids for the tracks.\n\tvoid createTracks(ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Called when a packet ends.\n\tvoid packetFinished();\n\t// Called when a packet starts.\n\tvoid packetStarted(long pesTimeUs, int flags);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses a continuous MPEG Audio byte stream and extracts individual frames."}
{"index": 4197, "repo": "exoplayer-core-2.9.6", "code": "Class NotificationUtil {\n\t// Creates a notification channel that notifications can be posted to.\n\tstatic void createNotificationChannel(android.content.Context context, java.lang.String id, int name, int importance);\n\t// Post a notification to be shown in the status bar.\n\tstatic void setNotification(android.content.Context context, int id, android.app.Notification notification);\n}", "des": "Utility methods for displaying Notifications."}
{"index": 4198, "repo": "exoplayer-core-2.9.6", "code": "Class PesReader {\n\t// Consumes the payload of a TS packet.\n\tvoid consume(ParsableByteArray data, int flags);\n\t// Initializes the payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses PES packet data and extracts samples."}
{"index": 4199, "repo": "exoplayer-core-2.9.6", "code": "Class PlatformScheduler {\n\t// Cancels anything that was previously scheduled, or else does nothing.\n\tboolean cancel();\n\t// Schedules a service to be started in the foreground when some Requirements are met.\n\tboolean schedule(Requirements requirements, java.lang.String servicePackage, java.lang.String serviceAction);\n}", "des": "A Scheduler that uses JobScheduler. To use this scheduler, you must add PlatformScheduler.PlatformSchedulerService to your manifest:"}
{"index": 4200, "repo": "exoplayer-core-2.9.6", "code": "Interface Player.MetadataComponent {\n\t// Adds a MetadataOutput to receive metadata.\n\tvoid addMetadataOutput(MetadataOutput output);\n\t// Removes a MetadataOutput.\n\tvoid removeMetadataOutput(MetadataOutput output);\n}", "des": "The metadata component of a Player."}
{"index": 4201, "repo": "exoplayer-core-2.9.6", "code": "Interface Player.TextComponent {\n\t// Registers an output to receive text events.\n\tvoid addTextOutput(TextOutput listener);\n\t// Removes a text output.\n\tvoid removeTextOutput(TextOutput listener);\n}", "des": "The text component of a Player."}
{"index": 4202, "repo": "exoplayer-core-2.9.6", "code": "Class PriorityTaskManager {\n\t// Register a new task.\n\tvoid add(int priority);\n\t// Blocks until the task is allowed to proceed.\n\tvoid proceed(int priority);\n\t// A non-blocking variant of proceed(int).\n\tboolean proceedNonBlocking(int priority);\n\t// A throwing variant of proceed(int).\n\tvoid proceedOrThrow(int priority);\n\t// Unregister a task.\n\tvoid remove(int priority);\n}", "des": "Allows tasks with associated priorities to control how they proceed relative to one another."}
{"index": 4203, "repo": "exoplayer-core-2.9.6", "code": "Class ProgressiveDownloader {\n\t// Interrupts any current download operation and prevents future operations from running.\n\tvoid cancel();\n\t// Downloads the media.\n\tvoid download();\n\t// Returns the total number of downloaded bytes.\n\tlong getDownloadedBytes();\n\t// Returns the estimated download percentage, or C.PERCENTAGE_UNSET if no estimate is available.\n\tfloat getDownloadPercentage();\n\t// Removes the media.\n\tvoid remove();\n}", "des": "A downloader for progressive media streams."}
{"index": 4204, "repo": "exoplayer-core-2.9.6", "code": "Class Projection {\n\t// Generates an equirectangular projection.\n\tstatic Projection createEquirectangular(float radius, int latitudes, int longitudes, float verticalFovDegrees, float horizontalFovDegrees, int stereoMode);\n\t// Generates a complete sphere equirectangular projection.\n\tstatic Projection createEquirectangular(int stereoMode);\n}", "des": "The projection mesh used with 360/VR videos."}
{"index": 4205, "repo": "exoplayer-core-2.9.6", "code": "Class Projection.Mesh {\n\t// Returns the SubMesh for the given index.\n\tProjection.SubMesh getSubMesh(int index);\n\t// Returns the number of sub meshes.\n\tint getSubMeshCount();\n}", "des": "A Mesh associated with the projection scene."}
{"index": 4206, "repo": "exoplayer-core-2.9.6", "code": "Interface RendererCapabilities {\n\t// Returns the track type that the Renderer handles.\n\tint getTrackType();\n\t// Returns the extent to which the Renderer supports a given format.\n\tint supportsFormat(Format format);\n\t// Returns the extent to which the Renderer supports adapting between supported formats that have different mime types.\n\tint supportsMixedMimeTypeAdaptation();\n}", "des": "Defines the capabilities of a Renderer."}
{"index": 4207, "repo": "exoplayer-core-2.9.6", "code": "Class RepeatModeUtil {\n\t// Gets the next repeat mode out of enabledModes starting from currentMode.\n\tstatic int getNextRepeatMode(int currentMode, int enabledModes);\n\t// Verifies whether a given repeatMode is enabled in the bitmask enabledModes.\n\tstatic boolean isRepeatModeEnabled(int repeatMode, int enabledModes);\n}", "des": "Util class for repeat mode handling."}
{"index": 4208, "repo": "exoplayer-core-2.9.6", "code": "Class Requirements {\n\t// Returns whether the requirements are met.\n\tboolean checkRequirements(android.content.Context context);\n\t// Returns required network type.\n\tint getRequiredNetworkType();\n\t// Returns the encoded requirements data which can be used with Requirements(int).\n\tint getRequirementsData();\n\t// Returns whether the device should be charging.\n\tboolean isChargingRequired();\n\t// Returns whether the device should be idle.\n\tboolean isIdleRequired();\n}", "des": "Defines a set of device state requirements."}
{"index": 4209, "repo": "exoplayer-core-2.9.6", "code": "Class RequirementsWatcher {\n\t// Returns watched Requirements.\n\tRequirements getRequirements();\n\t// Starts watching for changes.\n\tvoid start();\n\t// Stops watching for changes.\n\tvoid stop();\n}", "des": "Watches whether the Requirements are met and notifies the RequirementsWatcher.Listener on changes."}
{"index": 4210, "repo": "exoplayer-core-2.9.6", "code": "Interface RequirementsWatcher.Listener {\n\t// Called when the requirements are met.\n\tvoid requirementsMet(RequirementsWatcher requirementsWatcher);\n\t// Called when the requirements are not met.\n\tvoid requirementsNotMet(RequirementsWatcher requirementsWatcher);\n}", "des": "Notified when RequirementsWatcher instance first created and on changes whether the Requirements are met."}
{"index": 4211, "repo": "exoplayer-core-2.9.6", "code": "Interface SampleStream {\n\t// Returns whether data is available to be read.\n\tboolean isReady();\n\t// Throws an error that's preventing data from being read.\n\tvoid maybeThrowError();\n\t// Attempts to read from the stream.\n\tint readData(FormatHolder formatHolder, DecoderInputBuffer buffer, boolean formatRequired);\n\t// Attempts to skip to the keyframe before the specified position, or to the end of the stream if positionUs is beyond it.\n\tint skipData(long positionUs);\n}", "des": "A stream of media samples (and associated format information)."}
{"index": 4212, "repo": "exoplayer-core-2.9.6", "code": "Interface Scheduler {\n\t// Cancels anything that was previously scheduled, or else does nothing.\n\tboolean cancel();\n\t// Schedules a service to be started in the foreground when some Requirements are met.\n\tboolean schedule(Requirements requirements, java.lang.String servicePackage, java.lang.String serviceAction);\n}", "des": "Schedules a service to be started in the foreground when some Requirements are met."}
{"index": 4213, "repo": "exoplayer-core-2.9.6", "code": "Interface SectionPayloadReader {\n\t// Called by a SectionReader when a full section is received.\n\tvoid consume(ParsableByteArray sectionData);\n\t// Initializes the section payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n}", "des": "Reads section data."}
{"index": 4214, "repo": "exoplayer-core-2.9.6", "code": "Class SectionReader {\n\t// Consumes the payload of a TS packet.\n\tvoid consume(ParsableByteArray data, int flags);\n\t// Initializes the payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Reads section data packets and feeds the whole sections to a given SectionPayloadReader. Useful information on PSI sections can be found in ISO/IEC 13818-1, section 2.4.4."}
{"index": 4215, "repo": "exoplayer-core-2.9.6", "code": "Interface SeekMap {\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Obtains seek points for the specified seek time in microseconds.\n\tSeekMap.SeekPoints getSeekPoints(long timeUs);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n}", "des": "Maps seek positions (in microseconds) to corresponding positions (byte offsets) in the stream."}
{"index": 4216, "repo": "exoplayer-core-2.9.6", "code": "Class SeekMap.Unseekable {\n\t// Returns the duration of the stream in microseconds.\n\tlong getDurationUs();\n\t// Obtains seek points for the specified seek time in microseconds.\n\tSeekMap.SeekPoints getSeekPoints(long timeUs);\n\t// Returns whether seeking is supported.\n\tboolean isSeekable();\n}", "des": "A SeekMap that does not support seeking."}
{"index": 4217, "repo": "exoplayer-core-2.9.6", "code": "Class SegmentDownloadAction {\n\tboolean equals(java.lang.Object o);\n\t// Returns keys of tracks to be downloaded.\n\tjava.util.List<StreamKey> getKeys();\n\t// Serializes itself into the output.\n\tvoid writeToStream(java.io.DataOutputStream output);\n}", "des": "DownloadAction for SegmentDownloaders."}
{"index": 4218, "repo": "exoplayer-core-2.9.6", "code": "Class SegmentDownloadAction.SegmentDownloadActionDeserializer {\n\t// Returns a DownloadAction.\n\tprotected abstract DownloadAction createDownloadAction(android.net.Uri manifestUri, boolean isRemoveAction, byte[] data, java.util.List<StreamKey> keys);\n\t// Deserializes an action from the input.\n\tDownloadAction readFromStream(int version, java.io.DataInputStream input);\n\t// Deserializes a key from the input.\n\tprotected StreamKey readKey(int version, java.io.DataInputStream input);\n}", "des": "Base class for SegmentDownloadAction Deserializers."}
{"index": 4219, "repo": "exoplayer-core-2.9.6", "code": "Interface SequenceableLoader {\n\t// Attempts to continue loading.\n\tboolean continueLoading(long positionUs);\n\t// Returns an estimate of the position up to which data is buffered.\n\tlong getBufferedPositionUs();\n\t// Returns the next load time, or C.TIME_END_OF_SOURCE if loading has finished.\n\tlong getNextLoadPositionUs();\n\t// Re-evaluates the buffer given the playback position.\n\tvoid reevaluateBuffer(long positionUs);\n}", "des": "A loader that can proceed in approximate synchronization with other loaders."}
{"index": 4220, "repo": "exoplayer-core-2.9.6", "code": "Class SimpleOutputBuffer {\n\t// Clears the buffer.\n\tvoid clear();\n\t// Initializes the buffer.\n\tjava.nio.ByteBuffer init(long timeUs, int size);\n\t// Releases the output buffer for reuse.\n\tvoid release();\n}", "des": "Buffer for SimpleDecoder output."}
{"index": 4221, "repo": "exoplayer-core-2.9.6", "code": "Class SinglePeriodAdTimeline {\n\t// Populates a Timeline.Period with data for the period at the specified index.\n\tTimeline.Period getPeriod(int periodIndex, Timeline.Period period, boolean setIds);\n\t// Populates a Timeline.Window with data for the window at the specified index.\n\tTimeline.Window getWindow(int windowIndex, Timeline.Window window, boolean setTag, long defaultPositionProjectionUs);\n}", "des": "A Timeline for sources that have ads."}
{"index": 4222, "repo": "exoplayer-core-2.9.6", "code": "Class SingleSampleMediaChunk {\n\t// Cancels the load.\n\tvoid cancelLoad();\n\t// Returns whether the chunk has been fully loaded.\n\tboolean isLoadCompleted();\n\t// Performs the load, returning on completion or cancellation.\n\tvoid load();\n}", "des": "A BaseMediaChunk for chunks consisting of a single raw sample."}
{"index": 4223, "repo": "exoplayer-core-2.9.6", "code": "Class SlidingPercentile {\n\t// Adds a new weighted value.\n\tvoid addSample(int weight, float value);\n\t// Computes a percentile by integration.\n\tfloat getPercentile(float percentile);\n}", "des": "Calculate any percentile over a sliding window of weighted values. A maximum weight is configured. Once the total weight of the values reaches the maximum weight, the oldest value is reduced in weight until it reaches zero and is removed. This maintains a constant total weight, equal to the maximum allowed, at the steady state."}
{"index": 4224, "repo": "exoplayer-core-2.9.6", "code": "Class SpliceInfoSectionReader {\n\t// Called by a SectionReader when a full section is received.\n\tvoid consume(ParsableByteArray sectionData);\n\t// Initializes the section payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n}", "des": "Parses splice info sections as defined by SCTE35."}
{"index": 4225, "repo": "exoplayer-core-2.9.6", "code": "Class SsaDecoder {\n\t// Decodes data into a Subtitle.\n\tprotected com.google.android.exoplayer2.text.ssa.SsaSubtitle decode(byte[] bytes, int length, boolean reset);\n\t// Parses an SSA timecode string.\n\tstatic long parseTimecodeUs(java.lang.String timeString);\n}", "des": "A SimpleSubtitleDecoder for SSA/ASS."}
{"index": 4226, "repo": "exoplayer-core-2.9.6", "code": "Interface Subtitle {\n\t// Retrieve the cues that should be displayed at a given time.\n\tjava.util.List<Cue> getCues(long timeUs);\n\t// Returns the event time at a specified index.\n\tlong getEventTime(int index);\n\t// Returns the number of event times, where events are defined as points in time at which the cues returned by getCues(long) changes.\n\tint getEventTimeCount();\n\t// Returns the index of the first event that occurs after a given time (exclusive).\n\tint getNextEventTimeIndex(long timeUs);\n}", "des": "A subtitle consisting of timed Cues."}
{"index": 4227, "repo": "exoplayer-core-2.9.6", "code": "Interface SubtitleDecoderFactory {\n\t// Creates a SubtitleDecoder for the given Format.\n\tSubtitleDecoder createDecoder(Format format);\n\t// Returns whether the factory is able to instantiate a SubtitleDecoder for the given Format.\n\tboolean supportsFormat(Format format);\n}", "des": "A factory for SubtitleDecoder instances."}
{"index": 4228, "repo": "exoplayer-core-2.9.6", "code": "Interface TeeAudioProcessor.AudioBufferSink {\n\t// Called when the audio processor is flushed with a format of subsequent input.\n\tvoid flush(int sampleRateHz, int channelCount, int encoding);\n\t// Called when data is written to the audio processor.\n\tvoid handleBuffer(java.nio.ByteBuffer buffer);\n}", "des": "A sink for audio buffers handled by the audio processor."}
{"index": 4229, "repo": "exoplayer-core-2.9.6", "code": "Class TeeAudioProcessor.WavFileAudioBufferSink {\n\t// Called when the audio processor is flushed with a format of subsequent input.\n\tvoid flush(int sampleRateHz, int channelCount, int encoding);\n\t// Called when data is written to the audio processor.\n\tvoid handleBuffer(java.nio.ByteBuffer buffer);\n}", "des": "A sink for audio buffers that writes output audio as .wav files with a given path prefix. When new audio data is handled after flushing the audio processor, a counter is incremented and its value is appended to the output file name."}
{"index": 4230, "repo": "exoplayer-core-2.9.6", "code": "Class TimedValueQueue<V> {\n\t// Associates the specified value with the specified timestamp.\n\tvoid add(long timestamp, V value);\n\t// Removes all of the values.\n\tvoid clear();\n\t// Returns the value with the closest timestamp to the given timestamp.\n\tV poll(long timestamp);\n\t// Returns the value with the greatest timestamp which is less than or equal to the given timestamp.\n\tV pollFloor(long timestamp);\n\t// Returns number of the values buffered.\n\tint size();\n}", "des": "A utility class to keep a queue of values with timestamps. This class is thread safe."}
{"index": 4231, "repo": "exoplayer-core-2.9.6", "code": "Class TraceUtil {\n\t// Writes a trace message to indicate that a given section of code has begun.\n\tstatic void beginSection(java.lang.String sectionName);\n\t// Writes a trace message to indicate that a given section of code has ended.\n\tstatic void endSection();\n}", "des": "Calls through to Trace methods on supported API levels."}
{"index": 4232, "repo": "exoplayer-core-2.9.6", "code": "Class TrackGroup {\n\tint describeContents();\n\tboolean equals(java.lang.Object obj);\n\t// Returns the format of the track at a given index.\n\tFormat getFormat(int index);\n\t// Returns the index of the track with the given format in the group.\n\tint indexOf(Format format);\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "Defines a group of tracks exposed by a MediaPeriod."}
{"index": 4233, "repo": "exoplayer-core-2.9.6", "code": "Class TrackGroupArray {\n\tint describeContents();\n\tboolean equals(java.lang.Object obj);\n\t// Returns the group at a given index.\n\tTrackGroup get(int index);\n\t// Returns the index of a group within the array.\n\tint indexOf(TrackGroup group);\n\t// Returns whether this track group array is empty.\n\tboolean isEmpty();\n\tvoid writeToParcel(android.os.Parcel dest, int flags);\n}", "des": "An array of TrackGroups exposed by a MediaPeriod."}
{"index": 4234, "repo": "exoplayer-core-2.9.6", "code": "Class TrackSelectionArray {\n\tboolean equals(java.lang.Object obj);\n\t// Returns the selection at a given index.\n\tTrackSelection get(int index);\n\t// Returns the selections in a newly allocated array.\n\t@NullableType TrackSelection[] getAll();\n}", "des": "An array of TrackSelections."}
{"index": 4235, "repo": "exoplayer-core-2.9.6", "code": "Class TrackSelectorResult {\n\t// Returns whether this result is equivalent to other for all renderers.\n\tboolean isEquivalent(TrackSelectorResult other);\n\t// Returns whether this result is equivalent to other for the renderer at the given index.\n\tboolean isEquivalent(TrackSelectorResult other, int index);\n\t// Returns whether the renderer at the specified index is enabled.\n\tboolean isRendererEnabled(int index);\n}", "des": "The result of a TrackSelector operation."}
{"index": 4236, "repo": "exoplayer-core-2.9.6", "code": "Interface TsPayloadReader {\n\t// Consumes the payload of a TS packet.\n\tvoid consume(ParsableByteArray data, int flags);\n\t// Initializes the payload reader.\n\tvoid init(TimestampAdjuster timestampAdjuster, ExtractorOutput extractorOutput, TsPayloadReader.TrackIdGenerator idGenerator);\n\t// Notifies the reader that a seek has occurred.\n\tvoid seek();\n}", "des": "Parses TS packet payload data."}
{"index": 4237, "repo": "exoplayer-core-2.9.6", "code": "Interface TsPayloadReader.Factory {\n\t// Returns the initial mapping from PIDs to payload readers.\n\tandroid.util.SparseArray<TsPayloadReader> createInitialPayloadReaders();\n\t// Returns a TsPayloadReader for a given stream type and elementary stream information.\n\tTsPayloadReader createPayloadReader(int streamType, TsPayloadReader.EsInfo esInfo);\n}", "des": "Factory of TsPayloadReader instances."}
{"index": 4238, "repo": "exoplayer-core-2.9.6", "code": "Class TsPayloadReader.TrackIdGenerator {\n\t// Generates a new set of track and track format ids.\n\tvoid generateNewId();\n\t// Returns the last generated format id, with the format \"programNumber/trackId\".\n\tjava.lang.String getFormatId();\n\t// Returns the last generated track id.\n\tint getTrackId();\n}", "des": "Generates track ids for initializing TsPayloadReaders' TrackOutputs."}
{"index": 4239, "repo": "exoplayer-core-2.9.6", "code": "Class TsUtil {\n\t// Returns the position of the first TS_SYNC_BYTE within the range [startPosition, limitPosition) from the provided data array, or returns limitPosition if sync byte could not be found.\n\tstatic int findSyncBytePosition(byte[] data, int startPosition, int limitPosition);\n\t// Returns the PCR value read from a given TS packet.\n\tstatic long readPcrFromPacket(ParsableByteArray packetBuffer, int startOfPacket, int pcrPid);\n}", "des": "Utilities method for extracting MPEG-TS streams."}
{"index": 4240, "repo": "exoplayer-core-2.9.6", "code": "Class UdpDataSource {\n\t// Closes the source.\n\tvoid close();\n\t// When the source is open, returns the Uri from which data is being read.\n\tandroid.net.Uri getUri();\n\t// Opens the source to read the specified data.\n\tlong open(DataSpec dataSpec);\n\t// Reads up to readLength bytes of data and stores them into buffer, starting at index offset.\n\tint read(byte[] buffer, int offset, int readLength);\n}", "des": "A UDP DataSource."}
{"index": 4241, "repo": "exoplayer-core-2.9.6", "code": "Class UriUtil {\n\t// Removes query parameter from an Uri, if present.\n\tstatic android.net.Uri removeQueryParameter(android.net.Uri uri, java.lang.String queryParameterName);\n\t// Performs relative resolution of a referenceUri with respect to a baseUri.\n\tstatic java.lang.String resolve(java.lang.String baseUri, java.lang.String referenceUri);\n\t// Like resolve(String, String), but returns a Uri instead of a String.\n\tstatic android.net.Uri resolveToUri(java.lang.String baseUri, java.lang.String referenceUri);\n}", "des": "Utility methods for manipulating URIs."}
{"index": 4242, "repo": "exoplayer-core-2.9.6", "code": "Class VideoFrameReleaseTimeHelper {\n\t// Adjusts a frame release timestamp.\n\tlong adjustReleaseTime(long framePresentationTimeUs, long unadjustedReleaseTimeNs);\n\t// Disables the helper.\n\tvoid disable();\n\t// Enables the helper.\n\tvoid enable();\n}", "des": "Makes a best effort to adjust frame release timestamps for a smoother visual result."}
{"index": 4243, "repo": "exoplayer-core-2.9.6", "code": "Class WavUtil {\n\t// Returns the PCM encoding for the given WAVE type value.\n\tstatic int getEncodingForType(int type, int bitsPerSample);\n\t// Returns the WAVE type value for the given encoding.\n\tstatic int getTypeForEncoding(int encoding);\n}", "des": "Utilities for handling WAVE files."}
{"index": 4244, "repo": "ignite-indexing-2.15.0", "code": "Enum CollocationModelAffinity {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CollocationModelAffinity valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CollocationModelAffinity[] values();\n}", "des": "Affinity of a table relative to previous joined tables."}
{"index": 4245, "repo": "ignite-indexing-2.15.0", "code": "Enum CollocationModelMultiplier {\n\tint multiplier();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CollocationModelMultiplier valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CollocationModelMultiplier[] values();\n}", "des": "Multiplier for different collocation types."}
{"index": 4246, "repo": "ignite-indexing-2.15.0", "code": "Enum CollocationModelType {\n\tboolean isCollocated();\n\tboolean isPartitioned();\n\tstatic CollocationModelType of(boolean partitioned, boolean collocated);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CollocationModelType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CollocationModelType[] values();\n}", "des": "Collocation type."}
{"index": 4247, "repo": "ignite-indexing-2.15.0", "code": "Class ConnectionManager {\n\tH2PooledConnection connection();\n\tH2PooledConnection connection(String schema);\n\torg.h2.store.DataHandler dataHandler();\n\t// Execute SQL statement on specific schema.\n\tvoid executeStatement(String schema, String sql);\n\t// Execute statement on H2 INFORMATION_SCHEMA.\n\tvoid executeSystemStatement(String sql);\n\t// Clear statement cache when cache is unregistered..\n\tvoid onCacheDestroyed();\n\t// Cancel all queries.\n\tvoid onKernalStop();\n\t// Close executor.\n\tvoid stop();\n}", "des": "H2 connection manager."}
{"index": 4248, "repo": "ignite-indexing-2.15.0", "code": "Class DmlBatchSender {\n\t// Add entry to batch.\n\tvoid add(Object key, javax.cache.processor.EntryProcessor<Object,Object,Boolean> proc, int rowNum);\n\tSQLException error();\n\tList<Object> failedKeys();\n\t// Flush any remaining entries.\n\tvoid flush();\n\t// Returns per row updates counter as array.\n\tint[] perRowCounterAsArray();\n\tClusterNode primaryNodeByKey(Object key);\n\t// Sets row as failed.\n\tvoid setFailed(int rowNum);\n\tlong updateCount();\n}", "des": "Batch sender class."}
{"index": 4249, "repo": "ignite-indexing-2.15.0", "code": "Class DmlDistributedUpdateRun {\n\tGridFutureAdapter<UpdateResult> future();\n\t// Handle disconnection.\n\tvoid handleDisconnect(javax.cache.CacheException e);\n\t// Handle leave of a node.\n\tvoid handleNodeLeft(UUID nodeId);\n\t// Handle response from remote node.\n\tvoid handleResponse(UUID id, GridH2DmlResponse msg);\n}", "des": "Context for DML operation on reducer node."}
{"index": 4250, "repo": "ignite-indexing-2.15.0", "code": "Class FastUpdate {\n\t// Create fast update instance.\n\tstatic FastUpdate create(GridSqlElement key, GridSqlElement val, @Nullable GridSqlElement newVal);\n\t// Perform single cache operation based on given args.\n\tUpdateResult execute(GridCacheAdapter cache, Object[] args);\n\tIgniteBiTuple getRow(Object[] args);\n}", "des": "Arguments for fast, query-less UPDATE or DELETE - key and, optionally, value and new value."}
{"index": 4251, "repo": "ignite-indexing-2.15.0", "code": "Class GridLuceneFile {\n\t// Deletes file and deallocates memory.\n\tvoid delete();\n\tCollection<org.apache.lucene.util.Accountable> getChildResources();\n\tGridLuceneDirectory getDirectory();\n\t// For non-stream access from thread that might be concurrent with writing\n\tlong getLength();\n\tString getName();\n\tlong ramBytesUsed();\n\t// Sets length.\n\tprotected void setLength(long length);\n}", "des": "Lucene file."}
{"index": 4252, "repo": "ignite-indexing-2.15.0", "code": "Class GridLuceneIndex {\n\tvoid close();\n\t// Runs lucene fulltext query over this index.\n\t<K,V> GridCloseableIterator<IgniteBiTuple<K,V>> query(String qry, IndexingQueryFilter filters, int limit);\n\t// Removes entry for given key from this index.\n\tvoid remove(CacheObject key);\n\t// Stores given data in this fulltext index.\n\tvoid store(CacheObject k, CacheObject v, GridCacheVersion ver, long expires);\n}", "des": "Lucene fulltext index."}
{"index": 4253, "repo": "ignite-indexing-2.15.0", "code": "Class GridMapQueryExecutor {\n\tvoid onCancel(ClusterNode node, GridQueryCancelRequest msg);\n\tvoid onDmlRequest(ClusterNode node, GridH2DmlRequest req);\n\tvoid onNextPageRequest(ClusterNode node, GridQueryNextPageRequest req);\n\t// Node left event handling method..\n\tvoid onNodeLeft(DiscoveryEvent evt);\n\tvoid onQueryRequest(ClusterNode node, GridH2QueryRequest req);\n\tvoid start(GridKernalContext ctx, IgniteH2Indexing h2);\n\t// Stop query map executor, cleanup resources.\n\tvoid stop();\n}", "des": "Map query executor."}
{"index": 4254, "repo": "ignite-indexing-2.15.0", "code": "Interface GridSqlAst {\n\t// Get the first child.\n\t<E extends GridSqlAst>E child();\n\t// Get child by index.\n\t<E extends GridSqlAst>E child(int childIdx);\n\t// Set child.\n\t<E extends GridSqlAst>void child(int childIdx, E child);\n\tString getSQL();\n\tGridSqlType resultType();\n\tint size();\n}", "des": "AST for SQL."}
{"index": 4255, "repo": "ignite-indexing-2.15.0", "code": "Class GridSqlElement {\n\tGridSqlElement addChild(GridSqlAst expr);\n\t// Get the first child.\n\t<E extends GridSqlAst>E child();\n\t// Get child by index.\n\t<E extends GridSqlAst>E child(int idx);\n\t// Set child.\n\t<E extends GridSqlAst>void child(int idx, E child);\n\tboolean equals(Object o);\n\tGridSqlType resultType();\n\tGridSqlElement resultType(GridSqlType type);\n\tint size();\n}", "des": "Base class for all SQL AST nodes."}
{"index": 4256, "repo": "ignite-indexing-2.15.0", "code": "Enum GridSqlFunctionType {\n\tString functionName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridSqlFunctionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridSqlFunctionType[] values();\n}", "des": "Full list of available functions see at Function"}
{"index": 4257, "repo": "ignite-indexing-2.15.0", "code": "Enum GridSqlOperationType {\n\tint childrenCount();\n\tString toSql(GridSqlOperation operation);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GridSqlOperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GridSqlOperationType[] values();\n}", "des": "Operation type."}
{"index": 4258, "repo": "ignite-indexing-2.15.0", "code": "Class GridSqlType {\n\t// Get the display size of this expression.\n\tint displaySize();\n\tstatic GridSqlType fromColumn(org.h2.table.Column c);\n\tstatic GridSqlType fromExpression(org.h2.expression.Expression e);\n\t// Get the precision of this expression.\n\tlong precision();\n\t// Get the scale of this expression.\n\tint scale();\n\tString sql();\n\tint type();\n}", "des": "SQL Data type based on H2."}
{"index": 4259, "repo": "ignite-indexing-2.15.0", "code": "Enum H2DatabaseType {\n\t// Gets DB type name.\n\tString dBTypeAsString();\n\t// Resolves enum by class.\n\tstatic H2DatabaseType fromClass(Class<?> cls);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic H2DatabaseType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic H2DatabaseType[] values();\n}", "des": "Enum that helps to map java types to database types."}
{"index": 4260, "repo": "ignite-indexing-2.15.0", "code": "Enum H2IndexType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic H2IndexType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic H2IndexType[] values();\n}", "des": "Type of supported indexed types."}
{"index": 4261, "repo": "ignite-indexing-2.15.0", "code": "Class H2PooledConnection {\n\t// Closes wrapped connection (return to pool or close).\n\tvoid close();\n\tConnection connection();\n\t// Prepare statement caching it if needed.\n\tPreparedStatement prepareStatement(String sql, byte qryFlags);\n\t// Get prepared statement without caching.\n\tPreparedStatement prepareStatementNoCache(String sql);\n\tString schema();\n\tvoid schema(@Nullable String schema);\n\tint statementCacheSize();\n}", "des": "Pooled connection wrapper to use close semantic to recycle connection (return to the pool)."}
{"index": 4262, "repo": "ignite-indexing-2.15.0", "code": "Enum H2QueryInfo.QueryType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic H2QueryInfo.QueryType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic H2QueryInfo.QueryType[] values();\n}", "des": "Query type."}
{"index": 4263, "repo": "ignite-indexing-2.15.0", "code": "Class H2TableDescriptor {\n\tGridCacheContextInfo<?,?> cacheInfo();\n\tString cacheName();\n\t// Create hash index if needed.\n\tvoid createHashIndex(GridH2Table tbl);\n\t// Create text (lucene) index if needed.\n\tvoid createTextIndex(GridH2Table tbl);\n\torg.h2.index.Index hashIndex();\n\tIgniteH2Indexing indexing();\n\tString schemaName();\n\tGridH2Table table();\n\tvoid table(GridH2Table tbl);\n}", "des": "Information about table in database."}
{"index": 4264, "repo": "ignite-indexing-2.15.0", "code": "Class PartitionExtractor {\n\t// Extract partitions.\n\tPartitionResult extract(GridSqlQuery qry);\n\t// Merge partition info from multiple queries.\n\tPartitionResult mergeMapQueries(List<GridCacheSqlQuery> qrys);\n\t// Unwrap column if possible.\n\tstatic @Nullable GridSqlColumn unwrapColumn(GridSqlAst ast);\n\t// Unwrap constant if possible.\n\tstatic @Nullable GridSqlConst unwrapConst(GridSqlAst ast);\n}", "des": "Partition tree extractor."}
{"index": 4265, "repo": "ignite-indexing-2.15.0", "code": "Class QueryContextRegistry {\n\t// Clear shared context.\n\tboolean clearShared(UUID nodeId, long qryId);\n\t// Clear shared contexts on local node stop.\n\tvoid clearSharedOnLocalNodeStop();\n\t// Clear shared contexts on remote node stop.\n\tvoid clearSharedOnRemoteNodeStop(UUID nodeId);\n\t// Access query context from another thread.\n\t@Nullable QueryContext getShared(UUID nodeId, long qryId, int segmentId);\n\t// Sets current thread local context.\n\tvoid setShared(UUID nodeId, long qryId, QueryContext ctx);\n}", "des": "Registry of all currently available query contexts."}
{"index": 4266, "repo": "ignite-indexing-2.15.0", "code": "Class QueryParameters {\n\tObject[] arguments();\n\tboolean autoCommit();\n\tList<Object[]> batchedArguments();\n\tBoolean dataPageScanEnabled();\n\tboolean lazy();\n\tNestedTxMode nestedTxMode();\n\tint pageSize();\n\tint[] partitions();\n\tint timeout();\n\t// Convert current batched arguments to a form with single arguments.\n\tQueryParameters toSingleBatchedArguments(Object[] args);\n\t// Gets update internal bach size.\n\tint updateBatchSize();\n}", "des": "Query parameters which vary between requests having the same execution plan. Essentially, these are the arguments of original SqlFieldsQuery which are not part of QueryDescriptor."}
{"index": 4267, "repo": "ignite-indexing-2.15.0", "code": "Class QueryParser {\n\t// Clear cached plans.\n\tvoid clearCache();\n\t// Parse the query.\n\tQueryParserResult parse(String schemaName, SqlFieldsQuery qry, boolean remainingAllowed);\n\t// Create parameters from query.\n\tQueryParameters queryParameters(SqlFieldsQuery qry);\n}", "des": "Parser module. Splits incoming request into a series of parsed results."}
{"index": 4268, "repo": "ignite-indexing-2.15.0", "code": "Class QueryParserMetricsHolder {\n\t// Increment cache hits counter.\n\tvoid countCacheHit();\n\t// Increment cache misses counter.\n\tvoid countCacheMiss();\n}", "des": "Metric holder for metrics of query parser."}
{"index": 4269, "repo": "ignite-indexing-2.15.0", "code": "Enum SplitterQueryModelType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SplitterQueryModelType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SplitterQueryModelType[] values();\n}", "des": "Splitter query model type."}
{"index": 4270, "repo": "ignite-indexing-2.15.0", "code": "Class SqlSystemViewColumnCondition {\n\t// Parse condition for column.\n\tstatic SqlSystemViewColumnCondition forColumn(int colIdx, org.h2.result.SearchRow start, org.h2.result.SearchRow end);\n\t// Checks whether the condition is equality.\n\tboolean isEquality();\n\t// Checks whether the condition is range.\n\tboolean isRange();\n\t// Gets value, if condition is equality.\n\torg.h2.value.Value valueForEquality();\n}", "des": "Column condition."}
{"index": 4271, "repo": "ignite-indexing-2.15.0", "code": "Class UnsortedBaseReducer {\n\tprotected void addPage0(ReduceResultPage page);\n\t// Check if all rows has been fetched from all sources.\n\tboolean fetchedAll();\n\tprotected org.h2.index.Cursor findAllFetched(List<org.h2.result.Row> fetched, @Nullable org.h2.result.SearchRow first, @Nullable org.h2.result.SearchRow last);\n\t// Set source nodes.\n\tvoid setSources(Map<ClusterNode,BitSet> nodesToSegmentsCnt);\n}", "des": "Base unsorted merge index."}
{"index": 4272, "repo": "ignite-indexing-2.15.0", "code": "Enum UpdateMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic UpdateMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic UpdateMode[] values();\n}", "des": "DML statement execution plan type - MERGE/INSERT from rows or subquery, or UPDATE/DELETE from subquery or literals/params based."}
{"index": 4273, "repo": "ignite-indexing-2.15.0", "code": "Class UpdatePlanBuilder {\n\t// Prepare update plan for COPY command (AKA bulk load).\n\tstatic UpdatePlan planForBulkLoad(SqlBulkLoadCommand cmd, GridH2Table tbl);\n\t// Generate SELECT statements to retrieve data for modifications from and find fast UPDATE or DELETE args, if available.\n\tstatic UpdatePlan planForStatement(QueryDescriptor planKey, GridSqlStatement stmt, boolean mvccEnabled, IgniteH2Indexing idx, IgniteLogger log, boolean forceFillAbsentPKsWithDefaults);\n}", "des": "Logic for building update plans performed by DmlStatementsProcessor."}
{"index": 4274, "repo": "lucene-analyzers-common-8.11.2", "code": "Class AbstractWordsFileFilterFactory {\n\t// Default word set implementation.\n\tprotected abstract CharArraySet createDefaultWords();\n\tString getFormat();\n\tString getWordFiles();\n\tCharArraySet getWords();\n\t// Initialize the set of stopwords provided via ResourceLoader, or using defaults.\n\tvoid inform(ResourceLoader loader);\n\tboolean isIgnoreCase();\n}", "des": "Abstract parent class for analysis factories that accept a stopwords file as input."}
{"index": 4275, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ArabicAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Arabic."}
{"index": 4276, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ArabicNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for ArabicNormalizationFilter."}
{"index": 4277, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ArabicStemmer {\n\t// Stem an input buffer of Arabic text.\n\tint stem(char[] s, int len);\n\t// Stem a prefix off an Arabic word.\n\tint stemPrefix(char[] s, int len);\n\t// Stem suffix(es) off an Arabic word.\n\tint stemSuffix(char[] s, int len);\n}", "des": "Stemmer for Arabic."}
{"index": 4278, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ArmenianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Armenian."}
{"index": 4279, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ASCIIFoldingFilter {\n\t// Converts characters above ASCII to their ASCII equivalents.\n\tvoid foldToASCII(char[] input, int length);\n\t// Converts characters above ASCII to their ASCII equivalents.\n\tstatic int foldToASCII(char[] input, int inputPos, char[] output, int outputPos, int length);\n\tboolean incrementToken();\n\t// Does the filter preserve the original tokens?\n\tboolean isPreserveOriginal();\n\tvoid reset();\n}", "des": "This class converts alphabetic, numeric, and symbolic Unicode characters which are not in the first 127 ASCII characters (the \"Basic Latin\" Unicode block) into their ASCII equivalents, if one exists. Characters from the following Unicode blocks are converted; however, only those characters with reasonable ASCII alternatives are converted: C1 Controls and Latin-1 Supplement: http://www.unicode.org/charts/PDF/U0080.pdf Latin Extended-A: http://www.unicode.org/charts/PDF/U0100.pdf Latin Extended-B: http://www.unicode.org/charts/PDF/U0180.pdf Latin Extended Additional: http://www.unicode.org/charts/PDF/U1E00.pdf Latin Extended-C: http://www.unicode.org/charts/PDF/U2C60.pdf Latin Extended-D: http://www.unicode.org/charts/PDF/UA720.pdf IPA Extensions: http://www.unicode.org/charts/PDF/U0250.pdf Phonetic Extensions: http://www.unicode.org/charts/PDF/U1D00.pdf Phonetic Extensions Supplement: http://www.unicode.org/charts/PDF/U1D80.pdf General Punctuation: http://www.unicode.org/charts/PDF/U2000.pdf Superscripts and Subscripts: http://www.unicode.org/charts/PDF/U2070.pdf Enclosed Alphanumerics: http://www.unicode.org/charts/PDF/U2460.pdf Dingbats: http://www.unicode.org/charts/PDF/U2700.pdf Supplemental Punctuation: http://www.unicode.org/charts/PDF/U2E00.pdf Alphabetic Presentation Forms: http://www.unicode.org/charts/PDF/UFB00.pdf Halfwidth and Fullwidth Forms: http://www.unicode.org/charts/PDF/UFF00.pdf See: http://en.wikipedia.org/wiki/Latin_characters_in_Unicode For example, '' will be replaced by 'a'."}
{"index": 4280, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ASCIIFoldingFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for ASCIIFoldingFilter."}
{"index": 4281, "repo": "lucene-analyzers-common-8.11.2", "code": "Class BaseCharFilter {\n\t// Adds an offset correction mapping at the given output stream offset.\n\tprotected void addOffCorrectMap(int off, int cumulativeDiff);\n\t// Retrieve the corrected offset.\n\tprotected int correct(int currentOff);\n\tprotected int getLastCumulativeDiff();\n}", "des": "Base utility class for implementing a CharFilter. You subclass this, and then record mappings by calling addOffCorrectMap(int, int), and then invoke the correct method to correct an offset."}
{"index": 4282, "repo": "lucene-analyzers-common-8.11.2", "code": "Class BasqueAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Basque."}
{"index": 4283, "repo": "lucene-analyzers-common-8.11.2", "code": "Class BengaliAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Bengali."}
{"index": 4284, "repo": "lucene-analyzers-common-8.11.2", "code": "Class BengaliNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for BengaliNormalizationFilter."}
{"index": 4285, "repo": "lucene-analyzers-common-8.11.2", "code": "Class BrazilianAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Brazilian Portuguese language."}
{"index": 4286, "repo": "lucene-analyzers-common-8.11.2", "code": "Class BrazilianStemmer {\n\t// For log and debug purpose\n\tString log();\n\t// Stems the given term to an unique discriminator.\n\tprotected String stem(String term);\n}", "des": "A stemmer for Brazilian Portuguese words."}
{"index": 4287, "repo": "lucene-analyzers-common-8.11.2", "code": "Class BulgarianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tAnalyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Bulgarian."}
{"index": 4288, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ByteVector {\n\t// This is to implement memory allocation in the array.\n\tint alloc(int size);\n\t// returns current capacity of array\n\tint capacity();\n\tbyte get(int index);\n\tbyte[] getArray();\n\t// return number of items in array\n\tint length();\n\tvoid put(int index, byte val);\n\tvoid trimToSize();\n}", "des": "This class implements a simple byte vector with access to the underlying array. This class has been taken from the Apache FOP project (http://xmlgraphics.apache.org/fop/). They have been slightly modified."}
{"index": 4289, "repo": "lucene-analyzers-common-8.11.2", "code": "Class CatalanAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Catalan."}
{"index": 4290, "repo": "lucene-analyzers-common-8.11.2", "code": "Class CharVector {\n\tint alloc(int size);\n\t// returns current capacity of array\n\tint capacity();\n\t// Reset Vector but don't resize or clear elements\n\tvoid clear();\n\tCharVector clone();\n\tchar get(int index);\n\tchar[] getArray();\n\t// return number of items in array\n\tint length();\n\tvoid put(int index, char val);\n\tvoid trimToSize();\n}", "des": "This class implements a simple char vector with access to the underlying array. This class has been taken from the Apache FOP project (http://xmlgraphics.apache.org/fop/). They have been slightly modified."}
{"index": 4291, "repo": "lucene-analyzers-common-8.11.2", "code": "Class CJKWidthCharFilterFactory {\n\t// Wraps the given Reader with a CharFilter.\n\tReader create(Reader input);\n\t// Normalize the specified input Reader While the default implementation returns input unchanged, char filters that should be applied at normalization time can delegate to create method.\n\tReader normalize(Reader input);\n}", "des": "Factory for CJKWidthCharFilter."}
{"index": 4292, "repo": "lucene-analyzers-common-8.11.2", "code": "Class CJKWidthFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for CJKWidthFilter."}
{"index": 4293, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ClasspathResourceLoader {\n\t// Finds class of the name and expected type\n\t<T> Class<? extends T> findClass(String cname, Class<T> expectedType);\n\t// Creates an instance of the name and expected type\n\t<T> T newInstance(String cname, Class<T> expectedType);\n\t// Opens a named resource\n\tInputStream openResource(String resource);\n}", "des": "Simple ResourceLoader that uses ClassLoader.getResourceAsStream(String) and Class.forName(String,boolean,ClassLoader) to open resources and classes, respectively."}
{"index": 4294, "repo": "lucene-analyzers-common-8.11.2", "code": "Class CommonGramsFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenFilter create(TokenStream input);\n\t// Default word set implementation.\n\tprotected CharArraySet createDefaultWords();\n\tCharArraySet getCommonWords();\n}", "des": "Constructs a CommonGramsFilter."}
{"index": 4295, "repo": "lucene-analyzers-common-8.11.2", "code": "Class CommonGramsQueryFilter {\n\t// Output bigrams whenever possible to optimize queries.\n\tboolean incrementToken();\n\t// Convenience method to check if the current type is a gram type\n\tboolean isGramType();\n\tvoid reset();\n}", "des": "Wrap a CommonGramsFilter optimizing phrase queries by only returning single words when they are not a member of a bigram. Example: query input to CommonGramsFilter: \"the rain in spain falls mainly\" output of CommomGramsFilter/input to CommonGramsQueryFilter: |\"the, \"the-rain\"|\"rain\" \"rain-in\"|\"in, \"in-spain\"|\"spain\"|\"falls\"|\"mainly\" output of CommonGramsQueryFilter:\"the-rain\", \"rain-in\" ,\"in-spain\", \"falls\", \"mainly\""}
{"index": 4296, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ConcatenateGraphFilter {\n\tvoid close();\n\tvoid end();\n\tboolean incrementToken();\n\tvoid reset();\n\t// Converts the tokenStream to an automaton, treating the transition labels as utf-8.\n\tAutomaton toAutomaton();\n\t// Converts the tokenStream to an automaton.\n\tAutomaton toAutomaton(boolean unicodeAware);\n}", "des": "Concatenates/Joins every incoming token with a separator into one output token for every path through the token stream (which is a graph). In simple cases this yields one token, but in the presence of any tokens with a zero positionIncrmeent (e.g. synonyms) it will be more. This filter uses the token bytes, position increment, and position length of the incoming stream. Other attributes are not used or manipulated."}
{"index": 4297, "repo": "lucene-analyzers-common-8.11.2", "code": "Interface ConcatenateGraphFilter.BytesRefBuilderTermAttribute {\n\t// Returns the builder from which the term is derived.\n\tBytesRefBuilder builder();\n\t// Returns the term represented as UTF-16\n\tCharSequence toUTF16();\n}", "des": "Attribute providing access to the term builder and UTF-16 conversion"}
{"index": 4298, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ConcatenateGraphFilter.BytesRefBuilderTermAttributeImpl {\n\t// Returns the builder from which the term is derived.\n\tBytesRefBuilder builder();\n\tvoid clear();\n\tAttributeImpl clone();\n\tvoid copyTo(AttributeImpl target);\n\tBytesRef getBytesRef();\n\tvoid reflectWith(AttributeReflector reflector);\n\t// Returns the term represented as UTF-16\n\tCharSequence toUTF16();\n}", "des": "Implementation of ConcatenateGraphFilter.BytesRefBuilderTermAttribute"}
{"index": 4299, "repo": "lucene-analyzers-common-8.11.2", "code": "Class CzechAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns a set of default Czech-stopwords\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Czech language."}
{"index": 4300, "repo": "lucene-analyzers-common-8.11.2", "code": "Class DanishAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Danish."}
{"index": 4301, "repo": "lucene-analyzers-common-8.11.2", "code": "Class DecimalDigitFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for DecimalDigitFilter."}
{"index": 4302, "repo": "lucene-analyzers-common-8.11.2", "code": "Class DelimitedPayloadTokenFilterFactory {\n\t// Transform the specified input TokenStream\n\tDelimitedPayloadTokenFilter create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "Factory for DelimitedPayloadTokenFilter."}
{"index": 4303, "repo": "lucene-analyzers-common-8.11.2", "code": "Class DictionaryCompoundWordTokenFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "Factory for DictionaryCompoundWordTokenFilter."}
{"index": 4304, "repo": "lucene-analyzers-common-8.11.2", "code": "Class DutchAnalyzer {\n\t// Returns a (possibly reused) TokenStream which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Dutch language."}
{"index": 4305, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ElisionFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for ElisionFilter."}
{"index": 4306, "repo": "lucene-analyzers-common-8.11.2", "code": "Class EnglishAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for English."}
{"index": 4307, "repo": "lucene-analyzers-common-8.11.2", "code": "Class EstonianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Estonian."}
{"index": 4308, "repo": "lucene-analyzers-common-8.11.2", "code": "Class FilesystemResourceLoader {\n\t// Finds class of the name and expected type\n\t<T> Class<? extends T> findClass(String cname, Class<T> expectedType);\n\t// Creates an instance of the name and expected type\n\t<T> T newInstance(String cname, Class<T> expectedType);\n\t// Opens a named resource\n\tInputStream openResource(String resource);\n}", "des": "Simple ResourceLoader that opens resource files from the local file system, optionally resolving against a base directory."}
{"index": 4309, "repo": "lucene-analyzers-common-8.11.2", "code": "Class FinnishAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Finnish."}
{"index": 4310, "repo": "lucene-analyzers-common-8.11.2", "code": "Class FrenchAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for French language."}
{"index": 4311, "repo": "lucene-analyzers-common-8.11.2", "code": "Class GalicianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Galician."}
{"index": 4312, "repo": "lucene-analyzers-common-8.11.2", "code": "Class GermanAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns a set of default German-stopwords\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for German language."}
{"index": 4313, "repo": "lucene-analyzers-common-8.11.2", "code": "Class GermanNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for GermanNormalizationFilter."}
{"index": 4314, "repo": "lucene-analyzers-common-8.11.2", "code": "Class GreekAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns a set of default Greek-stopwords\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for the Greek language."}
{"index": 4315, "repo": "lucene-analyzers-common-8.11.2", "code": "Class GreekLowerCaseFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream in);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for GreekLowerCaseFilter."}
{"index": 4316, "repo": "lucene-analyzers-common-8.11.2", "code": "Class HindiAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Hindi."}
{"index": 4317, "repo": "lucene-analyzers-common-8.11.2", "code": "Class HindiNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for HindiNormalizationFilter."}
{"index": 4318, "repo": "lucene-analyzers-common-8.11.2", "code": "Class HungarianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Hungarian."}
{"index": 4319, "repo": "lucene-analyzers-common-8.11.2", "code": "Class HunspellStemFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream tokenStream);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "TokenFilterFactory that creates instances of HunspellStemFilter. Example config for British English: Both parameters dictionary and affix are mandatory. Dictionaries for many languages are available through the OpenOffice project. See http://wiki.apache.org/solr/Hunspell"}
{"index": 4320, "repo": "lucene-analyzers-common-8.11.2", "code": "Class HyphenationCompoundWordTokenFilter {\n\t// Decomposes the current CompoundWordTokenFilterBase.termAtt and places CompoundWordTokenFilterBase.CompoundToken instances in the CompoundWordTokenFilterBase.tokens list.\n\tprotected void decompose();\n\t// Create a hyphenator tree\n\tstatic HyphenationTree getHyphenationTree(InputSource hyphenationSource);\n\t// Create a hyphenator tree\n\tstatic HyphenationTree getHyphenationTree(String hyphenationFilename);\n}", "des": "A TokenFilter that decomposes compound words found in many Germanic languages. \"Donaudampfschiff\" becomes Donau, dampf, schiff so that you can find \"Donaudampfschiff\" even when you only enter \"schiff\". It uses a hyphenation grammar and a word dictionary to achieve this."}
{"index": 4321, "repo": "lucene-analyzers-common-8.11.2", "code": "Class HyphenationCompoundWordTokenFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenFilter create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "Factory for HyphenationCompoundWordTokenFilter."}
{"index": 4322, "repo": "lucene-analyzers-common-8.11.2", "code": "Class IndicNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for IndicNormalizationFilter."}
{"index": 4323, "repo": "lucene-analyzers-common-8.11.2", "code": "Class IndonesianAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Indonesian (Bahasa)"}
{"index": 4324, "repo": "lucene-analyzers-common-8.11.2", "code": "Class IrishAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Irish."}
{"index": 4325, "repo": "lucene-analyzers-common-8.11.2", "code": "Class IrishLowerCaseFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for IrishLowerCaseFilter."}
{"index": 4326, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ItalianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Italian."}
{"index": 4327, "repo": "lucene-analyzers-common-8.11.2", "code": "Class KeepWordFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Default word set implementation.\n\tprotected CharArraySet createDefaultWords();\n}", "des": "Factory for KeepWordFilter."}
{"index": 4328, "repo": "lucene-analyzers-common-8.11.2", "code": "Class KeywordMarkerFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n\tboolean isIgnoreCase();\n}", "des": "Factory for KeywordMarkerFilter."}
{"index": 4329, "repo": "lucene-analyzers-common-8.11.2", "code": "Class LatvianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Latvian."}
{"index": 4330, "repo": "lucene-analyzers-common-8.11.2", "code": "Class LithuanianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Lithuanian."}
{"index": 4331, "repo": "lucene-analyzers-common-8.11.2", "code": "Class LowerCaseFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for LowerCaseFilter."}
{"index": 4332, "repo": "lucene-analyzers-common-8.11.2", "code": "Class NormalizeCharMap.Builder {\n\t// Records a replacement to be applied to the input stream.\n\tvoid add(String match, String replacement);\n\t// Builds the NormalizeCharMap; call this once you are done calling add(java.lang.String, java.lang.String).\n\tNormalizeCharMap build();\n}", "des": "Builds an NormalizeCharMap."}
{"index": 4333, "repo": "lucene-analyzers-common-8.11.2", "code": "Class NorwegianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Norwegian."}
{"index": 4334, "repo": "lucene-analyzers-common-8.11.2", "code": "Interface PatternConsumer {\n\t// Add a character class.\n\tvoid addClass(String chargroup);\n\t// Add a hyphenation exception.\n\tvoid addException(String word, ArrayList<Object> hyphenatedword);\n\t// Add hyphenation patterns.\n\tvoid addPattern(String pattern, String values);\n}", "des": "This interface is used to connect the XML pattern file parser to the hyphenation tree. This class has been taken from the Apache FOP project (http://xmlgraphics.apache.org/fop/). They have been slightly modified."}
{"index": 4335, "repo": "lucene-analyzers-common-8.11.2", "code": "Class PatternReplaceCharFilterFactory {\n\t// Wraps the given Reader with a CharFilter.\n\tReader create(Reader input);\n\t// Normalize the specified input Reader While the default implementation returns input unchanged, char filters that should be applied at normalization time can delegate to create method.\n\tReader normalize(Reader input);\n}", "des": "Factory for PatternReplaceCharFilter."}
{"index": 4336, "repo": "lucene-analyzers-common-8.11.2", "code": "Class PatternTypingFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "Provides a filter that will analyze tokens with the analyzer from an arbitrary field type. By itself this filter is not very useful. Normally it is combined with a filter that reacts to types or flags. <fieldType name=\"text_taf\" class=\"solr.TextField\" positionIncrementGap=\"100\"> <analyzer> <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/> <filter class=\"com.example.PatternTypingFilter\" patternFile=\"patterns.txt\"/> <filter class=\"solr.TokenAnalyzerFilter\" asType=\"text_en\" preserveType=\"true\"/> <filter class=\"solr.TypeAsSynonymFilterFactory\" prefix=\"__TAS__\" ignore=\"word,&lt;ALPHANUM&gt;,&lt;NUM&gt;,&lt;SOUTHEAST_ASIAN&gt;,&lt;IDEOGRAPHIC&gt;,&lt;HIRAGANA&gt;,&lt;KATAKANA&gt;,&lt;HANGUL&gt;,&lt;EMOJI&gt;\"/> </analyzer> </fieldType>"}
{"index": 4337, "repo": "lucene-analyzers-common-8.11.2", "code": "Class PersianAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\t// Wraps the Reader with PersianCharFilter\n\tprotected Reader initReader(String fieldName, Reader reader);\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Persian."}
{"index": 4338, "repo": "lucene-analyzers-common-8.11.2", "code": "Class PersianCharFilterFactory {\n\t// Wraps the given Reader with a CharFilter.\n\tReader create(Reader input);\n\t// Normalize the specified input Reader While the default implementation returns input unchanged, char filters that should be applied at normalization time can delegate to create method.\n\tReader normalize(Reader input);\n}", "des": "Factory for PersianCharFilter."}
{"index": 4339, "repo": "lucene-analyzers-common-8.11.2", "code": "Class PersianNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for PersianNormalizationFilter."}
{"index": 4340, "repo": "lucene-analyzers-common-8.11.2", "code": "Class PortugueseAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Portuguese."}
{"index": 4341, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ProtectedTermFilterFactory {\n\t// Modify the incoming TokenStream with a ConditionalTokenFilter\n\tprotected ConditionalTokenFilter create(TokenStream input, Function<TokenStream,TokenStream> inner);\n\t// Initialises this component with the corresponding ResourceLoader\n\tvoid doInform(ResourceLoader loader);\n\tCharArraySet getProtectedTerms();\n\tboolean isIgnoreCase();\n}", "des": "Factory for a ProtectedTermFilter"}
{"index": 4342, "repo": "lucene-analyzers-common-8.11.2", "code": "Class QueryAutoStopWordAnalyzer {\n\t// Provides information on which stop words have been identified for all fields\n\tTerm[] getStopWords();\n\t// Provides information on which stop words have been identified for a field\n\tString[] getStopWords(String fieldName);\n\tprotected Analyzer getWrappedAnalyzer(String fieldName);\n\tprotected Analyzer.TokenStreamComponents wrapComponents(String fieldName, Analyzer.TokenStreamComponents components);\n}", "des": "An Analyzer used primarily at query time to wrap another analyzer and provide a layer of protection which prevents very common words from being passed into queries."}
{"index": 4343, "repo": "lucene-analyzers-common-8.11.2", "code": "Interface ResourceLoader {\n\t// Finds class of the name and expected type\n\t<T> Class<? extends T> findClass(String cname, Class<T> expectedType);\n\t// Creates an instance of the name and expected type\n\t<T> T newInstance(String cname, Class<T> expectedType);\n\t// Opens a named resource\n\tInputStream openResource(String resource);\n}", "des": "Abstraction for loading resources (streams, files, and classes)."}
{"index": 4344, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ReverseStringFilter {\n\tboolean incrementToken();\n\t// Reverses the given input buffer in-place\n\tstatic void reverse(char[] buffer);\n\t// Partially reverses the given input buffer in-place from offset 0 up to the given length.\n\tstatic void reverse(char[] buffer, int len);\n\t// Partially reverses the given input buffer in-place from the given offset up to the given length.\n\tstatic void reverse(char[] buffer, int start, int len);\n\t// Reverses the given input string\n\tstatic String reverse(String input);\n}", "des": "Reverse token string, for example \"country\" => \"yrtnuoc\"."}
{"index": 4345, "repo": "lucene-analyzers-common-8.11.2", "code": "Class RollingCharBuffer {\n\t// Call this to notify us that no chars before this absolute position are needed anymore.\n\tvoid freeBefore(int pos);\n\tint get(int pos);\n\tchar[] get(int posStart, int length);\n\t// Clear array and switch to new reader.\n\tvoid reset(Reader reader);\n}", "des": "Acts like a forever growing char[] as you read characters into it from the provided reader, but internally it uses a circular buffer to only hold the characters that haven't been freed yet. This is like a PushbackReader, except you don't have to specify up-front the max size of the buffer, but you do have to periodically call freeBefore(int)."}
{"index": 4346, "repo": "lucene-analyzers-common-8.11.2", "code": "Class RomanianAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Romanian."}
{"index": 4347, "repo": "lucene-analyzers-common-8.11.2", "code": "Class RussianAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Russian language."}
{"index": 4348, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ScandinavianFoldingFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for ScandinavianFoldingFilter."}
{"index": 4349, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ScandinavianNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tScandinavianNormalizationFilter create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for ScandinavianNormalizationFilter."}
{"index": 4350, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SegmentingTokenizerBase {\n\tvoid end();\n\tboolean incrementToken();\n\t// Returns true if another word is available\n\tprotected abstract boolean incrementWord();\n\t// For sentence tokenization, these are the unambiguous break positions.\n\tprotected boolean isSafeEnd(char ch);\n\tvoid reset();\n\t// Provides the next input sentence for analysis\n\tprotected abstract void setNextSentence(int sentenceStart, int sentenceEnd);\n}", "des": "Breaks text into sentences with a BreakIterator and allows subclasses to decompose these sentences into words."}
{"index": 4351, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SerbianNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for SerbianNormalizationFilter."}
{"index": 4352, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ShingleAnalyzerWrapper {\n\tString getFillerToken();\n\t// The max shingle (token ngram) size\n\tint getMaxShingleSize();\n\t// The min shingle (token ngram) size\n\tint getMinShingleSize();\n\tString getTokenSeparator();\n\tAnalyzer getWrappedAnalyzer(String fieldName);\n\tboolean isOutputUnigrams();\n\tboolean isOutputUnigramsIfNoShingles();\n\tprotected Analyzer.TokenStreamComponents wrapComponents(String fieldName, Analyzer.TokenStreamComponents components);\n}", "des": "A ShingleAnalyzerWrapper wraps a ShingleFilter around another Analyzer."}
{"index": 4353, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SnowballPorterFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenFilter create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "Factory for SnowballFilter, with configurable language"}
{"index": 4354, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SoraniAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Sorani Kurdish."}
{"index": 4355, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SoraniNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for SoraniNormalizationFilter."}
{"index": 4356, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SpanishAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Spanish."}
{"index": 4357, "repo": "lucene-analyzers-common-8.11.2", "code": "Class StemmerOverrideFilter.Builder {\n\t// Adds an input string and its stemmer override output to this builder.\n\tboolean add(CharSequence input, CharSequence output);\n\t// Returns an StemmerOverrideFilter.StemmerOverrideMap to be used with the StemmerOverrideFilter\n\tStemmerOverrideFilter.StemmerOverrideMap build();\n}", "des": "This builder builds an FST for the StemmerOverrideFilter"}
{"index": 4358, "repo": "lucene-analyzers-common-8.11.2", "code": "Class StemmerOverrideFilter.StemmerOverrideMap {\n\t// Returns the value mapped to the given key or null if the key is not in the FST dictionary.\n\tBytesRef get(char[] buffer, int bufferLen, FST.Arc<BytesRef> scratchArc, FST.BytesReader fstReader);\n\t// Returns a FST.BytesReader to pass to the get(char[], int, FST.Arc, FST.BytesReader) method.\n\tFST.BytesReader getBytesReader();\n}", "des": "A read-only 4-byte FST backed map that allows fast case-insensitive key value lookups for StemmerOverrideFilter"}
{"index": 4359, "repo": "lucene-analyzers-common-8.11.2", "code": "Class StemmerOverrideFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n\tboolean isIgnoreCase();\n}", "des": "Factory for StemmerOverrideFilter."}
{"index": 4360, "repo": "lucene-analyzers-common-8.11.2", "code": "Class StopFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Default word set implementation.\n\tprotected CharArraySet createDefaultWords();\n\tCharArraySet getStopWords();\n}", "des": "Factory for StopFilter. <fieldType name=\"text_stop\" class=\"solr.TextField\" positionIncrementGap=\"100\" autoGeneratePhraseQueries=\"true\"> <analyzer> <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/> <filter class=\"solr.StopFilterFactory\" ignoreCase=\"true\" words=\"stopwords.txt\" format=\"wordset\" </analyzer> </fieldType>"}
{"index": 4361, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SwedishAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Swedish."}
{"index": 4362, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SynonymGraphFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n\t// Load synonyms with the given SynonymMap.Parser class.\n\tprotected SynonymMap loadSynonyms(ResourceLoader loader, String cname, boolean dedup, Analyzer analyzer);\n}", "des": "Factory for SynonymGraphFilter. <fieldType name=\"text_synonym\" class=\"solr.TextField\" positionIncrementGap=\"100\"> <analyzer> <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/> <filter class=\"solr.SynonymGraphFilterFactory\" synonyms=\"synonyms.txt\" format=\"solr\" ignoreCase=\"false\" expand=\"true\" tokenizerFactory=\"solr.WhitespaceTokenizerFactory\" [optional tokenizer factory parameters]/> </analyzer> </fieldType>"}
{"index": 4363, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SynonymMap.Builder {\n\t// Add a phrase->phrase synonym mapping.\n\tvoid add(CharsRef input, CharsRef output, boolean includeOrig);\n\t// Builds an SynonymMap and returns it.\n\tSynonymMap build();\n\t// Sugar: just joins the provided terms with SynonymMap.WORD_SEPARATOR.\n\tstatic CharsRef join(String[] words, CharsRefBuilder reuse);\n}", "des": "Builds an FSTSynonymMap."}
{"index": 4364, "repo": "lucene-analyzers-common-8.11.2", "code": "Class SynonymMap.Parser {\n\t// Sugar: analyzes the text with the analyzer and separates by SynonymMap.WORD_SEPARATOR.\n\tCharsRef analyze(String text, CharsRefBuilder reuse);\n\t// Parse the given input, adding synonyms to the inherited SynonymMap.Builder.\n\tabstract void parse(Reader in);\n}", "des": "Abstraction for parsing synonym files."}
{"index": 4365, "repo": "lucene-analyzers-common-8.11.2", "code": "Class TeeSinkTokenFilter {\n\t// TeeSinkTokenFilter passes all tokens to the added sinks when itself is consumed.\n\tvoid consumeAllTokens();\n\tvoid end();\n\tboolean incrementToken();\n\t// Returns a new TeeSinkTokenFilter.SinkTokenStream that receives all tokens consumed by this stream.\n\tTokenStream newSinkTokenStream();\n\tvoid reset();\n}", "des": "This TokenFilter provides the ability to set aside attribute states that have already been analyzed. This is useful in situations where multiple fields share many common analysis steps and then go their separate ways."}
{"index": 4366, "repo": "lucene-analyzers-common-8.11.2", "code": "Class TeluguAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop-words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Telugu."}
{"index": 4367, "repo": "lucene-analyzers-common-8.11.2", "code": "Class TeluguNormalizationFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for TeluguNormalizationFilter."}
{"index": 4368, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ThaiAnalyzer {\n\t// Creates Analyzer.TokenStreamComponents used to tokenize all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Thai language. It uses BreakIterator to break words."}
{"index": 4369, "repo": "lucene-analyzers-common-8.11.2", "code": "Class ThaiTokenizer {\n\t// Returns true if another word is available\n\tprotected boolean incrementWord();\n\t// Provides the next input sentence for analysis\n\tprotected void setNextSentence(int sentenceStart, int sentenceEnd);\n}", "des": "Tokenizer that use BreakIterator to tokenize Thai text."}
{"index": 4370, "repo": "lucene-analyzers-common-8.11.2", "code": "Enum TimeoutPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TimeoutPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TimeoutPolicy[] values();\n}", "des": "A strategy determining what to do when Hunspell API calls take too much time"}
{"index": 4371, "repo": "lucene-analyzers-common-8.11.2", "code": "Class TrimFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for TrimFilter."}
{"index": 4372, "repo": "lucene-analyzers-common-8.11.2", "code": "Class TurkishAnalyzer {\n\t// Creates a Analyzer.TokenStreamComponents which tokenizes all the text in the provided Reader.\n\tprotected Analyzer.TokenStreamComponents createComponents(String fieldName);\n\t// Returns an unmodifiable instance of the default stop words set.\n\tstatic CharArraySet getDefaultStopSet();\n\tprotected TokenStream normalize(String fieldName, TokenStream in);\n}", "des": "Analyzer for Turkish."}
{"index": 4373, "repo": "lucene-analyzers-common-8.11.2", "code": "Class TurkishLowerCaseFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for TurkishLowerCaseFilter."}
{"index": 4374, "repo": "lucene-analyzers-common-8.11.2", "code": "Class TypeTokenFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\tSet<String> getStopTypes();\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "Factory class for TypeTokenFilter."}
{"index": 4375, "repo": "lucene-analyzers-common-8.11.2", "code": "Class UpperCaseFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenStream create(TokenStream input);\n\t// Normalize the specified input TokenStream While the default implementation returns input unchanged, filters that should be applied at normalization time can delegate to create method.\n\tTokenStream normalize(TokenStream input);\n}", "des": "Factory for UpperCaseFilter. <fieldType name=\"text_uppercase\" class=\"solr.TextField\" positionIncrementGap=\"100\"> <analyzer> <tokenizer class=\"solr.WhitespaceTokenizerFactory\"/> <filter class=\"solr.UpperCaseFilterFactory\"/> </analyzer> </fieldType>"}
{"index": 4376, "repo": "lucene-analyzers-common-8.11.2", "code": "Class WordDelimiterGraphFilterFactory {\n\t// Transform the specified input TokenStream\n\tTokenFilter create(TokenStream input);\n\t// Initializes this component with the provided ResourceLoader (used for loading classes, files, etc).\n\tvoid inform(ResourceLoader loader);\n}", "des": "Factory for WordDelimiterGraphFilter."}
{"index": 4377, "repo": "ratis-common-2.5.1", "code": "Class AutoCloseableLock {\n\t// Acquire the given lock and then wrap it with AutoCloseableLock so that the given lock can be released by calling close(), or by using a try-with-resources statement as shown below.\n\tstatic AutoCloseableLock acquire(Lock lock);\n\tstatic AutoCloseableLock acquire(Lock lock, Runnable preUnlock);\n\t// Unlock the underlying lock.\n\tvoid close();\n}", "des": "Wrap a lock with the AutoCloseable interface so that the close() method will unlock the lock."}
{"index": 4378, "repo": "ratis-common-2.5.1", "code": "Class AwaitForSignal {\n\t// The same as Condition.await()\n\tvoid await();\n\t// The same as Condition.await(long, TimeUnit)\n\tboolean await(long time, TimeUnit unit);\n\t// The same as Condition.signal()\n\tvoid signal();\n}", "des": "This class is a partial implementation of Condition. Only some of the await and signal methods are implemented."}
{"index": 4379, "repo": "ratis-common-2.5.1", "code": "Interface CloseAsync<REPLY> {\n\t// The same as AutoCloseable.close().\n\tdefault void close();\n\t// Close asynchronously.\n\tCompletableFuture<REPLY> closeAsync();\n}", "des": "Support the closeAsync() method."}
{"index": 4380, "repo": "ratis-common-2.5.1", "code": "Class CodeInjectionForTesting {\n\t// Execute the injected code, if there is any.\n\tstatic boolean execute(String injectionPoint, Object localId, Object remoteId, Object... args);\n\t// Put an injection point.\n\tstatic void put(String injectionPoint, CodeInjectionForTesting.Code code);\n}", "des": "Inject code for testing."}
{"index": 4381, "repo": "ratis-common-2.5.1", "code": "Class JmxRegister {\n\t// Try registering the mBean with the names one by one.\n\tString register(Object mBean, Iterable<Supplier<String>> names);\n\t// Un-register the previously registered mBean.\n\tboolean unregister();\n}", "des": "For registering JMX beans."}
{"index": 4382, "repo": "ratis-common-2.5.1", "code": "Class LongMinMax {\n\t// Update min and max with the given number.\n\tvoid accumulate(long n);\n\t// Combine that to this.\n\tvoid combine(LongMinMax that);\n\tlong getMax();\n\tlong getMin();\n\tboolean isInitialized();\n}", "des": "Min and max values in long. This class is mutable. This class is NOT thread safe."}
{"index": 4383, "repo": "ratis-common-2.5.1", "code": "Class MultipleLinearRandomRetry {\n\tboolean equals(Object that);\n\t// Determines whether it is supposed to retry after the operation has failed.\n\tRetryPolicy.Action handleAttemptFailure(RetryPolicy.Event event);\n\t// Parse the given string as a MultipleLinearRandomRetry object.\n\tstatic MultipleLinearRandomRetry parseCommaSeparated(String input);\n}", "des": "Given pairs of number of retries and sleep time (n0, t0), (n1, t1), ..., the first n0 retries sleep t0 milliseconds on average, the following n1 retries sleep t1 milliseconds on average, and so on. For all the sleep, the actual sleep time is randomly uniform distributed in the close interval [0.5t, 1.5t], where t is the sleep time specified. The objects of this class are immutable."}
{"index": 4384, "repo": "ratis-common-2.5.1", "code": "Class OpenCloseState {\n\t// Assert this is open.\n\tvoid assertOpen();\n\t// Transit to close state.\n\tboolean close();\n\tThrowable getThrowable();\n\tboolean isClosed();\n\tboolean isOpened();\n\tboolean isUnopened();\n\t// Transit to open state.\n\tvoid open();\n}", "des": "The state of objects that can be unopened, opened, closed or exception."}
{"index": 4385, "repo": "ratis-common-2.5.1", "code": "Class Parameters {\n\t<T> T get(String key, Class<T> valueClass);\n\t// The same as get(String, Class) except that this method throws a NullPointerException if the key does not map to any value.\n\t<T> T getNonNull(String key, Class<T> valueClass);\n\t// Put the key-value pair to the map.\n\t<T> T put(String key, T value, Class<T> valueClass);\n}", "des": "A generic parameter map. The difference between this class and RaftProperties is that RaftProperties is String based, i.e. properties are strings, while this class is Object based, i.e. parameters can be any objects. Null keys or null values are not supported. This class is thread safe."}
{"index": 4386, "repo": "ratis-common-2.5.1", "code": "Interface ReferenceCountedObject<T> {\n\tT get();\n\t// Release the object.\n\tboolean release();\n\t// Retain the object for later use.\n\tT retain();\n\t// Wrap the given value as a ReferenceCountedObject.\n\tstatic <V> ReferenceCountedObject<V> wrap(V value, Runnable retainMethod, Runnable releaseMethod);\n}", "des": "A reference-counted object can be retained for later use and then be released for returning the resource. - When the object is retained, the reference count is incremented by 1. - When the object is released, the reference count is decremented by 1. - If the object is retained, it must be released afterward. Otherwise, the object will not be returned, and it will cause a resource leak. - If the object is retained multiple times, it must be released the same number of times. - If the object has been retained and then completely released (i.e. the reference count becomes 0), it must not be retained/released/accessed anymore since it may have been allocated for other use."}
{"index": 4387, "repo": "ratis-common-2.5.1", "code": "Enum SupportedRpcType {\n\tRpcFactory newFactory(Parameters parameters);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SupportedRpcType valueOf(String name);\n\t// Same as valueOf(String) except that this method is case insensitive.\n\tstatic SupportedRpcType valueOfIgnoreCase(String s);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SupportedRpcType[] values();\n}", "des": "The RPC types supported."}
{"index": 4388, "repo": "ratis-common-2.5.1", "code": "Enum TimeDuration.Abbreviation {\n\tList<String> getSymbols();\n\tTimeUnit unit();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TimeDuration.Abbreviation valueOf(String name);\n\tstatic TimeDuration.Abbreviation valueOf(TimeUnit unit);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TimeDuration.Abbreviation[] values();\n}", "des": "Abbreviations of TimeUnit."}
{"index": 4389, "repo": "ratis-common-2.5.1", "code": "Interface TimeoutExecutor {\n\tstatic TimeoutExecutor getInstance();\n\tint getTaskCount();\n\t// When timeout, run the task.\n\tdefault void onTimeout(TimeDuration timeout, CheckedRunnable<?> task, org.slf4j.Logger log, Supplier<String> errorMessage);\n\t// Schedule a timeout task.\n\t<THROWABLE extends Throwable>void onTimeout(TimeDuration timeout, CheckedRunnable<THROWABLE> task, Consumer<THROWABLE> errorHandler);\n}", "des": "Execute timeout tasks."}
{"index": 4390, "repo": "spring-cloud-aws-core-2.2.6.RELEASE", "code": "Interface StackResourceRegistry {\n\t// Returns the name of the stack represented by this stack resource registry.\n\tString getStackName();\n\t// Returns the physical id of the resource identified by the provided logical resource id.\n\tString lookupPhysicalResourceId(String logicalResourceId);\n}", "des": "Represents a registry of logical stack resource ids mapped to physical resource ids."}
{"index": 4391, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Interface BackupCopyJob {\n\t// Cancel copy job\n\tvoid cancel(String jobHandler);\n\t// Copy backup data to destination\n\tint copy(BackupInfo backupInfo, BackupManager backupManager, org.apache.hadoop.conf.Configuration conf, BackupType backupType, String[] options);\n}", "des": "Backup copy job is a part of a backup process. The concrete implementation is responsible for copying data from a cluster to backup destination. Concrete implementation is provided by backup provider, see BackupRestoreFactory"}
{"index": 4392, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Enum BackupInfo.BackupPhase {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BackupInfo.BackupPhase valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BackupInfo.BackupPhase[] values();\n}", "des": "BackupPhase - phases of an ACTIVE backup session (running), when state of a backup session is BackupState.RUNNING"}
{"index": 4393, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Enum BackupInfo.BackupState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BackupInfo.BackupState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BackupInfo.BackupState[] values();\n}", "des": "Backup session states"}
{"index": 4394, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Class BackupRestoreFactory {\n\t// Gets backup copy job\n\tstatic BackupCopyJob getBackupCopyJob(org.apache.hadoop.conf.Configuration conf);\n\t// Gets backup merge job\n\tstatic BackupMergeJob getBackupMergeJob(org.apache.hadoop.conf.Configuration conf);\n\t// Gets backup restore job\n\tstatic RestoreJob getRestoreJob(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Factory implementation for backup/restore related jobs"}
{"index": 4395, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Class FullTableBackupClient {\n\t// Backup request execution.\n\tvoid execute();\n\t// Do snapshot copy.\n\tprotected void snapshotCopy(BackupInfo backupInfo);\n\tprotected void snapshotTable(Admin admin, TableName tableName, String snapshotName);\n}", "des": "Full table backup implementation"}
{"index": 4396, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Class LogRollBackupSubprocedure {\n\tvoid acquireBarrier();\n\t// Cancel threads if they haven't finished.\n\tvoid cleanup(Exception e);\n\t// do a log roll.\n\tbyte[] insideBarrier();\n\t// Hooray!\n\tvoid releaseBarrier();\n}", "des": "This backup sub-procedure implementation forces a WAL rolling on a RS."}
{"index": 4397, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Class LogRollBackupSubprocedurePool {\n\tvoid abort(String why, Throwable e);\n\t// Attempt to cleanly shutdown any running tasks - allows currently running tasks to cleanly finish\n\tvoid close();\n\tboolean isAborted();\n\t// Submit a task to the pool.\n\tvoid submitTask(Callable<Void> task);\n\t// Wait for all of the currently outstanding tasks submitted via submitTask(Callable)\n\tboolean waitForOutstandingTasks();\n}", "des": "Handle running each of the individual tasks for completing a backup procedure on a region server."}
{"index": 4398, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Class LogRollRegionServerProcedureManager {\n\t// If in a running state, creates the specified subprocedure for handling a backup procedure.\n\tSubprocedure buildSubprocedure(byte[] data);\n\tString getProcedureSignature();\n\tvoid initialize(RegionServerServices rss);\n\t// Start accepting backup procedure requests.\n\tvoid start();\n\t// Close this and all running backup procedure tasks\n\tvoid stop(boolean force);\n}", "des": "This manager class handles the work dealing with distributed WAL roll request."}
{"index": 4399, "repo": "hbase-backup-3.0.0-alpha-4", "code": "Class MapReduceHFileSplitterJob {\n\t// Sets up the actual job.\n\torg.apache.hadoop.mapreduce.Job createSubmittableJob(String[] args);\n\t// Main entry point.\n\tstatic void main(String[] args);\n\tint run(String[] args);\n}", "des": "A tool to split HFiles into new region boundaries as a MapReduce job. The tool generates HFiles for later bulk importing."}
{"index": 4400, "repo": "calcite-core-1.34.0", "code": "Class AbstractConverter {\n\t// Returns the cost of this plan (not including children).\n\t@Nullable RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq);\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Describes the inputs and attributes of this relational expression.\n\tRelWriter explainTerms(RelWriter pw);\n\t// Indicates whether it is an enforcer operator, e.g.\n\tboolean isEnforcer();\n}", "des": "Converts a relational expression to any given output convention."}
{"index": 4401, "repo": "calcite-core-1.34.0", "code": "Class AbstractQueryableTable {\n\t// Returns the element type of the collection that will implement this table.\n\tType getElementType();\n\t// Generates an expression with which this table can be referenced in generated code.\n\torg.apache.calcite.linq4j.tree.Expression getExpression(SchemaPlus schema, String tableName, Class clazz);\n}", "des": "Abstract base class for implementing Table."}
{"index": 4402, "repo": "calcite-core-1.34.0", "code": "Class AbstractSqlType {\n\t// Gets a canonical object representing the family of this type.\n\tRelDataTypeFamily getFamily();\n\t// Returns the precedence list for this type.\n\tRelDataTypePrecedenceList getPrecedenceList();\n\t// Gets the SqlTypeName of this type.\n\tSqlTypeName getSqlTypeName();\n\t// Queries whether this type allows null values.\n\tboolean isNullable();\n}", "des": "Abstract base class for SQL implementations of RelDataType."}
{"index": 4403, "repo": "calcite-core-1.34.0", "code": "Interface AggAddContext {\n\t// Returns Linq4j form of arguments.\n\tList<org.apache.calcite.linq4j.tree.Expression> arguments();\n\t// Returns RexNode representation of arguments.\n\tList<RexNode> rexArguments();\n\t// Returns RexNode representation of the filter, or null.\n\t@Nullable RexNode rexFilterArgument();\n\t// Returns a RexToLixTranslator suitable to transform the arguments.\n\tRexToLixTranslator rowTranslator();\n}", "des": "Information for a call to AggImplementor.implementAdd(AggContext, AggAddContext)."}
{"index": 4404, "repo": "calcite-core-1.34.0", "code": "Class AggregateCaseToFilterRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Rule that converts CASE-style filtered aggregates into true filtered aggregates."}
{"index": 4405, "repo": "calcite-core-1.34.0", "code": "Interface AggregateExpandDistinctAggregatesRule.Config {\n\t// Whether to use GROUPING SETS, default true.\n\tdefault boolean isUsingGroupingSets();\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateExpandDistinctAggregatesRule toRule();\n\t// Sets isUsingGroupingSets().\n\tAggregateExpandDistinctAggregatesRule.Config withUsingGroupingSets(boolean usingGroupingSets);\n}", "des": "Rule configuration."}
{"index": 4406, "repo": "calcite-core-1.34.0", "code": "Interface AggregateExpandWithinDistinctRule.Config {\n\t// Whether the code generated by the rule should throw if the arguments are not functionally dependent.\n\tdefault boolean throwIfNotUnique();\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateExpandWithinDistinctRule toRule();\n\t// Sets throwIfNotUnique().\n\tAggregateExpandWithinDistinctRule.Config withThrowIfNotUnique(boolean throwIfNotUnique);\n}", "des": "Rule configuration."}
{"index": 4407, "repo": "calcite-core-1.34.0", "code": "Interface AggregateExtractProjectRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateExtractProjectRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateExtractProjectRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends RelNode> inputClass);\n}", "des": "Rule configuration."}
{"index": 4408, "repo": "calcite-core-1.34.0", "code": "Class AggregateFunctionImpl {\n\t// Creates an aggregate function, or returns null.\n\tstatic @Nullable AggregateFunctionImpl create(Class<?> clazz);\n\t// Returns implementor that translates the function to linq4j expression.\n\tAggImplementor getImplementor(boolean windowContext);\n\t// Returns the parameters of this function.\n\tList<FunctionParameter> getParameters();\n\t// Returns the return type of this function, constructed using the given type factory.\n\tRelDataType getReturnType(RelDataTypeFactory typeFactory);\n}", "des": "Implementation of AggregateFunction via user-defined class. The class should implement A init(), A add(A, V), and R result(A) methods. All the methods should be either static or instance. Bonus point: when using non-static implementation, the aggregate object is reused through the calculation, thus it can have aggregation-related state."}
{"index": 4409, "repo": "calcite-core-1.34.0", "code": "Interface AggregateJoinJoinRemoveRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateJoinJoinRemoveRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateJoinJoinRemoveRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4410, "repo": "calcite-core-1.34.0", "code": "Interface AggregateJoinRemoveRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateJoinRemoveRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateJoinRemoveRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4411, "repo": "calcite-core-1.34.0", "code": "Class AggregateProjectConstantToDummyJoinRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Planner rule that recognizes a Aggregate on top of a Project where the aggregate's group set contains literals (true, false, DATE, chars, etc), and removes the literals from the group keys by joining with a dummy table of literals."}
{"index": 4412, "repo": "calcite-core-1.34.0", "code": "Interface AggregateProjectMergeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateProjectMergeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateProjectMergeRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends Project> projectClass);\n}", "des": "Rule configuration."}
{"index": 4413, "repo": "calcite-core-1.34.0", "code": "Interface AggregateProjectPullUpConstantsRule.Config {\n\t// Creates the operands for the rule instance.\n\tdefault RelRule.OperandTransform operandSupplier();\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateProjectPullUpConstantsRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateProjectPullUpConstantsRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends RelNode> inputClass);\n}", "des": "Rule configuration."}
{"index": 4414, "repo": "calcite-core-1.34.0", "code": "Interface AggregateProjectStarTableRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateProjectStarTableRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateProjectStarTableRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends Project> projectClass, Class<StarTable.StarTableScan> scanClass);\n}", "des": "Rule configuration."}
{"index": 4415, "repo": "calcite-core-1.34.0", "code": "Interface AggregateRemoveRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateRemoveRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateRemoveRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass);\n}", "des": "Rule configuration."}
{"index": 4416, "repo": "calcite-core-1.34.0", "code": "Interface AggregateStarTableRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateStarTableRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateStarTableRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<StarTable.StarTableScan> scanClass);\n}", "des": "Rule configuration."}
{"index": 4417, "repo": "calcite-core-1.34.0", "code": "Interface AggregateUnionAggregateRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateUnionAggregateRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateUnionAggregateRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends Union> unionClass, Class<? extends RelNode> firstUnionInputClass, Class<? extends RelNode> secondUnionInputClass);\n}", "des": "Rule configuration."}
{"index": 4418, "repo": "calcite-core-1.34.0", "code": "Interface AggregateUnionTransposeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateUnionTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateUnionTransposeRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends Union> unionClass);\n}", "des": "Rule configuration."}
{"index": 4419, "repo": "calcite-core-1.34.0", "code": "Interface AggregateValuesRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault AggregateValuesRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault AggregateValuesRule.Config withOperandFor(Class<? extends Aggregate> aggregateClass, Class<? extends Values> valuesClass);\n}", "des": "Rule configuration."}
{"index": 4420, "repo": "calcite-core-1.34.0", "code": "Class AggregatingSelectScope.Resolved {\n\t// Returns whether a given expression is equal to one of the grouping expressions.\n\tboolean isGroupingExpr(SqlNode operand);\n\t// Returns whether a field should be nullable due to grouping sets.\n\tboolean isNullable(int i);\n\tint lookupGroupingExpr(SqlNode operand);\n}", "des": "Information about an aggregating scope that can only be determined after validation has occurred. Therefore it cannot be populated when the scope is created."}
{"index": 4421, "repo": "calcite-core-1.34.0", "code": "Interface AggResultContext {\n\tAggregateCall call();\n\t// Expression by which to reference the key upon which the values in the accumulator were aggregated.\n\t@Nullable org.apache.calcite.linq4j.tree.Expression key();\n\t// Returns an expression that references the ith field of the key, cast to the appropriate type.\n\torg.apache.calcite.linq4j.tree.Expression keyField(int i);\n}", "des": "Information for a call to AggImplementor.implementResult(AggContext, AggResultContext)"}
{"index": 4422, "repo": "calcite-core-1.34.0", "code": "Class AggResultContextImpl {\n\tAggregateCall call();\n\t// Expression by which to reference the key upon which the values in the accumulator were aggregated.\n\t@Nullable org.apache.calcite.linq4j.tree.Expression key();\n\t// Returns an expression that references the ith field of the key, cast to the appropriate type.\n\torg.apache.calcite.linq4j.tree.Expression keyField(int i);\n}", "des": "Implementation of AggResultContext."}
{"index": 4423, "repo": "calcite-core-1.34.0", "code": "Class ArraySqlType {\n\t// Generates a string representation of this type.\n\tprotected void generateTypeString(StringBuilder sb, boolean withDetail);\n\t// Gets the component type if this type is a collection, otherwise null.\n\tRelDataType getComponentType();\n\t// Gets a canonical object representing the family of this type.\n\tRelDataTypeFamily getFamily();\n\t// Returns the precedence list for this type.\n\tRelDataTypePrecedenceList getPrecedenceList();\n}", "des": "SQL array type."}
{"index": 4424, "repo": "calcite-core-1.34.0", "code": "Class AssignableOperandTypeChecker {\n\t// Checks the types of all operands to an operator call.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Returns a string describing the allowed formal signatures of a call, e.g.\n\tString getAllowedSignatures(SqlOperator op, String opName);\n\t// Returns the range of operand counts allowed in a call.\n\tSqlOperandCountRange getOperandCountRange();\n}", "des": "AssignableOperandTypeChecker implements SqlOperandTypeChecker by verifying that the type of each argument is assignable to a predefined set of parameter types (under the SQL definition of \"assignable\")."}
{"index": 4425, "repo": "calcite-core-1.34.0", "code": "Class Bindables.BindableProjectRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\tRelNode convert(RelNode rel);\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n}", "des": "Rule to convert a LogicalProject to a Bindables.BindableProject."}
{"index": 4426, "repo": "calcite-core-1.34.0", "code": "Class BiRel {\n\t// Interacts with the RelVisitor in a visitor pattern to traverse the tree of relational expressions.\n\tvoid childrenAccept(RelVisitor visitor);\n\t// Describes the inputs and attributes of this relational expression.\n\tRelWriter explainTerms(RelWriter pw);\n\t// Returns an array of this relational expression's inputs.\n\tList<RelNode> getInputs();\n\tRelNode getLeft();\n\tRelNode getRight();\n\t// Replaces the ordinalInParentth input.\n\tvoid replaceInput(int ordinalInParent, RelNode p);\n}", "des": "Abstract base class for relational expressions with a two inputs."}
{"index": 4427, "repo": "calcite-core-1.34.0", "code": "Class Bug {\n\t// Use this method to flag temporary code.\n\tstatic <T> T remark(T remark);\n\t// Use this method to flag code that should be re-visited after upgrading a component.\n\tstatic boolean upgrade(String remark);\n}", "des": "Holder for a list of constants describing which bugs which have not been fixed."}
{"index": 4428, "repo": "calcite-core-1.34.0", "code": "Interface BuiltInMetadata.Parallelism {\n\t// Returns whether each physical operator implementing this relational expression belongs to a different process than its inputs.\n\tBoolean isPhaseTransition();\n\t// Returns the number of distinct splits of the data.\n\tInteger splitCount();\n}", "des": "Metadata about the degree of parallelism of a relational expression, and how its operators are assigned to processes with independent resource pools."}
{"index": 4429, "repo": "calcite-core-1.34.0", "code": "Interface BuiltInMetadata.Size {\n\t// Determines the average size (in bytes) of a value of a column in this relational expression.\n\tList<Double> averageColumnSizes();\n\t// Determines the average size (in bytes) of a row from this relational expression.\n\t@Nullable Double averageRowSize();\n}", "des": "Metadata about the size of rows and columns."}
{"index": 4430, "repo": "calcite-core-1.34.0", "code": "Enum BuiltInMethod {\n\tString getMethodName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BuiltInMethod valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BuiltInMethod[] values();\n}", "des": "Built-in methods."}
{"index": 4431, "repo": "calcite-core-1.34.0", "code": "Interface CalciteConnection {\n\tCalciteConnectionConfig config();\n\t// Creates a context for preparing a statement for execution.\n\tCalcitePrepare.Context createPrepareContext();\n\t// Returns an instance of the connection properties.\n\tProperties getProperties();\n\t// Returns the root schema.\n\tSchemaPlus getRootSchema();\n\tString getSchema();\n\t// Returns the type factory.\n\tJavaTypeFactory getTypeFactory();\n\tvoid setSchema(String schema);\n}", "des": "Extension to Calcite's implementation of JDBC connection allows schemas to be defined dynamically."}
{"index": 4432, "repo": "calcite-core-1.34.0", "code": "Interface CalciteServerStatement {\n\t// Creates a context for preparing a statement for execution.\n\tCalcitePrepare.Context createPrepareContext();\n\t// Returns the connection.\n\tCalciteConnection getConnection();\n\t@Nullable Iterator<Object> getResultSet();\n\torg.apache.calcite.avatica.Meta.Signature getSignature();\n\tvoid setResultSet(Iterator<Object> resultSet);\n\tvoid setSignature(org.apache.calcite.avatica.Meta.Signature signature);\n}", "des": "Statement within a Calcite server."}
{"index": 4433, "repo": "calcite-core-1.34.0", "code": "Class CalcRelSplitter {\n\t// Returns whether a relational expression can be implemented solely in a given CalcRelSplitter.RelType.\n\tprotected boolean canImplement(LogicalCalc rel, String relTypeName);\n\t// Returns a list of sets of expressions that should be on the same level.\n\tprotected List<Set<Integer>> getCohorts();\n\t// Opportunity to further refine the relational expression created for a given level.\n\tprotected RelNode handle(RelNode rel);\n}", "des": "CalcRelSplitter operates on a Calc with multiple RexCall sub-expressions that cannot all be implemented by a single concrete RelNode."}
{"index": 4434, "repo": "calcite-core-1.34.0", "code": "Class CancelFlag {\n\t// Clears any pending cancellation request.\n\tvoid clearCancel();\n\t// Returns whether a cancellation has been requested.\n\tboolean isCancelRequested();\n\t// Requests a cancellation.\n\tvoid requestCancel();\n}", "des": "CancelFlag is used to post and check cancellation requests."}
{"index": 4435, "repo": "calcite-core-1.34.0", "code": "Class ChainedRelMetadataProvider {\n\tboolean equals(@Nullable Object obj);\n\t// Retrieves a list of MetadataHandler for implements a particular MetadataHandler.class.\n\tList<MetadataHandler<?>> handlers(Class<? extends MetadataHandler<?>> handlerClass);\n\t// Creates a chain.\n\tstatic RelMetadataProvider of(List<RelMetadataProvider> list);\n}", "des": "Implementation of the RelMetadataProvider interface via the Glossary.CHAIN_OF_RESPONSIBILITY_PATTERN."}
{"index": 4436, "repo": "calcite-core-1.34.0", "code": "Class ChainedSqlOperatorTable {\n\t// Retrieves a list of all functions and operators in this table.\n\tList<SqlOperator> getOperatorList();\n\t// Retrieves a list of operators with a given name and syntax.\n\tvoid lookupOperatorOverloads(SqlIdentifier opName, @Nullable SqlFunctionCategory category, SqlSyntax syntax, List<SqlOperator> operatorList, SqlNameMatcher nameMatcher);\n}", "des": "ChainedSqlOperatorTable implements the SqlOperatorTable interface by chaining together any number of underlying operator table instances."}
{"index": 4437, "repo": "calcite-core-1.34.0", "code": "Enum CharLiteralStyle {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CharLiteralStyle valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CharLiteralStyle[] values();\n}", "des": "Styles of character literal."}
{"index": 4438, "repo": "calcite-core-1.34.0", "code": "Class CoerceInputsRule {\n\t// Returns the convention of the result of firing this rule, null if not known.\n\t@Nullable Convention getOutConvention();\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "CoerceInputsRule pre-casts inputs to a particular type. This can be used to assist operator implementations which impose requirements on their input types."}
{"index": 4439, "repo": "calcite-core-1.34.0", "code": "Enum ColumnStrategy {\n\t// Returns whether you can insert into the column.\n\tboolean canInsertInto();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ColumnStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ColumnStrategy[] values();\n}", "des": "Describes how a column gets populated."}
{"index": 4440, "repo": "calcite-core-1.34.0", "code": "Interface Compatible {\n\t// Same behavior as ImmutableMap.copyOf(java.util.Map<? extends K, ? extends V>), available from Guava 19.0.\n\tstatic <K,V> com.google.common.collect.ImmutableMap<K,V> copyOf(Iterable<? extends Map.Entry<? extends K,? extends V>> entries);\n\t// Same as MethodHandles#privateLookupIn().\n\t<T> MethodHandles.Lookup lookupPrivate(Class<T> clazz);\n}", "des": "Compatibility layer."}
{"index": 4441, "repo": "calcite-core-1.34.0", "code": "Enum CompositeHintPredicate.Composition {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompositeHintPredicate.Composition valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompositeHintPredicate.Composition[] values();\n}", "des": "How hint predicates are composed."}
{"index": 4442, "repo": "calcite-core-1.34.0", "code": "Enum CompositeOperandTypeChecker.Composition {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompositeOperandTypeChecker.Composition valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompositeOperandTypeChecker.Composition[] values();\n}", "des": "How operands are composed."}
{"index": 4443, "repo": "calcite-core-1.34.0", "code": "Class Contexts {\n\t// Returns a context that wraps a list of contexts.\n\tstatic Context chain(Context... contexts);\n\t// Returns a context that returns null for all inquiries.\n\tstatic Context empty();\n\t// Returns a context that wraps an array of objects, ignoring any nulls.\n\tstatic Context of(Object... os);\n\t// Returns a context that wraps an object.\n\tstatic Context of(Object o);\n}", "des": "Utilities for Context."}
{"index": 4444, "repo": "calcite-core-1.34.0", "code": "Class ConversionUtil {\n\t// Converts a string into a BOOLEAN.\n\tstatic @Nullable Boolean toBoolean(@Nullable String str);\n\t// Converts a string into a byte array.\n\tstatic byte[] toByteArrayFromString(String value, int radix);\n\t// Converts an approximate value into a string, following the SQL 2003 standard.\n\tstatic String toStringFromApprox(double d, boolean isFloat);\n\t// Converts a byte array into a bit string or a hex string.\n\tstatic String toStringFromByteArray(byte[] value, int radix);\n}", "des": "Utility functions for converting from one type to another."}
{"index": 4445, "repo": "calcite-core-1.34.0", "code": "Interface Converter {\n\t// Returns the sole input relational expression.\n\tRelNode getInput();\n\t// Returns the trait of the input relational expression.\n\tRelTraitSet getInputTraits();\n\t// Returns the definition of trait which this converter works on.\n\t@Nullable RelTraitDef getTraitDef();\n}", "des": "A relational expression implements the interface Converter to indicate that it converts a physical attribute, or trait, of a relational expression from one value to another."}
{"index": 4446, "repo": "calcite-core-1.34.0", "code": "Class ConverterImpl {\n\t// Returns the cost of this plan (not including children).\n\t@Nullable RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq);\n\t// Returns the trait of the input relational expression.\n\tRelTraitSet getInputTraits();\n\t// Returns the definition of trait which this converter works on.\n\t@Nullable RelTraitDef getTraitDef();\n}", "des": "Abstract implementation of Converter."}
{"index": 4447, "repo": "calcite-core-1.34.0", "code": "Class CorrelationId {\n\tint compareTo(CorrelationId other);\n\tboolean equals(@Nullable Object obj);\n\t// Returns the identifier.\n\tint getId();\n\t// Returns the preferred name of the variable.\n\tString getName();\n\t// Converts a set of names to a set of correlation ids.\n\tstatic Set<String> names(Set<CorrelationId> set);\n\t// Converts a set of correlation ids to a set of names.\n\tstatic com.google.common.collect.ImmutableSet<CorrelationId> setOf(Set<String> set);\n}", "des": "Describes the necessary parameters for an implementation in order to identify and set dynamic variables."}
{"index": 4448, "repo": "calcite-core-1.34.0", "code": "Interface DataContext {\n\t// Returns a context variable.\n\t@Nullable Object get(String name);\n\t// Returns the query provider.\n\torg.apache.calcite.linq4j.QueryProvider getQueryProvider();\n\t// Returns a sub-schema with a given name, or null.\n\t@Nullable SchemaPlus getRootSchema();\n\t// Returns the type factory.\n\tJavaTypeFactory getTypeFactory();\n}", "des": "Runtime context allowing access to the tables in a database."}
{"index": 4449, "repo": "calcite-core-1.34.0", "code": "Enum DataContext.Variable {\n\t// Returns the value of this variable in a given data context.\n\t<T> T get(DataContext dataContext);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DataContext.Variable valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DataContext.Variable[] values();\n}", "des": "Variable that may be asked for in a call to DataContext.get(java.lang.String)."}
{"index": 4450, "repo": "calcite-core-1.34.0", "code": "Class DataContexts {\n\t// Returns an instance of DataContext with the given connection and root schema but no variables.\n\tstatic DataContext of(CalciteConnection connection, @Nullable SchemaPlus rootSchema);\n\t// Returns an instance of DataContext with the given function.\n\tstatic DataContext of(Function<String,? extends Object> fn);\n\t// Returns an instance of DataContext with the given map.\n\tstatic DataContext of(Map<String,?> map);\n}", "des": "Utilities for DataContext."}
{"index": 4451, "repo": "calcite-core-1.34.0", "code": "Class DateString {\n\tint compareTo(DateString o);\n\tboolean equals(@Nullable Object o);\n\t// Creates a DateString from a Calendar.\n\tstatic DateString fromCalendarFields(Calendar calendar);\n\t// Creates a DateString that is a given number of days since the epoch.\n\tstatic DateString fromDaysSinceEpoch(int days);\n\t// Returns the number of days since the epoch.\n\tint getDaysSinceEpoch();\n\t// Returns the number of milliseconds since the epoch.\n\tlong getMillisSinceEpoch();\n\tCalendar toCalendar();\n}", "des": "Date literal."}
{"index": 4452, "repo": "calcite-core-1.34.0", "code": "Class DateTimeStringUtils {\n\t// Create a SimpleDateFormat with format string with default time zone UTC.\n\tstatic SimpleDateFormat getDateFormatter(String format);\n\t// Create a SimpleDateFormat with format string and time zone.\n\tstatic SimpleDateFormat getDateFormatter(String format, TimeZone timeZone);\n}", "des": "Utility methods to manipulate String representation of DateTime values."}
{"index": 4453, "repo": "calcite-core-1.34.0", "code": "Class DdlExecutorImpl {\n\t// Template for methods that execute DDL commands.\n\tvoid execute(SqlNode node, CalcitePrepare.Context context);\n\t// Executes a DDL statement.\n\tvoid executeDdl(CalcitePrepare.Context context, SqlNode node);\n}", "des": "Abstract implementation of DdlExecutor."}
{"index": 4454, "repo": "calcite-core-1.34.0", "code": "Class DelegatingSqlValidatorTable {\n\t// Returns the access type of the table.\n\tSqlAccessType getAllowedAccess();\n\t// Returns whether a given column is monotonic.\n\tSqlMonotonicity getMonotonicity(String columnName);\n\tList<String> getQualifiedName();\n\tRelDataType getRowType();\n}", "des": "Implements SqlValidatorTable by delegating to a parent table."}
{"index": 4455, "repo": "calcite-core-1.34.0", "code": "Class DepthFirstIterator<V,E extends DefaultEdge> {\n\tboolean hasNext();\n\tV next();\n\t// Creates an iterable over the vertices in the given graph in a depth-first iteration order.\n\tstatic <V,E extends DefaultEdge>Iterable<V> of(DirectedGraph<V,E> graph, V start);\n\t// Populates a collection with the nodes reachable from a given node.\n\tstatic <V,E extends DefaultEdge>void reachable(Collection<V> list, DirectedGraph<V,E> graph, V start);\n\tvoid remove();\n}", "des": "Iterates over the vertices in a directed graph in depth-first order."}
{"index": 4456, "repo": "calcite-core-1.34.0", "code": "Enum DeriveMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DeriveMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DeriveMode[] values();\n}", "des": "The mode of trait derivation."}
{"index": 4457, "repo": "calcite-core-1.34.0", "code": "Class DynamicRecordType {\n\t// Returns true if the column name starts with DYNAMIC_STAR_PREFIX.\n\tstatic boolean isDynamicStarColName(String name);\n\t// Returns whether this type has dynamic structure (for \"schema-on-read\" table).\n\tboolean isDynamicStruct();\n}", "des": "Specific type of RelRecordType that corresponds to a dynamic table, where columns are created as they are requested."}
{"index": 4458, "repo": "calcite-core-1.34.0", "code": "Class EnumerableAggregate {\n\t// Creates a copy of this aggregate.\n\tEnumerableAggregate copy(RelTraitSet traitSet, RelNode input, ImmutableBitSet groupSet, @Nullable List<ImmutableBitSet> groupSets, List<AggregateCall> aggCalls);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of Aggregate in enumerable calling convention."}
{"index": 4459, "repo": "calcite-core-1.34.0", "code": "Class EnumerableBatchNestedLoopJoinRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Rule to convert a LogicalJoin to an EnumerableBatchNestedLoopJoin. You may provide a custom config to convert other nodes that extend Join."}
{"index": 4460, "repo": "calcite-core-1.34.0", "code": "Interface EnumerableBatchNestedLoopJoinRule.Config {\n\t// Batch size.\n\tdefault int batchSize();\n\t// Creates a rule that uses this configuration.\n\tdefault EnumerableBatchNestedLoopJoinRule toRule();\n\t// Sets batchSize().\n\tEnumerableBatchNestedLoopJoinRule.Config withBatchSize(int batchSize);\n}", "des": "Rule configuration."}
{"index": 4461, "repo": "calcite-core-1.34.0", "code": "Class EnumerableCollect {\n\tEnumerableCollect copy(RelTraitSet traitSet, RelNode newInput);\n\t// Creates an EnumerableCollect.\n\tstatic Collect create(RelNode input, RelDataType rowType);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of Collect in enumerable calling convention."}
{"index": 4462, "repo": "calcite-core-1.34.0", "code": "Class EnumerableInterpretable {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tEnumerableInterpretable copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates an interpreter node to implement this relational expression.\n\tNode implement(InterpretableRel.InterpreterImplementor implementor);\n\tstatic Bindable toBindable(Map<String,Object> parameters, CalcitePrepare.SparkHandler spark, EnumerableRel rel, EnumerableRel.Prefer prefer);\n}", "des": "Relational expression that converts an enumerable input to interpretable calling convention."}
{"index": 4463, "repo": "calcite-core-1.34.0", "code": "Class EnumerableLimitSort {\n\tEnumerableLimitSort copy(RelTraitSet traitSet, RelNode newInput, RelCollation newCollation, @Nullable RexNode offset, @Nullable RexNode fetch);\n\t// Creates an EnumerableLimitSort.\n\tstatic EnumerableLimitSort create(RelNode input, RelCollation collation, @Nullable RexNode offset, @Nullable RexNode fetch);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of Sort in enumerable calling convention. It optimizes sorts that have a limit and an optional offset."}
{"index": 4464, "repo": "calcite-core-1.34.0", "code": "Class EnumerableMergeUnionRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Rule to convert a LogicalSort on top of a LogicalUnion into a EnumerableMergeUnion."}
{"index": 4465, "repo": "calcite-core-1.34.0", "code": "Enum EnumerableRel.Prefer {\n\tEnumerableRel.Prefer of(JavaRowFormat format);\n\tJavaRowFormat prefer(JavaRowFormat format);\n\tJavaRowFormat preferArray();\n\tJavaRowFormat preferCustom();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EnumerableRel.Prefer valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EnumerableRel.Prefer[] values();\n}", "des": "Preferred physical type."}
{"index": 4466, "repo": "calcite-core-1.34.0", "code": "Class EnumerableRepeatUnion {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tEnumerableRepeatUnion copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of RepeatUnion in enumerable calling convention."}
{"index": 4467, "repo": "calcite-core-1.34.0", "code": "Class EnumerableSort {\n\tEnumerableSort copy(RelTraitSet traitSet, RelNode newInput, RelCollation newCollation, @Nullable RexNode offset, @Nullable RexNode fetch);\n\t// Creates an EnumerableSort.\n\tstatic EnumerableSort create(RelNode child, RelCollation collation, @Nullable RexNode offset, @Nullable RexNode fetch);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of Sort in enumerable calling convention."}
{"index": 4468, "repo": "calcite-core-1.34.0", "code": "Class EnumerableTableFunctionScan {\n\t// Copies this relational expression, substituting traits and inputs.\n\tEnumerableTableFunctionScan copy(RelTraitSet traitSet, List<RelNode> inputs, RexNode rexCall, @Nullable Type elementType, RelDataType rowType, @Nullable Set<RelColumnMapping> columnMappings);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of TableFunctionScan in enumerable calling convention."}
{"index": 4469, "repo": "calcite-core-1.34.0", "code": "Class EnumerableTableModify {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of TableModify in enumerable calling convention."}
{"index": 4470, "repo": "calcite-core-1.34.0", "code": "Class EnumerableTableSpool {\n\tprotected Spool copy(RelTraitSet traitSet, RelNode input, Spool.Type readType, Spool.Type writeType);\n\t// Creates an EnumerableTableSpool.\n\tstatic EnumerableTableSpool create(RelNode input, Spool.Type readType, Spool.Type writeType, RelOptTable table);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of TableSpool in enumerable calling convention that writes into a ModifiableTable (which must exist in the current schema)."}
{"index": 4471, "repo": "calcite-core-1.34.0", "code": "Class EnumerableUncollect {\n\tEnumerableUncollect copy(RelTraitSet traitSet, RelNode newInput);\n\t// Creates an EnumerableUncollect.\n\tstatic EnumerableUncollect create(RelTraitSet traitSet, RelNode input, boolean withOrdinality);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of Uncollect in enumerable calling convention."}
{"index": 4472, "repo": "calcite-core-1.34.0", "code": "Class EnumerableWindow {\n\t// Returns the cost of this plan (not including children).\n\t@Nullable RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq);\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Implementation of Window in enumerable calling convention."}
{"index": 4473, "repo": "calcite-core-1.34.0", "code": "Class ExchangeRemoveConstantKeysRule {\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n\t// Removes constant in distribution keys.\n\tprotected static List<Integer> simplifyDistributionKeys(RelDistribution distribution, Set<Integer> constants);\n}", "des": "Planner rule that removes keys from a Exchange if those keys are known to be constant."}
{"index": 4474, "repo": "calcite-core-1.34.0", "code": "Class ExplicitOperandTypeChecker {\n\t// Checks the types of all operands to an operator call.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Returns a string describing the allowed formal signatures of a call, e.g.\n\tString getAllowedSignatures(SqlOperator op, String opName);\n\t// Returns the range of operand counts allowed in a call.\n\tSqlOperandCountRange getOperandCountRange();\n}", "des": "Parameter type-checking strategy for Explicit Type."}
{"index": 4475, "repo": "calcite-core-1.34.0", "code": "Class ExplicitOperatorBinding {\n\t// Returns the number of bound operands.\n\tint getOperandCount();\n\t// Gets the type of a bound operand.\n\tRelDataType getOperandType(int ordinal);\n\t// Determines whether a bound operand is NULL.\n\tboolean isOperandNull(int ordinal, boolean allowCast);\n\t// Wraps a validation error with context appropriate to this operator call.\n\tCalciteException newError(org.apache.calcite.runtime.Resources.ExInst<SqlValidatorException> e);\n}", "des": "ExplicitOperatorBinding implements SqlOperatorBinding via an underlying array of known operand types."}
{"index": 4476, "repo": "calcite-core-1.34.0", "code": "Interface ExtensibleTable {\n\t// Returns a table that has the row type of this table plus the given fields.\n\tTable extend(List<RelDataTypeField> fields);\n\t// Returns the starting offset of the first extended column, which may differ from the field count when the table stores metadata columns that are not counted in the row-type field count.\n\tint getExtendedColumnOffset();\n}", "des": "Table whose row type can be extended to include extra fields."}
{"index": 4477, "repo": "calcite-core-1.34.0", "code": "Interface FilterCalcMergeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault FilterCalcMergeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault FilterCalcMergeRule.Config withOperandFor(Class<? extends Filter> filterClass, Class<? extends Calc> calcClass);\n}", "des": "Rule configuration."}
{"index": 4478, "repo": "calcite-core-1.34.0", "code": "Interface FilterCorrelateRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault FilterCorrelateRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault FilterCorrelateRule.Config withOperandFor(Class<? extends Filter> filterClass, Class<? extends Correlate> correlateClass);\n}", "des": "Rule configuration."}
{"index": 4479, "repo": "calcite-core-1.34.0", "code": "Class FilterFlattenCorrelatedConditionRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Planner rule that matches a Filter expression with correlated variables, and rewrites the condition in a simpler form that is more convenient for the decorrelation logic."}
{"index": 4480, "repo": "calcite-core-1.34.0", "code": "Class FilterJoinRule<C extends FilterJoinRule.Config> {\n\t// Infers more equal conditions for the join condition.\n\tprotected List<RexNode> inferJoinEqualConditions(List<RexNode> rexNodes, Join join);\n\tprotected void perform(RelOptRuleCall call, @Nullable Filter filter, Join join);\n\t// Validates that target execution framework can satisfy join filters.\n\tprotected void validateJoinFilters(List<RexNode> aboveFilters, List<RexNode> joinFilters, Join join, JoinRelType joinType);\n}", "des": "Planner rule that pushes filters above and within a join node into the join node and/or its children nodes."}
{"index": 4481, "repo": "calcite-core-1.34.0", "code": "Interface FilterJoinRule.Config {\n\t// Predicate that returns whether a filter is valid in the ON clause of a join for this particular kind of join.\n\tFilterJoinRule.Predicate getPredicate();\n\t// Whether to try to strengthen join-type, default false.\n\tdefault boolean isSmart();\n\t// Sets getPredicate() ()}.\n\tFilterJoinRule.Config withPredicate(FilterJoinRule.Predicate predicate);\n\t// Sets isSmart().\n\tFilterJoinRule.Config withSmart(boolean smart);\n}", "des": "Rule configuration."}
{"index": 4482, "repo": "calcite-core-1.34.0", "code": "Interface FilterMergeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault FilterMergeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault FilterMergeRule.Config withOperandFor(Class<? extends Filter> filterClass);\n}", "des": "Rule configuration."}
{"index": 4483, "repo": "calcite-core-1.34.0", "code": "Interface FilterMultiJoinMergeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault FilterMultiJoinMergeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault FilterMultiJoinMergeRule.Config withOperandFor(Class<? extends Filter> filterClass, Class<? extends MultiJoin> multiJoinClass);\n}", "des": "Rule configuration."}
{"index": 4484, "repo": "calcite-core-1.34.0", "code": "Interface FormatElement {\n\t// Applies a consumer to a format element.\n\tdefault void flatten(Consumer<FormatElement> consumer);\n\t// Formats a date to its appropriate string representation for the element.\n\tString format(Date date);\n\t// Returns the description of an element.\n\tString getDescription();\n}", "des": "A format element in a format string. Knows how to parse and unparse itself."}
{"index": 4485, "repo": "calcite-core-1.34.0", "code": "Enum FormatElementEnum {\n\t// Returns the description of an element.\n\tString getDescription();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FormatElementEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FormatElementEnum[] values();\n}", "des": "Implementation of FormatElement containing the standard format elements. These are based on Oracle's format model documentation."}
{"index": 4486, "repo": "calcite-core-1.34.0", "code": "Interface FormatModel {\n\t// Returns the map used to create the FormatModel instance.\n\tMap<String,FormatElement> getElementMap();\n\t// Parses a format string using element identifiers supplied by format.\n\tList<FormatElement> parse(String format);\n}", "des": "Describes the format strings used by a formatting function such as FORMAT_TIMESTAMP or CAST(string AS DATE FORMAT formatString)."}
{"index": 4487, "repo": "calcite-core-1.34.0", "code": "Class FormatModels {\n\t// Creates a composite format element from the provided list of elements and description.\n\tstatic FormatElement compositeElement(String description, FormatElement... fmtElements);\n\t// Creates a FormatModel that uses the provided map to identify FormatElements while parsing a format string.\n\tstatic FormatModel create(Map<String,FormatElement> elementMap);\n\t// Creates a literal format element.\n\tstatic FormatElement literalElement(String literal);\n}", "des": "Utilities for FormatModel."}
{"index": 4488, "repo": "calcite-core-1.34.0", "code": "Interface FunctionContext {\n\t// Returns the value of an argument to this function, null if the argument is the NULL literal.\n\t<V> V getArgumentValueAs(int ordinal, Class<V> valueClass);\n\t// Returns the number of parameters.\n\tint getParameterCount();\n\t// Returns the type factory.\n\tRelDataTypeFactory getTypeFactory();\n\t// Returns whether the value of an argument is constant.\n\tboolean isArgumentConstant(int ordinal);\n}", "des": "Information about a function call that is passed to the constructor of a function instance."}
{"index": 4489, "repo": "calcite-core-1.34.0", "code": "Interface FunctionParameter {\n\t// Name of the parameter.\n\tString getName();\n\t// Zero-based ordinal of this parameter within the member's parameter list.\n\tint getOrdinal();\n\t// Returns the type of this parameter.\n\tRelDataType getType(RelDataTypeFactory typeFactory);\n\t// Returns whether this parameter is optional.\n\tboolean isOptional();\n}", "des": "Parameter to a Function."}
{"index": 4490, "repo": "calcite-core-1.34.0", "code": "Class Graphs.FrozenGraph<V,E extends DefaultEdge> {\n\t// Returns an iterator of all paths between two nodes, in non-decreasing order of path lengths.\n\tList<List<V>> getPaths(V from, V to);\n\t// Returns the shortest distance between two points, -1, if there is no path.\n\tint getShortestDistance(V from, V to);\n}", "des": "Immutable grap."}
{"index": 4491, "repo": "calcite-core-1.34.0", "code": "Class GroupByScope {\n\t// Returns the root node of this scope.\n\tSqlNode getNode();\n\t// Performs any scope-specific validation of an expression.\n\tvoid validateExpr(SqlNode expr);\n}", "des": "Represents the name-resolution context for expressions in an GROUP BY clause."}
{"index": 4492, "repo": "calcite-core-1.34.0", "code": "Class H2SqlDialect {\n\t// Returns whether the dialect supports character set names as part of a data type, for instance VARCHAR(30) CHARACTER SET `ISO-8859-1`.\n\tboolean supportsCharSet();\n\t// Returns whether this dialect support the specified type of join.\n\tboolean supportsJoinType(JoinRelType joinType);\n\t// Returns whether this dialect supports window functions (OVER clause).\n\tboolean supportsWindowFunctions();\n}", "des": "A SqlDialect implementation for the H2 database."}
{"index": 4493, "repo": "calcite-core-1.34.0", "code": "Enum HepMatchOrder {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HepMatchOrder valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HepMatchOrder[] values();\n}", "des": "HepMatchOrder specifies the order of graph traversal when looking for rule matches."}
{"index": 4494, "repo": "calcite-core-1.34.0", "code": "Interface Hintable {\n\t// Attaches list of hints to this relational expression.\n\tdefault RelNode attachHints(List<RelHint> hintList);\n\t// Returns the hints of this relational expressions as an immutable list.\n\tcom.google.common.collect.ImmutableList<RelHint> getHints();\n\t// Returns a new relational expression with the specified hints hintList.\n\tdefault RelNode withHints(List<RelHint> hintList);\n}", "des": "Hintable is a kind of RelNode that can attach RelHints."}
{"index": 4495, "repo": "calcite-core-1.34.0", "code": "Class HintPredicates {\n\t// Returns a composed hint predicate that represents a short-circuiting logical AND of an array of hint predicates hintPredicates.\n\tstatic HintPredicate and(HintPredicate... hintPredicates);\n\t// Returns a composed hint predicate that represents a short-circuiting logical OR of an array of hint predicates hintPredicates.\n\tstatic HintPredicate or(HintPredicate... hintPredicates);\n}", "des": "A collection of hint predicates."}
{"index": 4496, "repo": "calcite-core-1.34.0", "code": "Class HintStrategy.Builder {\n\tHintStrategy build();\n\t// Registers an array of desired converter rules during the RelOptPlanner planning.\n\tHintStrategy.Builder converterRules(ConverterRule... rules);\n\t// Registers an array of rules to exclude during the RelOptPlanner planning.\n\tHintStrategy.Builder excludedRules(RelOptRule... rules);\n\t// Registers a hint option checker to validate the hint options.\n\tHintStrategy.Builder optionChecker(HintOptionChecker optionChecker);\n}", "des": "Builder for HintStrategy."}
{"index": 4497, "repo": "calcite-core-1.34.0", "code": "Class HintStrategyTable {\n\t// Applies this HintStrategyTable hint strategies to the given relational expression and the hints.\n\tList<RelHint> apply(List<RelHint> hints, RelNode rel);\n\t// Returns a HintStrategyTable builder.\n\tstatic HintStrategyTable.Builder builder();\n\t// Returns whether the hintable has hints that imply the given rule should be excluded.\n\tboolean isRuleExcluded(Hintable hintable, RelOptRule rule);\n\t// Checks if the given hint is valid.\n\tboolean validateHint(RelHint hint);\n}", "des": "A collection of HintStrategys."}
{"index": 4498, "repo": "calcite-core-1.34.0", "code": "Interface Hoist.Config {\n\t// Returns the configuration for the SQL parser.\n\tSqlParser.Config parserConfig();\n\t// Sets parserConfig().\n\tHoist.Config withParserConfig(SqlParser.Config parserConfig);\n}", "des": "Configuration."}
{"index": 4499, "repo": "calcite-core-1.34.0", "code": "Class Holder<E> {\n\t// Applies a transform to the value.\n\tHolder<E> accept(UnaryOperator<E> transform);\n\t// Creates a holder containing null.\n\tstatic <E> Holder<E> empty();\n\t// Gets the value.\n\tE get();\n\t// Creates a holder containing a given value.\n\tstatic <E> Holder<E> of(E e);\n\t// Sets the value.\n\tvoid set(E e);\n}", "des": "A mutable slot that can contain one object."}
{"index": 4500, "repo": "calcite-core-1.34.0", "code": "Class ImmutableNullableMap<K,V> {\n\t// Returns an immutable map containing the given elements.\n\tstatic <K,V> Map<K,V> copyOf(Map<? extends K,? extends V> map);\n\t// Returns an immutable navigable map containing the given entries.\n\tstatic <K,V> Map<K,V> copyOf(SortedMap<? extends K,? extends V> map);\n}", "des": "An immutable map that may contain null values."}
{"index": 4501, "repo": "calcite-core-1.34.0", "code": "Interface ImplicitCastOperandTypeChecker {\n\t// Checks the types of an operator's all operands, but without type coercion.\n\tboolean checkOperandTypesWithoutTypeCoercion(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Get the operand SqlTypeFamily of formal index iFormalOperand.\n\tSqlTypeFamily getOperandSqlTypeFamily(int iFormalOperand);\n}", "des": "An operand type checker that supports implicit type cast, see TypeCoercion.builtinFunctionCoercion(SqlCallBinding, List, List) for details."}
{"index": 4502, "repo": "calcite-core-1.34.0", "code": "Class InformixSqlDialect {\n\t// Returns whether the dialect supports VALUES in a sub-query with and an \"AS t(column, ...)\" values to define column names.\n\tboolean supportsAliasedValues();\n\t// Returns whether the dialect supports GROUP BY literals.\n\tboolean supportsGroupByLiteral();\n}", "des": "A SqlDialect implementation for the Informix database."}
{"index": 4503, "repo": "calcite-core-1.34.0", "code": "Interface InitializerContext {\n\t// Converts a SqlNode to RexNode.\n\tRexNode convertExpression(SqlNode expr);\n\tRexBuilder getRexBuilder();\n\t// Parses a column computation expression for a table.\n\tdefault SqlNode parseExpression(SqlParser.Config config, String expr);\n\t// Validate the expression with a base table row type.\n\tSqlNode validateExpression(RelDataType rowType, SqlNode expr);\n}", "des": "Provides context for InitializerExpressionFactory methods."}
{"index": 4504, "repo": "calcite-core-1.34.0", "code": "Class InterpretableConverter {\n\t// Executes this statement and returns an enumerable which will yield rows.\n\torg.apache.calcite.linq4j.Enumerable<Object[]> bind(DataContext dataContext);\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Gets the type of the element(s) that are returned in this collection.\n\tClass<Object[]> getElementType();\n}", "des": "Relational expression that converts any relational expression input to InterpretableConvention, by wrapping it in an interpreter."}
{"index": 4505, "repo": "calcite-core-1.34.0", "code": "Interface IntersectToDistinctRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault IntersectToDistinctRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault IntersectToDistinctRule.Config withOperandFor(Class<? extends Intersect> intersectClass);\n}", "des": "Rule configuration."}
{"index": 4506, "repo": "calcite-core-1.34.0", "code": "Class IntervalOperandTypeChecker {\n\t// Checks the type of a single operand against a particular ordinal position within a formal operator signature.\n\tboolean checkSingleOperandType(SqlCallBinding callBinding, SqlNode node, int iFormalOperand, boolean throwOnFailure);\n\t// Returns a string describing the allowed formal signatures of a call, e.g.\n\tString getAllowedSignatures(SqlOperator op, String opName);\n}", "des": "Parameter type-checking strategy whether the operand must be an interval."}
{"index": 4507, "repo": "calcite-core-1.34.0", "code": "Class JaninoCompiler.JaninoCompilerArgs {\n\tvoid setDestdir(String destdir);\n\tvoid setFullClassName(String fullClassName);\n\t// Sets the source code (that is, the full java program, generally starting with something like \"package com.foo.bar;\") and the file name.\n\tvoid setSource(String source, String fileName);\n\t// Returns whether JavaCompilerArgs.setSource(java.lang.String, java.lang.String) will work.\n\tboolean supportsSetSource();\n}", "des": "Arguments to an invocation of the Janino compiler."}
{"index": 4508, "repo": "calcite-core-1.34.0", "code": "Class JavaToSqlTypeConversionRules {\n\t// Returns the singleton instance.\n\tstatic JavaToSqlTypeConversionRules instance();\n\t// Returns a corresponding SqlTypeName for a given Java class.\n\t@Nullable SqlTypeName lookup(Class javaClass);\n}", "des": "JavaToSqlTypeConversionRules defines mappings from common Java types to corresponding SQL types."}
{"index": 4509, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules {\n\t// Creates a list of rules with the given JDBC convention instance.\n\tstatic List<RelOptRule> rules(JdbcConvention out);\n\t// Creates a list of rules with the given JDBC convention instance and builder factory.\n\tstatic List<RelOptRule> rules(JdbcConvention out, RelBuilderFactory relBuilderFactory);\n}", "des": "Rules and relational operators for JdbcConvention calling convention."}
{"index": 4510, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcAggregateRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcAggregateRule.\n\tstatic JdbcRules.JdbcAggregateRule create(JdbcConvention out);\n}", "des": "Rule to convert a Aggregate to a JdbcRules.JdbcAggregate."}
{"index": 4511, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcFilterRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcFilterRule.\n\tstatic JdbcRules.JdbcFilterRule create(JdbcConvention out);\n}", "des": "Rule to convert a Filter to an JdbcRules.JdbcFilter."}
{"index": 4512, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcIntersectRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcIntersectRule.\n\tstatic JdbcRules.JdbcIntersectRule create(JdbcConvention out);\n}", "des": "Rule to convert a Intersect to a JdbcRules.JdbcIntersect."}
{"index": 4513, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcJoinRule {\n\t// Converts a Join into a JdbcJoin.\n\t@Nullable RelNode convert(Join join, boolean convertInputTraits);\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcJoinRule.\n\tstatic JdbcRules.JdbcJoinRule create(JdbcConvention out);\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n}", "des": "Rule that converts a join to JDBC."}
{"index": 4514, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcMinusRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcMinusRule.\n\tstatic JdbcRules.JdbcMinusRule create(JdbcConvention out);\n}", "des": "Rule to convert a Minus to a JdbcRules.JdbcMinus."}
{"index": 4515, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcProject {\n\t// Returns the cost of this plan (not including children).\n\t@Nullable RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq);\n\t// Copies a project.\n\tJdbcRules.JdbcProject copy(RelTraitSet traitSet, RelNode input, List<RexNode> projects, RelDataType rowType);\n\tSqlImplementor.Result implement(JdbcImplementor implementor);\n}", "des": "Implementation of Project in jdbc calling convention."}
{"index": 4516, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcProjectRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcProjectRule.\n\tstatic JdbcRules.JdbcProjectRule create(JdbcConvention out);\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n}", "des": "Rule to convert a Project to an JdbcRules.JdbcProject."}
{"index": 4517, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcSortRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Converts a Sort into a JdbcSort.\n\tRelNode convert(Sort sort, boolean convertInputTraits);\n\t// Creates a JdbcSortRule.\n\tstatic JdbcRules.JdbcSortRule create(JdbcConvention out);\n}", "des": "Rule to convert a Sort to an JdbcRules.JdbcSort."}
{"index": 4518, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcTableModificationRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcToEnumerableConverterRule.\n\tstatic JdbcRules.JdbcTableModificationRule create(JdbcConvention out);\n}", "des": "Rule that converts a table-modification to JDBC."}
{"index": 4519, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcTableModify {\n\t// Returns the cost of this plan (not including children).\n\t@Nullable RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq);\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\tSqlImplementor.Result implement(JdbcImplementor implementor);\n}", "des": "Table-modification operator implemented in JDBC convention."}
{"index": 4520, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcUnionRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcUnionRule.\n\tstatic JdbcRules.JdbcUnionRule create(JdbcConvention out);\n}", "des": "Rule to convert an Union to a JdbcRules.JdbcUnion."}
{"index": 4521, "repo": "calcite-core-1.34.0", "code": "Class JdbcRules.JdbcValuesRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcValuesRule.\n\tstatic JdbcRules.JdbcValuesRule create(JdbcConvention out);\n}", "des": "Rule that converts a values operator to JDBC."}
{"index": 4522, "repo": "calcite-core-1.34.0", "code": "Class JdbcTableScan {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\tSqlImplementor.Result implement(JdbcImplementor implementor);\n\t// Returns a new relational expression with the specified hints hintList.\n\tRelNode withHints(List<RelHint> hintList);\n}", "des": "Relational expression representing a scan of a table in a JDBC data source."}
{"index": 4523, "repo": "calcite-core-1.34.0", "code": "Class JdbcToEnumerableConverter {\n\t// Returns the cost of this plan (not including children).\n\t@Nullable RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq);\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates a plan for this expression according to a calling convention.\n\tEnumerableRel.Result implement(EnumerableRelImplementor implementor, EnumerableRel.Prefer pref);\n}", "des": "Relational expression representing a scan of a table in a JDBC data source."}
{"index": 4524, "repo": "calcite-core-1.34.0", "code": "Class JdbcToEnumerableConverterRule {\n\t// Converts a relational expression to the target trait(s) of this rule.\n\t@Nullable RelNode convert(RelNode rel);\n\t// Creates a JdbcToEnumerableConverterRule.\n\tstatic JdbcToEnumerableConverterRule create(JdbcConvention out);\n}", "des": "Rule to convert a relational expression from JdbcConvention to EnumerableConvention."}
{"index": 4525, "repo": "calcite-core-1.34.0", "code": "Interface JoinAddRedundantSemiJoinRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault JoinAddRedundantSemiJoinRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault JoinAddRedundantSemiJoinRule.Config withOperandFor(Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4526, "repo": "calcite-core-1.34.0", "code": "Class JoinCommuteRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n\t// Returns a relational expression with the inputs switched round.\n\tstatic @Nullable RelNode swap(Join join, boolean swapOuterJoins, RelBuilder relBuilder);\n}", "des": "Planner rule that permutes the inputs to a Join."}
{"index": 4527, "repo": "calcite-core-1.34.0", "code": "Enum JoinConditionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JoinConditionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JoinConditionType[] values();\n}", "des": "Enumerates the types of condition in a join expression."}
{"index": 4528, "repo": "calcite-core-1.34.0", "code": "Interface JoinProjectTransposeRule.Config {\n\t// Whether to include outer joins, default false.\n\tdefault boolean isIncludeOuter();\n\t// Creates a rule that uses this configuration.\n\tdefault JoinProjectTransposeRule toRule();\n\t// Sets isIncludeOuter().\n\tJoinProjectTransposeRule.Config withIncludeOuter(boolean includeOuter);\n}", "des": "Rule configuration."}
{"index": 4529, "repo": "calcite-core-1.34.0", "code": "Interface JoinPushExpressionsRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault JoinPushExpressionsRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault JoinPushExpressionsRule.Config withOperandFor(Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4530, "repo": "calcite-core-1.34.0", "code": "Interface JoinPushThroughJoinRule.Config {\n\t// Whether to push on the right.\n\tdefault boolean isRight();\n\t// Creates a rule that uses this configuration.\n\tdefault JoinPushThroughJoinRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault JoinPushThroughJoinRule.Config withOperandFor(Class<? extends Join> joinClass);\n\t// Sets isRight().\n\tJoinPushThroughJoinRule.Config withRight(boolean right);\n}", "des": "Rule configuration."}
{"index": 4531, "repo": "calcite-core-1.34.0", "code": "Interface JoinPushTransitivePredicatesRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault JoinPushTransitivePredicatesRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault JoinPushTransitivePredicatesRule.Config withOperandFor(Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4532, "repo": "calcite-core-1.34.0", "code": "Class JoinToCorrelateRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Rule that converts a Join into a LogicalCorrelate, which can then be implemented using nested loops."}
{"index": 4533, "repo": "calcite-core-1.34.0", "code": "Interface JoinToCorrelateRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault JoinToCorrelateRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault JoinToCorrelateRule.Config withOperandFor(Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4534, "repo": "calcite-core-1.34.0", "code": "Class JoinToMultiJoinRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Planner rule to flatten a tree of LogicalJoins into a single MultiJoin with N inputs."}
{"index": 4535, "repo": "calcite-core-1.34.0", "code": "Interface JoinToMultiJoinRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault JoinToMultiJoinRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault JoinToMultiJoinRule.Config withOperandFor(Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4536, "repo": "calcite-core-1.34.0", "code": "Enum JoinType {\n\t// Returns whether a join of this type may generate NULL values on the left-hand side.\n\tboolean generatesNullsOnLeft();\n\t// Returns whether a join of this type may generate NULL values on the right-hand side.\n\tboolean generatesNullsOnRight();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JoinType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JoinType[] values();\n}", "des": "Enumerates the types of join."}
{"index": 4537, "repo": "calcite-core-1.34.0", "code": "Interface JoinUnionTransposeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault JoinUnionTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault JoinUnionTransposeRule.Config withOperandFor(Class<? extends Join> joinClass, Class<? extends Union> unionClass, boolean left);\n}", "des": "Rule configuration."}
{"index": 4538, "repo": "calcite-core-1.34.0", "code": "Enum JsonFunctions.JsonModifyMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JsonFunctions.JsonModifyMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JsonFunctions.JsonModifyMode[] values();\n}", "des": "Used in the JsonModify function."}
{"index": 4539, "repo": "calcite-core-1.34.0", "code": "Enum JsonFunctions.PathMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JsonFunctions.PathMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JsonFunctions.PathMode[] values();\n}", "des": "Path spec has two different modes: lax mode and strict mode. Lax mode suppresses any thrown exception and returns null, whereas strict mode throws exceptions."}
{"index": 4540, "repo": "calcite-core-1.34.0", "code": "Enum JsonSchema.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JsonSchema.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JsonSchema.Type[] values();\n}", "des": "Built-in schema types."}
{"index": 4541, "repo": "calcite-core-1.34.0", "code": "Class Lattice.Measure {\n\t// Returns the set of distinct argument ordinals.\n\tImmutableBitSet argBitSet();\n\t// Returns a list of argument ordinals.\n\tList<Integer> argOrdinals();\n\tint compareTo(Lattice.Measure measure);\n\tboolean equals(@Nullable Object obj);\n}", "des": "A measure within a Lattice."}
{"index": 4542, "repo": "calcite-core-1.34.0", "code": "Class Lattice.SqlWriter {\n\t// Re-binds this writer to a different StringBuilder.\n\tLattice.SqlWriter with(StringBuilder buf);\n\t// Writes an expression.\n\tLattice.SqlWriter write(RexNode e);\n}", "des": "The information necessary to convert a column to SQL."}
{"index": 4543, "repo": "calcite-core-1.34.0", "code": "Class LatticeSuggester {\n\t// Adds a query.\n\tList<Lattice> addQuery(RelNode r);\n\t// Returns the minimal set of lattices necessary to cover all of the queries seen.\n\tSet<Lattice> getLatticeSet();\n\t// Converts a column reference to an expression.\n\tRexNode toRex(LatticeTable table, int column);\n}", "des": "Algorithm that suggests a set of lattices."}
{"index": 4544, "repo": "calcite-core-1.34.0", "code": "Enum Lex {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Lex valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Lex[] values();\n}", "des": "Named, built-in lexical policy. A lexical policy describes how identifiers are quoted, whether they are converted to upper- or lower-case when they are read, and whether they are matched case-sensitively."}
{"index": 4545, "repo": "calcite-core-1.34.0", "code": "Class ListSqlOperatorTable {\n\tprotected static SqlFunctionCategory category(SqlOperator operator);\n\t// Retrieves a list of all functions and operators in this table.\n\tList<SqlOperator> getOperatorList();\n\t// Retrieves a list of operators with a given name and syntax.\n\tvoid lookupOperatorOverloads(SqlIdentifier opName, @Nullable SqlFunctionCategory category, SqlSyntax syntax, List<SqlOperator> operatorList, SqlNameMatcher nameMatcher);\n}", "des": "Implementation of the SqlOperatorTable interface by using a list of operators."}
{"index": 4546, "repo": "calcite-core-1.34.0", "code": "Class LiteralOperandTypeChecker {\n\t// Checks the type of a single operand against a particular ordinal position within a formal operator signature.\n\tboolean checkSingleOperandType(SqlCallBinding callBinding, SqlNode node, int iFormalOperand, boolean throwOnFailure);\n\t// Returns a string describing the allowed formal signatures of a call, e.g.\n\tString getAllowedSignatures(SqlOperator op, String opName);\n}", "des": "Parameter type-checking strategy type must be a literal (whether null is allowed is determined by the constructor). CAST(NULL as ...) is considered to be a NULL literal but not CAST(CAST(NULL as ...) AS ...)"}
{"index": 4547, "repo": "calcite-core-1.34.0", "code": "Interface Litmus {\n\t// Checks a condition.\n\tdefault boolean check(boolean condition, @Nullable String message, Object... args);\n\t// Called when test fails.\n\tboolean fail(@Nullable String message, Object... args);\n\t// Called when test succeeds.\n\tdefault boolean succeed();\n\t// Creates a Litmus that, if it fails, will use the given arguments.\n\tdefault Litmus withMessageArgs(@Nullable String message, Object... args);\n}", "des": "Callback to be called when a test for validity succeeds or fails."}
{"index": 4548, "repo": "calcite-core-1.34.0", "code": "Class LogicalDelta {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates a LogicalDelta.\n\tstatic LogicalDelta create(RelNode input);\n}", "des": "Sub-class of Delta not targeted at any particular engine or calling convention."}
{"index": 4549, "repo": "calcite-core-1.34.0", "code": "Class LogicalExchange {\n\t// Accepts a visit from a shuttle.\n\tRelNode accept(RelShuttle shuttle);\n\tExchange copy(RelTraitSet traitSet, RelNode newInput, RelDistribution newDistribution);\n\t// Creates a LogicalExchange.\n\tstatic LogicalExchange create(RelNode input, RelDistribution distribution);\n}", "des": "Sub-class of Exchange not targeted at any particular engine or calling convention."}
{"index": 4550, "repo": "calcite-core-1.34.0", "code": "Class LogicalIntersect {\n\t// Accepts a visit from a shuttle.\n\tRelNode accept(RelShuttle shuttle);\n\tLogicalIntersect copy(RelTraitSet traitSet, List<RelNode> inputs, boolean all);\n\t// Creates a LogicalIntersect.\n\tstatic LogicalIntersect create(List<RelNode> inputs, boolean all);\n\t// Returns a new relational expression with the specified hints hintList.\n\tRelNode withHints(List<RelHint> hintList);\n}", "des": "Sub-class of Intersect not targeted at any particular engine or calling convention."}
{"index": 4551, "repo": "calcite-core-1.34.0", "code": "Class LogicalMinus {\n\t// Accepts a visit from a shuttle.\n\tRelNode accept(RelShuttle shuttle);\n\tLogicalMinus copy(RelTraitSet traitSet, List<RelNode> inputs, boolean all);\n\t// Creates a LogicalMinus.\n\tstatic LogicalMinus create(List<RelNode> inputs, boolean all);\n\t// Returns a new relational expression with the specified hints hintList.\n\tRelNode withHints(List<RelHint> hintList);\n}", "des": "Sub-class of Minus not targeted at any particular engine or calling convention."}
{"index": 4552, "repo": "calcite-core-1.34.0", "code": "Class LogicalRepeatUnion {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tLogicalRepeatUnion copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates a LogicalRepeatUnion.\n\tstatic LogicalRepeatUnion create(RelNode seed, RelNode iterative, boolean all, int iterationLimit, @Nullable RelOptTable transientTable);\n\t// Creates a LogicalRepeatUnion.\n\tstatic LogicalRepeatUnion create(RelNode seed, RelNode iterative, boolean all, @Nullable RelOptTable transientTable);\n}", "des": "Sub-class of RepeatUnion not targeted at any particular engine or calling convention."}
{"index": 4553, "repo": "calcite-core-1.34.0", "code": "Class LogicalSnapshot {\n\tSnapshot copy(RelTraitSet traitSet, RelNode input, RexNode period);\n\t// Creates a LogicalSnapshot.\n\tstatic LogicalSnapshot create(RelNode input, RexNode period);\n\t// Returns a new relational expression with the specified hints hintList.\n\tRelNode withHints(List<RelHint> hintList);\n}", "des": "Sub-class of Snapshot not targeted at any particular engine or calling convention."}
{"index": 4554, "repo": "calcite-core-1.34.0", "code": "Class LogicalSort {\n\t// Accepts a visit from a shuttle.\n\tRelNode accept(RelShuttle shuttle);\n\tSort copy(RelTraitSet traitSet, RelNode newInput, RelCollation newCollation, @Nullable RexNode offset, @Nullable RexNode fetch);\n\t// Creates a LogicalSort.\n\tstatic LogicalSort create(RelNode input, RelCollation collation, @Nullable RexNode offset, @Nullable RexNode fetch);\n\t// Returns a new relational expression with the specified hints hintList.\n\tRelNode withHints(List<RelHint> hintList);\n}", "des": "Sub-class of Sort not targeted at any particular engine or calling convention."}
{"index": 4555, "repo": "calcite-core-1.34.0", "code": "Class LogicalTableScan {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Creates a LogicalTableScan.\n\tstatic LogicalTableScan create(RelOptCluster cluster, RelOptTable relOptTable, List<RelHint> hints);\n\t// Returns a new relational expression with the specified hints hintList.\n\tRelNode withHints(List<RelHint> hintList);\n}", "des": "A LogicalTableScan reads all the rows from a RelOptTable."}
{"index": 4556, "repo": "calcite-core-1.34.0", "code": "Class LogicalUnion {\n\t// Accepts a visit from a shuttle.\n\tRelNode accept(RelShuttle shuttle);\n\tLogicalUnion copy(RelTraitSet traitSet, List<RelNode> inputs, boolean all);\n\t// Creates a LogicalUnion.\n\tstatic LogicalUnion create(List<RelNode> inputs, boolean all);\n\t// Returns a new relational expression with the specified hints hintList.\n\tRelNode withHints(List<RelHint> hintList);\n}", "des": "Sub-class of Union not targeted at any particular engine or calling convention."}
{"index": 4557, "repo": "calcite-core-1.34.0", "code": "Class LoptOptimizeJoinRule {\n\t// Determines whether a join is a removable self-join.\n\tstatic boolean isRemovableSelfJoin(Join joinRel);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Planner rule that implements the heuristic planner for determining optimal join orderings."}
{"index": 4558, "repo": "calcite-core-1.34.0", "code": "Interface Mapping {\n\t// Removes all elements in the mapping.\n\tvoid clear();\n\t// Returns the mapping type.\n\tMappingType getMappingType();\n\t// Returns the number of sources.\n\tint getSourceCount();\n\t// Returns the number of targets.\n\tint getTargetCount();\n\t// Returns whether this mapping is the identity.\n\tboolean isIdentity();\n\t// Returns an iterator over the elements in this mapping.\n\tIterator<IntPair> iterator();\n\t// Returns the number of elements in the mapping.\n\tint size();\n}", "des": "A Mapping is a relationship between a source domain to target domain of integers."}
{"index": 4559, "repo": "calcite-core-1.34.0", "code": "Interface Mappings.CoreMapping {\n\t// Returns the mapping type.\n\tMappingType getMappingType();\n\t// Returns the number of elements in the mapping.\n\tint size();\n}", "des": "Core interface of all mappings."}
{"index": 4560, "repo": "calcite-core-1.34.0", "code": "Interface Mappings.FunctionMapping {\n\t// Returns the mapping type.\n\tMappingType getMappingType();\n\tint getSourceCount();\n\t// Returns the target that a source maps to.\n\tint getTarget(int source);\n\t// Returns the target that a source maps to, or -1 if it is not mapped.\n\tint getTargetOpt(int source);\n}", "des": "Mapping where every source has a target. But: A target may not have a source. May not be finite."}
{"index": 4561, "repo": "calcite-core-1.34.0", "code": "Class Mappings.OverridingSourceMapping {\n\t// Removes all elements in the mapping.\n\tvoid clear();\n\t// Returns the mapping type.\n\tMappingType getMappingType();\n\t// Returns the source that a target maps to.\n\tint getSource(int target);\n\tMapping inverse();\n\t// Returns whether this mapping is the identity.\n\tboolean isIdentity();\n\t// Returns an iterator over the elements in this mapping.\n\tIterator<IntPair> iterator();\n\t// Returns the number of elements in the mapping.\n\tint size();\n}", "des": "Source mapping that returns the same result as a parent Mappings.SourceMapping except for specific overriding elements."}
{"index": 4562, "repo": "calcite-core-1.34.0", "code": "Interface Mappings.SourceMapping {\n\t// Returns the mapping type.\n\tMappingType getMappingType();\n\t// Returns the source that a target maps to.\n\tint getSource(int target);\n\tint getSourceCount();\n\t// Returns the source that a target maps to, or -1 if it is not mapped.\n\tint getSourceOpt(int target);\n\tint getTargetCount();\n\t// Returns the target that a source maps to, or -1 if it is not mapped.\n\tint getTargetOpt(int source);\n\tMapping inverse();\n\tboolean isIdentity();\n}", "des": "Mapping suitable for sourcing columns."}
{"index": 4563, "repo": "calcite-core-1.34.0", "code": "Interface Mappings.TargetMapping {\n\tint getSourceCount();\n\t// Returns the source that a target maps to, or -1 if it is not mapped.\n\tint getSourceOpt(int target);\n\t// Returns the target that a source maps to.\n\tint getTarget(int source);\n\tint getTargetCount();\n\t// Returns the target that a source maps to, or -1 if it is not mapped.\n\tint getTargetOpt(int source);\n\tMapping inverse();\n\tvoid set(int source, int target);\n}", "des": "Mapping suitable for mapping columns to a target."}
{"index": 4564, "repo": "calcite-core-1.34.0", "code": "Class MapSqlType {\n\t// Generates a string representation of this type.\n\tprotected void generateTypeString(StringBuilder sb, boolean withDetail);\n\t// Gets a canonical object representing the family of this type.\n\tRelDataTypeFamily getFamily();\n\t// Gets the key type if this type is a map, otherwise null.\n\tRelDataType getKeyType();\n\t// Gets the value type if this type is a map, otherwise null.\n\tRelDataType getValueType();\n}", "des": "SQL map type."}
{"index": 4565, "repo": "calcite-core-1.34.0", "code": "Interface MaterializedViewFilterScanRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault MaterializedViewFilterScanRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault MaterializedViewFilterScanRule.Config withOperandFor(Class<? extends Filter> filterClass, Class<? extends TableScan> scanClass);\n}", "des": "Rule configuration."}
{"index": 4566, "repo": "calcite-core-1.34.0", "code": "Enum MaterializedViewRule.MatchModality {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MaterializedViewRule.MatchModality valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MaterializedViewRule.MatchModality[] values();\n}", "des": "Complete, view partial, or query partial."}
{"index": 4567, "repo": "calcite-core-1.34.0", "code": "Class MaterializedViewTable {\n\t// Table macro that returns a materialized view.\n\tstatic MaterializedViewTable.MaterializedViewTableMacro create(CalciteSchema schema, String viewSql, @Nullable List<String> viewSchemaPath, List<String> viewPath, @Nullable String suggestedTableName, boolean existing);\n\t// Converts this table into a relational expression.\n\tRelNode toRel(RelOptTable.ToRelContext context, RelOptTable relOptTable);\n}", "des": "Table that is a materialized view."}
{"index": 4568, "repo": "calcite-core-1.34.0", "code": "Interface Member {\n\t// Evaluates this member to yield a result.\n\torg.apache.calcite.linq4j.Queryable evaluate(Object schemaInstance, List<Object> arguments);\n\t// The name of this function.\n\tString getName();\n\t// Returns the parameters of this member.\n\tList<FunctionParameter> getParameters();\n\t// Returns the type of this function's result.\n\tRelDataType getType();\n}", "des": "A named expression in a schema. Examples of members"}
{"index": 4569, "repo": "calcite-core-1.34.0", "code": "Interface MetadataHandlerProvider {\n\t// Provide a handler for the requested metadata class.\n\t<MH extends MetadataHandler<?>>MH handler(Class<MH> handlerClass);\n\t// Revise the handler for a given kind of metadata.\n\tdefault <MH extends MetadataHandler<?>>MH revise(Class<MH> handlerClass);\n}", "des": "Provides MetadataHandler call sites for RelMetadataQuery. The handlers provided are responsible for updating the cache stored in RelMetadataQuery."}
{"index": 4570, "repo": "calcite-core-1.34.0", "code": "Enum ModelHandler.ExtraOperand {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ModelHandler.ExtraOperand valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ModelHandler.ExtraOperand[] values();\n}", "des": "Extra operands automatically injected into a JsonCustomSchema.operand, as extra context for the adapter."}
{"index": 4571, "repo": "calcite-core-1.34.0", "code": "Interface ModifiableTable {\n\t// Returns the modifiable collection.\n\t@Nullable Collection getModifiableCollection();\n\t// Creates a relational expression that modifies this table.\n\tTableModify toModificationRel(RelOptCluster cluster, RelOptTable table, Prepare.CatalogReader catalogReader, RelNode child, TableModify.Operation operation, @Nullable List<String> updateColumnList, @Nullable List<RexNode> sourceExpressionList, boolean flattened);\n}", "des": "A table that can be modified."}
{"index": 4572, "repo": "calcite-core-1.34.0", "code": "Interface ModifiableView {\n\t// Returns the column mapping onto another table.\n\tImmutableIntList getColumnMapping();\n\t// Returns a constraint that each candidate row must satisfy.\n\tRexNode getConstraint(RexBuilder rexBuilder, RelDataType tableRowType);\n\t// Returns the underlying table.\n\tTable getTable();\n\t// Returns the full path of the underlying table.\n\tPath getTablePath();\n}", "des": "A modifiable view onto ModifiableTable."}
{"index": 4573, "repo": "calcite-core-1.34.0", "code": "Class MultisetOperandTypeChecker {\n\t// Checks the types of all operands to an operator call.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Returns a string describing the allowed formal signatures of a call, e.g.\n\tString getAllowedSignatures(SqlOperator op, String opName);\n\t// Returns the range of operand counts allowed in a call.\n\tSqlOperandCountRange getOperandCountRange();\n}", "des": "Parameter type-checking strategy where types must be ([nullable] Multiset, [nullable] Multiset), and the two types must have the same element type."}
{"index": 4574, "repo": "calcite-core-1.34.0", "code": "Class MultisetSqlType {\n\t// Generates a string representation of this type.\n\tprotected void generateTypeString(StringBuilder sb, boolean withDetail);\n\t// Gets the component type if this type is a collection, otherwise null.\n\tRelDataType getComponentType();\n\t// Gets a canonical object representing the family of this type.\n\tRelDataTypeFamily getFamily();\n\t// Returns the precedence list for this type.\n\tRelDataTypePrecedenceList getPrecedenceList();\n}", "des": "MultisetSqlType represents a standard SQL2003 multiset type."}
{"index": 4575, "repo": "calcite-core-1.34.0", "code": "Interface NestedBlockBuilder {\n\t// Returns the current code block.\n\torg.apache.calcite.linq4j.tree.BlockBuilder currentBlock();\n\t// Leaves the current code block.\n\tvoid exitBlock();\n\t// Starts nested code block.\n\torg.apache.calcite.linq4j.tree.BlockBuilder nestBlock();\n\t// Uses given block as the new code context.\n\tvoid nestBlock(org.apache.calcite.linq4j.tree.BlockBuilder block);\n}", "des": "Allows to build nested code blocks with tracking of current context."}
{"index": 4576, "repo": "calcite-core-1.34.0", "code": "Class NestedBlockBuilderImpl {\n\t// Returns the current code block.\n\torg.apache.calcite.linq4j.tree.BlockBuilder currentBlock();\n\t// Leaves the current code block.\n\tvoid exitBlock();\n\t// Starts nested code block.\n\torg.apache.calcite.linq4j.tree.BlockBuilder nestBlock();\n\t// Uses given block as the new code context.\n\tvoid nestBlock(org.apache.calcite.linq4j.tree.BlockBuilder block);\n}", "des": "Allows to build nested code blocks with tracking of current context."}
{"index": 4577, "repo": "calcite-core-1.34.0", "code": "Enum NullPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NullPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NullPolicy[] values();\n}", "des": "Describes when a function/operator will return null."}
{"index": 4578, "repo": "calcite-core-1.34.0", "code": "Enum NullSentinel {\n\tstatic Comparable mask(@Nullable Comparable value);\n\tstatic Object mask(@Nullable Object value);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NullSentinel valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NullSentinel[] values();\n}", "des": "Placeholder for null values."}
{"index": 4579, "repo": "calcite-core-1.34.0", "code": "Class OperandMetadataImpl {\n\t// Returns whether the list of parameters is fixed-length.\n\tboolean isFixedParameters();\n\t// Returns the names of the parameters.\n\tList<String> paramNames();\n\t// Returns the types of the parameters.\n\tList<RelDataType> paramTypes(RelDataTypeFactory typeFactory);\n}", "des": "Operand type-checking strategy user-defined functions (including user-defined aggregate functions, table functions, and table macros)."}
{"index": 4580, "repo": "calcite-core-1.34.0", "code": "Enum Optionality {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Optionality valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Optionality[] values();\n}", "des": "Four states that describe whether a particular behavior or property is allowed and/or not allowed."}
{"index": 4581, "repo": "calcite-core-1.34.0", "code": "Class OverScope {\n\t// Returns whether an expression is monotonic in this scope.\n\tSqlMonotonicity getMonotonicity(SqlNode expr);\n\t// Returns the root node of this scope.\n\tSqlNode getNode();\n}", "des": "The name-resolution scope of a OVER clause. The objects visible are those in the parameters found on the left side of the over clause, and objects inherited from the parent scope."}
{"index": 4582, "repo": "calcite-core-1.34.0", "code": "Interface Path {\n\t// Returns the names of this path, not including the name of the root.\n\tList<String> names();\n\t// Returns the parent path, or null if the path is empty.\n\tPath parent();\n\t// Returns the schemas of this path.\n\tList<Schema> schemas();\n}", "des": "Path from a root schema to a particular object (schema, table, function)."}
{"index": 4583, "repo": "calcite-core-1.34.0", "code": "Enum Pattern.Op {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Pattern.Op valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Pattern.Op[] values();\n}", "des": "Operator that constructs composite Pattern instances."}
{"index": 4584, "repo": "calcite-core-1.34.0", "code": "Enum PigRelBuilder.GroupOption {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PigRelBuilder.GroupOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PigRelBuilder.GroupOption[] values();\n}", "des": "Option for performing group efficiently if data set is already sorted."}
{"index": 4585, "repo": "calcite-core-1.34.0", "code": "Class PivotScope {\n\t// By analogy with ListScope.getChildren(), but this scope only has one namespace, and it is anonymous.\n\tSqlValidatorNamespace getChild();\n\t// Returns the root node of this scope.\n\tSqlPivot getNode();\n}", "des": "Scope for expressions in a PIVOT clause."}
{"index": 4586, "repo": "calcite-core-1.34.0", "code": "Enum PrecedenceClimbingParser.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PrecedenceClimbingParser.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PrecedenceClimbingParser.Type[] values();\n}", "des": "Token type."}
{"index": 4587, "repo": "calcite-core-1.34.0", "code": "Interface Prepare.CatalogReader {\n\t// Finds a table or schema with the given name, possibly qualified.\n\t@Nullable Prepare.PreparingTable getTable(List<String> names);\n\t// Retrieves a RelOptTable based upon a member access.\n\t@Nullable Prepare.PreparingTable getTableForMember(List<String> names);\n\t// Returns a catalog reader the same as this one but with a possibly different schema path.\n\tPrepare.CatalogReader withSchemaPath(List<String> schemaPath);\n}", "des": "Interface by which validator and planner can read table metadata."}
{"index": 4588, "repo": "calcite-core-1.34.0", "code": "Interface ProjectCalcMergeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault ProjectCalcMergeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault ProjectCalcMergeRule.Config withOperandFor(Class<? extends Project> projectClass, Class<? extends Calc> calcClass);\n}", "des": "Rule configuration."}
{"index": 4589, "repo": "calcite-core-1.34.0", "code": "Interface ProjectJoinJoinRemoveRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault ProjectJoinJoinRemoveRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault ProjectJoinJoinRemoveRule.Config withOperandFor(Class<? extends Project> projectClass, Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4590, "repo": "calcite-core-1.34.0", "code": "Interface ProjectJoinRemoveRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault ProjectJoinRemoveRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault ProjectJoinRemoveRule.Config withOperandFor(Class<? extends Project> projectClass, Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4591, "repo": "calcite-core-1.34.0", "code": "Class ProjectMergeRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "ProjectMergeRule merges a Project into another Project, provided the projects aren't projecting identical sets of input references."}
{"index": 4592, "repo": "calcite-core-1.34.0", "code": "Interface ProjectMultiJoinMergeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault ProjectMultiJoinMergeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault ProjectMultiJoinMergeRule.Config withOperandFor(Class<? extends Project> projectClass, Class<MultiJoin> multiJoinClass);\n}", "des": "Rule configuration."}
{"index": 4593, "repo": "calcite-core-1.34.0", "code": "Class ProjectRemoveRule {\n\t// Whether the planner should automatically prune old node when there is at least 1 equivalent rel generated by the rule.\n\tboolean autoPruneOld();\n\tstatic boolean isTrivial(Project project);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n\t// Returns the child of a project if the project is trivial, otherwise the project itself.\n\tstatic RelNode strip(Project project);\n}", "des": "Planner rule that, given a Project node that merely returns its input, converts the node into its child."}
{"index": 4594, "repo": "calcite-core-1.34.0", "code": "Interface ProjectSetOpTransposeRule.Config {\n\t// Defines when an expression should not be pushed.\n\tPushProjector.ExprCondition preserveExprCondition();\n\t// Creates a rule that uses this configuration.\n\tdefault ProjectSetOpTransposeRule toRule();\n\t// Sets preserveExprCondition().\n\tProjectSetOpTransposeRule.Config withPreserveExprCondition(PushProjector.ExprCondition condition);\n}", "des": "Rule configuration."}
{"index": 4595, "repo": "calcite-core-1.34.0", "code": "Interface ProjectWindowTransposeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault ProjectWindowTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault ProjectWindowTransposeRule.Config withOperandFor(Class<? extends Project> projectClass, Class<? extends Window> windowClass);\n}", "des": "Rule configuration."}
{"index": 4596, "repo": "calcite-core-1.34.0", "code": "Interface PruneEmptyRules.RemoveEmptySingleRule.RemoveEmptySingleRuleConfig {\n\t// Creates a rule that uses this configuration.\n\tdefault PruneEmptyRules.RemoveEmptySingleRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault <R extends RelNode>PruneEmptyRules.RemoveEmptySingleRule.RemoveEmptySingleRuleConfig withOperandFor(Class<R> relClass, Predicate<R> predicate);\n}", "des": "Rule configuration."}
{"index": 4597, "repo": "calcite-core-1.34.0", "code": "Class RandomFunction {\n\t// Implements the RAND() SQL function.\n\tdouble rand();\n\t// Implements the RAND_INTEGER(bound) SQL function.\n\tint randInteger(int bound);\n\t// Implements the RAND_INTEGER(seed, bound) SQL function.\n\tint randIntegerSeed(int seed, int bound);\n\t// Implements the RAND(seed) SQL function.\n\tdouble randSeed(int seed);\n}", "des": "Function object for RAND and RAND_INTEGER, with and without seed."}
{"index": 4598, "repo": "calcite-core-1.34.0", "code": "Class ReduceDecimalsRule {\n\t// Returns the convention of the result of firing this rule, null if not known.\n\t@Nullable Convention getOutConvention();\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Rule that reduces decimal operations (such as casts or arithmetic) into operations involving more primitive types (such as longs and doubles). The rule allows Calcite implementations to deal with decimals in a consistent manner, while saving the effort of implementing them."}
{"index": 4599, "repo": "calcite-core-1.34.0", "code": "Class ReduceExpressionsRule.CalcReduceExpressionsRule {\n\t// For static schema systems, a filter that is always false or null can be replaced by a values operator that produces no rows, as the schema information can just be taken from the input Rel.\n\tprotected RelNode createEmptyRelOrEquivalent(RelOptRuleCall call, Calc input);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Rule that reduces constants inside a Calc."}
{"index": 4600, "repo": "calcite-core-1.34.0", "code": "Class ReduceExpressionsRule.FilterReduceExpressionsRule {\n\t// For static schema systems, a filter that is always false or null can be replaced by a values operator that produces no rows, as the schema information can just be taken from the input Rel.\n\tprotected RelNode createEmptyRelOrEquivalent(RelOptRuleCall call, Filter input);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Rule that reduces constants inside a Filter. If the condition is a constant, the filter is removed (if TRUE) or replaced with an empty Values (if FALSE or NULL)."}
{"index": 4601, "repo": "calcite-core-1.34.0", "code": "Class ReflectiveConvertletTable {\n\t// Registers that one operator is an alias for another.\n\tprotected void addAlias(SqlOperator alias, SqlOperator target);\n\t// Returns the convertlet applicable to a given expression.\n\t@Nullable SqlRexConvertlet get(SqlCall call);\n\t// Registers a convertlet for a given operator instance.\n\tprotected void registerOp(SqlOperator op, SqlRexConvertlet convertlet);\n}", "des": "Implementation of SqlRexConvertletTable which uses reflection to call any method of the form public RexNode convertXxx(ConvertletContext, SqlNode) or public RexNode convertXxx(ConvertletContext, SqlOperator, SqlCall)."}
{"index": 4602, "repo": "calcite-core-1.34.0", "code": "Class ReflectiveFunctionBase {\n\t// Creates a ParameterListBuilder.\n\tstatic ReflectiveFunctionBase.ParameterListBuilder builder();\n\t// Returns the parameters of this function.\n\tList<FunctionParameter> getParameters();\n}", "des": "Implementation of a function that is based on a method. This class mainly solves conversion of method parameter types to List form."}
{"index": 4603, "repo": "calcite-core-1.34.0", "code": "Class ReflectiveSchema {\n\t// Returns a multi-map of functions in this schema by name.\n\tprotected com.google.common.collect.Multimap<String,Function> getFunctionMultimap();\n\t// Returns a map of tables in this schema by name.\n\tprotected Map<String,Table> getTableMap();\n\t// Returns the wrapped object.\n\tObject getTarget();\n}", "des": "Implementation of Schema that exposes the public fields and methods in a Java object."}
{"index": 4604, "repo": "calcite-core-1.34.0", "code": "Interface RelBuilder.GroupKey {\n\t// Assigns an alias to this group key.\n\tRelBuilder.GroupKey alias(@Nullable String alias);\n\t// Returns the number of columns in the group key.\n\tint groupKeyCount();\n}", "des": "Information necessary to create the GROUP BY clause of an Aggregate."}
{"index": 4605, "repo": "calcite-core-1.34.0", "code": "Interface RelCollation {\n\t// Returns the ordinals and directions of the columns in this ordering.\n\tList<RelFieldCollation> getFieldCollations();\n\t// Returns the ordinals of the key columns.\n\tdefault ImmutableIntList getKeys();\n}", "des": "Description of the physical ordering of a relational expression."}
{"index": 4606, "repo": "calcite-core-1.34.0", "code": "Class RelColumnOrigin {\n\tboolean equals(@Nullable Object obj);\n\t// Returns the 0-based index of column in origin table; whether this ordinal is flattened or unflattened depends on whether UDT flattening has already been performed on the relational expression which produced this description.\n\tint getOriginColumnOrdinal();\n\t// Returns table of origin.\n\tRelOptTable getOriginTable();\n\t// Consider the query select a+b as c, d as e from t.\n\tboolean isDerived();\n}", "des": "RelColumnOrigin is a data structure describing one of the origins of an output column produced by a relational expression."}
{"index": 4607, "repo": "calcite-core-1.34.0", "code": "Class RelCrossType {\n\t// Generates a string representation of this type.\n\tprotected void generateTypeString(StringBuilder sb, boolean withDetail);\n\t// Returns the contained types.\n\tList<RelDataType> getTypes();\n\t// Queries whether this is a structured type.\n\tboolean isStruct();\n}", "des": "Type of the cartesian product of two or more sets of records."}
{"index": 4608, "repo": "calcite-core-1.34.0", "code": "Enum RelDataTypeComparability {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RelDataTypeComparability valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RelDataTypeComparability[] values();\n}", "des": "RelDataTypeComparability is an enumeration of the categories of comparison operators which types may support."}
{"index": 4609, "repo": "calcite-core-1.34.0", "code": "Interface RelDataTypeField {\n\t// Gets the ordinal of this field within its containing type.\n\tint getIndex();\n\t// Gets the name of this field, which is unique within its containing type.\n\tString getName();\n\t// Gets the type of this field.\n\tRelDataType getType();\n\t// Returns true if this is a dynamic star field.\n\tboolean isDynamicStar();\n}", "des": "RelDataTypeField represents the definition of a field in a structured RelDataType."}
{"index": 4610, "repo": "calcite-core-1.34.0", "code": "Class RelDataTypeFieldImpl {\n\tboolean equals(@Nullable Object obj);\n\t// Gets the ordinal of this field within its containing type.\n\tint getIndex();\n\tString getKey();\n\t// Gets the name of this field, which is unique within its containing type.\n\tString getName();\n\t// Gets the type of this field.\n\tRelDataType getType();\n\tRelDataType getValue();\n\t// Returns true if this is a dynamic star field.\n\tboolean isDynamicStar();\n\tRelDataType setValue(RelDataType value);\n}", "des": "Default implementation of RelDataTypeField."}
{"index": 4611, "repo": "calcite-core-1.34.0", "code": "Interface RelDataTypePrecedenceList {\n\t// Compares the precedence of two types.\n\tint compareTypePrecedence(RelDataType type1, RelDataType type2);\n\t// Determines whether a type appears in this precedence list.\n\tboolean containsType(RelDataType type);\n}", "des": "RelDataTypePrecedenceList defines a type precedence list for a particular type."}
{"index": 4612, "repo": "calcite-core-1.34.0", "code": "Interface RelDecorrelator.AdjustProjectForCountAggregateRule.AdjustProjectForCountAggregateRuleConfig {\n\t// Returns the flavor of the rule (true for 4 operands, false for 3 operands).\n\tboolean flavor();\n\t// Creates a rule that uses this configuration.\n\tdefault RelDecorrelator.AdjustProjectForCountAggregateRule toRule();\n\t// Sets flavor().\n\tRelDecorrelator.AdjustProjectForCountAggregateRule.AdjustProjectForCountAggregateRuleConfig withFlavor(boolean flavor);\n}", "des": "Rule configuration."}
{"index": 4613, "repo": "calcite-core-1.34.0", "code": "Interface RelDecorrelator.Config {\n\t// Returns the RelDecorrelator that will be context for the created rule instance.\n\tRelDecorrelator decorrelator();\n\t// Sets decorrelator().\n\tRelDecorrelator.Config withDecorrelator(RelDecorrelator decorrelator);\n}", "des": "Base configuration for rules that are non-static in a RelDecorrelator."}
{"index": 4614, "repo": "calcite-core-1.34.0", "code": "Class RelDecorrelator.CorelMapBuilder {\n\t// Creates a CorelMap by iterating over a RelNode tree.\n\tRelDecorrelator.CorelMap build(RelNode... rels);\n\tRelNode visit(RelNode other);\n\t// Visits a particular child of a parent.\n\tprotected RelNode visitChild(RelNode parent, int i, RelNode input);\n}", "des": "Builds a RelDecorrelator.CorelMap."}
{"index": 4615, "repo": "calcite-core-1.34.0", "code": "Interface RelDigest {\n\t// Reset state, possibly cache of hash code.\n\tvoid clear();\n\t// Returns the relnode that this digest is associated with.\n\tRelNode getRel();\n}", "des": "The digest is the exact representation of the corresponding RelNode, at anytime, anywhere. The only difference is that digest is compared using #equals and #hashCode, which are prohibited to override for RelNode, for legacy reasons."}
{"index": 4616, "repo": "calcite-core-1.34.0", "code": "Interface RelDistribution {\n\t// Applies mapping to this distribution trait.\n\tRelDistribution apply(Mappings.TargetMapping mapping);\n\t// Returns the ordinals of the key columns.\n\tList<Integer> getKeys();\n\t// Returns the type of distribution.\n\tRelDistribution.Type getType();\n}", "des": "Description of the physical distribution of a relational expression."}
{"index": 4617, "repo": "calcite-core-1.34.0", "code": "Enum RelDistribution.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RelDistribution.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RelDistribution.Type[] values();\n}", "des": "Type of distribution."}
{"index": 4618, "repo": "calcite-core-1.34.0", "code": "Class RelDistributions {\n\t// Creates a hash distribution.\n\tstatic RelDistribution hash(Collection<? extends Number> numbers);\n\tstatic RelDistribution of(RelDistribution.Type type, ImmutableIntList keys);\n\t// Creates a range distribution.\n\tstatic RelDistribution range(Collection<? extends Number> numbers);\n}", "des": "Utilities concerning RelDistribution."}
{"index": 4619, "repo": "calcite-core-1.34.0", "code": "Interface RelDotWriter.WriteOption {\n\t// The max length of node labels.\n\tdefault int maxNodeLabelLength();\n\t// The max length of node label in a line.\n\tdefault int maxNodeLabelPerLine();\n\t// Predicate for nodes that need to be highlighted.\n\t@Nullable Predicate<RelNode> nodePredicate();\n}", "des": "Options for displaying the rel node plan in dot format."}
{"index": 4620, "repo": "calcite-core-1.34.0", "code": "Class RelEnumTypes {\n\t// Converts an enum into its name.\n\tstatic String fromEnum(Enum enumValue);\n\t// Converts a literal into a value that can be serialized to JSON.\n\tstatic @Nullable Object fromEnum(@Nullable Object value);\n}", "des": "Registry of Enum classes that can be serialized to JSON."}
{"index": 4621, "repo": "calcite-core-1.34.0", "code": "Enum RelFieldCollation.NullDirection {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RelFieldCollation.NullDirection valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RelFieldCollation.NullDirection[] values();\n}", "des": "Ordering of nulls."}
{"index": 4622, "repo": "calcite-core-1.34.0", "code": "Class RelHint {\n\t// Creates a hint builder with specified hint name.\n\tstatic RelHint.Builder builder(String hintName);\n\t// Returns a copy of this hint with specified inherit path.\n\tRelHint copy(List<Integer> inheritPath);\n\tboolean equals(@Nullable Object o);\n}", "des": "Hint attached to a relation expression."}
{"index": 4623, "repo": "calcite-core-1.34.0", "code": "Class RelMetadataQueryBase {\n\t// Removes cached metadata values for specified RelNode.\n\tboolean clearCache(RelNode rel);\n\t// Provide a handler for the requested metadata class.\n\tprotected <MH extends MetadataHandler<?>>MH handler(Class<MH> handlerClass);\n\t// Re-generates the handler for a given kind of metadata, adding support for class_ if it is not already present.\n\tprotected <H extends MetadataHandler<?>>H revise(Class<H> def);\n}", "des": "Base class for the RelMetadataQuery that uses the metadata handler class generated by the Janino."}
{"index": 4624, "repo": "calcite-core-1.34.0", "code": "Interface RelOptCostFactory {\n\t// Creates a cost object.\n\tRelOptCost makeCost(double rowCount, double cpu, double io);\n\t// Creates a cost object representing an enormous non-infinite cost.\n\tRelOptCost makeHugeCost();\n\t// Creates a cost object representing infinite cost.\n\tRelOptCost makeInfiniteCost();\n\t// Creates a cost object representing a small positive cost.\n\tRelOptCost makeTinyCost();\n\t// Creates a cost object representing zero cost.\n\tRelOptCost makeZeroCost();\n}", "des": "Cost model for query planning."}
{"index": 4625, "repo": "calcite-core-1.34.0", "code": "Class RelOptLattice {\n\t// Retrieves a materialized table that will satisfy an aggregate query on the star table.\n\t@Nullable Pair<CalciteSchema.TableEntry,TileKey> getAggregate(RelOptPlanner planner, ImmutableBitSet groupSet, List<Lattice.Measure> measureList);\n\t// Rewrites a relational expression to use a lattice.\n\t@Nullable RelNode rewrite(RelNode node);\n\tRelOptTable rootTable();\n}", "des": "Use of a lattice by the query optimizer."}
{"index": 4626, "repo": "calcite-core-1.34.0", "code": "Class RelOptMaterialization {\n\t// Converts a relational expression to a form where LogicalJoins are as close to leaves as possible.\n\tstatic RelNode toLeafJoinForm(RelNode rel);\n\t// Converts a relational expression to one that uses a StarTable.\n\tstatic @Nullable RelNode tryUseStar(RelNode rel, RelOptTable starRelOptTable);\n}", "des": "Records that a particular query is materialized by a particular table."}
{"index": 4627, "repo": "calcite-core-1.34.0", "code": "Class RelOptQuery {\n\t// Returns the relational expression which populates a correlating variable.\n\t@Nullable RelNode lookupCorrel(String name);\n\t// Maps a correlating variable to a RelNode.\n\tvoid mapCorrel(String name, RelNode rel);\n}", "des": "A RelOptQuery represents a set of relational expressions which derive from the same select statement."}
{"index": 4628, "repo": "calcite-core-1.34.0", "code": "Enum RelOptRuleOperandChildPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RelOptRuleOperandChildPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RelOptRuleOperandChildPolicy[] values();\n}", "des": "Policy by which operands will be matched by relational expressions with any number of children."}
{"index": 4629, "repo": "calcite-core-1.34.0", "code": "Class RelOptSamplingParameters {\n\t// If isRepeatable() returns true, this method returns a user-specified seed value.\n\tint getRepeatableSeed();\n\t// Returns the sampling percentage.\n\tfloat getSamplingPercentage();\n\t// Indicates whether Bernoulli or system sampling should be performed.\n\tboolean isBernoulli();\n\t// Indicates whether the sample results should be repeatable.\n\tboolean isRepeatable();\n}", "des": "RelOptSamplingParameters represents the parameters necessary to produce a sample of a relation."}
{"index": 4630, "repo": "calcite-core-1.34.0", "code": "Interface RelOptSchema {\n\t// Retrieves a RelOptTable based upon a member access.\n\t@Nullable RelOptTable getTableForMember(List<String> names);\n\t// Returns the type factory used to generate types for this schema.\n\tRelDataTypeFactory getTypeFactory();\n\t// Registers all of the rules supported by this schema.\n\tvoid registerRules(RelOptPlanner planner);\n}", "des": "A RelOptSchema is a set of RelOptTable objects."}
{"index": 4631, "repo": "calcite-core-1.34.0", "code": "Enum RelOptUtil.Logic {\n\tRelOptUtil.Logic negate();\n\t// Variant of negate() to be used within LogicVisitor, where FALSE values may exist.\n\tRelOptUtil.Logic negate2();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RelOptUtil.Logic valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RelOptUtil.Logic[] values();\n}", "des": "Policies for handling two- and three-valued boolean logic."}
{"index": 4632, "repo": "calcite-core-1.34.0", "code": "Enum RelOptUtil.SubQueryType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RelOptUtil.SubQueryType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RelOptUtil.SubQueryType[] values();\n}", "des": "What kind of sub-query."}
{"index": 4633, "repo": "calcite-core-1.34.0", "code": "Interface RelReferentialConstraint {\n\t// The (source, target) column ordinals.\n\tList<IntPair> getColumnPairs();\n\t// The qualified name of the referencing table, e.g.\n\tList<String> getSourceQualifiedName();\n\t// The qualified name of the referenced table, e.g.\n\tList<String> getTargetQualifiedName();\n}", "des": "Interface for a referential constraint, i.e., Foreign-Key - Unique-Key relationship, between two tables."}
{"index": 4634, "repo": "calcite-core-1.34.0", "code": "Class RelReferentialConstraintImpl {\n\t// The (source, target) column ordinals.\n\tList<IntPair> getColumnPairs();\n\t// The qualified name of the referencing table, e.g.\n\tList<String> getSourceQualifiedName();\n\t// The qualified name of the referenced table, e.g.\n\tList<String> getTargetQualifiedName();\n\tstatic RelReferentialConstraintImpl of(List<String> sourceQualifiedName, List<String> targetQualifiedName, List<IntPair> columnPairs);\n}", "des": "RelOptReferentialConstraint base implementation."}
{"index": 4635, "repo": "calcite-core-1.34.0", "code": "Interface RelRule.OperandBuilder {\n\t// Supplies an operand that has been built manually.\n\tRelRule.Done exactly(RelOptRuleOperand operand);\n\t// Starts building an operand by specifying its class.\n\t<R extends RelNode>RelRule.OperandDetailBuilder<R> operand(Class<R> relClass);\n}", "des": "Callback to create an operand."}
{"index": 4636, "repo": "calcite-core-1.34.0", "code": "Class RelToSqlConverterUtil {\n\t// Creates regex pattern based on the TRIM flag.\n\tstatic SqlCharStringLiteral createRegexPatternLiteral(SqlNode call, SqlLiteral trimFlag);\n\t// Returns a SqlSpecialOperator with given operator name, mainly used for unparse override.\n\tstatic SqlSpecialOperator specialOperatorByName(String opName);\n\t// For usage of TRIM, LTRIM and RTRIM in Hive, see Hive UDF usage.\n\tstatic void unparseHiveTrim(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "Utilities used by multiple dialect for RelToSql conversion."}
{"index": 4637, "repo": "calcite-core-1.34.0", "code": "Class RelVisitor {\n\t// Starts an iteration.\n\t@Nullable RelNode go(RelNode p);\n\t// Replaces the root node of this traversal.\n\tvoid replaceRoot(@Nullable RelNode node);\n\t// Visits a node during a traversal.\n\tvoid visit(RelNode node, int ordinal, @Nullable RelNode parent);\n}", "des": "A RelVisitor is a Visitor role in the visitor pattern and visits RelNode objects as the role of Element. Other components in the pattern: RelNode.childrenAccept(RelVisitor)."}
{"index": 4638, "repo": "calcite-core-1.34.0", "code": "Class RepeatUnion {\n\tprotected RelDataType deriveRowType();\n\t// Returns an estimate of the number of rows this relational expression will return.\n\tdouble estimateRowCount(RelMetadataQuery mq);\n\t// Describes the inputs and attributes of this relational expression.\n\tRelWriter explainTerms(RelWriter pw);\n\tRelNode getIterativeRel();\n\tRelNode getSeedRel();\n\t@Nullable RelOptTable getTransientTable();\n}", "des": "Relational expression that computes a repeat union (recursive union in SQL terminology)."}
{"index": 4639, "repo": "calcite-core-1.34.0", "code": "Class RexChecker {\n\t// Returns the number of failures encountered.\n\tint getFailureCount();\n\t// Returns whether an expression is valid.\n\tboolean isValid(RexNode expr);\n\tBoolean visitCall(RexCall call);\n\tBoolean visitCorrelVariable(RexCorrelVariable v);\n\tBoolean visitFieldAccess(RexFieldAccess fieldAccess);\n\tBoolean visitInputRef(RexInputRef ref);\n\tBoolean visitLocalRef(RexLocalRef ref);\n}", "des": "Visitor which checks the validity of a RexNode expression."}
{"index": 4640, "repo": "calcite-core-1.34.0", "code": "Class RexCorrelVariable {\n\t// Accepts a visitor with a payload, dispatching to the right overloaded RexBiVisitor.visitInputRef(RexInputRef, Object) visitXxx} method.\n\t<R,P> R accept(RexBiVisitor<R,P> visitor, P arg);\n\t// Accepts a visitor, dispatching to the right overloaded visitXxx method.\n\t<R> R accept(RexVisitor<R> visitor);\n\tboolean equals(@Nullable Object obj);\n\t// Returns the kind of node this is.\n\tSqlKind getKind();\n}", "des": "Reference to the current row of a correlating relational expression."}
{"index": 4641, "repo": "calcite-core-1.34.0", "code": "Enum RexDigestIncludeType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RexDigestIncludeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RexDigestIncludeType[] values();\n}", "des": "Defines if type information should be printed for RexLiteral."}
{"index": 4642, "repo": "calcite-core-1.34.0", "code": "Class RexDynamicParam {\n\t// Accepts a visitor with a payload, dispatching to the right overloaded RexBiVisitor.visitInputRef(RexInputRef, Object) visitXxx} method.\n\t<R,P> R accept(RexBiVisitor<R,P> visitor, P arg);\n\t// Accepts a visitor, dispatching to the right overloaded visitXxx method.\n\t<R> R accept(RexVisitor<R> visitor);\n\tboolean equals(@Nullable Object obj);\n\tint getIndex();\n\t// Returns the kind of node this is.\n\tSqlKind getKind();\n}", "des": "Dynamic parameter reference in a row-expression."}
{"index": 4643, "repo": "calcite-core-1.34.0", "code": "Class RexExecutorImpl {\n\t// Creates an RexExecutable that allows to apply the generated code during query processing (filter, projection).\n\tstatic RexExecutable getExecutable(RexBuilder rexBuilder, List<RexNode> exps, RelDataType rowType);\n\t// Do constant reduction using generated code.\n\tvoid reduce(RexBuilder rexBuilder, List<RexNode> constExps, List<RexNode> reducedValues);\n}", "des": "Evaluates a RexNode expression."}
{"index": 4644, "repo": "calcite-core-1.34.0", "code": "Class RexLocalRef {\n\t// Accepts a visitor with a payload, dispatching to the right overloaded RexBiVisitor.visitInputRef(RexInputRef, Object) visitXxx} method.\n\t<R,P> R accept(RexBiVisitor<R,P> visitor, P arg);\n\t// Accepts a visitor, dispatching to the right overloaded visitXxx method.\n\t<R> R accept(RexVisitor<R> visitor);\n\tboolean equals(@Nullable Object obj);\n\t// Returns the kind of node this is.\n\tSqlKind getKind();\n}", "des": "Local variable."}
{"index": 4645, "repo": "calcite-core-1.34.0", "code": "Class RexNormalize {\n\t// Computes the hashCode of a rex call.\n\tstatic int hashCode(SqlOperator operator, List<RexNode> operands);\n\t// Normalizes the variables of a rex call.\n\tstatic Pair<SqlOperator,List<RexNode>> normalize(SqlOperator operator, List<RexNode> operands);\n}", "des": "Context required to normalize a row-expression."}
{"index": 4646, "repo": "calcite-core-1.34.0", "code": "Class RexRangeRef {\n\t// Accepts a visitor with a payload, dispatching to the right overloaded RexBiVisitor.visitInputRef(RexInputRef, Object) visitXxx} method.\n\t<R,P> R accept(RexBiVisitor<R,P> visitor, P arg);\n\t// Accepts a visitor, dispatching to the right overloaded visitXxx method.\n\t<R> R accept(RexVisitor<R> visitor);\n\tboolean equals(@Nullable Object obj);\n\tint getOffset();\n\tRelDataType getType();\n}", "des": "Reference to a range of columns."}
{"index": 4647, "repo": "calcite-core-1.34.0", "code": "Class RexSqlReflectiveConvertletTable {\n\t// Returns the convertlet applicable to a given expression.\n\t@Nullable RexSqlConvertlet get(RexCall call);\n\t// Registers a convertlet for a given operator instance.\n\tprotected void registerOp(SqlOperator op, RexSqlConvertlet convertlet);\n}", "des": "Implementation of RexSqlConvertletTable."}
{"index": 4648, "repo": "calcite-core-1.34.0", "code": "Class RexSqlStandardConvertletTable {\n\t// Converts a call to an operator into a SqlCall to the same operator.\n\t@Nullable SqlNode convertCall(RexToSqlNodeConverter converter, RexCall call);\n\t// Creates and registers a convertlet for an operator in which the SQL and Rex representations are structurally equivalent.\n\tprotected void registerEquivOp(SqlOperator op);\n}", "des": "Standard implementation of RexSqlConvertletTable."}
{"index": 4649, "repo": "calcite-core-1.34.0", "code": "Interface RexToSqlNodeConverter {\n\t// Converts a RexCall to a SqlNode expression.\n\t@Nullable SqlNode convertCall(RexCall call);\n\t// Converts a RexInputRef to a SqlIdentifier.\n\t@Nullable SqlNode convertInputRef(RexInputRef ref);\n\t// Converts a RexLiteral to a SqlLiteral.\n\t@Nullable SqlNode convertLiteral(RexLiteral literal);\n\t// Converts a RexNode to a SqlNode expression, typically by dispatching to one of the other interface methods.\n\t@Nullable SqlNode convertNode(RexNode node);\n}", "des": "Converts expressions from RexNode to SqlNode."}
{"index": 4650, "repo": "calcite-core-1.34.0", "code": "Class RexToSqlNodeConverterImpl {\n\t// Converts a RexCall to a SqlNode expression.\n\t@Nullable SqlNode convertCall(RexCall call);\n\t// Converts a RexInputRef to a SqlIdentifier.\n\t@Nullable SqlNode convertInputRef(RexInputRef ref);\n\t// Converts a RexLiteral to a SqlLiteral.\n\t@Nullable SqlNode convertLiteral(RexLiteral literal);\n\t// Converts a RexNode to a SqlNode expression, typically by dispatching to one of the other interface methods.\n\t@Nullable SqlNode convertNode(RexNode node);\n}", "des": "Standard implementation of RexToSqlNodeConverter."}
{"index": 4651, "repo": "calcite-core-1.34.0", "code": "Class RexUtil.SubQueryFinder {\n\t// Returns whether a Filter contains a sub-query.\n\tstatic boolean containsSubQuery(Filter filter);\n\t// Returns whether a Join contains a sub-query.\n\tstatic boolean containsSubQuery(Join join);\n\t// Returns whether a Project contains a sub-query.\n\tstatic boolean containsSubQuery(Project project);\n\tstatic @Nullable RexSubQuery find(Iterable<RexNode> nodes);\n\tstatic @Nullable RexSubQuery find(RexNode node);\n\tVoid visitSubQuery(RexSubQuery subQuery);\n}", "des": "Visitor that throws Util.FoundOne if applied to an expression that contains a RexSubQuery."}
{"index": 4652, "repo": "calcite-core-1.34.0", "code": "Class Row.RowBuilder {\n\t// Returns a Row.\n\tRow build();\n\t// Allocates a new internal array.\n\tvoid reset();\n\t// Sets the value of a particular column.\n\tvoid set(int index, @Nullable Object value);\n\tint size();\n}", "des": "Utility class to build row objects."}
{"index": 4653, "repo": "calcite-core-1.34.0", "code": "Class RuleQueue {\n\t// Add a RuleMatch into the queue.\n\tabstract void addMatch(org.apache.calcite.plan.volcano.VolcanoRuleMatch match);\n\t// clear this rule queue.\n\tabstract boolean clear();\n\t// Returns whether to skip a match.\n\tprotected boolean skipMatch(org.apache.calcite.plan.volcano.VolcanoRuleMatch match);\n}", "des": "A data structure that manages rule matches for RuleDriver. Different RuleDriver requires different ways to pop matches, thus different ways to store rule matches that are not called."}
{"index": 4654, "repo": "calcite-core-1.34.0", "code": "Class RuleSets {\n\t// Creates a rule set with a given collection of rules.\n\tstatic RuleSet ofList(Iterable<? extends RelOptRule> rules);\n\t// Creates a rule set with a given array of rules.\n\tstatic RuleSet ofList(RelOptRule... rules);\n}", "des": "Utilities for creating and composing rule sets."}
{"index": 4655, "repo": "calcite-core-1.34.0", "code": "Class Sample {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\t// Describes the inputs and attributes of this relational expression.\n\tRelWriter explainTerms(RelWriter pw);\n\t// Retrieve the sampling parameters for this Sample.\n\tRelOptSamplingParameters getSamplingParameters();\n}", "des": "Relational expression that returns a sample of the rows from its input."}
{"index": 4656, "repo": "calcite-core-1.34.0", "code": "Enum Schema.TableType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Schema.TableType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Schema.TableType[] values();\n}", "des": "Table type."}
{"index": 4657, "repo": "calcite-core-1.34.0", "code": "Interface SemiJoinFilterTransposeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault SemiJoinFilterTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SemiJoinFilterTransposeRule.Config withOperandFor(Class<? extends Join> joinClass, Class<? extends Filter> filterClass);\n}", "des": "Rule configuration."}
{"index": 4658, "repo": "calcite-core-1.34.0", "code": "Interface SemiJoinJoinTransposeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault SemiJoinJoinTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SemiJoinJoinTransposeRule.Config withOperandFor(Class<? extends Join> joinClass, Class<? extends Join> join2Class);\n}", "des": "Rule configuration."}
{"index": 4659, "repo": "calcite-core-1.34.0", "code": "Interface SemiJoinProjectTransposeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault SemiJoinProjectTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SemiJoinProjectTransposeRule.Config withOperandFor(Class<? extends Join> joinClass, Class<? extends Project> projectClass);\n}", "des": "Rule configuration."}
{"index": 4660, "repo": "calcite-core-1.34.0", "code": "Interface SemiJoinRemoveRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault SemiJoinRemoveRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SemiJoinRemoveRule.Config withOperandFor(Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4661, "repo": "calcite-core-1.34.0", "code": "Class SemiJoinRule.JoinOnUniqueToSemiJoinRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "SemiJoinRule that matches a Project on top of a Join with a RelNode which is unique for Join's right keys."}
{"index": 4662, "repo": "calcite-core-1.34.0", "code": "Interface SemiJoinRule.JoinToSemiJoinRule.JoinToSemiJoinRuleConfig {\n\t// Creates a rule that uses this configuration.\n\tdefault SemiJoinRule.JoinToSemiJoinRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SemiJoinRule.JoinToSemiJoinRule.JoinToSemiJoinRuleConfig withOperandFor(Class<Join> joinClass, Class<Aggregate> aggregateClass);\n}", "des": "Rule configuration."}
{"index": 4663, "repo": "calcite-core-1.34.0", "code": "Interface SemiJoinRule.ProjectToSemiJoinRule.ProjectToSemiJoinRuleConfig {\n\t// Creates a rule that uses this configuration.\n\tdefault SemiJoinRule.ProjectToSemiJoinRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SemiJoinRule.ProjectToSemiJoinRule.ProjectToSemiJoinRuleConfig withOperandFor(Class<? extends Project> projectClass, Class<? extends Join> joinClass, Class<? extends Aggregate> aggregateClass);\n}", "des": "Rule configuration."}
{"index": 4664, "repo": "calcite-core-1.34.0", "code": "Class SerializableCharset {\n\t// Returns a SerializableCharset wrapping the given Charset, or null if the charset is null.\n\tstatic @PolyNull SerializableCharset forCharset(@PolyNull Charset charset);\n\t// Returns the wrapped Charset.\n\tCharset getCharset();\n}", "des": "Serializable wrapper around a Charset."}
{"index": 4665, "repo": "calcite-core-1.34.0", "code": "Class SetopOperandTypeChecker {\n\t// Checks the types of all operands to an operator call.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Returns a string describing the allowed formal signatures of a call, e.g.\n\tString getAllowedSignatures(SqlOperator op, String opName);\n\t// Returns the range of operand counts allowed in a call.\n\tSqlOperandCountRange getOperandCountRange();\n}", "des": "Parameter type-checking strategy for a set operator (UNION, INTERSECT, EXCEPT)."}
{"index": 4666, "repo": "calcite-core-1.34.0", "code": "Class SimpleProfiler {\n\t// Creates a profile of a data set.\n\tProfiler.Profile profile(Iterable<List<Comparable>> rows, List<Profiler.Column> columns, Collection<ImmutableBitSet> initialGroups);\n\t// Returns a measure of how much an actual value differs from expected.\n\tstatic double surprise(double expected, double actual);\n}", "des": "Basic implementation of Profiler."}
{"index": 4667, "repo": "calcite-core-1.34.0", "code": "Class SocketFactoryImpl {\n\t// Applies the current settings to the given socket.\n\tprotected Socket applySettings(Socket s);\n\tSocket createSocket();\n\tSocket createSocket(InetAddress host, int port);\n\tSocket createSocket(InetAddress host, int port, InetAddress local, int localPort);\n\tSocket createSocket(String host, int port);\n\tSocket createSocket(String host, int port, InetAddress local, int localPort);\n\t// Returns a copy of the environment's default socket factory.\n\tstatic SocketFactory getDefault();\n}", "des": "Extends the SocketFactory object with the main functionality being that the created sockets inherit a set of options whose values are set in the SocketFactoryImpl."}
{"index": 4668, "repo": "calcite-core-1.34.0", "code": "Class SortExchange {\n\tSortExchange copy(RelTraitSet traitSet, RelNode newInput, RelDistribution newDistribution);\n\tabstract SortExchange copy(RelTraitSet traitSet, RelNode newInput, RelDistribution newDistribution, RelCollation newCollation);\n\t// Describes the inputs and attributes of this relational expression.\n\tRelWriter explainTerms(RelWriter pw);\n\t// Returns the array of RelFieldCollations asked for by the sort specification, from most significant to least significant.\n\tRelCollation getCollation();\n}", "des": "Relational expression that performs Exchange and Sort simultaneously."}
{"index": 4669, "repo": "calcite-core-1.34.0", "code": "Interface SortJoinCopyRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault SortJoinCopyRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SortJoinCopyRule.Config withOperandFor(Class<? extends Sort> sortClass, Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4670, "repo": "calcite-core-1.34.0", "code": "Class SortJoinTransposeRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Planner rule that pushes a Sort past a Join."}
{"index": 4671, "repo": "calcite-core-1.34.0", "code": "Interface SortJoinTransposeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault SortJoinTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault SortJoinTransposeRule.Config withOperandFor(Class<? extends Sort> sortClass, Class<? extends Join> joinClass);\n}", "des": "Rule configuration."}
{"index": 4672, "repo": "calcite-core-1.34.0", "code": "Class SortUnionTransposeRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Planner rule that pushes a Sort past a Union."}
{"index": 4673, "repo": "calcite-core-1.34.0", "code": "Interface SortUnionTransposeRule.Config {\n\t// Whether to match a Sort whose Sort.fetch is null.\n\tdefault boolean matchNullFetch();\n\t// Creates a rule that uses this configuration.\n\tdefault SortUnionTransposeRule toRule();\n\t// Sets matchNullFetch().\n\tSortUnionTransposeRule.Config withMatchNullFetch(boolean matchNullFetch);\n\t// Defines an operand tree for the given classes.\n\tdefault SortUnionTransposeRule.Config withOperandFor(Class<? extends Sort> sortClass, Class<? extends Union> unionClass);\n}", "des": "Rule configuration."}
{"index": 4674, "repo": "calcite-core-1.34.0", "code": "Enum SpatialTypeUtils.SpatialType {\n\tint code();\n\t// Returns the OGC type of a geometry.\n\tstatic SpatialTypeUtils.SpatialType fromGeometry(org.locationtech.jts.geom.Geometry g);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SpatialTypeUtils.SpatialType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SpatialTypeUtils.SpatialType[] values();\n}", "des": "Geometry types, with the names and codes assigned by OGC."}
{"index": 4675, "repo": "calcite-core-1.34.0", "code": "Class Spool {\n\t// Creates a copy of this relational expression, perhaps changing traits and inputs.\n\tRelNode copy(RelTraitSet traitSet, List<RelNode> inputs);\n\tprotected abstract Spool copy(RelTraitSet traitSet, RelNode input, Spool.Type readType, Spool.Type writeType);\n\t// Describes the inputs and attributes of this relational expression.\n\tRelWriter explainTerms(RelWriter pw);\n}", "des": "Relational expression that iterates over its input and, in addition to returning its results, will forward them into other consumers."}
{"index": 4676, "repo": "calcite-core-1.34.0", "code": "Enum Spool.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Spool.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Spool.Type[] values();\n}", "des": "Enumeration representing spool read / write type."}
{"index": 4677, "repo": "calcite-core-1.34.0", "code": "Class SqlAbstractDateTimeLiteral {\n\tRelDataType createSqlType(RelDataTypeFactory typeFactory);\n\tint getPrec();\n\t// Converts this literal to a TimestampString.\n\tprotected TimestampString getTimestamp();\n\t// Returns e.g.\n\tabstract String toFormattedString();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SQL literal representing a DATE, TIME or TIMESTAMP value."}
{"index": 4678, "repo": "calcite-core-1.34.0", "code": "Class SqlAbstractGroupFunction {\n\t// Whether this aggregate function allows a FILTER (WHERE ...) clause.\n\tboolean allowsFilter();\n\t// Returns whether this function allows a DISTINCT or ALL quantifier.\n\tboolean isQuantifierAllowed();\n\t// Validates a call to this operator.\n\tvoid validateCall(SqlCall call, SqlValidator validator, SqlValidatorScope scope, SqlValidatorScope operandScope);\n}", "des": "Base class for grouping functions GROUP_ID, GROUPING_ID, GROUPING."}
{"index": 4679, "repo": "calcite-core-1.34.0", "code": "Enum SqlAccessEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlAccessEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlAccessEnum[] values();\n}", "des": "Access type."}
{"index": 4680, "repo": "calcite-core-1.34.0", "code": "Class SqlAdvisor.ValidateErrorInfo {\n\t// Returns 1-based end column number.\n\tint getEndColumnNum();\n\t// Returns 1-based end line number.\n\tint getEndLineNum();\n\t// Returns the error message.\n\t@Nullable String getMessage();\n\t// Returns 1-based starting column number.\n\tint getStartColumnNum();\n\t// Returns 1-based starting line number.\n\tint getStartLineNum();\n}", "des": "Text and position info of a validator or parser exception."}
{"index": 4681, "repo": "calcite-core-1.34.0", "code": "Class SqlAlienSystemTypeNameSpec {\n\t// Returns whether this spec is structurally equivalent to another spec.\n\tboolean equalsDeep(SqlTypeNameSpec node, Litmus litmus);\n\t// Writes a SQL representation of this spec to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Represents a type name for an alien system. For example, UNSIGNED is a built-in type in MySQL which is synonym of INTEGER."}
{"index": 4682, "repo": "calcite-core-1.34.0", "code": "Class SqlAnyValueAggFunction {\n\t// Returns whether this aggregate function allows the DISTINCT keyword.\n\tOptionality getDistinctOptionality();\n\t// Gets rollup aggregation function.\n\tSqlAggFunction getRollup();\n\t// Finds an instance of an interface implemented by this object, or returns null if this object does not support that interface.\n\t<T> T unwrap(Class<T> clazz);\n}", "des": "Definition of the ANY_VALUE aggregate functions, returning any one of the values which go into it."}
{"index": 4683, "repo": "calcite-core-1.34.0", "code": "Class SqlAttributeDefinition {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for SqlAttributeDefinition, which is part of a SqlCreateType."}
{"index": 4684, "repo": "calcite-core-1.34.0", "code": "Class SqlBaseContextVariable {\n\t// Returns whether a call to this operator is monotonic.\n\tSqlMonotonicity getMonotonicity(SqlOperatorBinding call);\n\t// Returns the syntactic type of this operator, never null.\n\tSqlSyntax getSyntax();\n\t// Returns whether it is unsafe to cache query plans referencing this operator; false is assumed by default.\n\tboolean isDynamicFunction();\n}", "des": "Base class for functions such as \"USER\", \"CURRENT_ROLE\", and \"CURRENT_PATH\"."}
{"index": 4685, "repo": "calcite-core-1.34.0", "code": "Class SqlBasicTypeNameSpec {\n\t// Derive type from this SqlTypeNameSpec.\n\tRelDataType deriveType(SqlValidator validator);\n\t// Returns whether this spec is structurally equivalent to another spec.\n\tboolean equalsDeep(SqlTypeNameSpec node, Litmus litmus);\n\t@Nullable String getCharSetName();\n\tint getPrecision();\n\tint getScale();\n\t// Writes a SQL representation of this spec to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A sql type name specification of basic sql type."}
{"index": 4686, "repo": "calcite-core-1.34.0", "code": "Class SqlBasicVisitor<R> {\n\t// Visits a call to a SqlOperator.\n\tR visit(SqlCall call);\n\t// Visits a datatype specification.\n\tR visit(SqlDataTypeSpec type);\n\t// Visits a dynamic parameter.\n\tR visit(SqlDynamicParam param);\n\t// Visits an identifier.\n\tR visit(SqlIdentifier id);\n\t// Visits an interval qualifier.\n\tR visit(SqlIntervalQualifier intervalQualifier);\n\t// Visits a literal.\n\tR visit(SqlLiteral literal);\n\t// Visits a list of SqlNode objects.\n\tR visit(SqlNodeList nodeList);\n}", "des": "Basic implementation of SqlVisitor which does nothing at each node."}
{"index": 4687, "repo": "calcite-core-1.34.0", "code": "Interface SqlBasicVisitor.ArgHandler<R> {\n\t// Returns the result of visiting all children of a call to an operator, then the call itself.\n\tR result();\n\t// Visits a particular operand of a call, using a given visitor.\n\tR visitChild(SqlVisitor<R> visitor, SqlNode expr, int i, @Nullable SqlNode operand);\n}", "des": "Argument handler."}
{"index": 4688, "repo": "calcite-core-1.34.0", "code": "Class SqlBasicVisitor.ArgHandlerImpl<R> {\n\tstatic <R> SqlBasicVisitor.ArgHandler<R> instance();\n\t// Returns the result of visiting all children of a call to an operator, then the call itself.\n\tR result();\n\t// Visits a particular operand of a call, using a given visitor.\n\tR visitChild(SqlVisitor<R> visitor, SqlNode expr, int i, @Nullable SqlNode operand);\n}", "des": "Default implementation of SqlBasicVisitor.ArgHandler which merely calls SqlNode.accept(org.apache.calcite.sql.util.SqlVisitor) on each operand."}
{"index": 4689, "repo": "calcite-core-1.34.0", "code": "Enum SqlBetweenOperator.Flag {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlBetweenOperator.Flag valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlBetweenOperator.Flag[] values();\n}", "des": "Defines the \"SYMMETRIC\" and \"ASYMMETRIC\" keywords."}
{"index": 4690, "repo": "calcite-core-1.34.0", "code": "Class SqlBinaryStringLiteral {\n\t// Clones a SqlNode with a different position.\n\tSqlBinaryStringLiteral clone(SqlParserPos pos);\n\t// Helper routine for SqlUtil.concatenateLiterals(java.util.List<org.apache.calcite.sql.SqlLiteral>).\n\tprotected org.apache.calcite.sql.SqlAbstractStringLiteral concat1(List<SqlLiteral> literals);\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A binary (or hexadecimal) string literal."}
{"index": 4691, "repo": "calcite-core-1.34.0", "code": "Class SqlBitOpAggFunction {\n\t// Returns whether this aggregate function allows the DISTINCT keyword.\n\tOptionality getDistinctOptionality();\n\t// Finds an instance of an interface implemented by this object, or returns null if this object does not support that interface.\n\t<T> T unwrap(Class<T> clazz);\n}", "des": "Definition of the BIT_AND and BIT_OR aggregate functions, returning the bitwise AND/OR of all non-null input values, or null if none."}
{"index": 4692, "repo": "calcite-core-1.34.0", "code": "Class SqlCharStringLiteral {\n\t// Clones a SqlNode with a different position.\n\tSqlCharStringLiteral clone(SqlParserPos pos);\n\t// Helper routine for SqlUtil.concatenateLiterals(java.util.List<org.apache.calcite.sql.SqlLiteral>).\n\tprotected org.apache.calcite.sql.SqlAbstractStringLiteral concat1(List<SqlLiteral> literals);\n\t// Returns the collation.\n\t@Nullable SqlCollation getCollation();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A character string literal."}
{"index": 4693, "repo": "calcite-core-1.34.0", "code": "Class SqlCheckConstraint {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for UNIQUE, PRIMARY KEY constraints."}
{"index": 4694, "repo": "calcite-core-1.34.0", "code": "Enum SqlCollation.Coercibility {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlCollation.Coercibility valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlCollation.Coercibility[] values();\n}", "des": "A consisting of a column reference has the coercibility characteristic Implicit, with collating sequence as defined when the column was created. A consisting of a value other than a column (e.g., a host variable or a literal) has the coercibility characteristic Coercible, with the default collation for its character repertoire. A simply containing a has the coercibility characteristic Explicit, with the collating sequence specified in the ."}
{"index": 4695, "repo": "calcite-core-1.34.0", "code": "Class SqlCollectionTypeNameSpec {\n\t// Derive type from this SqlTypeNameSpec.\n\tRelDataType deriveType(SqlValidator validator);\n\t// Returns whether this spec is structurally equivalent to another spec.\n\tboolean equalsDeep(SqlTypeNameSpec spec, Litmus litmus);\n\tSqlTypeNameSpec getElementTypeName();\n\t// Writes a SQL representation of this spec to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A sql type name specification of collection type."}
{"index": 4696, "repo": "calcite-core-1.34.0", "code": "Class SqlColumnDeclaration {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for UNIQUE, PRIMARY KEY constraints."}
{"index": 4697, "repo": "calcite-core-1.34.0", "code": "Class SqlConvertFunction {\n\t// Returns a template describing how the operator signature is to be built.\n\tString getSignatureTemplate(int operandsCount);\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "Common base for the CONVERT and TRANSLATE functions."}
{"index": 4698, "repo": "calcite-core-1.34.0", "code": "Class SqlCreateForeignSchema {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Returns options as a list of (name, value) pairs.\n\tList<Pair<SqlIdentifier,SqlNode>> options();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for CREATE FOREIGN SCHEMA statement."}
{"index": 4699, "repo": "calcite-core-1.34.0", "code": "Class SqlCreateFunction {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for CREATE FUNCTION statement."}
{"index": 4700, "repo": "calcite-core-1.34.0", "code": "Class SqlCreateMaterializedView {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for CREATE MATERIALIZED VIEW statement."}
{"index": 4701, "repo": "calcite-core-1.34.0", "code": "Class SqlCreateSchema {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for CREATE SCHEMA statement."}
{"index": 4702, "repo": "calcite-core-1.34.0", "code": "Class SqlCreateTable {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for CREATE TABLE statement."}
{"index": 4703, "repo": "calcite-core-1.34.0", "code": "Class SqlCreateType {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for CREATE TYPE statement."}
{"index": 4704, "repo": "calcite-core-1.34.0", "code": "Class SqlCreateView {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for CREATE VIEW statement."}
{"index": 4705, "repo": "calcite-core-1.34.0", "code": "Class SqlCurrentDateFunction {\n\t// Returns whether a call to this operator is monotonic.\n\tSqlMonotonicity getMonotonicity(SqlOperatorBinding call);\n\t// Returns the syntactic type of this operator, never null.\n\tSqlSyntax getSyntax();\n\t// Returns whether it is unsafe to cache query plans referencing this operator; false is assumed by default.\n\tboolean isDynamicFunction();\n}", "des": "The CURRENT_DATE function."}
{"index": 4706, "repo": "calcite-core-1.34.0", "code": "Class SqlDateLiteral {\n\t// Clones a SqlNode with a different position.\n\tSqlDateLiteral clone(SqlParserPos pos);\n\tRelDataType createSqlType(RelDataTypeFactory typeFactory);\n\t// Converts this literal to a DateString.\n\tprotected DateString getDate();\n\t// Returns e.g.\n\tString toFormattedString();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SQL literal representing a DATE value, such as DATE '2004-10-22'."}
{"index": 4707, "repo": "calcite-core-1.34.0", "code": "Class SqlDatetimePlusOperator {\n\t// Returns whether a call to this operator is monotonic.\n\tSqlMonotonicity getMonotonicity(SqlOperatorBinding call);\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "Operator that adds an INTERVAL to a DATETIME."}
{"index": 4708, "repo": "calcite-core-1.34.0", "code": "Class SqlDatetimeSubtractionOperator {\n\t// Returns whether a call to this operator is monotonic.\n\tSqlMonotonicity getMonotonicity(SqlOperatorBinding call);\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "A special operator for the subtraction of two DATETIMEs. The format of DATETIME subtraction is: \"(\" <datetime> \"-\" <datetime> \")\" <interval qualifier>"}
{"index": 4709, "repo": "calcite-core-1.34.0", "code": "Enum SqlDdlNodes.FileType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlDdlNodes.FileType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlDdlNodes.FileType[] values();\n}", "des": "File type for CREATE FUNCTION."}
{"index": 4710, "repo": "calcite-core-1.34.0", "code": "Class SqlDescribeSchema {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\tSqlIdentifier getSchema();\n\t// Changes the value of an operand.\n\tvoid setOperand(int i, @Nullable SqlNode operand);\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SqlDescribeSchema is a node of a parse tree that represents a DESCRIBE SCHEMA statement."}
{"index": 4711, "repo": "calcite-core-1.34.0", "code": "Class SqlDescribeTable {\n\t@Nullable SqlIdentifier getColumn();\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\tSqlIdentifier getTable();\n\t// Changes the value of an operand.\n\tvoid setOperand(int i, @Nullable SqlNode operand);\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SqlDescribeTable is a node of a parse tree that represents a DESCRIBE TABLE statement."}
{"index": 4712, "repo": "calcite-core-1.34.0", "code": "Enum SqlDialect.CalendarPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlDialect.CalendarPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlDialect.CalendarPolicy[] values();\n}", "des": "Whether this JDBC driver needs you to pass a Calendar object to methods such as ResultSet.getTimestamp(int, java.util.Calendar)."}
{"index": 4713, "repo": "calcite-core-1.34.0", "code": "Enum SqlDialect.DatabaseProduct {\n\t// Returns a dummy dialect for this database.\n\tSqlDialect getDialect();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlDialect.DatabaseProduct valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlDialect.DatabaseProduct[] values();\n}", "des": "Rough list of flavors of database."}
{"index": 4714, "repo": "calcite-core-1.34.0", "code": "Class SqlDropObject {\n\tvoid execute(CalcitePrepare.Context context);\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Base class for parse trees of DROP TABLE, DROP VIEW, DROP MATERIALIZED VIEW and DROP TYPE statements."}
{"index": 4715, "repo": "calcite-core-1.34.0", "code": "Class SqlDropSchema {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for DROP SCHEMA statement."}
{"index": 4716, "repo": "calcite-core-1.34.0", "code": "Enum SqlExplain.Depth {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlExplain.Depth valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlExplain.Depth[] values();\n}", "des": "The level of abstraction with which to display the plan."}
{"index": 4717, "repo": "calcite-core-1.34.0", "code": "Enum SqlExplainFormat {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlExplainFormat valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlExplainFormat[] values();\n}", "des": "Output format for EXPLAIN PLAN statement."}
{"index": 4718, "repo": "calcite-core-1.34.0", "code": "Enum SqlExplainLevel {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlExplainLevel valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlExplainLevel[] values();\n}", "des": "SqlExplainLevel defines detail levels for EXPLAIN PLAN."}
{"index": 4719, "repo": "calcite-core-1.34.0", "code": "Enum SqlFunctionCategory {\n\tboolean isFunction();\n\tboolean isSpecific();\n\tboolean isTableFunction();\n\tboolean isUserDefined();\n\tboolean isUserDefinedNotSpecificFunction();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlFunctionCategory valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlFunctionCategory[] values();\n}", "des": "Enumeration of the categories of SQL-invoked routines."}
{"index": 4720, "repo": "calcite-core-1.34.0", "code": "Enum SqlFunctions.FlatProductInputType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlFunctions.FlatProductInputType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlFunctions.FlatProductInputType[] values();\n}", "des": "Type of argument passed into SqlFunctions.flatProduct(int[], boolean, org.apache.calcite.runtime.SqlFunctions.FlatProductInputType[])."}
{"index": 4721, "repo": "calcite-core-1.34.0", "code": "Enum SqlHint.HintOptionFormat {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlHint.HintOptionFormat valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlHint.HintOptionFormat[] values();\n}", "des": "Enumeration that represents hint option format."}
{"index": 4722, "repo": "calcite-core-1.34.0", "code": "Class SqlIdentifierMoniker {\n\t// Returns the array of component names.\n\tList<String> getFullyQualifiedNames();\n\t// Returns the type of object referred to by this moniker.\n\tSqlMonikerType getType();\n\tString id();\n\t// Creates a SqlIdentifier containing the fully-qualified name.\n\tSqlIdentifier toIdentifier();\n}", "des": "An implementation of SqlMoniker that encapsulates the normalized name information of a SqlIdentifier."}
{"index": 4723, "repo": "calcite-core-1.34.0", "code": "Enum SqlImplementor.Clause {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlImplementor.Clause valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlImplementor.Clause[] values();\n}", "des": "Clauses in a SQL query. Ordered by evaluation order. SELECT is set only when there is a NON-TRIVIAL SELECT clause."}
{"index": 4724, "repo": "calcite-core-1.34.0", "code": "Class SqlInOperator {\n\t// Returns whether the ordinalth argument to this operator must be scalar (as opposed to a query).\n\tboolean argumentMustBeScalar(int ordinal);\n\t// Derives the type of a call to this operator.\n\tRelDataType deriveType(SqlValidator validator, SqlValidatorScope scope, SqlCall call);\n\t// Returns the operator that is the logical inverse of this operator.\n\tSqlOperator not();\n\t// Returns whether the given operands are valid.\n\tboolean validRexOperands(int count, Litmus litmus);\n}", "des": "Definition of the SQL IN operator, which tests for a value's membership in a sub-query or a list of values."}
{"index": 4725, "repo": "calcite-core-1.34.0", "code": "Enum SqlInsertKeyword {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlInsertKeyword valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlInsertKeyword[] values();\n}", "des": "Defines the keywords that can occur immediately after the \"INSERT\" keyword."}
{"index": 4726, "repo": "calcite-core-1.34.0", "code": "Class SqlInternalOperator {\n\t// Derives the type of a call to this operator.\n\tRelDataType deriveType(SqlValidator validator, SqlValidatorScope scope, SqlCall call);\n\t// Returns the syntactic type of this operator, never null.\n\tSqlSyntax getSyntax();\n}", "des": "Generic operator for nodes with internal syntax."}
{"index": 4727, "repo": "calcite-core-1.34.0", "code": "Class SqlIntervalLiteral {\n\t// Clones a SqlNode with a different position.\n\tSqlIntervalLiteral clone(SqlParserPos pos);\n\t// Returns sign of value.\n\tint signum();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SQL literal representing a time interval."}
{"index": 4728, "repo": "calcite-core-1.34.0", "code": "Class SqlIntervalOperator {\n\t// Returns a template describing how the operator signature is to be built.\n\tString getSignatureTemplate(int operandsCount);\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "Interval expression."}
{"index": 4729, "repo": "calcite-core-1.34.0", "code": "Enum SqlJdbcDataTypeName {\n\t// Creates a parse tree node for a type identifier of this name.\n\tSqlNode createDataType(SqlParserPos pos);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJdbcDataTypeName valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJdbcDataTypeName[] values();\n}", "des": "Defines the name of the types which can occur as a type argument in a JDBC {fn CONVERT(value, type)} function. (This function has similar functionality to CAST, and is not to be confused with the SQL standard CONVERT function.)"}
{"index": 4730, "repo": "calcite-core-1.34.0", "code": "Class SqlJoin.SqlJoinOperator {\n\t// Creates a call to this operator with an array of operands.\n\tSqlCall createCall(@Nullable SqlLiteral functionQualifier, SqlParserPos pos, SqlNode... operands);\n\t// Returns the syntactic type of this operator, never null.\n\tSqlSyntax getSyntax();\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "Describes the syntax of the SQL JOIN operator."}
{"index": 4731, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonConstructorNullClause {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonConstructorNullClause valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonConstructorNullClause[] values();\n}", "des": "Indicating how JSON constructors handle null."}
{"index": 4732, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonEmptyOrError {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonEmptyOrError valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonEmptyOrError[] values();\n}", "des": "Flag to indicate if the json value is missing or an error is thrown where EmptyOrErrorBehavior is invoked."}
{"index": 4733, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonEncoding {\n\tString getStandardName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonEncoding valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonEncoding[] values();\n}", "des": "Supported json encodings that could be passed to a JsonValueExpression."}
{"index": 4734, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonExistsErrorBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonExistsErrorBehavior valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonExistsErrorBehavior[] values();\n}", "des": "Categorizing Json exists error behaviors."}
{"index": 4735, "repo": "calcite-core-1.34.0", "code": "Class SqlJsonExistsFunction {\n\t// Returns a string describing the expected operand types of a call, e.g.\n\tString getAllowedSignatures(String opNameToUse);\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "The JSON_EXISTS function."}
{"index": 4736, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonQueryEmptyOrErrorBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonQueryEmptyOrErrorBehavior valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonQueryEmptyOrErrorBehavior[] values();\n}", "des": "Categorizing Json query empty or error behaviors."}
{"index": 4737, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonQueryWrapperBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonQueryWrapperBehavior valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonQueryWrapperBehavior[] values();\n}", "des": "How json query function handle array result."}
{"index": 4738, "repo": "calcite-core-1.34.0", "code": "Class SqlJsonRemoveFunction {\n\t// Checks that the operand values in a SqlCall to this operator are valid.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Returns a string describing the expected operand types of a call, e.g.\n\tString getAllowedSignatures(String opNameToUse);\n\t// Returns a constraint on the number of operands expected by this operator.\n\tSqlOperandCountRange getOperandCountRange();\n}", "des": "The JSON_REMOVE function."}
{"index": 4739, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonValueEmptyOrErrorBehavior {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonValueEmptyOrErrorBehavior valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonValueEmptyOrErrorBehavior[] values();\n}", "des": "Categorizing Json value empty or error behaviors."}
{"index": 4740, "repo": "calcite-core-1.34.0", "code": "Enum SqlJsonValueReturning {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlJsonValueReturning valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlJsonValueReturning[] values();\n}", "des": "Flag to indicate the explicit return type of JSON_VALUE."}
{"index": 4741, "repo": "calcite-core-1.34.0", "code": "Class SqlKeyConstraint {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Creates a PRIMARY KEY constraint.\n\tstatic SqlKeyConstraint primary(SqlParserPos pos, SqlIdentifier name, SqlNodeList columnList);\n\t// Creates a UNIQUE constraint.\n\tstatic SqlKeyConstraint unique(SqlParserPos pos, SqlIdentifier name, SqlNodeList columnList);\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree for UNIQUE, PRIMARY KEY constraints."}
{"index": 4742, "repo": "calcite-core-1.34.0", "code": "Class SqlLeadLagAggFunction {\n\t// Returns whether this is a window function that allows framing (i.e.\n\tboolean allowsFraming();\n\t// Returns whether this aggregate function allows specifying null treatment (RESPECT NULLS or IGNORE NULLS).\n\tboolean allowsNullTreatment();\n}", "des": "LEAD and LAG aggregate functions return the value of given expression evaluated at given offset."}
{"index": 4743, "repo": "calcite-core-1.34.0", "code": "Enum SqlLibrary {\n\t// Looks up a value.\n\tstatic @Nullable SqlLibrary of(String name);\n\t// Parses a comma-separated string such as \"standard,oracle\".\n\tstatic List<SqlLibrary> parse(String libraryNameList);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlLibrary valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlLibrary[] values();\n}", "des": "A library is a collection of SQL functions and operators."}
{"index": 4744, "repo": "calcite-core-1.34.0", "code": "Class SqlLibraryOperatorTableFactory {\n\t// Returns a SQL operator table that contains operators in the given set of libraries.\n\tSqlOperatorTable getOperatorTable(Iterable<SqlLibrary> librarySet);\n\t// Returns a SQL operator table that contains operators in the given library or libraries.\n\tSqlOperatorTable getOperatorTable(SqlLibrary... libraries);\n}", "des": "Factory that creates operator tables that consist of functions and operators for particular named libraries. For example, the following code will return an operator table that contains operators for both Oracle and MySQL:"}
{"index": 4745, "repo": "calcite-core-1.34.0", "code": "Class SqlMapValueConstructor {\n\t// Checks that the operand values in a SqlCall to this operator are valid.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Infers the return type of an invocation of this operator; only called after the number and types of operands have already been validated.\n\tRelDataType inferReturnType(SqlOperatorBinding opBinding);\n}", "des": "Definition of the MAP constructor, MAP [<key>, <value>, ...]."}
{"index": 4746, "repo": "calcite-core-1.34.0", "code": "Enum SqlMatchRecognize.AfterOption {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlMatchRecognize.AfterOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlMatchRecognize.AfterOption[] values();\n}", "des": "Options for AFTER MATCH clause."}
{"index": 4747, "repo": "calcite-core-1.34.0", "code": "Enum SqlMatchRecognize.RowsPerMatchOption {\n\tSqlLiteral symbol(SqlParserPos pos);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlMatchRecognize.RowsPerMatchOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlMatchRecognize.RowsPerMatchOption[] values();\n}", "des": "Options for ROWS PER MATCH."}
{"index": 4748, "repo": "calcite-core-1.34.0", "code": "Class SqlMinMaxAggFunction {\n\t// Returns whether this aggregate function allows the DISTINCT keyword.\n\tOptionality getDistinctOptionality();\n\tList<RelDataType> getParameterTypes(RelDataTypeFactory typeFactory);\n\tRelDataType getReturnType(RelDataTypeFactory typeFactory);\n\t// Gets rollup aggregation function.\n\tSqlAggFunction getRollup();\n\t// Finds an instance of an interface implemented by this object, or returns null if this object does not support that interface.\n\t<T> T unwrap(Class<T> clazz);\n}", "des": "Definition of the MIN and MAX aggregate functions, returning the returns the smallest/largest of the values which go into it."}
{"index": 4749, "repo": "calcite-core-1.34.0", "code": "Enum SqlModality {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlModality valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlModality[] values();\n}", "des": "Relational or streaming."}
{"index": 4750, "repo": "calcite-core-1.34.0", "code": "Interface SqlMoniker {\n\t// Returns the array of component names.\n\tList<String> getFullyQualifiedNames();\n\t// Returns the type of object referred to by this moniker.\n\tSqlMonikerType getType();\n\tString id();\n\t// Creates a SqlIdentifier containing the fully-qualified name.\n\tSqlIdentifier toIdentifier();\n}", "des": "An interface of an object identifier that represents a SqlIdentifier."}
{"index": 4751, "repo": "calcite-core-1.34.0", "code": "Class SqlMonikerImpl {\n\tboolean equals(@Nullable Object obj);\n\t// Returns the array of component names.\n\tList<String> getFullyQualifiedNames();\n\t// Returns the type of object referred to by this moniker.\n\tSqlMonikerType getType();\n\tString id();\n\t// Creates a SqlIdentifier containing the fully-qualified name.\n\tSqlIdentifier toIdentifier();\n}", "des": "A generic implementation of SqlMoniker."}
{"index": 4752, "repo": "calcite-core-1.34.0", "code": "Enum SqlMonikerType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlMonikerType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlMonikerType[] values();\n}", "des": "An enumeration of moniker types."}
{"index": 4753, "repo": "calcite-core-1.34.0", "code": "Class SqlMultisetMemberOfOperator {\n\t// Checks that the operand values in a SqlCall to this operator are valid.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Returns a constraint on the number of operands expected by this operator.\n\tSqlOperandCountRange getOperandCountRange();\n}", "des": "Multiset MEMBER OF. Checks to see if a element belongs to a multiset. Example: 'green' MEMBER OF MULTISET['red','almost green','blue'] returns false."}
{"index": 4754, "repo": "calcite-core-1.34.0", "code": "Class SqlNameMatchers {\n\t// Creates a name matcher that can suggest corrections to what the user typed.\n\tstatic SqlNameMatcher liberal();\n\t// Returns a name matcher with the given case sensitivity.\n\tstatic SqlNameMatcher withCaseSensitive(boolean caseSensitive);\n}", "des": "Helpers for SqlNameMatcher."}
{"index": 4755, "repo": "calcite-core-1.34.0", "code": "Class SqlNewOperator {\n\t// Method to check if call requires expansion when it has decimal operands.\n\tboolean requiresDecimalExpansion();\n\t// Rewrites a call to this operator.\n\tSqlNode rewriteCall(SqlValidator validator, SqlCall call);\n}", "des": "SqlNewOperator represents an SQL new specification such as NEW UDT(1, 2). When used in an SqlCall, SqlNewOperator takes a single operand, which is an invocation of the constructor method; but when used in a RexCall, the operands are the initial values to be used for the new instance."}
{"index": 4756, "repo": "calcite-core-1.34.0", "code": "Interface SqlNodeToRexConverter {\n\t// Converts a SqlCall to a RexNode expression.\n\tRexNode convertCall(SqlRexContext cx, SqlCall call);\n\t// Converts a SQL Interval Qualifier to a REX literal.\n\tRexLiteral convertInterval(SqlRexContext cx, SqlIntervalQualifier intervalQualifier);\n\t// Converts a SQL literal to a REX literal.\n\tRexNode convertLiteral(SqlRexContext cx, SqlLiteral literal);\n}", "des": "Converts expressions from SqlNode to RexNode."}
{"index": 4757, "repo": "calcite-core-1.34.0", "code": "Class SqlNodeToRexConverterImpl {\n\t// Converts a SqlCall to a RexNode expression.\n\tRexNode convertCall(SqlRexContext cx, SqlCall call);\n\t// Converts a SQL Interval Qualifier to a REX literal.\n\tRexLiteral convertInterval(SqlRexContext cx, SqlIntervalQualifier intervalQualifier);\n\t// Converts a SQL literal to a REX literal.\n\tRexNode convertLiteral(SqlRexContext cx, SqlLiteral literal);\n}", "des": "Standard implementation of SqlNodeToRexConverter."}
{"index": 4758, "repo": "calcite-core-1.34.0", "code": "Enum SqlNullSemantics {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlNullSemantics valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlNullSemantics[] values();\n}", "des": "SqlNullSemantics defines the possible comparison rules for values which might be null. In SQL (and internal plans used to process SQL) different rules are used depending on the context."}
{"index": 4759, "repo": "calcite-core-1.34.0", "code": "Interface SqlOperandCountRange {\n\t// Returns an upper bound.\n\tint getMax();\n\t// Returns an lower bound.\n\tint getMin();\n\t// Returns whether count is a valid number of operands.\n\tboolean isValidCount(int count);\n}", "des": "A class that describes how many operands an operator can take."}
{"index": 4760, "repo": "calcite-core-1.34.0", "code": "Interface SqlOperandMetadata {\n\t// Returns the names of the parameters.\n\tList<String> paramNames();\n\t// Returns the types of the parameters.\n\tList<RelDataType> paramTypes(RelDataTypeFactory typeFactory);\n}", "des": "Extension to SqlOperandTypeChecker that also provides names and types of particular operands."}
{"index": 4761, "repo": "calcite-core-1.34.0", "code": "Enum SqlOperandTypeChecker.Consistency {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlOperandTypeChecker.Consistency valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlOperandTypeChecker.Consistency[] values();\n}", "des": "Strategy used to make arguments consistent."}
{"index": 4762, "repo": "calcite-core-1.34.0", "code": "Interface SqlOperatorTable {\n\t// Retrieves a list of all functions and operators in this table.\n\tList<SqlOperator> getOperatorList();\n\t// Retrieves a list of operators with a given name and syntax.\n\tvoid lookupOperatorOverloads(SqlIdentifier opName, @Nullable SqlFunctionCategory category, SqlSyntax syntax, List<SqlOperator> operatorList, SqlNameMatcher nameMatcher);\n}", "des": "SqlOperatorTable defines a directory interface for enumerating and looking up SQL operators and functions."}
{"index": 4763, "repo": "calcite-core-1.34.0", "code": "Class SqlOrderBy {\n\t// Returns the type of node this is, or SqlKind.OTHER if it's nothing special.\n\tSqlKind getKind();\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n}", "des": "Parse tree node that represents an ORDER BY on a query other than a SELECT (e.g. VALUES or UNION)."}
{"index": 4764, "repo": "calcite-core-1.34.0", "code": "Class SqlOverlayFunction {\n\t// Returns a template describing how the operator signature is to be built.\n\tString getSignatureTemplate(int operandsCount);\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "The OVERLAY function."}
{"index": 4765, "repo": "calcite-core-1.34.0", "code": "Class SqlOverOperator {\n\t// Accepts a SqlVisitor, and tells it to visit each child.\n\t<R> void acceptCall(SqlVisitor<R> visitor, SqlCall call, boolean onlyExpressions, SqlBasicVisitor.ArgHandler<R> argHandler);\n\t// Derives the type of a call to this operator.\n\tRelDataType deriveType(SqlValidator validator, SqlValidatorScope scope, SqlCall call);\n\t// Validates a call to this operator.\n\tvoid validateCall(SqlCall call, SqlValidator validator, SqlValidatorScope scope, SqlValidatorScope operandScope);\n}", "des": "An operator describing a window function specification."}
{"index": 4766, "repo": "calcite-core-1.34.0", "code": "Class SqlParseException {\n\tThrowable getCause();\n\t// Returns a list of the token names which could have legally occurred at this point.\n\tCollection<String> getExpectedTokenNames();\n\t// Returns the expected token sequences.\n\tint[][] getExpectedTokenSequences();\n\t// Returns the position where this error occurred.\n\tSqlParserPos getPos();\n\t// Returns the token images.\n\tString[] getTokenImages();\n}", "des": "SqlParseException defines a checked exception corresponding to SqlParser."}
{"index": 4767, "repo": "calcite-core-1.34.0", "code": "Interface SqlParserImplFactory {\n\t// Returns a DDL executor.\n\tdefault DdlExecutor getDdlExecutor();\n\t// Get the underlying parser implementation.\n\torg.apache.calcite.sql.parser.SqlAbstractParserImpl getParser(Reader stream);\n}", "des": "Factory for SqlAbstractParserImpl objects."}
{"index": 4768, "repo": "calcite-core-1.34.0", "code": "Class SqlRegexpReplaceFunction {\n\t// Checks that the operand values in a SqlCall to this operator are valid.\n\tboolean checkOperandTypes(SqlCallBinding callBinding, boolean throwOnFailure);\n\t// Returns a constraint on the number of operands expected by this operator.\n\tSqlOperandCountRange getOperandCountRange();\n}", "des": "The REGEXP_REPLACE(source_string, pattern, replacement [, pos, occurrence, match_type]) searches for a regular expression pattern and replaces every occurrence of the pattern with the specified string."}
{"index": 4769, "repo": "calcite-core-1.34.0", "code": "Interface SqlReturnTypeInference {\n\t// Returns a return-type inference that applies this rule then a transform.\n\tdefault SqlReturnTypeInference andThen(SqlTypeTransform transform);\n\t// Infers the return type of a call to an SqlOperator.\n\t@Nullable RelDataType inferReturnType(SqlOperatorBinding opBinding);\n\t// Returns a return-type inference that applies this rule then another rule, until one of them returns a not-null result.\n\tdefault SqlReturnTypeInference orElse(SqlReturnTypeInference transform);\n}", "des": "Strategy interface to infer the type of an operator call from the type of the operands."}
{"index": 4770, "repo": "calcite-core-1.34.0", "code": "Class SqlRowTypeNameSpec {\n\t// Derive type from this SqlTypeNameSpec.\n\tRelDataType deriveType(SqlValidator sqlValidator);\n\t// Returns whether this spec is structurally equivalent to another spec.\n\tboolean equalsDeep(SqlTypeNameSpec node, Litmus litmus);\n\tint getArity();\n\tList<SqlIdentifier> getFieldNames();\n\tList<SqlDataTypeSpec> getFieldTypes();\n\t// Writes a SQL representation of this spec to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A sql type name specification of row type."}
{"index": 4771, "repo": "calcite-core-1.34.0", "code": "Class SqlSampleSpec {\n\t// Creates a sample which substitutes one relation for another.\n\tstatic SqlSampleSpec createNamed(String name);\n\t// Creates a table sample without repeatability.\n\tstatic SqlSampleSpec createTableSample(boolean isBernoulli, float samplePercentage);\n\t// Creates a table sample with repeatability.\n\tstatic SqlSampleSpec createTableSample(boolean isBernoulli, float samplePercentage, int repeatableSeed);\n}", "des": "Specification of a SQL sample."}
{"index": 4772, "repo": "calcite-core-1.34.0", "code": "Class SqlSampleSpec.SqlTableSampleSpec {\n\t// Seed to produce repeatable samples.\n\tint getRepeatableSeed();\n\t// Returns sampling percentage.\n\tfloat getSamplePercentage();\n\t// Indicates Bernoulli vs.\n\tboolean isBernoulli();\n\t// Indicates whether repeatable seed should be used.\n\tboolean isRepeatable();\n}", "des": "Sample specification."}
{"index": 4773, "repo": "calcite-core-1.34.0", "code": "Class SqlScopedShuttle {\n\t// Returns the current scope.\n\tprotected SqlValidatorScope getScope();\n\t// Visits a call to a SqlOperator.\n\t@Nullable SqlNode visit(SqlCall call);\n\t// Visits an operator call.\n\tprotected @Nullable SqlNode visitScoped(SqlCall call);\n}", "des": "Refinement to SqlShuttle which maintains a stack of scopes."}
{"index": 4774, "repo": "calcite-core-1.34.0", "code": "Enum SqlSelectKeyword {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlSelectKeyword valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlSelectKeyword[] values();\n}", "des": "Defines the keywords which can occur immediately after the \"SELECT\" keyword."}
{"index": 4775, "repo": "calcite-core-1.34.0", "code": "Class SqlSimpleParser {\n\t// Turns a partially completed or syntactically incorrect SQL statement into a simplified, valid one that can be validated.\n\tString simplifySql(String sql);\n\t// Turns a partially completed or syntactically incorrect sql statement into a simplified, valid one that can be passed into getCompletionHints().\n\tString simplifySql(String sql, int cursor);\n}", "des": "A simple parser that takes an incomplete and turn it into a syntactically correct statement. It is used in the SQL editor user-interface."}
{"index": 4776, "repo": "calcite-core-1.34.0", "code": "Class SqlSnapshot {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\tSqlNode getPeriod();\n\tSqlNode getTableRef();\n\t// Changes the value of an operand.\n\tvoid setOperand(int i, @Nullable SqlNode operand);\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Parse tree node for \"FOR SYSTEM_TIME AS OF\" temporal clause."}
{"index": 4777, "repo": "calcite-core-1.34.0", "code": "Class SqlSpatialTypeFunctions {\n\t// Explodes the geom into multiple geometries.\n\tstatic ScannableTable ST_Explode(org.locationtech.jts.geom.Geometry geom);\n\t// Calculates a regular grid of polygons based on geom.\n\tstatic ScannableTable ST_MakeGrid(org.locationtech.jts.geom.Geometry geom, BigDecimal deltaX, BigDecimal deltaY);\n\t// Calculates a regular grid of points based on geom.\n\tstatic ScannableTable ST_MakeGridPoints(org.locationtech.jts.geom.Geometry geom, BigDecimal deltaX, BigDecimal deltaY);\n}", "des": "Utilities for spatial type functions."}
{"index": 4778, "repo": "calcite-core-1.34.0", "code": "Class SqlSpatialTypeOperatorTable {\n\t// Retrieves a list of all functions and operators in this table.\n\tList<SqlOperator> getOperatorList();\n\t// Retrieves a list of operators with a given name and syntax.\n\tvoid lookupOperatorOverloads(SqlIdentifier opName, @Nullable SqlFunctionCategory category, SqlSyntax syntax, List<SqlOperator> operatorList, SqlNameMatcher nameMatcher);\n}", "des": "Implementation of SqlSpatialTypeOperatorTable containing the spatial operators and functions."}
{"index": 4779, "repo": "calcite-core-1.34.0", "code": "Class SqlSpecialOperator {\n\t// Returns the syntactic type of this operator, never null.\n\tSqlSyntax getSyntax();\n\t// Reduces a list of operators and arguments according to the rules of precedence and associativity.\n\tSqlSpecialOperator.ReduceResult reduceExpr(int ordinal, SqlSpecialOperator.TokenSequence list);\n}", "des": "Generic operator for nodes with special syntax."}
{"index": 4780, "repo": "calcite-core-1.34.0", "code": "Class SqlString {\n\tboolean equals(@Nullable Object obj);\n\t// Returns the dialect.\n\tSqlDialect getDialect();\n\t// Returns indices of dynamic parameters.\n\t@Nullable com.google.common.collect.ImmutableList<Integer> getDynamicParameters();\n\t// Returns the SQL string.\n\tString getSql();\n}", "des": "String that represents a kocher SQL statement, expression, or fragment."}
{"index": 4781, "repo": "calcite-core-1.34.0", "code": "Class SqlSumAggFunction {\n\tList<RelDataType> getParameterTypes(RelDataTypeFactory typeFactory);\n\tRelDataType getReturnType(RelDataTypeFactory typeFactory);\n\t// Gets rollup aggregation function.\n\tSqlAggFunction getRollup();\n\t// Finds an instance of an interface implemented by this object, or returns null if this object does not support that interface.\n\t<T> T unwrap(Class<T> clazz);\n}", "des": "Sum is an aggregator which returns the sum of the values which go into it. It has precisely one argument of numeric type (int, long, float, double), and the result is the same type."}
{"index": 4782, "repo": "calcite-core-1.34.0", "code": "Class SqlSumEmptyIsZeroAggFunction {\n\tList<RelDataType> getParameterTypes(RelDataTypeFactory typeFactory);\n\tRelDataType getReturnType(RelDataTypeFactory typeFactory);\n\t// Gets rollup aggregation function.\n\tSqlAggFunction getRollup();\n\t// Finds an instance of an interface implemented by this object, or returns null if this object does not support that interface.\n\t<T> T unwrap(Class<T> clazz);\n}", "des": "Sum0 is an aggregator which returns the sum of the values which go into it like Sum. It differs in that when no non null values are applied zero is returned instead of null. Can be used along with Count to implement Sum."}
{"index": 4783, "repo": "calcite-core-1.34.0", "code": "Enum SqlSyntax {\n\t// Converts a call to an operator of this syntax into a string.\n\tabstract void unparse(SqlWriter writer, SqlOperator operator, SqlCall call, int leftPrec, int rightPrec);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlSyntax valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlSyntax[] values();\n}", "des": "Enumeration of possible syntactic types of operators."}
{"index": 4784, "repo": "calcite-core-1.34.0", "code": "Interface SqlTableFunction {\n\t// Returns the record type of the table yielded by this function when applied to given arguments.\n\tSqlReturnTypeInference getRowTypeInference();\n\t// Returns the table parameter characteristics for ordinalth parameter to this table function.\n\tdefault @Nullable TableCharacteristic tableCharacteristic(int ordinal);\n}", "des": "A function that returns a table."}
{"index": 4785, "repo": "calcite-core-1.34.0", "code": "Class SqlTableRef {\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SqlTableRef is a node of a parse tree which represents a table reference."}
{"index": 4786, "repo": "calcite-core-1.34.0", "code": "Class SqlTimeLiteral {\n\t// Clones a SqlNode with a different position.\n\tSqlTimeLiteral clone(SqlParserPos pos);\n\t// Converts this literal to a TimeString.\n\tprotected TimeString getTime();\n\t// Returns e.g.\n\tString toFormattedString();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SQL literal representing a TIME value, for example TIME '14:33:44.567'."}
{"index": 4787, "repo": "calcite-core-1.34.0", "code": "Class SqlTimestampLiteral {\n\t// Clones a SqlNode with a different position.\n\tSqlTimestampLiteral clone(SqlParserPos pos);\n\t// Returns e.g.\n\tString toFormattedString();\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SQL literal representing a TIMESTAMP value, for example TIMESTAMP '1969-07-21 03:15 GMT'."}
{"index": 4788, "repo": "calcite-core-1.34.0", "code": "Class SqlTranslate3Function {\n\t// Returns a template describing how the operator signature is to be built.\n\tString getSignatureTemplate(int operandsCount);\n\t// Writes a SQL representation of a call to this operator to a writer, including parentheses if the operators on either side are of greater precedence.\n\tvoid unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec);\n}", "des": "Definition of the \"TRANSLATE\" built-in SQL function that takes 3 arguments."}
{"index": 4789, "repo": "calcite-core-1.34.0", "code": "Enum SqlTrimFunction.Flag {\n\tint getLeft();\n\tint getRight();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlTrimFunction.Flag valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlTrimFunction.Flag[] values();\n}", "des": "Defines the enumerated values \"LEADING\", \"TRAILING\", \"BOTH\"."}
{"index": 4790, "repo": "calcite-core-1.34.0", "code": "Class SqlTypeAssignmentRule {\n\t// Returns the type mappings of this rule instance.\n\tMap<SqlTypeName,com.google.common.collect.ImmutableSet<SqlTypeName>> getTypeMapping();\n\t// Returns an instance.\n\tstatic SqlTypeAssignmentRule instance();\n}", "des": "Rules that determine whether a type is assignable from another type."}
{"index": 4791, "repo": "calcite-core-1.34.0", "code": "Class SqlTypeCoercionRule {\n\t// Returns the type mappings of this rule instance.\n\tMap<SqlTypeName,com.google.common.collect.ImmutableSet<SqlTypeName>> getTypeMapping();\n\t// Returns an instance.\n\tstatic SqlTypeCoercionRule instance();\n\t// Returns an instance with specified type mappings.\n\tstatic SqlTypeCoercionRule instance(Map<SqlTypeName,com.google.common.collect.ImmutableSet<SqlTypeName>> map);\n}", "des": "Rules that determine whether a type is castable from another type."}
{"index": 4792, "repo": "calcite-core-1.34.0", "code": "Class SqlTypeExplicitPrecedenceList {\n\t// Compares the precedence of two types.\n\tint compareTypePrecedence(RelDataType type1, RelDataType type2);\n\t// Determines whether a type appears in this precedence list.\n\tboolean containsType(RelDataType type);\n}", "des": "SqlTypeExplicitPrecedenceList implements the RelDataTypePrecedenceList interface via an explicit list of SqlTypeName entries."}
{"index": 4793, "repo": "calcite-core-1.34.0", "code": "Interface SqlTypeMappingRule {\n\t// Returns whether it is valid to apply the defined rules from type from to type to.\n\tdefault boolean canApplyFrom(SqlTypeName to, SqlTypeName from);\n\t// Returns the type mappings of this rule instance.\n\tMap<SqlTypeName,com.google.common.collect.ImmutableSet<SqlTypeName>> getTypeMapping();\n}", "des": "Interface that defines rules within type mappings."}
{"index": 4794, "repo": "calcite-core-1.34.0", "code": "Class SqlTypeMappingRules {\n\t// Returns a SqlTypeMappingRules.Builder to build the type mappings.\n\tstatic SqlTypeMappingRules.Builder builder();\n\t// Returns the SqlTypeMappingRule instance based on the specified coerce to indicate whether to return as a type coercion rule.\n\tstatic SqlTypeMappingRule instance(boolean coerce);\n}", "des": "This class defines some utilities to build type mapping matrix which would then use to construct the SqlTypeMappingRule rules."}
{"index": 4795, "repo": "calcite-core-1.34.0", "code": "Enum SqlTypeName.Limit {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlTypeName.Limit valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlTypeName.Limit[] values();\n}", "des": "Limit."}
{"index": 4796, "repo": "calcite-core-1.34.0", "code": "Class SqlTypeNameSpec {\n\t// Derive type from this SqlTypeNameSpec.\n\tabstract RelDataType deriveType(SqlValidator validator);\n\t// Returns whether this spec is structurally equivalent to another spec.\n\tabstract boolean equalsDeep(SqlTypeNameSpec spec, Litmus litmus);\n\tSqlParserPos getParserPos();\n\tSqlIdentifier getTypeName();\n\t// Writes a SQL representation of this spec to a writer.\n\tabstract void unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A SqlTypeNameSpec is a type name specification that allows user to customize sql node unparsing and data type deriving."}
{"index": 4797, "repo": "calcite-core-1.34.0", "code": "Class SqlUnknownLiteral {\n\t// Clones a SqlNode with a different position.\n\tSqlLiteral clone(SqlParserPos pos);\n\t// Returns the value of this literal.\n\tString getValue();\n\t// Converts this unknown literal to a literal of known type.\n\tSqlLiteral resolve(SqlTypeName typeName);\n\t// Writes a SQL representation of this node to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "Literal whose type is not yet known."}
{"index": 4798, "repo": "calcite-core-1.34.0", "code": "Class SqlUserDefinedFunction {\n\t// Returns function that implements given operator call.\n\tFunction getFunction();\n\t@Nullable SqlOperandMetadata getOperandTypeChecker();\n\t// Use SqlOperandMetadata.paramNames() on the result of SqlOperator.getOperandTypeChecker().\n\tList<String> getParamNames();\n}", "des": "User-defined scalar function."}
{"index": 4799, "repo": "calcite-core-1.34.0", "code": "Class SqlUserDefinedTableFunction {\n\t// Returns the row type of the table yielded by this function when applied to given arguments.\n\tType getElementType(SqlOperatorBinding callBinding);\n\t// Returns function that implements given operator call.\n\tTableFunction getFunction();\n\t// Returns the record type of the table yielded by this function when applied to given arguments.\n\tSqlReturnTypeInference getRowTypeInference();\n}", "des": "User-defined table function."}
{"index": 4800, "repo": "calcite-core-1.34.0", "code": "Class SqlUserDefinedTableMacro {\n\t@Nullable SqlOperandMetadata getOperandTypeChecker();\n\t// Use SqlOperandMetadata.paramNames() on the result of SqlOperator.getOperandTypeChecker().\n\tList<String> getParamNames();\n\t// Returns the record type of the table yielded by this function when applied to given arguments.\n\tSqlReturnTypeInference getRowTypeInference();\n\t// Returns the table in this UDF, or null if there is no table.\n\tTranslatableTable getTable(SqlOperatorBinding callBinding);\n}", "des": "User-defined table macro."}
{"index": 4801, "repo": "calcite-core-1.34.0", "code": "Class SqlUserDefinedTypeNameSpec {\n\t// Derive type from this SqlTypeNameSpec.\n\tRelDataType deriveType(SqlValidator validator);\n\t// Returns whether this spec is structurally equivalent to another spec.\n\tboolean equalsDeep(SqlTypeNameSpec spec, Litmus litmus);\n\t// Writes a SQL representation of this spec to a writer.\n\tvoid unparse(SqlWriter writer, int leftPrec, int rightPrec);\n}", "des": "A sql type name specification of user defined type."}
{"index": 4802, "repo": "calcite-core-1.34.0", "code": "Enum SqlValidatorImpl.Status {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlValidatorImpl.Status valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlValidatorImpl.Status[] values();\n}", "des": "Validation status."}
{"index": 4803, "repo": "calcite-core-1.34.0", "code": "Class SqlValidatorScope.Path {\n\tprotected void build(com.google.common.collect.ImmutableList.Builder<SqlValidatorScope.Step> paths);\n\t// Creates a path that consists of this path plus one additional step.\n\tSqlValidatorScope.Step plus(@Nullable RelDataType rowType, int i, String name, StructKind kind);\n\t// Number of steps in this path.\n\tint stepCount();\n\t// Returns the steps in this path.\n\tList<SqlValidatorScope.Step> steps();\n}", "des": "A sequence of steps by which an identifier was resolved. Immutable."}
{"index": 4804, "repo": "calcite-core-1.34.0", "code": "Interface SqlValidatorTable {\n\t// Returns the access type of the table.\n\tSqlAccessType getAllowedAccess();\n\t// Returns whether a given column is monotonic.\n\tSqlMonotonicity getMonotonicity(String columnName);\n\tList<String> getQualifiedName();\n\tRelDataType getRowType();\n\t// Returns whether the table is temporal.\n\tboolean isTemporal();\n\tboolean supportsModality(SqlModality modality);\n\t// Returns the table.\n\tdefault Table table();\n}", "des": "Supplies a SqlValidator with the metadata for a table."}
{"index": 4805, "repo": "calcite-core-1.34.0", "code": "Interface SqlValidatorWithHints {\n\t// Looks up completion hints for a syntactically correct SQL statement that has been parsed into an expression tree.\n\tList<SqlMoniker> lookupHints(SqlNode topNode, SqlParserPos pos);\n\t// Looks up the fully qualified name for a SqlIdentifier at a given Parser Position in a parsed expression tree Note: call this only after SqlValidator.validate(org.apache.calcite.sql.SqlNode) has been called.\n\t@Nullable SqlMoniker lookupQualifiedName(SqlNode topNode, SqlParserPos pos);\n}", "des": "Extends SqlValidator to allow discovery of useful data such as fully qualified names of SQL objects, alternative valid SQL objects that can be used in the SQL statement (dubbed as hints)."}
{"index": 4806, "repo": "calcite-core-1.34.0", "code": "Class SqlWindowTableFunction {\n\t// Returns whether the ordinalth argument to this operator must be scalar (as opposed to a query).\n\tboolean argumentMustBeScalar(int ordinal);\n\t@Nullable SqlOperandMetadata getOperandTypeChecker();\n\t// Returns the record type of the table yielded by this function when applied to given arguments.\n\tSqlReturnTypeInference getRowTypeInference();\n}", "des": "Base class for a table-valued function that computes windows. Examples include TUMBLE, HOP and SESSION."}
{"index": 4807, "repo": "calcite-core-1.34.0", "code": "Class SqlWindowTableFunction.AbstractOperandMetadata {\n\t// Returns the range of operand counts allowed in a call.\n\tSqlOperandCountRange getOperandCountRange();\n\t// Returns whether the ith operand is optional.\n\tboolean isOptional(int i);\n\t// Returns the names of the parameters.\n\tList<String> paramNames();\n\t// Returns the types of the parameters.\n\tList<RelDataType> paramTypes(RelDataTypeFactory typeFactory);\n}", "des": "Partial implementation of operand type checker."}
{"index": 4808, "repo": "calcite-core-1.34.0", "code": "Class SqlWith {\n\t// Returns the type of node this is, or SqlKind.OTHER if it's nothing special.\n\tSqlKind getKind();\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Changes the value of an operand.\n\tvoid setOperand(int i, @Nullable SqlNode operand);\n\t// Validates this call.\n\tvoid validate(SqlValidator validator, SqlValidatorScope scope);\n}", "des": "The WITH clause of a query. It wraps a SELECT, UNION, or INTERSECT."}
{"index": 4809, "repo": "calcite-core-1.34.0", "code": "Class SqlWithItem {\n\t// Returns the type of node this is, or SqlKind.OTHER if it's nothing special.\n\tSqlKind getKind();\n\t// Returns the list of operands.\n\tList<SqlNode> getOperandList();\n\tSqlOperator getOperator();\n\t// Changes the value of an operand.\n\tvoid setOperand(int i, @Nullable SqlNode operand);\n}", "des": "An item in a WITH clause of a query. It has a name, an optional column list, and a query."}
{"index": 4810, "repo": "calcite-core-1.34.0", "code": "Interface SqlWriter.FrameType {\n\t// Returns the name of this frame type.\n\tString getName();\n\t// Returns whether this frame type should cause the code be further indented.\n\tboolean needsIndent();\n}", "des": "Frame type."}
{"index": 4811, "repo": "calcite-core-1.34.0", "code": "Enum SqlWriter.SubQueryStyle {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlWriter.SubQueryStyle valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlWriter.SubQueryStyle[] values();\n}", "des": "Style of formatting sub-queries."}
{"index": 4812, "repo": "calcite-core-1.34.0", "code": "Enum SqlWriterConfig.LineFolding {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SqlWriterConfig.LineFolding valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SqlWriterConfig.LineFolding[] values();\n}", "des": "Policy for how to do deal with long lines."}
{"index": 4813, "repo": "calcite-core-1.34.0", "code": "Class StackWriter {\n\t// Writes an SQL identifier.\n\tstatic void printSqlIdentifier(PrintWriter pw, String s);\n\t// Writes an SQL string literal.\n\tstatic void printSqlStringLiteral(PrintWriter pw, String s);\n\tvoid write(char[] cbuf, int off, int len);\n\tvoid write(int c);\n\tvoid write(String str, int off, int len);\n}", "des": "A helper class for generating formatted text. StackWriter keeps track of nested formatting state like indentation level and quote escaping. Typically, it is inserted between a PrintWriter and the real Writer; directives are passed straight through the PrintWriter via the write method, as in the following example:"}
{"index": 4814, "repo": "calcite-core-1.34.0", "code": "Interface StreamRules.DeltaAggregateTransposeRule.DeltaAggregateTransposeRuleConfig {\n\t// Creates a rule that uses this configuration.\n\tdefault StreamRules.DeltaAggregateTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault RelRule.Config withOperandFor(Class<? extends RelNode> relClass);\n}", "des": "Rule configuration."}
{"index": 4815, "repo": "calcite-core-1.34.0", "code": "Interface StreamRules.DeltaFilterTransposeRule.DeltaFilterTransposeRuleConfig {\n\t// Creates a rule that uses this configuration.\n\tdefault StreamRules.DeltaFilterTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault RelRule.Config withOperandFor(Class<? extends RelNode> relClass);\n}", "des": "Rule configuration."}
{"index": 4816, "repo": "calcite-core-1.34.0", "code": "Interface StreamRules.DeltaProjectTransposeRule.DeltaProjectTransposeRuleConfig {\n\t// Creates a rule that uses this configuration.\n\tdefault StreamRules.DeltaProjectTransposeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault RelRule.Config withOperandFor(Class<? extends RelNode> relClass);\n}", "des": "Rule configuration."}
{"index": 4817, "repo": "calcite-core-1.34.0", "code": "Enum Strong.Policy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Strong.Policy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Strong.Policy[] values();\n}", "des": "How whether an operator's operands are null affects whether a call to that operator evaluates to null."}
{"index": 4818, "repo": "calcite-core-1.34.0", "code": "Enum StructKind {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StructKind valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StructKind[] values();\n}", "des": "Describes a policy for resolving fields in record types."}
{"index": 4819, "repo": "calcite-core-1.34.0", "code": "Interface SubQueryConverter {\n\t// Returns whether the sub-query can be converted.\n\tboolean canConvertSubQuery();\n\t// Converts the sub-query to an equivalent expression.\n\tRexNode convertSubQuery(SqlCall subQuery, SqlToRelConverter parentConverter, boolean isExists, boolean isExplain);\n}", "des": "SubQueryConverter provides the interface for classes that convert sub-queries into equivalent expressions."}
{"index": 4820, "repo": "calcite-core-1.34.0", "code": "Interface SubQueryRemoveRule.Config {\n\t// Forwards a call to RelOptRule.onMatch(RelOptRuleCall).\n\tRelRule.MatchHandler<SubQueryRemoveRule> matchHandler();\n\t// Creates a rule that uses this configuration.\n\tdefault SubQueryRemoveRule toRule();\n\t// Sets matchHandler().\n\tSubQueryRemoveRule.Config withMatchHandler(RelRule.MatchHandler<SubQueryRemoveRule> matchHandler);\n}", "des": "Rule configuration."}
{"index": 4821, "repo": "calcite-core-1.34.0", "code": "Class SybaseSqlDialect {\n\t// Converts an offset and fetch into SQL.\n\tvoid unparseOffsetFetch(SqlWriter writer, @Nullable SqlNode offset, @Nullable SqlNode fetch);\n\t// Converts a fetch into a \"SELECT TOP(fetch)\".\n\tvoid unparseTopN(SqlWriter writer, @Nullable SqlNode offset, @Nullable SqlNode fetch);\n}", "des": "A SqlDialect implementation for the Sybase database."}
{"index": 4822, "repo": "calcite-core-1.34.0", "code": "Enum TableAccessMap.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TableAccessMap.Mode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TableAccessMap.Mode[] values();\n}", "des": "Access mode."}
{"index": 4823, "repo": "calcite-core-1.34.0", "code": "Class TableCharacteristic.Builder {\n\tTableCharacteristic build();\n\t// Input table supports pass-through columns.\n\tTableCharacteristic.Builder passColumnsThrough();\n\t// DBMS could prune virtual processors if the input table is empty.\n\tTableCharacteristic.Builder pruneIfEmpty();\n}", "des": "Builder for TableCharacteristic."}
{"index": 4824, "repo": "calcite-core-1.34.0", "code": "Enum TableCharacteristic.Semantics {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TableCharacteristic.Semantics valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TableCharacteristic.Semantics[] values();\n}", "des": "Input table has either row semantics or set semantics."}
{"index": 4825, "repo": "calcite-core-1.34.0", "code": "Interface TableFunction {\n\t// Returns the row type of the table yielded by this function when applied to given arguments.\n\tType getElementType(List<? extends Object> arguments);\n\t// Returns the record type of the table yielded by this function when applied to given arguments.\n\tRelDataType getRowType(RelDataTypeFactory typeFactory, List<? extends Object> arguments);\n}", "des": "Function that returns a table during execution time."}
{"index": 4826, "repo": "calcite-core-1.34.0", "code": "Class TableMacroImpl {\n\t// Applies arguments to yield a table.\n\tTranslatableTable apply(List<? extends Object> arguments);\n\t// Creates a TableMacro from a class, looking for an \"eval\" method.\n\tstatic @Nullable TableMacro create(Class<?> clazz);\n\t// Creates a TableMacro from a method.\n\tstatic @Nullable TableMacro create(Method method);\n}", "des": "Implementation of TableMacro based on a method."}
{"index": 4827, "repo": "calcite-core-1.34.0", "code": "Enum TableModify.Operation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TableModify.Operation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TableModify.Operation[] values();\n}", "des": "Enumeration of supported modification operations."}
{"index": 4828, "repo": "calcite-core-1.34.0", "code": "Class TableSpool {\n\t// Describes the inputs and attributes of this relational expression.\n\tRelWriter explainTerms(RelWriter pw);\n\t// If this relational expression represents an access to a table, returns that table, otherwise returns null.\n\tRelOptTable getTable();\n}", "des": "Spool that writes into a table."}
{"index": 4829, "repo": "calcite-core-1.34.0", "code": "Interface TemporalTable {\n\t// Returns the name of the system column that contains the end effective time of each row.\n\tString getSysEndFieldName();\n\t// Returns the name of the system column that contains the start effective time of each row.\n\tString getSysStartFieldName();\n}", "des": "Table that is temporal."}
{"index": 4830, "repo": "calcite-core-1.34.0", "code": "Class TraitMatchingRule {\n\t// Creates a configuration for a TraitMatchingRule.\n\tstatic TraitMatchingRule.Config config(ConverterRule converterRule, RelBuilderFactory relBuilderFactory);\n\t// Returns the convention of the result of firing this rule, null if not known.\n\t@Nullable Convention getOutConvention();\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "TraitMatchingRule adapts a converter rule, restricting it to fire only when its input already matches the expected output trait. This can be used with HepPlanner in cases where alternate implementations are available and it is desirable to minimize converters."}
{"index": 4831, "repo": "calcite-core-1.34.0", "code": "Interface TraitMatchingRule.Config {\n\t// Returns the rule to be restricted; rule must take a single operand expecting a single input.\n\tConverterRule converterRule();\n\t// Creates a rule that uses this configuration.\n\tdefault TraitMatchingRule toRule();\n\t// Sets converterRule().\n\tTraitMatchingRule.Config withConverterRule(ConverterRule converterRule);\n}", "des": "Rule configuration."}
{"index": 4832, "repo": "calcite-core-1.34.0", "code": "Class UnionEliminatorRule {\n\t// Whether the planner should automatically prune old node when there is at least 1 equivalent rel generated by the rule.\n\tboolean autoPruneOld();\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "UnionEliminatorRule checks to see if its possible to optimize a Union call by eliminating the Union operator altogether in the case the call consists of only one input."}
{"index": 4833, "repo": "calcite-core-1.34.0", "code": "Interface UnionEliminatorRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault UnionEliminatorRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault UnionEliminatorRule.Config withOperandFor(Class<? extends Union> unionClass);\n}", "des": "Rule configuration."}
{"index": 4834, "repo": "calcite-core-1.34.0", "code": "Class UnionMergeRule {\n\t// Returns whether this rule could possibly match the given operands.\n\tboolean matches(RelOptRuleCall call);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "UnionMergeRule implements the rule for combining two non-distinct SetOps into a single SetOp."}
{"index": 4835, "repo": "calcite-core-1.34.0", "code": "Interface UnionMergeRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault UnionMergeRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault UnionMergeRule.Config withOperandFor(Class<? extends RelNode> setOpClass);\n}", "des": "Rule configuration."}
{"index": 4836, "repo": "calcite-core-1.34.0", "code": "Interface UnionPullUpConstantsRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault UnionPullUpConstantsRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault UnionPullUpConstantsRule.Config withOperandFor(Class<? extends Union> unionClass);\n}", "des": "Rule configuration."}
{"index": 4837, "repo": "calcite-core-1.34.0", "code": "Interface UnionToDistinctRule.Config {\n\t// Creates a rule that uses this configuration.\n\tdefault UnionToDistinctRule toRule();\n\t// Defines an operand tree for the given classes.\n\tdefault UnionToDistinctRule.Config withOperandFor(Class<? extends Union> unionClass);\n}", "des": "Rule configuration."}
{"index": 4838, "repo": "calcite-core-1.34.0", "code": "Class UnpivotScope {\n\t// By analogy with ListScope.getChildren(), but this scope only has one namespace, and it is anonymous.\n\tSqlValidatorNamespace getChild();\n\t// Returns the root node of this scope.\n\tSqlUnpivot getNode();\n}", "des": "Scope for expressions in an UNPIVOT clause."}
{"index": 4839, "repo": "calcite-core-1.34.0", "code": "Class Unsafe {\n\t// Clears the contents of a StringWriter.\n\tstatic void clear(StringWriter sw);\n\t// Calls Object.notifyAll().\n\tstatic void notifyAll(Object o);\n\t// Helper for the SQL REGEXP_REPLACE function.\n\tstatic String regexpReplace(String s, Pattern pattern, String replacement, int pos, int occurrence);\n\t// Calls System.exit(int).\n\tstatic void systemExit(int status);\n\t// Calls Object.wait().\n\tstatic void wait(Object o);\n}", "des": "Contains methods that call JDK methods that the forbidden APIs checker does not approve of."}
{"index": 4840, "repo": "calcite-core-1.34.0", "code": "Class ValuesReduceRule {\n\t// Does the work.\n\tprotected void apply(RelOptRuleCall call, @Nullable LogicalProject project, @Nullable LogicalFilter filter, LogicalValues values);\n\t// Receives notification about a rule match.\n\tvoid onMatch(RelOptRuleCall call);\n}", "des": "Planner rule that folds projections and filters into an underlying LogicalValues."}
{"index": 4841, "repo": "calcite-core-1.34.0", "code": "Interface ValuesReduceRule.Config {\n\t// Forwards a call to RelOptRule.onMatch(RelOptRuleCall).\n\tRelRule.MatchHandler<ValuesReduceRule> matchHandler();\n\t// Creates a rule that uses this configuration.\n\tdefault ValuesReduceRule toRule();\n\t// Sets matchHandler().\n\tValuesReduceRule.Config withMatchHandler(RelRule.MatchHandler<ValuesReduceRule> matchHandler);\n\t// Defines an operand tree for the given classes.\n\tdefault ValuesReduceRule.Config withOperandFor(Class<? extends RelNode> relClass);\n}", "des": "Rule configuration."}
{"index": 4842, "repo": "calcite-core-1.34.0", "code": "Class VerticaSqlDialect {\n\t// Returns whether this dialect supports a given function or operator.\n\tboolean supportsFunction(SqlOperator operator, RelDataType type, List<RelDataType> paramTypes);\n\t// Returns whether the dialect supports nested aggregations, for instance SELECT SUM(SUM(1)) .\n\tboolean supportsNestedAggregations();\n}", "des": "A SqlDialect implementation for the Vertica database."}
{"index": 4843, "repo": "calcite-core-1.34.0", "code": "Class VolcanoRuleCall {\n\t// Called when all operands have matched.\n\tprotected void onMatch();\n\t// Registers that a rule has produced an equivalent relational expression.\n\tvoid transformTo(RelNode rel, Map<RelNode,RelNode> equiv, RelHintsPropagator handler);\n}", "des": "VolcanoRuleCall implements the RelOptRuleCall interface for VolcanoPlanner."}
{"index": 4844, "repo": "calcite-core-1.34.0", "code": "Class WinAggAddContextImpl {\n\t// Returns Linq4j form of arguments.\n\tList<org.apache.calcite.linq4j.tree.Expression> arguments();\n\t// Returns a RexToLixTranslator suitable to transform the arguments.\n\tRexToLixTranslator rowTranslator();\n}", "des": "Implementation of WinAggAddContext."}
{"index": 4845, "repo": "calcite-core-1.34.0", "code": "Enum WinAggImplementor.SeekType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WinAggImplementor.SeekType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WinAggImplementor.SeekType[] values();\n}", "des": "Allows to access rows in window partition relative to first/last and current row."}
{"index": 4846, "repo": "calcite-core-1.34.0", "code": "Interface WinAggResultContext {\n\t// Returns Linq4j form of arguments.\n\tList<org.apache.calcite.linq4j.tree.Expression> arguments(org.apache.calcite.linq4j.tree.Expression rowIndex);\n\t// Returns RexNode representation of arguments.\n\tList<RexNode> rexArguments();\n}", "des": "Information for a call to AggImplementor.implementResult(AggContext, AggResultContext)."}
{"index": 4847, "repo": "calcite-core-1.34.0", "code": "Class Window.Group {\n\tRelCollation collation();\n\tboolean equals(@Nullable Object obj);\n\t// Presents a view of the Window.RexWinAggCall list as a list of AggregateCall.\n\tList<AggregateCall> getAggregateCalls(Window windowRel);\n\t// Returns if the window is guaranteed to have rows.\n\tboolean isAlwaysNonEmpty();\n}", "des": "Group of windowed aggregate calls that have the same window specification."}
{"index": 4848, "repo": "mahout-math-0.13.0", "code": "Class AbstractObjectList<T> {\n\t// Appends all of the elements of the specified Collection to the receiver.\n\tvoid addAllOf(Collection<T> collection);\n\t// Inserts all elements of the specified collection before the specified position into the receiver.\n\tvoid beforeInsertAllOf(int index, Collection<T> collection);\n\t// Replaces the part of the receiver starting at from (inclusive) with all the elements of the specified collection.\n\tabstract void replaceFromWith(int from, Collection<T> other);\n}", "des": "Abstract base class for resizable lists holding objects or primitive data types such as int, float, etc.First see the package summary and javadoc tree view to get the broad picture."}
{"index": 4849, "repo": "mahout-math-0.13.0", "code": "Class Arithmetic {\n\t// Efficiently returns the binomial coefficient, often also referred to as \"n over k\" or \"n choose k\".\n\tstatic double binomial(long n, long k);\n\t// Returns log(k!).\n\tstatic double logFactorial(int k);\n}", "des": "Arithmetic functions."}
{"index": 4850, "repo": "mahout-math-0.13.0", "code": "Enum BackEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BackEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BackEnum[] values();\n}", "des": "Matrix backends"}
{"index": 4851, "repo": "mahout-math-0.13.0", "code": "Interface ByteComparator {\n\t// Compares its two arguments for order.\n\tint compare(byte o1, byte o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 4852, "repo": "mahout-math-0.13.0", "code": "Class Centroid {\n\tvoid addWeight(double newWeight);\n\t// Return a copy of the recipient\n\tCentroid clone();\n\tstatic Centroid create(int key, Vector initialValue);\n\t// Return an empty vector of the same underlying class as the receiver\n\tCentroid like();\n\tvoid update(Vector v);\n\tvoid update(Vector other, double wy);\n}", "des": "A centroid is a weighted vector. We have it delegate to the vector itself for lots of operations to make it easy to use vector search classes and such."}
{"index": 4853, "repo": "mahout-math-0.13.0", "code": "Interface CharComparator {\n\t// Compares its two arguments for order.\n\tint compare(char o1, char o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 4854, "repo": "mahout-math-0.13.0", "code": "Class CholeskyDecomposition {\n\tint[] getInversePivot();\n\tMatrix getL();\n\tPivotedMatrix getPermutedL();\n\tint[] getPivot();\n\tboolean isPositiveDefinite();\n\t// Compute inv(L) * z efficiently.\n\tMatrix solveLeft(Matrix z);\n\t// Compute z * inv(L') efficiently\n\tMatrix solveRight(Matrix z);\n}", "des": "Cholesky decomposition shamelessly ported from JAMA."}
{"index": 4855, "repo": "mahout-math-0.13.0", "code": "Class DenseSymmetricMatrix {\n\t// Return the value at the given indexes, without checking bounds\n\tdouble getQuick(int row, int column);\n\t// Set the value at the given index, without checking bounds\n\tvoid setQuick(int row, int column, double value);\n}", "des": "Economy packaging for a dense symmetric in-core matrix."}
{"index": 4856, "repo": "mahout-math-0.13.0", "code": "Interface DoubleComparator {\n\t// Compares its two arguments for order.\n\tint compare(double o1, double o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 4857, "repo": "mahout-math-0.13.0", "code": "Class EigenDecomposition {\n\t// Return the block diagonal eigenvalue matrix\n\tMatrix getD();\n\t// Return the imaginary parts of the eigenvalues\n\tVector getImagEigenvalues();\n\t// Return the real parts of the eigenvalues\n\tVector getRealEigenvalues();\n\t// Return the eigenvector matrix\n\tMatrix getV();\n}", "des": "Eigenvalues and eigenvectors of a real matrix."}
{"index": 4858, "repo": "mahout-math-0.13.0", "code": "Interface FloatComparator {\n\t// Compares its two arguments for order.\n\tint compare(float o1, float o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 4859, "repo": "mahout-math-0.13.0", "code": "Class HebbianSolver {\n\t// Uses the SingularVectorVerifier to check for convergence\n\tprotected boolean hasNotConverged(Vector currentPseudoEigen, Matrix corpus, TrainingState state);\n\tstatic void main(String[] args);\n\t// Primary singular vector solving method.\n\tTrainingState solve(Matrix corpus, int desiredRank);\n\tprotected EigenStatus verify(Matrix corpus, Vector currentPseudoEigen);\n}", "des": "The Hebbian solver is an iterative, sparse, singular value decomposition solver, based on the paper Generalized Hebbian Algorithm for Latent Semantic Analysis (2005) by Genevieve Gorrell and Brandyn Webb (a.k.a. Simon Funk). TODO: more description here! For now: read the inline comments, and the comments for the constructors."}
{"index": 4860, "repo": "mahout-math-0.13.0", "code": "Interface IntComparator {\n\t// Compares its two arguments for order.\n\tint compare(int o1, int o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 4861, "repo": "mahout-math-0.13.0", "code": "Interface LongComparator {\n\t// Compares its two arguments for order.\n\tint compare(long o1, long o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 4862, "repo": "mahout-math-0.13.0", "code": "Interface MatrixFlavor {\n\t// Whether matrix is backed by a native system -- such as java memory, lapack/atlas, Magma etc.\n\tBackEnum getBacking();\n\t// Structure flavors\n\tTraversingStructureEnum getStructure();\n\tboolean isDense();\n}", "des": "A set of matrix structure properties that I denote as \"flavor\" (by analogy to quarks)"}
{"index": 4863, "repo": "mahout-math-0.13.0", "code": "Interface MatrixTimesOps {\n\t// Computes matrix product of (that * this)\n\tMatrix timesLeft(Matrix that);\n\t// computes matrix product of (this * that)\n\tMatrix timesRight(Matrix that);\n}", "des": "Optional interface for optimized matrix multiplications. Some concrete Matrix implementations may mix this in."}
{"index": 4864, "repo": "mahout-math-0.13.0", "code": "Class Mult {\n\t// Returns the result of the function evaluation.\n\tdouble apply(double a);\n\t// a / constant.\n\tstatic Mult div(double constant);\n\tdouble getMultiplicator();\n\t// a * constant.\n\tstatic Mult mult(double constant);\n\tvoid setMultiplicator(double multiplicator);\n}", "des": "Only for performance tuning of compute intensive linear algebraic computations. Constructs functions that return one of a * constant a / constant a is variable, constant is fixed, but for performance reasons publicly accessible. Intended to be passed to matrix.assign(function) methods."}
{"index": 4865, "repo": "mahout-math-0.13.0", "code": "Class NegativeBinomial {\n\t// Returns the cumulative distribution function.\n\tdouble cdf(int k);\n\tint nextInt();\n\t// Returns a sample from this distribution.\n\tint nextInt(int r, double p);\n\t// Returns the probability distribution function.\n\tdouble pdf(int k);\n}", "des": "Mostly deprecated until unit tests are in place. Until this time, this class/interface is unsupported."}
{"index": 4866, "repo": "mahout-math-0.13.0", "code": "Class Normal {\n\t// Returns the cumulative distribution function.\n\tdouble cdf(double x);\n\t// Returns a random number from the distribution.\n\tdouble nextDouble();\n\t// Returns the probability density function.\n\tdouble pdf(double x);\n\t// Sets the uniform random generator internally used.\n\tvoid setRandomGenerator(Random randomGenerator);\n\t// Sets the mean and variance.\n\tvoid setState(double mean, double standardDeviation);\n}", "des": "Implements a normal distribution specified mean and standard deviation."}
{"index": 4867, "repo": "mahout-math-0.13.0", "code": "Class OldQRDecomposition {\n\t// Generates and returns the (economy-sized) orthogonal factor Q.\n\tMatrix getQ();\n\t// Returns the upper triangular factor, R.\n\tMatrix getR();\n\t// Returns whether the matrix A has full rank.\n\tboolean hasFullRank();\n\t// Least squares solution of A*X = B; returns X.\n\tMatrix solve(Matrix B);\n}", "des": "partially deprecated until unit tests are in place. Until this time, this class/interface is unsupported."}
{"index": 4868, "repo": "mahout-math-0.13.0", "code": "Class Polynomial {\n\t// Evaluates the given polynomial of degree N at x, assuming coefficient of N is 1.0.\n\tstatic double p1evl(double x, double[] coef, int N);\n\t// Evaluates the given polynomial of degree N at x.\n\tstatic double polevl(double x, double[] coef, int N);\n}", "des": "Polynomial functions."}
{"index": 4869, "repo": "mahout-math-0.13.0", "code": "Class QRDecomposition {\n\t// Generates and returns the (economy-sized) orthogonal factor Q.\n\tMatrix getQ();\n\t// Returns the upper triangular factor, R.\n\tMatrix getR();\n\t// Returns whether the matrix A has full rank.\n\tboolean hasFullRank();\n\t// Least squares solution of A*X = B; returns X.\n\tMatrix solve(Matrix B);\n}", "des": "For an m x n matrix A with m >= n, the QR decomposition is an m x n orthogonal matrix Q and an n x n upper triangular matrix R so that A = Q*R."}
{"index": 4870, "repo": "mahout-math-0.13.0", "code": "Class RandomEngine {\n\t// Equivalent to raw().\n\tdouble apply(double dummy);\n\t// Equivalent to nextInt().\n\tint apply(int dummy);\n\tdouble nextDouble();\n\tfloat nextFloat();\n\tabstract int nextInt();\n\tlong nextLong();\n\tdouble raw();\n}", "des": "Abstract base class for uniform pseudo-random number generating engines."}
{"index": 4871, "repo": "mahout-math-0.13.0", "code": "Interface ShortComparator {\n\t// Compares its two arguments for order.\n\tint compare(short o1, short o2);\n\t// Indicates whether some other object is \"equal to\" this Comparator.\n\tboolean equals(Object obj);\n}", "des": "A comparison function which imposes a total ordering on some collection of elements. Comparators can be passed to a sort method (such as org.apache.mahout.math.Sorting.quickSort) to allow precise control over the sort order."}
{"index": 4872, "repo": "mahout-math-0.13.0", "code": "Enum TraversingStructureEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TraversingStructureEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TraversingStructureEnum[] values();\n}", "des": "STRUCTURE HINT"}
{"index": 4873, "repo": "mahout-math-0.13.0", "code": "Class WeightedVector {\n\t// Return a copy of the recipient\n\tWeightedVector clone();\n\tint getIndex();\n\tdouble getWeight();\n\t// Return an empty vector of the same underlying class as the receiver\n\tVector like();\n\tstatic WeightedVector project(Vector v, Vector projection);\n\tstatic WeightedVector project(Vector v, Vector projection, int index);\n\tvoid setIndex(int index);\n\tvoid setWeight(double newWeight);\n}", "des": "Decorates a vector with a floating point weight and an index."}
{"index": 4874, "repo": "nifi-client-dto-1.22.0", "code": "Class BannerDTO {\n\t// The banner footer text.\n\tString getFooterText();\n\t// The banner header text.\n\tString getHeaderText();\n\tvoid setFooterText(String footerText);\n\tvoid setHeaderText(String headerText);\n}", "des": "Banners that should appear on the top and bottom of this NiFi."}
{"index": 4875, "repo": "nifi-client-dto-1.22.0", "code": "Class BundleDTO {\n\tboolean equals(Object o);\n\t// The artifact of the bundle.\n\tString getArtifact();\n\t// The group of the bundle.\n\tString getGroup();\n\t// The version of the bundle.\n\tString getVersion();\n\tvoid setArtifact(String artifact);\n\tvoid setGroup(String group);\n\tvoid setVersion(String version);\n}", "des": "Typed component within NiFi."}
{"index": 4876, "repo": "nifi-client-dto-1.22.0", "code": "Class ComponentDTO {\n\tboolean equals(Object obj);\n\t// The id for this component.\n\tString getId();\n\tString getParentGroupId();\n\t// The position of this component in the UI if applicable, null otherwise.\n\tPositionDTO getPosition();\n\tString getVersionedComponentId();\n\tvoid setId(String id);\n\tvoid setParentGroupId(String parentGroupId);\n\tvoid setPosition(PositionDTO position);\n\tvoid setVersionedComponentId(String id);\n}", "des": "Base class for all nifi components."}
{"index": 4877, "repo": "nifi-client-dto-1.22.0", "code": "Class FlowBreadcrumbDTO {\n\t// The id for this group.\n\tString getId();\n\t// The name for this group.\n\tString getName();\n\tVersionControlInformationDTO getVersionControlInformation();\n\tvoid setId(String id);\n\tvoid setName(String name);\n\tvoid setVersionControlInformation(VersionControlInformationDTO versionControlInformation);\n}", "des": "Breadcrumb for the flow."}
{"index": 4878, "repo": "nifi-client-dto-1.22.0", "code": "Class LabelEntity {\n\t// The LabelDTO that is being serialized.\n\tLabelDTO getComponent();\n\t// The dimensions of this label.\n\tDimensionsDTO getDimensions();\n\tLong getzIndex();\n\tvoid setComponent(LabelDTO component);\n\tvoid setDimensions(DimensionsDTO dimensions);\n\tvoid setzIndex(Long zIndex);\n}", "des": "A serialized representation of this class can be placed in the entity body of a request or response to or from the API. This particular entity holds a reference to a LabelDTO."}
{"index": 4879, "repo": "nifi-client-dto-1.22.0", "code": "Enum LineageRequestDTO.LineageRequestType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LineageRequestDTO.LineageRequestType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LineageRequestDTO.LineageRequestType[] values();\n}", "des": "The type of this lineage request."}
{"index": 4880, "repo": "nifi-client-dto-1.22.0", "code": "Class ParameterContextReferenceEntity {\n\t// The ParameterContextReferenceDTO that is being serialized.\n\tParameterContextReferenceDTO getComponent();\n\t// The id for this component.\n\tString getId();\n\t// The permissions for this component.\n\tPermissionsDTO getPermissions();\n\tvoid setComponent(ParameterContextReferenceDTO component);\n\tvoid setId(String id);\n\tvoid setPermissions(PermissionsDTO permissions);\n}", "des": "A serialized representation of this class can be placed in the entity body of a request or response to or from the API. This particular entity holds a reference to a ParameterContextReferenceDTO."}
{"index": 4881, "repo": "nifi-client-dto-1.22.0", "code": "Class ParameterProviderConfigurationEntity {\n\t// The ParameterProviderConfigurationDTO that is being serialized.\n\tParameterProviderConfigurationDTO getComponent();\n\t// The id for this component.\n\tString getId();\n\t// The permissions for this component.\n\tPermissionsDTO getPermissions();\n\tvoid setComponent(ParameterProviderConfigurationDTO component);\n\tvoid setId(String id);\n\tvoid setPermissions(PermissionsDTO permissions);\n}", "des": "A serialized representation of this class can be placed in the entity body of a request or response to or from the API. This particular entity holds a reference to a ParameterProviderConfigurationDTO."}
{"index": 4882, "repo": "nifi-client-dto-1.22.0", "code": "Class ProcessGroupFlowEntity {\n\t// The permissions for this component.\n\tPermissionsDTO getPermissions();\n\t// The ProcessGroupFlowDTO that is being serialized.\n\tProcessGroupFlowDTO getProcessGroupFlow();\n\tvoid setPermissions(PermissionsDTO permissions);\n\tvoid setProcessGroupFlow(ProcessGroupFlowDTO flow);\n}", "des": "A serialized representation of this class can be placed in the entity body of a request or response to or from the API. This particular entity holds a reference to a ProcessGroupFlowDTO."}
{"index": 4883, "repo": "nifi-client-dto-1.22.0", "code": "Class ProcessorEntity {\n\t// The ProcessorDTO that is being serialized.\n\tProcessorDTO getComponent();\n\tString getInputRequirement();\n\tPermissionsDTO getOperatePermissions();\n\t// The Processor status.\n\tProcessorStatusDTO getStatus();\n\tvoid setComponent(ProcessorDTO component);\n\tvoid setInputRequirement(String inputRequirement);\n\tvoid setOperatePermissions(PermissionsDTO operatePermissions);\n\tvoid setStatus(ProcessorStatusDTO status);\n}", "des": "A serialized representation of this class can be placed in the entity body of a request or response to or from the API. This particular entity holds a reference to a ProcessorDTO."}
{"index": 4884, "repo": "nifi-client-dto-1.22.0", "code": "Class ResourceDTO {\n\t// The identifier of the resource.\n\tString getIdentifier();\n\t// The name of the resource.\n\tString getName();\n\tvoid setIdentifier(String identifier);\n\tvoid setName(String name);\n}", "des": "Resource that supports access/authorization policies."}
{"index": 4885, "repo": "nifi-client-dto-1.22.0", "code": "Class RevisionDTO {\n\t// A client identifier used to make a request.\n\tString getClientId();\n\tString getLastModifier();\n\t// NiFi employs an optimistic locking strategy where the client must include a revision in their request when performing an update.\n\tLong getVersion();\n\tvoid setClientId(String clientId);\n\tvoid setLastModifier(String lastModifier);\n\tvoid setVersion(Long version);\n}", "des": "Current revision for this NiFi."}
{"index": 4886, "repo": "nifi-client-dto-1.22.0", "code": "Class TenantsEntity {\n\t// The collection of user groups that are being serialized.\n\tCollection<TenantEntity> getUserGroups();\n\t// The collection of users that are being serialized.\n\tCollection<TenantEntity> getUsers();\n\tvoid setUserGroups(Collection<TenantEntity> userGroups);\n\tvoid setUsers(Collection<TenantEntity> users);\n}", "des": "A serialized representation of this class can be placed in the entity body of a request or response to or from the API. This particular entity holds a reference to a collection of TenantEntity objects."}
{"index": 4887, "repo": "cassandra-all-4.1.2", "code": "Class AbstractMarker {\n\tvoid addFunctionsTo(java.util.List<Function> functions);\n\t// Collects the column specification for the bind variables in this Term.\n\tvoid collectMarkerSpecification(VariableSpecifications boundNames);\n\t// Whether or not that term contains at least one bind marker.\n\tboolean containsBindMarker();\n}", "des": "A single bind marker."}
{"index": 4888, "repo": "cassandra-all-4.1.2", "code": "Class AbstractMarker.Raw {\n\t// The type of the term if it can be infered.\n\tAbstractType<?> getExactTypeIfKnown(java.lang.String keyspace);\n\tjava.lang.String getText();\n\t// This method validates this RawTerm is valid for provided column specification and \"prepare\" this RawTerm, returning the resulting prepared Term.\n\tTerm.NonTerminal prepare(java.lang.String keyspace, ColumnSpecification receiver);\n\tAssignmentTestable.TestResult testAssignment(java.lang.String keyspace, ColumnSpecification receiver);\n}", "des": "A parsed, but non prepared, bind marker."}
{"index": 4889, "repo": "cassandra-all-4.1.2", "code": "Class AbstractMutableVirtualTable.ColumnValue {\n\t// Returns the column value corresponding to the specified cell.\n\tstatic AbstractMutableVirtualTable.ColumnValue from(Cell<?> cell);\n\t// Returns the column name.\n\tjava.lang.String name();\n\t// Returns the column value.\n\t<V> V value();\n}", "des": "A regular column value."}
{"index": 4890, "repo": "cassandra-all-4.1.2", "code": "Class AbstractNetworkTopologySnitch {\n\t// compares two endpoints in relation to the target endpoint, returning as Comparator.compare would\n\tint compareEndpoints(InetAddressAndPort address, Replica r1, Replica r2);\n\t// Return the data center for which an endpoint resides in\n\tabstract java.lang.String getDatacenter(InetAddressAndPort endpoint);\n\t// Return the rack for which an endpoint resides in\n\tabstract java.lang.String getRack(InetAddressAndPort endpoint);\n}", "des": "An endpoint snitch tells Cassandra information about network topology that it can use to route requests more efficiently."}
{"index": 4891, "repo": "cassandra-all-4.1.2", "code": "Class Accumulator<E> {\n\t// Adds an item to the collection.\n\tvoid add(E item);\n\tint capacity();\n\t// Removes element at the speficied index from this accumulator.\n\tvoid clearUnsafe(int i);\n\tE get(int i);\n\tboolean isEmpty();\n\tint size();\n\tjava.util.Collection<E> snapshot();\n}", "des": "A simple append-only collection supporting an unbounded number of concurrent readers/writers, but a bounded number of items."}
{"index": 4892, "repo": "cassandra-all-4.1.2", "code": "Class AggregateFcts {\n\tstatic java.util.Collection<AggregateFunction> all();\n\t// Creates a COUNT function for the specified type.\n\tstatic AggregateFunction makeCountFunction(AbstractType<?> inputType);\n\t// Creates a MAX function for the specified type.\n\tstatic AggregateFunction makeMaxFunction(AbstractType<?> inputType);\n\t// Creates a MIN function for the specified type.\n\tstatic AggregateFunction makeMinFunction(AbstractType<?> inputType);\n}", "des": "Factory methods for aggregate functions."}
{"index": 4893, "repo": "cassandra-all-4.1.2", "code": "Interface AggregateFunction.Aggregate {\n\t// Adds the specified input to this aggregate.\n\tvoid addInput(ProtocolVersion protocolVersion, java.util.List<java.nio.ByteBuffer> values);\n\t// Computes and returns the aggregate current value.\n\tjava.nio.ByteBuffer compute(ProtocolVersion protocolVersion);\n\t// Reset this aggregate.\n\tvoid reset();\n}", "des": "An aggregation operation."}
{"index": 4894, "repo": "cassandra-all-4.1.2", "code": "Enum AggregationSpecification.Kind {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AggregationSpecification.Kind valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AggregationSpecification.Kind[] values();\n}", "des": "The AggregationSpecification kinds."}
{"index": 4895, "repo": "cassandra-all-4.1.2", "code": "Class AlibabaCloudSnitch {\n\t// Return the data center for which an endpoint resides in\n\tjava.lang.String getDatacenter(InetAddressAndPort endpoint);\n\t// Return the rack for which an endpoint resides in\n\tjava.lang.String getRack(InetAddressAndPort endpoint);\n}", "des": "A snitch that assumes an ECS region is a DC and an ECS availability_zone is a rack. This information is available in the config for the node. the format of the zone-id is like :cn-hangzhou-a where cn means china, hangzhou means the hangzhou region, a means the az id. We use cn-hangzhou as the dc, and f as the zone-id."}
{"index": 4896, "repo": "cassandra-all-4.1.2", "code": "Enum ApplicationState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ApplicationState valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ApplicationState[] values();\n}", "des": "The various \"states\" exchanged through Gossip."}
{"index": 4897, "repo": "cassandra-all-4.1.2", "code": "Class AsyncMessageOutputPlus {\n\t// Flush any remaining writes, and release any buffers.\n\tvoid close();\n\t// Discard any buffered data, and the buffers that contain it.\n\tvoid discard();\n\tprotected void doFlush(int count);\n\t// Returns the current position of the underlying target like a file-pointer or the position withing a buffer.\n\tlong position();\n}", "des": "A DataOutputStreamPlus that writes ASYNCHRONOUSLY to a Netty Channel. Intended as single use, to write one (large) message. The close() and flush() methods synchronously wait for pending writes, and will propagate any exceptions encountered in writing them to the wire. The correctness of this class depends on the ChannelPromise we create against a Channel always being completed, which appears to be a guarantee provided by Netty so long as the event loop is running."}
{"index": 4898, "repo": "cassandra-all-4.1.2", "code": "Class AuditEvent {\n\tAuditLogEntry getEntry();\n\tjava.lang.String getSource();\n\t// Returns event type discriminator.\n\tjava.lang.Enum<?> getType();\n\t// Returns map of key-value pairs containing relevant event details.\n\tjava.util.Map<java.lang.String,java.io.Serializable> toMap();\n}", "des": "wrapper to expose audit events as DiagnosticEvents."}
{"index": 4899, "repo": "cassandra-all-4.1.2", "code": "Enum AuditLogEntryCategory {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AuditLogEntryCategory valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AuditLogEntryCategory[] values();\n}", "des": "Enum to categorize AuditLogEntries"}
{"index": 4900, "repo": "cassandra-all-4.1.2", "code": "Class Awaitable.AsyncAwaitable {\n\t// Awaitable.await()\n\tAwaitable await();\n\t// Awaitable.awaitUntil(long)\n\tboolean awaitUntil(long nanoTimeDeadline);\n\t// Return true once signalled.\n\tprotected abstract boolean isSignalled();\n\t// Signal any waiting threads; isSignalled() must return true before this method is invoked.\n\tprotected void signal();\n}", "des": "A barebones asynchronous Awaitable. If your state is minimal, or can be updated concurrently, extend this class."}
{"index": 4901, "repo": "cassandra-all-4.1.2", "code": "Class Awaitable.SyncAwaitable {\n\t// Awaitable.await()\n\tAwaitable await();\n\t// Awaitable.awaitUntil(long)\n\tboolean awaitUntil(long nanoTimeDeadline);\n\t// Return true once signalled.\n\tprotected abstract boolean isSignalled();\n\tstatic boolean waitUntil(java.lang.Object monitor, long deadlineNanos);\n}", "des": "A barebones Awaitable that uses mutual exclusion. If your state will be updated while holding the object monitor, extend this class."}
{"index": 4902, "repo": "cassandra-all-4.1.2", "code": "Enum BTree.Dir {\n\tstatic BTree.Dir desc(boolean desc);\n\tBTree.Dir invert();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BTree.Dir valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BTree.Dir[] values();\n}", "des": "Represents the direction of iteration."}
{"index": 4903, "repo": "cassandra-all-4.1.2", "code": "Class ByteBufferCloner {\n\t// Allocate a slice of the given length.\n\tabstract java.nio.ByteBuffer allocate(int size);\n\tjava.nio.ByteBuffer clone(byte[] bytes);\n\tjava.nio.ByteBuffer clone(java.nio.ByteBuffer buffer);\n\t// Clones the specified cell.\n\tCell<?> clone(Cell<?> cell);\n\t// Clones the specified clustering.\n\tClustering<?> clone(Clustering<?> clustering);\n\t// Clones the specified key.\n\tDecoratedKey clone(DecoratedKey key);\n\t<V> java.nio.ByteBuffer clone(V value, ValueAccessor<V> accessor);\n}", "des": "Cloner class that can be use to clone partition elements using on-heap or off-heap buffers."}
{"index": 4904, "repo": "cassandra-all-4.1.2", "code": "Class Bytes {\n\t// Parse an hex string representing a CQL blob.\n\tstatic java.nio.ByteBuffer fromHexString(java.lang.String str);\n\t// Extract the content of the provided ByteBuffer as a byte array.\n\tstatic byte[] getArray(java.nio.ByteBuffer bytes);\n\t// Converts a blob to its CQL hex string representation.\n\tstatic java.lang.String toHexString(byte[] byteArray);\n\t// Converts a blob to its CQL hex string representation.\n\tstatic java.lang.String toHexString(java.nio.ByteBuffer bytes);\n}", "des": "Simple utility methods to make working with bytes (blob) easier."}
{"index": 4905, "repo": "cassandra-all-4.1.2", "code": "Interface CachedPartition {\n\t// The number of rows that were live at the time the partition was cached.\n\tint cachedLiveRows();\n\t// The last row in this cached partition (in order words, the row with the biggest clustering that the partition contains).\n\tRow lastRow();\n\t// The number of Row objects in this cached partition.\n\tint rowCount();\n\t// The number of rows in this cached partition that have at least one non-expiring non-deleted cell.\n\tint rowsWithNonExpiringCells();\n}", "des": "A partition stored in the partition cache. Note that in practice, the only implementation of this is CachedBTreePartition, we keep this interface mainly to make it clear what we need from partition in the cache (that we don't otherwise)"}
{"index": 4906, "repo": "cassandra-all-4.1.2", "code": "Interface CASRequest {\n\t// Returns whether the provided CF, that represents the values fetched using the readFilter(), match the CAS conditions this object stands for.\n\tboolean appliesTo(FilteredPartition current);\n\t// The updates to perform of a CAS success.\n\tPartitionUpdate makeUpdates(FilteredPartition current, ClientState clientState, Ballot ballot);\n\t// The command to use to fetch the value to compare for the CAS.\n\tSinglePartitionReadCommand readCommand(int nowInSec);\n}", "des": "Abstract the conditions and updates for a CAS operation."}
{"index": 4907, "repo": "cassandra-all-4.1.2", "code": "Class CassandraPrincipal {\n\t// Compares the specified Object with this CassPrincipal for equality.\n\tboolean equals(java.lang.Object o);\n\t// Return the username for this CassPrincipal.\n\tjava.lang.String getName();\n}", "des": ""}
{"index": 4908, "repo": "cassandra-all-4.1.2", "code": "Class CassandraStreamWriter {\n\tprotected long totalSize();\n\t// Sequentially read bytes from the file and write them to the output stream\n\tprotected long write(ChannelProxy proxy, DataIntegrityMetadata.ChecksumValidator validator, StreamingDataOutputPlus output, long start, int transferOffset, int toTransfer, int bufferSize);\n\t// Stream file of specified sections to given channel.\n\tvoid write(StreamingDataOutputPlus out);\n}", "des": "CassandraStreamWriter writes given section of the SSTable to given channel."}
{"index": 4909, "repo": "cassandra-all-4.1.2", "code": "Class CastFcts {\n\tstatic java.util.Collection<Function> all();\n\t// Creates the name of the cast function use to cast to the specified type.\n\tstatic java.lang.String getFunctionName(AbstractType<?> outputType);\n\t// Creates the name of the cast function use to cast to the specified type.\n\tstatic java.lang.String getFunctionName(CQL3Type outputType);\n}", "des": "Casting functions"}
{"index": 4910, "repo": "cassandra-all-4.1.2", "code": "Interface ChunkReader {\n\t// Buffer size required for this rebufferer.\n\tint chunkSize();\n\t// Specifies type of buffer the caller should attempt to give.\n\tBufferType preferredBufferType();\n\t// Read the chunk at the given position, attempting to fill the capacity of the given buffer.\n\tvoid readChunk(long position, java.nio.ByteBuffer buffer);\n}", "des": "RandomFileReader component that reads data from a file into a provided buffer and may have requirements over the size and alignment of reads. A caching or buffer-managing rebufferer will reference one of these to do the actual reading. Note: Implementations of this interface must be thread-safe!"}
{"index": 4911, "repo": "cassandra-all-4.1.2", "code": "Interface Clock {\n\t// Semantically equivalent to System.currentTimeMillis()\n\tlong currentTimeMillis();\n\t// Semantically equivalent to System.nanoTime()\n\tlong nanoTime();\n\tstatic void waitUntil(long deadlineNanos);\n}", "des": "Wrapper around time related functions that are either implemented by using the default JVM calls or by using a custom implementation for testing purposes. See Clock.Global.instance for how to use a custom implementation. Please note that Clock wasn't used, as it would not be possible to provide an implementation for nanoTime() with the exact same properties of System.nanoTime()."}
{"index": 4912, "repo": "cassandra-all-4.1.2", "code": "Interface Cloner {\n\t// Clones the specified cell.\n\tCell<?> clone(Cell<?> cell);\n\t// Clones the specified clustering.\n\tClustering<?> clone(Clustering<?> clustering);\n\t// Clones the specified key.\n\tDecoratedKey clone(DecoratedKey key);\n}", "des": "Allow cloning of partition elements"}
{"index": 4913, "repo": "cassandra-all-4.1.2", "code": "Class CloudstackSnitch {\n\t// Return the data center for which an endpoint resides in\n\tjava.lang.String getDatacenter(InetAddressAndPort endpoint);\n\t// Return the rack for which an endpoint resides in\n\tjava.lang.String getRack(InetAddressAndPort endpoint);\n}", "des": "A snitch that assumes a Cloudstack Zone follows the typical convention -- and uses the country/location tuple as a datacenter and the availability zone as a rack"}
{"index": 4914, "repo": "cassandra-all-4.1.2", "code": "Class CollectionEntryIndex {\n\t// Extract the value to be inserted into the index from the components of the base data\n\tjava.nio.ByteBuffer getIndexedValue(java.nio.ByteBuffer partitionKey, Clustering<?> clustering, CellPath path, java.nio.ByteBuffer cellValue);\n\t// Check whether a value retrieved from an index is still valid by comparing it to current row from the base table.\n\tboolean isStale(Row data, java.nio.ByteBuffer indexValue, int nowInSec);\n}", "des": "Index on the element and value of cells participating in a collection. The row keys for this index are a composite of the collection element and value of indexed columns."}
{"index": 4915, "repo": "cassandra-all-4.1.2", "code": "Class CollectionKeyIndexBase {\n\t// Used to construct an the clustering for an entry in the index table based on values from the base data.\n\t<T> CBuilder buildIndexClusteringPrefix(java.nio.ByteBuffer partitionKey, ClusteringPrefix<T> prefix, CellPath path);\n\t// Used at search time to convert a row in the index table into a simple struct containing the values required to retrieve the corresponding row from the base table.\n\tIndexEntry decodeEntry(DecoratedKey indexedValue, Row indexEntry);\n}", "des": "Common superclass for indexes that capture collection keys, including indexes on such keys themselves. A cell indexed by this index will have the general form: ck_0 ... ck_n c_name [col_elt] : v where ck_i are the cluster keys, c_name the CQL3 column name, col_elt the collection element that we want to index (which may or may not be there depending on whether c_name is the collection we're indexing), and v the cell value. Such a cell is indexed if c_name is the indexed collection (in which case we are guaranteed to have col_elt). The index entry can be viewed in the following way: - the row key is determined by subclasses of this type. - the cell name will be 'rk ck_0 ... ck_n' where rk is the row key of the initial cell."}
{"index": 4916, "repo": "cassandra-all-4.1.2", "code": "Enum ColumnFamilyStore.FlushReason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ColumnFamilyStore.FlushReason valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ColumnFamilyStore.FlushReason[] values();\n}", "des": "Reason for initiating a memtable flush."}
{"index": 4917, "repo": "cassandra-all-4.1.2", "code": "Enum ColumnMetadata.Kind {\n\tboolean isPrimaryKeyKind();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ColumnMetadata.Kind valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ColumnMetadata.Kind[] values();\n}", "des": "The type of CQL3 column this definition represents. There is 4 main type of CQL3 columns: those parts of the partition key, those parts of the clustering columns and amongst the others, regular and static ones. IMPORTANT: this enum is serialized as toString() and deserialized by calling Kind.valueOf(), so do not override toString() or rename existing values."}
{"index": 4918, "repo": "cassandra-all-4.1.2", "code": "Enum Component.Type {\n\tstatic Component.Type fromRepresentation(java.lang.String repr);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Component.Type valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Component.Type[] values();\n}", "des": "WARNING: Be careful while changing the names or string representation of the enum members. Streaming code depends on the names during streaming (Ref: CASSANDRA-14556)."}
{"index": 4919, "repo": "cassandra-all-4.1.2", "code": "Class CompressedInputStream {\n\tvoid close();\n\t// Invoked when crossing into the next SSTableReader.PartitionPositionBounds section in CassandraCompressedStreamReader.read(DataInputPlus).\n\tvoid position(long position);\n\t// Implementations must implement this method to refill the buffer.\n\tprotected void reBuffer();\n}", "des": "InputStream which reads compressed chunks from the underlying input stream and deals with decompression and position tracking. The underlying input will be an instance of RebufferingInputStream except in some unit tests. Compressed chunks transferred will be a subset of all chunks in the source streamed sstable - just enough to deserialize the requested partition position ranges. Correctness of the entire operation depends on provided partition position ranges and compressed chunks properly matching, and there is no way on the receiving side to verify if that's the case, which arguably makes this a little brittle."}
{"index": 4920, "repo": "cassandra-all-4.1.2", "code": "Class CompressionInfo {\n\t// Returns the offset and length of the file chunks.\n\tabstract CompressionMetadata.Chunk[] chunks();\n\tboolean equals(java.lang.Object o);\n\t// Computes the size of the file to transfer.\n\tlong getTotalSize();\n\t// Create a CompressionInfo instance which is fully initialized.\n\tstatic CompressionInfo newInstance(CompressionMetadata.Chunk[] chunks, CompressionParams parameters);\n\t// Returns the compression parameters.\n\tabstract CompressionParams parameters();\n}", "des": "Container that carries compression parameters and chunks to decompress data from stream."}
{"index": 4921, "repo": "cassandra-all-4.1.2", "code": "Interface Condition {\n\t// Returns true once signalled.\n\tboolean isSignalled();\n\t// Factory method used to capture and redirect instantiations for simulation\n\tstatic Condition newOneTimeCondition();\n\t// Signal the condition as met, and wake all waiting threads.\n\tvoid signal();\n\t// Signal the condition as met, and wake all waiting threads.\n\tdefault void signalAll();\n}", "des": "Simpler API than java.util.concurrent.Condition; would be nice to extend it, but also nice to share API with Future, for which Netty's API is incompatible with java.util.concurrent.Condition Awaitable for explicit external signals."}
{"index": 4922, "repo": "cassandra-all-4.1.2", "code": "Class Condition.Async {\n\t// Return true once signalled.\n\tboolean isSignalled();\n\t// Signal any waiting threads; Awaitable.AsyncAwaitable.isSignalled() must return true before this method is invoked.\n\tvoid signal();\n}", "des": "An asynchronous Condition. Typically lower overhead than Condition.Sync."}
{"index": 4923, "repo": "cassandra-all-4.1.2", "code": "Class Condition.Sync {\n\t// Return true once signalled.\n\tboolean isSignalled();\n\t// Signal the condition as met, and wake all waiting threads.\n\tvoid signal();\n}", "des": "A Condition based on its object monitor. WARNING: lengthy operations performed while holding the lock may prevent timely notification of waiting threads that a deadline has passed."}
{"index": 4924, "repo": "cassandra-all-4.1.2", "code": "Enum Config.PaxosOnLinearizabilityViolation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Config.PaxosOnLinearizabilityViolation valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Config.PaxosOnLinearizabilityViolation[] values();\n}", "des": "A safety mechanism for detecting incorrect paxos state, that may be down either to a bug or incorrect usage of LWTs (most likely due to unsafe mixing of SERIAL and LOCAL_SERIAL operations), and rejecting"}
{"index": 4925, "repo": "cassandra-all-4.1.2", "code": "Enum Config.PaxosStatePurging {\n\tstatic Config.PaxosStatePurging fromBoolean(boolean enabled);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Config.PaxosStatePurging valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Config.PaxosStatePurging[] values();\n}", "des": "Select the kind of paxos state purging to use. Migration to repaired is recommended, but requires that regular paxos repairs are performed (which by default run as part of incremental repair). Once migrated from legacy it is unsafe to return to legacy, but gc_grace mode may be used in its place and performs a very similar cleanup process. Should only be modified once paxos_variant = v2."}
{"index": 4926, "repo": "cassandra-all-4.1.2", "code": "Enum Config.PaxosVariant {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Config.PaxosVariant valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Config.PaxosVariant[] values();\n}", "des": "The variants of paxos implementation and semantics supported by Cassandra."}
{"index": 4927, "repo": "cassandra-all-4.1.2", "code": "Enum ConsistentSession.State {\n\tboolean canTransitionTo(ConsistentSession.State state);\n\tstatic ConsistentSession.State valueOf(int ordinal);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConsistentSession.State valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConsistentSession.State[] values();\n}", "des": "The possible states of a ConsistentSession. The typical progression is PREPARING, PREPARED, REPAIRING, FINALIZE_PROMISED, and FINALIZED. With the exception of FINALIZED, any state can be transitions to FAILED."}
{"index": 4928, "repo": "cassandra-all-4.1.2", "code": "Enum Cursor.Decision {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Cursor.Decision valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Cursor.Decision[] values();\n}", "des": "The Cursor.Decision tells the Cursor what to do on each step while traversing the Trie. NOTE: Not all operations that work with a Cursor support all Cursor.Decision types"}
{"index": 4929, "repo": "cassandra-all-4.1.2", "code": "Interface DataInputPlus {\n\t// Think hard before opting for an unsigned encoding.\n\tdefault long readUnsignedVInt();\n\tdefault long readVInt();\n\t// Always skips the requested number of bytes, unless EOF is reached\n\tint skipBytes(int n);\n\tdefault void skipBytesFully(int n);\n}", "des": "Extension to DataInput that provides support for reading varints"}
{"index": 4930, "repo": "cassandra-all-4.1.2", "code": "Class DataStorageSpec.IntKibibytesBound {\n\t// Returns the amount of data storage in bytes as an int\n\tint toBytes();\n\tlong toBytesInLong();\n\t// Returns the amount of data storage in kibibytes as an int\n\tint toKibibytes();\n}", "des": "Represents a data storage quantity used for Cassandra configuration. The bound is [0, Integer.MAX_VALUE) in kibibytes. If the user sets a different unit - we still validate that converted to kibibytes the quantity will not exceed that upper bound. (CASSANDRA-17571)"}
{"index": 4931, "repo": "cassandra-all-4.1.2", "code": "Class DataStorageSpec.IntMebibytesBound {\n\t// Returns the amount of data storage in bytes as an int\n\tint toBytes();\n\t// Returns the amount of data storage in bytes as long\n\tlong toBytesInLong();\n\t// Returns the amount of data storage in kibibytes as an int\n\tint toKibibytes();\n\t// Returns the amount of data storage in mebibytes as an int\n\tint toMebibytes();\n}", "des": "Represents a data storage quantity used for Cassandra configuration. The bound is [0, Integer.MAX_VALUE) in mebibytes. If the user sets a different unit - we still validate that converted to mebibytes the quantity will not exceed that upper bound. (CASSANDRA-17571)"}
{"index": 4932, "repo": "cassandra-all-4.1.2", "code": "Class DataType.CollectionType {\n\t// Returns a String representation of this data type suitable for inclusion as a parameter type in a function or aggregate signature.\n\tjava.lang.String asFunctionParameterString();\n\tboolean equals(java.lang.Object o);\n\t// Returns the type arguments of this type.\n\tjava.util.List<DataType> getTypeArguments();\n\t// Returns whether this data type is frozen.\n\tboolean isFrozen();\n}", "des": "Instances of this class represent collection types, that is, lists, sets or maps."}
{"index": 4933, "repo": "cassandra-all-4.1.2", "code": "Enum DataType.Name {\n\t// Return true if the provided Name is equal to this one, or if they are aliases for each other, and false otherwise.\n\tboolean isCompatibleWith(DataType.Name that);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DataType.Name valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DataType.Name[] values();\n}", "des": "The CQL type name."}
{"index": 4934, "repo": "cassandra-all-4.1.2", "code": "Class DefaultCompactionWriter {\n\t// estimated number of keys we should write\n\tlong estimatedKeys();\n\tboolean realAppend(UnfilteredRowIterator partition);\n\t// Implementations of this method should finish the current sstable writer and start writing to this directory.\n\tvoid switchCompactionLocation(Directories.DataDirectory directory);\n}", "des": "The default compaction writer - creates one output file in L0"}
{"index": 4935, "repo": "cassandra-all-4.1.2", "code": "Class DescribeStatement.Element {\n\t// Returns the schema elements that must be part of the output.\n\tprotected java.util.stream.Stream<? extends SchemaElement> describe(ClientState state, Keyspaces keyspaces);\n\t// Returns the columns of the ResultMetadata\n\tprotected java.util.List<ColumnSpecification> metadata(ClientState state);\n\tprotected java.util.List<java.nio.ByteBuffer> toRow(SchemaElement element, boolean withInternals);\n}", "des": "DescribeStatement implementation used for describe queries for a single schema element."}
{"index": 4936, "repo": "cassandra-all-4.1.2", "code": "Class DescribeStatement.Listing {\n\t// Returns the schema elements that must be part of the output.\n\tprotected java.util.stream.Stream<? extends SchemaElement> describe(ClientState state, Keyspaces keyspaces);\n\t// Returns the columns of the ResultMetadata\n\tprotected java.util.List<ColumnSpecification> metadata(ClientState state);\n\tprotected java.util.List<java.nio.ByteBuffer> toRow(SchemaElement element, boolean withInternals);\n}", "des": "DescribeStatement implementation used for describe queries that only list elements names."}
{"index": 4937, "repo": "cassandra-all-4.1.2", "code": "Enum DeserializationHelper.Flag {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DeserializationHelper.Flag valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DeserializationHelper.Flag[] values();\n}", "des": "Flag affecting deserialization behavior (this only affect counters in practice). - LOCAL: for deserialization of local data (Expired columns are converted to tombstones (to gain disk space)). - FROM_REMOTE: for deserialization of data received from remote hosts (Expired columns are converted to tombstone and counters have their delta cleared) - PRESERVE_SIZE: used when no transformation must be performed, i.e, when we must ensure that deserializing and reserializing the result yield the exact same bytes. Streaming uses this."}
{"index": 4938, "repo": "cassandra-all-4.1.2", "code": "Class DiagnosticEvent {\n\t// Returns event type discriminator.\n\tabstract java.lang.Enum<?> getType();\n\t// Returns map of key-value pairs containing relevant event details.\n\tabstract java.util.Map<java.lang.String,java.io.Serializable> toMap();\n}", "des": "Base class for internally emitted events used for diagnostics and testing."}
{"index": 4939, "repo": "cassandra-all-4.1.2", "code": "Enum Directories.FileType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Directories.FileType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Directories.FileType[] values();\n}", "des": "The type of files that can be listed by SSTableLister, we never return txn logs, use LifecycleTransaction.getFiles() if you need txn logs."}
{"index": 4940, "repo": "cassandra-all-4.1.2", "code": "Enum Directories.OnTxnErr {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Directories.OnTxnErr valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Directories.OnTxnErr[] values();\n}", "des": "How to handle a failure to read a txn log file. Note that we will try a few times before giving up."}
{"index": 4941, "repo": "cassandra-all-4.1.2", "code": "Class DisableFlag {\n\t// Aborts the operation if this guardrail is disabled.\n\tvoid ensureEnabled(ClientState state);\n\t// Aborts the operation if this guardrail is disabled.\n\tvoid ensureEnabled(java.lang.String what, ClientState state);\n}", "des": "A guardrail that completely disables the use of a particular feature."}
{"index": 4942, "repo": "cassandra-all-4.1.2", "code": "Class Duration {\n\tboolean equals(java.lang.Object obj);\n\t// Converts a String into a duration.\n\tstatic Duration from(java.lang.String input);\n\t// Returns the number of days in this duration.\n\tint getDays();\n\t// Returns the number of months in this duration.\n\tint getMonths();\n\t// Returns the number of nanoseconds in this duration.\n\tlong getNanoseconds();\n\t// Creates a duration with the given number of months, days and nanoseconds.\n\tstatic Duration newInstance(int months, int days, long nanoseconds);\n}", "des": "Represents a duration. A duration stores separately months, days, and seconds due to the fact that the number of days in a month varies, and a day can have 23 or 25 hours if a daylight saving is involved."}
{"index": 4943, "repo": "cassandra-all-4.1.2", "code": "Class DurationSpec.IntMinutesBound {\n\t// Returns this duration in number of milliseconds as an int\n\tint toMilliseconds();\n\t// Returns this duration in number of minutes as an int\n\tint toMinutes();\n\t// Returns this duration in number of seconds as an int\n\tint toSeconds();\n}", "des": "Represents a duration used for Cassandra configuration. The bound is [0, Integer.MAX_VALUE) in minutes. If the user sets a different unit - we still validate that converted to minutes the quantity will not exceed that upper bound. (CASSANDRA-17571)"}
{"index": 4944, "repo": "cassandra-all-4.1.2", "code": "Class DurationType {\n\tCQL3Type asCQL3Type();\n\t// Given a parsed JSON string, return a byte representation of the object.\n\tTerm fromJSONObject(java.lang.Object parsed);\n\t// get a byte representation of the given string.\n\tjava.nio.ByteBuffer fromString(java.lang.String source);\n\tTypeSerializer<Duration> getSerializer();\n\t// Needed to handle ReversedType in value-compatibility checks.\n\tboolean isValueCompatibleWithInternal(AbstractType<?> otherType);\n\tboolean referencesDuration();\n}", "des": "Represents a duration. The duration is stored as months, days, and nanoseconds. This is done"}
{"index": 4945, "repo": "cassandra-all-4.1.2", "code": "Class Ec2Snitch {\n\t// Return the data center for which an endpoint resides in\n\tjava.lang.String getDatacenter(InetAddressAndPort endpoint);\n\t// Return the rack for which an endpoint resides in\n\tjava.lang.String getRack(InetAddressAndPort endpoint);\n\t// Determine if the datacenter or rack values in the current node's snitch conflict with those passed in parameters.\n\tboolean validate(java.util.Set<java.lang.String> datacenters, java.util.Set<java.lang.String> racks);\n}", "des": "A snitch that assumes an EC2 region is a DC and an EC2 availability_zone is a rack. This information is available in the config for the node."}
{"index": 4946, "repo": "cassandra-all-4.1.2", "code": "Class EncodingStats {\n\tboolean equals(java.lang.Object o);\n\t// Merge one or more EncodingStats, that are lazily materialized from some list of arbitrary type by the provided function\n\tstatic <V,F extends java.util.function.Function<V,EncodingStats>>EncodingStats merge(java.util.List<V> values, F function);\n\t// Merge this stats with another one.\n\tEncodingStats mergeWith(EncodingStats that);\n\tlong unsharedHeapSize();\n}", "des": "Stats used for the encoding of the rows and tombstones of a given source."}
{"index": 4947, "repo": "cassandra-all-4.1.2", "code": "Class ErrorCollector {\n\t// Invoked when a syntax error with a specified message occurs.\n\tvoid syntaxError(org.antlr.runtime.BaseRecognizer recognizer, java.lang.String errorMsg);\n\t// Invoked when a syntax error occurs.\n\tvoid syntaxError(org.antlr.runtime.BaseRecognizer recognizer, java.lang.String[] tokenNames, org.antlr.runtime.RecognitionException e);\n\t// Throws the first syntax error found by the lexer or the parser if it exists.\n\tvoid throwFirstSyntaxError();\n}", "des": "ErrorListener that collect and enhance the errors send by the CQL lexer and parser."}
{"index": 4948, "repo": "cassandra-all-4.1.2", "code": "Interface ErrorListener {\n\t// Invoked when a syntax error with a specified message occurs.\n\tvoid syntaxError(org.antlr.runtime.BaseRecognizer recognizer, java.lang.String errorMsg);\n\t// Invoked when a syntax error occurs.\n\tvoid syntaxError(org.antlr.runtime.BaseRecognizer recognizer, java.lang.String[] tokenNames, org.antlr.runtime.RecognitionException e);\n}", "des": "Listener used to collect the syntax errors emitted by the Lexer and Parser."}
{"index": 4949, "repo": "cassandra-all-4.1.2", "code": "Enum ExceptionCode {\n\tstatic ExceptionCode fromValue(int value);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExceptionCode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExceptionCode[] values();\n}", "des": "Exceptions code, as defined by the binary protocol."}
{"index": 4950, "repo": "cassandra-all-4.1.2", "code": "Class FieldIdentifier {\n\tboolean equals(java.lang.Object o);\n\t// Creates a FieldIdentifier from an internal string.\n\tstatic FieldIdentifier forInternalString(java.lang.String text);\n\t// Creates a FieldIdentifier from a quoted identifier string.\n\tstatic FieldIdentifier forQuoted(java.lang.String text);\n\t// Creates a FieldIdentifier from an unquoted identifier string.\n\tstatic FieldIdentifier forUnquoted(java.lang.String text);\n}", "des": "Identifies a field in a UDT."}
{"index": 4951, "repo": "cassandra-all-4.1.2", "code": "Class FileAuditLogger {\n\tboolean isEnabled();\n\t// Logs AuditLogEntry.\n\tvoid log(AuditLogEntry auditLogEntry);\n\t// Stop and cleanup any resources of IAuditLogger implementations.\n\tvoid stop();\n}", "des": "Synchronous, file-based audit logger; just uses the standard logging mechansim."}
{"index": 4952, "repo": "cassandra-all-4.1.2", "code": "Class FrequencySampler<T> {\n\t// Start to record samples\n\tvoid beginSampling(int capacity, int durationMillis);\n\t// Call to stop collecting samples, and gather the results\n\tjava.util.List<Sampler.Sample<T>> finishSampling(int count);\n\tprotected void insert(T item, long value);\n\tboolean isEnabled();\n}", "des": "Find the most frequent sample. A sample adds to the sum of its key ie"}
{"index": 4953, "repo": "cassandra-all-4.1.2", "code": "Class GoogleCloudSnitch {\n\t// Return the data center for which an endpoint resides in\n\tjava.lang.String getDatacenter(InetAddressAndPort endpoint);\n\t// Return the rack for which an endpoint resides in\n\tjava.lang.String getRack(InetAddressAndPort endpoint);\n}", "des": "A snitch that assumes an GCE region is a DC and an GCE availability_zone is a rack. This information is available in the config for the node."}
{"index": 4954, "repo": "cassandra-all-4.1.2", "code": "Class GossiperEvent {\n\t// Returns event type discriminator.\n\tjava.lang.Enum<GossiperEvent.GossiperEventType> getType();\n\t// Returns map of key-value pairs containing relevant event details.\n\tjava.util.HashMap<java.lang.String,java.io.Serializable> toMap();\n}", "des": "DiagnosticEvent implementation for Gossiper activities."}
{"index": 4955, "repo": "cassandra-all-4.1.2", "code": "Class GroupingState {\n\t// Returns the last row clustering or null if either no rows has been processed yet or the last row was a static row.\n\tClustering<?> clustering();\n\t// Checks if the state contains a Clustering for the last row that has been processed.\n\tboolean hasClustering();\n\t// Returns the last row partition key or null if no rows has been processed yet.\n\tjava.nio.ByteBuffer partitionKey();\n}", "des": "GroupMaker state."}
{"index": 4956, "repo": "cassandra-all-4.1.2", "code": "Interface GuardrailsConfigProvider {\n\t// Creates an instance of the custom guardrails config provider of the given class.\n\tstatic GuardrailsConfigProvider build(java.lang.String customImpl);\n\t// Returns the GuardrailsConfig to be used for the specified ClientState.\n\tGuardrailsConfig getOrCreate(ClientState state);\n}", "des": "Provider of GuardrailsConfigs for a ClientState."}
{"index": 4957, "repo": "cassandra-all-4.1.2", "code": "Class HistogramBuilder {\n\tvoid add(long value);\n\t// See buildWithStdevRangesAroundMean(int)\n\tEstimatedHistogram buildWithStdevRangesAroundMean();\n\t// Calculate the min, mean, max and standard deviation of the items in the builder, and generate an EstimatedHistogram with upto maxdev stdev size ranges either side of the mean, until min/max are hit; if either min/max are not reached a further range is inserted at the relevant ends.\n\tEstimatedHistogram buildWithStdevRangesAroundMean(int maxdevs);\n}", "des": "Simple class for constructing an EsimtatedHistogram from a set of predetermined values"}
{"index": 4958, "repo": "cassandra-all-4.1.2", "code": "Enum ICompressor.Uses {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ICompressor.Uses valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ICompressor.Uses[] values();\n}", "des": "Ways that a particular instance of ICompressor should be used internally in Cassandra. GENERAL: Suitable for general use FAST_COMPRESSION: Suitable for use in particularly latency sensitive compression situations (flushes)."}
{"index": 4959, "repo": "cassandra-all-4.1.2", "code": "Interface IMetadataComponentSerializer<T extends MetadataComponent> {\n\t// Deserialize metadata component from given input.\n\tT deserialize(Version version, DataInputPlus in);\n\t// Serialize metadata component to given output.\n\tvoid serialize(Version version, T component, DataOutputPlus out);\n\t// Calculate and return serialized size.\n\tint serializedSize(Version version, T component);\n}", "des": "Metadata component serializer"}
{"index": 4960, "repo": "cassandra-all-4.1.2", "code": "Enum Index.LoadType {\n\tboolean supportsReads();\n\tboolean supportsWrites();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Index.LoadType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Index.LoadType[] values();\n}", "des": "Supported loads. An index could be badly initialized and support only reads i.e."}
{"index": 4961, "repo": "cassandra-all-4.1.2", "code": "Enum IndexTransaction.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IndexTransaction.Type valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IndexTransaction.Type[] values();\n}", "des": "Used to differentiate between type of index transaction when obtaining a handler from Index implementations."}
{"index": 4962, "repo": "cassandra-all-4.1.2", "code": "Interface IPartitionerDependentSerializer<T> {\n\t// Deserialize into the specified DataInputStream instance.\n\tT deserialize(java.io.DataInput in, IPartitioner p, int version);\n\t// Serialize the specified type into the specified DataOutputStream instance.\n\tvoid serialize(T t, DataOutputPlus out, int version);\n\t// Calculate serialized size of object without actually serializing.\n\tlong serializedSize(T t, int version);\n}", "des": "Versioned serializer where the serialization depends on partitioner. On serialization the partitioner is given by the entity being serialized. To deserialize the partitioner used must be known to the calling method."}
{"index": 4963, "repo": "cassandra-all-4.1.2", "code": "Interface IResource {\n\t// Returns the set of Permissions that may be applied to this resource Certain permissions are not applicable to particular types of resources.\n\tjava.util.Set<Permission> applicablePermissions();\n\tboolean exists();\n\tjava.lang.String getName();\n\t// Gets next resource in the hierarchy.\n\tIResource getParent();\n\t// Indicates whether or not this resource has a parent in the hierarchy.\n\tboolean hasParent();\n}", "des": "The interface at the core of Cassandra authorization. Represents a resource in the hierarchy. Currently just one resource type is supported by Cassandra"}
{"index": 4964, "repo": "cassandra-all-4.1.2", "code": "Enum IRoleManager.Option {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IRoleManager.Option valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IRoleManager.Option[] values();\n}", "des": "Supported options for CREATE ROLE/ALTER ROLE (and CREATE USER/ALTER USER, which are aliases provided for backwards compatibility)."}
{"index": 4965, "repo": "cassandra-all-4.1.2", "code": "Enum ISslContextFactory.SocketType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ISslContextFactory.SocketType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ISslContextFactory.SocketType[] values();\n}", "des": "Indicates if the process holds the inbound/listening (Server) end of the socket or the outbound side (Client)."}
{"index": 4966, "repo": "cassandra-all-4.1.2", "code": "Interface KeyAnalyzer<K> {\n\t// Returns the index of the first bit that is different in the two keys.\n\tint bitIndex(K key, K otherKey);\n\t// Returns true if a key's bit it set at the given index.\n\tboolean isBitSet(K key, int bitIndex);\n\t// Returns true if the second argument is a prefix of the first argument.\n\tboolean isPrefix(K key, K prefix);\n\t// Returns the key's length in bits.\n\tint lengthInBits(K key);\n}", "des": "The KeyAnalyzer provides bit-level access to keys for the PatriciaTrie."}
{"index": 4967, "repo": "cassandra-all-4.1.2", "code": "Interface LastEventIdBroadcasterMBean {\n\t// Retrieves a list of all event types and their highest IDs.\n\tjava.util.Map<java.lang.String,java.lang.Comparable> getLastEventIds();\n\t// Retrieves a list of all event types and their highest IDs, if updated since specified timestamp, or null.\n\tjava.util.Map<java.lang.String,java.lang.Comparable> getLastEventIdsIfModified(long lastUpdate);\n}", "des": "Provides a list of event types and the corresponding highest event IDs. Consumers may these IDs to determine if new data is available."}
{"index": 4968, "repo": "cassandra-all-4.1.2", "code": "Interface LifecycleNewTracker {\n\tOperationType opType();\n\t// Called when a new table is about to be created, so that this table can be tracked by a transaction.\n\tvoid trackNew(SSTable table);\n\t// Called when a new table is no longer required, so that this table can be untracked by a transaction.\n\tvoid untrackNew(SSTable table);\n}", "des": "An interface for tracking new sstables added to a LifecycleTransaction, possibly through some proxy."}
{"index": 4969, "repo": "cassandra-all-4.1.2", "code": "Class Lists.DelayedValue {\n\tvoid addFunctionsTo(java.util.List<Function> functions);\n\t// Bind the values in this term to the values contained in values.\n\tTerm.Terminal bind(QueryOptions options);\n\t// Collects the column specification for the bind variables in this Term.\n\tvoid collectMarkerSpecification(VariableSpecifications boundNames);\n\t// Whether or not that term contains at least one bind marker.\n\tboolean containsBindMarker();\n}", "des": "Basically similar to a Value, but with some non-pure function (that need to be evaluated at execution time) in it. Note: this would also work for a list with bind markers, but we don't support that because 1) it's not excessively useful and 2) we wouldn't have a good column name to return in the ColumnSpecification for those markers (not a blocker per-se but we don't bother due to 1))."}
{"index": 4970, "repo": "cassandra-all-4.1.2", "code": "Class LoadingMap<K,V> {\n\t// If the value for the given key is missing, execute a load function to obtain a value and put it into the map.\n\tV blockingLoadIfAbsent(K key, java.util.function.Supplier<? extends V> loadFunction);\n\t// If a value for the given key is present, unload function is run and the value is removed from the map.\n\tV blockingUnloadIfPresent(K key, java.util.function.Consumer<? super V> unloadFunction);\n\t// Get a value for a given key.\n\tV getIfReady(K key);\n}", "des": "An extension of NonBlockingHashMap where all values are wrapped by Future."}
{"index": 4971, "repo": "cassandra-all-4.1.2", "code": "Class LocalSyncTask {\n\tvoid abort();\n\t// Callback for various streaming events.\n\tvoid handleStreamEvent(StreamEvent event);\n\tboolean isLocal();\n\tvoid onFailure(java.lang.Throwable t);\n\tvoid onSuccess(StreamState result);\n\t// Starts sending/receiving our list of differences to/from the remote endpoint: creates a callback that will be called out of band once the streams complete.\n\tprotected void startSync();\n}", "des": "LocalSyncTask performs streaming between local(coordinator) node and remote replica."}
{"index": 4972, "repo": "cassandra-all-4.1.2", "code": "Class LogbackLoggingSupport {\n\tjava.util.Map<java.lang.String,java.lang.String> getLoggingLevels();\n\t// Hook used to execute logging implementation specific customization at Cassandra shutdown time.\n\tvoid onShutdown();\n\t// Hook used to execute logging implementation specific customization at Cassandra startup time.\n\tvoid onStartup();\n\t// Changes the given logger to the given log level.\n\tvoid setLoggingLevel(java.lang.String classQualifier, java.lang.String rawLevel);\n}", "des": "Encapsulates all logback-specific implementations in a central place. Generally, the Cassandra code-base should be logging-backend agnostic and only use slf4j-api. This class MUST NOT be used directly, but only via LoggingSupportFactory which dynamically loads and instantiates an appropriate implementation according to the used slf4j binding."}
{"index": 4973, "repo": "cassandra-all-4.1.2", "code": "Interface LoggingSupport {\n\tjava.util.Map<java.lang.String,java.lang.String> getLoggingLevels();\n\t// Hook used to execute logging implementation specific customization at Cassandra shutdown time.\n\tdefault void onShutdown();\n\t// Hook used to execute logging implementation specific customization at Cassandra startup time.\n\tdefault void onStartup();\n\t// Changes the given logger to the given log level.\n\tvoid setLoggingLevel(java.lang.String classQualifier, java.lang.String rawLevel);\n}", "des": "Common abstraction of functionality which can be implemented for different logging backend implementations (slf4j bindings). Concrete implementations are dynamically loaded and instantiated by LoggingSupportFactory.getLoggingSupport()."}
{"index": 4974, "repo": "cassandra-all-4.1.2", "code": "Class MergeIterator.Reducer<In,Out> {\n\t// May be overridden by implementations that require cleaning up after use\n\tvoid close();\n\tprotected abstract Out getReduced();\n\t// Called at the beginning of each new key, before any reduce is called.\n\tprotected void onKeyChange();\n\t// combine this object with the previous ones.\n\tabstract void reduce(int idx, In current);\n\tboolean trivialReduceIsTrivial();\n}", "des": "Accumulator that collects values of type A, and outputs a value of type B."}
{"index": 4975, "repo": "cassandra-all-4.1.2", "code": "Enum MessageFlag {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MessageFlag valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MessageFlag[] values();\n}", "des": "Binary message flags to be passed as flags field of Message."}
{"index": 4976, "repo": "cassandra-all-4.1.2", "code": "Enum MetadataType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MetadataType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MetadataType[] values();\n}", "des": "Defines Metadata component type."}
{"index": 4977, "repo": "cassandra-all-4.1.2", "code": "Class NativeFunction {\n\t// Checks whether the function is a native/hard coded one or not.\n\tboolean isNative();\n\t// Checks whether the function is a pure function (as in doesn't depend on, nor produces side effects) or not.\n\tboolean isPure();\n}", "des": "Base class for our native/hardcoded functions."}
{"index": 4978, "repo": "cassandra-all-4.1.2", "code": "Class NativeScalarFunction {\n\t// Checks whether the function is an aggregate function or not.\n\tboolean isAggregate();\n\tboolean isCalledOnNullInput();\n\t// Checks if a partial application of the function is monotonic.\n\tprotected boolean isPartialApplicationMonotonic(java.util.List<java.nio.ByteBuffer> partialParameters);\n}", "des": "Base class for the ScalarFunction native classes."}
{"index": 4979, "repo": "cassandra-all-4.1.2", "code": "Class NativeTransportService {\n\tvoid clearConnectionHistory();\n\t// Ultimately stops servers and closes all resources.\n\tvoid destroy();\n\tboolean isRunning();\n\t// Starts native transport servers.\n\tvoid start();\n\t// Stops currently running native transport servers.\n\tvoid stop();\n\tstatic boolean useEpoll();\n}", "des": "Handles native transport server lifecycle and associated resources. Lazily initialized."}
{"index": 4980, "repo": "cassandra-all-4.1.2", "code": "Class NonBlockingRateLimiter {\n\tlong getIntervalNanos();\n\tint getRate();\n\tlong getStartedNanos();\n\t// Reserves a single permit slot on the timeline which may not yet be available.\n\tlong reserveAndGetDelay(java.util.concurrent.TimeUnit delayUnit);\n\tvoid setRate(int permitsPerSecond);\n\tvoid setRate(int permitsPerSecond, com.google.common.base.Ticker ticker);\n\t// Reserves a single permit slot on the timeline, but only if one is available.\n\tboolean tryReserve();\n}", "des": "A rate limiter implementation that allows callers to reserve permits that may only be available in the future, delegating to them decisions about how to schedule/delay work and whether or not to block execution to do so."}
{"index": 4981, "repo": "cassandra-all-4.1.2", "code": "Class NoOpAuditLogger {\n\tboolean isEnabled();\n\t// Logs AuditLogEntry.\n\tvoid log(AuditLogEntry logMessage);\n\t// Stop and cleanup any resources of IAuditLogger implementations.\n\tvoid stop();\n}", "des": "No-Op implementation of IAuditLogger to be used as a default audit logger when audit logging is disabled."}
{"index": 4982, "repo": "cassandra-all-4.1.2", "code": "Enum NoSpamLogger.Level {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NoSpamLogger.Level valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NoSpamLogger.Level[] values();\n}", "des": "Levels for programmatically specifying the severity of a log statement"}
{"index": 4983, "repo": "cassandra-all-4.1.2", "code": "Class Operation {\n\tvoid addFunctionsTo(java.util.List<Function> functions);\n\t// Collects the column specification for the bind variables of this operation.\n\tvoid collectMarkerSpecification(VariableSpecifications boundNames);\n\t// Execute the operation.\n\tabstract void execute(DecoratedKey partitionKey, UpdateParameters params);\n\tboolean requiresRead();\n}", "des": "An UPDATE or DELETE operation. For UPDATE this includes: - setting a constant - counter operations - collections operations and for DELETE: - deleting a column - deleting an element of collection column Fine grained operation are obtained from their raw counterpart (Operation.Raw, which correspond to a parsed, non-checked operation) by provided the receiver for the operation."}
{"index": 4984, "repo": "cassandra-all-4.1.2", "code": "Interface Operation.RawDeletion {\n\t// The name of the column affected by this delete operation.\n\tColumnIdentifier affectedColumn();\n\t// This method validates the operation (i.e.\n\tOperation prepare(java.lang.String keyspace, ColumnMetadata receiver, TableMetadata metadata);\n}", "des": "A parsed raw DELETE operation. This can be one of: - Deleting a column - Deleting an element of a collection"}
{"index": 4985, "repo": "cassandra-all-4.1.2", "code": "Class OpOrder {\n\tvoid awaitNewBarrier();\n\tOpOrder.Group getCurrent();\n\t// Creates a new barrier.\n\tOpOrder.Barrier newBarrier();\n\t// Start an operation against this OpOrder.\n\tOpOrder.Group start();\n}", "des": ""}
{"index": 4986, "repo": "cassandra-all-4.1.2", "code": "Interface OutgoingStream {\n\t// Release any resources held by the stream\n\tvoid finish();\n\tlong getEstimatedSize();\n\tjava.lang.String getName();\n\tint getNumFiles();\n\tTimeUUID getPendingRepair();\n\tlong getRepairedAt();\n\tTableId getTableId();\n\t// Write the streams data into the socket\n\tvoid write(StreamSession session, StreamingDataOutputPlus output, int version);\n}", "des": "Some subset of data to be streamed. Implementations handle writing out their data via the write method. On the receiving end, IncomingStream streams the data in. All the data contained in a given stream needs to have the same repairedAt timestamp (or 0) and pendingRepair id (or null)."}
{"index": 4987, "repo": "cassandra-all-4.1.2", "code": "Enum ParamType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ParamType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ParamType[] values();\n}", "des": "Type names and serializers for various parameters that can be put in Message params map. It should be safe to add new params without bumping messaging version - Message serializer will skip over any params it doesn't recognise. Please don't add boolean params here. Extend and use MessageFlag instead."}
{"index": 4988, "repo": "cassandra-all-4.1.2", "code": "Interface PartialScalarFunction {\n\t// Returns the original function.\n\tFunction getFunction();\n\t// Returns the list of input parameters for the function where some parameters can be Function.UNRESOLVED.\n\tjava.util.List<java.nio.ByteBuffer> getPartialParameters();\n}", "des": "A partial application of a function."}
{"index": 4989, "repo": "cassandra-all-4.1.2", "code": "Class PasswordObfuscator {\n\t// Obfuscates everything after the first appearance password token\n\tstatic java.lang.String obfuscate(java.lang.String sourceString);\n\t// Obfuscates the password in a query\n\tstatic java.lang.String obfuscate(java.lang.String query, RoleOptions opts);\n}", "des": "Obfuscates passwords in a given string"}
{"index": 4990, "repo": "cassandra-all-4.1.2", "code": "Enum Permission {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Permission valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Permission[] values();\n}", "des": "An enum encapsulating the set of possible permissions that an authenticated user can have on a resource. IAuthorizer implementations may encode permissions using ordinals, so the Enum order must never change order. Adding new values is ok."}
{"index": 4991, "repo": "cassandra-all-4.1.2", "code": "Interface ProgressEventNotifier {\n\t// Register progress listener to this publisher.\n\tvoid addProgressListener(ProgressListener listener);\n\t// Remove progress listener from this publisher.\n\tvoid removeProgressListener(ProgressListener listener);\n}", "des": "Interface for ProgressEvent publisher."}
{"index": 4992, "repo": "cassandra-all-4.1.2", "code": "Class ProgressEventNotifierSupport {\n\t// Register progress listener to this publisher.\n\tvoid addProgressListener(ProgressListener listener);\n\tprotected void fireProgressEvent(java.lang.String tag, ProgressEvent event);\n\t// Remove progress listener from this publisher.\n\tvoid removeProgressListener(ProgressListener listener);\n}", "des": "Provides basic, thread safe ProgressEvent notification support"}
{"index": 4993, "repo": "cassandra-all-4.1.2", "code": "Enum ProgressEventType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ProgressEventType valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ProgressEventType[] values();\n}", "des": "Progress event type."}
{"index": 4994, "repo": "cassandra-all-4.1.2", "code": "Enum ProgressInfo.Direction {\n\tstatic ProgressInfo.Direction fromByte(byte direction);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ProgressInfo.Direction valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ProgressInfo.Direction[] values();\n}", "des": "Direction of the stream."}
{"index": 4995, "repo": "cassandra-all-4.1.2", "code": "Class QualifiedName {\n\tboolean equals(java.lang.Object o);\n\tjava.lang.String getKeyspace();\n\tjava.lang.String getName();\n\t// Checks if the keyspace is specified.\n\tboolean hasKeyspace();\n\t// Sets the keyspace.\n\tvoid setKeyspace(java.lang.String ks, boolean keepCase);\n\tvoid setName(java.lang.String cf, boolean keepCase);\n\t// Returns a string representation of the qualified name that is safe to use directly in CQL queries.\n\tjava.lang.String toCQLString();\n}", "des": "Class for the names of the keyspace-prefixed elements (e.g. table, index, view names)"}
{"index": 4996, "repo": "cassandra-all-4.1.2", "code": "Class QueryState {\n\tstatic QueryState forInternalCalls();\n\tint generatedNowInSeconds();\n\tlong generatedTimestamp();\n\tjava.net.InetAddress getClientAddress();\n\tClientState getClientState();\n\t// Generate, cache, and record a nowInSeconds value on the server-side.\n\tint getNowInSeconds();\n\t// Generate, cache, and record a timestamp value on the server-side.\n\tlong getTimestamp();\n}", "des": "Primarily used as a recorder for server-generated timestamps (timestamp, in microseconds, and nowInSeconds - in, well, seconds). The goal is to be able to use a single consistent server-generated value for both timestamps across the whole request, and later be able to inspect QueryState for the generated values - for logging or other purposes."}
{"index": 4997, "repo": "cassandra-all-4.1.2", "code": "Class RackInferringSnitch {\n\t// Return the data center for which an endpoint resides in\n\tjava.lang.String getDatacenter(InetAddressAndPort endpoint);\n\t// Return the rack for which an endpoint resides in\n\tjava.lang.String getRack(InetAddressAndPort endpoint);\n}", "des": "A simple endpoint snitch implementation that assumes datacenter and rack information is encoded in the 2nd and 3rd octets of the ip address, respectively."}
{"index": 4998, "repo": "cassandra-all-4.1.2", "code": "Class RangeTombstone {\n\t// The slice of rows that is deleted by this range tombstone.\n\tSlice deletedSlice();\n\t// The deletion time for this (range) tombstone.\n\tDeletionTime deletionTime();\n\tboolean equals(java.lang.Object other);\n\tjava.lang.String toString(ClusteringComparator comparator);\n}", "des": "A range tombstone is a tombstone that covers a slice/range of rows."}
{"index": 4999, "repo": "cassandra-all-4.1.2", "code": "Interface Rebufferer {\n\t// Called when a reader is closed.\n\tvoid closeReader();\n\t// Rebuffer (move on or seek to) a given position, and return a buffer that can be used there.\n\tRebufferer.BufferHolder rebuffer(long position);\n}", "des": "Rebufferer for reading data by a RandomAccessReader."}
{"index": 5000, "repo": "cassandra-all-4.1.2", "code": "Enum RepairParallelism {\n\t// Return RepairParallelism that match given name.\n\tstatic RepairParallelism fromName(java.lang.String name);\n\tjava.lang.String getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RepairParallelism valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RepairParallelism[] values();\n}", "des": "Specify the degree of parallelism when calculating the merkle trees in a repair job."}
{"index": 5001, "repo": "cassandra-all-4.1.2", "code": "Enum ReplicaCollection.Builder.Conflict {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReplicaCollection.Builder.Conflict valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReplicaCollection.Builder.Conflict[] values();\n}", "des": "Passed to add() and addAll() as ignoreConflicts parameter. The meaning of conflict varies by collection type (for Endpoints, it is a duplicate InetAddressAndPort; for RangesAtEndpoint it is a duplicate Range)."}
{"index": 5002, "repo": "cassandra-all-4.1.2", "code": "Interface ReplicaPlan.Shared<E extends Endpoints<E>,P extends ReplicaPlan<E,P>> {\n\t// add the provided replica to this shared plan, by updating the internal reference\n\tvoid addToContacts(Replica replica);\n\t// get the shared replica plan, non-volatile (so maybe stale) but no risk of partially initialised\n\tP get();\n}", "des": "Used by AbstractReadExecutor, {Data,Digest}Resolver and ReadRepair to share a ReplicaPlan whose 'contacts' replicas we progressively modify via various forms of speculation (initial speculation, rr-read and rr-write) The internal reference is not volatile, despite being shared between threads. The initial reference provided to the constructor should be visible by the normal process of sharing data between threads (i.e. executors, etc) and any updates will either be seen or not seen, perhaps not promptly, but certainly not incompletely. The contained ReplicaPlan has only final member properties, so it cannot be seen partially initialised. TODO: there's no reason this couldn't be achieved instead by a ReplicaPlan with mutable contacts, simplifying the hierarchy"}
{"index": 5003, "repo": "cassandra-all-4.1.2", "code": "Interface RequestCallback<T> {\n\t// Returns true if the callback handles failure reporting - in which case the remove host will be asked to report failures to us in the event of a problem processing the request.\n\tdefault boolean invokeOnFailure();\n\t// Called when there is an exception on the remote node or timeout happens\n\tdefault void onFailure(InetAddressAndPort from, RequestFailureReason failureReason);\n\tvoid onResponse(Message<T> msg);\n\tdefault boolean trackLatencyForSnitch();\n}", "des": "implementors of RequestCallback need to make sure that any public methods are threadsafe with respect to onResponse(org.apache.cassandra.net.Message) being called from the message service. In particular, if any shared state is referenced, making response alone synchronized will not suffice."}
{"index": 5004, "repo": "cassandra-all-4.1.2", "code": "Class RowIterators {\n\tstatic void digest(RowIterator iterator, Digest digest);\n\t// Wraps the provided iterator so it logs the returned rows for debugging purposes.\n\tstatic RowIterator loggingIterator(RowIterator iterator, java.lang.String id);\n\t// Filter the provided iterator to only include cells that are selected by the user.\n\tstatic RowIterator withOnlyQueriedData(RowIterator iterator, ColumnFilter filter);\n}", "des": "Static methods to work with row iterators."}
{"index": 5005, "repo": "cassandra-all-4.1.2", "code": "Interface ScalarFunction {\n\t// Applies this function to the specified parameter.\n\tjava.nio.ByteBuffer execute(ProtocolVersion protocolVersion, java.util.List<java.nio.ByteBuffer> parameters);\n\tboolean isCalledOnNullInput();\n\t// Checks if the function is monotonic.\n\tdefault boolean isMonotonic();\n\t// Does a partial application of the function.\n\tdefault ScalarFunction partialApplication(ProtocolVersion protocolVersion, java.util.List<java.nio.ByteBuffer> partialParameters);\n}", "des": "Determines a single output value based on any number of input values."}
{"index": 5006, "repo": "cassandra-all-4.1.2", "code": "Class Selectable.RawIdentifier {\n\t// Creates a RawIdentifier from a quoted identifier string.\n\tstatic Selectable.RawIdentifier forQuoted(java.lang.String text);\n\t// Creates a RawIdentifier from an unquoted identifier string.\n\tstatic Selectable.RawIdentifier forUnquoted(java.lang.String text);\n\tColumnMetadata prepare(TableMetadata cfm);\n\tFieldIdentifier toFieldIdentifier();\n}", "des": "In the selection clause, the parser cannot differentiate between Maps and UDTs as a column identifier and field identifier have the same syntax. By consequence, we need to wait until the type is known to create the proper Object: ColumnMetadata or FieldIdentifier."}
{"index": 5007, "repo": "cassandra-all-4.1.2", "code": "Class Selectable.WithElementSelection {\n\t// The type of the Selectable if it can be infered.\n\tAbstractType<?> getExactTypeIfKnown(java.lang.String keyspace);\n\tSelector.Factory newSelectorFactory(TableMetadata cfm, AbstractType<?> expectedType, java.util.List<ColumnMetadata> defs, VariableSpecifications boundNames);\n\t// Checks if this Selectable select columns matching the specified predicate.\n\tboolean selectColumns(java.util.function.Predicate<ColumnMetadata> predicate);\n}", "des": "Represents the selection of an element of a collection (eg. c[x])."}
{"index": 5008, "repo": "cassandra-all-4.1.2", "code": "Class Selectable.WithFieldSelection {\n\t// The type of the Selectable if it can be infered.\n\tAbstractType<?> getExactTypeIfKnown(java.lang.String keyspace);\n\tSelector.Factory newSelectorFactory(TableMetadata table, AbstractType<?> expectedType, java.util.List<ColumnMetadata> defs, VariableSpecifications boundNames);\n\t// Checks if this Selectable select columns matching the specified predicate.\n\tboolean selectColumns(java.util.function.Predicate<ColumnMetadata> predicate);\n}", "des": "Represents the selection of the field of a UDT (eg. t.f)."}
{"index": 5009, "repo": "cassandra-all-4.1.2", "code": "Class Selectable.WithSliceSelection {\n\t// The type of the Selectable if it can be infered.\n\tAbstractType<?> getExactTypeIfKnown(java.lang.String keyspace);\n\tSelector.Factory newSelectorFactory(TableMetadata cfm, AbstractType<?> expectedType, java.util.List<ColumnMetadata> defs, VariableSpecifications boundNames);\n\t// Checks if this Selectable select columns matching the specified predicate.\n\tboolean selectColumns(java.util.function.Predicate<ColumnMetadata> predicate);\n}", "des": "Represents the selection of a slice of a collection (eg. c[x..y])."}
{"index": 5010, "repo": "cassandra-all-4.1.2", "code": "Enum Selector.Kind {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Selector.Kind valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Selector.Kind[] values();\n}", "des": "The Selector kinds."}
{"index": 5011, "repo": "cassandra-all-4.1.2", "code": "Class ShardBoundaries {\n\tboolean equals(java.lang.Object o);\n\t// Computes the shard to use for the provided key.\n\tint getShardForKey(PartitionPosition key);\n\t// Computes the shard to use for the provided token.\n\tint getShardForToken(Token tk);\n\t// The number of shards that this boundaries support, that is how many different shard ids getShardForToken(org.apache.cassandra.dht.Token) might possibly return.\n\tint shardCount();\n}", "des": "Holds boundaries (tokens) used to map a particular token (so partition key) to a shard id. In practice, each keyspace has its associated boundaries, see Keyspace."}
{"index": 5012, "repo": "cassandra-all-4.1.2", "code": "Class ShareableBytes {\n\tjava.nio.ByteBuffer get();\n\tboolean hasRemaining();\n\tvoid release();\n\tint remaining();\n\t// Ensure this ShareableBytes will use atomic operations for updating its count from now on.\n\tShareableBytes share();\n\t// Create a slice over the next length bytes, consuming them from our buffer, and incrementing the owner count\n\tShareableBytes sliceAndConsume(int length);\n\tstatic ShareableBytes wrap(java.nio.ByteBuffer buffer);\n}", "des": "A wrapper for possibly sharing portions of a single, BufferPools.forNetworking() managed, ByteBuffer; optimised for the case where no sharing is necessary. When sharing is necessary, share() method must be invoked by the owning thread before a ShareableBytes instance can be shared with another thread."}
{"index": 5013, "repo": "cassandra-all-4.1.2", "code": "Class SimpleCachedBufferPool {\n\t// Checks if the number of used buffers has exceeded the maximum number of cached buffers.\n\tboolean atLimit();\n\tjava.nio.ByteBuffer createBuffer();\n\t// Empties the buffer pool.\n\tvoid emptyBufferPool();\n\tjava.nio.ByteBuffer getThreadLocalReusableBuffer(int size);\n\tvoid releaseBuffer(java.nio.ByteBuffer buffer);\n}", "des": "A very simple Bytebuffer pool with a fixed allocation size and a cached max allocation count. Will allow you to go past the \"max\", freeing all buffers allocated beyond the max buffer count on release. Has a reusable thread local ByteBuffer that users can make use of."}
{"index": 5014, "repo": "cassandra-all-4.1.2", "code": "Class SSTableHeaderFix {\n\tstatic SSTableHeaderFix.Builder builder();\n\tvoid execute();\n\tstatic void fixNonFrozenUDTIfUpgradeFrom30();\n\t// Whether execute() found mismatches.\n\tboolean hasChanges();\n\t// Whether execute() encountered an error.\n\tboolean hasError();\n}", "des": "Validates and fixes type issues in the serialization-header of sstables."}
{"index": 5015, "repo": "cassandra-all-4.1.2", "code": "Interface SSTableId.Builder<T extends SSTableId> {\n\t// Creates an identifier instance from its binary representation\n\tT fromBytes(java.nio.ByteBuffer bytes);\n\t// Creates an identifier instance from its string representation\n\tT fromString(java.lang.String str);\n\t// Creates a new generator of identifiers.\n\tjava.util.function.Supplier<T> generator(java.util.stream.Stream<SSTableId> existingIdentifiers);\n\tboolean isUniqueIdentifier(java.nio.ByteBuffer bytes);\n\tboolean isUniqueIdentifier(java.lang.String str);\n}", "des": "Builder that can create instances of certain implementation of SSTableId."}
{"index": 5016, "repo": "cassandra-all-4.1.2", "code": "Class SSTableIterator {\n\tprotected AbstractSSTableIterator.Reader createReaderInternal(RowIndexEntry indexEntry, FileDataInput file, boolean shouldCloseFile);\n\t// Checks if there are more slice to process.\n\tprotected boolean hasMoreSlices();\n\t// Whether or not the rows returned by this iterator are in reversed clustering order.\n\tboolean isReverseOrder();\n\t// Returns the index of the next slice to process.\n\tprotected int nextSliceIndex();\n}", "des": "A Cell Iterator over SSTable"}
{"index": 5017, "repo": "cassandra-all-4.1.2", "code": "Enum SSTableReadsListener.SelectionReason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SSTableReadsListener.SelectionReason valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SSTableReadsListener.SelectionReason[] values();\n}", "des": "The reasons for selecting an SSTable"}
{"index": 5018, "repo": "cassandra-all-4.1.2", "code": "Enum SSTableReadsListener.SkippingReason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SSTableReadsListener.SkippingReason valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SSTableReadsListener.SkippingReason[] values();\n}", "des": "The reasons for skipping an SSTable"}
{"index": 5019, "repo": "cassandra-all-4.1.2", "code": "Class SSTableReversedIterator {\n\tprotected AbstractSSTableIterator.Reader createReaderInternal(RowIndexEntry indexEntry, FileDataInput file, boolean shouldCloseFile);\n\t// Checks if there are more slice to process.\n\tprotected boolean hasMoreSlices();\n\t// Whether or not the rows returned by this iterator are in reversed clustering order.\n\tboolean isReverseOrder();\n\t// Returns the index of the next slice to process.\n\tprotected int nextSliceIndex();\n}", "des": "A Cell Iterator in reversed clustering order over SSTable"}
{"index": 5020, "repo": "cassandra-all-4.1.2", "code": "Class SSTablesGlobalTracker {\n\tvoid handleNotification(INotification notification, java.lang.Object sender);\n\t// Register a new subscriber to this tracker.\n\tboolean register(INotificationConsumer subscriber);\n\t// Unregister a subscriber from this tracker.\n\tboolean unregister(INotificationConsumer subscriber);\n\t// The set of all sstable versions currently in use on this node.\n\tjava.util.Set<VersionAndType> versionsInUse();\n}", "des": "Tracks all sstables in use on the local node."}
{"index": 5021, "repo": "cassandra-all-4.1.2", "code": "Interface StandardTokenizerInterface {\n\tchar[] getArray();\n\tbyte[] getBytes();\n\t// Resumes scanning until the next regular expression is matched, the end of input is encountered or an I/O-Error occurs.\n\tint getNextToken();\n\tjava.lang.String getText();\n\t// Returns the current position.\n\tlong yychar();\n\t// Returns the length of the matched text region.\n\tint yylength();\n\t// Resets the scanner to read from a new input stream.\n\tvoid yyreset(java.io.Reader reader);\n}", "des": "Internal interface for supporting versioned grammars."}
{"index": 5022, "repo": "cassandra-all-4.1.2", "code": "Interface StartupCheck {\n\t// Run some test to determine whether the system is safe to be started In the case where a test determines it is not safe to proceed, the test should log a message regarding the reason for the failure and ideally the steps required to remedy the problem.\n\tvoid execute(StartupChecksOptions startupChecksOptions);\n\tdefault StartupChecks.StartupCheckType getStartupCheckType();\n\t// Post-hook after all startup checks succeeded.\n\tdefault void postAction(StartupChecksOptions options);\n}", "des": "A test to determine if the system is in a valid state to start up. Some implementations may not actually halt startup, but provide information or advice on tuning and non-fatal environmental issues (e.g. like checking for and warning about suboptimal JVM settings). Other checks may indicate that the system is not in a correct state to be started. Examples include missing or unaccessible data directories, unreadable sstables and misconfiguration of cluster_name in cassandra.yaml. The StartupChecks class manages a collection of these tests, which it executes right at the beginning of the server settup process."}
{"index": 5023, "repo": "cassandra-all-4.1.2", "code": "Class StartupChecks {\n\tstatic java.nio.file.Path getReadAheadKBPath(java.lang.String blockDirectoryPath);\n\t// Run the configured tests and return a report detailing the results.\n\tvoid verify(StartupChecksOptions options);\n\tStartupChecks withDefaultTests();\n\t// Add system test to be run before schema is loaded during startup\n\tStartupChecks withTest(StartupCheck test);\n}", "des": "Verifies that the system and environment is in a fit state to be started. Used in CassandraDaemon#setup() to check various settings and invariants. Each individual test is modelled as an implementation of StartupCheck, these are run at the start of CassandraDaemon#setup() before any local state is mutated. The default checks are a mix of informational tests (inspectJvmOptions), initialization (initSigarLibrary, checkCacheServiceInitialization) and invariant checking (checkValidLaunchDate, checkSystemKeyspaceState, checkSSTablesFormat). In addition, if checkSystemKeyspaceState determines that the release version has changed since last startup (i.e. the node has been upgraded) it snapshots the system keyspace to make it easier to back out if necessary. If any check reports a failure, then the setup method exits with an error (after logging any output from the tests). If all tests report success, setup can continue. We should be careful in future to ensure anything which mutates local state (such as writing new sstables etc) only happens after we've verified the initial setup."}
{"index": 5024, "repo": "cassandra-all-4.1.2", "code": "Class StreamingRepairTask {\n\t// Callback for various streaming events.\n\tvoid handleStreamEvent(StreamEvent event);\n\t// If we failed on either stream in or out, respond fail to coordinator\n\tvoid onFailure(java.lang.Throwable t);\n\t// If we succeeded on both stream in and out, respond back to coordinator\n\tvoid onSuccess(StreamState state);\n\tvoid run();\n}", "des": "StreamingRepairTask performs data streaming between two remote replicas, neither of which is repair coordinator. Task will send SyncResponse message back to coordinator upon streaming completion."}
{"index": 5025, "repo": "cassandra-all-4.1.2", "code": "Enum StreamMessage.Type {\n\tstatic StreamMessage.Type lookupById(int id);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StreamMessage.Type valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StreamMessage.Type[] values();\n}", "des": "StreamMessage types"}
{"index": 5026, "repo": "cassandra-all-4.1.2", "code": "Class StreamReceiveTask {\n\t// Abort this task.\n\tvoid abort();\n\tStreamReceiver getReceiver();\n\tint getTotalNumberOfFiles();\n\tlong getTotalSize();\n\t// Process received stream.\n\tvoid received(IncomingStream stream);\n\tstatic void shutdownAndWait(long timeout, java.util.concurrent.TimeUnit unit);\n}", "des": "Task that manages receiving files for the session for certain ColumnFamily."}
{"index": 5027, "repo": "cassandra-all-4.1.2", "code": "Enum StreamSession.State {\n\tboolean isFinalState();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StreamSession.State valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StreamSession.State[] values();\n}", "des": "State Transition:"}
{"index": 5028, "repo": "cassandra-all-4.1.2", "code": "Class StreamStateStore {\n\tSystemKeyspace.AvailableRanges getAvailableRanges(java.lang.String keyspace, IPartitioner partitioner);\n\t// When StreamSession completes, make all keyspaces/ranges in session available to be served.\n\tvoid handleStreamEvent(StreamEvent event);\n\t// Check if given token's data is available in this node.\n\tboolean isDataAvailable(java.lang.String keyspace, Token token);\n\tvoid onFailure(java.lang.Throwable throwable);\n\tvoid onSuccess(StreamState streamState);\n}", "des": "Store and update available ranges (data already received) to system keyspace."}
{"index": 5029, "repo": "cassandra-all-4.1.2", "code": "Class TableMetadataRef {\n\t// Create a new ref to the passed TableMetadata for use by offline tools only.\n\tstatic TableMetadataRef forOfflineTools(TableMetadata metadata);\n\tTableMetadata get();\n\t// Returns node-local table metadata\n\tTableMetadata getLocal();\n\tvoid setLocalOverrides(TableMetadata metadata);\n}", "des": "Encapsulates a volatile reference to an immutable TableMetadata instance. Used in classes that need up-to-date metadata to avoid the cost of looking up Schema hashmaps."}
{"index": 5030, "repo": "cassandra-all-4.1.2", "code": "Class Term.Raw {\n\tboolean equals(java.lang.Object o);\n\t// The type of the term if it can be infered.\n\tabstract AbstractType<?> getExactTypeIfKnown(java.lang.String keyspace);\n\tabstract java.lang.String getText();\n\t// This method validates this RawTerm is valid for provided column specification and \"prepare\" this RawTerm, returning the resulting prepared Term.\n\tabstract Term prepare(java.lang.String keyspace, ColumnSpecification receiver);\n}", "des": "A parsed, non prepared (thus untyped) term. This can be one of: - a constant - a collection literal - a function call - a marker"}
{"index": 5031, "repo": "cassandra-all-4.1.2", "code": "Class TimeFcts.FloorTimestampFunction {\n\t// Serializes the specified time.\n\tprotected java.nio.ByteBuffer fromTimeInMillis(long timeInMillis);\n\tstatic TimeFcts.FloorTimestampFunction newInstance();\n\tstatic TimeFcts.FloorTimestampFunction newInstanceWithStartTimeArgument();\n\t// Deserializes the specified starting time.\n\tprotected java.lang.Long toStartingTimeInMillis(java.nio.ByteBuffer bytes);\n\t// Deserializes the specified input time.\n\tprotected java.lang.Long toTimeInMillis(java.nio.ByteBuffer bytes);\n}", "des": "Function that rounds a timestamp down to the closest multiple of a duration."}
{"index": 5032, "repo": "cassandra-all-4.1.2", "code": "Class TimeFcts.FloorTimeUuidFunction {\n\t// Serializes the specified time.\n\tprotected java.nio.ByteBuffer fromTimeInMillis(long timeInMillis);\n\tstatic TimeFcts.FloorTimeUuidFunction newInstance();\n\tstatic TimeFcts.FloorTimeUuidFunction newInstanceWithStartTimeArgument();\n\t// Deserializes the specified starting time.\n\tprotected java.lang.Long toStartingTimeInMillis(java.nio.ByteBuffer bytes);\n\t// Deserializes the specified input time.\n\tprotected java.lang.Long toTimeInMillis(java.nio.ByteBuffer bytes);\n}", "des": "Function that rounds a timeUUID down to the closest multiple of a duration."}
{"index": 5033, "repo": "cassandra-all-4.1.2", "code": "Class TokenMetadataEvent {\n\t// Returns event type discriminator.\n\tTokenMetadataEvent.TokenMetadataEventType getType();\n\t// Returns map of key-value pairs containing relevant event details.\n\tjava.util.HashMap<java.lang.String,java.io.Serializable> toMap();\n}", "des": "Events related to TokenMetadata changes."}
{"index": 5034, "repo": "cassandra-all-4.1.2", "code": "Interface UnfilteredRowIterator {\n\t// Returns whether this iterator has no data (including no deletion data).\n\tdefault boolean isEmpty();\n\t// The partition level deletion for the partition this iterate over.\n\tDeletionTime partitionLevelDeletion();\n\t// Return \"statistics\" about what is returned by this iterator.\n\tEncodingStats stats();\n}", "des": "An iterator over the rows of a given partition that also includes deletion informations."}
{"index": 5035, "repo": "cassandra-all-4.1.2", "code": "Interface UnfilteredRowIterators.MergeListener {\n\tvoid close();\n\t// Called once for the merged partition.\n\tvoid onMergedPartitionLevelDeletion(DeletionTime mergedDeletion, DeletionTime[] versions);\n\t// Called once for every range tombstone marker participating in the merge.\n\tvoid onMergedRangeTombstoneMarkers(RangeTombstoneMarker merged, RangeTombstoneMarker[] versions);\n\t// Called once for every row participating in the merge.\n\tRow onMergedRows(Row merged, Row[] versions);\n}", "des": "Interface for a listener interested in the result of merging multiple versions of a given row."}
{"index": 5036, "repo": "cassandra-all-4.1.2", "code": "Interface UpdateFunction<K,V> {\n\t// Computes the value that should be inserted in the BTree.\n\tV insert(K insert);\n\t// Computes the result of merging the existing value with the one from the update.\n\tV merge(V replacing, K update);\n\tstatic <K> UpdateFunction<K,K> noOp();\n\tvoid onAllocatedOnHeap(long heapSize);\n}", "des": "An interface defining the method to be applied to the existing and replacing object in a BTree. The objects returned by the methods will be the object that need to be stored in the BTree."}
{"index": 5037, "repo": "cassandra-all-4.1.2", "code": "Class UserType.Field {\n\tboolean equals(java.lang.Object o);\n\t// Returns the name of the field.\n\tjava.lang.String getName();\n\t// Returns the type of the field.\n\tDataType getType();\n}", "des": "A UDT field."}
{"index": 5038, "repo": "cassandra-all-4.1.2", "code": "Class UUIDGen {\n\t// decomposes a uuid into raw bytes.\n\tstatic byte[] decompose(java.util.UUID uuid);\n\t// Returns a milliseconds-since-epoch value for a type-1 UUID.\n\tstatic long getAdjustedTimestamp(java.util.UUID uuid);\n\t// creates a type 1 uuid from raw bytes.\n\tstatic java.util.UUID getUUID(java.nio.ByteBuffer raw);\n\tstatic java.nio.ByteBuffer toByteBuffer(java.util.UUID uuid);\n}", "des": "The goods are here: www.ietf.org/rfc/rfc4122.txt."}
{"index": 5039, "repo": "cassandra-all-4.1.2", "code": "Class ValidationTask {\n\t// Release any trees already received by this task, and place it a state where any trees received subsequently will be properly discarded.\n\tvoid abort();\n\tboolean isActive();\n\t// Send ValidationRequest to replica\n\tvoid run();\n\t// Receive MerkleTrees from replica node.\n\tvoid treesReceived(MerkleTrees trees);\n}", "des": "ValidationTask sends ValidationRequest to a replica. When a replica sends back message, task completes."}
{"index": 5040, "repo": "cassandra-all-4.1.2", "code": "Class Values<T> {\n\t// Triggers a warning for each of the provided values that is discouraged by this guardrail.\n\tvoid guard(java.util.Set<T> values, ClientState state);\n\t// Triggers a warning for each of the provided values that is discouraged by this guardrail.\n\tvoid guard(java.util.Set<T> values, java.util.function.Consumer<T> ignoreAction, ClientState state);\n}", "des": "A guardrail that warns about some specific values, warns about but ignores some other values, and/or rejects the use of some other values."}
{"index": 5041, "repo": "cassandra-all-4.1.2", "code": "Class Verifier.RangeOwnHelper {\n\t// check if the given key is contained in any of the given ranges Must be called in sorted order - key should be increasing\n\tboolean check(DecoratedKey key);\n\t// check if the given key is contained in any of the given ranges Must be called in sorted order - key should be increasing\n\tvoid validate(DecoratedKey key);\n}", "des": "Use the fact that check(..) is called with sorted tokens - we keep a pointer in to the normalized ranges and only bump the pointer if the key given is out of range. This is done to avoid calling .contains(..) many times for each key (with vnodes for example)"}
{"index": 5042, "repo": "cassandra-all-4.1.2", "code": "Interface WaitQueue.Signal {\n\t// Should only be called by the owning thread.\n\tvoid cancel();\n\t// atomically: cancels the Signal if !isSet(), or returns true if isSignalled()\n\tboolean checkAndClear();\n\tboolean isCancelled();\n\tboolean isSet();\n}", "des": "A Signal is a one-time-use mechanism for a thread to wait for notification that some condition state has transitioned that it may be interested in (and hence should check if it is). It is potentially transient, i.e. the state can change in the meantime, it only indicates that it should be checked, not necessarily anything about what the expected state should be. Signal implementations should never wake up spuriously, they are always woken up by a signal() or signalAll(). This abstract definition of Signal does not need to be tied to a WaitQueue. Whilst RegisteredSignal is the main building block of Signals, this abstract definition allows us to compose Signals in useful ways. The Signal is 'owned' by the thread that registered itself with WaitQueue(s) to obtain the underlying RegisteredSignal(s); only the owning thread should use a Signal."}
{"index": 5043, "repo": "cassandra-all-4.1.2", "code": "Class WaitQueue.Standard.AbstractSignal {\n\t// Await indefinitely, throwing any interrupt.\n\tWaitQueue.Signal await();\n\t// Await until the deadline (in nanoTime), throwing any interrupt.\n\tboolean awaitUntil(long nanoTimeDeadline);\n}", "des": "An abstract signal implementation TODO: use intrusive linked list"}
{"index": 5044, "repo": "cassandra-all-4.1.2", "code": "Class WithOnlyQueriedData<I extends BaseRowIterator<?>> {\n\t// Applied to the PartitionColumns of any rows iterator.\n\tprotected RegularAndStaticColumns applyToPartitionColumns(RegularAndStaticColumns columns);\n\t// Applied to any row we encounter in a rows iterator\n\tprotected Row applyToRow(Row row);\n\t// Applied to the static row of any rows iterator.\n\tprotected Row applyToStatic(Row row);\n}", "des": "Function to skip cells (from an iterator) that are not part of those queried by the user according to the provided ColumnFilter. See UnfilteredRowIterators.withOnlyQueriedData(org.apache.cassandra.db.rows.UnfilteredRowIterator, org.apache.cassandra.db.filter.ColumnFilter) for more details."}
{"index": 5045, "repo": "cassandra-all-4.1.2", "code": "Interface WithResources {\n\tdefault WithResources and(WithResources withResources);\n\tstatic WithResources and(WithResources first, WithResources second);\n\t// Instantiate any necessary resources\n\tCloseable get();\n\t// A convenience method to avoid unnecessary work.\n\tdefault boolean isNoOp();\n\tstatic WithResources none();\n}", "des": "A generic interface for encapsulating a Runnable task with related work before and after execution, using the built-in try-with-resources functionality offered by Closeable. See ExecutorPlus.execute(WithResources, Runnable)"}
{"index": 5046, "repo": "cassandra-all-4.1.2", "code": "Class WrappedDataOutputStreamPlus {\n\tvoid close();\n\tvoid flush();\n\t// Writes count bytes from the byte array buffer starting at offset to this RandomAccessFile starting at the current file pointer..\n\tvoid write(byte[] buffer, int offset, int count);\n\t// Writes the specified byte oneByte to this RandomAccessFile starting at the current file pointer.\n\tvoid write(int oneByte);\n}", "des": "When possible use WrappedDataOutputStreamPlus instead of this class, as it will be more efficient when using Plus methods. This class is only for situations where it cannot be used. The channel provided by this class is just a wrapper around the output stream."}
{"index": 5047, "repo": "nifi-framework-core-api-1.22.0", "code": "Enum ControllerServiceState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ControllerServiceState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ControllerServiceState[] values();\n}", "des": "Represents the valid states for a Controller Service."}
{"index": 5048, "repo": "nifi-framework-core-api-1.22.0", "code": "Enum FlowFileConcurrency {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FlowFileConcurrency valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FlowFileConcurrency[] values();\n}", "des": "Specifies the concurrency level of a Process Group"}
{"index": 5049, "repo": "nifi-framework-core-api-1.22.0", "code": "Class FlowModification {\n\t// Get the last modifier.\n\tString getLastModifier();\n\t// Get the revision.\n\tRevision getRevision();\n}", "des": "Records a flow modification. This includes the resulting revision and the user that performed the modification."}
{"index": 5050, "repo": "nifi-framework-core-api-1.22.0", "code": "Interface LifeCycle {\n\tboolean isRunning();\n\t// Initiates the start state of the lifecyle.\n\tvoid start();\n\t// Initiates the stop state of the lifecycle.\n\tvoid stop(boolean force);\n}", "des": "Represents a start/stop lifecyle for a component. start should only be called once per lifecyle unless otherwise documented by implementing classes."}
{"index": 5051, "repo": "dubbo-3.2.4", "code": "class AbstractAnnotatedMethodParameterProcessor {\n\t// The string presenting the annotation type\n\tClass getAnnotationClass();\n\t// Process the specified method parameter\n\tvoid process(Annotation annotation, Parameter parameter, int parameterIndex, Method method, Class<?> serviceType, Class<?> serviceInterfaceClass, RestMethodMetadata restMethodMetadata);\n}", "des": "The abstract AnnotatedMethodParameterProcessor implementation"}
{"index": 5052, "repo": "dubbo-3.2.4", "code": "class AbstractClusterInvoker<T> {\n\t// destroy.\n\tvoid destroy();\n\tDirectory<T> getDirectory();\n\t// get service interface.\n\tClass<T> getInterface();\n\tURL getRegistryUrl();\n\t// get url.\n\tURL getUrl();\n\t// invoke.\n\tResult invoke(Invocation invocation);\n\t// is available.\n\tboolean isAvailable();\n\tboolean isDestroyed();\n}", "des": "AbstractClusterInvoker"}
{"index": 5053, "repo": "dubbo-3.2.4", "code": "class AbstractConditionMatcher {\n\t// match patterns extracted from when condition\n\tSet<String> getMatches();\n\t// mismatch patterns extracted from then condition\n\tSet<String> getMismatches();\n\tstatic String getSampleValueFromUrl(String conditionKey, Map<String,String> sample, URL param, Invocation invocation);\n\t// Determines if the patterns of this matcher matches with request context.\n\tboolean isMatch(Map<String,String> sample, URL param, Invocation invocation, boolean isWhenCondition);\n}", "des": "The abstract implementation of ConditionMatcher, records the match and mismatch patterns of this matcher while at the same time provides the common match logics."}
{"index": 5054, "repo": "dubbo-3.2.4", "code": "class AbstractConfigurator {\n\t// Configure the provider url.\n\tURL configure(URL url);\n\t// Get the configurator url.\n\tURL getUrl();\n}", "des": "AbstractConfigurator"}
{"index": 5055, "repo": "dubbo-3.2.4", "code": "class AbstractExporter<T> {\n\t// subclasses need to override this method to destroy resources.\n\tvoid afterUnExport();\n\t// get invoker.\n\tInvoker<T> getInvoker();\n\t// register to registry\n\tvoid register();\n\t// unexport.\n\tvoid unexport();\n\t// unregister from registry\n\tvoid unregister();\n}", "des": "AbstractExporter."}
{"index": 5056, "repo": "dubbo-3.2.4", "code": "class AbstractInvoker<T> {\n\t// destroy.\n\tvoid destroy();\n\t// get service interface.\n\tClass<T> getInterface();\n\t// get url.\n\tURL getUrl();\n\t// invoke.\n\tResult invoke(Invocation inv);\n\t// is available.\n\tboolean isAvailable();\n\tboolean isDestroyed();\n}", "des": "This Invoker works on Consumer side."}
{"index": 5057, "repo": "dubbo-3.2.4", "code": "class AbstractProtocol {\n\t// Destroy protocol: 1.\n\tvoid destroy();\n\tMap<String,Exporter<?>> getExporterMap();\n\tCollection<Exporter<?>> getExporters();\n\t// Get all servers serving this protocol\n\tList<ProtocolServer> getServers();\n\t// Refer a remote service: 1.\n\t<T> Invoker<T> refer(Class<T> type, URL url);\n\t// Override this method if you just need framework model\n\tvoid setFrameworkModel(FrameworkModel frameworkModel);\n}", "des": "abstract ProtocolSupport."}
{"index": 5058, "repo": "dubbo-3.2.4", "code": "class AbstractProxyFactory {\n\tstatic Class<?>[] getInternalInterfaces();\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker);\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker, boolean generic);\n\tabstract <T> T getProxy(Invoker<T> invoker, Class<?>[] types);\n}", "des": "AbstractProxyFactory"}
{"index": 5059, "repo": "dubbo-3.2.4", "code": "class AbstractProxyInvoker<T> {\n\t// destroy.\n\tvoid destroy();\n\t// get service interface.\n\tClass<T> getInterface();\n\t// get url.\n\tURL getUrl();\n\t// invoke.\n\tResult invoke(Invocation invocation);\n\t// is available.\n\tboolean isAvailable();\n}", "des": "This Invoker works on provider side, delegates RPC to interface implementation."}
{"index": 5060, "repo": "dubbo-3.2.4", "code": "class AbstractRegistryFactory {\n\t// Connect to the registry Connecting the registry needs to support the contract: 1.\n\tRegistry getRegistry(URL url);\n\t// Override this method if you just need application model\n\tvoid setApplicationModel(ApplicationModel applicationModel);\n}", "des": "AbstractRegistryFactory. (SPI, Singleton, ThreadSafe)"}
{"index": 5061, "repo": "dubbo-3.2.4", "code": "class AbstractServer {\n\t// close the channel.\n\tvoid close();\n\t// Graceful close the channel.\n\tvoid close(int timeout);\n\t// on channel connected.\n\tvoid connected(Channel ch);\n\t// on channel disconnected.\n\tvoid disconnected(Channel ch);\n\tint getAccepts();\n\tInetSocketAddress getBindAddress();\n\t// get local address.\n\tInetSocketAddress getLocalAddress();\n\t// reset.\n\tvoid reset(URL url);\n\t// send message.\n\tvoid send(Object message, boolean sent);\n}", "des": "AbstractServer"}
{"index": 5062, "repo": "dubbo-3.2.4", "code": "class AbstractServiceDiscoveryFactory {\n\tList<ServiceDiscovery> getAllServiceDiscoveries();\n\t// Get the instance of ServiceDiscovery\n\tServiceDiscovery getServiceDiscovery(URL registryURL);\n\t// Override this method if you just need application model\n\tvoid setApplicationModel(ApplicationModel applicationModel);\n}", "des": "Abstract ServiceDiscoveryFactory implementation with cache, the subclass should implement createDiscovery(URL) method to create an instance of ServiceDiscovery"}
{"index": 5063, "repo": "dubbo-3.2.4", "code": "class AbstractServiceRestMetadataResolver {\n\t// Resolve the REST metadata from the specified Dubbo Service interface or type\n\tServiceRestMetadata resolve(Class<?> serviceType);\n\tServiceRestMetadata resolve(Class<?> serviceType, ServiceRestMetadata serviceRestMetadata);\n\t// Support to resolve REST metadata or not\n\tboolean supports(Class<?> serviceType);\n\tboolean supports(Class<?> serviceType, boolean consumer);\n}", "des": "The abstract ServiceRestMetadataResolver class to provider some template methods assemble the instance of ServiceRestMetadata will extended by the sub-classes."}
{"index": 5064, "repo": "dubbo-3.2.4", "code": "class AbstractTripleReactorPublisher<T> {\n\tvoid cancel();\n\tboolean isCancelled();\n\t// onCompleted\n\tvoid onCompleted();\n\t// onError\n\tvoid onError(Throwable throwable);\n\t// onNext\n\tvoid onNext(T data);\n\tvoid request(long l);\n\tvoid startRequest();\n\tvoid subscribe(org.reactivestreams.Subscriber<? super T> subscriber);\n}", "des": "The middle layer between CallStreamObserver and Reactive API."}
{"index": 5065, "repo": "dubbo-3.2.4", "code": "class AbstractZookeeperTransporter {\n\t// share connect for registry, metadata, etc..\n\tZookeeperClient connect(URL url);\n\tvoid destroy();\n\t// get the ZookeeperClient from cache, the ZookeeperClient must be connected.\n\tZookeeperClient fetchAndUpdateZookeeperClientCache(List<String> addressList);\n\t// get all zookeeper urls (such as zookeeper://127.0.0.1:2181?\n\tList<String> getURLBackupAddress(URL url);\n\t// for unit test\n\tMap<String,ZookeeperClient> getZookeeperClientMap();\n}", "des": "AbstractZookeeperTransporter is abstract implements of ZookeeperTransporter."}
{"index": 5066, "repo": "dubbo-3.2.4", "code": "class AdaptiveClassCodeGenerator {\n\t// generate and return class code\n\tString generate();\n\t// generate and return class code\n\tString generate(boolean sort);\n}", "des": "Code generator for Adaptive class"}
{"index": 5067, "repo": "dubbo-3.2.4", "code": "class AdaptiveCompiler {\n\t// Compile java source code.\n\tClass<?> compile(Class<?> neighbor, String code, ClassLoader classLoader);\n\tstatic void setDefaultCompiler(String compiler);\n\t// Override this method if you just need framework model\n\tvoid setFrameworkModel(FrameworkModel frameworkModel);\n}", "des": "AdaptiveCompiler. (SPI, Singleton, ThreadSafe)"}
{"index": 5068, "repo": "dubbo-3.2.4", "code": "class AdaptiveExtensionInjector {\n\t// Destroy the component\n\tvoid destroy();\n\t// Get instance of specify type and name.\n\t<T> T getInstance(Class<T> type, String name);\n\t// Initialize the component before start\n\tvoid initialize();\n\tvoid setExtensionAccessor(ExtensionAccessor extensionAccessor);\n\t// Start the component\n\tvoid start();\n}", "des": "AdaptiveExtensionInjector"}
{"index": 5069, "repo": "dubbo-3.2.4", "code": "class AggregateMetricsCollector {\n\t// Collect metrics as MetricSample\n\tList<MetricSample> collect();\n\tboolean isCollectEnabled();\n\tboolean isSupport(MetricsEvent event);\n\t// notify event.\n\tvoid onEvent(RequestEvent event);\n\tvoid onEventError(RequestEvent event);\n\tvoid onEventFinish(RequestEvent event);\n\tvoid setCollectEnabled(Boolean collectEnabled);\n}", "des": "Aggregation metrics collector implementation of MetricsCollector. This collector only enabled when metrics aggregation config is enabled."}
{"index": 5070, "repo": "dubbo-3.2.4", "code": "interface AnnotatedMethodParameterProcessor {\n\t// Build the default value\n\tstatic String buildDefaultValue(int parameterIndex);\n\t// The string presenting the annotation type\n\tClass getAnnotationClass();\n\t// The string presenting the annotation name\n\tString getAnnotationName();\n\t// Process the specified method parameter\n\tvoid process(Annotation annotation, Parameter parameter, int parameterIndex, Method method, Class<?> serviceType, Class<?> serviceInterfaceClass, RestMethodMetadata restMethodMetadata);\n}", "des": "The interface to process the annotated method parameter"}
{"index": 5071, "repo": "dubbo-3.2.4", "code": "class ArrayTypeBuilder {\n\t// Whether the build accept the class passed in.\n\tboolean accept(Class<?> clazz);\n\t// Build type definition with the type or class.\n\tTypeDefinition build(Type type, Class<?> clazz, Map<String,TypeDefinition> typeCache);\n}", "des": "2015/1/27."}
{"index": 5072, "repo": "dubbo-3.2.4", "code": "class ArrayUtils {\n\tstatic boolean contains(String[] array, String valueToFind);\n\tstatic int indexOf(String[] array, String valueToFind, int startIndex);\n\t// Checks if the array is null or empty.\n\tstatic boolean isEmpty(Object[] array);\n\t// Checks if the array is not null or empty.\n\tstatic boolean isNotEmpty(Object[] array);\n\t// Convert from variable arguments to array\n\tstatic <T> T[] of(T... values);\n}", "des": "Contains some methods to check array."}
{"index": 5073, "repo": "dubbo-3.2.4", "code": "interface AsyncContext {\n\tboolean isAsyncStarted();\n\t// Reset Context is not necessary.\n\tvoid resetContext();\n\t// Signal RpcContext switch.\n\tvoid signalContextSwitch();\n\t// change the context state to start\n\tvoid start();\n\t// change the context state to stop\n\tboolean stop();\n\t// write value and complete the async context.\n\tvoid write(Object value);\n}", "des": "AsyncContext works like AsyncContext in the Servlet 3.0. An AsyncContext is stated by a call to RpcContext.startAsync()."}
{"index": 5074, "repo": "dubbo-3.2.4", "code": "class BodyParameterProcessor {\n\t// The string presenting the annotation name\n\tString getAnnotationName();\n\t// Process the specified method parameter\n\tvoid process(Annotation annotation, Parameter parameter, int parameterIndex, Method method, Class<?> serviceType, Class<?> serviceInterfaceClass, RestMethodMetadata restMethodMetadata);\n}", "des": "The AnnotatedMethodParameterProcessor implementation for JAX-RS's @FormParam"}
{"index": 5075, "repo": "dubbo-3.2.4", "code": "enum BootstrapTakeoverMode {\n\t// \n\tstatic BootstrapTakeoverMode valueOf(String name);\n\t// ,  \n\tstatic BootstrapTakeoverMode[] values();\n}", "des": "Mode of which of DubboBootstrap lifecycle being takeover SPRING: will be controlled by spring context MANUAL: will be controlled by users, after all services init, should call DubboBootstrap.start() to init app-level env AUTO: env will be init once ServiceConfigBase.export() finished SERVLET: will be controlled by java servlet container"}
{"index": 5076, "repo": "dubbo-3.2.4", "code": "class ByteArrayCodec {\n\tMediaType contentType();\n\t// content-type support judge\n\tboolean contentTypeSupport(MediaType mediaType, Class<?> targetType);\n\tObject decode(byte[] body, Class<?> targetType);\n\tvoid encode(OutputStream outputStream, Object unSerializedBody, URL url);\n\t// class type support judge\n\tboolean typeSupport(Class<?> targetType);\n}", "des": "body type is byte array"}
{"index": 5077, "repo": "dubbo-3.2.4", "code": "class Bzip2 {\n\t// compress payload\n\tbyte[] compress(byte[] payloadByteArr);\n\t// decompress payload\n\tbyte[] decompress(byte[] payloadByteArr);\n\t// message encoding of current compressor\n\tString getMessageEncoding();\n}", "des": "bzip2 compressor, faster compression efficiency"}
{"index": 5078, "repo": "dubbo-3.2.4", "code": "interface Cache {\n\t// API to return stored value using a key.\n\tObject get(Object key);\n\t// API to store value against a key\n\tvoid put(Object key, Object value);\n}", "des": "Cache interface to support storing and retrieval of value against a lookup key. It has two operation get and put. put-Storing value against a key. get-Retrieval of object."}
{"index": 5079, "repo": "dubbo-3.2.4", "code": "class CacheFilter {\n\t// If cache is configured, dubbo will invoke method on each method call.\n\tResult invoke(Invoker<?> invoker, Invocation invocation);\n\t// Dubbo will populate and set the cache factory instance based on service/method/consumer/provider configured cache attribute value.\n\tvoid setCacheFactory(CacheFactory cacheFactory);\n}", "des": "CacheFilter is a core component of dubbo.Enabling cache key of service,method,consumer or provider dubbo will cache method return value. Along with cache key we need to configure cache type. Dubbo default implemented cache types are lru threadlocal jcache expiring"}
{"index": 5080, "repo": "dubbo-3.2.4", "code": "interface Channel {\n\t// get attribute.\n\tObject getAttribute(String key);\n\t// get remote address.\n\tInetSocketAddress getRemoteAddress();\n\t// has attribute.\n\tboolean hasAttribute(String key);\n\t// is connected.\n\tboolean isConnected();\n\t// remove attribute.\n\tvoid removeAttribute(String key);\n\t// set attribute.\n\tvoid setAttribute(String key, Object value);\n}", "des": "Channel. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5081, "repo": "dubbo-3.2.4", "code": "enum ChannelEventRunnable.ChannelState {\n\t// \n\tstatic ChannelEventRunnable.ChannelState valueOf(String name);\n\t// ,  \n\tstatic ChannelEventRunnable.ChannelState[] values();\n}", "des": "ChannelState"}
{"index": 5082, "repo": "dubbo-3.2.4", "code": "interface ChannelHandler {\n\t// on exception caught.\n\tvoid caught(Channel channel, Throwable exception);\n\t// on channel connected.\n\tvoid connected(Channel channel);\n\t// on channel disconnected.\n\tvoid disconnected(Channel channel);\n\t// on message received.\n\tvoid received(Channel channel, Object message);\n\t// on message sent.\n\tvoid sent(Channel channel, Object message);\n}", "des": "ChannelHandler. (API, Prototype, ThreadSafe)"}
{"index": 5083, "repo": "dubbo-3.2.4", "code": "class ChannelHandlerAdapter {\n\t// on exception caught.\n\tvoid caught(Channel channel, Throwable exception);\n\t// on channel connected.\n\tvoid connected(Channel channel);\n\t// on channel disconnected.\n\tvoid disconnected(Channel channel);\n\t// on message received.\n\tvoid received(Channel channel, Object message);\n\t// on message sent.\n\tvoid sent(Channel channel, Object message);\n}", "des": "ChannelHandlerAdapter."}
{"index": 5084, "repo": "dubbo-3.2.4", "code": "class ClassUtils {\n\tstatic String getCanonicalNameForParameterizedType(ParameterizedType parameterizedType);\n\t// Get the code source file or class path of the Class passed in.\n\tstatic String getCodeSource(Class<?> clazz);\n\t// Get all non-static fields of the Class passed in or its super classes.\n\tstatic List<Field> getNonStaticFields(Class<?> clazz);\n\t// Get all public, non-static methods of the Class passed in.\n\tstatic List<Method> getPublicNonStaticMethods(Class<?> clazz);\n}", "des": "2015/1/27."}
{"index": 5085, "repo": "dubbo-3.2.4", "code": "interface ClientCall.Listener {\n\t// Callback when call is finished.\n\tvoid onClose(TriRpcStatus status, Map<String,Object> trailers, boolean isReturnTriException);\n\t// Callback when message received.\n\tvoid onMessage(Object message, int actualContentLength);\n\t// Called when the call is started, user can use this to set some configurations.\n\tvoid onStart(ClientCall call);\n}", "des": "Listener for receive response."}
{"index": 5086, "repo": "dubbo-3.2.4", "code": "interface ClientStream {\n\t// No more data will be sent, half close this stream to wait server response.\n\tio.netty.util.concurrent.Future<?> halfClose();\n\t// Send message to remote peer.\n\tio.netty.util.concurrent.Future<?> sendMessage(byte[] message, int compressFlag, boolean eos);\n}", "des": "ClientStream is used to send request to server and receive response from server. Response is received by ClientStream.Listener Requests are sent by ClientStream directly."}
{"index": 5087, "repo": "dubbo-3.2.4", "code": "class CollectionTypeBuilder {\n\t// Whether the build accept the class passed in.\n\tboolean accept(Class<?> clazz);\n\t// Build type definition with the type or class.\n\tTypeDefinition build(Type type, Class<?> clazz, Map<String,TypeDefinition> typeCache);\n}", "des": "2015/1/27."}
{"index": 5088, "repo": "dubbo-3.2.4", "code": "interface ConditionMatcher {\n\t// match patterns extracted from when condition\n\tSet<String> getMatches();\n\t// mismatch patterns extracted from then condition\n\tSet<String> getMismatches();\n\t// Determines if the patterns of this matcher matches with request context.\n\tboolean isMatch(Map<String,String> sample, URL param, Invocation invocation, boolean isWhenCondition);\n}", "des": "ConditionMatcher represents a specific match condition of a condition rule."}
{"index": 5089, "repo": "dubbo-3.2.4", "code": "interface ConditionMatcherFactory {\n\t// Create a matcher instance for the key.\n\tConditionMatcher createMatcher(String key, ModuleModel model);\n\t// Check if the key is of the form of the current matcher type which this factory instance represents..\n\tboolean shouldMatch(String key);\n}", "des": "Factory of ConditionMatcher instances."}
{"index": 5090, "repo": "dubbo-3.2.4", "code": "enum ConfigChangeType {\n\t// \n\tstatic ConfigChangeType valueOf(String name);\n\t// ,  \n\tstatic ConfigChangeType[] values();\n}", "des": "Config change event type"}
{"index": 5091, "repo": "dubbo-3.2.4", "code": "enum ConfigMode {\n\t// \n\tstatic ConfigMode valueOf(String name);\n\t// ,  \n\tstatic ConfigMode[] values();\n}", "des": "Config processing mode for unique config type, e.g. ApplicationConfig, ModuleConfig, MonitorConfig, SslConfig, MetricsConfig"}
{"index": 5092, "repo": "dubbo-3.2.4", "code": "interface Configurator {\n\t// Sort by host, then by priority 1. the url with a specific host ip should have higher priority than 0.0.0.0 2. if two url has the same host, compare by priority value\n\tdefault int compareTo(Configurator o);\n\t// Configure the provider url.\n\tURL configure(URL url);\n\t// Get the configurator url.\n\tURL getUrl();\n\t// Convert override urls to map for use when re-refer.\n\tstatic Optional<List<Configurator>> toConfigurators(List<URL> urls);\n}", "des": "Configurator. (SPI, Prototype, ThreadSafe)"}
{"index": 5093, "repo": "dubbo-3.2.4", "code": "interface Container {\n\t// start method to load the container.\n\tvoid start();\n\t// stop method to unload the container.\n\tvoid stop();\n}", "des": "Container. (SPI, Singleton, ThreadSafe)"}
{"index": 5094, "repo": "dubbo-3.2.4", "code": "interface Converter<S,T> {\n\t// Accept the source type and target type or not\n\tdefault boolean accept(Class<?> sourceType, Class<?> targetType);\n\t// Convert the source-typed value to the target-typed value\n\tT convert(S source);\n\t// Get the source type\n\tdefault Class<S> getSourceType();\n\t// Get the target type\n\tdefault Class<T> getTargetType();\n}", "des": "A class to convert the source-typed value to the target-typed value"}
{"index": 5095, "repo": "dubbo-3.2.4", "code": "enum CuratorFrameworkParams {\n\t// Get the parameter value from the specified URL\n\t<T> T getParameterValue(URL url);\n\t// \n\tstatic CuratorFrameworkParams valueOf(String name);\n\t// ,  \n\tstatic CuratorFrameworkParams[] values();\n}", "des": "The enumeration for the parameters of CuratorFramework"}
{"index": 5096, "repo": "dubbo-3.2.4", "code": "interface DataInput {\n\t// Read boolean.\n\tboolean readBool();\n\t// Read byte.\n\tbyte readByte();\n\t// Read byte array.\n\tbyte[] readBytes();\n\t// Read double.\n\tdouble readDouble();\n\t// Read float.\n\tfloat readFloat();\n\t// Read integer.\n\tint readInt();\n\t// Read long.\n\tlong readLong();\n\t// Read short integer.\n\tshort readShort();\n\t// Read UTF-8 string.\n\tString readUTF();\n}", "des": "Basic data type input interface."}
{"index": 5097, "repo": "dubbo-3.2.4", "code": "class DefaultMetricsServiceExporter {\n\t// Exports the MetricsService as a Dubbo service\n\tMetricsServiceExporter export();\n\t// Initialize exporter\n\tvoid init();\n\t// Override this method if you just need application model\n\tvoid setApplicationModel(ApplicationModel applicationModel);\n\t// Unexports the MetricsService\n\tMetricsServiceExporter unexport();\n}", "des": "Export metrics service"}
{"index": 5098, "repo": "dubbo-3.2.4", "code": "class DefaultModuleDeployer {\n\tReferenceCache getReferenceCache();\n\tFuture getStartFuture();\n\t// Initialize the component\n\tvoid initialize();\n\t// Whether start in background, do not await finish\n\tboolean isBackground();\n\tvoid postDestroy();\n\tvoid preDestroy();\n\t// Prepare for export/refer service, trigger initializing application and module\n\tvoid prepare();\n\t// Starts the component.\n\tFuture start();\n\t// Stops the component.\n\tvoid stop();\n}", "des": "Export/refer services of module"}
{"index": 5099, "repo": "dubbo-3.2.4", "code": "class DefaultPage<T> {\n\t// The data of current page\n\tList<T> getData();\n\t// Gets the offset of request\n\tint getOffset();\n\t// Gets the size of request for pagination query\n\tint getPageSize();\n\t// Get the number of total pages.\n\tint getTotalPages();\n\t// Gets the total amount of elements.\n\tint getTotalSize();\n\t// It indicates has next page or not\n\tboolean hasNext();\n}", "des": "The default implementation of Page"}
{"index": 5100, "repo": "dubbo-3.2.4", "code": "class DefaultValueParameterProcessor {\n\t// The string presenting the annotation name\n\tString getAnnotationName();\n\t// Get the priority\n\tint getPriority();\n}", "des": "The AnnotatedMethodParameterProcessor implementation for JAX-RS's @DefaultValue *"}
{"index": 5101, "repo": "dubbo-3.2.4", "code": "class DelegateProviderMetaDataInvoker<T> {\n\t// destroy.\n\tvoid destroy();\n\t// get service interface.\n\tClass<T> getInterface();\n\tServiceConfig<?> getMetadata();\n\t// get url.\n\tURL getUrl();\n\t// invoke.\n\tResult invoke(Invocation invocation);\n\t// is available.\n\tboolean isAvailable();\n}", "des": "An invoker wrapper that wrap the invoker and all the metadata (ServiceConfig)"}
{"index": 5102, "repo": "dubbo-3.2.4", "code": "enum DeployState {\n\t// \n\tstatic DeployState valueOf(String name);\n\t// ,  \n\tstatic DeployState[] values();\n}", "des": "Deploy state enum"}
{"index": 5103, "repo": "dubbo-3.2.4", "code": "class DubboAnnotationUtils {\n\t// Resolve the parameters of DubboService and DubboReference from the specified.\n\tstatic Map<String,String> convertParameters(String[] parameters);\n\t// Resolve the service interface name from @Service annotation attributes.\n\tstatic String resolveInterfaceName(Map<String,Object> attributes, Class<?> defaultInterfaceClass);\n}", "des": "Dubbo Annotation Utilities Class"}
{"index": 5104, "repo": "dubbo-3.2.4", "code": "class DubboInvoker<T> {\n\t// destroy.\n\tvoid destroy();\n\t// is available.\n\tboolean isAvailable();\n}", "des": "DubboInvoker"}
{"index": 5105, "repo": "dubbo-3.2.4", "code": "class DubboLoadingStrategy {\n\tString directory();\n\tString getName();\n\t// Get the priority\n\tint getPriority();\n\t// Indicates current LoadingStrategy supports overriding other lower prioritized instances or not.\n\tboolean overridden();\n}", "des": "Dubbo LoadingStrategy"}
{"index": 5106, "repo": "dubbo-3.2.4", "code": "class DubboMonitor {\n\t// Collect monitor data 1. support invocation count: count://host/interface?\n\tvoid collect(URL url);\n\t// destroy.\n\tvoid destroy();\n\t// get url.\n\tURL getUrl();\n\t// is available.\n\tboolean isAvailable();\n\t// Lookup monitor data 1. support lookup by day: count://host/interface?\n\tList<URL> lookup(URL query);\n\tvoid send();\n}", "des": "DubboMonitor"}
{"index": 5107, "repo": "dubbo-3.2.4", "code": "enum DubboObservationDocumentation {\n\t// \n\tstatic DubboObservationDocumentation valueOf(String name);\n\t// ,  \n\tstatic DubboObservationDocumentation[] values();\n}", "des": "Documentation of Dubbo observations."}
{"index": 5108, "repo": "dubbo-3.2.4", "code": "class DubboProtocol {\n\t// Destroy protocol: 1.\n\tvoid destroy();\n\t// Export service for remote invocation: 1.\n\t<T> Exporter<T> export(Invoker<T> invoker);\n\t// Get default port when user doesn't config the port.\n\tint getDefaultPort();\n\tstatic DubboProtocol getDubboProtocol(ScopeModel scopeModel);\n\tCollection<Invoker<?>> getInvokers();\n\t<T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url);\n\t// Refer a remote service: 1.\n\t<T> Invoker<T> refer(Class<T> type, URL url);\n}", "des": "dubbo protocol support."}
{"index": 5109, "repo": "dubbo-3.2.4", "code": "class DubboShutdownHook {\n\tboolean getRegistered();\n\t// Register the ShutdownHook\n\tvoid register();\n\tvoid run();\n\t// Unregister the ShutdownHook\n\tvoid unregister();\n}", "des": "The shutdown hook thread to do the cleanup stuff. This is a singleton in order to ensure there is only one shutdown hook registered. Because ApplicationShutdownHooks use IdentityHashMap to store the shutdown hooks."}
{"index": 5110, "repo": "dubbo-3.2.4", "code": "interface Endpoint {\n\t// close the channel.\n\tvoid close();\n\t// Graceful close the channel.\n\tvoid close(int timeout);\n\t// get channel handler.\n\tChannelHandler getChannelHandler();\n\t// get local address.\n\tInetSocketAddress getLocalAddress();\n\t// get url.\n\tURL getUrl();\n\t// is closed.\n\tboolean isClosed();\n\t// send message.\n\tvoid send(Object message);\n\t// send message.\n\tvoid send(Object message, boolean sent);\n\tvoid startClose();\n}", "des": "Endpoint. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5111, "repo": "dubbo-3.2.4", "code": "class EnumTypeBuilder {\n\t// Whether the build accept the class passed in.\n\tboolean accept(Class<?> clazz);\n\t// Build type definition with the type or class.\n\tTypeDefinition build(Type type, Class<?> clazz, Map<String,TypeDefinition> typeCache);\n}", "des": "2015/1/27."}
{"index": 5112, "repo": "dubbo-3.2.4", "code": "class EnvironmentUtils {\n\t// Extras The properties from ConfigurableEnvironment\n\tstatic Map<String,Object> extractProperties(org.springframework.core.env.ConfigurableEnvironment environment);\n\t// Filters Dubbo Properties from ConfigurableEnvironment\n\tstatic SortedMap<String,String> filterDubboProperties(org.springframework.core.env.ConfigurableEnvironment environment);\n}", "des": "The utilities class for Environment"}
{"index": 5113, "repo": "dubbo-3.2.4", "code": "enum EventType {\n\tint getIntValue();\n\t// \n\tstatic EventType valueOf(String name);\n\t// ,  \n\tstatic EventType[] values();\n}", "des": "2019-02-26"}
{"index": 5114, "repo": "dubbo-3.2.4", "code": "interface ExchangeChannel {\n\t// graceful close.\n\tvoid close(int timeout);\n\t// get message handler.\n\tExchangeHandler getExchangeHandler();\n\t// send request.\n\tCompletableFuture<Object> request(Object request, ExecutorService executor);\n\t// send request.\n\tCompletableFuture<Object> request(Object request, int timeout, ExecutorService executor);\n}", "des": "ExchangeChannel. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5115, "repo": "dubbo-3.2.4", "code": "interface Exchanger {\n\t// bind.\n\tExchangeServer bind(URL url, ExchangeHandler handler);\n\t// connect.\n\tExchangeClient connect(URL url, ExchangeHandler handler);\n}", "des": "Exchanger. (SPI, Singleton, ThreadSafe)"}
{"index": 5116, "repo": "dubbo-3.2.4", "code": "interface ExchangeServer {\n\t// get channel.\n\tExchangeChannel getExchangeChannel(InetSocketAddress remoteAddress);\n\t// get channels.\n\tCollection<ExchangeChannel> getExchangeChannels();\n}", "des": "ExchangeServer. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5117, "repo": "dubbo-3.2.4", "code": "class ExpiringCache {\n\t// API to return stored value using a key against the calling thread specific store.\n\tObject get(Object key);\n\t// API to store value against a key in the calling thread scope.\n\tvoid put(Object key, Object value);\n}", "des": "This class store the cache value with the characteristic of expiration time. If a service,method,consumer or provided is configured with key cache with value expiring, dubbo initialize the instance of this class using ExpiringCacheFactory to store method's returns value to server from store without making method call."}
{"index": 5118, "repo": "dubbo-3.2.4", "code": "interface Exporter<T> {\n\t// get invoker.\n\tInvoker<T> getInvoker();\n\t// register to registry\n\tvoid register();\n\t// unexport.\n\tvoid unexport();\n\t// unregister from registry\n\tvoid unregister();\n}", "des": "Exporter. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5119, "repo": "dubbo-3.2.4", "code": "interface ExporterChangeListener {\n\t// This method is called when an Exporter object is exported.\n\tvoid onExporterChangeExport(Exporter<?> exporter);\n\t// This method is called when an Exporter object is unexported.\n\tvoid onExporterChangeUnExport(Exporter<?> exporter);\n}", "des": "An interface for listening to changes in the export state of an Exporter object."}
{"index": 5120, "repo": "dubbo-3.2.4", "code": "interface ExporterListener {\n\t// The exporter exported.\n\tvoid exported(Exporter<?> exporter);\n\t// The exporter unexported.\n\tvoid unexported(Exporter<?> exporter);\n}", "des": "ExporterListener. (SPI, Singleton, ThreadSafe)"}
{"index": 5121, "repo": "dubbo-3.2.4", "code": "class ExporterListenerAdapter {\n\t// The exporter exported.\n\tvoid exported(Exporter<?> exporter);\n\t// The exporter unexported.\n\tvoid unexported(Exporter<?> exporter);\n}", "des": "ExporterListenerAdapter"}
{"index": 5122, "repo": "dubbo-3.2.4", "code": "enum ExtensionScope {\n\t// \n\tstatic ExtensionScope valueOf(String name);\n\t// ,  \n\tstatic ExtensionScope[] values();\n}", "des": "Extension SPI Scope"}
{"index": 5123, "repo": "dubbo-3.2.4", "code": "class FilterChainBuilder.FilterChainNode<T,TYPE extends Invoker<T>,FILTER extends BaseFilter> {\n\t// destroy.\n\tvoid destroy();\n\t// get service interface.\n\tClass<T> getInterface();\n\tTYPE getOriginalInvoker();\n\t// get url.\n\tURL getUrl();\n\t// invoke.\n\tResult invoke(Invocation invocation);\n\t// is available.\n\tboolean isAvailable();\n}", "des": "Works on provider side"}
{"index": 5124, "repo": "dubbo-3.2.4", "code": "class FixedParamValue {\n\t// max index is 2^31 - 1\n\tint getIndex(String value);\n\t// DEFAULT value will be returned if n = 0\n\tString getN(int n);\n}", "des": "In lower case"}
{"index": 5125, "repo": "dubbo-3.2.4", "code": "class FutureContext {\n\t// get future.\n\t<T> CompletableFuture<T> getCompletableFuture();\n\tstatic FutureContext getContext();\n\t// set future.\n\tvoid setFuture(CompletableFuture<?> future);\n}", "des": "Used for async call scenario. But if the method you are calling has a CompletableFuture signature you do not need to use this class since you will get a Future response directly."}
{"index": 5126, "repo": "dubbo-3.2.4", "code": "class Gzip {\n\t// compress payload\n\tbyte[] compress(byte[] payloadByteArr);\n\t// decompress payload\n\tbyte[] decompress(byte[] payloadByteArr);\n\t// message encoding of current compressor\n\tString getMessageEncoding();\n}", "des": "gzip compressor"}
{"index": 5127, "repo": "dubbo-3.2.4", "code": "interface H2TransportListener {\n\tvoid cancelByRemote(long errorCode);\n\t// Transport data\n\tvoid onData(io.netty.buffer.ByteBuf data, boolean endStream);\n\t// Transport metadata\n\tvoid onHeader(io.netty.handler.codec.http2.Http2Headers headers, boolean endStream);\n}", "des": "An observer used for transport messaging which provides full streaming support. A TransportObserver receives raw data or control messages from local/remote."}
{"index": 5128, "repo": "dubbo-3.2.4", "code": "class HashedWheelTimer {\n\t// the timer is stop\n\tboolean isStop();\n\t// Schedules the specified TimerTask for one-time execution after the specified delay.\n\tTimeout newTimeout(TimerTask task, long delay, TimeUnit unit);\n\t// Returns the number of pending timeouts of this Timer.\n\tlong pendingTimeouts();\n\t// Starts the background thread explicitly.\n\tvoid start();\n\t// Releases all resources acquired by this Timer and cancels all tasks which were scheduled but not executed yet.\n\tSet<Timeout> stop();\n}", "des": "A Timer optimized for approximated I/O timeout scheduling. Tick Duration"}
{"index": 5129, "repo": "dubbo-3.2.4", "code": "class HeaderExchangeHandler {\n\t// on exception caught.\n\tvoid caught(Channel channel, Throwable exception);\n\t// on channel connected.\n\tvoid connected(Channel channel);\n\t// on channel disconnected.\n\tvoid disconnected(Channel channel);\n\tChannelHandler getHandler();\n\t// on message received.\n\tvoid received(Channel channel, Object message);\n\t// on message sent.\n\tvoid sent(Channel channel, Object message);\n}", "des": "ExchangeReceiver"}
{"index": 5130, "repo": "dubbo-3.2.4", "code": "class HeaderExchanger {\n\t// bind.\n\tExchangeServer bind(URL url, ExchangeHandler handler);\n\t// connect.\n\tExchangeClient connect(URL url, ExchangeHandler handler);\n}", "des": "DefaultMessenger"}
{"index": 5131, "repo": "dubbo-3.2.4", "code": "interface HttpMessageCodec<InputStream,OutputStream> {\n\tMediaType contentType();\n\t// content-type support judge\n\tboolean contentTypeSupport(MediaType mediaType, Class<?> targetType);\n\t// class type support judge\n\tboolean typeSupport(Class<?> targetType);\n}", "des": "for http body codec"}
{"index": 5132, "repo": "dubbo-3.2.4", "code": "class Identity {\n\t// compress payload\n\tbyte[] compress(byte[] payloadByteArr);\n\t// decompress payload\n\tbyte[] decompress(byte[] payloadByteArr);\n\t// message encoding of current compressor\n\tString getMessageEncoding();\n}", "des": "Default compressor"}
{"index": 5133, "repo": "dubbo-3.2.4", "code": "class InjvmInvoker<T> {\n\t// Specific implementation of the AbstractInvoker.invoke(Invocation) method\n\tResult doInvoke(Invocation invocation);\n\t// is available.\n\tboolean isAvailable();\n}", "des": "InjvmInvoker"}
{"index": 5134, "repo": "dubbo-3.2.4", "code": "class InjvmProtocol {\n\t// Export service for remote invocation: 1.\n\t<T> Exporter<T> export(Invoker<T> invoker);\n\t// Get default port when user doesn't config the port.\n\tint getDefaultPort();\n\tstatic InjvmProtocol getInjvmProtocol(ScopeModel scopeModel);\n\tboolean isInjvmRefer(URL url);\n\t<T> Invoker<T> protocolBindingRefer(Class<T> serviceType, URL url);\n}", "des": "InjvmProtocol"}
{"index": 5135, "repo": "dubbo-3.2.4", "code": "class InmemoryConfiguration {\n\t// Add a set of properties into the store\n\tvoid addProperties(Map<String,String> properties);\n\t// Add one property into the store, the previous value will be replaced if the key exists\n\tvoid addProperty(String key, String value);\n\tObject getInternalProperty(String key);\n\tMap<String,String> getProperties();\n\t// set store\n\tvoid setProperties(Map<String,String> properties);\n}", "des": "In-memory configuration"}
{"index": 5136, "repo": "dubbo-3.2.4", "code": "class InternalRunnable {\n\t// After the task execution is completed, it will call InternalThreadLocal.removeAll() to clear unnecessary variables in the thread.\n\tvoid run();\n\t// Wrap ordinary Runnable into InternalThreadLocal.\n\tstatic Runnable Wrap(Runnable runnable);\n}", "des": "InternalRunnable There is a risk of memory leak when using InternalThreadLocal without calling InternalThreadLocal.removeAll(). This design is learning from FastThreadLocalRunnable which is in Netty."}
{"index": 5137, "repo": "dubbo-3.2.4", "code": "class InternalThread {\n\t// Sets the internal data structure that keeps the threadLocal variables bound to this thread.\n\tvoid setThreadLocalMap(InternalThreadLocalMap threadLocalMap);\n\t// Returns the internal data structure that keeps the threadLocal variables bound to this thread.\n\tInternalThreadLocalMap threadLocalMap();\n}", "des": "InternalThread"}
{"index": 5138, "repo": "dubbo-3.2.4", "code": "interface Invoker<T> {\n\t// get service interface.\n\tClass<T> getInterface();\n\t// invoke.\n\tResult invoke(Invocation invocation);\n}", "des": "Invoker. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5139, "repo": "dubbo-3.2.4", "code": "interface InvokerListener {\n\t// The invoker destroyed.\n\tvoid destroyed(Invoker<?> invoker);\n\t// The invoker referred\n\tvoid referred(Invoker<?> invoker);\n}", "des": "InvokerListener. (SPI, Singleton, ThreadSafe)"}
{"index": 5140, "repo": "dubbo-3.2.4", "code": "class InvokerListenerAdapter {\n\t// The invoker destroyed.\n\tvoid destroyed(Invoker<?> invoker);\n\t// The invoker referred\n\tvoid referred(Invoker<?> invoker);\n}", "des": "InvokerListenerAdapter"}
{"index": 5141, "repo": "dubbo-3.2.4", "code": "class InvokerWrapper<T> {\n\t// destroy.\n\tvoid destroy();\n\t// get service interface.\n\tClass<T> getInterface();\n\t// get url.\n\tURL getUrl();\n\t// invoke.\n\tResult invoke(Invocation invocation);\n\t// is available.\n\tboolean isAvailable();\n}", "des": "InvokerWrapper"}
{"index": 5142, "repo": "dubbo-3.2.4", "code": "class JavaObjectInput {\n\t// Read byte array.\n\tbyte[] readBytes();\n\t// Consider use ObjectInput.readObject(Class) or ObjectInput.readObject(Class, Type) where possible\n\tObject readObject();\n\t// read object\n\t<T> T readObject(Class<T> cls);\n\t// read object\n\t<T> T readObject(Class<T> cls, Type type);\n\t// Read UTF-8 string.\n\tString readUTF();\n}", "des": "Java object input implementation"}
{"index": 5143, "repo": "dubbo-3.2.4", "code": "class JavaObjectOutput {\n\t// Flush buffer.\n\tvoid flushBuffer();\n\t// write object.\n\tvoid writeObject(Object obj);\n\t// Write string.\n\tvoid writeUTF(String v);\n}", "des": "Java object output implementation"}
{"index": 5144, "repo": "dubbo-3.2.4", "code": "class JCache {\n\t// API to return stored value using a key.\n\tObject get(Object key);\n\t// API to store value against a key\n\tvoid put(Object key, Object value);\n}", "des": "This class store the cache value per thread. If a service,method,consumer or provided is configured with key cache with value jcache, dubbo initialize the instance of this class using JCacheFactory to store method's returns value to server from store without making method call."}
{"index": 5145, "repo": "dubbo-3.2.4", "code": "enum JRE {\n\t// get current JRE version\n\tstatic JRE currentVersion();\n\t// is current version\n\tboolean isCurrentVersion();\n\t// \n\tstatic JRE valueOf(String name);\n\t// ,  \n\tstatic JRE[] values();\n}", "des": "JRE version"}
{"index": 5146, "repo": "dubbo-3.2.4", "code": "class JsonCodec {\n\tMediaType contentType();\n\t// content-type support judge\n\tboolean contentTypeSupport(MediaType mediaType, Class<?> targetType);\n\tObject decode(byte[] body, Class<?> targetType);\n\tvoid encode(OutputStream outputStream, Object unSerializedBody, URL url);\n\t// class type support judge\n\tboolean typeSupport(Class<?> targetType);\n}", "des": "body is json"}
{"index": 5147, "repo": "dubbo-3.2.4", "code": "enum KeyTypeEnum {\n\t// Build Key\n\tabstract String build(String one, String... others);\n\t// \n\tstatic KeyTypeEnum valueOf(String name);\n\t// ,  \n\tstatic KeyTypeEnum[] values();\n}", "des": "2019-08-15"}
{"index": 5148, "repo": "dubbo-3.2.4", "code": "enum Level {\n\t// \n\tstatic Level valueOf(String name);\n\t// ,  \n\tstatic Level[] values();\n}", "des": "Level"}
{"index": 5149, "repo": "dubbo-3.2.4", "code": "class LfuCache {\n\t// API to return stored value using a key against the calling thread specific store.\n\tObject get(Object key);\n\t// API to store value against a key in the calling thread scope.\n\tvoid put(Object key, Object value);\n}", "des": "This class store the cache value per thread. If a service,method,consumer or provided is configured with key cache with value lfu, dubbo initialize the instance of this class using LfuCacheFactory to store method's returns value to server from store without making method call."}
{"index": 5150, "repo": "dubbo-3.2.4", "code": "interface Lifecycle {\n\t// Destroy the component\n\tvoid destroy();\n\t// Initialize the component before start\n\tvoid initialize();\n\t// Start the component\n\tvoid start();\n}", "des": "The Lifecycle of Dubbo component"}
{"index": 5151, "repo": "dubbo-3.2.4", "code": "class ListenerExporterWrapper<T> {\n\t// get invoker.\n\tInvoker<T> getInvoker();\n\t// register to registry\n\tvoid register();\n\t// unexport.\n\tvoid unexport();\n\t// unregister from registry\n\tvoid unregister();\n}", "des": "ListenerExporter"}
{"index": 5152, "repo": "dubbo-3.2.4", "code": "class ListenerInvokerWrapper<T> {\n\t// destroy.\n\tvoid destroy();\n\t// get service interface.\n\tClass<T> getInterface();\n\tInvoker<T> getInvoker();\n\tList<InvokerListener> getListeners();\n\t// get url.\n\tURL getUrl();\n\t// invoke.\n\tResult invoke(Invocation invocation);\n\t// is available.\n\tboolean isAvailable();\n}", "des": "ListenerInvoker"}
{"index": 5153, "repo": "dubbo-3.2.4", "code": "interface LoggerAdapter {\n\t// Get the current logging file\n\tFile getFile();\n\t// Get the current logging level\n\tLevel getLevel();\n\t// Get a logger\n\tLogger getLogger(Class<?> key);\n\t// Get a logger\n\tLogger getLogger(String key);\n\t// Return is the current logger has been configured.\n\tdefault boolean isConfigured();\n\t// Set the current logging file\n\tvoid setFile(File file);\n\t// Set the current logging level\n\tvoid setLevel(Level level);\n}", "des": "Logger provider"}
{"index": 5154, "repo": "dubbo-3.2.4", "code": "class LruCache {\n\t// API to return stored value using a key against the calling thread specific store.\n\tObject get(Object key);\n\t// API to store value against a key in the calling thread scope.\n\tvoid put(Object key, Object value);\n}", "des": "This class store the cache value per thread. If a service,method,consumer or provided is configured with key cache with value lru, dubbo initialize the instance of this class using LruCacheFactory to store method's returns value to server from store without making method call."}
{"index": 5155, "repo": "dubbo-3.2.4", "code": "class MapTypeBuilder {\n\t// Whether the build accept the class passed in.\n\tboolean accept(Class<?> clazz);\n\t// Build type definition with the type or class.\n\tTypeDefinition build(Type type, Class<?> clazz, Map<String,TypeDefinition> typeCache);\n}", "des": "2015/1/27."}
{"index": 5156, "repo": "dubbo-3.2.4", "code": "interface MemberUtils {\n\t// check the specified member is private or not ?\n\tstatic boolean isPrivate(Member member);\n\t// check the specified member is public or not ?\n\tstatic boolean isPublic(Member member);\n\t// check the specified member is static or not ?\n\tstatic boolean isStatic(Member member);\n}", "des": "Java Reflection Member Utilities class"}
{"index": 5157, "repo": "dubbo-3.2.4", "code": "class MemoryLimitCalculator {\n\t// Take the current JVM's maximum available memory as a percentage of the result as the limit.\n\tstatic long calculate(float percentage);\n\t// By default, it takes 80% of the maximum available memory of the current JVM.\n\tstatic long defaultLimit();\n\t// Get the maximum available memory of the current JVM.\n\tstatic long maxAvailable();\n}", "des": "Runtime.freeMemory() technology is used to calculate the memory limit by using the percentage of the current maximum available memory, which can be used with MemoryLimiter."}
{"index": 5158, "repo": "dubbo-3.2.4", "code": "class MemorySafeLinkedBlockingQueue<E> {\n\t// get the max free memory.\n\tint getMaxFreeMemory();\n\t// determine if there is any remaining free memory.\n\tboolean hasRemainedMemory();\n\tboolean offer(E e);\n\tboolean offer(E e, long timeout, TimeUnit unit);\n\tvoid put(E e);\n\t// set the max free memory.\n\tvoid setMaxFreeMemory(int maxFreeMemory);\n\t// set the rejector.\n\tvoid setRejector(Rejector<E> rejector);\n}", "des": "Can completely solve the OOM problem caused by LinkedBlockingQueue, does not depend on Instrumentation and is easier to use than MemoryLimitedLinkedBlockingQueue."}
{"index": 5159, "repo": "dubbo-3.2.4", "code": "interface MetadataParamsFilter {\n\t// params that need to be excluded before sending to registry center\n\tdefault String[] instanceParamsExcluded();\n\t// params that need to be sent to registry center\n\tdefault String[] instanceParamsIncluded();\n\t// params that need to be excluded before sending to metadata center\n\tdefault String[] serviceParamsExcluded();\n\t// params that need to be sent to metadata center\n\tdefault String[] serviceParamsIncluded();\n}", "des": "This filter applies an either 'include' or 'exclude' policy with 'include' having higher priority. That means if 'include' is specified then params specified in 'exclude' will be ignored If multiple Filter extensions are provided, then, 1. All params specified as should be included within different Filter extension instances will determine the params that will finally be used. 2. If none of the Filter extensions specified any params as should be included, then the final effective params would be those left after removed all the params specified as should be excluded. It is recommended for most users to use 'exclude' policy for service params and 'include' policy for instance params. Please use 'params-filter=-default, -filterName1, filterName2' to activate or deactivate filter extensions."}
{"index": 5160, "repo": "dubbo-3.2.4", "code": "enum MetricsCategory {\n\t// \n\tstatic MetricsCategory valueOf(String name);\n\t// ,  \n\tstatic MetricsCategory[] values();\n}", "des": "Metric category."}
{"index": 5161, "repo": "dubbo-3.2.4", "code": "interface MetricsServiceExporter {\n\t// Exports the MetricsService as a Dubbo service\n\tMetricsServiceExporter export();\n\t// Initialize exporter\n\tvoid init();\n\t// Unexports the MetricsService\n\tMetricsServiceExporter unexport();\n}", "des": "The exporter of MetricsService"}
{"index": 5162, "repo": "dubbo-3.2.4", "code": "class Mixin {\n\t// mixin interface and delegates.\n\tstatic Mixin mixin(Class<?>[] ics, Class<?> dc);\n\t// mixin interface and delegates.\n\tstatic Mixin mixin(Class<?>[] ics, Class<?>[] dcs);\n\t// mixin interface and delegates.\n\tstatic Mixin mixin(Class<?>[] ics, Class<?>[] dcs, ClassLoader cl);\n\t// mixin interface and delegates.\n\tstatic Mixin mixin(Class<?>[] ics, Class<?> dc, ClassLoader cl);\n\t// new Mixin instance.\n\tabstract Object newInstance(Object[] ds);\n}", "des": "Mixin"}
{"index": 5163, "repo": "dubbo-3.2.4", "code": "class MockProtocol {\n\t// Export service for remote invocation: 1.\n\t<T> Exporter<T> export(Invoker<T> invoker);\n\t// Get default port when user doesn't config the port.\n\tint getDefaultPort();\n\t<T> Invoker<T> protocolBindingRefer(Class<T> type, URL url);\n}", "des": "MockProtocol is used for generating a mock invoker by URL and type on consumer side"}
{"index": 5164, "repo": "dubbo-3.2.4", "code": "interface ModuleDeployer {\n\tReferenceCache getReferenceCache();\n\tFuture getStartFuture();\n\t// Initialize the component\n\tvoid initialize();\n\t// Whether start in background, do not await finish\n\tboolean isBackground();\n\tboolean isInitialized();\n\tvoid postDestroy();\n\tvoid preDestroy();\n\tvoid prepare();\n\tvoid setPending();\n\t// Starts the component.\n\tFuture start();\n\t// Stops the component.\n\tvoid stop();\n}", "des": "Export/refer services of module"}
{"index": 5165, "repo": "dubbo-3.2.4", "code": "interface MonitorService {\n\t// Collect monitor data 1. support invocation count: count://host/interface?\n\tvoid collect(URL statistics);\n\t// Lookup monitor data 1. support lookup by day: count://host/interface?\n\tList<URL> lookup(URL query);\n}", "des": "MonitorService. (SPI, Prototype, ThreadSafe)"}
{"index": 5166, "repo": "dubbo-3.2.4", "code": "class MulticastServiceDiscovery {\n\tvoid doDestroy();\n\tvoid doRegister(ServiceInstance serviceInstance);\n\tvoid doUnregister(ServiceInstance serviceInstance);\n\t// Update Service Instance.\n\tvoid doUpdate(ServiceInstance oldServiceInstance, ServiceInstance newServiceInstance);\n\tList<ServiceInstance> getInstances(String serviceName);\n\t// Gets all service names\n\tSet<String> getServices();\n\tURL getUrl();\n}", "des": "TODO: make multicast protocol support Service Discovery"}
{"index": 5167, "repo": "dubbo-3.2.4", "code": "class MultiValueCodec {\n\tMediaType contentType();\n\t// content-type support judge\n\tboolean contentTypeSupport(MediaType mediaType, Class<?> targetType);\n\tObject decode(byte[] body, Class<?> targetType);\n\tvoid encode(OutputStream outputStream, Object unSerializedBody, URL url);\n\t// class type support judge\n\tboolean typeSupport(Class<?> targetType);\n}", "des": "body is form"}
{"index": 5168, "repo": "dubbo-3.2.4", "code": "interface MultiValueConverter<S> {\n\t// Accept the source type and target type or not\n\tboolean accept(Class<S> sourceType, Class<?> multiValueType);\n\t// Convert the source to be the multiple value\n\tObject convert(S source, Class<?> multiValueType, Class<?> elementType);\n\t// Get the source type\n\tdefault Class<S> getSourceType();\n}", "des": "An interface to convert the source-typed value to multiple value, e.g , Java array, Collection or sub-interfaces"}
{"index": 5169, "repo": "dubbo-3.2.4", "code": "class NacosRegistry {\n\t// destroy.\n\tvoid destroy();\n\tvoid doRegister(URL url);\n\tvoid doSubscribe(URL url, NotifyListener listener);\n\tvoid doUnregister(URL url);\n\tvoid doUnsubscribe(URL url, NotifyListener listener);\n\t// is available.\n\tboolean isAvailable();\n\t// Query the registered data that matches the conditions.\n\tList<URL> lookup(URL url);\n}", "des": "Nacos Registry"}
{"index": 5170, "repo": "dubbo-3.2.4", "code": "class NacosServiceDiscovery {\n\tvoid addServiceInstancesChangedListener(ServiceInstancesChangedListener listener);\n\tvoid doDestroy();\n\tvoid doRegister(ServiceInstance serviceInstance);\n\tvoid doUnregister(ServiceInstance serviceInstance);\n\tList<ServiceInstance> getInstances(String serviceName);\n\t// Gets all service names\n\tSet<String> getServices();\n\tURL getUrl();\n\t// unsubscribe to instance change event.\n\tvoid removeServiceInstancesChangedListener(ServiceInstancesChangedListener listener);\n}", "des": "Nacos ServiceDiscovery implementation"}
{"index": 5171, "repo": "dubbo-3.2.4", "code": "class NettyPortUnificationServer {\n\tvoid addSupportedProtocol(URL url, ChannelHandler handler);\n\tvoid bind();\n\t// close the channel.\n\tvoid close();\n\t// get channel.\n\tChannel getChannel(InetSocketAddress remoteAddress);\n\t// get channels.\n\tCollection<Channel> getChannels();\n\t// get local address.\n\tInetSocketAddress getLocalAddress();\n\t// is bound.\n\tboolean isBound();\n}", "des": "NettyServer"}
{"index": 5172, "repo": "dubbo-3.2.4", "code": "class NettyPortUnificationServer {\n\tvoid addSupportedProtocol(URL url, ChannelHandler handler);\n\tvoid bind();\n\t// Whether the implementation can sense and handle the idle connection.\n\tboolean canHandleIdle();\n\t// close the channel.\n\tvoid close();\n\tvoid doClose();\n\tvoid doOpen();\n\t// get channel.\n\tChannel getChannel(InetSocketAddress remoteAddress);\n\t// get channels.\n\tCollection<Channel> getChannels();\n\t// get local address.\n\tInetSocketAddress getLocalAddress();\n\t// is bound.\n\tboolean isBound();\n}", "des": "PortUnificationServer."}
{"index": 5173, "repo": "dubbo-3.2.4", "code": "class NettyServer {\n\t// get channel.\n\tChannel getChannel(InetSocketAddress remoteAddress);\n\t// get channels.\n\tCollection<Channel> getChannels();\n\t// is bound.\n\tboolean isBound();\n}", "des": "NettyServer"}
{"index": 5174, "repo": "dubbo-3.2.4", "code": "class NettyServer {\n\t// Whether the implementation can sense and handle the idle connection.\n\tboolean canHandleIdle();\n\t// get channel.\n\tChannel getChannel(InetSocketAddress remoteAddress);\n\t// get channels.\n\tCollection<Channel> getChannels();\n\t// is bound.\n\tboolean isBound();\n}", "des": "NettyServer."}
{"index": 5175, "repo": "dubbo-3.2.4", "code": "class NettyTransporter {\n\t// Bind a server.\n\tRemotingServer bind(URL url, ChannelHandler handler);\n\t// Connect to a server.\n\tClient connect(URL url, ChannelHandler handler);\n}", "des": "Default extension of Transporter using netty4.x."}
{"index": 5176, "repo": "dubbo-3.2.4", "code": "interface Node {\n\t// destroy.\n\tvoid destroy();\n\t// get url.\n\tURL getUrl();\n\t// is available.\n\tboolean isAvailable();\n}", "des": "Node. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5177, "repo": "dubbo-3.2.4", "code": "interface ObjectInput {\n\tdefault Map<String,Object> readAttachments();\n\tdefault String readEvent();\n\t// Consider use readObject(Class) or readObject(Class, Type) where possible\n\tObject readObject();\n\t// read object\n\t<T> T readObject(Class<T> cls);\n\t// read object\n\t<T> T readObject(Class<T> cls, Type type);\n\t// The following methods are customized for the requirement of Dubbo's RPC protocol implementation.\n\tdefault Throwable readThrowable();\n}", "des": "Object input interface."}
{"index": 5178, "repo": "dubbo-3.2.4", "code": "interface ObjectOutput {\n\tdefault void writeAttachments(Map<String,Object> attachments);\n\tdefault void writeEvent(String data);\n\t// write object.\n\tvoid writeObject(Object obj);\n\t// The following methods are customized for the requirement of Dubbo's RPC protocol implementation.\n\tdefault void writeThrowable(Throwable obj);\n}", "des": "Object output interface."}
{"index": 5179, "repo": "dubbo-3.2.4", "code": "interface OrderedPropertiesProvider {\n\t// load the properties\n\tProperties initProperties();\n\t// order\n\tint priority();\n}", "des": "The smaller value, the higher priority"}
{"index": 5180, "repo": "dubbo-3.2.4", "code": "interface Page<T> {\n\t// The data of current page\n\tList<T> getData();\n\t// The size of data\n\tdefault int getDataSize();\n\t// Gets the offset of request\n\tint getOffset();\n\t// Gets the size of request for pagination query\n\tint getPageSize();\n\t// Get the number of total pages.\n\tint getTotalPages();\n\t// Gets the total amount of elements.\n\tint getTotalSize();\n\t// Returns whether the page has data at all.\n\tdefault boolean hasData();\n\t// It indicates has next page or not\n\tboolean hasNext();\n}", "des": "The model class of pagination"}
{"index": 5181, "repo": "dubbo-3.2.4", "code": "class PathUtil {\n\t// generate real path from rawPath according to argInfo and method args\n\tstatic String resolvePathVariable(String rawPath, List<ArgInfo> argInfos, List<Object> args);\n\t// parse pathVariable index from url by annotation info\n\tstatic void setArgInfoSplitIndex(String rawPath, List<ArgInfo> argInfos);\n}", "des": "is used to parse url pathVariable"}
{"index": 5182, "repo": "dubbo-3.2.4", "code": "interface Predicates {\n\t// Predicate always return false\n\tstatic <T> Predicate<T> alwaysFalse();\n\t// Predicate always return true\n\tstatic <T> Predicate<T> alwaysTrue();\n\t// a composed predicate that represents a short-circuiting logical AND of predicates\n\tstatic <T> Predicate<T> and(Predicate<T>... predicates);\n\t// a composed predicate that represents a short-circuiting logical OR of predicates\n\tstatic <T> Predicate<T> or(Predicate<T>... predicates);\n}", "des": "The utilities class for Java Predicate"}
{"index": 5183, "repo": "dubbo-3.2.4", "code": "interface Protocol {\n\t// Destroy protocol: 1.\n\tvoid destroy();\n\t// Export service for remote invocation: 1.\n\t<T> Exporter<T> export(Invoker<T> invoker);\n\t// Get default port when user doesn't config the port.\n\tint getDefaultPort();\n\t// Get all servers serving this protocol\n\tdefault List<ProtocolServer> getServers();\n\t// Refer a remote service: 1.\n\t<T> Invoker<T> refer(Class<T> type, URL url);\n}", "des": "RPC Protocol extension interface, which encapsulates the details of remote invocation."}
{"index": 5184, "repo": "dubbo-3.2.4", "code": "class ProtocolFilterWrapper {\n\t// Destroy protocol: 1.\n\tvoid destroy();\n\t// Export service for remote invocation: 1.\n\t<T> Exporter<T> export(Invoker<T> invoker);\n\t// Get default port when user doesn't config the port.\n\tint getDefaultPort();\n\t// Get all servers serving this protocol\n\tList<ProtocolServer> getServers();\n\t// Refer a remote service: 1.\n\t<T> Invoker<T> refer(Class<T> type, URL url);\n}", "des": "ListenerProtocol"}
{"index": 5185, "repo": "dubbo-3.2.4", "code": "class ProtocolListenerWrapper {\n\t// Destroy protocol: 1.\n\tvoid destroy();\n\t// Export service for remote invocation: 1.\n\t<T> Exporter<T> export(Invoker<T> invoker);\n\t// Get default port when user doesn't config the port.\n\tint getDefaultPort();\n\t// Get all servers serving this protocol\n\tList<ProtocolServer> getServers();\n\t// Refer a remote service: 1.\n\t<T> Invoker<T> refer(Class<T> type, URL url);\n}", "des": "ListenerProtocol"}
{"index": 5186, "repo": "dubbo-3.2.4", "code": "class Proxy {\n\tClass<?> getClassToCreate();\n\t// Get proxy.\n\tstatic Proxy getProxy(Class<?>... ics);\n\t// get instance with default handler.\n\tObject newInstance();\n\t// get instance with special handler.\n\tObject newInstance(InvocationHandler handler);\n}", "des": "Proxy."}
{"index": 5187, "repo": "dubbo-3.2.4", "code": "interface ProxyFactory {\n\t// create invoker.\n\t<T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url);\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker);\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker, boolean generic);\n}", "des": "ProxyFactory. (API/SPI, Singleton, ThreadSafe)"}
{"index": 5188, "repo": "dubbo-3.2.4", "code": "class RangeValuePattern {\n\t// Is the pattern matches with the request context\n\tboolean match(String pattern, String value, URL url, Invocation invocation, boolean isWhenCondition);\n\t// Is the input pattern of a specific form, for example, range pattern '1~100', wildcard pattern 'hello*', etc.\n\tboolean shouldMatch(String pattern);\n}", "des": "Matches with patterns like 'key=1~100', 'key=~100' or 'key=1~'"}
{"index": 5189, "repo": "dubbo-3.2.4", "code": "class ReferenceCountedResource {\n\t// Useful when used together with try-with-resources pattern\n\tvoid close();\n\t// Decreases the reference count by 1 and calls this#destroy if the reference count reaches 0.\n\tboolean release();\n\t// Increments the reference count by 1.\n\tReferenceCountedResource retain();\n}", "des": "inspired by Netty"}
{"index": 5190, "repo": "dubbo-3.2.4", "code": "enum RegisterTypeEnum {\n\t// \n\tstatic RegisterTypeEnum valueOf(String name);\n\t// ,  \n\tstatic RegisterTypeEnum[] values();\n}", "des": "Indicate that a service need to be registered to registry or not"}
{"index": 5191, "repo": "dubbo-3.2.4", "code": "class RegistryDirectory<T> {\n\t// destroy.\n\tvoid destroy();\n\t// Haomin: added for test purpose\n\tMap<URL,Invoker<T>> getUrlInvokerMap();\n\tboolean isServiceDiscovery();\n\t// Triggered when a service change notification is received.\n\tvoid notify(List<URL> urls);\n\tvoid subscribe(URL url);\n\tvoid unSubscribe(URL url);\n}", "des": "RegistryDirectory"}
{"index": 5192, "repo": "dubbo-3.2.4", "code": "class RegistryManager {\n\tvoid clearRegistryNotDestroy();\n\t// Close all created registries\n\tvoid destroyAll();\n\tstatic RegistryManager getInstance(ApplicationModel applicationModel);\n\t// Get all registries\n\tCollection<Registry> getRegistries();\n\tRegistry getRegistry(String key);\n\tList<ServiceDiscovery> getServiceDiscoveries();\n\tvoid putRegistry(String key, Registry registry);\n\tvoid removeDestroyedRegistry(Registry toRm);\n\t// Reset state of AbstractRegistryFactory\n\tvoid reset();\n}", "des": "Application Level, used to collect Registries"}
{"index": 5193, "repo": "dubbo-3.2.4", "code": "interface RegistryProtocolListener {\n\t// Notify RegistryProtocol's listeners when the protocol is destroyed\n\tvoid onDestroy();\n\t// Notify RegistryProtocol's listeners when a service is registered\n\tvoid onExport(RegistryProtocol registryProtocol, Exporter<?> exporter);\n\t// Notify RegistryProtocol's listeners when a service is subscribed\n\tvoid onRefer(RegistryProtocol registryProtocol, ClusterInvoker<?> invoker, URL url, URL registryURL);\n}", "des": "RegistryProtocol listener is introduced to provide a chance to user to customize or change export and refer behavior of RegistryProtocol. For example: re-export or re-refer on the fly when certain condition meets."}
{"index": 5194, "repo": "dubbo-3.2.4", "code": "interface RemotingServer {\n\t// get channel.\n\tChannel getChannel(InetSocketAddress remoteAddress);\n\t// get channels.\n\tCollection<Channel> getChannels();\n\t// is bound.\n\tboolean isBound();\n}", "des": "Remoting Server. (API/SPI, Prototype, ThreadSafe)"}
{"index": 5195, "repo": "dubbo-3.2.4", "code": "class ScopeBeanExtensionInjector {\n\t// Get instance of specify type and name.\n\t<T> T getInstance(Class<T> type, String name);\n\t// Override this method if you need get the scope model (maybe one of FrameworkModel/ApplicationModel/ModuleModel).\n\tvoid setScopeModel(ScopeModel scopeModel);\n}", "des": "Inject scope bean to SPI extension instance"}
{"index": 5196, "repo": "dubbo-3.2.4", "code": "class ScriptStateRouter<T> {\n\t// To decide whether this router should take effect when none of the invoker can match the router rule, which means the StateRouter.route(BitList, URL, Invocation, boolean, Holder) would be empty.\n\tboolean isForce();\n\t// To decide whether this router need to execute every time an RPC comes or should only execute when addresses or rule change.\n\tboolean isRuntime();\n}", "des": "ScriptRouter"}
{"index": 5197, "repo": "dubbo-3.2.4", "code": "class SerializableClassRegistry {\n\t// get registered classes\n\tstatic Map<Class<?>,Object> getRegisteredClasses();\n\t// only supposed to be called at startup time\n\tstatic void registerClass(Class<?> clazz);\n\t// only supposed to be called at startup time\n\tstatic void registerClass(Class<?> clazz, Object serializer);\n}", "des": "Provide a unified serialization registry, this class used for dubbo-serialization-fst and dubbo-serialization-kryo, it will register some classes at startup time (for example AbstractKryoFactory#create)"}
{"index": 5198, "repo": "dubbo-3.2.4", "code": "interface ServerCall {\n\t// Close the call.\n\tvoid close(TriRpcStatus status, Map<String,Object> responseAttrs);\n\t// Request more request data from the client.\n\tvoid request(int numMessages);\n\t// Send message to client\n\tvoid sendMessage(Object message);\n}", "des": "ServerCall manipulates server details of a RPC call. Request messages are acquired by ServerCall.Listener. Backpressure is supported by request(int).Response messages are sent by sendMessage(Object)."}
{"index": 5199, "repo": "dubbo-3.2.4", "code": "interface ServerCall.Listener {\n\tvoid onCancel(TriRpcStatus status);\n\t// Request completed.\n\tvoid onComplete();\n\t// Callback when a request message is received.\n\tvoid onMessage(Object message, int actualContentLength);\n}", "des": "A listener to receive request messages."}
{"index": 5200, "repo": "dubbo-3.2.4", "code": "interface ServerStream {\n\t// Complete the stream, send response to client\n\tio.netty.util.concurrent.Future<?> complete(TriRpcStatus status, Map<String,Object> attachments, boolean isNeedReturnException, int exceptionCode);\n\t// Send message to client\n\tio.netty.util.concurrent.Future<?> sendMessage(byte[] message, int compressFlag);\n}", "des": "ServerStream is used to send response to client and receive requests from client. ServerStream.Listener is used to receive requests from client."}
{"index": 5201, "repo": "dubbo-3.2.4", "code": "class ServiceBean<T> {\n\tvoid afterPropertiesSet();\n\tvoid destroy();\n\t// Get the name of ServiceBean\n\tString getBeanName();\n\t// Gets associated Service\n\tService getService();\n\tvoid setApplicationContext(org.springframework.context.ApplicationContext applicationContext);\n\tvoid setApplicationEventPublisher(org.springframework.context.ApplicationEventPublisher applicationEventPublisher);\n\tvoid setBeanName(String name);\n}", "des": "ServiceFactoryBean"}
{"index": 5202, "repo": "dubbo-3.2.4", "code": "class ServiceDefinitionBuilder {\n\t// Describe a Java interface in ServiceDefinition.\n\tstatic ServiceDefinition build(Class<?> interfaceClass);\n\tstatic <T extends ServiceDefinition>void build(T sd, Class<?> interfaceClass);\n\tstatic FullServiceDefinition buildFullDefinition(Class<?> interfaceClass);\n\tstatic FullServiceDefinition buildFullDefinition(Class<?> interfaceClass, Map<String,String> params);\n\t// Describe a Java interface in Json schema.\n\tstatic String schema(Class<?> clazz);\n}", "des": "2015/1/27."}
{"index": 5203, "repo": "dubbo-3.2.4", "code": "interface ServiceDiscoveryFactory {\n\t// Get the extension instance of ServiceDiscoveryFactory by the protocol\n\tstatic ServiceDiscoveryFactory getExtension(URL registryURL);\n\t// Get the instance of ServiceDiscovery\n\tServiceDiscovery getServiceDiscovery(URL registryURL);\n}", "des": "The factory to create ServiceDiscovery"}
{"index": 5204, "repo": "dubbo-3.2.4", "code": "interface ServiceListener {\n\t// Callback when ServiceConfig is exported\n\tvoid exported(ServiceConfig sc);\n\t// Callback when ServiceConfig is unexported\n\tvoid unexported(ServiceConfig sc);\n}", "des": "Listener for service config"}
{"index": 5205, "repo": "dubbo-3.2.4", "code": "interface ServiceRestMetadataResolver {\n\t// Resolve the REST metadata from the specified Dubbo Service interface or type\n\tServiceRestMetadata resolve(Class<?> serviceType);\n\tServiceRestMetadata resolve(Class<?> serviceType, ServiceRestMetadata serviceRestMetadata);\n\t// Support to resolve REST metadata or not\n\tboolean supports(Class<?> serviceType);\n\tboolean supports(Class<?> serviceType, boolean consumer);\n}", "des": "The interface to resolve the REST metadata from the specified Dubbo Service interface or type."}
{"index": 5206, "repo": "dubbo-3.2.4", "code": "class ServicesLoadingStrategy {\n\tString directory();\n\tString getName();\n\t// Get the priority\n\tint getPriority();\n\t// Indicates current LoadingStrategy supports overriding other lower prioritized instances or not.\n\tboolean overridden();\n}", "des": "Services LoadingStrategy"}
{"index": 5207, "repo": "dubbo-3.2.4", "code": "class Snappy {\n\t// compress payload\n\tbyte[] compress(byte[] payloadByteArr);\n\t// decompress payload\n\tbyte[] decompress(byte[] payloadByteArr);\n\t// message encoding of current compressor\n\tString getMessageEncoding();\n}", "des": "snappy compressor, Provide high-speed compression speed and reasonable compression ratio"}
{"index": 5208, "repo": "dubbo-3.2.4", "code": "class SpringContainer {\n\tstatic org.springframework.context.support.ClassPathXmlApplicationContext getContext();\n\t// start method to load the container.\n\tvoid start();\n\t// stop method to unload the container.\n\tvoid stop();\n}", "des": "SpringContainer. (SPI, Singleton, ThreadSafe) The container class implementation for Spring"}
{"index": 5209, "repo": "dubbo-3.2.4", "code": "class Stack<E> {\n\t// clear stack.\n\tvoid clear();\n\t// get.\n\tE get(int index);\n\t// is empty.\n\tboolean isEmpty();\n\t// peek.\n\tE peek();\n\t// pop.\n\tE pop();\n\t// push.\n\tvoid push(E ele);\n\t// remove.\n\tE remove(int index);\n\t// set.\n\tE set(int index, E value);\n\t// get stack size.\n\tint size();\n}", "des": "Stack."}
{"index": 5210, "repo": "dubbo-3.2.4", "code": "class StaticDirectory<T> {\n\tvoid buildRouterChain();\n\t// destroy.\n\tvoid destroy();\n\t// list invokers include all invokers from registry\n\tList<Invoker<T>> getAllInvokers();\n\t// get service type.\n\tClass<T> getInterface();\n\t// is available.\n\tboolean isAvailable();\n\tvoid notify(List<Invoker<T>> invokers);\n}", "des": "StaticDirectory"}
{"index": 5211, "repo": "dubbo-3.2.4", "code": "enum Status.Level {\n\t// \n\tstatic Status.Level valueOf(String name);\n\t// ,  \n\tstatic Status.Level[] values();\n}", "des": "Level"}
{"index": 5212, "repo": "dubbo-3.2.4", "code": "interface Stream {\n\t// Cancel by this peer.\n\tio.netty.util.concurrent.Future<?> cancelByLocal(TriRpcStatus status);\n\t// Get remote peer address.\n\tSocketAddress remoteAddress();\n\t// Request n message from remote peer.\n\tvoid request(int n);\n\t// Send headers to remote peer.\n\tio.netty.util.concurrent.Future<?> sendHeader(io.netty.handler.codec.http2.Http2Headers headers);\n}", "des": "Stream is a bi-directional channel that manipulates the data flow between peers. Inbound data from remote peer is acquired by Stream.Listener. Outbound data to remote peer is sent directly by Stream. Backpressure is supported by request(int)."}
{"index": 5213, "repo": "dubbo-3.2.4", "code": "interface Stream.Listener {\n\t// Callback when receive cancel signal.\n\tvoid onCancelByRemote(TriRpcStatus status);\n\t// Callback when receive message.\n\tvoid onMessage(byte[] message, boolean isReturnTriException);\n}", "des": "Register a Stream.Listener to receive inbound data from remote peer."}
{"index": 5214, "repo": "dubbo-3.2.4", "code": "interface StreamObserver<T> {\n\t// onCompleted\n\tvoid onCompleted();\n\t// onError\n\tvoid onError(Throwable throwable);\n\t// onNext\n\tvoid onNext(T data);\n}", "des": "StreamObserver is a common streaming API. It is an observer for receiving messages. Implementations are NOT required to be thread-safe."}
{"index": 5215, "repo": "dubbo-3.2.4", "code": "class StringCodec {\n\tMediaType contentType();\n\t// content-type support judge\n\tboolean contentTypeSupport(MediaType mediaType, Class<?> targetType);\n\tObject decode(byte[] body, Class<?> targetType);\n\tvoid encode(OutputStream outputStream, Object unSerializedBody, URL url);\n\t// class type support judge\n\tboolean typeSupport(Class<?> targetType);\n}", "des": "body is string"}
{"index": 5216, "repo": "dubbo-3.2.4", "code": "class StringToArrayConverter {\n\t// Accept the source type and target type or not\n\tboolean accept(Class<String> type, Class<?> multiValueType);\n\t// Convert the segments to multiple value object\n\tObject convert(String[] segments, int size, Class<?> targetType, Class<?> elementType);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to array-type object"}
{"index": 5217, "repo": "dubbo-3.2.4", "code": "class StringToBooleanConverter {\n\t// Convert the source-typed value to the target-typed value\n\tBoolean convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Boolean"}
{"index": 5218, "repo": "dubbo-3.2.4", "code": "class StringToByteConverter {\n\t// Convert the source-typed value to the target-typed value\n\tByte convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Byte"}
{"index": 5219, "repo": "dubbo-3.2.4", "code": "class StringToCharacterConverter {\n\t// Convert the source-typed value to the target-typed value\n\tCharacter convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Character"}
{"index": 5220, "repo": "dubbo-3.2.4", "code": "class StringToCharArrayConverter {\n\t// Convert the source-typed value to the target-typed value\n\tchar[] convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to char[]"}
{"index": 5221, "repo": "dubbo-3.2.4", "code": "class StringToDoubleConverter {\n\t// Convert the source-typed value to the target-typed value\n\tDouble convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Double"}
{"index": 5222, "repo": "dubbo-3.2.4", "code": "class StringToFloatConverter {\n\t// Convert the source-typed value to the target-typed value\n\tFloat convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Float"}
{"index": 5223, "repo": "dubbo-3.2.4", "code": "class StringToIntegerConverter {\n\t// Convert the source-typed value to the target-typed value\n\tInteger convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Integer"}
{"index": 5224, "repo": "dubbo-3.2.4", "code": "class StringToIterableConverter<T extends Iterable> {\n\t// Accept the source type and target type or not\n\tboolean accept(Class<String> type, Class<?> multiValueType);\n\t// Convert the segments to multiple value object\n\tObject convert(String[] segments, int size, Class<?> multiValueType, Class<?> elementType);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Iterable-based value"}
{"index": 5225, "repo": "dubbo-3.2.4", "code": "class StringToLongConverter {\n\t// Convert the source-typed value to the target-typed value\n\tLong convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Long"}
{"index": 5226, "repo": "dubbo-3.2.4", "code": "interface StringToMultiValueConverter {\n\t// Convert the segments to multiple value object\n\tObject convert(String[] segments, int size, Class<?> targetType, Class<?> elementType);\n\t// Convert the source to be the multiple value\n\tdefault Object convert(String source, Class<?> multiValueType, Class<?> elementType);\n}", "des": "The class to convert String to multiple value object"}
{"index": 5227, "repo": "dubbo-3.2.4", "code": "class StringToOptionalConverter {\n\t// Convert the source-typed value to the target-typed value\n\tOptional convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Optional"}
{"index": 5228, "repo": "dubbo-3.2.4", "code": "class StringToShortConverter {\n\t// Convert the source-typed value to the target-typed value\n\tShort convert(String source);\n\t// Get the priority\n\tint getPriority();\n}", "des": "The class to convert String to Short"}
{"index": 5229, "repo": "dubbo-3.2.4", "code": "class StubProxyFactory {\n\t// create invoker.\n\t<T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url);\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker);\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker, boolean generic);\n}", "des": "Stub proxy factory is used to generate non-reflection invoker and proxy. It relies on Dubbo3 Triple compiler."}
{"index": 5230, "repo": "dubbo-3.2.4", "code": "class StubProxyFactoryWrapper {\n\t// create invoker.\n\t<T> Invoker<T> getInvoker(T proxy, Class<T> type, URL url);\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker);\n\t// create proxy.\n\t<T> T getProxy(Invoker<T> invoker, boolean generic);\n\tvoid setProtocol(Protocol protocol);\n}", "des": "StubProxyFactoryWrapper"}
{"index": 5231, "repo": "dubbo-3.2.4", "code": "class TextCodec {\n\tMediaType contentType();\n\t// content-type support judge\n\tboolean contentTypeSupport(MediaType mediaType, Class<?> targetType);\n\tObject decode(byte[] body, Class<?> targetType);\n\tvoid encode(OutputStream outputStream, Object unSerializedBody, URL url);\n\t// class type support judge\n\tboolean typeSupport(Class<?> targetType);\n}", "des": "content-type is text/html"}
{"index": 5232, "repo": "dubbo-3.2.4", "code": "class ThreadLocalCache {\n\t// API to return stored value using a key against the calling thread specific store.\n\tObject get(Object key);\n\t// API to store value against a key in the calling thread scope.\n\tvoid put(Object key, Object value);\n}", "des": "This class store the cache value per thread. If a service,method,consumer or provided is configured with key cache with value threadlocal, dubbo initialize the instance of this class using ThreadLocalCacheFactory to store method's returns value to server from store without making method call."}
{"index": 5233, "repo": "dubbo-3.2.4", "code": "interface ThrowableAction {\n\t// Executes the action\n\tvoid execute();\n\t// Executes ThrowableAction\n\tstatic void execute(ThrowableAction action);\n}", "des": "A function interface for action with Throwable"}
{"index": 5234, "repo": "dubbo-3.2.4", "code": "interface ThrowableConsumer<T> {\n\t// Applies this function to the given argument.\n\tvoid accept(T t);\n\t// Executes ThrowableConsumer\n\tdefault void execute(T t);\n\t// Executes ThrowableConsumer\n\tstatic <T> void execute(T t, ThrowableConsumer<T> consumer);\n}", "des": "Consumer with Throwable"}
{"index": 5235, "repo": "dubbo-3.2.4", "code": "interface ThrowableFunction<T,R> {\n\t// Applies this function to the given argument.\n\tR apply(T t);\n\t// Executes ThrowableFunction\n\tdefault R execute(T t);\n\t// Executes ThrowableFunction\n\tstatic <T,R> R execute(T t, ThrowableFunction<T,R> function);\n}", "des": "Function with Throwable"}
{"index": 5236, "repo": "dubbo-3.2.4", "code": "interface Timeout {\n\t// Attempts to cancel the TimerTask associated with this handle.\n\tboolean cancel();\n\t// Returns true if and only if the TimerTask associated with this handle has been cancelled.\n\tboolean isCancelled();\n\t// Returns true if and only if the TimerTask associated with this handle has been expired.\n\tboolean isExpired();\n\t// Returns the TimerTask which is associated with this handle.\n\tTimerTask task();\n\t// Returns the Timer that created this handle.\n\tTimer timer();\n}", "des": "A handle associated with a TimerTask that is returned by a Timer."}
{"index": 5237, "repo": "dubbo-3.2.4", "code": "interface Timer {\n\t// the timer is stop\n\tboolean isStop();\n\t// Schedules the specified TimerTask for one-time execution after the specified delay.\n\tTimeout newTimeout(TimerTask task, long delay, TimeUnit unit);\n\t// Releases all resources acquired by this Timer and cancels all tasks which were scheduled but not executed yet.\n\tSet<Timeout> stop();\n}", "des": "Schedules TimerTasks for one-time future execution in a background thread."}
{"index": 5238, "repo": "dubbo-3.2.4", "code": "class TLadder {\n\t// add one item\n\tTLadder addItem(String item);\n\t// render\n\tString rendering();\n}", "des": "Ladder"}
{"index": 5239, "repo": "dubbo-3.2.4", "code": "interface Transporter {\n\t// Bind a server.\n\tRemotingServer bind(URL url, ChannelHandler handler);\n\t// Connect to a server.\n\tClient connect(URL url, ChannelHandler handler);\n}", "des": "Transporter. (SPI, Singleton, ThreadSafe)"}
{"index": 5240, "repo": "dubbo-3.2.4", "code": "class TripleInvoker<T> {\n\t// destroy.\n\tvoid destroy();\n\t// is available.\n\tboolean isAvailable();\n}", "des": "TripleInvoker"}
{"index": 5241, "repo": "dubbo-3.2.4", "code": "class TTable {\n\t// Add a row\n\tTTable addRow(Object... columnDataArray);\n\t// get border\n\tTTable.Border getBorder();\n\t// get column count\n\tint getColumnCount();\n\t// set padding\n\tTTable padding(int padding);\n\t// render\n\tString rendering();\n\tstatic String wrap(String string, int width);\n}", "des": "Table"}
{"index": 5242, "repo": "dubbo-3.2.4", "code": "enum TTable.Align {\n\t// \n\tstatic TTable.Align valueOf(String name);\n\t// ,  \n\tstatic TTable.Align[] values();\n}", "des": "alignment"}
{"index": 5243, "repo": "dubbo-3.2.4", "code": "class TTable.ColumnDefine {\n\t// get rows for the current column\n\tint getRowCount();\n\t// get current width\n\tint getWidth();\n}", "des": "column definition"}
{"index": 5244, "repo": "dubbo-3.2.4", "code": "class TTree {\n\tTTree begin();\n\t// create a branch node\n\tTTree begin(Object data);\n\t// end a branch node\n\tTTree end();\n\tObject get();\n\tboolean isTop();\n\t// render\n\tString rendering();\n\tTTree set(Object data);\n}", "des": "tree"}
{"index": 5245, "repo": "dubbo-3.2.4", "code": "interface TypeBuilder {\n\t// Whether the build accept the class passed in.\n\tboolean accept(Class<?> clazz);\n\t// Build type definition with the type or class.\n\tTypeDefinition build(Type type, Class<?> clazz, Map<String,TypeDefinition> typeCache);\n}", "des": "2015/1/27."}
{"index": 5246, "repo": "dubbo-3.2.4", "code": "class TypeDefinition {\n\tboolean equals(Object o);\n\t// Format the String presenting Java type\n\tstatic String formatType(String type);\n\t// Format the String array presenting Java types\n\tstatic String[] formatTypes(String[] types);\n\tList<String> getEnums();\n\tList<String> getItems();\n\tMap<String,String> getProperties();\n\tString getType();\n\tvoid setEnums(List<String> enums);\n\tvoid setItems(List<String> items);\n\tvoid setProperties(Map<String,String> properties);\n\tvoid setType(String type);\n}", "des": "2015/1/27."}
{"index": 5247, "repo": "dubbo-3.2.4", "code": "class ValidationFilter {\n\t// Perform the validation of before invoking the actual method based on validation attribute value.\n\tResult invoke(Invoker<?> invoker, Invocation invocation);\n\t// Sets the validation instance for ValidationFilter\n\tvoid setValidation(Validation validation);\n}", "des": "ValidationFilter invoke the validation by finding the right Validator instance based on the configured validation attribute value of invoker url before the actual method invocation."}
{"index": 5248, "repo": "dubbo-3.2.4", "code": "class WildcardValuePattern {\n\t// Is the pattern matches with the request context\n\tboolean match(String pattern, String value, URL url, Invocation invocation, boolean isWhenCondition);\n\t// Is the input pattern of a specific form, for example, range pattern '1~100', wildcard pattern 'hello*', etc.\n\tboolean shouldMatch(String key);\n}", "des": "Matches with patterns like 'key=hello', 'key=hello*', 'key=*hello', 'key=h*o' or 'key=*'"}
{"index": 5249, "repo": "dubbo-3.2.4", "code": "class XMLCodec {\n\tMediaType contentType();\n\t// content-type support judge\n\tboolean contentTypeSupport(MediaType mediaType, Class<?> targetType);\n\tObject decode(byte[] body, Class<?> targetType);\n\tvoid encode(OutputStream outputStream, Object unSerializedBody, URL url);\n\t// class type support judge\n\tboolean typeSupport(Class<?> targetType);\n}", "des": "body content-type is xml"}
{"index": 5250, "repo": "dubbo-3.2.4", "code": "class ZookeeperRegistry {\n\t// destroy.\n\tvoid destroy();\n\tvoid doRegister(URL url);\n\tvoid doSubscribe(URL url, NotifyListener listener);\n\tvoid doUnregister(URL url);\n\tvoid doUnsubscribe(URL url, NotifyListener listener);\n\t// is available.\n\tboolean isAvailable();\n\t// Query the registered data that matches the conditions.\n\tList<URL> lookup(URL url);\n}", "des": "ZookeeperRegistry"}
{"index": 5251, "repo": "dubbo-3.2.4", "code": "class ZookeeperServiceDiscovery {\n\tvoid addServiceInstancesChangedListener(ServiceInstancesChangedListener listener);\n\tvoid doDestroy();\n\tvoid doRegister(ServiceInstance serviceInstance);\n\tvoid doUnregister(ServiceInstance serviceInstance);\n\tList<ServiceInstance> getInstances(String serviceName);\n\t// Gets all service names\n\tSet<String> getServices();\n\t// unsubscribe to instance change event.\n\tvoid removeServiceInstancesChangedListener(ServiceInstancesChangedListener listener);\n}", "des": "Zookeeper ServiceDiscovery implementation based on Apache Curator X Discovery"}
{"index": 5252, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractActionMethodEndpointMapping {\n\t// Returns the action value for the specified method.\n\tprotected abstract URI getActionForMethod(Method method);\n\t// Return the class or interface to use for method reflection.\n\tprotected Class<?> getEndpointClass(Object endpoint);\n\t// Helper method that registers the methods of the given bean.\n\tprotected void registerMethods(Object endpoint);\n}", "des": "Abstract base class for WS-Addressing Action-mapped EndpointMapping implementations that map to MethodEndpoints. Provides infrastructure for mapping endpoint methods to actions."}
{"index": 5253, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractAnnotationMethodEndpointMapping<T> {\n\t// Returns the 'endpoint' annotation type.\n\tprotected Class<? extends Annotation> getEndpointAnnotationType();\n\t// Initializes the interceptors.\n\tprotected void initApplicationContext();\n\t// Set whether to detect endpoint beans in ancestor ApplicationContexts.\n\tvoid setDetectEndpointsInAncestorContexts(boolean detectEndpointsInAncestorContexts);\n}", "des": "Abstract base for EndpointMapping implementations that map classes tagged with an annotation. By default the annotation is Endpoint, but this can be overriden in subclasses."}
{"index": 5254, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractCachingDestinationProvider {\n\t// Return the destination URI.\n\tURI getDestination();\n\t// Abstract template method that looks up the URI.\n\tprotected abstract URI lookupDestination();\n\t// Set whether to cache resolved destinations.\n\tvoid setCache(boolean cache);\n}", "des": "Abstract base class for DestinationProvider implementations that cache destination URI."}
{"index": 5255, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractCallbackHandler {\n\t// Iterates over the given callbacks, and calls handleInternal for each of them.\n\tvoid handle(Callback[] callbacks);\n\t// Template method that should be implemented by subclasses.\n\tprotected abstract void handleInternal(Callback callback);\n}", "des": "Abstract implementation of a CallbackHandler."}
{"index": 5256, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractHttpWebServiceMessageSender {\n\t// Return whether to accept GZIP encoding, that is, whether to send the HTTP Accept-Encoding header with gzip as value.\n\tboolean isAcceptGzipEncoding();\n\t// Set whether to accept GZIP encoding, that is, whether to send the HTTP Accept-Encoding header with gzip as value.\n\tvoid setAcceptGzipEncoding(boolean acceptGzipEncoding);\n\t// Does this WebServiceMessageSender support the supplied URI?\n\tboolean supports(URI uri);\n}", "des": "Abstract base class for WebServiceMessageSender implementations that use HTTP."}
{"index": 5257, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractJaasValidationCallbackHandler {\n\tvoid afterPropertiesSet();\n\t// Returns the login context name.\n\tString getLoginContextName();\n\t// Sets the login context name.\n\tvoid setLoginContextName(String loginContextName);\n}", "des": "Abstract base class for integrating with JAAS. Provides a login context name property."}
{"index": 5258, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractMessageCreator {\n\t// Create a message.\n\tWebServiceMessage createMessage(WebServiceMessageFactory messageFactory);\n\t// Abstract template method, invoked by createMessage(WebServiceMessageFactory) after a message has been created.\n\tprotected abstract void doWithMessage(WebServiceMessage message);\n}", "des": "Abstract base class for the WebServiceMessageCreator interface."}
{"index": 5259, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractMimeMessage {\n\t// Add an attachment to the message, taking the content from a File.\n\tAttachment addAttachment(String contentId, File file);\n\t// Add an attachment to the message, taking the content from an InputStreamSource.\n\tAttachment addAttachment(String contentId, org.springframework.core.io.InputStreamSource inputStreamSource, String contentType);\n}", "des": "Abstract implementation of the MimeMessage interface. Contains convenient default implementations."}
{"index": 5260, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractQNameEndpointMapping {\n\t// Returns the endpoint key for the given message context.\n\tprotected String getLookupKeyForMessage(MessageContext messageContext);\n\t// Template method that resolves the qualified names from the given SOAP message.\n\tprotected abstract QName resolveQName(MessageContext messageContext);\n\t// Validates the given endpoint key.\n\tprotected boolean validateLookupKey(String key);\n}", "des": "Abstract base class for EndpointMappings that resolve qualified names as registration keys."}
{"index": 5261, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class AbstractSoapMessageMatcher {\n\t// Abstract template method that gets invoked from match(WebServiceMessage) if the given message is a SoapMessage.\n\tprotected abstract void match(SoapMessage soapMessage);\n\t// Matches the given message against the expectations.\n\tvoid match(WebServiceMessage message);\n}", "des": "Abstract base class for SOAP-specific WebServiceMessageMatcher implementations."}
{"index": 5262, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface Attachment {\n\t// Returns the content identifier of the attachment.\n\tString getContentId();\n\t// Returns the content type of the attachment.\n\tString getContentType();\n\t// Returns the data handler of the attachment.\n\tDataHandler getDataHandler();\n\t// Return an InputStream to read the contents of the attachment from.\n\tInputStream getInputStream();\n\t// Returns the size of the attachment in bytes.\n\tlong getSize();\n}", "des": "Represents an attachment to a MimeMessage"}
{"index": 5263, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface ClientInterceptor {\n\t// Callback after completion of request and response (fault) processing.\n\tvoid afterCompletion(MessageContext messageContext, Exception ex);\n\t// Processes the incoming response fault.\n\tboolean handleFault(MessageContext messageContext);\n\t// Processes the outgoing request message.\n\tboolean handleRequest(MessageContext messageContext);\n\t// Processes the incoming response message.\n\tboolean handleResponse(MessageContext messageContext);\n}", "des": "Workflow interface that allows for customized client-side message interception. Applications can register any number of existing or custom interceptors on a WebServiceTemplate, to add common pre- and postprocessing behavior without needing to modify payload handling code."}
{"index": 5264, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class ClientInterceptorAdapter {\n\t// Does nothing by default.\n\tvoid afterCompletion(MessageContext messageContext, Exception ex);\n\t// Processes the incoming response fault.\n\tboolean handleFault(MessageContext messageContext);\n\t// Processes the outgoing request message.\n\tboolean handleRequest(MessageContext messageContext);\n\t// Processes the incoming response message.\n\tboolean handleResponse(MessageContext messageContext);\n}", "des": "Default implementation of the ClientInterceptor interface, for simplified implementation of pre-only/post-only interceptors."}
{"index": 5265, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class CommonsXsdSchema {\n\t// Creates a XmlValidator based on the schema.\n\tXmlValidator createValidator();\n\tQName[] getElementNames();\n\t// Returns the wrapped Commons XmlSchema object.\n\torg.apache.ws.commons.schema.XmlSchema getSchema();\n\t// Returns the Source of the schema.\n\tSource getSource();\n\t// Returns the target namespace of this schema.\n\tString getTargetNamespace();\n}", "des": "Implementation of the XsdSchema interface that uses Apache WS-Commons XML Schema."}
{"index": 5266, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class DiffMatcher {\n\t// Creates a Diff for the given message.\n\tprotected abstract org.custommonkey.xmlunit.Diff createDiff(WebServiceMessage message);\n\t// Matches the given message against the expectations.\n\tvoid match(WebServiceMessage message);\n}", "des": "Implementation of WebServiceMessageMatcher based on XMLUnit's Diff."}
{"index": 5267, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class DomPoxMessage {\n\t// Returns the document underlying this message.\n\tDocument getDocument();\n\tString getFaultReason();\n\t// Returns the contents of the message as a Result.\n\tResult getPayloadResult();\n\t// Returns the contents of the message as a Source.\n\tSource getPayloadSource();\n\tboolean hasFault();\n\t// Writes the entire message to the given output stream.\n\tvoid writeTo(OutputStream outputStream);\n}", "des": "Implementation of the PoxMessage interface that is based on a DOM Document."}
{"index": 5268, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface EndpointAdapter {\n\t// Use the given endpoint to handle the request.\n\tvoid invoke(MessageContext messageContext, Object endpoint);\n\t// Does this EndpointAdapter support the given endpoint?\n\tboolean supports(Object endpoint);\n}", "des": "Interface that must be implemented for each endpoint type to handle a message request. This interface is used to allow the MessageDispatcher to be indefinitely extensible. It accesses all installed endpoints through this interface, meaning that is does not contain code specific to any endpoint type."}
{"index": 5269, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class EndpointInterceptorAdapter {\n\t// Does nothing by default.\n\tvoid afterCompletion(MessageContext messageContext, Object endpoint, Exception ex);\n\t// Returns true.\n\tboolean handleFault(MessageContext messageContext, Object endpoint);\n\t// Returns true.\n\tboolean handleRequest(MessageContext messageContext, Object endpoint);\n\t// Returns true.\n\tboolean handleResponse(MessageContext messageContext, Object endpoint);\n\t// Returns false.\n\tboolean understands(Element header);\n}", "des": "Default implementation of the EndpointInterceptor interface, for simplified implementation of pre-only/post-only interceptors."}
{"index": 5270, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class EndpointInvocationChain {\n\t// Returns the endpoint object to invoke.\n\tObject getEndpoint();\n\t// Returns the array of interceptors to apply before the handler executes.\n\tEndpointInterceptor[] getInterceptors();\n}", "des": "Endpoint invocation chain, consisting of an endpoint object and any preprocessing interceptors."}
{"index": 5271, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class EndpointReference {\n\tboolean equals(Object o);\n\t// Returns the address of the endpoint.\n\tURI getAddress();\n\t// Returns the reference parameters of the endpoint, as a list of Node objects.\n\tList<Node> getReferenceParameters();\n\t// Returns the reference properties of the endpoint, as a list of Node objects.\n\tList<Node> getReferenceProperties();\n}", "des": "Represents an Endpoint Reference, as defined in the WS-Addressing specification."}
{"index": 5272, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface FaultAwareWebServiceConnection {\n\t// Indicates whether this connection received a fault.\n\tboolean hasFault();\n\t// Sets a specific fault code.\n\tvoid setFaultCode(QName faultCode);\n}", "des": "Sub-interface of WebServiceConnection that is aware of any Fault messages received. Fault messages (such as SoapFault SOAP Faults) often require different processing rules. Typically, fault detection is done by inspecting connection error codes, etc."}
{"index": 5273, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface FaultAwareWebServiceMessage {\n\t// Returns the fault code, if any.\n\tQName getFaultCode();\n\t// Returns the fault reason message.\n\tString getFaultReason();\n\t// Does this message have a fault?\n\tboolean hasFault();\n}", "des": "Sub-interface of WebServiceMessage that can contain special Fault messages. Fault messages (such as SoapFault SOAP Faults) often require different processing rules."}
{"index": 5274, "repo": "spring-ws-3.0.10.RELEASE", "code": "Enum FaultCode {\n\tQName value();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FaultCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FaultCode[] values();\n}", "des": "Enumeration that represents the standard SOAP Fault codes for use with the JDK 1.5+ SoapFault annotation."}
{"index": 5275, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface HeadersAwareReceiverWebServiceConnection {\n\t// Adds a response header with the given name and value.\n\tvoid addResponseHeader(String name, String value);\n\t// Returns an iteration over all the header names this request contains.\n\tIterator<String> getRequestHeaderNames();\n\t// Returns an iteration over all the string values of the specified header.\n\tIterator<String> getRequestHeaders(String name);\n}", "des": "Interface to define access to header information for certain WebServiceConnection implementations."}
{"index": 5276, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class HttpUrlConnectionMessageSender {\n\t// Create a new WebServiceConnection to the specified URI.\n\tWebServiceConnection createConnection(URI uri);\n\t// Template method for preparing the given HttpURLConnection.\n\tprotected void prepareConnection(HttpURLConnection connection);\n\t// Sets the timeout until a connection is established.\n\tvoid setConnectionTimeout(Duration connectTimeout);\n\t// Set the socket read timeout.\n\tvoid setReadTimeout(Duration readTimeout);\n}", "des": "WebServiceMessageSender implementation that uses standard J2SE facilities to execute POST requests, without support for HTTP authentication or advanced configuration options."}
{"index": 5277, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class InliningXsdSchemaTypesProvider {\n\tvoid addTypes(javax.wsdl.Definition definition);\n\t// Returns the XSD schema collection to inline.\n\tXsdSchemaCollection getSchemaCollection();\n\t// Sets the single XSD schema to inline.\n\tvoid setSchema(XsdSchema schema);\n\t// Sets the XSD schema collection to inline.\n\tvoid setSchemaCollection(XsdSchemaCollection schemaCollection);\n}", "des": "Implementation of TypesProvider that inlines a XsdSchema or XsdSchemaCollection into the WSDL."}
{"index": 5278, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class JaxpVersion {\n\t// Gets the JAXP version.\n\tstatic int getJaxpVersion();\n\t// Convenience method to determine if the current JAXP version is at least 1.4 (packaged with JDK 1.6).\n\tstatic boolean isAtLeastJaxp14();\n}", "des": "Helper class used to find the current version of JAXP. We cannot depend on the Java version, since JAXP can be upgraded independently of the Java version."}
{"index": 5279, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class JmsMessageReceiver {\n\t// Handles an incoming message.\n\tprotected void handleMessage(javax.jms.Message request, javax.jms.Session session);\n\t// Sets the optional MessagePostProcessor to further modify outgoing messages after the XML contents has been set.\n\tvoid setPostProcessor(org.springframework.jms.core.MessagePostProcessor postProcessor);\n\t// Sets the encoding used to read from and write to TextMessage messages.\n\tvoid setTextMessageEncoding(String textMessageEncoding);\n}", "des": "Convenience base class for JMS server-side transport objects. Contains a WebServiceMessageReceiver, and has methods for handling incoming JMS BytesMessage and TextMessage requests. Also contains a textMessageEncoding property, which determines the encoding used to read from and write to TextMessages. This property defaults to UTF-8."}
{"index": 5280, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class KeyManagersFactoryBean {\n\tvoid afterPropertiesSet();\n\tKeyManager[] getObject();\n\tClass<?> getObjectType();\n\tboolean isSingleton();\n\t// Sets the algorithm of the KeyManager to use.\n\tvoid setAlgorithm(String algorithm);\n\t// Sets the source of key material.\n\tvoid setKeyStore(KeyStore keyStore);\n\t// Sets the password to use for integrity checking.\n\tvoid setPassword(String password);\n\t// Sets the provider of the key manager to use.\n\tvoid setProvider(String provider);\n}", "des": "Spring factory bean for an array of KeyManagers."}
{"index": 5281, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class KeyStoreFactoryBean {\n\tvoid afterPropertiesSet();\n\tKeyStore getObject();\n\tClass<KeyStore> getObjectType();\n\tboolean isSingleton();\n\t// Sets the location of the key store to use.\n\tvoid setLocation(org.springframework.core.io.Resource location);\n\t// Sets the password to use for integrity checking.\n\tvoid setPassword(String password);\n\t// Sets the provider of the key store to use.\n\tvoid setProvider(String provider);\n\t// Sets the type of the KeyStore to use.\n\tvoid setType(String type);\n}", "des": "Spring factory bean for a KeyStore."}
{"index": 5282, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class KeyStoreUtils {\n\t// Loads the key store indicated by system properties.\n\tstatic KeyStore loadDefaultKeyStore();\n\t// Loads a default trust store.\n\tstatic KeyStore loadDefaultTrustStore();\n}", "des": "Generic utility methods for dealing with KeyStore objects."}
{"index": 5283, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class LocationTransformerObjectSupport {\n\t// Transform the given location string to reflect the given request.\n\tprotected String transformLocation(String location, javax.servlet.http.HttpServletRequest request);\n\t// Transforms the locations of the given definition document using the given XPath expression.\n\tprotected void transformLocations(XPathExpression xPathExpression, Document definitionDocument, javax.servlet.http.HttpServletRequest request);\n}", "des": "Abstract base class for WsdlDefinitionHandlerAdapter and XsdSchemaHandlerAdapter that transforms XSD and WSDL location attributes."}
{"index": 5284, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class MarshallingUtils {\n\t// Marshals the given object to the payload of the given message using the provided Marshaller.\n\tstatic void marshal(org.springframework.oxm.Marshaller marshaller, Object graph, WebServiceMessage message);\n\t// Unmarshals the payload of the given message using the provided Unmarshaller.\n\tstatic Object unmarshal(org.springframework.oxm.Unmarshaller unmarshaller, WebServiceMessage message);\n}", "des": "Helper class for endpoints and endpoint mappings that use marshalling."}
{"index": 5285, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class MessageContextMethodArgumentResolver {\n\t// Resolves the given parameter into a method argument.\n\tMessageContext resolveArgument(MessageContext messageContext, org.springframework.core.MethodParameter parameter);\n\t// Indicates whether the given method parameter is supported by this resolver.\n\tboolean supportsParameter(org.springframework.core.MethodParameter parameter);\n}", "des": "Implementation of MethodArgumentResolver that supports MessageContext arguments."}
{"index": 5286, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class MessageEndpointAdapter {\n\t// Use the given endpoint to handle the request.\n\tvoid invoke(MessageContext messageContext, Object endpoint);\n\t// Does this EndpointAdapter support the given endpoint?\n\tboolean supports(Object endpoint);\n}", "des": "Adapter to use a MessageEndpoint as the endpoint for a EndpointInvocationChain."}
{"index": 5287, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface MessageIdStrategy {\n\t// Indicates whether the given MessageID value is a duplicate or not\n\tboolean isDuplicate(URI messageId);\n\t// Returns a new WS-Addressing MessageID for the given SoapMessage.\n\tURI newMessageId(SoapMessage message);\n}", "des": "Strategy interface that encapsulates the creation and validation of WS-Addressing MessageIDs."}
{"index": 5288, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface MethodArgumentResolver {\n\t// Resolves the given parameter into a method argument.\n\tObject resolveArgument(MessageContext messageContext, org.springframework.core.MethodParameter parameter);\n\t// Indicates whether the given method parameter is supported by this resolver.\n\tboolean supportsParameter(org.springframework.core.MethodParameter parameter);\n}", "des": "Strategy interface used to resolve method parameters into arguments. This interface is used to allow the DefaultMethodEndpointAdapter to be indefinitely extensible."}
{"index": 5289, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface MethodReturnValueHandler {\n\t// Handles the given return value.\n\tvoid handleReturnValue(MessageContext messageContext, org.springframework.core.MethodParameter returnType, Object returnValue);\n\t// Indicates whether the given method return type is supported by this handler.\n\tboolean supportsReturnType(org.springframework.core.MethodParameter returnType);\n}", "des": "Strategy interface used to handle method return values. This interface is used to allow the DefaultMethodEndpointAdapter to be indefinitely extensible."}
{"index": 5290, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class MockStrategiesHelper {\n\t// Returns the application context.\n\torg.springframework.context.ApplicationContext getApplicationContext();\n\t// Returns a single strategy found in the given application context.\n\t<T> T getStrategy(Class<T> type);\n\t// Returns a single strategy found in the given application context, or instantiates a default strategy if no applicable strategy was found.\n\t<T,D extends T>T getStrategy(Class<T> type, Class<D> defaultType);\n}", "des": "Helper class for for loading default implementations of an interface."}
{"index": 5291, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class MockWebServiceMessageSender {\n\t// Create a new WebServiceConnection to the specified URI.\n\torg.springframework.ws.test.client.MockSenderConnection createConnection(URI uri);\n\t// Always returns true.\n\tboolean supports(URI uri);\n}", "des": "Mock implementation of WebServiceMessageSender. Contains a list of expected MockSenderConnections, and iterates over those."}
{"index": 5292, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface MonitoringStrategy {\n\t// Returns the folder open mode to be used by this strategy.\n\tint getFolderOpenMode();\n\t// Monitors the given folder, and returns any new messages when they arrive.\n\tjavax.mail.Message[] monitor(javax.mail.Folder folder);\n}", "des": "Defines the contract for objects that monitor a given folder for new messages. Allows for multiple implementation strategies, including polling, or event-driven techniques such as IMAP's IDLE command."}
{"index": 5293, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class PayloadEndpointAdapter {\n\t// Use the given endpoint to handle the request.\n\tvoid invoke(MessageContext messageContext, Object endpoint);\n\t// Does this EndpointAdapter support the given endpoint?\n\tboolean supports(Object endpoint);\n}", "des": "Adapter to use a PayloadEndpoint as the endpoint for a EndpointInvocationChain."}
{"index": 5294, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class PayloadRootAnnotationMethodEndpointMapping {\n\t// Returns the endpoint keys for the given message context.\n\tprotected QName getLookupKeyForMessage(MessageContext messageContext);\n\t// Returns the endpoint keys for the given method.\n\tprotected List<QName> getLookupKeysForMethod(Method method);\n\t// Override the default TransformerFactory.\n\tstatic void setTransformerFactory(TransformerFactory transformerFactory);\n}", "des": "Implementation of the EndpointMapping interface that uses the PayloadRoot annotation to map methods to request payload root elements."}
{"index": 5295, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class PayloadRootQNameEndpointMapping {\n\t// Template method that resolves the qualified names from the given SOAP message.\n\tprotected QName resolveQName(MessageContext messageContext);\n\t// Override the default TransformerFactory.\n\tstatic void setTransformerFactory(TransformerFactory transformerFactory);\n}", "des": "Implementation of the EndpointMapping interface to map from the qualified name of the request payload root element. Supports both mapping to bean instances and mapping to bean names: the latter is required for prototype endpoints."}
{"index": 5296, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class PayloadValidatingInterceptor {\n\t// Returns the part of the request message that is to be validated.\n\tprotected Source getValidationRequestSource(WebServiceMessage request);\n\t// Returns the part of the response message that is to be validated.\n\tprotected Source getValidationResponseSource(WebServiceMessage response);\n}", "des": "Client-side interceptor that validates the contents of WebServiceMessages using a schema. Allows for both W3C XML and RELAX NG schemas."}
{"index": 5297, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class PayloadValidatingInterceptor {\n\t// Returns the payload source of the given message.\n\tprotected Source getValidationRequestSource(WebServiceMessage request);\n\t// Returns the payload source of the given message.\n\tprotected Source getValidationResponseSource(WebServiceMessage response);\n}", "des": "Interceptor that validates the contents of WebServiceMessages using a schema. Allows for both W3C XML and RELAX NG schemas."}
{"index": 5298, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class PollingMonitoringStrategy {\n\t// Invoked after the Thread.sleep(long) method has been invoked.\n\tprotected void afterSleep(javax.mail.Folder folder);\n\t// Sets the interval used in between message polls, in milliseconds.\n\tvoid setPollingInterval(long pollingInterval);\n\t// Template method that blocks until new messages arrive in the given folder.\n\tprotected void waitForNewMessages(javax.mail.Folder folder);\n}", "des": "Implementation of the MonitoringStrategy interface that uses a simple polling mechanism. Defines a polling interval property which defines the interval in between message polls."}
{"index": 5299, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface ResponseActions {\n\t// Allows for further expectations to be set on the request.\n\tResponseActions andExpect(RequestMatcher requestMatcher);\n\t// Sets the ResponseCreator for this mock.\n\tvoid andRespond(ResponseCreator responseCreator);\n}", "des": "Allows for setting up responses and additional expectations. Implementations of this interface are returned by MockWebServiceServer.expect(RequestMatcher)."}
{"index": 5300, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SaajXmlReader {\n\t// Throws a SAXNotRecognizedException exception.\n\tboolean getFeature(String name);\n\t// Parses the StAX XML reader passed at construction-time.\n\tvoid parse(InputSource ignored);\n\t// Parses the StAX XML reader passed at construction-time.\n\tvoid parse(String ignored);\n\t// Throws a SAXNotRecognizedException exception.\n\tvoid setFeature(String name, boolean value);\n}", "des": "SAX XMLReader that reads from a SAAJ Node. Consumes XMLEvents from an XMLEventReader, and calls the corresponding methods on the SAX callback interfaces."}
{"index": 5301, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SaxUtils {\n\t// Creates a SAX InputSource from the given resource.\n\tstatic InputSource createInputSource(org.springframework.core.io.Resource resource);\n\t// Retrieves the URL from the given resource as System ID.\n\tstatic String getSystemId(org.springframework.core.io.Resource resource);\n}", "des": "Convenient utility methods for dealing with SAX."}
{"index": 5302, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SchemaLoaderUtils {\n\t// Retrieves the URL from the given resource as System ID.\n\tstatic String getSystemId(org.springframework.core.io.Resource resource);\n\t// Load schema from the given resource.\n\tstatic Schema loadSchema(org.springframework.core.io.Resource[] resources, String schemaLanguage);\n\t// Load schema from the given resource.\n\tstatic Schema loadSchema(org.springframework.core.io.Resource resource, String schemaLanguage);\n}", "des": "Convenient utility methods for loading of Schema objects, performing standard handling of input streams."}
{"index": 5303, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SimplePasswordValidationCallbackHandler {\n\tvoid afterPropertiesSet();\n\t// Invoked when the callback has a WSPasswordCallback.USERNAME_TOKEN usage.\n\tvoid handleUsernameToken(org.apache.wss4j.common.ext.WSPasswordCallback callback);\n\t// Sets the users to validate against.\n\tvoid setUsers(Properties users);\n\tvoid setUsersMap(Map<String,String> users);\n}", "des": "Simple callback handler that validates passwords against a in-memory Properties object. Password validation is done on a case-sensitive basis."}
{"index": 5304, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SimplePasswordValidationCallbackHandler {\n\tvoid afterPropertiesSet();\n\t// Template method that should be implemented by subclasses.\n\tprotected void handleInternal(Callback callback);\n\t// Sets the users to validate against.\n\tvoid setUsers(Properties users);\n\tvoid setUsersMap(Map<String,String> users);\n}", "des": "Simple callback handler that validates passwords agains a in-memory Properties object. Password validation is done on a case-sensitive basis."}
{"index": 5305, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SimpleWebServiceMessageReceiverObjectSupport {\n\tvoid afterPropertiesSet();\n\t// Returns the WebServiceMessageReceiver used by this listener.\n\tWebServiceMessageReceiver getMessageReceiver();\n\tprotected void handleConnection(WebServiceConnection connection);\n\t// Sets the WebServiceMessageReceiver used by this listener.\n\tvoid setMessageReceiver(WebServiceMessageReceiver messageReceiver);\n}", "des": "Base class for server-side transport objects which have a predefined WebServiceMessageReceiver."}
{"index": 5306, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SimpleWsdl11Definition {\n\tvoid afterPropertiesSet();\n\t// Returns the Source of the definition.\n\tSource getSource();\n\t// Set the WSDL resource to be exposed by calls to this instances' getSource() method.\n\tvoid setWsdl(org.springframework.core.io.Resource wsdlResource);\n}", "des": "The default Wsdl11Definition implementation."}
{"index": 5307, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SimpleXsdSchema {\n\tvoid afterPropertiesSet();\n\t// Creates a XmlValidator based on the schema.\n\tXmlValidator createValidator();\n\t// Returns the Source of the schema.\n\tSource getSource();\n\t// Returns the target namespace of this schema.\n\tString getTargetNamespace();\n\t// Set the XSD resource to be exposed by calls to this instances' getSource() method.\n\tvoid setXsd(org.springframework.core.io.Resource xsdResource);\n}", "des": "The default XsdSchema implementation."}
{"index": 5308, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface Soap12Fault {\n\t// Adds a fault subcode this fault.\n\tvoid addFaultSubcode(QName subcode);\n\t// Returns the fault node.\n\tString getFaultNode();\n\t// Returns the reason associated with the given language.\n\tString getFaultReasonText(Locale locale);\n\t// Returns an iteration over the fault subcodes.\n\tIterator<QName> getFaultSubcodes();\n\t// Sets the fault node.\n\tvoid setFaultNode(String uri);\n\t// Sets the specified fault reason text.\n\tvoid setFaultReasonText(Locale locale, String text);\n}", "des": "Subinterface of SoapFault that exposes SOAP 1.2 functionality. Necessary because SOAP 1.1 differs from SOAP 1.2 with respect to SOAP Faults."}
{"index": 5309, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface Soap12Header {\n\t// Adds a new NotUnderstood SoapHeaderElement this header.\n\tSoapHeaderElement addNotUnderstoodHeaderElement(QName headerName);\n\t// Adds a new Upgrade SoapHeaderElement this header.\n\tSoapHeaderElement addUpgradeHeaderElement(String[] supportedSoapUris);\n\t// Returns an Iterator over all the header elements that should be processed for the given roles.\n\tIterator<SoapHeaderElement> examineHeaderElementsToProcess(String[] roles, boolean isUltimateReceiver);\n}", "des": "Subinterface of SoapHeader that exposes SOAP 1.2 functionality."}
{"index": 5310, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapEndpointInvocationChain {\n\t// Gets the actors (SOAP 1.1) or roles (SOAP 1.2) associated with an invocation of this chain and its contained interceptors and endpoint.\n\tString[] getActorsOrRoles();\n\t// Indicates whether this chain fulfills the SOAP 1.2 Ultimate Receiver role.\n\tboolean isUltimateReceiver();\n}", "des": "SOAP-specific subclass of the EndpointInvocationChain. Adds associated actors (SOAP 1.1) or roles (SOAP 1.2). Used by the SoapMessageDispatcher to determine the MustUnderstand headers for particular endpoint."}
{"index": 5311, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface SoapEndpointMapping {\n\t// Sets a single SOAP actor/actorOrRole to apply to all endpoints mapped by the delegate endpoint mapping.\n\tvoid setActorOrRole(String actorOrRole);\n\t// Sets the array of SOAP actors/actorsOrRoles to apply to all endpoints mapped by the delegate endpoint mapping.\n\tvoid setActorsOrRoles(String[] actorsOrRoles);\n\t// Indicates whether this the endpoint fulfills the SOAP 1.2 Ultimate Receiver role.\n\tvoid setUltimateReceiver(boolean ultimateReceiver);\n}", "des": "SOAP-specific sub-interface of the EndpointMapping. Adds associated actors (SOAP 1.1) or roles (SOAP 1.2). Used by the SoapMessageDispatcher to determine the MustUnderstand headers for particular endpoint."}
{"index": 5312, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface SoapEnvelope {\n\t// Returns the SoapBody.\n\tSoapBody getBody();\n\t// Returns the SoapHeader.\n\tSoapHeader getHeader();\n}", "des": "Represents the Envelope element in a SOAP message. The header contains the optional SoapHeader and SoapBody."}
{"index": 5313, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface SoapFault {\n\t// Creates an optional SoapFaultDetail object and assigns it to this fault.\n\tSoapFaultDetail addFaultDetail();\n\t// Returns the fault actor or role.\n\tString getFaultActorOrRole();\n\t// Returns the fault code.\n\tQName getFaultCode();\n\t// Returns the optional detail element for this SoapFault.\n\tSoapFaultDetail getFaultDetail();\n\t// Returns the fault string or reason.\n\tString getFaultStringOrReason();\n\t// Sets the fault actor.\n\tvoid setFaultActorOrRole(String faultActor);\n}", "des": "Represents the Fault element in the body of a SOAP message."}
{"index": 5314, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapFaultClientException {\n\t// Returns the fault code.\n\tQName getFaultCode();\n\t// Returns the fault string or reason.\n\tString getFaultStringOrReason();\n\t// Returns the SoapFault.\n\tSoapFault getSoapFault();\n}", "des": "Thrown by SoapFaultMessageResolver when the response message has a fault."}
{"index": 5315, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapFaultDefinition {\n\t// Returns the fault code.\n\tQName getFaultCode();\n\t// Returns the fault string or reason text.\n\tString getFaultStringOrReason();\n\t// Gets the fault string locale.\n\tLocale getLocale();\n\t// Sets the fault code.\n\tvoid setFaultCode(QName faultCode);\n\t// Sets the fault string or reason text.\n\tvoid setFaultStringOrReason(String faultStringOrReason);\n\t// Sets the fault string locale.\n\tvoid setLocale(Locale locale);\n}", "des": "Defines properties for a SOAP Fault. Used by the SoapFaultDefinitionEditor and the SoapFaultMappingExceptionResolver."}
{"index": 5316, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface SoapFaultDetail {\n\t// Adds a new SoapFaultDetailElement with the specified qualified name to this detail.\n\tSoapFaultDetailElement addFaultDetailElement(QName name);\n\t// Gets an iterator over all of the SoapFaultDetailElements in this detail.\n\tIterator<SoapFaultDetailElement> getDetailEntries();\n\t// Returns a Result that represents the concents of the detail.\n\tResult getResult();\n}", "des": "Represents the detail element in a SOAP fault. A detail contains SoapFaultDetailElements, which represent the individual details."}
{"index": 5317, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface SoapFaultDetailElement {\n\t// Adds a new text node to this element.\n\tvoid addText(String text);\n\t// Returns a Result that allows for writing to the contents of the detail element.\n\tResult getResult();\n}", "des": "Represents the content for an individual SOAP detail entry in a SOAP Message. All SoapFaultDetailElements are contained in a SoapDetail."}
{"index": 5318, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapFaultMappingExceptionResolver {\n\t// Return the depth to the superclass matching.\n\tprotected int getDepth(String exceptionMapping, Exception ex);\n\t// Template method that returns the SoapFaultDefinition for the given exception.\n\tprotected SoapFaultDefinition getFaultDefinition(Object endpoint, Exception ex);\n\t// Set the mappings between exception class names and SOAP Faults.\n\tvoid setExceptionMappings(Properties mappings);\n}", "des": "Exception resolver that allows for mapping exception class names to SOAP Faults. The mappings are set using the exceptionMappings property, the format of which is documented in SoapFaultDefinitionEditor."}
{"index": 5319, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapHeaderElementMethodArgumentResolver {\n\t// Resolves the given parameter into a method argument.\n\tObject resolveArgument(MessageContext messageContext, org.springframework.core.MethodParameter parameter);\n\t// Indicates whether the given method parameter is supported by this resolver.\n\tboolean supportsParameter(org.springframework.core.MethodParameter parameter);\n}", "des": "Implementation of MethodArgumentResolver that supports resolving SoapHeaderElement parameters. Target method parameters must be annotated with SoapHeader to indicate the SOAP header to resolve. This resolver supports simple SoapHeaderElement parameters and List parameters for elements that appear multiple times in the same SOAP header. The following snippet shows an example of supported declarations."}
{"index": 5320, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapMessageDispatcher {\n\t// Process the headers targeted at the actor or role fullfilled by the endpoint.\n\tprotected boolean handleRequest(EndpointInvocationChain mappedEndpoint, MessageContext messageContext);\n\t// Sets the message used for MustUnderstand fault.\n\tvoid setMustUnderstandFaultString(String mustUnderstandFaultString);\n\t// Sets the locale of the message used for MustUnderstand fault.\n\tvoid setMustUnderstandFaultStringLocale(Locale mustUnderstandFaultStringLocale);\n}", "des": "SOAP-specific subclass of the MessageDispatcher. Adds functionality for adding actor roles to a endpoint invocation chain, and endpoint interception using SoapEndpointInterceptor objects."}
{"index": 5321, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface SoapMessageFactory {\n\t// Creates a new, empty SoapMessage.\n\tSoapMessage createWebServiceMessage();\n\t// Reads a SoapMessage from the given input stream.\n\tSoapMessage createWebServiceMessage(InputStream inputStream);\n\t// Sets the SOAP Version used by this factory.\n\tvoid setSoapVersion(SoapVersion version);\n}", "des": "Sub-interface of WebServiceMessageFactory which contains SOAP-specific properties and methods."}
{"index": 5322, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapMethodArgumentResolver {\n\t// Resolves the given parameter into a method argument.\n\tObject resolveArgument(MessageContext messageContext, org.springframework.core.MethodParameter parameter);\n\t// Indicates whether the given method parameter is supported by this resolver.\n\tboolean supportsParameter(org.springframework.core.MethodParameter parameter);\n}", "des": "Implementation of MethodArgumentResolver that supports SoapMessage, SoapBody, SoapEnvelope, and SoapHeader."}
{"index": 5323, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SoapUtils {\n\t// Escapes the given SOAP action to be surrounded by quotes.\n\tstatic String escapeAction(String soapAction);\n\t// Returns the value of the action parameter in the given SOAP 1.2 content type.\n\tstatic String extractActionFromContentType(String contentType);\n\t// Replaces or adds the value of the action parameter in the given SOAP 1.2 content type.\n\tstatic String setActionInContentType(String contentType, String action);\n}", "des": "Contains various utility methods for handling SOAP messages."}
{"index": 5324, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SpringCertificateValidationCallbackHandler {\n\tvoid afterPropertiesSet();\n\t// Handles CertificateValidationCallbacks, and throws an UnsupportedCallbackException for others\n\tprotected void handleInternal(Callback callback);\n\t// Sets the Spring Security authentication manager.\n\tvoid setAuthenticationManager(org.springframework.security.authentication.AuthenticationManager authenticationManager);\n\tvoid setIgnoreFailure(boolean ignoreFailure);\n}", "des": "Callback handler that validates a certificate using an Spring Security AuthenticationManager. Logic based on Spring Security's X509ProcessingFilter."}
{"index": 5325, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class SpringPlainTextPasswordValidationCallbackHandler {\n\tvoid afterPropertiesSet();\n\t// Handles PasswordValidationCallbacks that contain a PlainTextPasswordRequest, and throws an UnsupportedCallbackException for others.\n\tprotected void handleInternal(Callback callback);\n\t// Sets the Spring Security authentication manager.\n\tvoid setAuthenticationManager(org.springframework.security.authentication.AuthenticationManager authenticationManager);\n\tvoid setIgnoreFailure(boolean ignoreFailure);\n}", "des": "Callback handler that validates a certificate uses an Spring Security AuthenticationManager. Logic based on Spring Security's BasicProcessingFilter."}
{"index": 5326, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface StreamingPayload {\n\t// Returns the qualified name of the payload.\n\tQName getName();\n\t// Writes this payload to the given XMLStreamWriter.\n\tvoid writeTo(XMLStreamWriter streamWriter);\n}", "des": "Defines the contract for payloads that can be written directly to a XMLStreamWriter."}
{"index": 5327, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class StringSource {\n\t// Returns null.\n\tInputStream getInputStream();\n\tReader getReader();\n\t// Throws UnsupportedOperationException.\n\tvoid setInputStream(InputStream inputStream);\n\t// Throws UnsupportedOperationException.\n\tvoid setReader(Reader reader);\n}", "des": "Convenient subclass of StreamSource that reads from a StringReader. The string to be read can be set via the constructor."}
{"index": 5328, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class TransportContextHolder {\n\t// Return the TransportContext associated with the current thread, if any.\n\tstatic TransportContext getTransportContext();\n\t// Associate the given TransportContext with the current thread.\n\tstatic void setTransportContext(TransportContext transportContext);\n}", "des": "Simple holder class that associates a TransportContext instance with the current thread. The TransportContext will be inherited by any child threads spawned by the current thread."}
{"index": 5329, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class TransportOutputStream {\n\t// Adds a header with the given name and value.\n\tabstract void addHeader(String name, String value);\n\tvoid close();\n\t// Returns the output stream to write to.\n\tprotected abstract OutputStream createOutputStream();\n\tvoid flush();\n\tvoid write(byte[] b);\n\tvoid write(byte[] b, int off, int len);\n\tvoid write(int b);\n}", "des": "A TransportOutputStream is an output stream with MIME input headers. It is used to write WebServiceMessages to a transport."}
{"index": 5330, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class TraxUtils {\n\t// Performs the given callback operation on a Result.\n\tstatic void doWithResult(Result result, TraxUtils.ResultCallback callback);\n\t// Performs the given callback operation on a Source.\n\tstatic void doWithSource(Source source, TraxUtils.SourceCallback callback);\n\t// Returns the Document of the given DOMSource.\n\tstatic Document getDocument(DOMSource source);\n}", "des": "Convenient utility methods for dealing with TrAX."}
{"index": 5331, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class TrustManagersFactoryBean {\n\tvoid afterPropertiesSet();\n\tTrustManager[] getObject();\n\tClass<?> getObjectType();\n\tboolean isSingleton();\n\t// Sets the algorithm of the TrustManager to use.\n\tvoid setAlgorithm(String algorithm);\n\t// Sets the source of certificate authorities and related trust material.\n\tvoid setKeyStore(KeyStore keyStore);\n\t// Sets the provider of the trust manager to use.\n\tvoid setProvider(String provider);\n}", "des": "Spring factory bean for an array of TrustManagers."}
{"index": 5332, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class UriEndpointMapping {\n\t// Returns the endpoint key for the given message context.\n\tprotected String getLookupKeyForMessage(MessageContext messageContext);\n\t// Indicates whether the path should be used instead of the full URI.\n\tvoid setUsePath(boolean usePath);\n\t// Validates the given endpoint key.\n\tprotected boolean validateLookupKey(String key);\n}", "des": "Implementation of the EndpointMapping interface to map from the full request URI or request URI path to endpoint beans. Supports both mapping to bean instances and mapping to bean names: the latter is required for prototype handlers."}
{"index": 5333, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class UuidMessageIdStrategy {\n\t// Returns false.\n\tboolean isDuplicate(URI messageId);\n\t// Returns a new WS-Addressing MessageID for the given SoapMessage.\n\tURI newMessageId(SoapMessage message);\n}", "des": "Implementation of the MessageIdStrategy interface that uses a UUID to generate a Message Id. The UUID is prefixed by urn:uuid:."}
{"index": 5334, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface WebServiceConnection {\n\t// Closes this connection.\n\tvoid close();\n\t// Returns the error message.\n\tString getErrorMessage();\n\t// Returns the URI for this connection.\n\tURI getUri();\n\t// Indicates whether this connection has an error.\n\tboolean hasError();\n\t// Receives a message using the given WebServiceMessageFactory.\n\tWebServiceMessage receive(WebServiceMessageFactory messageFactory);\n\t// Sends the given message using this connection.\n\tvoid send(WebServiceMessage message);\n}", "des": "Represents a point-to-point connection that a client can use for sending WebServiceMessage objects directly to a remote party."}
{"index": 5335, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface WebServiceMessage {\n\t// Returns the contents of the message as a Result.\n\tResult getPayloadResult();\n\t// Returns the contents of the message as a Source.\n\tSource getPayloadSource();\n\t// Writes the entire message to the given output stream.\n\tvoid writeTo(OutputStream outputStream);\n}", "des": "Represents a protocol-agnostic XML message."}
{"index": 5336, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface WebServiceMessageFactory {\n\t// Creates a new, empty WebServiceMessage.\n\tWebServiceMessage createWebServiceMessage();\n\t// Reads a WebServiceMessage from the given input stream.\n\tWebServiceMessage createWebServiceMessage(InputStream inputStream);\n}", "des": "The WebServiceMessageFactory serves as a factory for WebServiceMessages."}
{"index": 5337, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface WebServiceMessageSender {\n\t// Create a new WebServiceConnection to the specified URI.\n\tWebServiceConnection createConnection(URI uri);\n\t// Does this WebServiceMessageSender support the supplied URI?\n\tboolean supports(URI uri);\n}", "des": "Defines the methods for classes capable of sending and receiving WebServiceMessage instances across a transport."}
{"index": 5338, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class WebUtils {\n\t// Extract the URL filename from the given request URL path.\n\tstatic String extractFilenameFromUrlPath(String urlPath);\n\t// Extract the full URL filename (including file extension) from the given request URL path.\n\tstatic String extractFullFilenameFromUrlPath(String urlPath);\n}", "des": "Miscellaneous utilities for web applications. Used by various framework classes. NOTE: These are the parts of org.springframework.web.util.WebUtils deprecated in Spring Framework 5."}
{"index": 5339, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface WsConfigurer {\n\t// Add resolvers to support custom endpoint method argument types.\n\tvoid addArgumentResolvers(List<MethodArgumentResolver> argumentResolvers);\n\t// Add EndpointInterceptors for pre- and post-processing of endpoint method invocations.\n\tvoid addInterceptors(List<EndpointInterceptor> interceptors);\n\t// Add handlers to support custom controller method return value types.\n\tvoid addReturnValueHandlers(List<MethodReturnValueHandler> returnValueHandlers);\n}", "des": "Defines callback methods to customize the Java-based configuration for Spring Web Services enabled via @EnableWs."}
{"index": 5340, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class WsConfigurerAdapter {\n\t// Add resolvers to support custom endpoint method argument types.\n\tvoid addArgumentResolvers(List<MethodArgumentResolver> argumentResolvers);\n\t// Add EndpointInterceptors for pre- and post-processing of endpoint method invocations.\n\tvoid addInterceptors(List<EndpointInterceptor> interceptors);\n\t// Add handlers to support custom controller method return value types.\n\tvoid addReturnValueHandlers(List<MethodReturnValueHandler> returnValueHandlers);\n}", "des": "An default implementation of WsConfigurer with empty methods allowing sub-classes to override only the methods they're interested in."}
{"index": 5341, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class Wsdl11DestinationProvider {\n\t// Abstract template method that looks up the URI.\n\tprotected URI lookupDestination();\n\t// Sets the XPath expression to use when extracting the service location URI from a WSDL.\n\tvoid setLocationExpression(String expression);\n\t// Sets a WSDL location from which the service destination URI will be resolved.\n\tvoid setWsdl(org.springframework.core.io.Resource wsdlResource);\n}", "des": "Implementation of the DestinationProvider that resolves a destination URI from a WSDL file."}
{"index": 5342, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class Wsdl4jDefinition {\n\t// Returns the WSDL4J Definition.\n\tjavax.wsdl.Definition getDefinition();\n\t// Returns the Source of the definition.\n\tSource getSource();\n\t// Set the WSDL4J Definition.\n\tvoid setDefinition(javax.wsdl.Definition definition);\n}", "des": "Implementation of the Wsdl11Definition based on WSDL4J. A Definition can be given as as constructor argument, or set using a property."}
{"index": 5343, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class WsSecurityFaultException {\n\t// Returns the fault actor for the exception.\n\tString getFaultActor();\n\t// Returns the fault code for the exception.\n\tQName getFaultCode();\n\t// Returns the fault string for the exception.\n\tString getFaultString();\n}", "des": "Exception indicating that a WS-Security executions should result in a SOAP Fault."}
{"index": 5344, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class XmlRootElementEndpointMapping {\n\t// Returns the endpoint keys for the given message context.\n\tprotected QName getLookupKeyForMessage(MessageContext messageContext);\n\t// Returns the endpoint key for the given method.\n\tprotected QName getLookupKeyForMethod(Method method);\n\tvoid setTransformerHelper(TransformerHelper transformerHelper);\n}", "des": "Implementation of the EndpointMapping interface that uses the JAXB2 XmlRootElement annotation to map methods to request payload root elements."}
{"index": 5345, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface XmlValidator {\n\t// Validates the given Source, and returns an array of SAXParseExceptions as result.\n\tSAXParseException[] validate(Source source);\n\t// Validates the given Source and ValidationErrorHandler, and returns an array of SAXParseExceptions as result.\n\tSAXParseException[] validate(Source source, ValidationErrorHandler errorHandler);\n}", "des": "Simple processor that validates a given Source. Can be created via the XmlValidatorFactory."}
{"index": 5346, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class XmlValidatorFactory {\n\t// Create a XmlValidator with the given schema resources and schema language type.\n\tstatic XmlValidator createValidator(org.springframework.core.io.Resource[] schemaResources, String schemaLanguage);\n\t// Create a XmlValidator with the given schema resource and schema language type.\n\tstatic XmlValidator createValidator(org.springframework.core.io.Resource schemaResource, String schemaLanguage);\n}", "des": "Factory for XmlValidator objects, being aware of JAXP 1.3 Validators, and JAXP 1.0 parsing capabilities. Mainly for internal use within the framework."}
{"index": 5347, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class XPathExpressionFactory {\n\t// Create a compiled XPath expression using the given string.\n\tstatic XPathExpression createXPathExpression(String expression);\n\t// Create a compiled XPath expression using the given string and namespaces.\n\tstatic XPathExpression createXPathExpression(String expression, Map<String,String> namespaces);\n}", "des": "Factory for compiled XPathExpressions, being aware of JAXP 1.3+ XPath functionality, and Jaxen. Mainly for internal use of the framework."}
{"index": 5348, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class XPathExpressionFactoryBean {\n\tvoid afterPropertiesSet();\n\tXPathExpression getObject();\n\tClass<? extends XPathExpression> getObjectType();\n\tboolean isSingleton();\n\t// Sets the XPath expression.\n\tvoid setExpression(String expression);\n\t// Sets the namespaces for the expressions.\n\tvoid setNamespaces(Map<String,String> namespaces);\n}", "des": "Spring FactoryBean for XPathExpression object. Facilitates injection of XPath expressions into endpoint beans."}
{"index": 5349, "repo": "spring-ws-3.0.10.RELEASE", "code": "Class XPathPayloadEndpointMapping {\n\tvoid afterPropertiesSet();\n\t// Returns the endpoint key for the given message context.\n\tprotected String getLookupKeyForMessage(MessageContext messageContext);\n\t// Sets the XPath expression to be used.\n\tvoid setExpression(String expression);\n\t// Sets the namespaces bindings used in the expression.\n\tvoid setNamespaces(Map<String,String> namespaces);\n\t// Validates the given endpoint key.\n\tprotected boolean validateLookupKey(String key);\n}", "des": "Implementation of the EndpointMapping interface that maps to endpoint using an XPath expression. Supports both mapping to bean instances and mapping to bean names: the latter is required for prototype endpoints."}
{"index": 5350, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface XsdSchema {\n\t// Creates a XmlValidator based on the schema.\n\tXmlValidator createValidator();\n\t// Returns the Source of the schema.\n\tSource getSource();\n\t// Returns the target namespace of this schema.\n\tString getTargetNamespace();\n}", "des": "Represents an abstraction for XSD schemas."}
{"index": 5351, "repo": "spring-ws-3.0.10.RELEASE", "code": "Interface XsdSchemaCollection {\n\t// Creates a XmlValidator based on the schemas contained in this collection.\n\tXmlValidator createValidator();\n\t// Returns all schemas contained in this collection.\n\tXsdSchema[] getXsdSchemas();\n}", "des": "Represents an abstraction for a collection of XSD schemas."}
{"index": 5352, "repo": "hive-common-4.0.0-alpha-2", "code": "Class CommonCliOptions {\n\t// Add the hiveconf properties to the Java system properties, override anything therein.\n\tProperties addHiveconfToSystemProperties();\n\t// Should the client be verbose.\n\tboolean isVerbose();\n\t// Parse the arguments.\n\tvoid parse(String[] args);\n\t// Print usage information for the CLI.\n\tvoid printUsage();\n\tstatic void splitAndSetLogger(String propKey, Properties confProps);\n}", "des": "Reusable code for Hive Cli's."}
{"index": 5353, "repo": "hive-common-4.0.0-alpha-2", "code": "Class CompressionUtils {\n\t// Archive all the files in the inputFiles into outputFile\n\tstatic void tar(String parentDir, String[] inputFiles, String outputFile);\n\t// Untar an input file into an output file.\n\tstatic List<File> unTar(String inputFileName, String outputDirName);\n\t// Untar an input file into an output file.\n\tstatic List<File> unTar(String inputFileName, String outputDirName, boolean flatten);\n\tstatic void zip(String parentDir, String[] inputFiles, String outputFile);\n}", "des": "This class contains methods used for the purposes of compression, this class should not be accessed from code run in Hadoop."}
{"index": 5354, "repo": "hive-common-4.0.0-alpha-2", "code": "Class DateParser {\n\t// Obtains an instance of Date from a text string such as 2021-02-21.\n\tstatic Date parseDate(String text);\n\t// Obtains an instance of Date from a text string such as 2021-02-21.\n\tstatic boolean parseDate(String text, Date result);\n}", "des": "Date parser class for Hive."}
{"index": 5355, "repo": "hive-common-4.0.0-alpha-2", "code": "Class GcTimeMonitor {\n\t// Returns a copy of the most recent data measured by this monitor.\n\tGcTimeMonitor.GcData getLatestGcData();\n\t// Simple 'main' to facilitate manual testing of the pause monitor.\n\tstatic void main(String[] args);\n\tvoid run();\n\tvoid shutdown();\n}", "des": "Based on org.apache.hadoop.util.GcTimeMonitor. However, this class detects GC pauses using the same method as JvmPauseMonitor (by comparing the actual and expected thread sleep time) rather than by reading information from GarbageCollectionMXBean. The latter may sometimes report time spent in concurrent GC operations rather than GC pauses. This may result in inaccurate results when trying to estimate the time that the JVM is \"frozen\" due to GC. This class monitors the percentage of time the JVM is paused in GC within the specified observation window, say 1 minute. The user can provide a hook which will be called whenever this percentage exceeds the specified threshold."}
{"index": 5356, "repo": "hive-common-4.0.0-alpha-2", "code": "Class GcTimeMonitor.GcData {\n\tGcTimeMonitor.GcData clone();\n\t// Returns accumulated GC time since this JVM started.\n\tlong getAccumulatedGcTimeMs();\n\t// Returns the time since the start of the associated GcTimeMonitor.\n\tlong getGcMonitorRunTimeMs();\n\t// Returns the percentage (0..100) of time that the JVM spent in GC pauses within the observation window of the associated GcTimeMonitor.\n\tint getGcTimePercentage();\n}", "des": "Encapsulates data about GC pauses measured at the specific timestamp."}
{"index": 5357, "repo": "hive-common-4.0.0-alpha-2", "code": "Enum HiveCompat.CompatLevel {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveCompat.CompatLevel valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveCompat.CompatLevel[] values();\n}", "des": "Enum to represent a level of backward compatibility support."}
{"index": 5358, "repo": "hive-common-4.0.0-alpha-2", "code": "Enum HiveServer2TransportMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveServer2TransportMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveServer2TransportMode[] values();\n}", "des": "Hive Transport mode."}
{"index": 5359, "repo": "hive-common-4.0.0-alpha-2", "code": "Enum HiveSqlDateTimeFormatter.TokenType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveSqlDateTimeFormatter.TokenType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveSqlDateTimeFormatter.TokenType[] values();\n}", "des": "Represents broad categories of tokens."}
{"index": 5360, "repo": "hive-common-4.0.0-alpha-2", "code": "Enum HiveStringUtils.TraditionalBinaryPrefix {\n\t// Convert a string to long.\n\tstatic long string2long(String s);\n\tstatic HiveStringUtils.TraditionalBinaryPrefix valueOf(char symbol);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HiveStringUtils.TraditionalBinaryPrefix valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HiveStringUtils.TraditionalBinaryPrefix[] values();\n}", "des": "The traditional binary prefixes, kilo, mega, ..., exa, which can be represented by a 64-bit integer. TraditionalBinaryPrefix symbol are case insensitive."}
{"index": 5361, "repo": "hive-common-4.0.0-alpha-2", "code": "Enum HttpServer.XFrameOption {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HttpServer.XFrameOption valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HttpServer.XFrameOption[] values();\n}", "des": "The X-FRAME-OPTIONS header in HTTP response to mitigate clickjacking attack."}
{"index": 5362, "repo": "hive-common-4.0.0-alpha-2", "code": "Class JMXJsonServlet {\n\t// Process a GET request for the specified resource.\n\tvoid doGet(javax.servlet.http.HttpServletRequest request, javax.servlet.http.HttpServletResponse response);\n\t// Initialize this servlet.\n\tvoid init();\n}", "des": "Provides Read only web access to JMX."}
{"index": 5363, "repo": "hive-common-4.0.0-alpha-2", "code": "Enum JvmMetricsInfo {\n\tString description();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JvmMetricsInfo valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JvmMetricsInfo[] values();\n}", "des": "JVM and logging related metrics info instances. Ported from Hadoop JvmMetricsInfo."}
{"index": 5364, "repo": "hive-common-4.0.0-alpha-2", "code": "Interface Node {\n\t// Gets the vector of children nodes.\n\tList<? extends Node> getChildren();\n\t// Gets the name of the node.\n\tString getName();\n}", "des": "This interface defines the functions needed by the walkers and dispatchers. These are implemented by the node of the graph that needs to be walked."}
{"index": 5365, "repo": "hive-common-4.0.0-alpha-2", "code": "Class NumberUtils {\n\t// Get the first int stored in a long value.\n\tstatic int getFirstInt(long pair);\n\t// Get the second int stored in a long value.\n\tstatic int getSecondInt(long pair);\n\t// Store two ints in a single long value.\n\tstatic long makeIntPair(int i1, int i2);\n}", "des": "Collection of Number manipulation utilities common across Hive."}
{"index": 5366, "repo": "hive-common-4.0.0-alpha-2", "code": "Class ReflectionUtil {\n\t// Create an object for the given class and initialize it from conf\n\tstatic <T> T newInstance(Class<T> theClass, org.apache.hadoop.conf.Configuration conf);\n\t// Check and set 'configuration' if necessary.\n\tstatic void setConf(Object theObject, org.apache.hadoop.conf.Configuration conf);\n}", "des": "Same as Hadoop ReflectionUtils, but (1) does not leak classloaders (or shouldn't anyway, we rely on Guava cache, and could fix it otherwise); (2) does not have a hidden epic lock."}
{"index": 5367, "repo": "hadoop-aws-3.3.6", "code": "Class AbstractAuditSpanImpl {\n\tAuditSpanS3A activate();\n\t// Invoke AuditSpan.deactivate().\n\tvoid close();\n\t// Get the name of the operation.\n\tString getOperationName();\n\t// Return a span ID which must be unique for all spans within everywhere.\n\tString getSpanId();\n\tlong getTimestamp();\n}", "des": "Base class for the audit spans implementations.."}
{"index": 5368, "repo": "hadoop-aws-3.3.6", "code": "Class AbstractOperationAuditor {\n\t// Create a span ID.\n\tprotected String createSpanID();\n\t// Get the Auditor ID.\n\tString getAuditorId();\n\t// Get the IOStatistics Store.\n\torg.apache.hadoop.fs.statistics.impl.IOStatisticsStore getIOStatistics();\n\t// Get the options this auditor was initialized with.\n\tprotected OperationAuditorOptions getOptions();\n\t// Sets the IOStats and then calls init().\n\tvoid init(OperationAuditorOptions opts);\n}", "des": "This is a long-lived service which is created in S3A FS initialize (make it fast!) which provides context for tracking operations made to S3. An IOStatisticsStore is passed in -in production this is expected to be the S3AFileSystem instrumentation, which will have the AUDIT_SPAN_START statistic configured for counting durations."}
{"index": 5369, "repo": "hadoop-aws-3.3.6", "code": "Enum AbstractS3ACommitter.JobUUIDSource {\n\t// Source for messages.\n\tString getText();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AbstractS3ACommitter.JobUUIDSource valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AbstractS3ACommitter.JobUUIDSource[] values();\n}", "des": "Enumeration of Job UUID source."}
{"index": 5370, "repo": "hadoop-aws-3.3.6", "code": "Class AbstractStoreOperation {\n\t// Activate the audit span.\n\tvoid activateAuditSpan();\n\t// Get the audit span this object was created with.\n\torg.apache.hadoop.fs.store.audit.AuditSpan getAuditSpan();\n\t// Get the store context.\n\tStoreContext getStoreContext();\n}", "des": "Base class of operations in the store. An operation is something which executes against the context to perform a single function."}
{"index": 5371, "repo": "hadoop-aws-3.3.6", "code": "Class ArnResource {\n\t// Parses the passed `arn` string into a full ArnResource.\n\tstatic ArnResource accessPointFromArn(String arn);\n\t// Formatted endpoint for the resource.\n\tString getEndpoint();\n\t// Full arn for resource.\n\tString getFullArn();\n\t// Resource name.\n\tString getName();\n\t// Return owner's account id.\n\tString getOwnerAccountId();\n\t// Resource region.\n\tString getRegion();\n}", "des": "Represents an Arn Resource, this can be an accesspoint or bucket."}
{"index": 5372, "repo": "hadoop-aws-3.3.6", "code": "Class AuditContextUpdater {\n\t// Remove job/task info from the current audit context.\n\tvoid resetCurrentAuditContext();\n\t// Add job/task info to current audit context.\n\tvoid updateCurrentAuditContext();\n}", "des": "Class to track/update context information to set in threads."}
{"index": 5373, "repo": "hadoop-aws-3.3.6", "code": "Enum AWSPolicyProvider.AccessLevel {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AWSPolicyProvider.AccessLevel valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AWSPolicyProvider.AccessLevel[] values();\n}", "des": "Access levels."}
{"index": 5374, "repo": "hadoop-aws-3.3.6", "code": "Interface AwsSignerInitializer {\n\t// Register a store instance.\n\tvoid registerStore(String bucketName, org.apache.hadoop.conf.Configuration storeConf, DelegationTokenProvider dtProvider, org.apache.hadoop.security.UserGroupInformation storeUgi);\n\t// Unregister a store instance.\n\tvoid unregisterStore(String bucketName, org.apache.hadoop.conf.Configuration storeConf, DelegationTokenProvider dtProvider, org.apache.hadoop.security.UserGroupInformation storeUgi);\n}", "des": "Interface which can be implemented to allow initialization of any custom signers which may be used by the S3AFileSystem."}
{"index": 5375, "repo": "hadoop-aws-3.3.6", "code": "Interface BondedS3AStatisticsContext.S3AFSStatisticsSource {\n\t// Get the statistics of the FS instance, shared across all threads.\n\torg.apache.hadoop.fs.FileSystem.Statistics getInstanceStatistics();\n\t// Get the S3A Instrumentation.\n\tS3AInstrumentation getInstrumentation();\n}", "des": "This is the interface which an integration source must implement for the integration. Note that the FileSystem.statistics field may be null for a class;"}
{"index": 5376, "repo": "hadoop-aws-3.3.6", "code": "Class BulkDeleteRetryHandler {\n\t// Handler for failure of bulk delete requests.\n\tvoid bulkDeleteRetried(com.amazonaws.services.s3.model.DeleteObjectsRequest deleteRequest, Exception ex);\n\t// Increment a statistic by 1.\n\tprotected void incrementStatistic(Statistic statistic);\n\t// Increment a statistic by a specific value.\n\tprotected void incrementStatistic(Statistic statistic, long count);\n}", "des": "Handler for bulk delete retry events."}
{"index": 5377, "repo": "hadoop-aws-3.3.6", "code": "Enum ChangeDetectionPolicy.Mode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ChangeDetectionPolicy.Mode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ChangeDetectionPolicy.Mode[] values();\n}", "des": "What to do when change is detected."}
{"index": 5378, "repo": "hadoop-aws-3.3.6", "code": "Enum ChangeDetectionPolicy.Source {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ChangeDetectionPolicy.Source valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ChangeDetectionPolicy.Source[] values();\n}", "des": "The S3 object attribute used to detect change."}
{"index": 5379, "repo": "hadoop-aws-3.3.6", "code": "Interface ChangeTrackerStatistics {\n\t// How many version mismatches have occurred.\n\tlong getVersionMismatches();\n\t// A version mismatch was detected.\n\tvoid versionMismatchError();\n}", "des": "Interface for change tracking statistics."}
{"index": 5380, "repo": "hadoop-aws-3.3.6", "code": "Class CommitOperations.MaybeIOE {\n\t// Get any exception.\n\tIOException getException();\n\t// Is there an exception in this class?\n\tboolean hasException();\n\t// Rethrow any exception.\n\tvoid maybeRethrow();\n\t// Get an instance based on the exception: either a value or a reference to NONE.\n\tstatic CommitOperations.MaybeIOE of(IOException ex);\n}", "des": "A holder for a possible IOException; the call maybeRethrow() will throw any exception passed into the constructor, and be a no-op if none was. Why isn't a Java 8 optional used here? The main benefit would be that maybeRethrow() could be done as a map(), but because Java doesn't allow checked exceptions in a map, the following code is invalid"}
{"index": 5381, "repo": "hadoop-aws-3.3.6", "code": "Enum ConflictResolution {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConflictResolution valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConflictResolution[] values();\n}", "des": "Enum of conflict resolution algorithms."}
{"index": 5382, "repo": "hadoop-aws-3.3.6", "code": "Interface CountersAndGauges {\n\t// Add a value to a quantiles statistic.\n\tvoid addValueToQuantiles(Statistic op, long value);\n\t// Decrement a specific gauge.\n\tvoid decrementGauge(Statistic op, long count);\n\t// Increment a specific counter.\n\tvoid incrementCounter(Statistic op, long count);\n\t// Increment a specific gauge.\n\tvoid incrementGauge(Statistic op, long count);\n\t// Record a duration.\n\tvoid recordDuration(Statistic op, boolean success, Duration duration);\n}", "des": "This is the foundational API for collecting S3A statistics."}
{"index": 5383, "repo": "hadoop-aws-3.3.6", "code": "Class CountingChangeTracker {\n\t// How many version mismatches have occurred.\n\tlong getVersionMismatches();\n\t// A version mismatch was detected.\n\tvoid versionMismatchError();\n}", "des": "A change tracker which increments an atomic long."}
{"index": 5384, "repo": "hadoop-aws-3.3.6", "code": "Class CreateFileBuilder {\n\torg.apache.hadoop.fs.FSDataOutputStream build();\n\t// make the flag getter public.\n\tEnumSet<org.apache.hadoop.fs.CreateFlag> getFlags();\n\tCreateFileBuilder getThisBuilder();\n\t// Pass flags down.\n\tCreateFileBuilder withFlags(EnumSet<org.apache.hadoop.fs.CreateFlag> flags);\n}", "des": "Builder used in create file; takes a callback to the operation to create the file. Is non-recursive unless explicitly changed."}
{"index": 5385, "repo": "hadoop-aws-3.3.6", "code": "Class DeleteOperation {\n\t// Delete a directory tree.\n\tprotected void deleteDirectoryTree(org.apache.hadoop.fs.Path path, String dirKey);\n\t// Delete a file or directory tree.\n\tBoolean execute();\n\tlong getFilesDeleted();\n}", "des": "Implementation of the delete() operation. This issues only one bulk delete at a time, intending to update S3Guard after every request succeeded. Now that S3Guard has been removed, it would be possible to issue multiple delete calls in parallel. If this is done, then it may be good to experiment with different page sizes. The default value is InternalConstants.MAX_ENTRIES_TO_DELETE, the maximum a single POST permits."}
{"index": 5386, "repo": "hadoop-aws-3.3.6", "code": "Interface DirectoryPolicy {\n\t// Describe the policy for marker tools and logs.\n\tString describe();\n\t// Get the marker policy.\n\tDirectoryPolicy.MarkerPolicy getMarkerPolicy();\n\t// Does a specific path have the relevant option.\n\tboolean hasPathCapability(org.apache.hadoop.fs.Path path, String capability);\n\t// Should a directory marker be retained?\n\tboolean keepDirectoryMarkers(org.apache.hadoop.fs.Path path);\n}", "des": "Interface for Directory Marker policies to implement."}
{"index": 5387, "repo": "hadoop-aws-3.3.6", "code": "Enum DirectoryPolicy.MarkerPolicy {\n\t// Get the option name.\n\tString getOptionName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DirectoryPolicy.MarkerPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DirectoryPolicy.MarkerPolicy[] values();\n}", "des": "Supported retention policies."}
{"index": 5388, "repo": "hadoop-aws-3.3.6", "code": "Class DirectoryStagingCommitter {\n\t// Get the name of this committer.\n\tString getName();\n\t// Pre-commit actions for a job.\n\tvoid preCommitJob(CommitContext commitContext, AbstractS3ACommitter.ActiveCommit pending);\n\t// Set up the job, including calling the same method on the wrapped committer.\n\tvoid setupJob(org.apache.hadoop.mapreduce.JobContext context);\n}", "des": "This commits to a directory. The conflict policy is FAIL: fail the commit APPEND: add extra data to the destination. REPLACE: delete the destination directory in the job commit (i.e. after and only if all tasks have succeeded."}
{"index": 5389, "repo": "hadoop-aws-3.3.6", "code": "Class EncryptionSecretOperations {\n\t// Create SSE-KMS options for a request, iff the encryption is SSE-KMS.\n\tstatic Optional<com.amazonaws.services.s3.model.SSEAwsKeyManagementParams> createSSEAwsKeyManagementParams(EncryptionSecrets secrets);\n\t// Create SSE-C client side key encryption options on demand.\n\tstatic Optional<com.amazonaws.services.s3.model.SSECustomerKey> createSSECustomerKey(EncryptionSecrets secrets);\n}", "des": "These support operations on EncryptionSecrets which use the AWS SDK operations. Isolating them here ensures that that class is not required on the classpath."}
{"index": 5390, "repo": "hadoop-aws-3.3.6", "code": "Class ErrorTranslation {\n\t// Does this exception indicate that a reference to an object returned a 404.\n\tstatic boolean isObjectNotFound(com.amazonaws.AmazonServiceException e);\n\t// Does this exception indicate that the AWS Bucket was unknown.\n\tstatic boolean isUnknownBucket(com.amazonaws.AmazonServiceException e);\n}", "des": "Translate from AWS SDK-wrapped exceptions into IOExceptions with as much information as possible. The core of the translation logic is in S3AUtils, in translateException and nearby; that has grown to be a large a complex piece of logic, as it ties in with retry/recovery policies, throttling, etc. This class is where future expansion of that code should go so that we have an isolated place for all the changes.. The existing code las been left in S3AUtils it is to avoid cherry-picking problems on backports."}
{"index": 5391, "repo": "hadoop-aws-3.3.6", "code": "Class ExecutingStoreOperation<T> {\n\t// Apply calls execute().\n\tT apply();\n\t// Execute the operation.\n\tabstract T execute();\n\t// Check that the operation has not been invoked twice.\n\tprotected void executeOnlyOnce();\n}", "des": "A subclass of AbstractStoreOperation which provides a method execute() that may be invoked exactly once. It declares itself a CallableRaisingIOE and can be handed straight to methods which take those as parameters."}
{"index": 5392, "repo": "hadoop-aws-3.3.6", "code": "Class GetContentSummaryOperation {\n\t// Return the ContentSummary of a given path.\n\torg.apache.hadoop.fs.ContentSummary execute();\n\t// Return the ContentSummary of a given directory.\n\torg.apache.hadoop.fs.ContentSummary getDirSummary(org.apache.hadoop.fs.Path dir);\n\torg.apache.hadoop.fs.statistics.IOStatistics getIOStatistics();\n}", "des": "GetContentSummary operation. It is optimized for s3 and performs a deep tree listing, inferring directory counts from the paths returned. The Operation serves up IOStatistics; this counts the cost of all the list operations, but not the initial HEAD probe to see if the path is a file."}
{"index": 5393, "repo": "hadoop-aws-3.3.6", "code": "Interface GetContentSummaryOperation.GetContentSummaryCallbacks {\n\t// List all entries under a path.\n\torg.apache.hadoop.fs.RemoteIterator<S3ALocatedFileStatus> listFilesIterator(org.apache.hadoop.fs.Path path, boolean recursive);\n\t// Get the status of a path.\n\tS3AFileStatus probePathStatus(org.apache.hadoop.fs.Path path, Set<StatusProbeEnum> probes);\n}", "des": "Callbacks used by the operation."}
{"index": 5394, "repo": "hadoop-aws-3.3.6", "code": "Class Listing.AcceptAllButSelfAndS3nDirs {\n\t// Predicate to decide whether or not to accept a file status.\n\tboolean accept(org.apache.hadoop.fs.FileStatus status);\n\t// Reject a summary entry if the key path is the qualified Path, or it ends with \"_$folder$\".\n\tboolean accept(org.apache.hadoop.fs.Path keyPath, com.amazonaws.services.s3.model.S3ObjectSummary summary);\n\t// Accept all prefixes except the one for the base path, \"self\".\n\tboolean accept(org.apache.hadoop.fs.Path keyPath, String prefix);\n}", "des": "Accept all entries except the base path and those which map to S3N pseudo directory markers."}
{"index": 5395, "repo": "hadoop-aws-3.3.6", "code": "Class LoggingAuditor {\n\t// Add an attribute.\n\tvoid addAttribute(String key, String value);\n\tAuditSpanS3A createSpan(String operation, String path1, String path2);\n\t// Get the last header used.\n\tString getLastHeader();\n\t// Get the unbonded span to use after deactivating an active span.\n\tAuditSpanS3A getUnbondedSpan();\n\t// Service init, look for jobID and attach as an attribute in log entries.\n\tprotected void serviceInit(org.apache.hadoop.conf.Configuration conf);\n}", "des": "The LoggingAuditor logs operations at DEBUG (in SDK Request) and in span lifecycle and S3 request class construction at TRACE. The context information is added as the HTTP referrer."}
{"index": 5396, "repo": "hadoop-aws-3.3.6", "code": "Class MagicCommitTracker {\n\t// Complete operation: generate the final commit data, put it.\n\tboolean aboutToComplete(String uploadId, List<com.amazonaws.services.s3.model.PartETag> parts, long bytesWritten, org.apache.hadoop.fs.statistics.IOStatistics iostatistics);\n\t// Initialize the tracker.\n\tboolean initialize();\n\t// Flag to indicate that output is not visible after the stream is closed.\n\tboolean outputImmediatelyVisible();\n}", "des": "Put tracker for Magic commits."}
{"index": 5397, "repo": "hadoop-aws-3.3.6", "code": "Class MarkerTool {\n\t// Execute the marker tool, with no checks on return codes.\n\tstatic MarkerTool.ScanResult execMarkerTool(MarkerTool.ScanArgs scanArgs);\n\t// Return sub-command name.\n\tString getName();\n\tString getUsage();\n\tboolean isVerbose();\n\t// Reset the store and filesystem bindings.\n\tvoid resetBindings();\n\t// Run the tool, capturing the output (if the tool supports that).\n\tint run(String[] args, PrintStream stream);\n\tvoid setVerbose(boolean verbose);\n}", "des": "Audit an S3 bucket for directory markers."}
{"index": 5398, "repo": "hadoop-aws-3.3.6", "code": "Interface MarkerToolOperations {\n\t// Create an iterator over objects in S3.\n\torg.apache.hadoop.fs.RemoteIterator<S3AFileStatus> listObjects(org.apache.hadoop.fs.Path path, String key);\n\t// Remove keys from the store.\n\tvoid removeKeys(List<com.amazonaws.services.s3.model.DeleteObjectsRequest.KeyVersion> keysToDelete, boolean deleteFakeDir);\n}", "des": "Operations which must be offered by the store for MarkerTool. These are a proper subset of OperationCallbacks; this interface strips down those provided to the tool."}
{"index": 5399, "repo": "hadoop-aws-3.3.6", "code": "Class MarkerToolOperationsImpl {\n\t// Create an iterator over objects in S3.\n\torg.apache.hadoop.fs.RemoteIterator<S3AFileStatus> listObjects(org.apache.hadoop.fs.Path path, String key);\n\t// Remove keys from the store.\n\tvoid removeKeys(List<com.amazonaws.services.s3.model.DeleteObjectsRequest.KeyVersion> keysToDelete, boolean deleteFakeDir);\n}", "des": "Implement the marker tool operations by forwarding to the OperationCallbacks instance provided in the constructor."}
{"index": 5400, "repo": "hadoop-aws-3.3.6", "code": "Enum MarshalledCredentials.CredentialTypeRequired {\n\tString getText();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MarshalledCredentials.CredentialTypeRequired valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MarshalledCredentials.CredentialTypeRequired[] values();\n}", "des": "Enumeration of credential types for use in validation methods."}
{"index": 5401, "repo": "hadoop-aws-3.3.6", "code": "Interface MkdirOperation.MkdirCallbacks {\n\t// Create a fake directory, always ending in \"/\".\n\tvoid createFakeDirectory(org.apache.hadoop.fs.Path dir, boolean keepMarkers);\n\t// Get the status of a path.\n\tS3AFileStatus probePathStatus(org.apache.hadoop.fs.Path path, Set<StatusProbeEnum> probes);\n}", "des": "Callbacks used by mkdir."}
{"index": 5402, "repo": "hadoop-aws-3.3.6", "code": "Class NetworkBinding {\n\t// Configures the SSLConnectionSocketFactory used by the AWS SDK.\n\tstatic void bindSSLChannelMode(org.apache.hadoop.conf.Configuration conf, com.amazonaws.ClientConfiguration awsConf);\n\t// Given an S3 bucket region as returned by a bucket location query, fix it into a form which can be used by other AWS commands.\n\tstatic String fixBucketRegion(String region);\n\t// Log the dns address associated with s3 endpoint.\n\tstatic void logDnsLookup(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Configures network settings when communicating with AWS services."}
{"index": 5403, "repo": "hadoop-aws-3.3.6", "code": "Class NoopAuditor {\n\t// Create, init and start an instance.\n\tstatic NoopAuditor createAndStartNoopAuditor(org.apache.hadoop.conf.Configuration conf, NoopSpan.SpanActivationCallbacks activationCallbacks);\n\tAuditSpanS3A createSpan(String operation, String path1, String path2);\n\t// Get the unbonded span to use after deactivating an active span.\n\tAuditSpanS3A getUnbondedSpan();\n}", "des": "An audit service which returns the NoopSpan. Even though the spans are no-ops, each span is still created with a unique span ID."}
{"index": 5404, "repo": "hadoop-aws-3.3.6", "code": "Interface NoopSpan.SpanActivationCallbacks {\n\t// Span was activated.\n\tvoid activate(AuditSpanS3A span);\n\t// Span was deactivated.\n\tvoid deactivate(AuditSpanS3A span);\n}", "des": "Activation callbacks."}
{"index": 5405, "repo": "hadoop-aws-3.3.6", "code": "Interface OperationAuditor {\n\t// Check for permission to access a path.\n\tdefault boolean checkAccess(org.apache.hadoop.fs.Path path, S3AFileStatus status, org.apache.hadoop.fs.permission.FsAction mode);\n\t// Get the Auditor ID.\n\tString getAuditorId();\n\t// Get the unbonded span to use after deactivating an active span.\n\tAuditSpanS3A getUnbondedSpan();\n\t// Initialize.\n\tvoid init(OperationAuditorOptions options);\n\t// Span reference lost from GC operations.\n\tdefault void noteSpanReferenceLost(long threadId);\n}", "des": "Interfaces for audit services to implement."}
{"index": 5406, "repo": "hadoop-aws-3.3.6", "code": "Class OperationAuditorOptions {\n\t// Create one.\n\tstatic OperationAuditorOptions builder();\n\torg.apache.hadoop.conf.Configuration getConfiguration();\n\torg.apache.hadoop.fs.statistics.impl.IOStatisticsStore getIoStatisticsStore();\n\t// Set builder value.\n\tOperationAuditorOptions withConfiguration(org.apache.hadoop.conf.Configuration value);\n\t// Set builder value.\n\tOperationAuditorOptions withIoStatisticsStore(org.apache.hadoop.fs.statistics.impl.IOStatisticsStore value);\n}", "des": "Options for the OperationAuditor. Done as a builder and passed in so that if it is extended, external auditors will still link."}
{"index": 5407, "repo": "hadoop-aws-3.3.6", "code": "Class PartitionedStagingCommitter {\n\t// Commit the task by uploading all created files and then writing a pending entry for them.\n\tprotected int commitTaskInternal(org.apache.hadoop.mapreduce.TaskAttemptContext context, List<? extends org.apache.hadoop.fs.FileStatus> taskOutput, CommitContext commitContext);\n\t// Get the name of this committer.\n\tString getName();\n\t// All Job-side conflict resolution.\n\tvoid preCommitJob(CommitContext commitContext, AbstractS3ACommitter.ActiveCommit pending);\n}", "des": "Partitioned committer. This writes data to specific \"partition\" subdirectories, applying conflict resolution on a partition-by-partition basis. The existence and state of any parallel partitions for which there is no are output files are not considered in the conflict resolution. The conflict policy is FAIL: fail the commit if any of the partitions have data. APPEND: add extra data to the destination partitions. REPLACE: delete the destination partition in the job commit (i.e. after and only if all tasks have succeeded. To determine the paths, the precommit process actually has to read in all source files, independently of the final commit phase. This is inefficient, though some parallelization here helps."}
{"index": 5408, "repo": "hadoop-aws-3.3.6", "code": "Class PutObjectOptions {\n\t// Get the options to delete directory markers.\n\tstatic PutObjectOptions deletingDirs();\n\t// Headers for the put/post request.\n\tMap<String,String> getHeaders();\n\t// Get the marker retention flag.\n\tboolean isKeepMarkers();\n\t// Get the options to keep directories.\n\tstatic PutObjectOptions keepingDirs();\n}", "des": "Extensible structure for options when putting/writing objects."}
{"index": 5409, "repo": "hadoop-aws-3.3.6", "code": "Class PutTracker {\n\t// Callback when the upload is is about to complete.\n\tboolean aboutToComplete(String uploadId, List<com.amazonaws.services.s3.model.PartETag> parts, long bytesWritten, org.apache.hadoop.fs.statistics.IOStatistics iostatistics);\n\t// get the destination key.\n\tString getDestKey();\n\t// Startup event.\n\tboolean initialize();\n\t// Flag to indicate that output is not immediately visible after the stream is closed.\n\tboolean outputImmediatelyVisible();\n}", "des": "Multipart put tracker. Base class does nothing except declare that any MPU must complete in the close() operation."}
{"index": 5410, "repo": "hadoop-aws-3.3.6", "code": "Enum RoleModel.Effects {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RoleModel.Effects valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RoleModel.Effects[] values();\n}", "des": "Effect options."}
{"index": 5411, "repo": "hadoop-aws-3.3.6", "code": "Class RoleModel.Policy {\n\t// Add a collection of statements.\n\tvoid add(Collection<RoleModel.Statement> statements);\n\t// Add the statements of another policy to this one.\n\tvoid add(RoleModel.Policy other);\n\t// Add a single statement.\n\tvoid add(RoleModel.Statement stat);\n\t// Validation includes validating all statements.\n\tvoid validate();\n}", "des": "A policy is one or more statements."}
{"index": 5412, "repo": "hadoop-aws-3.3.6", "code": "Class RoleModel.Statement {\n\tRoleModel.Statement addActions(Collection<String> actions);\n\tRoleModel.Statement addActions(String... actions);\n\t// Add a list of resources.\n\tRoleModel.Statement addResources(Collection<String> resources);\n\tRoleModel.Statement addResources(String... resources);\n\tRoleModel.Statement setAllowed(boolean f);\n\t// validation operation.\n\tvoid validate();\n}", "des": "A single statement."}
{"index": 5413, "repo": "hadoop-aws-3.3.6", "code": "Class RolePolicies {\n\t// From an S3 bucket name, build an ARN to refer to it.\n\tstatic List<RoleModel.Statement> allowS3Operations(String bucket, boolean write);\n\t// From an S3 bucket name, build an ARN to refer to all objects in it.\n\tstatic String bucketObjectsToArn(String bucket);\n\t// From an S3 bucket name, build an ARN to refer to it.\n\tstatic String bucketToArn(String bucket);\n}", "des": "Operations, statements and policies covering the operations needed to work with S3."}
{"index": 5414, "repo": "hadoop-aws-3.3.6", "code": "Enum S3ADelegationTokens.TokenIssuingPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic S3ADelegationTokens.TokenIssuingPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic S3ADelegationTokens.TokenIssuingPolicy[] values();\n}", "des": "How will tokens be issued on request? The RequestNewToken policy does not guarantee that a tokens can be created, only that an attempt will be made to request one. It may fail (wrong credential types, wrong role, etc)."}
{"index": 5415, "repo": "hadoop-aws-3.3.6", "code": "Class S3ADtFetcher {\n\t// Returns Token object via FileSystem, null if bad argument.\n\torg.apache.hadoop.security.token.Token<?> addDelegationTokens(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.security.Credentials creds, String renewer, String url);\n\t// Returns the service name for HDFS, which is also a valid URL prefix.\n\torg.apache.hadoop.io.Text getServiceName();\n\tboolean isTokenRequired();\n}", "des": "A DT fetcher for S3A. This is a copy-and-paste of org.apache.hadoop.hdfs.HdfsDtFetcher. It is only needed for the `hadoop dtutil` command."}
{"index": 5416, "repo": "hadoop-aws-3.3.6", "code": "Interface S3AInputStream.InputStreamCallbacks {\n\t// Execute the request.\n\tcom.amazonaws.services.s3.model.S3Object getObject(com.amazonaws.services.s3.model.GetObjectRequest request);\n\t// Create a GET request.\n\tcom.amazonaws.services.s3.model.GetObjectRequest newGetRequest(String key);\n\t// Submit some asynchronous work, for example, draining a stream.\n\t<T> CompletableFuture<T> submit(org.apache.hadoop.util.functional.CallableRaisingIOE<T> operation);\n}", "des": "Callbacks for input stream IO."}
{"index": 5417, "repo": "hadoop-aws-3.3.6", "code": "Class S3Guard {\n\t// Is the path for the given FS instance authoritative?\n\tstatic boolean allowAuthoritative(org.apache.hadoop.fs.Path p, S3AFileSystem fs, Collection<String> authPaths);\n\t// Assert that the FS is not configured to use an unsupported S3Guard option.\n\tstatic boolean checkNoS3Guard(URI fsURI, org.apache.hadoop.conf.Configuration conf);\n\tstatic Collection<String> getAuthoritativePaths(S3AFileSystem fs);\n}", "des": "Logic for integrating MetadataStore with S3A. Most of the methods here were deleted when the S3Guard feature was removed."}
{"index": 5418, "repo": "hadoop-aws-3.3.6", "code": "Class S3GuardTool.BucketInfo {\n\t// Return sub-command name.\n\tString getName();\n\tString getUsage();\n\t// Run the tool, capturing the output (if the tool supports that).\n\tint run(String[] args, PrintStream out);\n}", "des": "Get info about a bucket and its S3Guard integration status."}
{"index": 5419, "repo": "hadoop-aws-3.3.6", "code": "Class S3ListRequest {\n\tcom.amazonaws.services.s3.model.ListObjectsRequest getV1();\n\tcom.amazonaws.services.s3.model.ListObjectsV2Request getV2();\n\t// Is this a v1 API request or v2?\n\tboolean isV1();\n\t// Restricted constructors to ensure v1 or v2, not both.\n\tstatic S3ListRequest v1(com.amazonaws.services.s3.model.ListObjectsRequest request);\n\t// Restricted constructors to ensure v1 or v2, not both.\n\tstatic S3ListRequest v2(com.amazonaws.services.s3.model.ListObjectsV2Request request);\n}", "des": "API version-independent container for S3 List requests."}
{"index": 5420, "repo": "hadoop-aws-3.3.6", "code": "Class S3xLoginHelper.Login {\n\t// Equality test matches user and password.\n\tboolean equals(Object o);\n\tString getPassword();\n\tString getUser();\n\t// Predicate to verify login details are defined.\n\tboolean hasLogin();\n}", "des": "Simple tuple of login details."}
{"index": 5421, "repo": "hadoop-aws-3.3.6", "code": "Class SelectTool {\n\t// Work out the bandwidth in MB/s.\n\tstatic double bandwidthMBs(long bytes, long durationMillisNS);\n\tlong getBytesRead();\n\t// Number of lines read, when printing to the console.\n\tlong getLinesRead();\n\t// Return sub-command name.\n\tString getName();\n\torg.apache.hadoop.util.OperationDuration getSelectDuration();\n\tString getUsage();\n\t// Execute the select operation.\n\tint run(String[] args, PrintStream out);\n}", "des": "This is a CLI tool for the select operation, which is available through the S3Guard command. Usage:"}
{"index": 5422, "repo": "hadoop-aws-3.3.6", "code": "Class SessionTokenIdentifier {\n\t// Return the expiry time in seconds since 1970-01-01.\n\tlong getExpiryTime();\n\t// Get the marshalled credentials.\n\tMarshalledCredentials getMarshalledCredentials();\n\t// Read state.\n\tvoid readFields(DataInput in);\n\t// Write state.\n\tvoid write(DataOutput out);\n}", "des": "A token identifier which contains a set of AWS session credentials, credentials which will be valid until they expire. Note 1: There's a risk here that the reference to MarshalledCredentials may trigger a transitive load of AWS classes, a load which will fail if the aws SDK isn't on the classpath. Note 2: This class does support subclassing, but every subclass MUST declare itself to be of a different token kind. Otherwise the process for decoding tokens breaks."}
{"index": 5423, "repo": "hadoop-aws-3.3.6", "code": "Enum Statistic {\n\t// Get a statistic from a symbol.\n\tstatic Statistic fromSymbol(String symbol);\n\tString getDescription();\n\tString getSymbol();\n\t// What type is this statistic?\n\tStatisticTypeEnum getType();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Statistic valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Statistic[] values();\n}", "des": "Statistic which are collected in S3A. Counter and duration statistics are published in S3AFileSystem.getStorageStatistics(). and as metrics in S3AInstrumentation."}
{"index": 5424, "repo": "hadoop-aws-3.3.6", "code": "Enum StatisticTypeEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StatisticTypeEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StatisticTypeEnum[] values();\n}", "des": "Enum of statistic types."}
{"index": 5425, "repo": "hadoop-aws-3.3.6", "code": "Enum StatusProbeEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StatusProbeEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StatusProbeEnum[] values();\n}", "des": "Enum of probes which can be made of S3."}
{"index": 5426, "repo": "hadoop-aws-3.3.6", "code": "Class STSClientFactory.STSClient {\n\tvoid close();\n\t// Request a set of role credentials.\n\tcom.amazonaws.services.securitytoken.model.Credentials requestRole(String roleARN, String sessionName, String policy, long duration, TimeUnit timeUnit);\n\t// Request a set of session credentials.\n\tcom.amazonaws.services.securitytoken.model.Credentials requestSessionCredentials(long duration, TimeUnit timeUnit);\n}", "des": "STS client connection with retries."}
{"index": 5427, "repo": "hadoop-aws-3.3.6", "code": "Enum Tristate {\n\tstatic Tristate fromBool(boolean v);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Tristate valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Tristate[] values();\n}", "des": "Simple enum to express {true, false, don't know}."}
{"index": 5428, "repo": "hadoop-aws-3.3.6", "code": "Class V2Migration {\n\t// Warns on use of custom signers.\n\tstatic void v1CustomSignerUsed();\n\t// Warns when v1 credential providers are used with delegation tokens.\n\tstatic void v1DelegationTokenCredentialProvidersUsed();\n\t// Warns on use of getObjectMetadata.\n\tstatic void v1GetObjectMetadataCalled();\n\t// Warns on an AWS V1 credential provider being referenced directly.\n\tstatic void v1ProviderReferenced(String name);\n\t// Warns on the v1 s3 client being requested.\n\tstatic void v1S3ClientRequested();\n}", "des": "This class provides utility methods required for migrating S3A to AWS Java SDK V2. For more information on the upgrade, see HADOOP-18073."}
{"index": 5429, "repo": "hadoop-aws-3.3.6", "code": "Interface WriteOperationHelper.WriteOperationHelperCallbacks {\n\t// Initiates a complete multi-part upload request.\n\tcom.amazonaws.services.s3.model.CompleteMultipartUploadResult completeMultipartUpload(com.amazonaws.services.s3.model.CompleteMultipartUploadRequest request);\n\t// Initiates a select request.\n\tcom.amazonaws.services.s3.model.SelectObjectContentResult selectObjectContent(com.amazonaws.services.s3.model.SelectObjectContentRequest request);\n}", "des": "Callbacks for writeOperationHelper."}
{"index": 5430, "repo": "avro-1.11.2", "code": "Class BinaryMessageDecoder<D> {\n\t// Adds a Schema that can be used to decode buffers.\n\tvoid addSchema(Schema writeSchema);\n\t// Deserialize a single datum from an InputStream.\n\tD decode(InputStream stream, D reuse);\n}", "des": "A MessageDecoder that reads a binary-encoded datum. This checks for the datum header and decodes the payload with the schema that corresponds to the 8-byte schema fingerprint."}
{"index": 5431, "repo": "avro-1.11.2", "code": "Class BinaryMessageEncoder<D> {\n\t// Serialize a single datum to a ByteBuffer.\n\tByteBuffer encode(D datum);\n\t// Serialize a single datum to an OutputStream.\n\tvoid encode(D datum, OutputStream stream);\n}", "des": "A MessageEncoder that adds a header and 8-byte schema fingerprint to each datum encoded as binary."}
{"index": 5432, "repo": "avro-1.11.2", "code": "Class BZip2Codec {\n\t// Compresses the input data\n\tByteBuffer compress(ByteBuffer uncompressedData);\n\t// Decompress the data\n\tByteBuffer decompress(ByteBuffer compressedData);\n\t// Codecs must implement an equals() method.\n\tboolean equals(Object obj);\n\t// Name of the codec; written to the file's metadata.\n\tString getName();\n}", "des": "Implements bzip2 compression and decompression."}
{"index": 5433, "repo": "avro-1.11.2", "code": "Class Codec {\n\t// Compresses the input data\n\tabstract ByteBuffer compress(ByteBuffer uncompressedData);\n\tprotected static int computeOffset(ByteBuffer data);\n\t// Decompress the data\n\tabstract ByteBuffer decompress(ByteBuffer compressedData);\n\t// Codecs must implement an equals() method.\n\tabstract boolean equals(Object other);\n\t// Name of the codec; written to the file's metadata.\n\tabstract String getName();\n}", "des": "Interface for Avro-supported compression codecs for data files. Note that Codec objects may maintain internal state (e.g. buffers) and are not thread safe."}
{"index": 5434, "repo": "avro-1.11.2", "code": "Interface DatumReader<D> {\n\t// Read a datum.\n\tD read(D reuse, Decoder in);\n\t// Set the writer's schema.\n\tvoid setSchema(Schema schema);\n}", "des": "Read data of a schema."}
{"index": 5435, "repo": "avro-1.11.2", "code": "Interface DatumWriter<D> {\n\t// Set the schema.\n\tvoid setSchema(Schema schema);\n\t// Write a datum.\n\tvoid write(D datum, Encoder out);\n}", "des": "Write data of a schema."}
{"index": 5436, "repo": "avro-1.11.2", "code": "Class DeflateCodec {\n\t// Compresses the input data\n\tByteBuffer compress(ByteBuffer data);\n\t// Decompress the data\n\tByteBuffer decompress(ByteBuffer data);\n\t// Codecs must implement an equals() method.\n\tboolean equals(Object obj);\n\t// Name of the codec; written to the file's metadata.\n\tString getName();\n}", "des": "Implements DEFLATE (RFC1951) compression and decompression. Note that there is a distinction between RFC1951 (deflate) and RFC1950 (zlib). zlib adds an extra 2-byte header at the front, and a 4-byte checksum at the end. The code here, by passing \"true\" as the \"nowrap\" option to Inflater and Deflater, is using RFC1951."}
{"index": 5437, "repo": "avro-1.11.2", "code": "Interface ErrorBuilder<T> {\n\t// Clears the cause\n\tErrorBuilder<T> clearCause();\n\t// Clears the value\n\tErrorBuilder<T> clearValue();\n\t// Gets the error cause\n\tThrowable getCause();\n\t// Gets the value\n\tObject getValue();\n\t// Checks whether the cause has been set\n\tboolean hasCause();\n\t// Checks whether the value has been set\n\tboolean hasValue();\n\t// Sets the error cause\n\tErrorBuilder<T> setCause(Throwable cause);\n\t// Sets the value\n\tErrorBuilder<T> setValue(Object value);\n}", "des": "Interface for error builders"}
{"index": 5438, "repo": "avro-1.11.2", "code": "Interface FileReader<D> {\n\t// Return the schema for data in this file.\n\tSchema getSchema();\n\t// Read the next datum from the file.\n\tD next(D reuse);\n\t// Return true if past the next synchronization point after a position.\n\tboolean pastSync(long position);\n\t// Move to the next synchronization point after a position.\n\tvoid sync(long position);\n\t// Return the current position in the input.\n\tlong tell();\n}", "des": "Interface for reading data from a file."}
{"index": 5439, "repo": "avro-1.11.2", "code": "Interface GenericArray<T> {\n\t// The current content of the location where List.add(Object) would next store an element, if any.\n\tT peek();\n\t// clean up reusable objects from array (if reset didn't already)\n\tdefault void prune();\n\t// reset size counter of array to zero\n\tdefault void reset();\n\t// Reverses the order of the elements in this array.\n\tvoid reverse();\n}", "des": "Array that permits reuse of contained elements."}
{"index": 5440, "repo": "avro-1.11.2", "code": "Class GenericData.Fixed {\n\t// Return the data.\n\tbyte[] bytes();\n\tvoid bytes(byte[] bytes);\n\tint compareTo(GenericData.Fixed that);\n\tboolean equals(Object o);\n\t// The schema of this instance.\n\tSchema getSchema();\n\tprotected void setSchema(Schema schema);\n}", "des": "Default implementation of GenericFixed."}
{"index": 5441, "repo": "avro-1.11.2", "code": "Class GenericData.Record {\n\tint compareTo(GenericData.Record that);\n\tboolean equals(Object o);\n\t// Return the value of a field given its position in the schema.\n\tObject get(int i);\n\t// Return the value of a field given its name.\n\tObject get(String key);\n\t// The schema of this instance.\n\tSchema getSchema();\n\t// Set the value of a field given its position in the schema.\n\tvoid put(int i, Object v);\n\t// Set the value of a field given its name.\n\tvoid put(String key, Object value);\n}", "des": "Default implementation of GenericRecord. Note that this implementation does not fill in default values for fields if they are not specified; use GenericRecordBuilder in that case."}
{"index": 5442, "repo": "avro-1.11.2", "code": "Enum GenericData.StringType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic GenericData.StringType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic GenericData.StringType[] values();\n}", "des": "Used to specify the Java type for a string schema."}
{"index": 5443, "repo": "avro-1.11.2", "code": "Interface GenericRecord {\n\t// Return the value of a field given its name.\n\tObject get(String key);\n\t// Return true if record has field with name: key\n\tdefault boolean hasField(String key);\n\t// Set the value of a field given its name.\n\tvoid put(String key, Object v);\n}", "des": "A generic instance of a record schema. Fields are accessible by name as well as by index."}
{"index": 5444, "repo": "avro-1.11.2", "code": "Interface IndexedRecord {\n\t// Return the value of a field given its position in the schema.\n\tObject get(int i);\n\t// Set the value of a field given its position in the schema.\n\tvoid put(int i, Object v);\n}", "des": "A record implementation that permits field access by integer index."}
{"index": 5445, "repo": "avro-1.11.2", "code": "Class Json {\n\t// Parses a JSON string and converts it to the object model described in JsonProperties.\n\tstatic Object parseJson(String s);\n\t// Converts an instance of the object model described in JsonProperties to a JSON string.\n\tstatic String toString(Object datum);\n}", "des": "Utilities for reading and writing arbitrary Json data in Avro format."}
{"index": 5446, "repo": "avro-1.11.2", "code": "Class Json.ObjectReader {\n\t// Read a datum.\n\tObject read(Object reuse, Decoder in);\n\t// Set the writer's schema.\n\tvoid setSchema(Schema schema);\n}", "des": "DatumReader for arbitrary Json data using the object model described in JsonProperties."}
{"index": 5447, "repo": "avro-1.11.2", "code": "Class Json.ObjectWriter {\n\t// Set the schema.\n\tvoid setSchema(Schema schema);\n\t// Write a datum.\n\tvoid write(Object datum, Encoder out);\n}", "des": "DatumWriter for arbitrary Json data using the object model described in JsonProperties."}
{"index": 5448, "repo": "avro-1.11.2", "code": "Class JsonGrammarGenerator {\n\t// Returns the non-terminal that is the start symbol for the grammar for the grammar for the given schema sc.\n\tSymbol generate(Schema schema);\n\t// Returns the non-terminal that is the start symbol for grammar of the given schema sc.\n\tSymbol generate(Schema sc, Map<org.apache.avro.io.parsing.ValidatingGrammarGenerator.LitS,Symbol> seen);\n}", "des": "The class that generates a grammar suitable to parse Avro data in JSON format."}
{"index": 5449, "repo": "avro-1.11.2", "code": "Class LogicalType {\n\t// Add this logical type to the given Schema.\n\tSchema addToSchema(Schema schema);\n\t// Get the name of this logical type.\n\tString getName();\n\t// Validate this logical type for the given Schema.\n\tvoid validate(Schema schema);\n}", "des": "Logical types provides an opt-in way to extend Avro's types. Logical types specify a way of representing a high-level type as a base Avro type. For example, a date is specified as the number of days after the unix epoch (or before using a negative value). This enables extensions to Avro's type system without breaking binary compatibility. Older versions see the base type and ignore the logical type."}
{"index": 5450, "repo": "avro-1.11.2", "code": "Class LogicalTypes.Decimal {\n\t// Add this logical type to the given Schema.\n\tSchema addToSchema(Schema schema);\n\tboolean equals(Object o);\n\tint getPrecision();\n\tint getScale();\n\t// Validate this logical type for the given Schema.\n\tvoid validate(Schema schema);\n}", "des": "Decimal represents arbitrary-precision fixed-scale decimal numbers"}
{"index": 5451, "repo": "avro-1.11.2", "code": "Class MessageDecoder.BaseDecoder<D> {\n\t// Deserialize a single datum from a byte array.\n\tD decode(byte[] encoded);\n\t// Deserialize a single datum from a byte array.\n\tD decode(byte[] encoded, D reuse);\n\t// Deserialize a single datum from a ByteBuffer.\n\tD decode(ByteBuffer encoded);\n\t// Deserialize a single datum from a ByteBuffer.\n\tD decode(ByteBuffer encoded, D reuse);\n\t// Deserialize a single datum from an InputStream.\n\tD decode(InputStream stream);\n}", "des": "Base class for MessageEncoder implementations that provides default implementations for most of the DatumEncoder API."}
{"index": 5452, "repo": "avro-1.11.2", "code": "Interface MessageEncoder<D> {\n\t// Serialize a single datum to a ByteBuffer.\n\tByteBuffer encode(D datum);\n\t// Serialize a single datum to an OutputStream.\n\tvoid encode(D datum, OutputStream stream);\n}", "des": "Serializes an individual datum as a ByteBuffer or to an OutputStream."}
{"index": 5453, "repo": "avro-1.11.2", "code": "Class ParsingDecoder {\n\t// Skips the action at the top of the stack.\n\tvoid skipAction();\n\tprotected abstract void skipFixed();\n\t// Skips the symbol at the top of the stack.\n\tvoid skipTopSymbol();\n}", "des": "Base class for parser-based Decoders."}
{"index": 5454, "repo": "avro-1.11.2", "code": "Class ParsingEncoder {\n\tprotected int depth();\n\tprotected void pop();\n\t// Push a new collection on to the stack.\n\tprotected void push();\n\t// Call this method before writing a batch of items in an array or a map.\n\tvoid setItemCount(long itemCount);\n\t// Start a new item of an array or map.\n\tvoid startItem();\n}", "des": "Base class for parser-based Encoders."}
{"index": 5455, "repo": "avro-1.11.2", "code": "Interface PathTracingException<T extends Throwable> {\n\t// produces a user-facing exception to be thrown back out to user code\n\tT summarize(Schema root);\n\t// appends a path element to the trace.\n\tvoid tracePath(PathElement step);\n}", "des": "interface for exceptions that can trace the AvroPath of an error"}
{"index": 5456, "repo": "avro-1.11.2", "code": "Class RawMessageEncoder<D> {\n\t// Serialize a single datum to a ByteBuffer.\n\tByteBuffer encode(D datum);\n\t// Serialize a single datum to an OutputStream.\n\tvoid encode(D datum, OutputStream stream);\n}", "des": "A MessageEncoder that encodes only a datum's bytes, without additional information (such as a schema fingerprint)."}
{"index": 5457, "repo": "avro-1.11.2", "code": "Class ReflectData.AllowNull {\n\t// Create a schema for a field.\n\tprotected Schema createFieldSchema(Field field, Map<String,Schema> names);\n\t// Return the singleton instance.\n\tstatic ReflectData.AllowNull get();\n}", "des": "ReflectData implementation that permits null field values. The schema generated for each field is a union of its declared type and null."}
{"index": 5458, "repo": "avro-1.11.2", "code": "Class ReflectDatumWriter<T> {\n\t// Called to write data.\n\tprotected void write(Schema schema, Object datum, Encoder out);\n\t// Called to write a array.\n\tprotected void writeArray(Schema schema, Object datum, Encoder out);\n\t// Called to write a bytes.\n\tprotected void writeBytes(Object datum, Encoder out);\n\t// Called to write a single field of a record.\n\tprotected void writeField(Object record, Schema.Field f, Encoder out, Object state);\n}", "des": "DatumWriter for existing classes via Java reflection."}
{"index": 5459, "repo": "avro-1.11.2", "code": "Class Resolver {\n\t// Uses GenericData.get() for the data param.\n\tstatic Resolver.Action resolve(Schema writer, Schema reader);\n\t// Returns a Resolver.Action tree for resolving the writer schema writer and the reader schema reader.\n\tstatic Resolver.Action resolve(Schema writer, Schema reader, GenericData data);\n}", "des": "Encapsulate schema-resolution logic in an easy-to-consume representation. See resolve(org.apache.avro.Schema, org.apache.avro.Schema, org.apache.avro.generic.GenericData) and also the separate document entitled refactoring-resolution for more information. It might also be helpful to study ResolvingGrammarGenerator as an example of how to use this class."}
{"index": 5460, "repo": "avro-1.11.2", "code": "Enum Resolver.Action.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Resolver.Action.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Resolver.Action.Type[] values();\n}", "des": "Helps us traverse faster."}
{"index": 5461, "repo": "avro-1.11.2", "code": "Class Resolver.Promote {\n\t// Returns true iff w and r are both primitive types and either they are the same type or w is promotable to r.\n\tstatic boolean isValid(Schema w, Schema r);\n\t// Return a promotion.\n\tstatic Resolver.Action resolve(Schema w, Schema r, GenericData d);\n}", "des": "In this case, the writer's type needs to be promoted to the reader's. These are constructed by resolve(org.apache.avro.Schema, org.apache.avro.Schema, org.apache.avro.generic.GenericData), which will only construct one when the writer's and reader's schemas are different (ie, no \"self promotion\"), and whent the promotion is one allowed by the Avro spec."}
{"index": 5462, "repo": "avro-1.11.2", "code": "Class ResolvingGrammarGenerator {\n\t// Encodes the given Json node n on to the encoder e according to the schema s.\n\tstatic void encode(Encoder e, Schema s, com.fasterxml.jackson.databind.JsonNode n);\n\t// Resolves the writer schema writer and the reader schema reader and returns the start symbol for the grammar generated.\n\tSymbol generate(Schema writer, Schema reader);\n}", "des": "The class that generates a resolving grammar to resolve between two schemas."}
{"index": 5463, "repo": "avro-1.11.2", "code": "Class Schema.Field {\n\tvoid addAlias(String alias);\n\t// Return the defined aliases as an unmodifiable Set.\n\tSet<String> aliases();\n\tObject defaultVal();\n\t// Field's documentation within the record, if set.\n\tString doc();\n\tboolean equals(Object other);\n\tboolean hasDefaultValue();\n\tString name();\n\tSchema.Field.Order order();\n\t// The position of this field within the record.\n\tint pos();\n\t// This field's Schema.\n\tSchema schema();\n}", "des": "A field within a record."}
{"index": 5464, "repo": "avro-1.11.2", "code": "Enum Schema.Field.Order {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Schema.Field.Order valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Schema.Field.Order[] values();\n}", "des": "How values of this field should be ordered when sorting records."}
{"index": 5465, "repo": "avro-1.11.2", "code": "Enum Schema.Type {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Schema.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Schema.Type[] values();\n}", "des": "The type of a schema."}
{"index": 5466, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.ArrayBuilder<R> {\n\t// Return a type builder for configuring the array's nested items schema.\n\tSchemaBuilder.TypeBuilder<R> items();\n\t// Complete configuration of this array, setting the schema of the array items to the schema provided.\n\tR items(Schema itemsSchema);\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.ArrayBuilder<R> self();\n}", "des": "Builds an Avro Array type with optional properties."}
{"index": 5467, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.BooleanBuilder<R> {\n\t// complete building this type, return control to context\n\tR endBoolean();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.BooleanBuilder<R> self();\n}", "des": "Builds an Avro boolean type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endBoolean()"}
{"index": 5468, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.BytesBuilder<R> {\n\t// complete building this type, return control to context\n\tR endBytes();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.BytesBuilder<R> self();\n}", "des": "Builds an Avro bytes type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endBytes()"}
{"index": 5469, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.BytesDefault<R> {\n\t// Completes this field with the default value provided, cannot be null\n\tSchemaBuilder.FieldAssembler<R> bytesDefault(byte[] defaultVal);\n\t// Completes this field with the default value provided, cannot be null\n\tSchemaBuilder.FieldAssembler<R> bytesDefault(ByteBuffer defaultVal);\n\t// Completes this field with the default value provided, cannot be null.\n\tSchemaBuilder.FieldAssembler<R> bytesDefault(String defaultVal);\n}", "des": "Choose whether to use a default value for the field or not."}
{"index": 5470, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.DoubleBuilder<R> {\n\t// complete building this type, return control to context\n\tR endDouble();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.DoubleBuilder<R> self();\n}", "des": "Builds an Avro double type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endDouble()"}
{"index": 5471, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.EnumBuilder<R> {\n\t// Set the default value of the enum.\n\tSchemaBuilder.EnumBuilder<R> defaultSymbol(String enumDefault);\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.EnumBuilder<R> self();\n\t// Configure this enum type's symbols, and end its configuration.\n\tR symbols(String... symbols);\n}", "des": "Builds an Avro Enum type with optional properties, namespace, doc, and aliases."}
{"index": 5472, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.FieldTypeBuilder<R> {\n\t// A shortcut for building a union of a type and null, with an optional default value of the non-null type.\n\tSchemaBuilder.BaseFieldTypeBuilder<R> nullable();\n\t// A shortcut for building a union of null and a type, with a null default.\n\tSchemaBuilder.BaseTypeBuilder<SchemaBuilder.FieldAssembler<R>> optional();\n\t// Build an Avro union schema type.\n\tSchemaBuilder.UnionFieldTypeBuilder<R> unionOf();\n}", "des": "FieldTypeBuilder adds unionOf(), nullable(), and optional() to BaseFieldTypeBuilder."}
{"index": 5473, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.FixedBuilder<R> {\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.FixedBuilder<R> self();\n\t// Configure this fixed type's size, and end its configuration.\n\tR size(int size);\n}", "des": "Builds an Avro Fixed type with optional properties, namespace, doc, and aliases."}
{"index": 5474, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.FixedDefault<R> {\n\t// Completes this field with the default value provided, cannot be null\n\tSchemaBuilder.FieldAssembler<R> fixedDefault(byte[] defaultVal);\n\t// Completes this field with the default value provided, cannot be null\n\tSchemaBuilder.FieldAssembler<R> fixedDefault(ByteBuffer defaultVal);\n\t// Completes this field with the default value provided, cannot be null.\n\tSchemaBuilder.FieldAssembler<R> fixedDefault(String defaultVal);\n}", "des": "Choose whether to use a default value for the field or not."}
{"index": 5475, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.FloatBuilder<R> {\n\t// complete building this type, return control to context\n\tR endFloat();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.FloatBuilder<R> self();\n}", "des": "Builds an Avro float type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endFloat()"}
{"index": 5476, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.IntBuilder<R> {\n\t// complete building this type, return control to context\n\tR endInt();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.IntBuilder<R> self();\n}", "des": "Builds an Avro int type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endInt()"}
{"index": 5477, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.LongBuilder<R> {\n\t// complete building this type, return control to context\n\tR endLong();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.LongBuilder<R> self();\n}", "des": "Builds an Avro long type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endLong()"}
{"index": 5478, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.MapBuilder<R> {\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.MapBuilder<R> self();\n\t// Return a type builder for configuring the map's nested values schema.\n\tSchemaBuilder.TypeBuilder<R> values();\n\t// Complete configuration of this map, setting the schema of the map values to the schema provided.\n\tR values(Schema valueSchema);\n}", "des": "Builds an Avro Map type with optional properties."}
{"index": 5479, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.NamedBuilder<S extends SchemaBuilder.NamedBuilder<S>> {\n\t// configure this type's optional name aliases\n\tS aliases(String... aliases);\n\t// configure this type's optional documentation string\n\tS doc(String doc);\n}", "des": "An abstract type that provides builder methods for configuring the name, doc, and aliases of all Avro types that have names (fields, Fixed, Record, and Enum)."}
{"index": 5480, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.NullBuilder<R> {\n\t// complete building this type, return control to context\n\tR endNull();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.NullBuilder<R> self();\n}", "des": "Builds an Avro null type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endNull()"}
{"index": 5481, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.PropBuilder<S extends SchemaBuilder.PropBuilder<S>> {\n\t// Set name-value pair properties for this type or field.\n\tS prop(String name, Object value);\n\t// Set name-value pair properties for this type or field.\n\tS prop(String name, String val);\n\t// a self-type for chaining builder subclasses.\n\tprotected abstract S self();\n}", "des": "An abstract builder for all Avro types. All Avro types can have arbitrary string key-value properties."}
{"index": 5482, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.StringBldr<R> {\n\t// complete building this type, return control to context\n\tR endString();\n\t// a self-type for chaining builder subclasses.\n\tprotected SchemaBuilder.StringBldr<R> self();\n}", "des": "Builds an Avro string type with optional properties. Set properties with SchemaBuilder.PropBuilder.prop(String, String), and finalize with endString()"}
{"index": 5483, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.TypeBuilder<R> {\n\t// A shortcut for building a union of a type and null.\n\tSchemaBuilder.BaseTypeBuilder<R> nullable();\n\t// Build an Avro union schema type.\n\tSchemaBuilder.BaseTypeBuilder<SchemaBuilder.UnionAccumulator<R>> unionOf();\n}", "des": "A Builder for creating any Avro schema type."}
{"index": 5484, "repo": "avro-1.11.2", "code": "Class SchemaBuilder.UnionAccumulator<R> {\n\t// Add an additional type to this union\n\tSchemaBuilder.BaseTypeBuilder<SchemaBuilder.UnionAccumulator<R>> and();\n\t// Complete this union\n\tR endUnion();\n}", "des": "Accumulates all of the types in a union. Add an additional type with and(). Complete the union with endUnion()"}
{"index": 5485, "repo": "avro-1.11.2", "code": "Enum SchemaCompatibility.SchemaCompatibilityType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SchemaCompatibility.SchemaCompatibilityType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SchemaCompatibility.SchemaCompatibilityType[] values();\n}", "des": "Identifies the type of a schema compatibility result."}
{"index": 5486, "repo": "avro-1.11.2", "code": "Class SchemaStore.Cache {\n\t// Adds a schema to this cache that can be retrieved using its AVRO-CRC-64 fingerprint.\n\tvoid addSchema(Schema schema);\n\t// Retrieves a fingerprint by its AVRO-CRC-64 fingerprint.\n\tSchema findByFingerprint(long fingerprint);\n}", "des": "A map-based cache of schemas by AVRO-CRC-64 fingerprint."}
{"index": 5487, "repo": "avro-1.11.2", "code": "Class SeekableByteArrayInput {\n\t// Return the length of the file.\n\tlong length();\n\t// Set the position for the next read().\n\tvoid seek(long p);\n\t// Return the position of the next read().\n\tlong tell();\n}", "des": "A SeekableInput backed with data in a byte array."}
{"index": 5488, "repo": "avro-1.11.2", "code": "Class SeekableFileInput {\n\t// Return the length of the file.\n\tlong length();\n\t// Set the position for the next read().\n\tvoid seek(long p);\n\t// Return the position of the next read().\n\tlong tell();\n}", "des": "A FileInputStream that implements SeekableInput."}
{"index": 5489, "repo": "avro-1.11.2", "code": "Interface SeekableInput {\n\t// Return the length of the file.\n\tlong length();\n\t// Equivalent to InputStream.read(byte[],int,int).\n\tint read(byte[] b, int off, int len);\n\t// Set the position for the next read().\n\tvoid seek(long p);\n\t// Return the position of the next read().\n\tlong tell();\n}", "des": "An InputStream that supports seek and tell."}
{"index": 5490, "repo": "avro-1.11.2", "code": "Class SkipParser {\n\t// Skips the repeater at the top the stack.\n\tvoid skipRepeater();\n\t// Pushes the given symbol on to the skip and skips it.\n\tvoid skipSymbol(Symbol symToSkip);\n\t// Skips data by calling skipXyz or readXyz methods on this, until the parser stack reaches the target level.\n\tvoid skipTo(int target);\n}", "des": "A parser that capable of skipping as well read and write. This class is used by decoders who (unlink encoders) are required to implement methods to skip."}
{"index": 5491, "repo": "avro-1.11.2", "code": "Interface SkipParser.SkipHandler {\n\t// Skips the action at the top of the stack.\n\tvoid skipAction();\n\t// Skips the symbol at the top of the stack.\n\tvoid skipTopSymbol();\n}", "des": "The clients implement this interface to skip symbols and actions."}
{"index": 5492, "repo": "avro-1.11.2", "code": "Class SnappyCodec {\n\t// Compresses the input data\n\tByteBuffer compress(ByteBuffer in);\n\t// Decompress the data\n\tByteBuffer decompress(ByteBuffer in);\n\t// Codecs must implement an equals() method.\n\tboolean equals(Object obj);\n\t// Name of the codec; written to the file's metadata.\n\tString getName();\n}", "des": "Implements Snappy compression and decompression."}
{"index": 5493, "repo": "avro-1.11.2", "code": "Class SpecificExceptionBase {\n\tboolean equals(Object that);\n\t// Return the value of a field given its position in the schema.\n\tabstract Object get(int field);\n\t// The schema of this instance.\n\tabstract Schema getSchema();\n\tSpecificData getSpecificData();\n\t// Set the value of a field given its position in the schema.\n\tabstract void put(int field, Object value);\n\tabstract void readExternal(ObjectInput in);\n\tabstract void writeExternal(ObjectOutput out);\n}", "des": "Base class for specific exceptions."}
{"index": 5494, "repo": "avro-1.11.2", "code": "Class SpecificFixed {\n\t// Return the data.\n\tbyte[] bytes();\n\tvoid bytes(byte[] bytes);\n\tint compareTo(SpecificFixed that);\n\tboolean equals(Object o);\n\t// The schema of this instance.\n\tabstract Schema getSchema();\n\tabstract void readExternal(ObjectInput in);\n\tabstract void writeExternal(ObjectOutput out);\n}", "des": "Base class for generated fixed-sized data classes."}
{"index": 5495, "repo": "avro-1.11.2", "code": "Class TracingAvroTypeException {\n\t// produces a user-facing exception to be thrown back out to user code\n\tAvroTypeException summarize(Schema root);\n\t// appends a path element to the trace.\n\tvoid tracePath(PathElement step);\n}", "des": "an AvroTypeException with extra fields used to trace back the path to a bad value through an object graph"}
{"index": 5496, "repo": "avro-1.11.2", "code": "Class TracingClassCastException {\n\tClassCastException getCause();\n\t// produces a user-facing exception to be thrown back out to user code\n\tClassCastException summarize(Schema root);\n\t// appends a path element to the trace.\n\tvoid tracePath(PathElement step);\n}", "des": "a ClassCastException with extra fields used to trace back the path to a bad value through an object graph"}
{"index": 5497, "repo": "avro-1.11.2", "code": "Class TracingNullPointException {\n\tNullPointerException getCause();\n\t// produces a user-facing exception to be thrown back out to user code\n\tNullPointerException summarize(Schema root);\n\t// appends a path element to the trace.\n\tvoid tracePath(PathElement step);\n}", "des": "a NullPointerException with extra fields used to trace back the path to a null value through an object graph"}
{"index": 5498, "repo": "avro-1.11.2", "code": "Class ValidatingGrammarGenerator {\n\t// Returns the non-terminal that is the start symbol for the grammar for the given schema sc.\n\tSymbol generate(Schema schema);\n\t// Returns the non-terminal that is the start symbol for the grammar for the given schema sc.\n\tSymbol generate(Schema sc, Map<org.apache.avro.io.parsing.ValidatingGrammarGenerator.LitS,Symbol> seen);\n}", "des": "The class that generates validating grammar."}
{"index": 5499, "repo": "avro-1.11.2", "code": "Class XZCodec {\n\t// Compresses the input data\n\tByteBuffer compress(ByteBuffer data);\n\t// Decompress the data\n\tByteBuffer decompress(ByteBuffer data);\n\t// Codecs must implement an equals() method.\n\tboolean equals(Object obj);\n\t// Name of the codec; written to the file's metadata.\n\tString getName();\n}", "des": "Implements xz compression and decompression."}
{"index": 5500, "repo": "curator-client-5.5.0", "code": "Class AdvancedTracerDriver {\n\t// Add to a named counter\n\tabstract void addEvent(EventTrace trace);\n\t// Record the given trace event\n\tabstract void addTrace(OperationTrace trace);\n}", "des": "Expose more metrics for the operations and events"}
{"index": 5501, "repo": "curator-client-5.5.0", "code": "Class CloseableExecutorService {\n\t// Closes any tasks currently in progress\n\tvoid close();\n\t// Returns true if this executor has been shut down.\n\tboolean isShutdown();\n\t// Submits a value-returning task for execution and returns a Future representing the pending results of the task.\n\t<V> Future<V> submit(Callable<V> task);\n\t// Submits a Runnable task for execution and returns a Future representing that task.\n\tFuture<?> submit(Runnable task);\n}", "des": "Decoration on an ExecutorService that tracks created futures and provides a method to close futures created via this class"}
{"index": 5502, "repo": "curator-client-5.5.0", "code": "Class CloseableScheduledExecutorService {\n\t// Creates and executes a one-shot action that becomes enabled after the given delay.\n\tFuture<?> schedule(Runnable task, long delay, TimeUnit unit);\n\t// Creates and executes a periodic action that becomes enabled first after the given initial delay, and subsequently with the given delay between the termination of one execution and the commencement of the next.\n\tFuture<?> scheduleWithFixedDelay(Runnable task, long initialDelay, long delay, TimeUnit unit);\n}", "des": "Decoration on an ScheduledExecutorService that tracks created futures and provides a method to close futures created via this class"}
{"index": 5503, "repo": "curator-client-5.5.0", "code": "Class DefaultTracerDriver {\n\t// Add to a named counter\n\tvoid addCount(String name, int increment);\n\t// Record the given trace event\n\tvoid addTrace(String name, long time, TimeUnit unit);\n}", "des": "Default tracer driver"}
{"index": 5504, "repo": "curator-client-5.5.0", "code": "Class ExceptionAccumulator {\n\t// Add an exception into the accumulated exceptions.\n\tvoid add(Throwable e);\n\t// If there is an accumulated exception, throw it\n\tvoid propagate();\n}", "des": "Utility to accumulate multiple potential exceptions into one that is thrown at the end"}
{"index": 5505, "repo": "curator-client-5.5.0", "code": "Class PathUtils {\n\t// Validate the provided znode path string\n\tstatic String validatePath(String path);\n\t// validate the provided znode path string\n\tstatic void validatePath(String path, boolean isSequential);\n}", "des": "This class is copied from Apache ZooKeeper. The original class is not exported by ZooKeeper bundle and thus it can't be used in OSGi. See issue: https://issues.apache.org/jira/browse/ZOOKEEPER-1627 A temporary workaround till the issue is resolved is to keep a copy of this class locally."}
{"index": 5506, "repo": "curator-client-5.5.0", "code": "Interface RetryPolicy {\n\t// Called when an operation has failed for some reason.\n\tboolean allowRetry(int retryCount, long elapsedTimeMs, RetrySleeper sleeper);\n\t// Called when an operation has failed with a specific exception.\n\tdefault boolean allowRetry(Throwable exception);\n}", "des": "Abstracts the policy to use when retrying connections"}
{"index": 5507, "repo": "curator-client-5.5.0", "code": "Class SessionFailedRetryPolicy {\n\t// Called when an operation has failed for some reason.\n\tboolean allowRetry(int retryCount, long elapsedTimeMs, RetrySleeper sleeper);\n\t// Called when an operation has failed with a specific exception.\n\tboolean allowRetry(Throwable exception);\n}", "des": "RetryPolicy implementation that failed on session expired."}
{"index": 5508, "repo": "curator-client-5.5.0", "code": "Class ThreadLocalRetryLoop {\n\t// Call to get the current retry loop.\n\tRetryLoop getRetryLoop(Supplier<RetryLoop> newRetryLoopSupplier);\n\t// Must be called to release the retry loop.\n\tvoid release();\n}", "des": ""}
{"index": 5509, "repo": "curator-client-5.5.0", "code": "Interface TracerDriver {\n\t// Add to a named counter\n\tvoid addCount(String name, int increment);\n\t// Record the given trace event\n\tvoid addTrace(String name, long time, TimeUnit unit);\n}", "des": "Mechanism for timing methods and recording counters"}
{"index": 5510, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Class AbstractInputFormat.AbstractRecordReader<K,V> {\n\tvoid close();\n\tlong getPos();\n\tfloat getProgress();\n\t// Initialize a scanner over the given input split using this task attempt configuration.\n\tvoid initialize(org.apache.hadoop.mapred.InputSplit inSplit, org.apache.hadoop.mapred.JobConf job);\n\t// Extracts Iterators settings from the context to be used by RecordReader.\n\tprotected abstract List<IteratorSetting> jobIterators(org.apache.hadoop.mapred.JobConf job, String tableName);\n}", "des": "An abstract base class to be used to create RecordReader instances that convert from Accumulo Key/Value pairs to the user's K/V types. Subclasses must implement RecordReader.next(Object, Object) to update key and value, and also to update the following variables: Key currentKey (used for progress reporting) int numKeysRead (used for progress reporting)"}
{"index": 5511, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Enum ConfiguratorBase.ConnectorInfo {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfiguratorBase.ConnectorInfo valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfiguratorBase.ConnectorInfo[] values();\n}", "des": "Specifies that connection info was configured"}
{"index": 5512, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Enum ConfiguratorBase.GeneralOpts {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConfiguratorBase.GeneralOpts valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConfiguratorBase.GeneralOpts[] values();\n}", "des": "Configuration keys for general configuration options."}
{"index": 5513, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Enum FileOutputConfigurator.Opts {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileOutputConfigurator.Opts valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileOutputConfigurator.Opts[] values();\n}", "des": "Configuration keys for AccumuloConfiguration."}
{"index": 5514, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Enum InputConfigurator.Features {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic InputConfigurator.Features valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic InputConfigurator.Features[] values();\n}", "des": "Configuration keys for various features."}
{"index": 5515, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Enum InputConfigurator.ScanOpts {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic InputConfigurator.ScanOpts valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic InputConfigurator.ScanOpts[] values();\n}", "des": "Configuration keys for Scanner."}
{"index": 5516, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Enum OutputConfigurator.Features {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OutputConfigurator.Features valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OutputConfigurator.Features[] values();\n}", "des": "Configuration keys for various features."}
{"index": 5517, "repo": "accumulo-client-mapreduce-2.0.0-alpha-1", "code": "Enum OutputConfigurator.WriteOpts {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic OutputConfigurator.WriteOpts valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic OutputConfigurator.WriteOpts[] values();\n}", "des": "Configuration keys for BatchWriter."}
{"index": 5518, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum AccessType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AccessType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AccessType[] values();\n}", "des": "Access types for a queue or an application."}
{"index": 5519, "repo": "hadoop-yarn-common-3.3.6", "code": "Class AddClusterLabelOp {\n\tList<org.apache.hadoop.yarn.api.records.NodeLabel> getLabels();\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, CommonNodeLabelsManager mgr);\n\tAddClusterLabelOp setLabels(List<org.apache.hadoop.yarn.api.records.NodeLabel> nodeLabels);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, CommonNodeLabelsManager mgr);\n}", "des": "Add label operation for file system."}
{"index": 5520, "repo": "hadoop-yarn-common-3.3.6", "code": "Class AddNodeToAttributeLogOp {\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, NodeAttributesManager mgr);\n\tAddNodeToAttributeLogOp setAttributes(List<org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes> attributesList);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, NodeAttributesManager mgr);\n}", "des": "File system Add Node to attribute mapping."}
{"index": 5521, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum AttributeExpressionOperation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AttributeExpressionOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AttributeExpressionOperation[] values();\n}", "des": "Operations which are allowed in Node Attributes Expression."}
{"index": 5522, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface AttributeValue {\n\t// compare the value against the other based on the AttributeExpressionOperation.\n\tboolean compareForOperation(AttributeValue other, AttributeExpressionOperation op);\n\tString getValue();\n\t// validate the value based on the type and initialize for further compare operations.\n\tvoid validateAndInitializeValue(String value);\n}", "des": "Interface to capture operations on AttributeValue."}
{"index": 5523, "repo": "hadoop-yarn-common-3.3.6", "code": "Class AutoRefreshNoHARMFailoverProxyProvider<T> {\n\torg.apache.hadoop.io.retry.FailoverProxyProvider.ProxyInfo<T> getProxy();\n\tprotected T getProxyInternal();\n\t// Initialize internal data structures, invoked right after instantiation.\n\tvoid init(org.apache.hadoop.conf.Configuration configuration, RMProxy<T> rmProxy, Class<T> protocol);\n\t// Stop the current proxy when performFailover.\n\tvoid performFailover(T currentProxy);\n}", "des": "A subclass of RMFailoverProxyProvider which tries to resolve the proxy DNS in the event of failover. This provider doesn't support HA or Federation."}
{"index": 5524, "repo": "hadoop-yarn-common-3.3.6", "code": "Class BoundedAppender {\n\t// Append a CharSequence considering limit, truncating from the head of csq or messages when necessary.\n\tBoundedAppender append(CharSequence csq);\n\tint getLimit();\n\t// Get current length of messages considering truncates without header and ellipses.\n\tint length();\n}", "des": "A CharSequence appender that considers its limit as upper bound."}
{"index": 5525, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum ContainerLogAggregationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerLogAggregationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerLogAggregationType[] values();\n}", "des": "Enumeration of various aggregation type of a container log."}
{"index": 5526, "repo": "hadoop-yarn-common-3.3.6", "code": "Class ContainerLogAppender {\n\tvoid activateOptions();\n\tvoid append(org.apache.log4j.spi.LoggingEvent event);\n\tvoid close();\n\tvoid flush();\n\t// Getter/Setter methods for log4j.\n\tString getContainerLogDir();\n\tString getContainerLogFile();\n\tlong getTotalLogFileSize();\n\tvoid setContainerLogDir(String containerLogDir);\n\tvoid setContainerLogFile(String containerLogFile);\n\t// Setter so that log4j can configure it from the configuration(log4j.properties).\n\tvoid setTotalLogFileSize(long logSize);\n}", "des": "A simple log4j-appender for container's logs."}
{"index": 5527, "repo": "hadoop-yarn-common-3.3.6", "code": "Class DefaultNoHARMFailoverProxyProvider<T> {\n\t// Close the current proxy.\n\tvoid close();\n\tClass<T> getInterface();\n\torg.apache.hadoop.io.retry.FailoverProxyProvider.ProxyInfo<T> getProxy();\n\t// Initialize internal data structures, invoked right after instantiation.\n\tvoid init(org.apache.hadoop.conf.Configuration conf, RMProxy<T> proxy, Class<T> protocol);\n\t// PerformFailover does nothing in this class.\n\tvoid performFailover(T currentProxy);\n}", "des": "An implementation of RMFailoverProxyProvider which does nothing in the event of failover, and always returns the same proxy object. This is the default non-HA RM Failover proxy provider. It is used to replace DefaultFailoverProxyProvider which was used as Yarn default non-HA."}
{"index": 5528, "repo": "hadoop-yarn-common-3.3.6", "code": "Class FSStoreOpHandler {\n\t// Will return StoreOp instance basead on opCode and StoreType.\n\tstatic FSNodeStoreLogOp get(int opCode, FSStoreOpHandler.StoreType storeType);\n\t// Get mirror operation of store Type.\n\tstatic FSNodeStoreLogOp getMirrorOp(FSStoreOpHandler.StoreType storeType);\n}", "des": "File system store op handler."}
{"index": 5529, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum FSStoreOpHandler.StoreType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FSStoreOpHandler.StoreType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FSStoreOpHandler.StoreType[] values();\n}", "des": "Store Type enum to hold label and attribute."}
{"index": 5530, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletImpl.EOpt {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletImpl.EOpt valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletImpl.EOpt[] values();\n}", "des": "Element options. (whether it needs end tag, is inline etc.)"}
{"index": 5531, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletImpl.EOpt {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletImpl.EOpt valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletImpl.EOpt[] values();\n}", "des": "Element options. (whether it needs end tag, is inline etc.)"}
{"index": 5532, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._FontSize {\n\t// Add a SMALL (small print) element\n\tHamletSpec.SMALL small();\n\t// Add a complete small (small print) element.\n\tHamletSpec._FontSize small(String cdata);\n\t// Add a complete small (small print) element.\n\tHamletSpec._FontSize small(String selector, String cdata);\n}", "des": "Part of %pre.exclusion"}
{"index": 5533, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._FontSize {\n\t// Add a SMALL (small print) element\n\tHamletSpec.SMALL small();\n\t// Add a complete small (small print) element.\n\tHamletSpec._FontSize small(String cdata);\n\t// Add a complete small (small print) element.\n\tHamletSpec._FontSize small(String selector, String cdata);\n}", "des": "Part of %pre.exclusion"}
{"index": 5534, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._ImgObject {\n\t// Add a IMG (image) element.\n\tHamletSpec.IMG img();\n\t// Add a IMG (image) element.\n\tHamletSpec._ImgObject img(String src);\n}", "des": "Part of %pre.exclusion"}
{"index": 5535, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._ImgObject {\n\t// Add a IMG (image) element.\n\tHamletSpec.IMG img();\n\t// Add a IMG (image) element.\n\tHamletSpec._ImgObject img(String src);\n}", "des": "Part of %pre.exclusion"}
{"index": 5536, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._InsDel {\n\t// Add a DEL (delete) element.\n\tHamletSpec.DEL del();\n\t// Add a complete DEL element.\n\tHamletSpec._InsDel del(String cdata);\n\t// Add an INS (insert) element.\n\tHamletSpec.INS ins();\n\t// Add a complete INS element.\n\tHamletSpec._InsDel ins(String cdata);\n}", "des": "INS and DEL are unusual for HTML \"in that they may serve as either block-level or inline elements (but not both)\". cf. http://www.w3.org/TR/html4/struct/text.html#h-9.4 cf. http://www.w3.org/TR/html5/edits.html#edits"}
{"index": 5537, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._InsDel {\n\t// Add a DEL (delete) element.\n\tHamletSpec.DEL del();\n\t// Add a complete DEL element.\n\tHamletSpec._InsDel del(String cdata);\n\t// Add an INS (insert) element.\n\tHamletSpec.INS ins();\n\t// Add a complete INS element.\n\tHamletSpec._InsDel ins(String cdata);\n}", "des": "INS and DEL are unusual for HTML \"in that they may serve as either block-level or inline elements (but not both)\". cf. http://www.w3.org/TR/html4/struct/text.html#h-9.4 cf. http://www.w3.org/TR/html5/edits.html#edits"}
{"index": 5538, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._SubSup {\n\t// Add a SUB (subscript) element.\n\tHamletSpec.SUB sub();\n\t// Add a complete SUB (subscript) element.\n\tHamletSpec._SubSup sub(String cdata);\n\t// Add a complete SUB (subscript) element.\n\tHamletSpec._SubSup sub(String selector, String cdata);\n\t// Add a SUP (superscript) element.\n\tHamletSpec.SUP sup();\n\t// Add a SUP (superscript) element.\n\tHamletSpec._SubSup sup(String cdata);\n\t// Add a SUP (superscript) element.\n\tHamletSpec._SubSup sup(String selector, String cdata);\n}", "des": "Part of %pre.exclusion"}
{"index": 5539, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec._SubSup {\n\t// Add a SUB (subscript) element.\n\tHamletSpec.SUB sub();\n\t// Add a complete SUB (subscript) element.\n\tHamletSpec._SubSup sub(String cdata);\n\t// Add a complete SUB (subscript) element.\n\tHamletSpec._SubSup sub(String selector, String cdata);\n\t// Add a SUP (superscript) element.\n\tHamletSpec.SUP sup();\n\t// Add a SUP (superscript) element.\n\tHamletSpec._SubSup sup(String cdata);\n\t// Add a SUP (superscript) element.\n\tHamletSpec._SubSup sup(String selector, String cdata);\n}", "des": "Part of %pre.exclusion"}
{"index": 5540, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.ButtonType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.ButtonType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.ButtonType[] values();\n}", "des": "Values for button types"}
{"index": 5541, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.ButtonType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.ButtonType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.ButtonType[] values();\n}", "des": "Values for button types"}
{"index": 5542, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.CoreAttrs {\n\t// space-separated list of classes\n\tHamletSpec.CoreAttrs $class(String cls);\n\t// document-wide unique id\n\tHamletSpec.CoreAttrs $id(String id);\n\t// associated style info\n\tHamletSpec.CoreAttrs $style(String style);\n\t// advisory title\n\tHamletSpec.CoreAttrs $title(String title);\n}", "des": "%coreattrs"}
{"index": 5543, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.CoreAttrs {\n\t// space-separated list of classes\n\tHamletSpec.CoreAttrs $class(String cls);\n\t// document-wide unique id\n\tHamletSpec.CoreAttrs $id(String id);\n\t// associated style info\n\tHamletSpec.CoreAttrs $style(String style);\n\t// advisory title\n\tHamletSpec.CoreAttrs $title(String title);\n}", "des": "%coreattrs"}
{"index": 5544, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Dir {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Dir valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Dir[] values();\n}", "des": "Values for the %18n dir attribute (case-insensitive)"}
{"index": 5545, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Dir {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Dir valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Dir[] values();\n}", "des": "Values for the %18n dir attribute (case-insensitive)"}
{"index": 5546, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.I18nAttrs {\n\t// direction for weak/neutral text\n\tHamletSpec.I18nAttrs $dir(HamletSpec.Dir dir);\n\t// language code\n\tHamletSpec.I18nAttrs $lang(String lang);\n}", "des": "%i18n"}
{"index": 5547, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.I18nAttrs {\n\t// direction for weak/neutral text\n\tHamletSpec.I18nAttrs $dir(HamletSpec.Dir dir);\n\t// language code\n\tHamletSpec.I18nAttrs $lang(String lang);\n}", "des": "%i18n"}
{"index": 5548, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.InputType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.InputType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.InputType[] values();\n}", "des": "%InputType (case-insensitive)"}
{"index": 5549, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.InputType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.InputType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.InputType[] values();\n}", "des": "%InputType (case-insensitive)"}
{"index": 5550, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.LinkType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.LinkType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.LinkType[] values();\n}", "des": "%LinkTypes (case-insensitive)"}
{"index": 5551, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.LinkType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.LinkType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.LinkType[] values();\n}", "des": "%LinkTypes (case-insensitive)"}
{"index": 5552, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.Listing {\n\t// Add a OL (ordered list) element.\n\tHamletSpec.OL ol();\n\t// Add a OL (ordered list) element.\n\tHamletSpec.OL ol(String selector);\n\t// Add a UL (unordered list) element.\n\tHamletSpec.UL ul();\n\t// Add a UL (unordered list) element.\n\tHamletSpec.UL ul(String selector);\n}", "des": "%list"}
{"index": 5553, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.Listing {\n\t// Add a OL (ordered list) element.\n\tHamletSpec.OL ol();\n\t// Add a OL (ordered list) element.\n\tHamletSpec.OL ol(String selector);\n\t// Add a UL (unordered list) element.\n\tHamletSpec.UL ul();\n\t// Add a UL (unordered list) element.\n\tHamletSpec.UL ul(String selector);\n}", "des": "%list"}
{"index": 5554, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Media {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Media valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Media[] values();\n}", "des": "%MediaDesc (case-sensitive)"}
{"index": 5555, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Media {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Media valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Media[] values();\n}", "des": "%MediaDesc (case-sensitive)"}
{"index": 5556, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Method {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Method valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Method[] values();\n}", "des": "Values for form methods (case-insensitive)"}
{"index": 5557, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Method {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Method valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Method[] values();\n}", "des": "Values for form methods (case-insensitive)"}
{"index": 5558, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.Preformatted {\n\t// Add a PRE (preformatted) element.\n\tHamletSpec.PRE pre();\n\t// Add a PRE (preformatted) element.\n\tHamletSpec.PRE pre(String selector);\n}", "des": "% preformatted"}
{"index": 5559, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface HamletSpec.Preformatted {\n\t// Add a PRE (preformatted) element.\n\tHamletSpec.PRE pre();\n\t// Add a PRE (preformatted) element.\n\tHamletSpec.PRE pre(String selector);\n}", "des": "% preformatted"}
{"index": 5560, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Scope {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Scope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Scope[] values();\n}", "des": "%Scope (case-insensitive)"}
{"index": 5561, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Scope {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Scope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Scope[] values();\n}", "des": "%Scope (case-insensitive)"}
{"index": 5562, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Shape {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Shape valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Shape[] values();\n}", "des": "%Shape (case-insensitive)"}
{"index": 5563, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum HamletSpec.Shape {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic HamletSpec.Shape valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic HamletSpec.Shape[] values();\n}", "des": "%Shape (case-insensitive)"}
{"index": 5564, "repo": "hadoop-yarn-common-3.3.6", "code": "Class HtmlPage {\n\t// The API to render the view\n\tvoid render();\n\t// Render the the HTML page.\n\tprotected abstract void render(Hamlet.HTML<HtmlPage.__> html);\n}", "des": "The parent class of all HTML pages. Override render(org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.HTML) to actually render the page."}
{"index": 5565, "repo": "hadoop-yarn-common-3.3.6", "code": "Class LogAggregationFileControllerFactory {\n\tLinkedList<LogAggregationFileController> getConfiguredLogAggregationFileControllerList();\n\t// Get LogAggregationFileController to read the aggregated logs for this application.\n\tLogAggregationFileController getFileControllerForRead(org.apache.hadoop.yarn.api.records.ApplicationId appId, String appOwner);\n\t// Get LogAggregationFileController to write.\n\tLogAggregationFileController getFileControllerForWrite();\n}", "des": "Use LogAggregationFileControllerFactory to get the correct LogAggregationFileController for write and read."}
{"index": 5566, "repo": "hadoop-yarn-common-3.3.6", "code": "Class MultiStateTransitionListener<OPERAND,EVENT,STATE extends Enum<STATE>> {\n\t// Add a listener to the list of listeners.\n\tvoid addListener(StateTransitionListener<OPERAND,EVENT,STATE> listener);\n\t// Post Transition Hook.\n\tvoid postTransition(OPERAND op, STATE beforeState, STATE afterState, EVENT processedEvent);\n\t// Pre Transition Hook.\n\tvoid preTransition(OPERAND op, STATE beforeState, EVENT eventToBeProcessed);\n}", "des": "A StateTransitionListener that dispatches the pre and post state transitions to multiple registered listeners. NOTE: The registered listeners are called in a for loop. Clients should know that a listener configured earlier might prevent a later listener from being called, if for instance it throws an un-caught Exception."}
{"index": 5567, "repo": "hadoop-yarn-common-3.3.6", "code": "Class NodeAttributeMirrorOp {\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, NodeAttributesManager mgr);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, NodeAttributesManager mgr);\n}", "des": "File System Node Attribute Mirror read and write operation."}
{"index": 5568, "repo": "hadoop-yarn-common-3.3.6", "code": "Class NodeLabelMirrorOp {\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, CommonNodeLabelsManager mgr);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, CommonNodeLabelsManager mgr);\n}", "des": "NodeLabel Mirror Op class."}
{"index": 5569, "repo": "hadoop-yarn-common-3.3.6", "code": "Class NodeToLabelOp {\n\tMap<org.apache.hadoop.yarn.api.records.NodeId,Set<String>> getNodeToLabels();\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, CommonNodeLabelsManager mgr);\n\tNodeToLabelOp setNodeToLabels(Map<org.apache.hadoop.yarn.api.records.NodeId,Set<String>> nodeToLabelsList);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, CommonNodeLabelsManager mgr);\n}", "des": "Node to label mapping store operation for label."}
{"index": 5570, "repo": "hadoop-yarn-common-3.3.6", "code": "Class RemoveClusterLabelOp {\n\tCollection<String> getLabels();\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, CommonNodeLabelsManager mgr);\n\tRemoveClusterLabelOp setLabels(Collection<String> nodeLabels);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, CommonNodeLabelsManager mgr);\n}", "des": "Remove label from cluster log store operation."}
{"index": 5571, "repo": "hadoop-yarn-common-3.3.6", "code": "Class RemoveNodeToAttributeLogOp {\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, NodeAttributesManager mgr);\n\tRemoveNodeToAttributeLogOp setAttributes(List<org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes> attrs);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, NodeAttributesManager mgr);\n}", "des": "File system remove node attribute from node operation."}
{"index": 5572, "repo": "hadoop-yarn-common-3.3.6", "code": "Class ReplaceNodeToAttributeLogOp {\n\tint getOpCode();\n\t// Read and populate StoreOp.\n\tvoid recover(InputStream is, NodeAttributesManager mgr);\n\tReplaceNodeToAttributeLogOp setAttributes(List<org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes> attrs);\n\t// Write operation to persistent storage.\n\tvoid write(OutputStream os, NodeAttributesManager mgr);\n}", "des": "File system replace node attribute from node operation."}
{"index": 5573, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface StateTransitionListener<OPERAND,EVENT,STATE extends Enum<STATE>> {\n\t// Post Transition Hook.\n\tvoid postTransition(OPERAND op, STATE beforeState, STATE afterState, EVENT processedEvent);\n\t// Pre Transition Hook.\n\tvoid preTransition(OPERAND op, STATE beforeState, EVENT eventToBeProcessed);\n}", "des": "A State Transition Listener. It exposes a pre and post transition hook called before and after the transition."}
{"index": 5574, "repo": "hadoop-yarn-common-3.3.6", "code": "Interface StoreOp<W,R,M> {\n\t// Read and populate StoreOp.\n\tvoid recover(R read, M mgr);\n\t// Write operation to persistent storage.\n\tvoid write(W write, M mgr);\n}", "des": "Define the interface for store activity. Used by for FileSystem based operation."}
{"index": 5575, "repo": "hadoop-yarn-common-3.3.6", "code": "Class StringAttributeValue {\n\t// compare the value against the other based on the AttributeExpressionOperation.\n\tboolean compareForOperation(AttributeValue other, AttributeExpressionOperation op);\n\tString getValue();\n\t// validate the value based on the type and initialize for further compare operations.\n\tvoid validateAndInitializeValue(String valueStr);\n}", "des": "Attribute value for String NodeAttributeType."}
{"index": 5576, "repo": "hadoop-yarn-common-3.3.6", "code": "Enum TimelineDelegationTokenOperation {\n\tString getHttpMethod();\n\tboolean requiresKerberosCredentials();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TimelineDelegationTokenOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TimelineDelegationTokenOperation[] values();\n}", "des": "DelegationToken operations."}
{"index": 5577, "repo": "hadoop-yarn-common-3.3.6", "code": "Class WebApps {\n\tstatic <T> WebApps.Builder<T> $for(String prefix);\n\t// Create a new webapp builder.\n\tstatic <T> WebApps.Builder<T> $for(String prefix, Class<T> api, T app);\n\t// Create a new webapp builder.\n\tstatic <T> WebApps.Builder<T> $for(String prefix, Class<T> api, T app, String wsPrefix);\n\tstatic <T> WebApps.Builder<T> $for(String prefix, T app);\n\tstatic <T> WebApps.Builder<T> $for(T app);\n}", "des": "Helpers to create an embedded webapp. Quick start:"}
{"index": 5578, "repo": "hadoop-yarn-common-3.3.6", "code": "Class WebServiceClient {\n\t// Create a client based on http conf.\n\tcom.sun.jersey.api.client.Client createClient();\n\tstatic void destroy();\n\tprotected com.sun.jersey.client.urlconnection.HttpURLConnectionFactory getHttpURLConnectionFactory();\n\tstatic WebServiceClient getWebServiceClient();\n\t// Construct a new WebServiceClient based on the configuration.\n\tstatic void initialize(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Utility for handling Web client."}
{"index": 5579, "repo": "lucene-analyzers-smartcn-8.11.2", "code": "Class Utility {\n\t// compare two arrays starting at the specified offsets.\n\tstatic int compareArray(char[] larray, int lstartIndex, char[] rarray, int rstartIndex);\n\t// Compare two arrays, starting at the specified offsets, but treating shortArray as a prefix to longArray.\n\tstatic int compareArrayByPrefix(char[] shortArray, int shortIndex, char[] longArray, int longIndex);\n\t// Return the internal CharType constant of a given character.\n\tstatic int getCharType(char ch);\n}", "des": "SmartChineseAnalyzer utility constants and methods"}
{"index": 5580, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class AbstractWALRoller<T extends Abortable> {\n\tvoid addWAL(WAL wal);\n\tprotected void afterWALArchive(org.apache.hadoop.fs.Path oldPath, org.apache.hadoop.fs.Path newPath);\n\tvoid close();\n\tvoid requestRollAll();\n\tvoid run();\n\tprotected abstract void scheduleFlush(String encodedRegionName, List<byte[]> families);\n\t// Wait until all wals have been rolled after calling requestRollAll().\n\tvoid waitUntilWalRollFinished();\n\t// Returns true if all WAL roll finished\n\tboolean walRollFinished();\n}", "des": "Runs periodically to determine if the WAL should be rolled."}
{"index": 5581, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ActivePolicyEnforcement {\n\t// Returns an unmodifiable version of the active SpaceViolationPolicyEnforcements.\n\tMap<TableName,SpaceViolationPolicyEnforcement> getPolicies();\n\t// Returns the proper SpaceViolationPolicyEnforcement implementation for the given table.\n\tSpaceViolationPolicyEnforcement getPolicyEnforcement(Region r);\n\t// Returns the proper SpaceViolationPolicyEnforcement implementation for the given table.\n\tSpaceViolationPolicyEnforcement getPolicyEnforcement(TableName tableName);\n}", "des": "A class to ease dealing with tables that have and do not have violation policies being enforced. This class is immutable, expect for locallyCachedPolicies. The locallyCachedPolicies are mutable given the current activePolicies and snapshots. It is expected that when a new instance of this class is instantiated, we also want to invalidate those previously cached policies (as they may now be invalidate if we received new quota usage information)."}
{"index": 5582, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class AssignRegionHandler {\n\tstatic AssignRegionHandler create(HRegionServer server, RegionInfo regionInfo, long openProcId, TableDescriptor tableDesc, long masterSystemTime);\n\t// Event exception handler, may be overridden\n\tprotected void handleException(Throwable t);\n\t// This method is the main processing loop to be implemented by the various subclasses.\n\tvoid process();\n}", "des": "Handles opening of a region on a region server."}
{"index": 5583, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class AverageIntervalRateLimiter {\n\tlong getNextRefillTime();\n\t// Time in milliseconds to wait for before requesting to consume 'amount' resource.\n\tlong getWaitInterval(long limit, long available, long amount);\n\t// Refill the available units w.r.t the elapsed time.\n\tlong refill(long limit);\n\tvoid setNextRefillTime(long nextRefillTime);\n}", "des": "This limiter will refill resources at every TimeUnit/resources interval. For example: For a limiter configured with 10resources/second, then 1 resource will be refilled after every 100ms (1sec/10resources)"}
{"index": 5584, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BaseEnvironment<C extends Coprocessor> {\n\tClassLoader getClassLoader();\n\torg.apache.hadoop.conf.Configuration getConfiguration();\n\t// Returns the HBase release\n\tString getHBaseVersion();\n\tC getInstance();\n\tint getLoadSequence();\n\tint getPriority();\n\t// Returns the coprocessor environment version\n\tint getVersion();\n\t// Clean up the environment\n\tvoid shutdown();\n\t// Initialize the environment\n\tvoid startup();\n}", "des": "Encapsulation of the environment of each coprocessor"}
{"index": 5585, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BaseFileCleanerDelegate {\n\t// Determines which of the given files are safe to delete\n\tIterable<org.apache.hadoop.fs.FileStatus> getDeletableFiles(Iterable<org.apache.hadoop.fs.FileStatus> files);\n\t// this method is used to pass some instance into subclass\n\tvoid init(Map<String,Object> params);\n\t// Should the master delete the file or keep it?\n\tprotected abstract boolean isFileDeletable(org.apache.hadoop.fs.FileStatus fStat);\n}", "des": "Base class for file cleaners which allows subclasses to implement a simple isFileDeletable method (which used to be the FileCleanerDelegate contract)."}
{"index": 5586, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BlockCacheKey {\n\tboolean equals(Object o);\n\tBlockType getBlockType();\n\t// Returns The hfileName portion of this cache key\n\tString getHfileName();\n\tlong getOffset();\n\t// Strings have two bytes per character due to default Java Unicode encoding (hence length times 2).\n\tlong heapSize();\n\tboolean isPrimary();\n\tvoid setBlockType(BlockType blockType);\n}", "des": "Cache Key for use with implementations of BlockCache"}
{"index": 5587, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BlockCacheUtil.CachedBlocksByFile {\n\tAgeSnapshot getAgeInCacheSnapshot();\n\tNavigableMap<String,NavigableSet<CachedBlock>> getCachedBlockStatsByFile();\n\t// Returns count of blocks in the cache\n\tint getCount();\n\tint getDataCount();\n\t// Returns Size of data.\n\tlong getDataSize();\n\t// Returns size of blocks in the cache\n\tlong getSize();\n\tboolean isFull();\n\t// Returns True if full....\n\tboolean update(CachedBlock cb);\n}", "des": "Use one of these to keep a running account of cached blocks by file. Throw it away when done. This is different than metrics in that it is stats on current state of a cache. See getLoadedCachedBlocksByFile"}
{"index": 5588, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface BlockCompressedSizePredicator {\n\t// Decides if the block should be finished based on the comparison of its uncompressed size against an adjusted size based on a predicated compression factor.\n\tboolean shouldFinishBlock(int uncompressed);\n\t// Updates the predicator with both compressed and uncompressed sizes of latest block written.\n\tvoid updateLatestBlockSizes(HFileContext context, int uncompressed, int compressed);\n}", "des": "Allows for defining different compression rate predicates on its implementing classes. Useful when compression is in place, and we want to define block size based on the compressed size, rather than the default behaviour that considers the uncompressed size only. Since we don't actually know the compressed size until we actual apply compression in the block byte buffer, we need to \"predicate\" this compression rate and minimize compression execution to avoid excessive resources usage. Different approaches for predicating the compressed block size can be defined by implementing classes. The updateLatestBlockSizes allows for updating uncompressed and compressed size values, and is called during block finishing (when we finally apply compression on the block data). Final block size predicate logic is implemented in shouldFinishBlock, which is called by the block writer once uncompressed size has reached the configured BLOCK size, and additional checks should be applied to decide if the block can be finished."}
{"index": 5589, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BloomContext {\n\t// Adds the last bloom key to the HFile Writer as part of StorefileWriter close.\n\tabstract void addLastBloomKey(HFile.Writer writer);\n\tCell getLastCell();\n\t// Returns true if the cell is a new key as per the bloom type\n\tprotected abstract boolean isNewKey(Cell cell);\n\t// Bloom information from the cell is retrieved\n\tvoid writeBloom(Cell cell);\n}", "des": "The bloom context that is used by the StorefileWriter to add the bloom details per cell"}
{"index": 5590, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface BloomFilter {\n\t// Check if the specified key is contained in the bloom filter.\n\tboolean contains(byte[] buf, int offset, int length, ByteBuff bloom);\n\t// Check if the specified key is contained in the bloom filter.\n\tboolean contains(Cell keyCell, ByteBuff bloom, BloomType type);\n\tboolean supportsAutoLoading();\n}", "des": "Implements a Bloom filter, as defined by Bloom in 1970."}
{"index": 5591, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface BloomFilterBase {\n\t// Returns Size of the bloom, in bytes\n\tlong getByteSize();\n\t// Returns The number of keys added to the bloom\n\tlong getKeyCount();\n\t// Returns The max number of keys that can be inserted to maintain the desired error rate\n\tlong getMaxKeys();\n}", "des": "Common methods Bloom filter methods required at read and write time."}
{"index": 5592, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface BloomFilterWriter {\n\t// Compact the Bloom filter before writing metadata & data to disk.\n\tvoid compactBloom();\n\t// Get a writable interface into bloom filter data (the actual Bloom bits).\n\torg.apache.hadoop.io.Writable getDataWriter();\n\t// Get a writable interface into bloom filter meta data.\n\torg.apache.hadoop.io.Writable getMetaWriter();\n\t// Returns the previous cell written by this writer\n\tCell getPrevCell();\n}", "des": "Specifies methods needed to add elements to a Bloom filter and serialize the resulting Bloom filter as a sequence of bytes."}
{"index": 5593, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BooleanStateStore {\n\t// Returns true if the flag is on, otherwise false\n\tboolean get();\n\tprotected abstract boolean parseFrom(byte[] bytes);\n\t// Set the flag on/off.\n\tboolean set(boolean on);\n\tprotected abstract byte[] toByteArray(boolean on);\n}", "des": "Store a boolean state."}
{"index": 5594, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BoundedRecoveredHFilesOutputSink {\n\tList<org.apache.hadoop.fs.Path> close();\n\t// Returns number of regions we've recovered\n\tint getNumberOfRecoveredRegions();\n\t// Returns a map from encoded region ID to the number of edits written out for that region.\n\tMap<String,Long> getOutputCounts();\n\t// Set status message in MonitoredTask instance that is set in this OutputSink\n\tprotected void updateStatusWithMsg(String msg);\n}", "des": "A WALSplitter sink that outputs HFiles. Runs with a bounded number of HFile writers at any one time rather than let the count run up."}
{"index": 5595, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface BulkLoadObserver {\n\t// Called as part of SecureBulkLoadEndpoint.cleanupBulkLoad() RPC call.\n\tdefault void preCleanupBulkLoad(ObserverContext<RegionCoprocessorEnvironment> ctx);\n\t// Called as part of SecureBulkLoadEndpoint.prepareBulkLoad() RPC call.\n\tdefault void prePrepareBulkLoad(ObserverContext<RegionCoprocessorEnvironment> ctx);\n}", "des": "Coprocessors implement this interface to observe and mediate bulk load operations. Exception Handling For all functions, exception handling is done as follows: Exceptions of type IOException are reported back to client. For any other kind of exception: If the configuration CoprocessorHost.ABORT_ON_ERROR_KEY is set to true, then the server aborts. Otherwise, coprocessor is removed from the server and DoNotRetryIOException is returned to the client."}
{"index": 5596, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class BusyRegionSplitPolicy {\n\t// Upon construction, this method will be called with the region to be governed.\n\tprotected void configureForRegion(HRegion region);\n\t// Returns true if the specified region should be split.\n\tprotected boolean shouldSplit();\n}", "des": "This class represents a split policy which makes the split decision based on how busy a region is. The metric that is used here is the fraction of total write requests that are blocked due to high memstore utilization. This fractional rate is calculated over a running window of \"hbase.busy.policy.aggWindow\" milliseconds. The rate is a time-weighted aggregated average of the rate in the current window and the true average rate in the previous window."}
{"index": 5597, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CachedEntryQueue {\n\t// Attempt to add the specified entry to this queue.\n\tvoid add(Map.Entry<BlockCacheKey,org.apache.hadoop.hbase.io.hfile.bucket.BucketEntry> entry);\n\t// Returns The next element in this queue, or null if the queue is empty.\n\tMap.Entry<BlockCacheKey,org.apache.hadoop.hbase.io.hfile.bucket.BucketEntry> poll();\n\t// Returns The last element in this queue, or null if the queue is empty.\n\tMap.Entry<BlockCacheKey,org.apache.hadoop.hbase.io.hfile.bucket.BucketEntry> pollLast();\n}", "des": "A memory-bound queue that will grow until an element brings total size larger than maxSize. From then on, only entries that are sorted larger than the smallest current entry will be inserted/replaced."}
{"index": 5598, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CanaryTool {\n\t// Run Canary in Region mode.\n\tint checkRegions(String[] targets);\n\t// Runs Canary in Region server mode.\n\tint checkRegionServers(String[] targets);\n\t// Runs Canary in Zookeeper mode.\n\tint checkZooKeeper();\n\torg.apache.hadoop.conf.Configuration getConf();\n\tMap<String,String> getReadFailures();\n\tMap<String,String> getWriteFailures();\n\tstatic void main(String[] args);\n\tint run(String[] args);\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "HBase Canary Tool for \"canary monitoring\" of a running HBase cluster. There are three modes: region mode (Default): For each region, try to get one row per column family outputting information on failure (ERROR) or else the latency. regionserver mode: For each regionserver try to get one row from one table selected randomly outputting information on failure (ERROR) or else the latency. zookeeper mode: for each zookeeper instance, selects a znode outputting information on failure (ERROR) or else the latency."}
{"index": 5599, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CatalogJanitor {\n\tprotected void chore();\n\tboolean getEnabled();\n\t// Returns Returns last published Report that comes of last successful scan of hbase:meta.\n\tCatalogJanitorReport getLastReport();\n\tprotected boolean initialChore();\n\t// For testing against a cluster.\n\tstatic void main(String[] args);\n\t// Run janitorial scan of catalog hbase:meta table looking for garbage to collect.\n\tint scan();\n\t// Scan hbase:meta.\n\tprotected CatalogJanitorReport scanForReport();\n\tboolean setEnabled(boolean enabled);\n}", "des": "A janitor for the catalog tables. Scans the hbase:meta catalog table on a period. Makes a lastReport on state of hbase:meta. Looks for unused regions to garbage collect. Scan of hbase:meta runs if we are NOT in maintenance mode, if we are NOT shutting down, AND if the assignmentmanager is loaded. Playing it safe, we will garbage collect no-longer needed region references only if there are no regions-in-transition (RIT)."}
{"index": 5600, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ChainWALEmptyEntryFilter {\n\t// Applies the filter, possibly returning a different Entry instance.\n\tWAL.Entry filter(WAL.Entry entry);\n\t// To allow the empty entries to get filtered, we want to set this optional flag to decide if we want to filter the entries which have no cells or all cells got filtered though WALCellFilter.\n\tvoid setFilterEmptyEntry(boolean filterEmptyEntry);\n}", "des": "A ChainWALEntryFilter for providing more flexible options"}
{"index": 5601, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ChangedReadersObserver {\n\t// Returns the read point of the current scan\n\tlong getReadPoint();\n\t// Notify observers.\n\tvoid updateReaders(List<HStoreFile> sfs, List<KeyValueScanner> memStoreScanners);\n}", "des": "If set of MapFile.Readers in Store change, implementors are notified."}
{"index": 5602, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class Chunk {\n\t// Try to allocate size bytes from the chunk.\n\tint alloc(int size);\n\t// Actually claim the memory for this chunk.\n\tvoid init();\n}", "des": "A chunk of memory out of which allocations are sliced."}
{"index": 5603, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum ChunkCreator.ChunkType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ChunkCreator.ChunkType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ChunkCreator.ChunkType[] values();\n}", "des": "Types of chunks, based on their sizes"}
{"index": 5604, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ClientZKSyncer {\n\t// Returns the zk path(s) to watch\n\tprotected abstract Set<String> getPathsToWatch();\n\tvoid nodeCreated(String path);\n\tvoid nodeDataChanged(String path);\n\tvoid nodeDeleted(String path);\n\tprotected void refreshWatchingList();\n\t// Starts the syncer\n\tvoid start();\n\t// Validate whether a znode path is watched by us\n\tprotected abstract boolean validate(String path);\n}", "des": "Tracks the target znode(s) on server ZK cluster and synchronize them to client ZK cluster if changed"}
{"index": 5605, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CloseChecker {\n\t// Check periodically to see if a system stop is requested every written bytes reach size limit.\n\tboolean isSizeLimit(Store store, long bytesWritten);\n\t// Check periodically to see if a system stop is requested every time.\n\tboolean isTimeLimit(Store store, long now);\n}", "des": "Check periodically to see if a system stop is requested"}
{"index": 5606, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CloseRegionHandler {\n\tRegionInfo getRegionInfo();\n\t// Event exception handler, may be overridden\n\tprotected void handleException(Throwable t);\n\t// This method is the main processing loop to be implemented by the various subclasses.\n\tvoid process();\n}", "des": "Handles closing of a region on a region server."}
{"index": 5607, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ClusterStatusPublisher {\n\tprotected void chore();\n\tprotected void cleanup();\n\t// Create the dead server to send.\n\tprotected List<ServerName> generateDeadServersListToSend();\n\t// Get the servers which died since a given timestamp.\n\tprotected List<Pair<ServerName,Long>> getDeadServers(long since);\n}", "des": "Class to publish the cluster status to the client. This allows them to know immediately the dead region servers, hence to cut the connection they have with them, eventually stop waiting on the socket. This improves the mean time to recover, and as well allows to increase on the client the different timeouts, as the dead servers will be detected separately."}
{"index": 5608, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CollectionBackedScanner {\n\t// Close the KeyValue scanner.\n\tvoid close();\n\t// Return the next Cell in this scanner, iterating the scanner\n\tCell next();\n\t// Look at the next Cell in this scanner, but do not iterate scanner.\n\tCell peek();\n\t// Reseek the scanner at or after the specified KeyValue.\n\tboolean reseek(Cell seekCell);\n\t// Seek the scanner at or after the specified KeyValue.\n\tboolean seek(Cell seekCell);\n}", "des": "Utility scanner that wraps a sortable collection and serves as a KeyValueScanner."}
{"index": 5609, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum CompactingMemStore.IndexType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompactingMemStore.IndexType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompactingMemStore.IndexType[] values();\n}", "des": "Types of indexes (part of immutable segments) to be used after flattening, compaction, or merge are applied."}
{"index": 5610, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface CompactionLifeCycleTracker {\n\t// Called after compaction is executed by CompactSplitThread.\n\tdefault void afterExecution(Store store);\n\t// Called before compaction is executed by CompactSplitThread.\n\tdefault void beforeExecution(Store store);\n\t// Called after all the requested compactions are completed.\n\tdefault void completed();\n\t// Called if the compaction request is failed for some reason.\n\tdefault void notExecuted(Store store, String reason);\n}", "des": "Used to track compaction execution."}
{"index": 5611, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CompactionPolicy {\n\t// Returns The current compaction configuration settings.\n\tCompactionConfiguration getConf();\n\t// Inform the policy that some configuration has been change, so cached value should be updated it any.\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n\tabstract boolean shouldPerformMajorCompaction(Collection<HStoreFile> filesToCompact);\n\tabstract boolean throttleCompaction(long compactionSize);\n}", "des": "A compaction policy determines how to select files for compaction, how to compact them, and how to generate the compacted files."}
{"index": 5612, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CompactionWindow {\n\t// Compares the window to a timestamp.\n\tabstract int compareToTimestamp(long timestamp);\n\t// Exclusive upper bound\n\tabstract long endMillis();\n\t// Move to the new window of the same tier or of the next tier, which represents an earlier time span.\n\tabstract CompactionWindow nextEarlierWindow();\n\t// Inclusive lower bound\n\tabstract long startMillis();\n}", "des": "Base class for compaction window implementation."}
{"index": 5613, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CompoundBloomFilter {\n\t// Check if the specified key is contained in the bloom filter.\n\tboolean contains(byte[] key, int keyOffset, int keyLength, ByteBuff bloom);\n\t// Check if the specified key is contained in the bloom filter.\n\tboolean contains(Cell keyCell, ByteBuff bloom, BloomType type);\n\tvoid enableTestingStats();\n\tString formatTestingStats();\n\tint getNumChunks();\n\tlong getNumPositivesForTesting(int chunk);\n\tlong getNumQueriesForTesting(int chunk);\n\tboolean supportsAutoLoading();\n}", "des": "A Bloom filter implementation built on top of BloomFilterChunk, encapsulating a set of fixed-size Bloom filters written out at the time of HFile generation into the data block stream, and loaded on demand at query time. This class only provides reading capabilities."}
{"index": 5614, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ConnectionRegistryEndpoint {\n\t// Get active master address.\n\tOptional<ServerName> getActiveMaster();\n\t// Get backup masters address.\n\tList<ServerName> getBackupMasters();\n\t// Get a iterator of the available bootstrap nodes.\n\tIterator<ServerName> getBootstrapNodes();\n\t// Get cluster id.\n\tString getClusterId();\n\t// Get the location of meta regions.\n\tList<HRegionLocation> getMetaLocations();\n}", "des": "Define the necessary method for carrying ClientMetaService."}
{"index": 5615, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ConstantSizeRegionSplitPolicy {\n\t// Upon construction, this method will be called with the region to be governed.\n\tprotected void configureForRegion(HRegion region);\n\t// Returns true if region size exceed the sizeToCheck\n\tprotected boolean isExceedSize(long sizeToCheck);\n\tboolean positiveJitterRate();\n\t// Returns true if the specified region should be split.\n\tprotected boolean shouldSplit();\n}", "des": "A RegionSplitPolicy implementation which splits a region as soon as any of its store files exceeds a maximum configurable size."}
{"index": 5616, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface CoordinatedStateManager {\n\t// Method to retrieve coordination for split log manager\n\tSplitLogManagerCoordination getSplitLogManagerCoordination();\n\t// Method to retrieve coordination for split log worker\n\tSplitLogWorkerCoordination getSplitLogWorkerCoordination();\n}", "des": "Implementations of this interface will keep and return to clients implementations of classes providing API to execute coordinated operations. This interface is client-side, so it does NOT include methods to retrieve the particular interface implementations. For each coarse-grained area of operations there will be a separate interface with implementation, providing API for relevant operations requiring coordination."}
{"index": 5617, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class CoprocessorWhitelistMasterObserver {\n\tOptional<MasterObserver> getMasterObserver();\n\t// Called before a new table is created by HMaster.\n\tvoid preCreateTable(ObserverContext<MasterCoprocessorEnvironment> ctx, TableDescriptor htd, RegionInfo[] regions);\n\t// Called prior to modifying a table's properties.\n\tTableDescriptor preModifyTable(ObserverContext<MasterCoprocessorEnvironment> ctx, TableName tableName, TableDescriptor currentDesc, TableDescriptor newDesc);\n}", "des": "Master observer for restricting coprocessor assignments."}
{"index": 5618, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class DateTieredMultiFileWriter {\n\t// Append the given cell\n\tvoid append(Cell cell);\n\t// Subclasses override this method to be called at the end of a successful sequence of append; all appends are processed before this method is called.\n\tprotected void preCommitWriters();\n\tprotected Collection<StoreFileWriter> writers();\n}", "des": "class for cell sink that separates the provided cells into multiple files for date tiered compaction."}
{"index": 5619, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class DateTieredStoreEngine {\n\t// Creates an instance of a compaction context specific to this engine.\n\tCompactionContext createCompaction();\n\t// Create the StoreEngine's components.\n\tprotected void createComponents(org.apache.hadoop.conf.Configuration conf, HStore store, CellComparator kvComparator);\n\tboolean needsCompaction(List<HStoreFile> filesCompacting);\n}", "des": "HBASE-15400 This store engine allows us to store data in date tiered layout with exponential sizing so that the more recent data has more granularity. Time-range scan will perform the best with most recent data. When data reach maxAge, they are compacted in fixed-size time windows for TTL and archiving. Please refer to design spec for more details. https://docs.google.com/document/d/1_AmlNb2N8Us1xICsTeGDLKIqL6T-oHoRLZ323MG_uy8/edit#heading=h.uk6y5pd3oqgx"}
{"index": 5620, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class DeadServer {\n\tSet<ServerName> copyServerNames();\n\t// Get the time when a server died\n\tDate getTimeOfDeath(ServerName deadServerName);\n\tboolean isDeadServer(ServerName serverName);\n\t// Called from rpc by operator cleaning up deadserver list.\n\tboolean removeDeadServer(ServerName deadServerName);\n\tint size();\n}", "des": "Class to hold dead servers list and utility querying dead server list. Servers are added when they expire or when we find them in filesystem on startup. When a server crash procedure is queued, it will populate the processing list and then remove the server from processing list when done. Servers are removed from dead server list when a new instance is started over the old on same hostname and port or when new Master comes online tidying up after all initialization. Processing list and deadserver list are not tied together (you don't have to be in deadservers list to be processing and vice versa)."}
{"index": 5621, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum DeleteTracker.DeleteResult {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DeleteTracker.DeleteResult valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DeleteTracker.DeleteResult[] values();\n}", "des": "Returns codes for delete result. The codes tell the ScanQueryMatcher whether the kv is deleted and why. Based on the delete result, the ScanQueryMatcher will decide the next operation"}
{"index": 5622, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class DelimitedKeyPrefixRegionSplitRestriction {\n\t// Returns a restricted split point.\n\tbyte[] getRestrictedSplitPoint(byte[] splitPoint);\n\t// Initialize the RegionSplitRestriction instance\n\tvoid initialize(TableDescriptor tableDescriptor, org.apache.hadoop.conf.Configuration conf);\n}", "des": "A RegionSplitRestriction implementation that groups rows by a prefix of the row-key with a delimiter. Only the first delimiter for the row key will define the prefix of the row key that is used for grouping."}
{"index": 5623, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class DirectMemoryUtils {\n\t// DirectByteBuffers are garbage collected by using a phantom reference and a reference queue.\n\tstatic void destroyDirectByteBuffer(ByteBuffer toBeDestroyed);\n\t// Returns the direct memory limit of the current progress\n\tstatic long getDirectMemorySize();\n\t// Returns the current amount of direct memory used.\n\tstatic long getDirectMemoryUsage();\n\t// Returns the current amount of direct memory used by netty module.\n\tstatic long getNettyDirectMemoryUsage();\n}", "des": "Utilities for interacting with and monitoring DirectByteBuffer allocations."}
{"index": 5624, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class DisabledRegionSplitPolicy {\n\t// Returns true if the specified region can be split.\n\tprotected boolean canSplit();\n\t// Returns true if the specified region should be split.\n\tprotected boolean shouldSplit();\n}", "des": "A RegionSplitPolicy that disables region splits. This should be used with care, since it will disable automatic sharding. Most of the time, using ConstantSizeRegionSplitPolicy with a large region size (10GB, etc) is safer."}
{"index": 5625, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class DisableTableViolationPolicyEnforcement {\n\t// Checks the given Mutation against this policy.\n\tvoid check(Mutation m);\n\t// Disables this policy.\n\tvoid disable();\n\t// Enables this policy.\n\tvoid enable();\n\t// Returns a logical name for the SpaceViolationPolicy that this enforcement is for.\n\tString getPolicyName();\n}", "des": "A SpaceViolationPolicyEnforcement which disables the table. The enforcement counterpart to SpaceViolationPolicy.DISABLE. This violation policy is different from others as it doesn't take action (i.e. enable/disable table) local to the RegionServer, like the other ViolationPolicies do. In case of violation, the appropriate action is initiated by the master."}
{"index": 5626, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum EventType {\n\tstatic EventType get(int code);\n\tint getCode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EventType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EventType[] values();\n}", "des": "List of all HBase event handler types."}
{"index": 5627, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ExclusiveMemHFileBlock {\n\t// Will be override by SharedMemHFileBlock or ExclusiveMemHFileBlock.\n\tboolean isSharedMem();\n\t// Reference count of this Cacheable.\n\tint refCnt();\n\t// Call ByteBuff.release() to decrease the reference count, if no other reference, it will return back the ByteBuffer to ByteBuffAllocator\n\tboolean release();\n\t// Increase its reference count, and only when no reference we can free the object's memory.\n\tExclusiveMemHFileBlock retain();\n}", "des": "The ByteBuffAllocator won't allocate pooled heap ByteBuff now; at the same time, if allocate an off-heap ByteBuff from allocator, then it must be a pooled one. That's to say, an exclusive memory HFileBlock would must be an heap block and a shared memory HFileBlock would must be an off-heap block."}
{"index": 5628, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum ExecutorType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExecutorType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExecutorType[] values();\n}", "des": "The following is a list of all executor types, both those that run in the master and those that run in the regionserver."}
{"index": 5629, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FastPathBalancedQueueRpcExecutor {\n\t// Add the request to the executor queue\n\tboolean dispatch(CallRunner callTask);\n\t// Override if providing alternate Handler implementation.\n\tprotected RpcHandler getHandler(String name, double handlerFailureThreshhold, int handlerCount, BlockingQueue<CallRunner> q, AtomicInteger activeHandlerCount, AtomicInteger failedHandlerCount, Abortable abortable);\n}", "des": "Balanced queue executor with a fastpath. Because this is FIFO, it has no respect for ordering so a fast path skipping the queuing of Calls if an Handler is available, is possible. Just pass the Call direct to waiting Handler thread. Try to keep the hot Handlers bubbling rather than let them go cold and lose context. Idea taken from Apace Kudu (incubating). See https://gerrit.cloudera.org/#/c/2938/7/src/kudu/rpc/service_queue.h"}
{"index": 5630, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FastPathRWQueueRpcExecutor {\n\t// Add the request to the executor queue\n\tboolean dispatch(CallRunner callTask);\n\t// Override if providing alternate Handler implementation.\n\tprotected RpcHandler getHandler(String name, double handlerFailureThreshhold, int handlerCount, BlockingQueue<CallRunner> q, AtomicInteger activeHandlerCount, AtomicInteger failedHandlerCount, Abortable abortable);\n}", "des": "RPC Executor that extends RWQueueRpcExecutor with fast-path feature, used in FastPathBalancedQueueRpcExecutor."}
{"index": 5631, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface FavoredNodesForRegion {\n\t// Get the favored nodes mapping for this region.\n\tInetSocketAddress[] getFavoredNodesForRegion(String encodedRegionName);\n\t// Used to update the favored nodes mapping when required.\n\tvoid updateRegionFavoredNodesMapping(String encodedRegionName, List<org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.ServerName> favoredNodes);\n}", "des": "Abstraction that allows different modules in RegionServer to update/get the favored nodes information for regions."}
{"index": 5632, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface FileArchiverNotifier {\n\t// Records a file and its size in bytes being moved to the archive directory.\n\tvoid addArchivedFiles(Set<Map.Entry<String,Long>> fileSizes);\n\t// Computes the size of a table and all of its snapshots, recording new \"full\" sizes for each.\n\tlong computeAndStoreSnapshotSizes(Collection<String> currentSnapshots);\n}", "des": "Interface allowing various implementations of tracking files that have recently been archived to allow for the Master to notice changes to snapshot sizes for space quotas. This object needs to ensure that addArchivedFiles(Set) and computeAndStoreSnapshotSizes(Collection) are mutually exclusive. If a \"full\" computation is in progress, new changes being archived should be held."}
{"index": 5633, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FileArchiverNotifierImpl {\n\t// Records a file and its size in bytes being moved to the archive directory.\n\tvoid addArchivedFiles(Set<Map.Entry<String,Long>> fileSizes);\n\t// Computes the size of a table and all of its snapshots, recording new \"full\" sizes for each.\n\tlong computeAndStoreSnapshotSizes(Collection<String> currentSnapshots);\n}", "des": "Tracks file archiving and updates the hbase quota table."}
{"index": 5634, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface FirstLevelBlockCache {\n\t// Whether the cache contains the block with specified cacheKey\n\tboolean containsBlock(BlockCacheKey cacheKey);\n\t// Specifies the secondary cache.\n\tvoid setVictimCache(BlockCache victimCache);\n}", "des": "In-memory BlockCache that may be backed by secondary layer(s)."}
{"index": 5635, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FixedIntervalRateLimiter {\n\tlong getNextRefillTime();\n\t// Time in milliseconds to wait for before requesting to consume 'amount' resource.\n\tlong getWaitInterval(long limit, long available, long amount);\n\t// Refill the available units w.r.t the elapsed time.\n\tlong refill(long limit);\n\tvoid setNextRefillTime(long nextRefillTime);\n}", "des": "With this limiter resources will be refilled only after a fixed interval of time."}
{"index": 5636, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FlushAllLargeStoresPolicy {\n\t// Upon construction, this method will be called with the region to be governed.\n\tprotected void configureForRegion(HRegion region);\n\t// Returns the stores need to be flushed.\n\tCollection<HStore> selectStoresToFlush();\n\tprotected boolean shouldFlush(HStore store);\n}", "des": "A FlushPolicy that only flushes store larger a given threshold. If no store is large enough, then all stores will be flushed."}
{"index": 5637, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface FlushLifeCycleTracker {\n\t// Called after flush is executed.\n\tdefault void afterExecution();\n\t// Called before flush is executed.\n\tdefault void beforeExecution();\n\t// Called if the flush request fails for some reason.\n\tdefault void notExecuted(String reason);\n}", "des": "Used to track flush execution."}
{"index": 5638, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FlushNonSloppyStoresFirstPolicy {\n\t// Upon construction, this method will be called with the region to be governed.\n\tprotected void configureForRegion(HRegion region);\n\t// Returns the stores need to be flushed.\n\tCollection<HStore> selectStoresToFlush();\n}", "des": "A FlushPolicy that only flushes store larger than a given threshold. If no store is large enough, then all stores will be flushed. Gives priority to selecting regular stores first, and only if no other option, selects sloppy stores which normaly require more memory."}
{"index": 5639, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FlushPolicy {\n\t// Upon construction, this method will be called with the region to be governed.\n\tprotected void configureForRegion(HRegion region);\n\t// Returns the stores need to be flushed.\n\tabstract Collection<HStore> selectStoresToFlush();\n}", "des": "A flush policy determines the stores that need to be flushed when flushing a region."}
{"index": 5640, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FlushPolicyFactory {\n\t// Create the FlushPolicy configured for the given table.\n\tstatic FlushPolicy create(HRegion region, org.apache.hadoop.conf.Configuration conf);\n\t// Get FlushPolicy class for the given table.\n\tstatic Class<? extends FlushPolicy> getFlushPolicyClass(TableDescriptor htd, org.apache.hadoop.conf.Configuration conf);\n}", "des": "The class that creates a flush policy from a conf and HTableDescriptor."}
{"index": 5641, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FlushSnapshotSubprocedure {\n\t// do nothing, core of snapshot is executed in insideBarrier() step.\n\tvoid acquireBarrier();\n\t// Cancel threads if they haven't finished.\n\tvoid cleanup(Exception e);\n\t// do a flush snapshot of every region on this rs from the target table.\n\tbyte[] insideBarrier();\n\t// Hooray!\n\tvoid releaseBarrier();\n}", "des": "This online snapshot implementation uses the distributed procedure framework to force a store flush and then records the hfiles. Its enter stage does nothing. Its leave stage then flushes the memstore, builds the region server's snapshot manifest from its hfiles list, and copies .regioninfos into the snapshot working directory. At the master side, there is an atomic rename of the working dir into the proper snapshot directory."}
{"index": 5642, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FlushTableSubprocedure {\n\t// Flush the online regions on this rs for the target table.\n\tvoid acquireBarrier();\n\t// Cancel threads if they haven't finished.\n\tvoid cleanup(Exception e);\n\t// The implementation of this method should act with the assumption that the barrier condition has been satisfied.\n\tbyte[] insideBarrier();\n\tvoid releaseBarrier();\n}", "des": "This flush region implementation uses the distributed procedure framework to flush table regions. Its acquireBarrier stage does nothing. Its insideBarrier stage flushes the regions."}
{"index": 5643, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ForeignException {\n\t// Takes a series of bytes and tries to generate an ForeignException instance for it.\n\tstatic ForeignException deserialize(byte[] bytes);\n\tString getSource();\n\t// The cause of a ForeignException can be an exception that was generated on a local in process thread, or a thread from a 'remote' separate process.\n\tboolean isRemote();\n\t// Converts a ForeignException to an array of bytes.\n\tstatic byte[] serialize(String source, Throwable t);\n}", "des": "A ForeignException is an exception from another thread or process."}
{"index": 5644, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ForeignExceptionDispatcher {\n\t// Listen for failures to a given process.\n\tvoid addListener(ForeignExceptionListener errorable);\n\t// Get the value of the captured exception.\n\tForeignException getException();\n\tString getName();\n\t// Non-exceptional form of ForeignExceptionSnare.rethrowException().\n\tboolean hasException();\n\t// Receive a ForeignException.\n\tvoid receive(ForeignException e);\n\t// Rethrow an exception currently held by the ForeignExceptionSnare.\n\tvoid rethrowException();\n}", "des": "The dispatcher acts as the state holding entity for foreign error handling. The first exception received by the dispatcher get passed directly to the listeners. Subsequent exceptions are dropped."}
{"index": 5645, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ForeignExceptionSnare {\n\t// Get the value of the captured exception.\n\tForeignException getException();\n\t// Non-exceptional form of rethrowException().\n\tboolean hasException();\n\t// Rethrow an exception currently held by the ForeignExceptionSnare.\n\tvoid rethrowException();\n}", "des": "This is an interface for a cooperative exception throwing mechanism. Implementations are containers that holds an exception from a separate thread. This can be used to receive exceptions from 'foreign' threads or from separate 'foreign' processes."}
{"index": 5646, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class FSVisitor {\n\t// Iterate over the region store files\n\tstatic void visitRegionStoreFiles(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path regionDir, FSVisitor.StoreFileVisitor visitor);\n\t// Iterate over the table store files\n\tstatic void visitTableStoreFiles(org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path tableDir, FSVisitor.StoreFileVisitor visitor);\n}", "des": "Utility methods for interacting with the hbase.root file system."}
{"index": 5647, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class HbckChore {\n\tprotected void chore();\n\t// Returns Returns last published Report that comes of last successful execution of this chore.\n\tHbckReport getLastReport();\n\tboolean isDisabled();\n\t// When running, the HBCK report may be changed later.\n\tboolean isRunning();\n\t// Request execution of this chore's action.\n\tboolean runChore();\n}", "des": "Used to do the hbck checking job at master side."}
{"index": 5648, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class HFileArchiveTableMonitor {\n\t// Add the named table to be those being archived.\n\tvoid addTable(String table);\n\tvoid clearArchive();\n\tvoid removeTable(String table);\n\t// Set the tables to be archived.\n\tvoid setArchiveTables(List<String> tables);\n\t// Determine if the given table should or should not allow its hfiles to be deleted in the archive\n\tboolean shouldArchiveTable(String tableName);\n}", "des": "Monitor the actual tables for which HFiles are archived for long-term retention (always kept unless ZK state changes)."}
{"index": 5649, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface HFileIndexBlockEncoder {\n\tHFileIndexBlockEncoder.EncodedSeeker createSeeker();\n\tvoid encode(BlockIndexChunk blockIndexChunk, boolean rootIndexBlock, DataOutput out);\n\t// Returns the index block encoding\n\tIndexBlockEncoding getIndexBlockEncoding();\n\t// Save metadata in HFile which will be written to disk\n\tvoid saveMetadata(HFile.Writer writer);\n}", "des": "Controls what kind of index block encoding is used. If index block encoding is not set or the given block is not a index block (encoded or not), methods should just return the unmodified block."}
{"index": 5650, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class HFileIndexBlockEncoderImpl {\n\tstatic HFileIndexBlockEncoder createFromFileInfo(HFileInfo fileInfo);\n\tHFileIndexBlockEncoder.EncodedSeeker createSeeker();\n\tvoid encode(BlockIndexChunk blockIndexChunk, boolean rootIndexBlock, DataOutput out);\n\t// Returns the index block encoding\n\tIndexBlockEncoding getIndexBlockEncoding();\n\t// Save metadata in HFile which will be written to disk\n\tvoid saveMetadata(HFile.Writer writer);\n}", "des": "Do different kinds of index block encoding according to column family options."}
{"index": 5651, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface HRegion.BulkLoadListener {\n\t// Called after a successful HFile load\n\tvoid doneBulkLoad(byte[] family, String srcPath);\n\t// Called after a failed HFile load\n\tvoid failedBulkLoad(byte[] family, String srcPath);\n\t// Called before an HFile is actually loaded\n\tString prepareBulkLoad(byte[] family, String srcPath, boolean copyFile, String customStaging);\n}", "des": "Listener class to enable callers of bulkLoadHFile() to perform any necessary pre/post processing of a given bulkload call"}
{"index": 5652, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class HRegion.FlushResultImpl {\n\t// Returns the detailed result code\n\tHRegion.FlushResult.Result getResult();\n\t// Convenience method, the equivalent of checking if result is FLUSHED_COMPACTION_NEEDED.\n\tboolean isCompactionNeeded();\n\t// Convenience method, the equivalent of checking if result is FLUSHED_NO_COMPACTION_NEEDED or FLUSHED_NO_COMPACTION_NEEDED.\n\tboolean isFlushSucceeded();\n}", "des": "Objects from this class are created when flushing to describe all the different states that that method ends up in. The Result enum describes those states. The sequence id should only be specified if the flush was successful, and the failure message should only be specified if it didn't flush."}
{"index": 5653, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class IncreasingToUpperBoundRegionSplitPolicy {\n\t// Upon construction, this method will be called with the region to be governed.\n\tprotected void configureForRegion(HRegion region);\n\tprotected long getSizeToCheck(int tableRegionsCount);\n\t// Returns true if the specified region should be split.\n\tprotected boolean shouldSplit();\n}", "des": "Split size is the number of regions that are on this server that all are of the same table, cubed, times 2x the region flush size OR the maximum region split size, whichever is smaller."}
{"index": 5654, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class InputStreamBlockDistribution {\n\t// Get the HDFSBlocksDistribution derived from the StoreFile input stream, re-computing if cache is expired.\n\tHDFSBlocksDistribution getHDFSBlockDistribution();\n\t// True if we should derive StoreFile HDFSBlockDistribution from the underlying input stream\n\tstatic boolean isEnabled(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Computes the HDFSBlockDistribution for a file based on the underlying located blocks for an HdfsDataInputStream reading that file. The backing DFSInputStream.getAllBlocks involves allocating an array of numBlocks size per call. It may also involve calling the namenode, if the DFSInputStream has not fetched all the blocks yet. In order to avoid allocation pressure, we cache the computed distribution for a configurable period of time."}
{"index": 5655, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class InternalScan {\n\t// StoreFiles will not be scanned.\n\tvoid checkOnlyMemStore();\n\t// MemStore will not be scanned.\n\tvoid checkOnlyStoreFiles();\n\t// Returns true if only the MemStore should be checked.\n\tboolean isCheckOnlyMemStore();\n\t// Returns true if only StoreFiles should be checked.\n\tboolean isCheckOnlyStoreFiles();\n}", "des": "Special scanner, currently used for increment operations to allow additional server-side arguments for Scan operations."}
{"index": 5656, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface InternalScanner {\n\t// Closes the scanner and releases any resources it has allocated\n\tvoid close();\n\t// Grab the next row's worth of values.\n\tdefault boolean next(List<Cell> result);\n\t// Grab the next row's worth of values.\n\tboolean next(List<Cell> result, ScannerContext scannerContext);\n}", "des": "Internal scanners differ from client-side scanners in that they operate on HStoreKeys and byte[] instead of RowResults. This is because they are actually close to how the data is physically stored, and therefore it is more convenient to interact with them that way. It is also much easier to merge the results across SortedMaps than RowResults."}
{"index": 5657, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class JVMClusterUtil.RegionServerThread {\n\t// Returns the region server\n\tHRegionServer getRegionServer();\n\t// Block until the region server has come online, indicating it is ready to be used.\n\tvoid waitForServerOnline();\n}", "des": "Datastructure to hold RegionServer Thread and RegionServer instance"}
{"index": 5658, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class JvmVersion {\n\t// Return the current JVM version information.\n\tstatic String getVersion();\n\t// Return true if the current JVM version is known to be unstable with HBase.\n\tstatic boolean isBadJvmVersion();\n}", "des": "Utility class to get and check the current JVM version."}
{"index": 5659, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class KeyPrefixRegionSplitRestriction {\n\t// Returns a restricted split point.\n\tbyte[] getRestrictedSplitPoint(byte[] splitPoint);\n\t// Initialize the RegionSplitRestriction instance\n\tvoid initialize(TableDescriptor tableDescriptor, org.apache.hadoop.conf.Configuration conf);\n}", "des": "A RegionSplitRestriction implementation that groups rows by a prefix of the row-key."}
{"index": 5660, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class LogCleaner {\n\tvoid cancel(boolean mayInterruptIfRunning);\n\tvoid cleanup();\n\t// Delete the given files\n\tprotected int deleteFiles(Iterable<org.apache.hadoop.fs.FileStatus> filesToDelete);\n\tvoid onConfigurationChange(org.apache.hadoop.conf.Configuration conf);\n\t// Validate the file to see if it even belongs in the directory.\n\tprotected boolean validate(org.apache.hadoop.fs.Path file);\n}", "des": "This Chore, every time it runs, will attempt to delete the WALs and Procedure WALs in the old logs folder. The WAL is only deleted if none of the cleaner delegates says otherwise."}
{"index": 5661, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class LruCachedBlock {\n\t// Block has been accessed.\n\tvoid access(long accessTime);\n\tint compareTo(LruCachedBlock that);\n\tboolean equals(Object obj);\n\tCacheable getBuffer();\n\t// Returns Time we were cached at in nano seconds.\n\tlong getCachedTime();\n\tBlockCacheKey getCacheKey();\n\tBlockPriority getPriority();\n\tlong heapSize();\n}", "des": "Represents an entry in the LruBlockCache."}
{"index": 5662, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class LruCachedBlockQueue {\n\t// Attempt to add the specified cached block to this queue.\n\tvoid add(LruCachedBlock cb);\n\t// Total size of all elements in this queue.\n\tlong heapSize();\n\t// Returns The next element in this queue, or null if the queue is empty.\n\tLruCachedBlock poll();\n\t// Returns The last element in this queue, or null if the queue is empty.\n\tLruCachedBlock pollLast();\n}", "des": "A memory-bound queue that will grow until an element brings total size >= maxSize. From then on, only entries that are sorted larger than the smallest current entry will be inserted/replaced."}
{"index": 5663, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MasterAddressSyncer {\n\t// Returns the zk path(s) to watch\n\tprotected Set<String> getPathsToWatch();\n\t// Validate whether a znode path is watched by us\n\tprotected boolean validate(String path);\n}", "des": "Tracks the active master address on server ZK cluster and synchronize them to client ZK cluster if changed"}
{"index": 5664, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MasterFifoRpcScheduler {\n\t// Dispatches an RPC request asynchronously.\n\tboolean dispatch(CallRunner task);\n\t// Retrieves the total number of active handler.\n\tint getActiveRpcHandlerCount();\n\t// Get call queue information\n\tCallQueueInfo getCallQueueInfo();\n\t// Retrieves length of the general queue for metrics.\n\tint getGeneralQueueLength();\n\t// Prepares for request serving.\n\tvoid start();\n\t// Stops serving new requests.\n\tvoid stop();\n}", "des": "A special RpcScheduler} only used for master. This scheduler separates RegionServerReport requests to independent handlers to avoid these requests block other requests. To use this scheduler, please set \"hbase.master.rpc.scheduler.factory.class\" to \"org.apache.hadoop.hbase.ipc.MasterFifoRpcScheduler\"."}
{"index": 5665, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MasterQuotasObserver {\n\tOptional<MasterObserver> getMasterObserver();\n\t// Called after the deleteNamespace operation has been requested.\n\tvoid postDeleteNamespace(ObserverContext<MasterCoprocessorEnvironment> ctx, String namespace);\n\t// Called after the deleteTable operation has been requested.\n\tvoid postDeleteTable(ObserverContext<MasterCoprocessorEnvironment> ctx, TableName tableName);\n\tvoid start(CoprocessorEnvironment ctx);\n}", "des": "An observer to automatically delete quotas when a table/namespace is deleted."}
{"index": 5666, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MasterRegionServerList {\n\t// Called when a region server is dead.\n\tvoid expired(ServerName sn);\n\t// Get all live region servers.\n\tSet<ServerName> getAll();\n\t// Called when a region server join the cluster.\n\tvoid started(ServerName sn);\n}", "des": "MasterRegion based RegionServerList."}
{"index": 5667, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MemoryBoundedLogMessageBuffer {\n\t// Append the given message to this buffer, automatically evicting older messages until the desired memory limit is achieved.\n\tvoid add(String messageText);\n\t// Dump the contents of the buffer to the given stream.\n\tvoid dumpTo(PrintWriter out);\n}", "des": "A size-bounded repository of alerts, which are kept in a linked list. Alerts can be added, and they will automatically be removed one by one when the specified heap usage is exhausted."}
{"index": 5668, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum MemStoreCompactionStrategy.Action {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MemStoreCompactionStrategy.Action valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MemStoreCompactionStrategy.Action[] values();\n}", "des": "Types of actions to be done on the pipeline upon MemStoreCompaction invocation. Note that every value covers the previous ones, i.e. if MERGE is the action it implies that the youngest segment is going to be flatten anyway."}
{"index": 5669, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MemStoreCompactor {\n\tvoid resetStats();\n\t// ---------------------------------------------------------------------- The request to dispatch the compaction asynchronous task.\n\tboolean start();\n\t// ---------------------------------------------------------------------- The request to cancel the compaction asynchronous task The compaction may still happen if the request was sent too late Non-blocking request\n\tvoid stop();\n}", "des": "The ongoing MemStore Compaction manager, dispatches a solo running compaction and interrupts the compaction if requested. The compaction is interrupted and stopped by CompactingMemStore, for example when another compaction needs to be started. Prior to compaction the MemStoreCompactor evaluates the compacting ratio and aborts the compaction if it is not worthy. The MemStoreScanner is used to traverse the compaction pipeline. The MemStoreScanner is included in internal store scanner, where all compaction logic is implemented. Threads safety: It is assumed that the compaction pipeline is immutable, therefore no special synchronization is required."}
{"index": 5670, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MemStoreSnapshot {\n\t// Returns Number of Cells in this snapshot.\n\tint getCellsCount();\n\tlong getDataSize();\n\t// Returns snapshot's identifier.\n\tlong getId();\n\tMemStoreSize getMemStoreSize();\n\t// Create new SnapshotSegmentScanners for iterating over the snapshot.\n\tList<KeyValueScanner> getScanners();\n\t// Returns TimeRangeTracker for all the Cells in the snapshot.\n\tTimeRangeTracker getTimeRangeTracker();\n\t// Returns true if tags are present in this snapshot\n\tboolean isTagsPresent();\n}", "des": "MemStoreSnapshot is a Context Object to hold details of the snapshot taken on a MemStore. Details include the snapshot's identifier, count of cells in it and total memory size occupied by all the cells, timestamp information of all the cells and the snapshot immutableSegment."}
{"index": 5671, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MetaLocationSyncer {\n\t// Returns the zk path(s) to watch\n\tprotected Set<String> getPathsToWatch();\n\tvoid setMetaReplicaCount(int replicaCount);\n\t// Validate whether a znode path is watched by us\n\tprotected boolean validate(String path);\n}", "des": "Tracks the meta region locations on server ZK cluster and synchronize them to client ZK cluster if changed"}
{"index": 5672, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MetricsWAL {\n\t// A request was made that the WAL be rolled.\n\tvoid logRollRequested(WALActionsListener.RollRequestReason reason);\n\t// For notification post append to the writer.\n\tvoid postAppend(long size, long time, WALKey logkey, WALEdit logEdit);\n\t// The WAL has been rolled.\n\tvoid postLogRoll(org.apache.hadoop.fs.Path oldPath, org.apache.hadoop.fs.Path newPath);\n\t// For notification post writer sync.\n\tvoid postSync(long timeInNanos, int handlerSyncs);\n}", "des": "Class used to push numbers about the WAL into the metrics subsystem. This will take a single function call and turn it into multiple manipulations of the hadoop metrics system."}
{"index": 5673, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MobFileCleanerChore {\n\t// Archives the mob files.\n\tvoid archiveMobFiles(org.apache.hadoop.conf.Configuration conf, TableName tableName, byte[] family, List<org.apache.hadoop.fs.Path> storeFiles);\n\tprotected void chore();\n\t// Performs housekeeping file cleaning (called by MOB Cleaner chore)\n\tvoid cleanupObsoleteMobFiles(org.apache.hadoop.conf.Configuration conf, TableName table);\n}", "des": "The class MobFileCleanerChore for running cleaner regularly to remove the expired and obsolete (files which have no active references to) mob files."}
{"index": 5674, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class MobStoreScanner {\n\t// Close the KeyValue scanner.\n\tvoid close();\n\t// Firstly reads the cells from the HBase.\n\tboolean next(List<Cell> outResult, ScannerContext ctx);\n\t// Called after a batch of rows scanned and set to be returned to client.\n\tvoid shipped();\n}", "des": "Scanner scans both the memstore and the MOB Store. Coalesce KeyValue stream into List for a single row."}
{"index": 5675, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface MutableOnlineRegions {\n\t// Add to online regions.\n\tvoid addRegion(HRegion r);\n\t// Removes the given Region from the list of onlineRegions.\n\tboolean removeRegion(HRegion r, ServerName destination);\n}", "des": "Interface to Map of online regions. In the Map, the key is the region's encoded name and the value is an Region instance."}
{"index": 5676, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class NamespaceTableCfWALEntryFilter {\n\t// Applies the filter, possibly returning a different Entry instance.\n\tWAL.Entry filter(WAL.Entry entry);\n\t// Applies the filter, possibly returning a different Cell instance.\n\tCell filterCell(WAL.Entry entry, Cell cell);\n}", "des": "Filter a WAL Entry by the peer config according to the table and family which it belongs to."}
{"index": 5677, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class NoInsertsViolationPolicyEnforcement {\n\t// Checks the given Mutation against this policy.\n\tvoid check(Mutation m);\n\t// Disables this policy.\n\tvoid disable();\n\t// Enables this policy.\n\tvoid enable();\n\t// Returns a logical name for the SpaceViolationPolicy that this enforcement is for.\n\tString getPolicyName();\n}", "des": "A SpaceViolationPolicyEnforcement which disallows any inserts to the table. The enforcement counterpart to SpaceViolationPolicy.NO_INSERTS."}
{"index": 5678, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class NoOpIndexBlockEncoder {\n\tHFileIndexBlockEncoder.EncodedSeeker createSeeker();\n\tvoid encode(BlockIndexChunk blockIndexChunk, boolean rootIndexBlock, DataOutput out);\n\t// Returns the index block encoding\n\tIndexBlockEncoding getIndexBlockEncoding();\n\t// Save metadata in HFile which will be written to disk\n\tvoid saveMetadata(HFile.Writer writer);\n}", "des": "Does not perform any kind of encoding/decoding."}
{"index": 5679, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class NoRegionSplitRestriction {\n\t// Returns a restricted split point.\n\tbyte[] getRestrictedSplitPoint(byte[] splitPoint);\n\t// Initialize the RegionSplitRestriction instance\n\tvoid initialize(TableDescriptor tableDescriptor, org.apache.hadoop.conf.Configuration conf);\n}", "des": "A RegionSplitRestriction implementation that does nothing."}
{"index": 5680, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class NoWritesCompactionsViolationPolicyEnforcement {\n\t// Returns whether or not compactions on this table should be disabled for this policy.\n\tboolean areCompactionsDisabled();\n\t// Disables this policy.\n\tvoid disable();\n\t// Enables this policy.\n\tvoid enable();\n\t// Returns a logical name for the SpaceViolationPolicy that this enforcement is for.\n\tString getPolicyName();\n}", "des": "A SpaceViolationPolicyEnforcement implementation which disables all updates and compactions. The enforcement counterpart to SpaceViolationPolicy.NO_WRITES_COMPACTIONS."}
{"index": 5681, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class NoWritesViolationPolicyEnforcement {\n\t// Checks the given Mutation against this policy.\n\tvoid check(Mutation m);\n\t// Disables this policy.\n\tvoid disable();\n\t// Enables this policy.\n\tvoid enable();\n\t// Returns a logical name for the SpaceViolationPolicy that this enforcement is for.\n\tString getPolicyName();\n}", "des": "A SpaceViolationPolicyEnforcement implementation which disables all writes flowing into HBase. The enforcement counterpart to SpaceViolationPolicy.NO_WRITES."}
{"index": 5682, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ObserverContext<E extends CoprocessorEnvironment> {\n\t// Call to indicate that the current coprocessor's return value (or parameter -- depends on the call-type) should be used in place of the value that would be obtained via normal processing; i.e.\n\tvoid bypass();\n\t// Returns the active user for the coprocessor call.\n\tOptional<User> getCaller();\n\tE getEnvironment();\n}", "des": "Carries the execution state for a given invocation of an Observer coprocessor (RegionObserver, MasterObserver, or WALObserver) method. The same ObserverContext instance is passed sequentially to all loaded coprocessors for a given Observer method trigger, with the CoprocessorEnvironment reference set appropriately for each Coprocessor type: e.g. the RegionCoprocessorEnvironment is passed to RegionCoprocessors, and so on."}
{"index": 5683, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ObserverContextImpl<E extends CoprocessorEnvironment> {\n\t// Call to indicate that the current coprocessor's return value (or parameter -- depends on the call-type) should be used in place of the value that would be obtained via normal processing; i.e.\n\tvoid bypass();\n\t// Returns the active user for the coprocessor call.\n\tOptional<User> getCaller();\n\tE getEnvironment();\n\tboolean isBypassable();\n\tvoid prepare(E env);\n\tboolean shouldBypass();\n}", "des": "This is the only implementation of ObserverContext, which serves as the interface for third-party Coprocessor developers."}
{"index": 5684, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface OnlineRegions {\n\t// Return Region instance.\n\tRegion getRegion(String encodedRegionName);\n\t// Get all online regions in this RS.\n\tList<? extends Region> getRegions();\n\t// Get all online regions of a table in this RS.\n\tList<? extends Region> getRegions(TableName tableName);\n}", "des": "Provides read-only access to the Regions presently online on the current RegionServer"}
{"index": 5685, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface OperationQuota {\n\t// Add a get result.\n\tvoid addGetResult(Result result);\n\t// Add a mutation result.\n\tvoid addMutation(Mutation mutation);\n\t// Add a scan result.\n\tvoid addScanResult(List<Result> results);\n\t// Checks if it is possible to execute the specified operation.\n\tvoid checkQuota(int numWrites, int numReads, int numScans);\n\t// Cleanup method on operation completion\n\tvoid close();\n\t// Returns the number of bytes available to read to avoid exceeding the quota\n\tlong getReadAvailable();\n}", "des": "Interface that allows to check the quota available for an operation."}
{"index": 5686, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class PersistentIOEngine {\n\t// Using an encryption algorithm to calculate a checksum, the default encryption algorithm is MD5\n\tprotected byte[] calculateChecksum(String algorithm);\n\t// Verify cache files's integrity\n\tprotected void verifyFileIntegrity(byte[] persistentChecksum, String algorithm);\n}", "des": "A class implementing PersistentIOEngine interface supports file integrity verification for BucketCache which use persistent IOEngine"}
{"index": 5687, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class PreviousBlockCompressionRatePredicator {\n\t// Returns true if the passed uncompressed size is larger than the limit calculated by updateLatestBlockSizes.\n\tboolean shouldFinishBlock(int uncompressed);\n\t// Recalculates compression rate for the last block and adjusts the block size limit as: BLOCK_SIZE * (uncompressed/compressed).\n\tvoid updateLatestBlockSizes(HFileContext context, int uncompressed, int compressed);\n}", "des": "This BlockCompressedSizePredicator implementation adjusts the block size limit based on the compression rate of the block contents read so far. For the first block, adjusted size would be zero, so it performs a compression of current block contents and calculate compression rate and adjusted size. For subsequent blocks, decision whether the block should be finished or not will be based on the compression rate calculated for the previous block."}
{"index": 5688, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface PriorityFunction {\n\t// Returns the deadline of the specified request.\n\tlong getDeadline(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.RequestHeader header, org.apache.hbase.thirdparty.com.google.protobuf.Message param);\n\t// Returns the 'priority type' of the specified request.\n\tint getPriority(org.apache.hadoop.hbase.shaded.protobuf.generated.RPCProtos.RequestHeader header, org.apache.hbase.thirdparty.com.google.protobuf.Message param, User user);\n}", "des": "Function to figure priority of incoming request."}
{"index": 5689, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ProtobufWALStreamReader {\n\t// Get or create the input stream used by cell decoder.\n\tprotected InputStream getCellCodecInputStream(org.apache.hadoop.fs.FSDataInputStream stream);\n\t// Read the next entry in WAL, use the given WAL.Entry if not null to hold the data.\n\tWAL.Entry next(WAL.Entry reuse);\n\t// Skip to the given position.\n\tprotected void skipTo(long position);\n}", "des": "A one way stream reader for reading protobuf based WAL file."}
{"index": 5690, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class QuotaObserverChore {\n\tprotected void chore();\n\t// Returns an unmodifiable view over the current SpaceQuotaSnapshot objects for each HBase namespace with a quota defined.\n\tMap<String,SpaceQuotaSnapshot> getNamespaceQuotaSnapshots();\n\t// Returns an unmodifiable view over the current SpaceQuotaSnapshot objects for each HBase table with a quota defined.\n\tMap<TableName,SpaceQuotaSnapshot> getTableQuotaSnapshots();\n}", "des": "Reads the currently received Region filesystem-space use reports and acts on those which violate a defined quota."}
{"index": 5691, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class QuotaState {\n\t// Return the limiter associated with this quota.\n\tQuotaLimiter getGlobalLimiter();\n\tlong getLastQuery();\n\tlong getLastUpdate();\n\t// Returns true if there is no quota information associated to this object\n\tboolean isBypass();\n\t// Setup the global quota information.\n\tvoid setQuotas(org.apache.hadoop.hbase.shaded.protobuf.generated.QuotaProtos.Quotas quotas);\n\t// Perform an update of the quota info based on the other quota info object.\n\tvoid update(QuotaState other);\n}", "des": "In-Memory state of table or namespace quotas"}
{"index": 5692, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum Region.Operation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Region.Operation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Region.Operation[] values();\n}", "des": "Operation enum is used in Region.startRegionOperation() and elsewhere to provide context for various checks."}
{"index": 5693, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum RegionObserver.MutationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RegionObserver.MutationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RegionObserver.MutationType[] values();\n}", "des": "Mutation type for postMutationBeforeWAL hook"}
{"index": 5694, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RegionReplicaFlushHandler {\n\t// Event exception handler, may be overridden\n\tprotected void handleException(Throwable t);\n\t// This method is the main processing loop to be implemented by the various subclasses.\n\tvoid process();\n}", "des": "HBASE-11580: With the async wal approach (HBASE-11568), the edits are not persisted to WAL in secondary region replicas. This means that a secondary region replica can serve some edits from it's memstore that are still not flushed from primary. We do not want to allow secondary region's seqId to go back in time, when this secondary region is opened elsewhere after a crash or region move. We will trigger a flush cache in the primary region replica and wait for observing a complete flush cycle before marking the region readsEnabled. This handler does the flushing of the primary region replica and ensures that regular region opening is not blocked while the secondary replica is blocked on flush."}
{"index": 5695, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RegionReplicationBufferManager {\n\t// Called after you ship the edits out.\n\tvoid decrease(long size);\n\t// Return whether we should just drop all the edits, if we have reached the hard limit of max pending size.\n\tboolean increase(long size);\n\tvoid stop();\n}", "des": "Manager the buffer size for all RegionReplicationSink."}
{"index": 5696, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RegionReplicationSink {\n\t// Add this edit to replication queue.\n\tvoid add(WALKeyImpl key, WALEdit edit, ServerCall<?> rpcCall);\n\t// Stop the replication sink.\n\tvoid stop();\n\t// Make sure that we have finished all the replicating requests.\n\tvoid waitUntilStopped();\n}", "des": "The class for replicating WAL edits to secondary replicas, one instance per region."}
{"index": 5697, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface RegionServerList {\n\t// Called when a region server is dead.\n\tvoid expired(ServerName sn);\n\t// Get all live region servers.\n\tSet<ServerName> getAll();\n\t// Called when a region server join the cluster.\n\tvoid started(ServerName sn);\n}", "des": "For storing the region server list."}
{"index": 5698, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RegionServerProcedureManager {\n\t// Initialize a globally barriered procedure for region servers.\n\tabstract void initialize(RegionServerServices rss);\n\t// Start accepting procedure requests.\n\tabstract void start();\n\t// Close this and all running procedure tasks\n\tabstract void stop(boolean force);\n}", "des": "A life-cycle management interface for globally barriered procedures on region servers."}
{"index": 5699, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface RegionSize {\n\t// Returns the size of the region.\n\tlong getSize();\n\t// Atomically adds the provided delta to the region size.\n\tRegionSize incrementSize(long delta);\n\t// Updates the size of the Region.\n\tRegionSize setSize(long newSize);\n}", "des": "Interface that encapsulates optionally sending a Region's size to the master."}
{"index": 5700, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RegionSizeImpl {\n\t// Returns the size of the region.\n\tlong getSize();\n\tlong heapSize();\n\t// Atomically adds the provided delta to the region size.\n\tRegionSizeImpl incrementSize(long delta);\n\t// Updates the size of the Region.\n\tRegionSizeImpl setSize(long newSize);\n}", "des": "An object encapsulating a Region's size and whether it's been reported to the master since the value last changed."}
{"index": 5701, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RegionSplitRestriction {\n\t// Create the RegionSplitRestriction configured for the given table.\n\tstatic RegionSplitRestriction create(TableDescriptor tableDescriptor, org.apache.hadoop.conf.Configuration conf);\n\t// Returns a restricted split point.\n\tabstract byte[] getRestrictedSplitPoint(byte[] splitPoint);\n\t// Initialize the RegionSplitRestriction instance\n\tabstract void initialize(TableDescriptor tableDescriptor, org.apache.hadoop.conf.Configuration conf);\n}", "des": "A split restriction that restricts the pattern of the split point."}
{"index": 5702, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface RegionStateListener {\n\t// Process region merge event.\n\tvoid onRegionMerged(RegionInfo mergedRegion);\n\t// Process region split event.\n\tvoid onRegionSplit(RegionInfo hri);\n\t// Process region split reverted event.\n\tvoid onRegionSplitReverted(RegionInfo hri);\n}", "des": "The listener interface for receiving region state events."}
{"index": 5703, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ReplicationHFileCleaner {\n\t// Determines which of the given files are safe to delete\n\tIterable<org.apache.hadoop.fs.FileStatus> getDeletableFiles(Iterable<org.apache.hadoop.fs.FileStatus> files);\n\t// this method is used to pass some instance into subclass\n\tvoid init(Map<String,Object> params);\n\t// Should the master delete the file or keep it?\n\tboolean isFileDeletable(org.apache.hadoop.fs.FileStatus fStat);\n\tboolean isStopped();\n\tvoid stop(String why);\n}", "des": "Implementation of a file cleaner that checks if a hfile is still scheduled for replication before deleting it from hfile archive directory."}
{"index": 5704, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ReplicationLoad {\n\t// buildReplicationLoad\n\tvoid buildReplicationLoad(List<ReplicationSourceInterface> sources, MetricsSink sinkMetrics);\n\torg.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.ReplicationLoadSink getReplicationLoadSink();\n\tList<org.apache.hadoop.hbase.shaded.protobuf.generated.ClusterStatusProtos.ReplicationLoadSource> getReplicationLoadSourceEntries();\n\t// sinkToString\n\tString sinkToString();\n\t// sourceToString\n\tString sourceToString();\n}", "des": "This class is used for exporting some of the info from replication metrics"}
{"index": 5705, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ReplicationLogCleaner {\n\t// Determines which of the given files are safe to delete\n\tIterable<org.apache.hadoop.fs.FileStatus> getDeletableFiles(Iterable<org.apache.hadoop.fs.FileStatus> files);\n\t// this method is used to pass some instance into subclass\n\tvoid init(Map<String,Object> params);\n\tboolean isStopped();\n\t// Will be called after cleaner run.\n\tvoid postClean();\n\t// Used to do some initialize work before every period clean\n\tvoid preClean();\n\tvoid stop(String why);\n}", "des": "Implementation of a log cleaner that checks if a log is still scheduled for replication before deleting it when its TTL is over."}
{"index": 5706, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ReplicationService {\n\t// Initializes the replication service object.\n\tvoid initialize(Server rs, org.apache.hadoop.fs.FileSystem fs, org.apache.hadoop.fs.Path logdir, org.apache.hadoop.fs.Path oldLogDir, WALFactory walFactory);\n\t// Refresh and Get ReplicationLoad\n\tReplicationLoad refreshAndGetReplicationLoad();\n\t// Start replication services.\n\tvoid startReplicationService();\n\t// Stops replication service.\n\tvoid stopReplicationService();\n}", "des": "Gateway to Cluster Replication. Used by HRegionServer. One such application is a cross-datacenter replication service that can keep two hbase clusters in sync."}
{"index": 5707, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ReplicationSourceService {\n\t// Returns a Handler to handle peer procedures.\n\tPeerProcedureHandler getPeerProcedureHandler();\n\t// Returns the replication manager\n\tReplicationSourceManager getReplicationManager();\n\t// Return the replication peers.\n\tReplicationPeers getReplicationPeers();\n\t// Returns an info provider for sync replication peer.\n\tSyncReplicationPeerInfoProvider getSyncReplicationPeerInfoProvider();\n}", "des": "A source for a replication stream has to expose this service. This service allows an application to hook into the regionserver and watch for new transactions."}
{"index": 5708, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ReplicationThrottler {\n\t// Add current size to the current cycle's total push size\n\tvoid addPushSize(long size);\n\t// Get how long the caller should sleep according to the current size and current cycle's total push size and start tick, return the sleep interval for throttling control.\n\tlong getNextSleepInterval(int size);\n\t// If throttling is enabled\n\tboolean isEnabled();\n\t// Reset the cycle start tick to NOW\n\tvoid resetStartTick();\n\tvoid setBandwidth(double bandwidth);\n}", "des": "Per-peer per-node throttling controller for replication: enabled if bandwidth > 0, a cycle = 100ms, by throttling we guarantee data pushed to peer within each cycle won't exceed 'bandwidth' bytes"}
{"index": 5709, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ReversedMobStoreScanner {\n\t// Close the KeyValue scanner.\n\tvoid close();\n\t// Firstly reads the cells from the HBase.\n\tboolean next(List<Cell> outResult, ScannerContext ctx);\n\t// Called after a batch of rows scanned and set to be returned to client.\n\tvoid shipped();\n}", "des": "ReversedMobStoreScanner extends from ReversedStoreScanner, and is used to support reversed scanning in both the memstore and the MOB store."}
{"index": 5710, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RollingStatCalculator {\n\t// Returns deviation of the data values that are in the current list of data values\n\tdouble getDeviation();\n\t// Returns mean of the data values that are in the current list of data values\n\tdouble getMean();\n\t// Inserts given data value to array of data values to be considered for statistics calculation\n\tvoid insertDataValue(long data);\n}", "des": "This class maintains mean and variation for any sequence of input provided to it. It is initialized with number of rolling periods which basically means the number of past inputs whose data will be considered to maintain mean and variation. It will use O(N) memory to maintain these statistics, where N is number of look up periods it was initialized with. If zero is passed during initialization then it will maintain mean and variance from the start. It will use O(1) memory only. But note that since it will maintain mean / variance from the start the statistics may behave like constants and may ignore short trends. All operations are O(1) except the initialization which is O(N)."}
{"index": 5711, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RowBloomContext {\n\t// Adds the last bloom key to the HFile Writer as part of StorefileWriter close.\n\tvoid addLastBloomKey(HFile.Writer writer);\n\t// Returns true if the cell is a new key as per the bloom type\n\tprotected boolean isNewKey(Cell cell);\n}", "des": "Handles ROW bloom related context. It works with both ByteBufferedCell and byte[] backed cells"}
{"index": 5712, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class RowColBloomContext {\n\t// Adds the last bloom key to the HFile Writer as part of StorefileWriter close.\n\tvoid addLastBloomKey(HFile.Writer writer);\n\t// Returns true if the cell is a new key as per the bloom type\n\tprotected boolean isNewKey(Cell cell);\n}", "des": "Handles ROWCOL bloom related context. It can work with both BytebufferdCells and byte[] backed cells"}
{"index": 5713, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface RSProcedureCallable {\n\t// Event type used to select thread pool.\n\tEventType getEventType();\n\t// Initialize the callable\n\tvoid init(byte[] parameter, HRegionServer rs);\n}", "des": "A general interface for a sub procedure runs at RS side."}
{"index": 5714, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ScannerContext {\n\t// Get the metrics instance.\n\tServerSideScanMetrics getMetrics();\n\t// In this mode, only block size progress is tracked, and limits are ignored.\n\tboolean getSkippingRow();\n\tboolean isTrackingMetrics();\n\tstatic ScannerContext.Builder newBuilder();\n\tstatic ScannerContext.Builder newBuilder(boolean keepProgress);\n}", "des": "ScannerContext instances encapsulate limit tracking AND progress towards those limits during invocations of InternalScanner.next(java.util.List) and InternalScanner.next(java.util.List)."}
{"index": 5715, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum ScannerContext.LimitScope {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ScannerContext.LimitScope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ScannerContext.LimitScope[] values();\n}", "des": "The various scopes where a limit can be enforced. Used to differentiate when a limit should be enforced or not."}
{"index": 5716, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum ScanQueryMatcher.MatchCode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ScanQueryMatcher.MatchCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ScanQueryMatcher.MatchCode[] values();\n}", "des": "ScanQueryMatcher.match(org.apache.hadoop.hbase.Cell) return codes. These instruct the scanner moving through memstores and StoreFiles what to do with the current KeyValue."}
{"index": 5717, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum ScanType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ScanType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ScanType[] values();\n}", "des": "Enum to distinguish general scan types."}
{"index": 5718, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ScopeWALEntryFilter {\n\t// Applies the filter, possibly returning a different Entry instance.\n\tWAL.Entry filter(WAL.Entry entry);\n\t// Applies the filter, possibly returning a different Cell instance.\n\tCell filterCell(WAL.Entry entry, Cell cell);\n}", "des": "Keeps KVs that are scoped other than local"}
{"index": 5719, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class SecurityUtil {\n\t// Get the user name from a principal\n\tstatic String getPrincipalWithoutRealm(String principal);\n\t// Get the user name from a principal\n\tstatic String getUserFromPrincipal(String principal);\n}", "des": "Security related generic utility methods."}
{"index": 5720, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ServerListener {\n\t// The server has joined the cluster.\n\tdefault void serverAdded(ServerName serverName);\n\t// The server was removed from the cluster.\n\tdefault void serverRemoved(ServerName serverName);\n\t// Started waiting on RegionServers to check-in.\n\tdefault void waiting();\n}", "des": "Get notification of server registration events. The invocations are inline so make sure your implementation is fast or else you'll slow hbase."}
{"index": 5721, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ServerProcedureInterface {\n\t// Returns Name of this server instance.\n\tServerName getServerName();\n\t// Given an operation type we can take decisions about what to do with pending operations.\n\tServerProcedureInterface.ServerOperationType getServerOperationType();\n\t// Returns True if this server has an hbase:meta table region.\n\tboolean hasMetaTableRegion();\n}", "des": "Procedures that handle servers -- e.g. server crash -- must implement this Interface. It is used by the procedure runner to figure locking and what queuing."}
{"index": 5722, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class SharedMemoryMmapIOEngine {\n\t// Transfers data from IOEngine to a Cacheable object.\n\tCacheable read(org.apache.hadoop.hbase.io.hfile.bucket.BucketEntry be);\n\t// IOEngine uses shared memory means, when reading Cacheable from it, those refers to the same memory area as used by the Engine for caching it.\n\tboolean usesSharedMemory();\n}", "des": "IO engine that stores data in pmem devices such as DCPMM. This engine also mmaps the file from the given path. But note that this path has to be a path on the pmem device so that when mmapped the file's address is mapped to the Pmem's address space and not in the DRAM. Since this address space is exclusive for the Pmem device there is no swapping out of the mmapped contents that generally happens when DRAM's free space is not enough to hold the specified file's mmapped contents. This gives us the option of using the MemoryType#SHARED type when serving the data from this pmem address space. We need not copy the blocks to the onheap space as we need to do for the case of ExclusiveMemoryMmapIOEngine."}
{"index": 5723, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ShutdownHook {\n\t// Install a shutdown hook that calls stop on the passed Stoppable and then thread joins against the passed threadToJoin.\n\tstatic void install(org.apache.hadoop.conf.Configuration conf, org.apache.hadoop.fs.FileSystem fs, Stoppable stop, Thread threadToJoin);\n\t// Main to test basic functionality.\n\tstatic void main(String[] args);\n}", "des": "Manage regionserver shutdown hooks."}
{"index": 5724, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class SnapshotFileCache {\n\t// Check to see if any of the passed file names is contained in any of the snapshots.\n\tIterable<org.apache.hadoop.fs.FileStatus> getUnreferencedFiles(List<org.apache.hadoop.fs.FileStatus> files, SnapshotManager snapshotManager);\n\tboolean isStopped();\n\tvoid stop(String why);\n\t// Trigger a cache refresh, even if its before the next cache refresh.\n\tvoid triggerCacheRefreshForTesting();\n}", "des": "Intelligently keep track of all the files for all the snapshots."}
{"index": 5725, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class SnapshotScannerHDFSAclCleaner {\n\t// this method is used to pass some instance into subclass\n\tvoid init(Map<String,Object> params);\n\t// Check if a empty directory with no subdirs or subfiles can be deleted\n\tboolean isEmptyDirDeletable(org.apache.hadoop.fs.Path dir);\n\t// Should the master delete the file or keep it?\n\tprotected boolean isFileDeletable(org.apache.hadoop.fs.FileStatus fStat);\n\tvoid setConf(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Implementation of a file cleaner that checks if a empty directory with no subdirs and subfiles is deletable when user scan snapshot feature is enabled"}
{"index": 5726, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class SnapshotSegmentScanner {\n\t// Close the KeyValue scanner.\n\tvoid close();\n\t// Get the order of this KeyValueScanner.\n\tlong getScannerOrder();\n\t// Return the next Cell in this scanner, iterating the scanner\n\tCell next();\n\t// Look at the next Cell in this scanner, but do not iterate scanner.\n\tCell peek();\n\t// Reseek the scanner at or after the specified KeyValue.\n\tboolean reseek(Cell seekCell);\n\t// Seek the scanner at or after the specified KeyValue.\n\tboolean seek(Cell seekCell);\n}", "des": "A basic SegmentScanner used against an ImmutableScanner snapshot Used flushing where we do a single pass, no reverse scanning or inserts happening. Its a dumbed-down Scanner that can go fast. Like CollectionBackedScanner (but making it know about Segments was onerous)."}
{"index": 5727, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface SpaceQuotaSnapshotNotifier {\n\t// Initializes the notifier.\n\tvoid initialize(Connection conn);\n\t// Informs the cluster of the current state of a space quota for a table.\n\tvoid transitionTable(TableName tableName, SpaceQuotaSnapshot snapshot);\n}", "des": "An interface which abstract away the action taken to enable or disable a space quota violation policy across the HBase cluster. Implementations must have a no-args constructor."}
{"index": 5728, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class SplitLogManagerCoordination.SplitLogManagerDetails {\n\t// Returns a set of failed deletions\n\tSet<String> getFailedDeletions();\n\t// Returns the master value\n\tMasterServices getMaster();\n\t// Returns server name\n\tServerName getServerName();\n\t// Returns map of tasks\n\tConcurrentMap<String,SplitLogManager.Task> getTasks();\n}", "des": "Detail class that shares data between coordination and split log manager"}
{"index": 5729, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface StoreConfigInformation {\n\t// The number of files required before flushes for this store will be blocked.\n\tlong getBlockingFileCount();\n\tString getColumnFamilyName();\n\tlong getCompactionCheckMultiplier();\n\t// Returns Gets the Memstore flush size for the region that this store works with.\n\tlong getMemStoreFlushSize();\n\tRegionInfo getRegionInfo();\n\t// Returns Gets the cf-specific time-to-live for store files.\n\tlong getStoreFileTtl();\n}", "des": "A more restricted interface for HStore. Only gives the caller access to information about store configuration/settings that cannot easily be obtained from XML config object. Example user would be CompactionPolicy that doesn't need entire (H)Store, only this. Add things here as needed."}
{"index": 5730, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum StoreFileTrackerFactory.Trackers {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StoreFileTrackerFactory.Trackers valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StoreFileTrackerFactory.Trackers[] values();\n}", "des": "Maps between configuration names for trackers and implementation classes."}
{"index": 5731, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class StripeStoreEngine {\n\t// Creates an instance of a compaction context specific to this engine.\n\tCompactionContext createCompaction();\n\t// Create the StoreEngine's components.\n\tprotected void createComponents(org.apache.hadoop.conf.Configuration conf, HStore store, CellComparator comparator);\n\tboolean needsCompaction(List<HStoreFile> filesCompacting);\n}", "des": "The storage engine that implements the stripe-based store/compaction scheme."}
{"index": 5732, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class Subprocedure.SubprocedureImpl {\n\t// The implementation of this method should gather and hold required resources (locks, disk space, etc) to satisfy the Procedures barrier condition.\n\tvoid acquireBarrier();\n\t// Users should override this method.\n\tvoid cleanup(Exception e);\n\t// The implementation of this method should act with the assumption that the barrier condition has been satisfied.\n\tbyte[] insideBarrier();\n}", "des": "Empty Subprocedure for testing. Must be public for stubbing used in testing to work."}
{"index": 5733, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface SyncReplicationPeerInfoProvider {\n\t// Check whether the given table is contained in a sync replication peer which can pass the state checker.\n\tboolean checkState(TableName table, BiPredicate<SyncReplicationState,SyncReplicationState> checker);\n\t// Return the peer id and remote WAL directory if the table is synchronously replicated and the state is SyncReplicationState.ACTIVE.\n\tOptional<Pair<String,String>> getPeerIdAndRemoteWALDir(TableName table);\n}", "des": "Get the information for a sync replication peer."}
{"index": 5734, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface TableProcedureInterface {\n\t// Returns the name of the table the procedure is operating on\n\tTableName getTableName();\n\t// Given an operation type we can take decisions about what to do with pending operations.\n\tTableProcedureInterface.TableOperationType getTableOperationType();\n}", "des": "Procedures that operates on a specific Table (e.g. create, delete, snapshot, ...) must implement this interface to allow the system handle the lock/concurrency problems."}
{"index": 5735, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class TableSpaceQuotaSnapshotNotifier {\n\t// Initializes the notifier.\n\tvoid initialize(Connection conn);\n\t// Informs the cluster of the current state of a space quota for a table.\n\tvoid transitionTable(TableName tableName, SpaceQuotaSnapshot snapshot);\n}", "des": "A SpaceQuotaSnapshotNotifier which uses the hbase:quota table."}
{"index": 5736, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface ThroughputController {\n\t// Control the throughput.\n\tlong control(String name, long size);\n\t// Finish the controller.\n\tvoid finish(String name);\n\t// Setup controller for the given region server.\n\tvoid setup(RegionServerServices server);\n\t// Start the throughput controller.\n\tvoid start(String name);\n}", "des": "A utility that constrains the total throughput of one or more simultaneous flows by sleeping when necessary."}
{"index": 5737, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class TimeoutExceptionInjector {\n\t// For all time forward, do not throw an error because the process has completed.\n\tvoid complete();\n\tlong getMaxTime();\n\t// Start a timer to fail a process if it takes longer than the expected time to complete.\n\tvoid start();\n\t// Trigger the timer immediately.\n\tvoid trigger();\n}", "des": "Time a given process/operation and report a failure if the elapsed time exceeds the max allowed time."}
{"index": 5738, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class UnassignRegionHandler {\n\tstatic UnassignRegionHandler create(HRegionServer server, String encodedName, long closeProcId, boolean abort, ServerName destination, boolean evictCache);\n\t// Event exception handler, may be overridden\n\tprotected void handleException(Throwable t);\n\t// This method is the main processing loop to be implemented by the various subclasses.\n\tvoid process();\n}", "des": "Handles closing of a region on a region server."}
{"index": 5739, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class UncompressedBlockSizePredicator {\n\t// Dummy implementation that always returns true.\n\tboolean shouldFinishBlock(int uncompressed);\n\t// Empty implementation.\n\tvoid updateLatestBlockSizes(HFileContext context, int uncompressed, int compressed);\n}", "des": "This BlockCompressedSizePredicator implementation doesn't actually performs any predicate and simply returns true on shouldFinishBlock. This is the default implementation if hbase.block.compressed.size.predicator property is not defined."}
{"index": 5740, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class VisibilityNewVersionBehaivorTracker {\n\t// Add the specified cell to the list of deletes to check against for this row operation.\n\tvoid add(Cell cell);\n\t// This method is not idempotent, we will save some info to judge VERSION_MASKED.\n\tDeleteTracker.DeleteResult isDeleted(Cell cell);\n\tprotected void resetInternal();\n}", "des": "Similar to MvccSensitiveTracker but tracks the visibility expression also before deciding if a Cell can be considered deleted"}
{"index": 5741, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class VisibilityScanDeleteTracker {\n\t// Add the specified Cell to the list of deletes to check against for this row operation.\n\tvoid add(Cell delCell);\n\t// Check if the specified Cell buffer has been deleted by a previously seen delete.\n\tDeleteTracker.DeleteResult isDeleted(Cell cell);\n\t// Called between rows.\n\tvoid reset();\n}", "des": "Similar to ScanDeletTracker but tracks the visibility expression also before deciding if a Cell can be considered deleted"}
{"index": 5742, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class WAL.Entry {\n\t// Gets the edit\n\tWALEdit getEdit();\n\t// Gets the key\n\tWALKeyImpl getKey();\n}", "des": "Utility class that lets us keep track of the edit with it's key."}
{"index": 5743, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum WALActionsListener.RollRequestReason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic WALActionsListener.RollRequestReason valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic WALActionsListener.RollRequestReason[] values();\n}", "des": "The reason for the log roll request."}
{"index": 5744, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface WALObserver {\n\t// Called after rolling the current WAL\n\tdefault void postWALRoll(ObserverContext<? extends WALCoprocessorEnvironment> ctx, org.apache.hadoop.fs.Path oldPath, org.apache.hadoop.fs.Path newPath);\n\t// Called before rolling the current WAL\n\tdefault void preWALRoll(ObserverContext<? extends WALCoprocessorEnvironment> ctx, org.apache.hadoop.fs.Path oldPath, org.apache.hadoop.fs.Path newPath);\n}", "des": "It's provided to have a way for coprocessors to observe, rewrite, or skip WALEdits as they are being written to the WAL. Note that implementers of WALObserver will not see WALEdits that report themselves as empty via WALEdit.isEmpty(). RegionObserver provides hooks for adding logic for WALEdits in the region context during reconstruction. Defines coprocessor hooks for interacting with operations on the WAL. Since most implementations will be interested in only a subset of hooks, this class uses 'default' functions to avoid having to add unnecessary overrides. When the functions are non-empty, it's simply to satisfy the compiler by returning value of expected (non-void) type. It is done in a way that these default definitions act as no-op. So our suggestion to implementation would be to not call these 'default' methods from overrides. Exception Handling For all functions, exception handling is done as follows: Exceptions of type IOException are reported back to client. For any other kind of exception: If the configuration CoprocessorHost.ABORT_ON_ERROR_KEY is set to true, then the server aborts. Otherwise, coprocessor is removed from the server and DoNotRetryIOException is returned to the client."}
{"index": 5745, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface WALStreamReader {\n\t// Override to remove the 'throws IOException' as we are just a reader.\n\tvoid close();\n\t// Get the current reading position.\n\tlong getPosition();\n\t// Read the next entry in WAL.\n\tdefault WAL.Entry next();\n\t// Read the next entry in WAL, use the given WAL.Entry if not null to hold the data.\n\tWAL.Entry next(WAL.Entry reuse);\n}", "des": "A one way WAL reader, without reset and seek support."}
{"index": 5746, "repo": "hbase-server-3.0.0-alpha-4", "code": "Interface WALTailingReader {\n\t// Override to remove the 'throws IOException' as we are just a reader.\n\tvoid close();\n\t// Get the current reading position.\n\tlong getPosition();\n\t// Read the next entry and make sure the position after reading does not go beyond the given limit.\n\tWALTailingReader.Result next(long limit);\n\t// Reopen the reader to see if there is new data arrives, and also seek(or skip) to the given position.\n\tvoid resetTo(long position, boolean resetCompression);\n}", "des": "A WAL reader which is designed for be able to tailing the WAL file which is currently being written. It adds support"}
{"index": 5747, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class WriteSinkCoprocessor {\n\tOptional<RegionObserver> getRegionObserver();\n\t// This will be called for every batch mutation operation happening at the server.\n\tvoid preBatchMutate(ObserverContext<RegionCoprocessorEnvironment> c, MiniBatchOperationInProgress<Mutation> miniBatchOp);\n\t// Called before the region is reported as open to the master.\n\tvoid preOpen(ObserverContext<RegionCoprocessorEnvironment> e);\n}", "des": ""}
{"index": 5748, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class YammerHistogramUtils {\n\t// Returns a summary of hist.\n\tstatic String getHistogramReport(com.codahale.metrics.Histogram hist);\n\t// Returns pretty summary of hist.\n\tstatic String getPrettyHistogramReport(com.codahale.metrics.Histogram h);\n\t// Returns an abbreviated summary of hist.\n\tstatic String getShortHistogramReport(com.codahale.metrics.Histogram hist);\n\t// Create a new Histogram instance.\n\tstatic com.codahale.metrics.Histogram newHistogram(com.codahale.metrics.Reservoir sample);\n}", "des": "Utility functions for working with Yammer Metrics."}
{"index": 5749, "repo": "hbase-server-3.0.0-alpha-4", "code": "Class ZKPermissionWatcher {\n\tvoid close();\n\t// Delete the acl notify node of namespace\n\tvoid deleteNamespaceACLNode(String namespace);\n\t// Delete the acl notify node of table\n\tvoid deleteTableACLNode(TableName tableName);\n\tvoid nodeChildrenChanged(String path);\n\tvoid nodeCreated(String path);\n\tvoid nodeDataChanged(String path);\n\tvoid nodeDeleted(String path);\n\tvoid start();\n\t// Write a table's access controls to the permissions mirror in zookeeper\n\tvoid writeToZookeeper(byte[] entry, byte[] permsData);\n}", "des": "Handles synchronization of access control list entries and updates throughout all nodes in the cluster. The AccessController instance on the _acl_ table regions, creates a znode for each table as /hbase/acl/tablename, with the znode data containing a serialized list of the permissions granted for the table. The AccessController instances on all other cluster hosts watch the znodes for updates, which trigger updates in the AuthManager permission cache."}
{"index": 5750, "repo": "hbase-server-3.0.0-alpha-4", "code": "Enum ZKSplitLogManagerCoordination.TaskFinisher.Status {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ZKSplitLogManagerCoordination.TaskFinisher.Status valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ZKSplitLogManagerCoordination.TaskFinisher.Status[] values();\n}", "des": "status that can be returned finish()"}
{"index": 5751, "repo": "fontbox-3.0.0-beta1", "code": "Class AFMParser {\n\t// This will parse the AFM document.\n\tFontMetrics parse();\n\t// This will parse the AFM document.\n\tFontMetrics parse(boolean reducedDataset);\n}", "des": "This class is used to parse AFM(Adobe Font Metrics) documents."}
{"index": 5752, "repo": "fontbox-3.0.0-beta1", "code": "Class CFFEncoding {\n\t// For use by subclasses only.\n\tprotected void add(int code, int sid);\n\t// Adds a new code/SID combination to the encoding.\n\tvoid add(int code, int sid, String name);\n}", "des": "A CFF Type 1-equivalent Encoding. An encoding is an array of codes associated with some or all glyphs in a font"}
{"index": 5753, "repo": "fontbox-3.0.0-beta1", "code": "Class CFFOperator {\n\t// Returns the operator name corresponding to the given one byte representation.\n\tstatic String getOperator(int b0);\n\t// Returns the operator name corresponding to the given two byte representation.\n\tstatic String getOperator(int b0, int b1);\n}", "des": "This class represents a CFF operator."}
{"index": 5754, "repo": "fontbox-3.0.0-beta1", "code": "Class CFFParser {\n\t// Parse CFF font using byte array, also passing in a byte source for future use.\n\tList<CFFFont> parse(byte[] bytes, CFFParser.ByteSource source);\n\t// Parse CFF font using a RandomAccessRead as input.\n\tList<CFFFont> parse(org.apache.pdfbox.io.RandomAccessRead randomAccessRead);\n}", "des": "This class represents a parser for a CFF font."}
{"index": 5755, "repo": "fontbox-3.0.0-beta1", "code": "Interface CmapLookup {\n\t// Returns all possible character codes for the given gid, or null if there is none.\n\tList<Integer> getCharCodes(int gid);\n\t// Returns the GlyphId linked with the given character code.\n\tint getGlyphId(int codePointAt);\n}", "des": "An interface that abstracts the cid <-> codepoint lookup functionality of cmap."}
{"index": 5756, "repo": "fontbox-3.0.0-beta1", "code": "Class CMapParser {\n\t// This will parse the stream and create a cmap object.\n\tCMap parse(org.apache.pdfbox.io.RandomAccessRead randomAcccessRead);\n\t// Parses a predefined CMap.\n\tCMap parsePredefined(String name);\n}", "des": "Parses a CMap stream."}
{"index": 5757, "repo": "fontbox-3.0.0-beta1", "code": "Class CmapSubtable {\n\t// Returns all possible character codes for the given gid, or null if there is none.\n\tList<Integer> getCharCodes(int gid);\n\t// Returns the GlyphId linked with the given character code.\n\tint getGlyphId(int characterCode);\n\tint getPlatformEncodingId();\n\tint getPlatformId();\n\tvoid setPlatformEncodingId(int platformEncodingIdValue);\n\tvoid setPlatformId(int platformIdValue);\n}", "des": "A \"cmap\" subtable."}
{"index": 5758, "repo": "fontbox-3.0.0-beta1", "code": "Class CodespaceRange {\n\t// Returns the length of the codes of the codespace.\n\tint getCodeLength();\n\t// Returns true if the given number of code bytes match this codespace range.\n\tboolean isFullMatch(byte[] code, int codeLen);\n\t// Returns true if the given code bytes match this codespace range.\n\tboolean matches(byte[] code);\n}", "des": "This represents a single entry in the codespace range."}
{"index": 5759, "repo": "fontbox-3.0.0-beta1", "code": "Class Composite {\n\t// This will add a composite part.\n\tvoid addPart(CompositePart part);\n\t// Getter for property name.\n\tString getName();\n\t// Getter for property parts.\n\tList<CompositePart> getParts();\n}", "des": "This class represents composite character data."}
{"index": 5760, "repo": "fontbox-3.0.0-beta1", "code": "Class CompositePart {\n\t// Getter for property name.\n\tString getName();\n\t// Getter for property xDisplacement.\n\tint getXDisplacement();\n\t// Getter for property yDisplacement.\n\tint getYDisplacement();\n}", "des": "This class represents a part of composite character data."}
{"index": 5761, "repo": "fontbox-3.0.0-beta1", "code": "Class Encoding {\n\t// This will add a character encoding.\n\tprotected void addCharacterEncoding(int code, String name);\n\t// This will get the character code for the name.\n\tInteger getCode(String name);\n\t// Returns an unmodifiable view of the code to name mapping.\n\tMap<Integer,String> getCodeToNameMap();\n\t// This will take a character code and get the name from the code.\n\tString getName(int code);\n}", "des": "A PostScript Encoding vector."}
{"index": 5762, "repo": "fontbox-3.0.0-beta1", "code": "Class FontFileFinder {\n\t// Automagically finds a list of font files on local system.\n\tList<URI> find();\n\t// Searches a given directory for font files.\n\tList<URI> find(String dir);\n}", "des": "Helps to autodetect/locate available operating system fonts. This class is based on a class provided by Apache FOP. see org.apache.fop.fonts.autodetect.FontFileFinder"}
{"index": 5763, "repo": "fontbox-3.0.0-beta1", "code": "Class GlyfDescript {\n\t// Returns the number of contours.\n\tint getContourCount();\n\t// Returns the hinting instructions.\n\tint[] getInstructions();\n\t// Resolve all parts of an composite glyph.\n\tvoid resolve();\n}", "des": "This class is based on code from Apache Batik a subproject of Apache XMLGraphics. see http://xmlgraphics.apache.org/batik/ for further details."}
{"index": 5764, "repo": "fontbox-3.0.0-beta1", "code": "Class GlyfSimpleDescript {\n\t// Returns the index of the ending point of the given contour.\n\tint getEndPtOfContours(int i);\n\t// Returns the flags of the given point.\n\tbyte getFlags(int i);\n\t// Returns the number of points.\n\tint getPointCount();\n\t// Returns the x coordinate of the given point.\n\tshort getXCoordinate(int i);\n\t// Returns the y coordinate of the given point.\n\tshort getYCoordinate(int i);\n\t// Returns whether this point is a composite or not.\n\tboolean isComposite();\n}", "des": "This class is based on code from Apache Batik a subproject of Apache XMLGraphics. see http://xmlgraphics.apache.org/batik/ for further details."}
{"index": 5765, "repo": "fontbox-3.0.0-beta1", "code": "Class GlyphData {\n\tBoundingBox getBoundingBox();\n\t// Returns the description of the glyph.\n\tGlyphDescription getDescription();\n\tshort getNumberOfContours();\n\t// Returns the path of the glyph.\n\tGeneralPath getPath();\n\t// Returns the xMax value.\n\tshort getXMaximum();\n\t// Returns the xMin value.\n\tshort getXMinimum();\n\t// Returns the yMax value.\n\tshort getYMaximum();\n\t// Returns the yMin value.\n\tshort getYMinimum();\n}", "des": "A glyph data record in the glyf table."}
{"index": 5766, "repo": "fontbox-3.0.0-beta1", "code": "Class HorizontalMetricsTable {\n\t// Returns the advance width for the given GID.\n\tint getAdvanceWidth(int gid);\n\t// Returns the left side bearing for the given GID.\n\tint getLeftSideBearing(int gid);\n}", "des": "A table in a true type font."}
{"index": 5767, "repo": "fontbox-3.0.0-beta1", "code": "Class KerningTable {\n\t// Obtain first subtable that supports non-cross-stream horizontal kerning.\n\tKerningSubtable getHorizontalKerningSubtable();\n\t// Obtain first subtable that supports horizontal kerning with specified cross stream.\n\tKerningSubtable getHorizontalKerningSubtable(boolean cross);\n}", "des": "A 'kern' table in a true type font."}
{"index": 5768, "repo": "fontbox-3.0.0-beta1", "code": "Class KernPair {\n\t// Getter for property firstKernCharacter.\n\tString getFirstKernCharacter();\n\t// Getter for property secondKernCharacter.\n\tString getSecondKernCharacter();\n\t// Getter for property x.\n\tfloat getX();\n\t// Getter for property y.\n\tfloat getY();\n}", "des": "This represents some kern pair data."}
{"index": 5769, "repo": "fontbox-3.0.0-beta1", "code": "Enum Language {\n\t// ScriptNames form the basis of identification of the language.\n\tString[] getScriptNames();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Language valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Language[] values();\n}", "des": "Enumerates the languages supported for GSUB operation. In order to support a new language, you need to add it here and then implement the GsubWorker for the given language and return the same from the GsubWorkerFactory.getGsubWorker(org.apache.fontbox.ttf.CmapLookup, GsubData)"}
{"index": 5770, "repo": "fontbox-3.0.0-beta1", "code": "Class Ligature {\n\t// Getter for property ligature.\n\tString getLigature();\n\t// Getter for property successor.\n\tString getSuccessor();\n}", "des": "This class represents a ligature, which is an entry of the CharMetrics."}
{"index": 5771, "repo": "fontbox-3.0.0-beta1", "code": "Class NamingTable {\n\t// Returns the font family name, in English.\n\tString getFontFamily();\n\t// Returns the font sub family name, in English.\n\tString getFontSubFamily();\n\t// Returns a name from the table, or null it it does not exist.\n\tString getName(int nameId, int platformId, int encodingId, int languageId);\n\t// This will get the name records for this naming table.\n\tList<NameRecord> getNameRecords();\n\t// Returns the PostScript name.\n\tString getPostScriptName();\n}", "des": "A table in a true type font."}
{"index": 5772, "repo": "fontbox-3.0.0-beta1", "code": "Class NativeFontDirFinder {\n\t// Generic method used by Mac and Unix font finders.\n\tList<File> find();\n\t// Returns an array of directories to search for fonts in.\n\tprotected abstract String[] getSearchableDirectories();\n}", "des": "Native font finder base class. This class is based on a class provided by Apache FOP. see org.apache.fop.fonts.autodetect.NativeFontDirFinder"}
{"index": 5773, "repo": "fontbox-3.0.0-beta1", "code": "Class OpenTypeFont {\n\t// Get the \"CFF\" table for this OTF.\n\tCFFTable getCFF();\n\t// Get the glyf table for this TTF.\n\tGlyphTable getGlyph();\n\t// Returns the path for the character with the given name.\n\tGeneralPath getPath(String name);\n\t// Returns true if this font uses OpenType Layout (Advanced Typographic) tables.\n\tboolean hasLayoutTables();\n\t// Returns true if this font is a PostScript outline font.\n\tboolean isPostScript();\n\t// Returns true if this font is supported.\n\tboolean isSupportedOTF();\n}", "des": "An OpenType (OTF/TTF) font."}
{"index": 5774, "repo": "fontbox-3.0.0-beta1", "code": "Class PfbParser {\n\t// Returns the pfb data as stream.\n\tInputStream getInputStream();\n\t// Returns the lengths.\n\tint[] getLengths();\n\t// Returns the pfbdata.\n\tbyte[] getPfbdata();\n\t// Returns the first segment\n\tbyte[] getSegment1();\n\t// Returns the second segment\n\tbyte[] getSegment2();\n\t// Returns the size of the pfb-data.\n\tint size();\n}", "des": "Parser for a pfb-file."}
{"index": 5775, "repo": "fontbox-3.0.0-beta1", "code": "Class SubstitutingCmapLookup {\n\t// Returns all possible character codes for the given gid, or null if there is none.\n\tList<Integer> getCharCodes(int gid);\n\t// Returns the GlyphId linked with the given character code.\n\tint getGlyphId(int characterCode);\n}", "des": "A cmap lookup that performs substitution via the 'GSUB' table."}
{"index": 5776, "repo": "fontbox-3.0.0-beta1", "code": "Class TrackKern {\n\t// Getter for property degree.\n\tint getDegree();\n\t// Getter for property maxKern.\n\tfloat getMaxKern();\n\t// Getter for property maxPointSize.\n\tfloat getMaxPointSize();\n\t// Getter for property minKern.\n\tfloat getMinKern();\n\t// Getter for property minPointSize.\n\tfloat getMinPointSize();\n}", "des": "This class represents a piece of track kerning data."}
{"index": 5777, "repo": "fontbox-3.0.0-beta1", "code": "Class TrueTypeCollection {\n\tvoid close();\n\t// Get a TT font from a collection.\n\tTrueTypeFont getFontByName(String name);\n\t// Run the callback for each TT font in the collection.\n\tvoid processAllFonts(TrueTypeCollection.TrueTypeFontProcessor trueTypeFontProcessor);\n}", "des": "A TrueType Collection, now more properly known as a \"Font Collection\" as it may contain either TrueType or OpenType fonts."}
{"index": 5778, "repo": "fontbox-3.0.0-beta1", "code": "Class TTFParser {\n\tprotected boolean allowCFF();\n\t// Parse a RandomAccessRead and return a TrueType font.\n\tTrueTypeFont parse(org.apache.pdfbox.io.RandomAccessRead randomAccessRead);\n\t// Parse an input stream and return a TrueType font that is to be embedded.\n\tTrueTypeFont parseEmbedded(InputStream inputStream);\n\tprotected TTFTable readTable(String tag);\n}", "des": "TrueType font file parser."}
{"index": 5779, "repo": "fontbox-3.0.0-beta1", "code": "Class TTFSubsetter {\n\t// Add the given character code to the subset.\n\tvoid add(int unicode);\n\t// Add the given character codes to the subset.\n\tvoid addAll(Set<Integer> unicodeSet);\n\tvoid addGlyphIds(Set<Integer> allGlyphIds);\n\t// Returns the map of new -> old GIDs.\n\tMap<Integer,Integer> getGIDMap();\n\t// Sets the prefix to add to the font's PostScript name.\n\tvoid setPrefix(String prefix);\n\t// Write the subfont to the given output stream.\n\tvoid writeToStream(OutputStream os);\n}", "des": "Subsetter for TrueType (TTF) fonts."}
{"index": 5780, "repo": "fontbox-3.0.0-beta1", "code": "Class VerticalMetricsTable {\n\t// Returns the advance height for the given GID.\n\tint getAdvanceHeight(int gid);\n\t// Returns the top sidebearing for the given GID\n\tint getTopSideBearing(int gid);\n}", "des": "A vertical metrics 'vmtx' table in a TrueType or OpenType font. This table is required by the OpenType CJK Font Guidelines for \"all OpenType fonts that are used for vertical writing\". This table is specified in both the TrueType and OpenType specifications."}
{"index": 5781, "repo": "fontbox-3.0.0-beta1", "code": "Class WGL4Names {\n\t// Returns a new array with all glyph names.\n\tstatic String[] getAllNames();\n\t// Returns the index of the glyph with the given name.\n\tstatic Integer getGlyphIndex(String name);\n\t// Returns the name of the glyph at the given index.\n\tstatic String getGlyphName(int index);\n}", "des": "Windows Glyph List 4 (WGL4) names for Mac glyphs."}
{"index": 5782, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum AuxServiceFile.TypeEnum {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AuxServiceFile.TypeEnum valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AuxServiceFile.TypeEnum[] values();\n}", "des": "Config Type."}
{"index": 5783, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class CGroupElasticMemoryController {\n\t// Checks if the CGroupElasticMemoryController is available on this system.\n\tstatic boolean isAvailable();\n\t// Main OOM listening thread.\n\tvoid run();\n\t// Stop listening to the cgroup.\n\tvoid stopListening();\n}", "des": "This thread controls memory usage using cgroups. It listens to out of memory events of all the containers together, and if we go over the limit picks a container to kill. The algorithm that picks the container is a plugin."}
{"index": 5784, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum CGroupsHandler.CGroupController {\n\tString getName();\n\t// Get the list of valid cgroup names.\n\tstatic Set<String> getValidCGroups();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CGroupsHandler.CGroupController valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CGroupsHandler.CGroupController[] values();\n}", "des": "List of supported cgroup subsystem types."}
{"index": 5785, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ConfigurationNodeAttributesProvider {\n\t// method for subclasses to cleanup.\n\tprotected void cleanUp();\n\t// Creates a timer task which be scheduled periodically by the provider, and the task is responsible to update node descriptors to the provider.\n\tTimerTask createTimerTask();\n\tSet<org.apache.hadoop.yarn.api.records.NodeAttribute> parseAttributes(String config);\n\tprotected void serviceInit(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Configuration based node attributes provider."}
{"index": 5786, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ConfigurationNodeLabelsProvider {\n\t// method for subclasses to cleanup.\n\tprotected void cleanUp();\n\t// Creates a timer task which be scheduled periodically by the provider, and the task is responsible to update node descriptors to the provider.\n\tTimerTask createTimerTask();\n\tprotected void serviceInit(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Provides Node's Labels by constantly monitoring the configuration."}
{"index": 5787, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum ContainerExecutor.ExitCode {\n\t// Get the exit code as an int.\n\tint getExitCode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerExecutor.ExitCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerExecutor.ExitCode[] values();\n}", "des": "The container exit code."}
{"index": 5788, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum ContainerExecutor.Signal {\n\t// Get the signal number.\n\tint getValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerExecutor.Signal valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerExecutor.Signal[] values();\n}", "des": "The constants for the signals."}
{"index": 5789, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ContainerReapContext {\n\t// Get the container set for the context.\n\tContainer getContainer();\n\t// Get the user set for the context.\n\tString getUser();\n}", "des": "Encapsulate the details needed to reap a container."}
{"index": 5790, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ContainerReapContext.Builder {\n\t// Builds the context with the attributes set.\n\tContainerReapContext build();\n\t// Set the container within the context.\n\tContainerReapContext.Builder setContainer(Container container);\n\t// Set the set within the context.\n\tContainerReapContext.Builder setUser(String user);\n}", "des": "Builder for the ContainerReapContext."}
{"index": 5791, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ContainerReInitEvent {\n\t// Get the Launch Context to be used for upgrade.\n\torg.apache.hadoop.yarn.api.records.ContainerLaunchContext getReInitLaunchContext();\n\t// Get the ResourceSet.\n\tResourceSet getResourceSet();\n\t// Should this re-Initialization be auto-committed.\n\tboolean isAutoCommit();\n}", "des": "ContainerEvent sent by ContainerManager to ContainerImpl to re-initiate Container."}
{"index": 5792, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum ContainerSchedulerEventType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerSchedulerEventType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerSchedulerEventType[] values();\n}", "des": "Event types associated with ContainerSchedulerEvent."}
{"index": 5793, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum ContainersMonitorImpl.ContainerMetric {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainersMonitorImpl.ContainerMetric valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainersMonitorImpl.ContainerMetric[] values();\n}", "des": "Type of container metric."}
{"index": 5794, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum ContainerState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerState[] values();\n}", "des": "States used by the container state machine."}
{"index": 5795, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class DefaultOOMHandler {\n\tprotected CGroupsHandler getCGroupsHandler();\n\t// Choose and kill a container in case of OOM.\n\tprotected boolean killContainer();\n\t// It is called when the node is under an OOM condition.\n\tvoid run();\n}", "des": "A very basic OOM handler implementation. See the javadoc on the run() method for details."}
{"index": 5796, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class DeletionTaskRecoveryInfo {\n\t// Return the deletion timestamp.\n\tlong getDeletionTimestamp();\n\t// Return all of the dependent DeletionTasks.\n\tList<Integer> getSuccessorTaskIds();\n\t// Return the recovered DeletionTask.\n\tDeletionTask getTask();\n}", "des": "Encapsulates the recovery info needed to recover a DeletionTask from the NM state store."}
{"index": 5797, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum DeletionTaskType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DeletionTaskType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DeletionTaskType[] values();\n}", "des": "Available types of DeletionTasks."}
{"index": 5798, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Interface DevicePlugin {\n\t// Called when update node resource.\n\tSet<Device> getDevices();\n\t// Called first when device plugin framework wants to register.\n\tDeviceRegisterRequest getRegisterRequestInfo();\n\t// Asking how these devices should be prepared/used before/when container launch.\n\tDeviceRuntimeSpec onDevicesAllocated(Set<Device> allocatedDevices, YarnRuntimeType yarnRuntime);\n\t// Called after device released.\n\tvoid onDevicesReleased(Set<Device> releasedDevices);\n}", "des": "A must interface for vendor plugin to implement."}
{"index": 5799, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum DirectoryCollection.DiskErrorCause {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DirectoryCollection.DiskErrorCause valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DirectoryCollection.DiskErrorCause[] values();\n}", "des": "The enum defines disk failure type."}
{"index": 5800, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum DockerCommandExecutor.DockerContainerStatus {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DockerCommandExecutor.DockerContainerStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DockerCommandExecutor.DockerContainerStatus[] values();\n}", "des": "Potential states that the docker status can return."}
{"index": 5801, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Interface DockerCommandPlugin {\n\t// Cleanup volumes created for one docker container\n\tDockerVolumeCommand getCleanupDockerVolumesCommand(Container container);\n\t// Create volume when needed.\n\tDockerVolumeCommand getCreateDockerVolumeCommand(Container container);\n\t// Update docker run command\n\tvoid updateDockerRunCommand(DockerRunCommand dockerRunCommand, Container container);\n}", "des": "Interface to make different resource plugins (e.g. GPU) can update docker run command without adding logic to Docker runtime."}
{"index": 5802, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class DockerContainerDeletionTask {\n\t// Convert the DockerContainerDeletionTask to the Protobuf representation for storing in the state store and recovery.\n\torg.apache.hadoop.yarn.proto.YarnServerNodemanagerRecoveryProtos.DeletionServiceDeleteTaskProto convertDeletionTaskToProto();\n\t// Get the id of the container to delete.\n\tString getContainerId();\n\t// Delete the specified Docker container.\n\tvoid run();\n}", "des": "DeletionTask handling the removal of Docker containers."}
{"index": 5803, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ExceptionReporter {\n\t// Returns output from health check.\n\tString getHealthReport();\n\t// Returns time stamp when node health check was last run.\n\tlong getLastHealthReportTime();\n\t// Gets whether the node is healthy or not.\n\tboolean isHealthy();\n\t// Report an exception to mark the node as unhealthy.\n\tvoid reportException(Exception ex);\n}", "des": "Simple HealthReporter implementation which reports whether a fatal exception has happened in the NodeManager. See the reportException call of NodeStatusUpdaterImpl"}
{"index": 5804, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Interface HealthReporter {\n\t// Returns output from health check.\n\tString getHealthReport();\n\t// Returns time stamp when node health check was last run.\n\tlong getLastHealthReportTime();\n\t// Gets whether the node is healthy or not.\n\tboolean isHealthy();\n}", "des": "Interface providing information about the health of a service. Associated pieces of information: whether the service is healthy (isHealthy()) report of the healthiness (getHealthReport()) latest timestamp of the health check (getLastHealthReportTime()) Classes implementing this interface are used in NodeHealthCheckerService. Developers are discouraged to implement new Java-based health scripts, they should rather try to implement it as a script and use the NodeHealthScriptRunner implementation."}
{"index": 5805, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum JavaSandboxLinuxContainerRuntime.SandboxMode {\n\tstatic JavaSandboxLinuxContainerRuntime.SandboxMode get(String mode);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JavaSandboxLinuxContainerRuntime.SandboxMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JavaSandboxLinuxContainerRuntime.SandboxMode[] values();\n}", "des": "Enumeration of the modes the JavaSandboxLinuxContainerRuntime can use. See JavaSandboxLinuxContainerRuntime for details on the behavior of each setting."}
{"index": 5806, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum LinuxContainerExecutor.ExitCode {\n\t// Get the exit code as an int.\n\tint getExitCode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LinuxContainerExecutor.ExitCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LinuxContainerExecutor.ExitCode[] values();\n}", "des": "The container exit code."}
{"index": 5807, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Interface LinuxContainerRuntime {\n\tdefault Map<String,org.apache.hadoop.yarn.api.records.LocalResource> getLocalResources(Container container);\n\t// Initialize the runtime.\n\tvoid initialize(org.apache.hadoop.conf.Configuration conf, Context nmContext);\n\t// Return whether the given environment variables indicate that the operation is requesting this runtime.\n\tboolean isRuntimeRequested(Map<String,String> env);\n\tdefault void start();\n\tdefault void stop();\n}", "des": "Linux-specific container runtime implementations must implement this interface."}
{"index": 5808, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum LinuxContainerRuntimeConstants.RuntimeType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LinuxContainerRuntimeConstants.RuntimeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LinuxContainerRuntimeConstants.RuntimeType[] values();\n}", "des": "Linux container runtime types for DelegatingLinuxContainerRuntime."}
{"index": 5809, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class NetworkTagMappingJsonManager {\n\t// Get networkTagHexID for the given container.\n\tString getNetworkTagHexID(Container container);\n\tNetworkTagMappingJsonManager.NetworkTagMapping getNetworkTagMapping();\n\t// Initialize the networkTagMapping manager.\n\tvoid initialize(org.apache.hadoop.conf.Configuration conf);\n}", "des": "The NetworkTagMapping JsonManager implementation."}
{"index": 5810, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Interface NetworkTagMappingManager {\n\t// Get networkTagHexID for the given container.\n\tString getNetworkTagHexID(Container container);\n\t// Initialize the networkTagMapping manager.\n\tvoid initialize(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Base interface for network tag mapping manager."}
{"index": 5811, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum NMStateStoreService.RecoveredContainerType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NMStateStoreService.RecoveredContainerType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NMStateStoreService.RecoveredContainerType[] values();\n}", "des": "Type of post recovery action."}
{"index": 5812, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum NMTimelineEventType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NMTimelineEventType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NMTimelineEventType[] values();\n}", "des": "Type of NMTimelineEvent."}
{"index": 5813, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Interface NodeDescriptorsProvider<T> {\n\t// Provides the descriptors.\n\tSet<T> getDescriptors();\n\t// Sets a set of descriptors to the provider.\n\tvoid setDescriptors(Set<T> descriptors);\n}", "des": "Interface which will be responsible for fetching node descriptors, a node descriptor could be a NodeLabel or a NodeAttribute."}
{"index": 5814, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class NodeHealthCheckerService {\n\tLocalDirsHandlerService getDiskHandler();\n\t// Joining the health reports of the dependent services.\n\tString getHealthReport();\n\t// Returns time stamp when node health check was last run.\n\tlong getLastHealthReportTime();\n\t// Gets whether the node is healthy or not.\n\tboolean isHealthy();\n\t// Propagating an exception to ExceptionReporter.\n\tvoid reportException(Exception exception);\n\tprotected void serviceInit(org.apache.hadoop.conf.Configuration conf);\n}", "des": "This class provides functionality of checking the health of a node and reporting back to the service for which the health checker has been asked to report. It is a CompositeService: every Service must be registered first in serviceInit, and should also implement the HealthReporter interface - otherwise an exception is thrown. Calling functions of HealthReporter merge its dependent services' reports."}
{"index": 5815, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum NodeManager.NodeManagerStatus {\n\tint getExitCode();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NodeManager.NodeManagerStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NodeManager.NodeManagerStatus[] values();\n}", "des": "Node manager return status codes."}
{"index": 5816, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class NodeResourceMonitorImpl {\n\t// Get the resource utilization of the node.\n\torg.apache.hadoop.yarn.api.records.ResourceUtilization getUtilization();\n\t// Initialize the service with the proper parameters.\n\tprotected void serviceInit(org.apache.hadoop.conf.Configuration conf);\n\t// Start the thread that does the node resource utilization monitoring.\n\tprotected void serviceStart();\n\t// Stop the thread that does the node resource utilization monitoring.\n\tprotected void serviceStop();\n}", "des": "Implementation of the node resource monitor. It periodically tracks the resource utilization of the node and reports it to the NM."}
{"index": 5817, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class NvidiaDockerV1CommandPlugin {\n\t// Cleanup volumes created for one docker container\n\tDockerVolumeCommand getCleanupDockerVolumesCommand(Container container);\n\t// Create volume when needed.\n\tDockerVolumeCommand getCreateDockerVolumeCommand(Container container);\n\tprotected boolean requestsGpu(Container container);\n\t// Update docker run command\n\tvoid updateDockerRunCommand(DockerRunCommand dockerRunCommand, Container container);\n}", "des": "Implementation to use nvidia-docker v1 as GPU docker command plugin."}
{"index": 5818, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class NvidiaDockerV2CommandPlugin {\n\t// Cleanup volumes created for one docker container\n\tDockerVolumeCommand getCleanupDockerVolumesCommand(Container container);\n\t// Create volume when needed.\n\tDockerVolumeCommand getCreateDockerVolumeCommand(Container container);\n\tprotected boolean requestsGpu(Container container);\n\t// Update docker run command\n\tvoid updateDockerRunCommand(DockerRunCommand dockerRunCommand, Container container);\n}", "des": "Implementation to use nvidia-docker v2 as GPU docker command plugin."}
{"index": 5819, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum NvidiaGPUPluginForRuntimeV2.DeviceLinkType {\n\tint getWeight();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NvidiaGPUPluginForRuntimeV2.DeviceLinkType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NvidiaGPUPluginForRuntimeV2.DeviceLinkType[] values();\n}", "des": "Different type of link. The weight of each link is a relative value. The higher weight, the higher cost between the GPUs"}
{"index": 5820, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class PerGpuTemperature {\n\t// Get current celsius GPU temperature\n\tFloat getCurrentGpuTemp();\n\t// Get max possible celsius GPU temperature\n\tFloat getMaxGpuTemp();\n\t// Get celsius GPU temperature which could make GPU runs slower\n\tFloat getSlowThresholdGpuTemp();\n\tvoid setCurrentGpuTemp(Float currentGpuTemp);\n\tvoid setMaxGpuTemp(Float maxGpuTemp);\n\tvoid setSlowThresholdGpuTemp(Float slowThresholdGpuTemp);\n}", "des": "Temperature of GPU"}
{"index": 5821, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum PrivilegedOperation.ResultCode {\n\tint getValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PrivilegedOperation.ResultCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PrivilegedOperation.ResultCode[] values();\n}", "des": "Result codes returned from the C container-executor. These must match the values in container-executor.h."}
{"index": 5822, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum PrivilegedOperation.RunAsUserCommand {\n\tint getValue();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PrivilegedOperation.RunAsUserCommand valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PrivilegedOperation.RunAsUserCommand[] values();\n}", "des": "List of commands that the container-executor will execute."}
{"index": 5823, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Interface RecoveryIterator<T> {\n\t// Returns true if the iteration has more elements.\n\tboolean hasNext();\n\t// Returns the next element in the iteration.\n\tT next();\n}", "des": "A wrapper for a Iterator to translate the raw RuntimeExceptions that can be thrown into IOException."}
{"index": 5824, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum ResourceEventType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ResourceEventType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ResourceEventType[] values();\n}", "des": "Events delivered to LocalizedResource. Each of these events is a subclass of ResourceEvent."}
{"index": 5825, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ResourceMappings {\n\t// Adds the resources for a given resource type.\n\tvoid addAssignedResources(String resourceType, ResourceMappings.AssignedResources assigned);\n\t// Get all resource mappings.\n\tList<Serializable> getAssignedResources(String resourceType);\n}", "des": "This class is used to store assigned resource to a single container by resource types. Assigned resource could be list of String For example, we can assign container to: \"numa\": [\"numa0\"] \"gpu\": [\"0\", \"1\", \"2\", \"3\"] \"fpga\": [\"1\", \"3\"] This will be used for NM restart container recovery."}
{"index": 5826, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ScriptBasedNodeAttributesProvider {\n\t// method for subclasses to cleanup.\n\tprotected void cleanUp();\n\t// Creates a timer task which be scheduled periodically by the provider, and the task is responsible to update node descriptors to the provider.\n\tTimerTask createTimerTask();\n\tprotected void serviceInit(org.apache.hadoop.conf.Configuration conf);\n}", "des": "Node attribute provider that periodically runs a script to collect node attributes."}
{"index": 5827, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class ScriptBasedNodeLabelsProvider {\n\t// Method used to terminate the Node Labels Fetch script.\n\tvoid cleanUp();\n\t// Creates a timer task which be scheduled periodically by the provider, and the task is responsible to update node descriptors to the provider.\n\tTimerTask createTimerTask();\n\tprotected void serviceInit(org.apache.hadoop.conf.Configuration conf);\n}", "des": "The class which provides functionality of getting the labels of the node using the configured node labels provider script. \"NODE_PARTITION:\" is the pattern which will be used to search node label partition from the out put of the NodeLabels provider script"}
{"index": 5828, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class SlidingWindowRetryPolicy {\n\t// Sets the clock.\n\tvoid setClock(org.apache.hadoop.yarn.util.Clock clock);\n\tboolean shouldRetry(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.SlidingWindowRetryPolicy.RetryContext retryContext, int errorCode);\n\t// Updates remaining retries and the restart time when required in the retryContext.\n\tprotected void updateRetryContext(org.apache.hadoop.yarn.server.nodemanager.containermanager.container.SlidingWindowRetryPolicy.RetryContext retryContext);\n}", "des": ""}
{"index": 5829, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class TimedHealthReporterService {\n\t// Returns output from health check.\n\tString getHealthReport();\n\t// Returns time stamp when node health check was last run.\n\tlong getLastHealthReportTime();\n\t// Gets whether the node is healthy or not.\n\tboolean isHealthy();\n\t// Method used to start the health monitoring.\n\tvoid serviceStart();\n\t// Method used to terminate the health monitoring service.\n\tprotected void serviceStop();\n\t// Sets if the node is healthy or not.\n\tprotected void setHealthy(boolean healthy);\n}", "des": "A HealthReporter skeleton for regularly checking a specific TimerTask and obtaining information about it."}
{"index": 5830, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class UpdateContainerSchedulerEvent {\n\t// Original Token before update.\n\torg.apache.hadoop.yarn.security.ContainerTokenIdentifier getOriginalToken();\n\t// Update Container Token.\n\torg.apache.hadoop.yarn.security.ContainerTokenIdentifier getUpdatedToken();\n\t// isExecTypeUpdate.\n\tboolean isExecTypeUpdate();\n\t// isIncrease.\n\tboolean isIncrease();\n\t// isResourceChange.\n\tboolean isResourceChange();\n}", "des": "Update Event consumed by the ContainerScheduler."}
{"index": 5831, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Class UpdateContainerTokenEvent {\n\t// Update Container Token.\n\torg.apache.hadoop.yarn.security.ContainerTokenIdentifier getUpdatedToken();\n\t// Is this update an ExecType Update.\n\tboolean isExecTypeUpdate();\n\t// Is this a container Increase.\n\tboolean isIncrease();\n\t// Is this update a ResourceChange.\n\tboolean isResourceChange();\n}", "des": "Update Event consumed by the Container."}
{"index": 5832, "repo": "hadoop-yarn-server-nodemanager-3.3.6", "code": "Enum YarnRuntimeType {\n\tString getName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic YarnRuntimeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic YarnRuntimeType[] values();\n}", "des": "YarnRuntime parameter enum for DevicePlugin. It's passed into onDevicesAllocated. Device plugin could populate DeviceRuntimeSpec based on which YARN container runtime will use."}
{"index": 5833, "repo": "flink-clients-1.17.1", "code": "interface ClusterClientServiceLoader {\n\t// Loads and returns a stream of the names of all available execution target names for Application Mode.\n\tjava.util.stream.Stream<String> getApplicationModeTargetNames();\n\t// Discovers the appropriate ClusterClientFactory based on the provided configuration.\n\t<ClusterID>ClusterClientFactory<ClusterID> getClusterClientFactory(org.apache.flink.configuration.Configuration configuration);\n}", "des": "An interface used to discover the appropriate cluster client factory based on the provided Configuration."}
{"index": 5834, "repo": "flink-clients-1.17.1", "code": "class DefaultClusterClientServiceLoader {\n\t// Loads and returns a stream of the names of all available execution target names for Application Mode.\n\tjava.util.stream.Stream<String> getApplicationModeTargetNames();\n\t// Discovers the appropriate ClusterClientFactory based on the provided configuration.\n\t<ClusterID>ClusterClientFactory<ClusterID> getClusterClientFactory(org.apache.flink.configuration.Configuration configuration);\n}", "des": "A service provider for cluster client factories."}
{"index": 5835, "repo": "flink-clients-1.17.1", "code": "interface EntryClassInformationProvider {\n\t// Returns the File referring to the Jar file that contains the job class or no File if the job class is located on the classpath.\n\tOptional<File> getJarFile();\n\t// Returns the name of the job class or an empty Optional if the job class name cannot be provided.\n\tOptional<String> getJobClassName();\n}", "des": "EntryClassInformationProvider provides information about the entry class."}
{"index": 5836, "repo": "flink-clients-1.17.1", "code": "enum MiniClusterClient.MiniClusterId {\n\t// \n\tstatic MiniClusterClient.MiniClusterId valueOf(String name);\n\t// ,  \n\tstatic MiniClusterClient.MiniClusterId[] values();\n}", "des": "The type of the Cluster ID for the local MiniCluster."}
{"index": 5837, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum AllocationTagNamespaceType {\n\tString getTypeKeyword();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AllocationTagNamespaceType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AllocationTagNamespaceType[] values();\n}", "des": "Class to describe all supported forms of namespaces for an allocation tag."}
{"index": 5838, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum AMCommand {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AMCommand valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AMCommand[] values();\n}", "des": "Command sent by the Resource Manager to the Application Master in the AllocateResponse"}
{"index": 5839, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ApplicationAccessType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ApplicationAccessType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ApplicationAccessType[] values();\n}", "des": "Application access types."}
{"index": 5840, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ApplicationConstants.ContainerLaunchType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ApplicationConstants.ContainerLaunchType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ApplicationConstants.ContainerLaunchType[] values();\n}", "des": "The type of launch for the container."}
{"index": 5841, "repo": "hadoop-yarn-api-3.3.6", "code": "Class ApplicationInitializationContext {\n\t// Get the data sent to the NodeManager via ContainerManagementProtocol.startContainers(StartContainersRequest) as part of ContainerLaunchContext.getServiceData()\n\tByteBuffer getApplicationDataForService();\n\t// Get ApplicationId of the application\n\tApplicationId getApplicationId();\n\t// Get the user-name of the application-submitter\n\tString getUser();\n}", "des": "Initialization context for AuxiliaryService when starting an application."}
{"index": 5842, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ApplicationsRequestScope {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ApplicationsRequestScope valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ApplicationsRequestScope[] values();\n}", "des": "Enumeration that controls the scope of applications fetched"}
{"index": 5843, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ApplicationTimeoutType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ApplicationTimeoutType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ApplicationTimeoutType[] values();\n}", "des": "Application timeout type."}
{"index": 5844, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum AttributeMappingOperationType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AttributeMappingOperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AttributeMappingOperationType[] values();\n}", "des": ""}
{"index": 5845, "repo": "hadoop-yarn-api-3.3.6", "code": "Interface ContainerLogAggregationPolicy {\n\t// The method used by the NodeManager log aggregation service to initial the policy object with parameters specified by the application or the cluster-wide setting.\n\tvoid parseParameters(String parameters);\n\t// The method used by the NodeManager log aggregation service to ask the policy object if a given container's logs should be aggregated.\n\tboolean shouldDoLogAggregation(ContainerLogContext logContext);\n}", "des": "This API is used by NodeManager to decide if a given container's logs should be aggregated at run time."}
{"index": 5846, "repo": "hadoop-yarn-api-3.3.6", "code": "Class ContainerLogContext {\n\t// Get ContainerId of the container.\n\tContainerId getContainerId();\n\t// Get ContainerType the type of the container.\n\tContainerType getContainerType();\n\t// Get the exit code of the container.\n\tint getExitCode();\n}", "des": "Context class for ContainerLogAggregationPolicy."}
{"index": 5847, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ContainerRetryPolicy {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerRetryPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerRetryPolicy[] values();\n}", "des": ""}
{"index": 5848, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ContainerState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerState[] values();\n}", "des": ""}
{"index": 5849, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ContainerSubState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerSubState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerSubState[] values();\n}", "des": "Container Sub-State."}
{"index": 5850, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ContainerType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerType[] values();\n}", "des": "Container property encoding allocation and execution semantics."}
{"index": 5851, "repo": "hadoop-yarn-api-3.3.6", "code": "Class ContainerUpdateRequest {\n\t// Get a list of container tokens to be used for authorization during container resource update.\n\tabstract List<Token> getContainersToUpdate();\n\tstatic ContainerUpdateRequest newInstance(List<Token> containersToIncrease);\n\t// Set container tokens to be used during container resource increase.\n\tabstract void setContainersToUpdate(List<Token> containersToUpdate);\n}", "des": ""}
{"index": 5852, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ContainerUpdateType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ContainerUpdateType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ContainerUpdateType[] values();\n}", "des": "Encodes the type of Container Update."}
{"index": 5853, "repo": "hadoop-yarn-api-3.3.6", "code": "Interface CsiAdaptorPlugin {\n\t// Returns the driver name of the csi-driver this adaptor works with.\n\tString getDriverName();\n\t// A csi-adaptor implementation can init its state within this function.\n\tvoid init(String driverName, org.apache.hadoop.conf.Configuration conf);\n}", "des": "csi-adaptor is a plugin, user can provide customized implementation according to this interface. NM will init and load this into a NM aux service, and it can run multiple csi-adaptor servers. User needs to implement all the methods defined in CsiAdaptorProtocol, and plus the methods in this interface."}
{"index": 5854, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum DecommissionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DecommissionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DecommissionType[] values();\n}", "des": "Specifies the different types of decommissioning of nodes."}
{"index": 5855, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ExecutionType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExecutionType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExecutionType[] values();\n}", "des": "Container property encoding execution semantics."}
{"index": 5856, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum FinalApplicationStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FinalApplicationStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FinalApplicationStatus[] values();\n}", "des": "Enumeration of various final states of an Application."}
{"index": 5857, "repo": "hadoop-yarn-api-3.3.6", "code": "Class FinishApplicationMasterResponse {\n\t// Get the flag which indicates that the application has successfully unregistered with the RM and the application can safely stop.\n\tabstract boolean getIsUnregistered();\n\tstatic FinishApplicationMasterResponse newInstance(boolean isRemovedFromRMStateStore);\n\t// Set the flag which indicates that the application has successfully unregistered with the RM and the application can safely stop.\n\tabstract void setIsUnregistered(boolean isUnregistered);\n}", "des": "The response sent by the ResourceManager to a ApplicationMaster on it's completion."}
{"index": 5858, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetApplicationAttemptReportRequest {\n\t// Get the ApplicationAttemptId of an application attempt.\n\tabstract ApplicationAttemptId getApplicationAttemptId();\n\tstatic GetApplicationAttemptReportRequest newInstance(ApplicationAttemptId applicationAttemptId);\n\t// Set the ApplicationAttemptId of an application attempt\n\tabstract void setApplicationAttemptId(ApplicationAttemptId applicationAttemptId);\n}", "des": ""}
{"index": 5859, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetApplicationAttemptReportResponse {\n\t// Get the ApplicationAttemptReport for the application attempt.\n\tabstract ApplicationAttemptReport getApplicationAttemptReport();\n\tstatic GetApplicationAttemptReportResponse newInstance(ApplicationAttemptReport ApplicationAttemptReport);\n\t// Get the ApplicationAttemptReport for the application attempt.\n\tabstract void setApplicationAttemptReport(ApplicationAttemptReport applicationAttemptReport);\n}", "des": ""}
{"index": 5860, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetApplicationAttemptsRequest {\n\t// Get the ApplicationId of an application\n\tabstract ApplicationId getApplicationId();\n\tstatic GetApplicationAttemptsRequest newInstance(ApplicationId applicationId);\n\t// Set the ApplicationId of an application\n\tabstract void setApplicationId(ApplicationId applicationId);\n}", "des": ""}
{"index": 5861, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetApplicationAttemptsResponse {\n\t// Get a list of ApplicationReport of an application.\n\tabstract List<ApplicationAttemptReport> getApplicationAttemptList();\n\tstatic GetApplicationAttemptsResponse newInstance(List<ApplicationAttemptReport> applicationAttempts);\n\t// Get a list of ApplicationReport of an application.\n\tabstract void setApplicationAttemptList(List<ApplicationAttemptReport> applicationAttempts);\n}", "des": ""}
{"index": 5862, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetApplicationReportRequest {\n\t// Get the ApplicationId of the application.\n\tabstract ApplicationId getApplicationId();\n\tstatic GetApplicationReportRequest newInstance(ApplicationId applicationId);\n\t// Set the ApplicationId of the application\n\tabstract void setApplicationId(ApplicationId applicationId);\n}", "des": ""}
{"index": 5863, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetAttributesToNodesRequest {\n\t// Get node attributeKeys for which mapping of hostname to attribute value is required.\n\tabstract Set<NodeAttributeKey> getNodeAttributes();\n\tstatic GetAttributesToNodesRequest newInstance();\n\tstatic GetAttributesToNodesRequest newInstance(Set<NodeAttributeKey> attributes);\n\t// Set node attributeKeys for which the mapping of hostname to attribute value is required.\n\tabstract void setNodeAttributes(Set<NodeAttributeKey> attributes);\n}", "des": ""}
{"index": 5864, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetClusterNodeAttributesResponse {\n\t// Get node attributes from the response.\n\tabstract Set<NodeAttributeInfo> getNodeAttributes();\n\t// Create instance of GetClusterNodeAttributesResponse.\n\tstatic GetClusterNodeAttributesResponse newInstance(Set<NodeAttributeInfo> attributes);\n\t// Set node attributes to the response.\n\tabstract void setNodeAttributes(Set<NodeAttributeInfo> attributes);\n}", "des": ""}
{"index": 5865, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetClusterNodesRequest {\n\t// The state to filter the cluster nodes with.\n\tabstract EnumSet<NodeState> getNodeStates();\n\tstatic GetClusterNodesRequest newInstance();\n\tstatic GetClusterNodesRequest newInstance(EnumSet<NodeState> states);\n\t// The state to filter the cluster nodes with.\n\tabstract void setNodeStates(EnumSet<NodeState> states);\n}", "des": ""}
{"index": 5866, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetContainerReportRequest {\n\t// Get the ContainerId of the Container.\n\tabstract ContainerId getContainerId();\n\tstatic GetContainerReportRequest newInstance(ContainerId containerId);\n\t// Set the ContainerId of the container\n\tabstract void setContainerId(ContainerId containerId);\n}", "des": ""}
{"index": 5867, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetContainersRequest {\n\t// Get the ApplicationAttemptId of an application attempt.\n\tabstract ApplicationAttemptId getApplicationAttemptId();\n\tstatic GetContainersRequest newInstance(ApplicationAttemptId applicationAttemptId);\n\t// Set the ApplicationAttemptId of an application attempt\n\tabstract void setApplicationAttemptId(ApplicationAttemptId applicationAttemptId);\n}", "des": ""}
{"index": 5868, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetContainersResponse {\n\t// Get a list of ContainerReport for all the containers of an application attempt.\n\tabstract List<ContainerReport> getContainerList();\n\tstatic GetContainersResponse newInstance(List<ContainerReport> containers);\n\t// Set a list of ContainerReport for all the containers of an application attempt.\n\tabstract void setContainerList(List<ContainerReport> containers);\n}", "des": ""}
{"index": 5869, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetContainerStatusesRequest {\n\t// Get the list of ContainerIds of containers for which to obtain the ContainerStatus.\n\tabstract List<ContainerId> getContainerIds();\n\tstatic GetContainerStatusesRequest newInstance(List<ContainerId> containerIds);\n\t// Set a list of ContainerIds of containers for which to obtain the ContainerStatus\n\tabstract void setContainerIds(List<ContainerId> containerIds);\n}", "des": "The request sent by the ApplicationMaster to the NodeManager to get ContainerStatus of requested containers."}
{"index": 5870, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetLocalizationStatusesRequest {\n\t// Get the list of container IDs of the containers for which the localization statuses are needed.\n\tabstract List<ContainerId> getContainerIds();\n\tstatic GetLocalizationStatusesRequest newInstance(List<ContainerId> containerIds);\n\t// Sets the list of container IDs of containers for which the localization statuses are needed.\n\tabstract void setContainerIds(List<ContainerId> containerIds);\n}", "des": "The request sent by an application master to the node manager to get LocalizationStatuses of containers."}
{"index": 5871, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetNewReservationResponse {\n\t// Get a new ReservationId to be used to submit a reservation.\n\tabstract ReservationId getReservationId();\n\tstatic GetNewReservationResponse newInstance(ReservationId reservationId);\n\t// Set a new ReservationId to be used to submit a reservation.\n\tabstract void setReservationId(ReservationId reservationId);\n}", "des": ""}
{"index": 5872, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetNodesToAttributesRequest {\n\t// Get hostnames for which mapping is required.\n\tabstract Set<String> getHostNames();\n\tstatic GetNodesToAttributesRequest newInstance(Set<String> hostNames);\n\t// Set hostnames for which mapping is required.\n\tabstract void setHostNames(Set<String> hostnames);\n}", "des": ""}
{"index": 5873, "repo": "hadoop-yarn-api-3.3.6", "code": "Class GetResourceProfileResponse {\n\tboolean equals(Object other);\n\t// Get the resources that will be allocated if the profile was used.\n\tabstract Resource getResource();\n\tstatic GetResourceProfileResponse newInstance();\n\t// Set the resources that will be allocated if the profile is used.\n\tabstract void setResource(Resource r);\n}", "des": "Response class for getting the details for a particular resource profile."}
{"index": 5874, "repo": "hadoop-yarn-api-3.3.6", "code": "Class IncreaseContainersResourceRequest {\n\t// Get a list of container tokens to be used for authorization during container resource increase.\n\tabstract List<Token> getContainersToIncrease();\n\tstatic IncreaseContainersResourceRequest newInstance(List<Token> containersToIncrease);\n\t// Set container tokens to be used during container resource increase.\n\tabstract void setContainersToIncrease(List<Token> containersToIncrease);\n}", "des": ""}
{"index": 5875, "repo": "hadoop-yarn-api-3.3.6", "code": "Class KillApplicationRequest {\n\t// Get the ApplicationId of the application to be aborted.\n\tabstract ApplicationId getApplicationId();\n\t// Get the diagnostics to which the application is being killed.\n\tabstract String getDiagnostics();\n\tstatic KillApplicationRequest newInstance(ApplicationId applicationId);\n\tabstract void setApplicationId(ApplicationId applicationId);\n\t// Set the diagnostics to which the application is being killed.\n\tabstract void setDiagnostics(String diagnostics);\n}", "des": ""}
{"index": 5876, "repo": "hadoop-yarn-api-3.3.6", "code": "Class KillApplicationResponse {\n\t// Get the flag which indicates that the process of killing application is completed or not.\n\tabstract boolean getIsKillCompleted();\n\tstatic KillApplicationResponse newInstance(boolean isKillCompleted);\n\t// Set the flag which indicates that the process of killing application is completed or not.\n\tabstract void setIsKillCompleted(boolean isKillCompleted);\n}", "des": "The response sent by the ResourceManager to the client aborting a submitted application."}
{"index": 5877, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum LocalizationState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LocalizationState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LocalizationState[] values();\n}", "des": "State of localization."}
{"index": 5878, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum LocalResourceType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LocalResourceType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LocalResourceType[] values();\n}", "des": "LocalResourceType specifies the type of a resource localized by the NodeManager."}
{"index": 5879, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum LocalResourceVisibility {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LocalResourceVisibility valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LocalResourceVisibility[] values();\n}", "des": "LocalResourceVisibility specifies the visibility of a resource localized by the NodeManager."}
{"index": 5880, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum LogAggregationStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LogAggregationStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LogAggregationStatus[] values();\n}", "des": ""}
{"index": 5881, "repo": "hadoop-yarn-api-3.3.6", "code": "Class NMToken {\n\tboolean equals(Object obj);\n\t// Get the NodeId of the NodeManager for which the NMToken is used to authenticate.\n\tabstract NodeId getNodeId();\n\t// Get the Token used for authenticating with NodeManager\n\tabstract Token getToken();\n\tstatic NMToken newInstance(NodeId nodeId, Token token);\n\tabstract void setNodeId(NodeId nodeId);\n\tabstract void setToken(Token token);\n}", "des": ""}
{"index": 5882, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum NodeAttributeOpCode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NodeAttributeOpCode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NodeAttributeOpCode[] values();\n}", "des": "Enumeration of various node attribute op codes."}
{"index": 5883, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum NodeAttributeType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NodeAttributeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NodeAttributeType[] values();\n}", "des": ""}
{"index": 5884, "repo": "hadoop-yarn-api-3.3.6", "code": "Class NodeId {\n\tprotected abstract void build();\n\tint compareTo(NodeId other);\n\tboolean equals(Object obj);\n\tstatic NodeId fromString(String nodeIdStr);\n\t// Get the hostname of the node.\n\tabstract String getHost();\n\t// Get the port for communicating with the node.\n\tabstract int getPort();\n\tstatic NodeId newInstance(String host, int port);\n\tprotected abstract void setHost(String host);\n\tprotected abstract void setPort(int port);\n}", "des": ""}
{"index": 5885, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum NodeState {\n\tboolean isActiveState();\n\tboolean isInactiveState();\n\tboolean isUnusable();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NodeState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NodeState[] values();\n}", "des": ""}
{"index": 5886, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum NodeUpdateType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic NodeUpdateType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic NodeUpdateType[] values();\n}", "des": ""}
{"index": 5887, "repo": "hadoop-yarn-api-3.3.6", "code": "Class PlacementConstraint.And {\n\t// Visitor pattern.\n\t<T> T accept(PlacementConstraint.Visitor<T> visitor);\n\t// Get the children of this composite constraint.\n\tList<PlacementConstraint.AbstractConstraint> getChildren();\n}", "des": "Class that represents a composite constraint that is a conjunction of other constraints."}
{"index": 5888, "repo": "hadoop-yarn-api-3.3.6", "code": "Class PlacementConstraint.CardinalityConstraint {\n\t// Visitor pattern.\n\t<T> T accept(PlacementConstraint.Visitor<T> visitor);\n\tboolean equals(Object o);\n\t// Get the allocation tags of the constraint.\n\tSet<String> getAllocationTags();\n\t// Get the maximum cardinality of the constraint.\n\tint getMaxCardinality();\n\t// Get the minimum cardinality of the constraint.\n\tint getMinCardinality();\n\t// Get the scope of the constraint.\n\tString getScope();\n}", "des": "Class that represents a cardinality constraint. Such a constraint allows the number of allocations with a specific set of tags and within a given scope to be between some minimum and maximum values. It is a specialized version of the PlacementConstraint.SingleConstraint, where the target is a set of allocation tags."}
{"index": 5889, "repo": "hadoop-yarn-api-3.3.6", "code": "Class PlacementConstraint.DelayedOr {\n\t// Visitor pattern.\n\t<T> T accept(PlacementConstraint.Visitor<T> visitor);\n\t// Get the children of this composite constraint.\n\tList<PlacementConstraint.TimedPlacementConstraint> getChildren();\n}", "des": "Class that represents a composite constraint that comprises a list of timed placement constraints (see PlacementConstraint.TimedPlacementConstraint). The scheduler should try to satisfy first the first timed child constraint within the specified time window. If this is not possible, it should attempt to satisfy the second, and so on."}
{"index": 5890, "repo": "hadoop-yarn-api-3.3.6", "code": "Class PlacementConstraint.Or {\n\t// Visitor pattern.\n\t<T> T accept(PlacementConstraint.Visitor<T> visitor);\n\t// Get the children of this composite constraint.\n\tList<PlacementConstraint.AbstractConstraint> getChildren();\n}", "des": "Class that represents a composite constraint that is a disjunction of other constraints."}
{"index": 5891, "repo": "hadoop-yarn-api-3.3.6", "code": "Class PlacementConstraint.TargetConstraint {\n\t// Visitor pattern.\n\t<T> T accept(PlacementConstraint.Visitor<T> visitor);\n\tboolean equals(Object o);\n\t// Get the target operator of the constraint.\n\torg.apache.hadoop.yarn.api.resource.PlacementConstraint.TargetConstraint.TargetOperator getOp();\n\t// Get the scope of the constraint.\n\tString getScope();\n\t// Get the set of target expressions.\n\tSet<PlacementConstraint.TargetExpression> getTargetExpressions();\n}", "des": "Class that represents a target constraint. Such a constraint requires an allocation to be placed within a scope that satisfies some specified expressions on node attributes and allocation tags. It is a specialized version of the PlacementConstraint.SingleConstraint, where the minimum and the maximum cardinalities take specific values based on the TargetOperator used."}
{"index": 5892, "repo": "hadoop-yarn-api-3.3.6", "code": "Class PlacementConstraint.TargetExpression {\n\t// Visitor pattern.\n\t<T> T accept(PlacementConstraint.Visitor<T> visitor);\n\tboolean equals(Object o);\n\t// Get the key of the target expression.\n\tString getTargetKey();\n\t// Get the type of the target expression.\n\tPlacementConstraint.TargetExpression.TargetType getTargetType();\n\t// Get the set of values of the target expression.\n\tSet<String> getTargetValues();\n}", "des": "Class representing the target expressions that are used in placement constraints. They might refer to expressions on node attributes, allocation tags, or be self-targets (referring to the allocation to which the constraint is attached)."}
{"index": 5893, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum PlacementConstraint.TargetExpression.TargetType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PlacementConstraint.TargetExpression.TargetType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PlacementConstraint.TargetExpression.TargetType[] values();\n}", "des": "Enum specifying the type of the target expression."}
{"index": 5894, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum PlacementConstraint.TimedPlacementConstraint.DelayUnit {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PlacementConstraint.TimedPlacementConstraint.DelayUnit valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PlacementConstraint.TimedPlacementConstraint.DelayUnit[] values();\n}", "des": "The unit of scheduling delay."}
{"index": 5895, "repo": "hadoop-yarn-api-3.3.6", "code": "Class PlacementConstraintParser {\n\t// Parses a given constraint expression to a PlacementConstraint.AbstractConstraint, this expression can be any valid form of constraint expressions.\n\tstatic PlacementConstraint.AbstractConstraint parseExpression(String constraintStr);\n\t// Parses a placement constraint specification.\n\tstatic Map<PlacementConstraintParser.SourceTags,PlacementConstraint> parsePlacementSpec(String expression);\n}", "des": "Placement constraint expression parser."}
{"index": 5896, "repo": "hadoop-yarn-api-3.3.6", "code": "Class Priority {\n\tint compareTo(Priority other);\n\tboolean equals(Object obj);\n\t// Get the assigned priority\n\tabstract int getPriority();\n\tstatic Priority newInstance(int p);\n\t// Set the assigned priority\n\tabstract void setPriority(int priority);\n}", "des": "The priority assigned to a ResourceRequest or Application or Container allocation"}
{"index": 5897, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum QueueACL {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QueueACL valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QueueACL[] values();\n}", "des": "QueueACL enumerates the various ACLs for queues."}
{"index": 5898, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum QueueState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic QueueState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic QueueState[] values();\n}", "des": "State of a Queue."}
{"index": 5899, "repo": "hadoop-yarn-api-3.3.6", "code": "Class QueueUserACLInfo {\n\t// Get the queue name of the queue.\n\tabstract String getQueueName();\n\t// Get the list of QueueACL for the given user.\n\tabstract List<QueueACL> getUserAcls();\n\tstatic QueueUserACLInfo newInstance(String queueName, List<QueueACL> acls);\n\tabstract void setQueueName(String queueName);\n\tabstract void setUserAcls(List<QueueACL> acls);\n}", "des": ""}
{"index": 5900, "repo": "hadoop-yarn-api-3.3.6", "code": "Class RejectedSchedulingRequest {\n\t// Get Rejection Reason.\n\tabstract RejectionReason getReason();\n\t// Get the Rejected Scheduling Request.\n\tabstract SchedulingRequest getRequest();\n\t// Create new RejectedSchedulingRequest.\n\tstatic RejectedSchedulingRequest newInstance(RejectionReason reason, SchedulingRequest request);\n\t// Set Rejection Reason.\n\tabstract void setReason(RejectionReason reason);\n\t// Set the SchedulingRequest.\n\tabstract void setRequest(SchedulingRequest request);\n}", "des": "This encapsulates a Rejected SchedulingRequest. It contains the offending Scheduling Request along with the reason for rejection."}
{"index": 5901, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum RejectionReason {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RejectionReason valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RejectionReason[] values();\n}", "des": "Reason for rejecting a Scheduling Request."}
{"index": 5902, "repo": "hadoop-yarn-api-3.3.6", "code": "Class ReleaseSharedCacheResourceRequest {\n\t// Get the ApplicationId of the resource to be released.\n\tabstract ApplicationId getAppId();\n\t// Get the key of the resource to be released.\n\tabstract String getResourceKey();\n\t// Set the ApplicationId of the resource to be released.\n\tabstract void setAppId(ApplicationId id);\n\t// Set the key of the resource to be released.\n\tabstract void setResourceKey(String key);\n}", "des": ""}
{"index": 5903, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ReservationACL {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReservationACL valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReservationACL[] values();\n}", "des": "ReservationACL enumerates the various ACLs for reservations."}
{"index": 5904, "repo": "hadoop-yarn-api-3.3.6", "code": "Class ReservationDeleteRequest {\n\t// Get the ReservationId, that corresponds to a valid resource allocation in the scheduler (between start and end time of this reservation)\n\tabstract ReservationId getReservationId();\n\tstatic ReservationDeleteRequest newInstance(ReservationId reservationId);\n\t// Set the ReservationId, that correspond to a valid resource allocation in the scheduler (between start and end time of this reservation)\n\tabstract void setReservationId(ReservationId reservationId);\n}", "des": "ReservationDeleteRequest captures the set of requirements the user has to delete an existing reservation."}
{"index": 5905, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ReservationRequestInterpreter {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ReservationRequestInterpreter valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ReservationRequestInterpreter[] values();\n}", "des": "Enumeration of various types of dependencies among multiple ReservationRequests within one ReservationDefinition (from least constraining to most constraining)."}
{"index": 5906, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ResourceTypes {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ResourceTypes valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ResourceTypes[] values();\n}", "des": "Enum which represents the resource type. Currently, the only type allowed is COUNTABLE."}
{"index": 5907, "repo": "hadoop-yarn-api-3.3.6", "code": "Class RunSharedCacheCleanerTaskResponse {\n\t// Get whether or not the shared cache manager has accepted the request.\n\tabstract boolean getAccepted();\n\t// Set whether or not the shared cache manager has accepted the request Shared cache manager will reject the request if there is an ongoing task\n\tabstract void setAccepted(boolean b);\n}", "des": ""}
{"index": 5908, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ShellContainerCommand {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ShellContainerCommand valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ShellContainerCommand[] values();\n}", "des": "Enumeration of various signal container commands."}
{"index": 5909, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum SignalContainerCommand {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SignalContainerCommand valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SignalContainerCommand[] values();\n}", "des": "Enumeration of various signal container commands."}
{"index": 5910, "repo": "hadoop-yarn-api-3.3.6", "code": "Class StartContainersRequest {\n\t// Get a list of StartContainerRequest to start containers.\n\tabstract List<StartContainerRequest> getStartContainerRequests();\n\tstatic StartContainersRequest newInstance(List<StartContainerRequest> requests);\n\t// Set a list of StartContainerRequest to start containers.\n\tabstract void setStartContainerRequests(List<StartContainerRequest> request);\n}", "des": ""}
{"index": 5911, "repo": "hadoop-yarn-api-3.3.6", "code": "Class StopContainersRequest {\n\t// Get the ContainerIds of the containers to be stopped.\n\tabstract List<ContainerId> getContainerIds();\n\tstatic StopContainersRequest newInstance(List<ContainerId> containerIds);\n\t// Set the ContainerIds of the containers to be stopped.\n\tabstract void setContainerIds(List<ContainerId> containerIds);\n}", "des": ""}
{"index": 5912, "repo": "hadoop-yarn-api-3.3.6", "code": "Class SubmitApplicationRequest {\n\t// Get the ApplicationSubmissionContext for the application.\n\tabstract ApplicationSubmissionContext getApplicationSubmissionContext();\n\tstatic SubmitApplicationRequest newInstance(ApplicationSubmissionContext context);\n\t// Set the ApplicationSubmissionContext for the application.\n\tabstract void setApplicationSubmissionContext(ApplicationSubmissionContext context);\n}", "des": ""}
{"index": 5913, "repo": "hadoop-yarn-api-3.3.6", "code": "Class TimelineDomains {\n\t// Add a single domain into the existing domain list\n\tvoid addDomain(TimelineDomain domain);\n\t// All a list of domains into the existing domain list\n\tvoid addDomains(List<TimelineDomain> domains);\n\t// Get a list of domains\n\tList<TimelineDomain> getDomains();\n\t// Set the domain list to the given list of domains\n\tvoid setDomains(List<TimelineDomain> domains);\n}", "des": "The class that hosts a list of timeline domains."}
{"index": 5914, "repo": "hadoop-yarn-api-3.3.6", "code": "Class TimelineEntities {\n\t// All a list of entities into the existing entity list\n\tvoid addEntities(List<TimelineEntity> entities);\n\t// Add a single entity into the existing entity list\n\tvoid addEntity(TimelineEntity entity);\n\t// Get a list of entities\n\tList<TimelineEntity> getEntities();\n\t// Set the entity list to the given list of entities\n\tvoid setEntities(List<TimelineEntity> entities);\n}", "des": "The class that hosts a list of timeline entities."}
{"index": 5915, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum TimelineHealth.TimelineHealthStatus {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TimelineHealth.TimelineHealthStatus valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TimelineHealth.TimelineHealthStatus[] values();\n}", "des": "Timline health status. RUNNING - Service is up and running READER_CONNECTION_FAULURE - isConnectionAlive() of reader implementation reported an error"}
{"index": 5916, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum TimelineMetric.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TimelineMetric.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TimelineMetric.Type[] values();\n}", "des": "Type of metric."}
{"index": 5917, "repo": "hadoop-yarn-api-3.3.6", "code": "Class TimelineMetricCalculator {\n\t// Compare two not-null numbers.\n\tstatic int compare(Number n1, Number n2);\n\t// Subtract operation between two Numbers.\n\tstatic Number sub(Number n1, Number n2);\n\t// Sum up two Numbers.\n\tstatic Number sum(Number n1, Number n2);\n}", "des": "A calculator for timeline metrics."}
{"index": 5918, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum TimelineMetricOperation {\n\t// Perform the aggregation operation.\n\tTimelineMetric aggregate(TimelineMetric incoming, TimelineMetric aggregate, Map<Object,Object> state);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TimelineMetricOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TimelineMetricOperation[] values();\n}", "des": "Aggregation operations."}
{"index": 5919, "repo": "hadoop-yarn-api-3.3.6", "code": "Class TimelinePutResponse.TimelinePutError {\n\t// Get the entity Id\n\tString getEntityId();\n\t// Get the entity type\n\tString getEntityType();\n\t// Get the error code\n\tint getErrorCode();\n\t// Set the entity Id\n\tvoid setEntityId(String entityId);\n\t// Set the entity type\n\tvoid setEntityType(String entityType);\n\t// Set the error code to the given error code\n\tvoid setErrorCode(int errorCode);\n}", "des": "A class that holds the error code for one entity."}
{"index": 5920, "repo": "hadoop-yarn-api-3.3.6", "code": "Class TimelineServiceHelper {\n\t// Inverts the given key.\n\tstatic long invertLong(long key);\n\t// Cast map to HashMap for generic type.\n\tstatic <E,V> HashMap<E,V> mapCastToHashMap(Map<E,V> originalMap);\n}", "des": "Helper class for Timeline service."}
{"index": 5921, "repo": "hadoop-yarn-api-3.3.6", "code": "Class TimelineWriteResponse.TimelineWriteError {\n\t// Get the entity Id.\n\tString getEntityId();\n\t// Get the entity type.\n\tString getEntityType();\n\t// Get the error code.\n\tint getErrorCode();\n\t// Set the entity Id.\n\tvoid setEntityId(String id);\n\t// Set the entity type.\n\tvoid setEntityType(String type);\n\t// Set the error code to the given error code.\n\tvoid setErrorCode(int code);\n}", "des": "A class that holds the error code for one entity."}
{"index": 5922, "repo": "hadoop-yarn-api-3.3.6", "code": "Class UnitsConversionUtil {\n\t// Compare a value in a given unit with a value in another unit.\n\tstatic int compare(String unitA, long valueA, String unitB, long valueB);\n\t// Compare a unit to another unit.\n\tstatic int compareUnits(String unitA, String unitB);\n\t// Converts a value from one unit to another.\n\tstatic long convert(String fromUnit, String toUnit, long fromValue);\n}", "des": "A util to convert values in one unit to another. Units refers to whether the value is expressed in pico, nano, etc."}
{"index": 5923, "repo": "hadoop-yarn-api-3.3.6", "code": "Class UpdateApplicationPriorityResponse {\n\t// Get the Priority of the application to be set.\n\tabstract Priority getApplicationPriority();\n\tstatic UpdateApplicationPriorityResponse newInstance(Priority priority);\n\t// Set the Priority of the application.\n\tabstract void setApplicationPriority(Priority priority);\n}", "des": ""}
{"index": 5924, "repo": "hadoop-yarn-api-3.3.6", "code": "Class UpdateApplicationTimeoutsResponse {\n\t// Get ApplicationTimeouts of the application.\n\tabstract Map<ApplicationTimeoutType,String> getApplicationTimeouts();\n\tstatic UpdateApplicationTimeoutsResponse newInstance();\n\t// Set the ApplicationTimeouts for the application.\n\tabstract void setApplicationTimeouts(Map<ApplicationTimeoutType,String> applicationTimeouts);\n}", "des": ""}
{"index": 5925, "repo": "hadoop-yarn-api-3.3.6", "code": "Class UpdatedContainer {\n\tboolean equals(Object obj);\n\t// Get the Container.\n\tabstract Container getContainer();\n\t// Get the ContainerUpdateType.\n\tabstract ContainerUpdateType getUpdateType();\n\t// Static Factory method.\n\tstatic UpdatedContainer newInstance(ContainerUpdateType updateType, Container container);\n\t// Set the Container.\n\tabstract void setContainer(Container container);\n\t// Set the ContainerUpdateType.\n\tabstract void setUpdateType(ContainerUpdateType updateType);\n}", "des": "An object that encapsulates an updated container and the type of Update."}
{"index": 5926, "repo": "hadoop-yarn-api-3.3.6", "code": "Class UpdateNodeResourceRequest {\n\t// Get the map from NodeId to ResourceOption.\n\tabstract Map<NodeId,ResourceOption> getNodeResourceMap();\n\tstatic UpdateNodeResourceRequest newInstance(Map<NodeId,ResourceOption> nodeResourceMap);\n\t// Set the map from NodeId to ResourceOption.\n\tabstract void setNodeResourceMap(Map<NodeId,ResourceOption> nodeResourceMap);\n}", "des": ""}
{"index": 5927, "repo": "hadoop-yarn-api-3.3.6", "code": "Class UseSharedCacheResourceRequest {\n\t// Get the ApplicationId of the resource to be used.\n\tabstract ApplicationId getAppId();\n\t// Get the key of the resource to be used.\n\tabstract String getResourceKey();\n\t// Set the ApplicationId of the resource to be used.\n\tabstract void setAppId(ApplicationId id);\n\t// Set the key of the resource to be used.\n\tabstract void setResourceKey(String key);\n}", "des": ""}
{"index": 5928, "repo": "hadoop-yarn-api-3.3.6", "code": "Class UseSharedCacheResourceResponse {\n\t// Get the Path corresponding to the requested resource in the shared cache.\n\tabstract String getPath();\n\t// Set the Path corresponding to a resource in the shared cache.\n\tabstract void setPath(String p);\n}", "des": ""}
{"index": 5929, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ValidateVolumeCapabilitiesRequest.AccessMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ValidateVolumeCapabilitiesRequest.AccessMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ValidateVolumeCapabilitiesRequest.AccessMode[] values();\n}", "des": "Volume access mode."}
{"index": 5930, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum ValidateVolumeCapabilitiesRequest.VolumeType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ValidateVolumeCapabilitiesRequest.VolumeType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ValidateVolumeCapabilitiesRequest.VolumeType[] values();\n}", "des": "Volume type."}
{"index": 5931, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum YarnApplicationAttemptState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic YarnApplicationAttemptState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic YarnApplicationAttemptState[] values();\n}", "des": "Enumeration of various states of a RMAppAttempt."}
{"index": 5932, "repo": "hadoop-yarn-api-3.3.6", "code": "Enum YarnApplicationState {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic YarnApplicationState valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic YarnApplicationState[] values();\n}", "des": "Enumeration of various states of an ApplicationMaster."}
{"index": 5933, "repo": "ratis-server-2.5.1", "code": "Class LogSegmentPath {\n\tint compareTo(LogSegmentPath that);\n\t// Get a list of LogSegmentPath from the given storage.\n\tstatic List<LogSegmentPath> getLogSegmentPaths(RaftStorage storage);\n\tPath getPath();\n\tLogSegmentStartEnd getStartEnd();\n\t// Match the given path with the LogSegmentStartEnd.getClosedSegmentPattern() or the LogSegmentStartEnd.getOpenSegmentPattern().\n\tstatic LogSegmentPath matchLogSegment(Path path);\n}", "des": "LogSegmentStartEnd with a Path. This is a value-based class."}
{"index": 5934, "repo": "curator-recipes-5.5.0", "code": "Class AtomicStats {\n\t// Returns the time spent trying the operation with optimistic locks\n\tlong getOptimisticTimeMs();\n\t// Returns the number of optimistic locks used to perform the operation\n\tint getOptimisticTries();\n\t// Returns the number of mutex locks used to perform the operation\n\tint getPromotedLockTries();\n\t// Returns the time spent trying the operation with mutex locks\n\tlong getPromotedTimeMs();\n}", "des": "Debugging stats about operations"}
{"index": 5935, "repo": "curator-recipes-5.5.0", "code": "Interface AtomicValue<T> {\n\t// Returns debugging stats about the operation\n\tAtomicStats getStats();\n\t// Returns the value of the counter after to the operation\n\tT postValue();\n\t// Returns the value of the counter prior to the operation\n\tT preValue();\n\t// MUST be checked. Returns true if the operation succeeded.\n\tboolean succeeded();\n}", "des": "Abstracts a value returned from one of the Atomics"}
{"index": 5936, "repo": "curator-recipes-5.5.0", "code": "Enum CuratorCache.Options {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CuratorCache.Options valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CuratorCache.Options[] values();\n}", "des": "cache build options"}
{"index": 5937, "repo": "curator-recipes-5.5.0", "code": "Interface CuratorCacheAccessor {\n\t// Return an entry from storage\n\tOptional<ChildData> get(String path);\n\t// Filter for a ChildData stream.\n\tstatic Predicate<ChildData> parentPathFilter(String parentPath);\n\t// Return the current number of entries in storage\n\tint size();\n\t// Return a stream over the storage entries.\n\tStream<ChildData> stream();\n}", "des": "Methods to access the underlying storage"}
{"index": 5938, "repo": "curator-recipes-5.5.0", "code": "Interface CuratorCacheListener {\n\t// Returns a builder allowing type specific, and special purpose listeners.\n\tstatic CuratorCacheListenerBuilder builder();\n\t// Called when a data is created, changed or deleted.\n\tvoid event(CuratorCacheListener.Type type, ChildData oldData, ChildData data);\n\t// When the cache is started, the initial nodes are tracked and when they are finished loading into the cache this method is called.\n\tdefault void initialized();\n}", "des": "Listener for CuratorCache events. The main functional interface is general purpose but you can build event specific listeners, etc. using the builder. Note: all listeners are wrapped in CuratorFramework.runSafe(Runnable) when called."}
{"index": 5939, "repo": "curator-recipes-5.5.0", "code": "Enum CuratorCacheListener.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CuratorCacheListener.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CuratorCacheListener.Type[] values();\n}", "des": "An enumerated type that describes a change"}
{"index": 5940, "repo": "curator-recipes-5.5.0", "code": "Class DefaultTreeCacheSelector {\n\t// Return true if this node should be returned from the cache\n\tboolean acceptChild(String fullPath);\n\t// Return true if children of this path should be cached.\n\tboolean traverseChildren(String fullPath);\n}", "des": "Default TreeCache selector - returns true for all methods"}
{"index": 5941, "repo": "curator-recipes-5.5.0", "code": "Class DistributedBarrier {\n\t// Utility to remove the barrier node\n\tvoid removeBarrier();\n\t// Utility to set the barrier node\n\tvoid setBarrier();\n\t// Blocks until the barrier node comes into existence\n\tvoid waitOnBarrier();\n\t// Blocks until the barrier no longer exists or the timeout elapses\n\tboolean waitOnBarrier(long maxWait, TimeUnit unit);\n}", "des": ""}
{"index": 5942, "repo": "curator-recipes-5.5.0", "code": "Class DistributedDoubleBarrier {\n\t// Enter the barrier and block until all members have entered\n\tvoid enter();\n\t// Enter the barrier and block until all members have entered or the timeout has elapsed\n\tboolean enter(long maxWait, TimeUnit unit);\n\tprotected List<String> getChildrenForEntering();\n\t// Leave the barrier and block until all members have left\n\tvoid leave();\n\t// Leave the barrier and block until all members have left or the timeout has elapsed\n\tboolean leave(long maxWait, TimeUnit unit);\n}", "des": ""}
{"index": 5943, "repo": "curator-recipes-5.5.0", "code": "Enum ErrorMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ErrorMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ErrorMode[] values();\n}", "des": "Used when the queue is created with a QueueBuilder.lockPath(String). Determines the behavior when the queue consumer throws an exception"}
{"index": 5944, "repo": "curator-recipes-5.5.0", "code": "Class GroupMember {\n\t// Have thisId leave the group and stop caching membership\n\tvoid close();\n\t// Return the current view of membership.\n\tMap<String,byte[]> getCurrentMembers();\n\t// Given a full ZNode path, return the member ID\n\tString idFromPath(String path);\n\t// Change the data stored in this instance's node\n\tvoid setThisData(byte[] data);\n\t// Start the group membership.\n\tvoid start();\n}", "des": "Group membership management. Adds this instance into a group and keeps a cache of members in the group"}
{"index": 5945, "repo": "curator-recipes-5.5.0", "code": "Interface InterProcessLock {\n\t// Acquire the mutex - blocking until it's available.\n\tvoid acquire();\n\t// Acquire the mutex - blocks until it's available or the given time expires.\n\tboolean acquire(long time, TimeUnit unit);\n\t// Returns true if the mutex is acquired by a thread in this JVM\n\tboolean isAcquiredInThisProcess();\n\t// Perform one release of the mutex.\n\tvoid release();\n}", "des": "NOTE: depending on its implementation, release() may throw an exception if the current thread does not own the lock"}
{"index": 5946, "repo": "curator-recipes-5.5.0", "code": "Class InterProcessMultiLock {\n\t// Acquire the mutex - blocking until it's available.\n\tvoid acquire();\n\t// Acquire the mutex - blocks until it's available or the given time expires.\n\tboolean acquire(long time, TimeUnit unit);\n\t// Returns true if the mutex is acquired by a thread in this JVM\n\tboolean isAcquiredInThisProcess();\n\t// Perform one release of the mutex.\n\tvoid release();\n}", "des": "A container that manages multiple locks as a single entity. When acquire() is called, all the locks are acquired. If that fails, any paths that were acquired are released. Similarly, when release() is called, all locks are released (failures are ignored)."}
{"index": 5947, "repo": "curator-recipes-5.5.0", "code": "Class InterProcessReadWriteLock {\n\t// Returns the lock used for reading.\n\tInterProcessReadWriteLock.ReadLock readLock();\n\t// Returns the lock used for writing.\n\tInterProcessReadWriteLock.WriteLock writeLock();\n}", "des": ""}
{"index": 5948, "repo": "curator-recipes-5.5.0", "code": "Class InterProcessSemaphoreMutex {\n\t// Acquire the mutex - blocking until it's available.\n\tvoid acquire();\n\t// Acquire the mutex - blocks until it's available or the given time expires.\n\tboolean acquire(long time, TimeUnit unit);\n\t// Returns true if the mutex is acquired by a thread in this JVM\n\tboolean isAcquiredInThisProcess();\n\t// Perform one release of the mutex.\n\tvoid release();\n}", "des": "A NON re-entrant mutex that works across JVMs. Uses Zookeeper to hold the lock. All processes in all JVMs that use the same lock path will achieve an inter-process critical section."}
{"index": 5949, "repo": "curator-recipes-5.5.0", "code": "Enum LeaderLatch.CloseMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic LeaderLatch.CloseMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic LeaderLatch.CloseMode[] values();\n}", "des": "How to handle listeners when the latch is closed"}
{"index": 5950, "repo": "curator-recipes-5.5.0", "code": "Interface LeaderLatchListener {\n\t// This is called when the LeaderLatch's state goes from hasLeadership = false to hasLeadership = true.\n\tvoid isLeader();\n\t// This is called when the LeaderLatch's state goes from hasLeadership = true to hasLeadership = false.\n\tvoid notLeader();\n}", "des": "A LeaderLatchListener can be used to be notified asynchronously about when the state of the LeaderLatch has changed. Note that just because you are in the middle of one of these method calls, it does not necessarily mean that hasLeadership() is the corresponding true/false value. It is possible for the state to change behind the scenes before these methods get called. The contract is that if that happens, you should see another call to the other method pretty quickly."}
{"index": 5951, "repo": "curator-recipes-5.5.0", "code": "Interface Lease {\n\t// Releases the lease so that other clients/processes can acquire it\n\tvoid close();\n\t// Return the data stored in the node for this lease\n\tbyte[] getData();\n\t// Return the the node for this lease\n\tString getNodeName();\n}", "des": "Represents an acquired lease from an InterProcessSemaphore. It is the client's responsibility to close this lease when it is no longer needed so that other blocked clients can use it. If the client crashes (or its session expires, etc.) the lease will automatically be closed."}
{"index": 5952, "repo": "curator-recipes-5.5.0", "code": "Class Participant {\n\tboolean equals(Object o);\n\t// Returns the ID set via LeaderSelector.setId(String)\n\tString getId();\n\t// Returns true if this participant is the current leader\n\tboolean isLeader();\n}", "des": "Describes a participant in a leadership selection"}
{"index": 5953, "repo": "curator-recipes-5.5.0", "code": "Enum PathChildrenCache.StartMode {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PathChildrenCache.StartMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PathChildrenCache.StartMode[] values();\n}", "des": "Method of priming cache on PathChildrenCache.start(StartMode)"}
{"index": 5954, "repo": "curator-recipes-5.5.0", "code": "Enum PathChildrenCacheEvent.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PathChildrenCacheEvent.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PathChildrenCacheEvent.Type[] values();\n}", "des": "Type of change"}
{"index": 5955, "repo": "curator-recipes-5.5.0", "code": "Class PersistentTtlNode {\n\t// Call when you are done with the PersistentTtlNode.\n\tvoid close();\n\t// Return the current value of our data\n\tbyte[] getData();\n\t// Set data that node should set in ZK also writes the data to the node.\n\tvoid setData(byte[] data);\n\t// You must call start() to initiate the persistent ttl node\n\tvoid start();\n\t// Block until the either initial node creation initiated by start() succeeds or the timeout elapses.\n\tboolean waitForInitialCreate(long timeout, TimeUnit unit);\n}", "des": ""}
{"index": 5956, "repo": "curator-recipes-5.5.0", "code": "Class PersistentWatcher {\n\t// Remove the watcher\n\tvoid close();\n\t// Container for setting listeners\n\torg.apache.curator.framework.listen.Listenable<org.apache.zookeeper.Watcher> getListenable();\n\t// Listeners are called when the persistent watcher has been successfully registered or re-registered after a connection disruption\n\torg.apache.curator.framework.listen.Listenable<Runnable> getResetListenable();\n\t// Start watching\n\tvoid start();\n}", "des": "A managed persistent watcher. The watch will be managed such that it stays set through connection lapses, etc."}
{"index": 5957, "repo": "curator-recipes-5.5.0", "code": "Interface QueuePutListener<T> {\n\t// Notification that a single item put has completed\n\tvoid putCompleted(T item);\n\t// Notification that a multi item put has completed\n\tvoid putMultiCompleted(MultiItem<T> items);\n}", "des": "Queue puts are done in the background. Use this listener to be notified when the put completes"}
{"index": 5958, "repo": "curator-recipes-5.5.0", "code": "Interface QueueSerializer<T> {\n\t// Deserialize bytes into a queue item\n\tT deserialize(byte[] bytes);\n\t// Turn a queue item into bytes\n\tbyte[] serialize(T item);\n}", "des": "Helper to serialize/deserialize queue items"}
{"index": 5959, "repo": "curator-recipes-5.5.0", "code": "Class QueueSharder<U,T extends QueueBase<U>> {\n\tvoid close();\n\t// Return one of the managed queues - the selection method cannot be relied on.\n\tT getQueue();\n\t// Return the current set of shard paths\n\tCollection<String> getQueuePaths();\n\t// Return the current number of mananged queues\n\tint getShardQty();\n\t// The sharder must be started\n\tvoid start();\n}", "des": ""}
{"index": 5960, "repo": "curator-recipes-5.5.0", "code": "Interface Revocable<T> {\n\t// Make the lock revocable.\n\tvoid makeRevocable(RevocationListener<T> listener);\n\t// Make the lock revocable.\n\tvoid makeRevocable(RevocationListener<T> listener, Executor executor);\n}", "des": "Specifies locks that can be revoked"}
{"index": 5961, "repo": "curator-recipes-5.5.0", "code": "Interface SharedCountReader {\n\t// Return the current value of the count\n\tint getCount();\n\t// Return the current count and version\n\tVersionedValue<Integer> getVersionedValue();\n}", "des": "Abstracts a shared integer and allows listening for changes to its value"}
{"index": 5962, "repo": "curator-recipes-5.5.0", "code": "Interface SharedValueReader {\n\t// Returns the listenable\n\torg.apache.curator.framework.listen.Listenable<SharedValueListener> getListenable();\n\t// Return the current value of the count\n\tbyte[] getValue();\n\t// Return the current version and value\n\tVersionedValue<byte[]> getVersionedValue();\n}", "des": "Abstracts a shared value and allows listening for changes to the value"}
{"index": 5963, "repo": "curator-recipes-5.5.0", "code": "Enum TreeCacheEvent.Type {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TreeCacheEvent.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TreeCacheEvent.Type[] values();\n}", "des": "Type of change"}
{"index": 5964, "repo": "curator-recipes-5.5.0", "code": "Interface TreeCacheSelector {\n\t// Return true if this node should be returned from the cache\n\tboolean acceptChild(String fullPath);\n\t// Return true if children of this path should be cached.\n\tboolean traverseChildren(String fullPath);\n}", "des": ""}
{"index": 5965, "repo": "iceberg-api-1.3.0", "code": "Interface Action<ThisT,R> {\n\t// Executes this action.\n\tR execute();\n\t// Configures this action with an extra option.\n\tdefault ThisT option(java.lang.String name, java.lang.String value);\n\t// Configures this action with extra options.\n\tdefault ThisT options(java.util.Map<java.lang.String,java.lang.String> options);\n}", "des": "An action performed on a table."}
{"index": 5966, "repo": "iceberg-api-1.3.0", "code": "Interface AddedRowsScanTask {\n\t// A list of delete files to apply when reading the data file in this task.\n\tjava.util.List<DeleteFile> deletes();\n\t// The number of files that will be opened by this scan task.\n\tdefault int filesCount();\n\t// Returns the type of changes produced by this task (i.e.\n\tdefault ChangelogOperation operation();\n\t// The number of bytes that should be read by this scan task.\n\tdefault long sizeBytes();\n}", "des": "A scan task for inserts generated by adding a data file to the table."}
{"index": 5967, "repo": "iceberg-api-1.3.0", "code": "Interface AppendFiles {\n\t// Append a DataFile to the table.\n\tAppendFiles appendFile(DataFile file);\n\t// Append a ManifestFile to the table.\n\tAppendFiles appendManifest(ManifestFile file);\n}", "des": "API for appending new files in a table."}
{"index": 5968, "repo": "iceberg-api-1.3.0", "code": "Class Binder {\n\t// Replaces all unbound/named references with bound references to fields in the given struct.\n\tstatic Expression bind(Types.StructType struct, Expression expr, boolean caseSensitive);\n\tstatic java.util.Set<java.lang.Integer> boundReferences(Types.StructType struct, java.util.List<Expression> exprs, boolean caseSensitive);\n\t// Returns whether an expression is bound.\n\tstatic boolean isBound(Expression expr);\n}", "des": "Rewrites expressions by replacing unbound named references with references to fields in a struct schema."}
{"index": 5969, "repo": "iceberg-api-1.3.0", "code": "Interface Bound<T> {\n\t// Produce a value from the struct for this expression.\n\tT eval(StructLike struct);\n\t// Returns the underlying reference.\n\tBoundReference<?> ref();\n}", "des": "Represents a bound value expression."}
{"index": 5970, "repo": "iceberg-api-1.3.0", "code": "Interface BoundTerm<T> {\n\t// Returns a Comparator for values produced by this term.\n\tdefault java.util.Comparator<T> comparator();\n\t// Returns whether this term is equivalent to another.\n\tboolean isEquivalentTo(BoundTerm<?> other);\n\t// Returns the type produced by this expression.\n\tType type();\n}", "des": "Represents a bound term."}
{"index": 5971, "repo": "iceberg-api-1.3.0", "code": "Class BoundTransform<S,T> {\n\t// Produce a value from the struct for this expression.\n\tT eval(StructLike struct);\n\t// Returns whether this term is equivalent to another.\n\tboolean isEquivalentTo(BoundTerm<?> other);\n\t// Returns the underlying reference.\n\tBoundReference<S> ref();\n\tTransform<S,T> transform();\n\t// Returns the type produced by this expression.\n\tType type();\n}", "des": "A transform expression."}
{"index": 5972, "repo": "iceberg-api-1.3.0", "code": "Enum ChangelogOperation {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ChangelogOperation valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ChangelogOperation[] values();\n}", "des": "An enum representing possible operations in a changelog."}
{"index": 5973, "repo": "iceberg-api-1.3.0", "code": "Interface ChangelogScanTask {\n\t// Returns the ordinal of changes produced by this task.\n\tint changeOrdinal();\n\t// Returns the snapshot ID in which the changes were committed.\n\tlong commitSnapshotId();\n\t// Returns the type of changes produced by this task (i.e.\n\tChangelogOperation operation();\n}", "des": "A changelog scan task."}
{"index": 5974, "repo": "iceberg-api-1.3.0", "code": "Class CloseableGroup {\n\t// Register an autocloseables to be managed by this class.\n\tvoid addCloseable(java.lang.AutoCloseable autoCloseable);\n\t// Register a closeable to be managed by this class.\n\tvoid addCloseable(java.io.Closeable closeable);\n\t// Close all the registered resources.\n\tvoid close();\n\t// Whether to suppress failure when any of the closeable this class tracks throws exception during closing.\n\tvoid setSuppressCloseFailure(boolean shouldSuppress);\n}", "des": "This class acts as a helper for handling the closure of multiple resource. It can be used for either inheritance or composition. To use it, register resources to be closed via the add() calls, and call the corresponding close method when needed."}
{"index": 5975, "repo": "iceberg-api-1.3.0", "code": "Interface CombinedScanTask {\n\t// Returns this cast to CombinedScanTask if it is one\n\tdefault CombinedScanTask asCombinedScanTask();\n\t// Return the tasks in this combined task.\n\tjava.util.Collection<FileScanTask> files();\n\t// Returns scan tasks in this group.\n\tdefault java.util.Collection<FileScanTask> tasks();\n}", "des": "A scan task made of several ranges from files."}
{"index": 5976, "repo": "iceberg-api-1.3.0", "code": "Interface ConvertEqualityDeleteFiles.Result {\n\t// Returns the count of the added position delete files.\n\tint addedPositionDeleteFilesCount();\n\t// Returns the count of the deletes that been converted.\n\tint convertedEqualityDeleteFilesCount();\n}", "des": "The action result that contains a summary of the execution."}
{"index": 5977, "repo": "iceberg-api-1.3.0", "code": "Interface Counter {\n\t// Increment the counter by 1.\n\tvoid increment();\n\t// Increment the counter by the provided amount.\n\tdefault void increment(int amount);\n\t// Increment the counter by the provided amount.\n\tvoid increment(long amount);\n\t// Determines whether this counter is a NOOP counter.\n\tdefault boolean isNoop();\n\t// The unit of the counter.\n\tdefault MetricsContext.Unit unit();\n\t// Reports the current count.\n\tlong value();\n}", "des": "Generalized Counter interface for creating telemetry-related instances when counting events."}
{"index": 5978, "repo": "iceberg-api-1.3.0", "code": "Interface DataFile {\n\t// Returns type of content stored in the file; one of DATA, POSITION_DELETES, or EQUALITY_DELETES.\n\tdefault FileContent content();\n\t// Returns the set of field IDs used for equality comparison, in equality delete files.\n\tdefault java.util.List<java.lang.Integer> equalityFieldIds();\n\tstatic Types.StructType getType(Types.StructType partitionType);\n}", "des": "Interface for data files listed in a table manifest."}
{"index": 5979, "repo": "iceberg-api-1.3.0", "code": "Interface DataTask {\n\t// Returns this cast to DataTask if it is one\n\tdefault DataTask asDataTask();\n\t// Returns true if this is a DataTask, false otherwise.\n\tdefault boolean isDataTask();\n\t// Returns an iterable of StructLike rows.\n\tCloseableIterable<StructLike> rows();\n}", "des": "A task that returns data as rows instead of where to read data."}
{"index": 5980, "repo": "iceberg-api-1.3.0", "code": "Class DefaultCounter {\n\t// Increment the counter by 1.\n\tvoid increment();\n\t// Increment the counter by the provided amount.\n\tvoid increment(long amount);\n\t// The unit of the counter.\n\tMetricsContext.Unit unit();\n\t// Reports the current count.\n\tlong value();\n}", "des": "A default Counter implementation that uses an AtomicLong to count events."}
{"index": 5981, "repo": "iceberg-api-1.3.0", "code": "Class DefaultMetricsContext {\n\t// Get a named counter.\n\tCounter counter(java.lang.String name, MetricsContext.Unit unit);\n\tHistogram histogram(java.lang.String name);\n\t// Get a named timer.\n\tTimer timer(java.lang.String name, java.util.concurrent.TimeUnit unit);\n}", "des": "A default MetricsContext implementation that uses native Java counters/timers."}
{"index": 5982, "repo": "iceberg-api-1.3.0", "code": "Interface DeletedDataFileScanTask {\n\t// A list of previously added delete files to apply when reading the data file in this task.\n\tjava.util.List<DeleteFile> existingDeletes();\n\t// The number of files that will be opened by this scan task.\n\tdefault int filesCount();\n\t// Returns the type of changes produced by this task (i.e.\n\tdefault ChangelogOperation operation();\n\t// The number of bytes that should be read by this scan task.\n\tdefault long sizeBytes();\n}", "des": "A scan task for deletes generated by removing a data file from the table."}
{"index": 5983, "repo": "iceberg-api-1.3.0", "code": "Interface DeleteFiles {\n\t// Enables or disables case sensitive expression binding for methods that accept expressions.\n\tDeleteFiles caseSensitive(boolean caseSensitive);\n\t// Delete a file path from the underlying table.\n\tDeleteFiles deleteFile(java.lang.CharSequence path);\n\t// Delete a file tracked by a DataFile from the underlying table.\n\tdefault DeleteFiles deleteFile(DataFile file);\n\t// Delete files that match an Expression on data rows from the table.\n\tDeleteFiles deleteFromRowFilter(Expression expr);\n}", "des": "API for deleting files from a table."}
{"index": 5984, "repo": "iceberg-api-1.3.0", "code": "Enum DeleteOrphanFiles.PrefixMismatchMode {\n\tstatic DeleteOrphanFiles.PrefixMismatchMode fromString(java.lang.String modeAsString);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DeleteOrphanFiles.PrefixMismatchMode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DeleteOrphanFiles.PrefixMismatchMode[] values();\n}", "des": "Defines the action behavior when location prefixes (scheme/authority) mismatch."}
{"index": 5985, "repo": "iceberg-api-1.3.0", "code": "Interface DeleteReachableFiles {\n\t// Passes an alternative delete implementation that will be used for files.\n\tDeleteReachableFiles deleteWith(java.util.function.Consumer<java.lang.String> deleteFunc);\n\t// Passes an alternative executor service that will be used for files removal.\n\tDeleteReachableFiles executeDeleteWith(java.util.concurrent.ExecutorService executorService);\n\t// Set the FileIO to be used for files removal\n\tDeleteReachableFiles io(FileIO io);\n}", "des": "An action that deletes all files referenced by a table metadata file."}
{"index": 5986, "repo": "iceberg-api-1.3.0", "code": "Enum DistributionMode {\n\tstatic DistributionMode fromName(java.lang.String modeName);\n\tjava.lang.String modeName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DistributionMode valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DistributionMode[] values();\n}", "des": "Enum of supported write distribution mode, it defines the write behavior of batch or streaming job:"}
{"index": 5987, "repo": "iceberg-api-1.3.0", "code": "Interface EncryptedInputFile {\n\t// The InputFile that is reading raw encrypted bytes from the underlying file system.\n\tInputFile encryptedInputFile();\n\t// Metadata pointing to some encryption key that would be used to decrypt the input file provided by encryptedInputFile().\n\tEncryptionKeyMetadata keyMetadata();\n}", "des": "Thin wrapper around an InputFile instance that is encrypted."}
{"index": 5988, "repo": "iceberg-api-1.3.0", "code": "Interface EncryptedOutputFile {\n\t// An OutputFile instance that encrypts the bytes that are written to its output streams.\n\tOutputFile encryptingOutputFile();\n\t// Metadata about the encryption key that is being used to encrypt the associated encryptingOutputFile().\n\tEncryptionKeyMetadata keyMetadata();\n}", "des": "Thin wrapper around a OutputFile that is encrypting bytes written to the underlying file system, via an encryption key that is symbolized by the enclosed EncryptionKeyMetadata."}
{"index": 5989, "repo": "iceberg-api-1.3.0", "code": "Interface Expression {\n\t// Returns whether this expression will accept the same values as another.\n\tdefault boolean isEquivalentTo(Expression other);\n\t// Returns the negation of this expression, equivalent to not(this).\n\tdefault Expression negate();\n\t// Returns the operation for an expression node.\n\tExpression.Operation op();\n}", "des": "Represents a boolean expression tree."}
{"index": 5990, "repo": "iceberg-api-1.3.0", "code": "Class ExpressionVisitors {\n\t// Traverses the given expression with a visitor.\n\tstatic <R> R visit(Expression expr, ExpressionVisitors.CustomOrderExpressionVisitor<R> visitor);\n\t// Traverses the given expression with a visitor.\n\tstatic <R> R visit(Expression expr, ExpressionVisitors.ExpressionVisitor<R> visitor);\n\t// Traverses the given expression with a visitor.\n\tstatic java.lang.Boolean visitEvaluator(Expression expr, ExpressionVisitors.ExpressionVisitor<java.lang.Boolean> visitor);\n}", "des": "Utils for traversing expressions."}
{"index": 5991, "repo": "iceberg-api-1.3.0", "code": "Class False {\n\t// Returns whether this expression will accept the same values as another.\n\tboolean isEquivalentTo(Expression other);\n\t// Returns the negation of this expression, equivalent to not(this).\n\tExpression negate();\n\t// Returns the operation for an expression node.\n\tExpression.Operation op();\n}", "des": "An expression that is always false."}
{"index": 5992, "repo": "iceberg-api-1.3.0", "code": "Enum FileContent {\n\tint id();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileContent valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileContent[] values();\n}", "des": "Content type stored in a file, one of DATA, POSITION_DELETES, or EQUALITY_DELETES."}
{"index": 5993, "repo": "iceberg-api-1.3.0", "code": "Interface FileScanTask {\n\t// Returns this cast to FileScanTask if it is one\n\tdefault FileScanTask asFileScanTask();\n\t// A list of delete files to apply when reading the task's data file.\n\tjava.util.List<DeleteFile> deletes();\n\t// The number of files that will be opened by this scan task.\n\tdefault int filesCount();\n\t// Returns true if this is a FileScanTask, false otherwise.\n\tdefault boolean isFileScanTask();\n\t// The number of bytes that should be read by this scan task.\n\tdefault long sizeBytes();\n}", "des": "A scan task over a range of bytes in a single data file."}
{"index": 5994, "repo": "iceberg-api-1.3.0", "code": "Class FixedReservoirHistogram {\n\t// Return the number of observations.\n\tint count();\n\t// Naive algorithm for calculating variance: https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n\tHistogram.Statistics statistics();\n\t// Update the histogram with a new value observed.\n\tvoid update(long value);\n}", "des": "A Histogram implementation with reservoir sampling."}
{"index": 5995, "repo": "iceberg-api-1.3.0", "code": "Interface HistoryEntry {\n\t// Returns ID of the new current snapshot.\n\tlong snapshotId();\n\t// Returns the timestamp in milliseconds of the change.\n\tlong timestampMillis();\n}", "des": "Table history entry."}
{"index": 5996, "repo": "iceberg-api-1.3.0", "code": "Interface IncrementalScan<ThisT,T extends ScanTask,G extends ScanTaskGroup<T>> {\n\t// Instructs this scan to look for changes starting from a particular snapshot (exclusive).\n\tThisT fromSnapshotExclusive(long fromSnapshotId);\n\t// Instructs this scan to look for changes starting from a particular snapshot (inclusive).\n\tThisT fromSnapshotInclusive(long fromSnapshotId);\n\t// Instructs this scan to look for changes up to a particular snapshot (inclusive).\n\tThisT toSnapshot(long toSnapshotId);\n}", "des": "API for configuring an incremental scan."}
{"index": 5997, "repo": "iceberg-api-1.3.0", "code": "Interface InputFile {\n\t// Checks whether the file exists.\n\tboolean exists();\n\t// Returns the total length of the file, in bytes\n\tlong getLength();\n\t// The fully-qualified location of the input file as a String.\n\tjava.lang.String location();\n\t// Opens a new SeekableInputStream for the underlying data file\n\tSeekableInputStream newStream();\n}", "des": "An interface used to read input files using SeekableInputStream instances."}
{"index": 5998, "repo": "iceberg-api-1.3.0", "code": "Interface LocationProvider {\n\t// Return a fully-qualified data file location for the given partition and filename.\n\tjava.lang.String newDataLocation(PartitionSpec spec, StructLike partitionData, java.lang.String filename);\n\t// Return a fully-qualified data file location for the given filename.\n\tjava.lang.String newDataLocation(java.lang.String filename);\n}", "des": "Interface for providing data file locations to write tasks."}
{"index": 5999, "repo": "iceberg-api-1.3.0", "code": "Interface LockManager {\n\t// Try to acquire a lock\n\tboolean acquire(java.lang.String entityId, java.lang.String ownerId);\n\t// Initialize lock manager from catalog properties.\n\tvoid initialize(java.util.Map<java.lang.String,java.lang.String> properties);\n\t// Release a lock\n\tboolean release(java.lang.String entityId, java.lang.String ownerId);\n}", "des": "An interface for locking, used to ensure commit isolation."}
{"index": 6000, "repo": "iceberg-api-1.3.0", "code": "Enum ManifestContent {\n\tstatic ManifestContent fromId(int id);\n\tint id();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ManifestContent valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ManifestContent[] values();\n}", "des": "Content type stored in a manifest file, either DATA or DELETES."}
{"index": 6001, "repo": "iceberg-api-1.3.0", "code": "Interface MergeableScanTask<ThisT> {\n\t// Checks if this task can merge with a given task.\n\tboolean canMerge(ScanTask other);\n\t// Merges this task with a given task.\n\tThisT merge(ScanTask other);\n}", "des": "A scan task that can be potentially merged with other scan tasks."}
{"index": 6002, "repo": "iceberg-api-1.3.0", "code": "Interface MetricsReporter {\n\t// A custom MetricsReporter implementation must have a no-arg constructor, which will be called first.\n\tdefault void initialize(java.util.Map<java.lang.String,java.lang.String> properties);\n\t// Indicates that an operation is done by reporting a MetricsReport.\n\tvoid report(MetricsReport report);\n}", "des": "This interface defines the basic API for reporting metrics for operations to a Table."}
{"index": 6003, "repo": "iceberg-api-1.3.0", "code": "Interface MigrateTable {\n\t// Drops the backup of the original table after a successful migration\n\tdefault MigrateTable dropBackup();\n\t// Sets table properties in the newly created Iceberg table.\n\tMigrateTable tableProperties(java.util.Map<java.lang.String,java.lang.String> properties);\n\t// Sets a table property in the newly created Iceberg table.\n\tMigrateTable tableProperty(java.lang.String name, java.lang.String value);\n}", "des": "An action that migrates an existing table to Iceberg."}
{"index": 6004, "repo": "iceberg-api-1.3.0", "code": "Interface OutputFile {\n\t// Create a new file and return a PositionOutputStream to it.\n\tPositionOutputStream create();\n\t// Create a new file and return a PositionOutputStream to it.\n\tPositionOutputStream createOrOverwrite();\n\t// Return the location this output file will create.\n\tjava.lang.String location();\n\t// Return an InputFile for the location of this output file.\n\tInputFile toInputFile();\n}", "des": "An interface used to create output files using PositionOutputStream instances."}
{"index": 6005, "repo": "iceberg-api-1.3.0", "code": "Class PartitionField {\n\tboolean equals(java.lang.Object other);\n\t// Returns the partition field id across all the table metadata's partition specs.\n\tint fieldId();\n\t// Returns the name of this partition field.\n\tjava.lang.String name();\n\t// Returns the field id of the source field in the spec's table schema.\n\tint sourceId();\n\t// Returns the transform used to produce partition values from source values.\n\tTransform<?,?> transform();\n}", "des": "Represents a single field in a PartitionSpec."}
{"index": 6006, "repo": "iceberg-api-1.3.0", "code": "Interface PartitionScanTask {\n\t// Returns the value of the partition for this scan task\n\tStructLike partition();\n\t// Returns the spec of the partition for this scan task\n\tPartitionSpec spec();\n}", "des": "A scan task for data within a particular partition"}
{"index": 6007, "repo": "iceberg-api-1.3.0", "code": "Interface PendingUpdate<T> {\n\t// Apply the pending changes and return the uncommitted changes for validation.\n\tT apply();\n\t// Apply the pending changes and commit.\n\tvoid commit();\n\t// Generates update event to notify about metadata changes\n\tdefault java.lang.Object updateEvent();\n}", "des": "API for table metadata changes."}
{"index": 6008, "repo": "iceberg-api-1.3.0", "code": "Class ResidualEvaluator {\n\t// Return a residual evaluator for a spec and expression.\n\tstatic ResidualEvaluator of(PartitionSpec spec, Expression expr, boolean caseSensitive);\n\t// Returns a residual expression for the given partition values.\n\tExpression residualFor(StructLike partitionData);\n\t// Return a residual evaluator for an unpartitioned spec.\n\tstatic ResidualEvaluator unpartitioned(Expression expr);\n}", "des": "Finds the residuals for an Expression the partitions in the given PartitionSpec."}
{"index": 6009, "repo": "iceberg-api-1.3.0", "code": "Interface RewriteDataFiles.FileGroupInfo {\n\t// returns which file group this is out of the total set of file groups for this rewrite\n\tint globalIndex();\n\t// returns which partition this file group contains files from\n\tStructLike partition();\n\t// returns which file group this is out of the set of file groups for this partition\n\tint partitionIndex();\n}", "des": "A description of a file group, when it was processed, and within which partition. For use tracking rewrite operations and for returning results."}
{"index": 6010, "repo": "iceberg-api-1.3.0", "code": "Enum RewriteJobOrder {\n\tstatic RewriteJobOrder fromName(java.lang.String orderName);\n\tjava.lang.String orderName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RewriteJobOrder valueOf(java.lang.String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RewriteJobOrder[] values();\n}", "des": "Enum of supported rewrite job order, it defines the order in which the file groups should be written."}
{"index": 6011, "repo": "iceberg-api-1.3.0", "code": "Interface RewriteManifests {\n\t// Rewrites only manifests that match the given predicate.\n\tRewriteManifests rewriteIf(java.util.function.Predicate<ManifestFile> predicate);\n\t// Rewrites manifests for a given spec id.\n\tRewriteManifests specId(int specId);\n\t// Passes a location where the staged manifests should be written.\n\tRewriteManifests stagingLocation(java.lang.String stagingLocation);\n}", "des": "An action that rewrites manifests."}
{"index": 6012, "repo": "iceberg-api-1.3.0", "code": "Interface RewriteManifests.Result {\n\t// Returns added manifests.\n\tjava.lang.Iterable<ManifestFile> addedManifests();\n\t// Returns rewritten manifests.\n\tjava.lang.Iterable<ManifestFile> rewrittenManifests();\n}", "des": "The action result that contains a summary of the execution."}
{"index": 6013, "repo": "iceberg-api-1.3.0", "code": "Interface RewritePositionDeleteFiles.FileGroupInfo {\n\t// Returns which position delete file group this is out of the total set of file groups for this rewrite\n\tint globalIndex();\n\t// Returns which partition this position delete file group contains files from.\n\tStructLike partition();\n\t// Returns which position delete file group this is out of the set of file groups for this partition\n\tint partitionIndex();\n}", "des": "A description of a position delete file group, when it was processed, and within which partition. For use tracking rewrite operations and for returning results."}
{"index": 6014, "repo": "iceberg-api-1.3.0", "code": "Interface ScanTaskGroup<T extends ScanTask> {\n\t// The estimated number of rows produced by this scan task.\n\tdefault long estimatedRowsCount();\n\t// The number of files that will be opened by this scan task.\n\tdefault int filesCount();\n\t// Returns a grouping key for this task group.\n\tdefault StructLike groupingKey();\n\t// The number of bytes that should be read by this scan task.\n\tdefault long sizeBytes();\n\t// Returns scan tasks in this group.\n\tjava.util.Collection<T> tasks();\n}", "des": "A scan task that may include partial input files, multiple input files or both."}
{"index": 6015, "repo": "iceberg-api-1.3.0", "code": "Class SeekableInputStream {\n\t// Return the current position in the InputStream.\n\tabstract long getPos();\n\t// Seek to a new position in the InputStream.\n\tabstract void seek(long newPos);\n}", "des": "SeekableInputStream is an interface with the methods needed to read data from a file or Hadoop data stream."}
{"index": 6016, "repo": "iceberg-api-1.3.0", "code": "Class SortField {\n\t// Returns the sort direction\n\tSortDirection direction();\n\tboolean equals(java.lang.Object other);\n\t// Returns the null order\n\tNullOrder nullOrder();\n\t// Checks whether this field's order satisfies another field's order.\n\tboolean satisfies(SortField other);\n\t// Returns the field id of the source field in the sort order's table schema\n\tint sourceId();\n\t// Returns the transform used to produce sort values from source values.\n\t<S,T> Transform<S,T> transform();\n}", "des": "A field in a SortOrder."}
{"index": 6017, "repo": "iceberg-api-1.3.0", "code": "Interface StatisticsFile {\n\t// List of statistics contained in the file.\n\tjava.util.List<BlobMetadata> blobMetadata();\n\t// Size of the Puffin footer.\n\tlong fileFooterSizeInBytes();\n\t// Size of the file\n\tlong fileSizeInBytes();\n\t// Returns fully qualified path to the file, suitable for constructing a Hadoop Path.\n\tjava.lang.String path();\n\t// ID of the Iceberg table's snapshot the statistics were computed from.\n\tlong snapshotId();\n}", "des": "Represents a statistics file in the Puffin format, that can be used to read table data more efficiently."}
{"index": 6018, "repo": "iceberg-api-1.3.0", "code": "Interface SupportsPrefixOperations {\n\t// Delete all files under a prefix.\n\tvoid deletePrefix(java.lang.String prefix);\n\t// Return an iterable of all files under a prefix.\n\tjava.lang.Iterable<FileInfo> listPrefix(java.lang.String prefix);\n}", "des": "This interface is intended as an extension for FileIO implementations to provide additional prefix based operations that may be useful in performing supporting operations."}
{"index": 6019, "repo": "iceberg-api-1.3.0", "code": "Class TableIdentifier {\n\tboolean equals(java.lang.Object other);\n\t// Whether the namespace is empty.\n\tboolean hasNamespace();\n\t// Returns the identifier name.\n\tjava.lang.String name();\n\t// Returns the identifier namespace.\n\tNamespace namespace();\n\tstatic TableIdentifier of(Namespace namespace, java.lang.String name);\n\tstatic TableIdentifier of(java.lang.String... names);\n\tstatic TableIdentifier parse(java.lang.String identifier);\n\tTableIdentifier toLowerCase();\n}", "des": "Identifies a table in iceberg catalog."}
{"index": 6020, "repo": "iceberg-api-1.3.0", "code": "Class True {\n\t// Returns whether this expression will accept the same values as another.\n\tboolean isEquivalentTo(Expression other);\n\t// Returns the negation of this expression, equivalent to not(this).\n\tExpression negate();\n\t// Returns the operation for an expression node.\n\tExpression.Operation op();\n}", "des": "An expression that is always true."}
{"index": 6021, "repo": "iceberg-api-1.3.0", "code": "Interface Unbound<T,B> {\n\t// Bind this value expression to concrete types.\n\tB bind(Types.StructType struct, boolean caseSensitive);\n\t// Returns this expression's underlying reference.\n\tNamedReference<?> ref();\n}", "des": "Represents an unbound expression node."}
{"index": 6022, "repo": "iceberg-api-1.3.0", "code": "Interface UpdateProperties {\n\t// Set the default file format for the table.\n\tUpdateProperties defaultFormat(FileFormat format);\n\t// Remove the given property key from the table.\n\tUpdateProperties remove(java.lang.String key);\n\t// Add a key/value property to the table.\n\tUpdateProperties set(java.lang.String key, java.lang.String value);\n}", "des": "API for updating table properties."}
{"index": 6023, "repo": "iceberg-api-1.3.0", "code": "Interface UpdateStatistics {\n\t// Remove the table's statistics file for given snapshot.\n\tUpdateStatistics removeStatistics(long snapshotId);\n\t// Set the table's statistics file for given snapshot, replacing the previous statistics file for the snapshot if any exists.\n\tUpdateStatistics setStatistics(long snapshotId, StatisticsFile statisticsFile);\n}", "des": "API for updating statistics files in a table."}
{"index": 6024, "repo": "iceberg-api-1.3.0", "code": "Interface UpdateViewProperties {\n\t// Remove the given property key from the view.\n\tUpdateViewProperties remove(java.lang.String key);\n\t// Add a key/value property to the view.\n\tUpdateViewProperties set(java.lang.String key, java.lang.String value);\n}", "des": "API for updating view properties."}
{"index": 6025, "repo": "iceberg-api-1.3.0", "code": "Interface ViewHistoryEntry {\n\t// Return the timestamp in milliseconds of the change\n\tlong timestampMillis();\n\t// Return ID of the new current version\n\tint versionId();\n}", "des": "View history entry."}
{"index": 6026, "repo": "camel-azure-3.8.0", "code": "Enum BlobType {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic BlobType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic BlobType[] values();\n}", "des": "Blob Type"}
{"index": 6027, "repo": "spring-plugin-core-3.0.0", "code": "public abstract class PluginRegistrySupport<T extends Plugin<S>,S> extends Object implements PluginRegistry<T,S>, Iterable<T> {\n\t// Returns all registered plugins.\n\tList<T> getPlugins();\n\t// Callback to initialize the plugin List.\n\tprotected List<T> initialize(List<T> plugins);\n\tIterator<T> iterator();\n}", "des": "Base class for PluginRegistry implementations."}
{"index": 6028, "repo": "spring-hateoas-2.1.2", "code": "public static interface AffordanceModel.PayloadMetadata {\n\t// Deprecated. since 1.4, for removal in 1.5.\n\tdefault Optional<AffordanceModel.PropertyMetadata> getPropertyMetadata(String name);\n\tdefault Class<?> getType();\n\t// Returns all properties contained in a payload.\n\tStream<AffordanceModel.PropertyMetadata> stream();\n}", "des": "Metadata about payloads."}
{"index": 6029, "repo": "spring-hateoas-2.1.2", "code": "public interface AffordanceModelFactory {\n\t// Return the AffordanceModel for the given ConfiguredAffordance.\n\tAffordanceModel getAffordanceModel(ConfiguredAffordance configured);\n\t// Declare the MediaType this factory supports.\n\tMediaType getMediaType();\n}", "des": "SPI for media type implementations to create a specific AffordanceModel for a ConfiguredAffordance."}
{"index": 6030, "repo": "spring-hateoas-2.1.2", "code": "public class Affordances extends Object implements AffordanceOperations {\n\t// Creates a new Affordances.AffordanceBuilder for the given HTTP method for further customization.\n\tConfigurableAffordance afford(HttpMethod httpMethod);\n\tstatic Affordances of(Link link);\n\t// Returns all Affordances created.\n\tStream<Affordance> stream();\n\t// Returns a Link equipped with the Affordance currently under construction.\n\tLink toLink();\n}", "des": "Primary API to construct Affordance instances."}
{"index": 6031, "repo": "spring-hateoas-2.1.2", "code": "public final class Alps extends Object {\n\t// Returns a new Alps.AlpsBuilder.\n\tstatic Alps.AlpsBuilder alps();\n\t// Returns a new Descriptor.DescriptorBuilder.\n\tstatic Descriptor.DescriptorBuilder descriptor();\n\t// Returns a new Doc.DocBuilder.\n\tstatic Doc.DocBuilder doc();\n\tboolean equals(Object o);\n\t// Returns a new Ext.ExtBuilder.\n\tstatic Ext.ExtBuilder ext();\n\tList<Descriptor> getDescriptor();\n\tDoc getDoc();\n\tString getVersion();\n}", "des": "An ALPS document."}
{"index": 6032, "repo": "spring-hateoas-2.1.2", "code": "public class AnnotationAttribute extends Object {\n\t// Returns the annotation type.\n\tClass<? extends Annotation> getAnnotationType();\n\t// Returns the Annotation attribute's value from the given Annotation.\n\tString getValueFrom(Annotation annotation);\n\t// Reads the Annotation attribute's value from the given MethodParameter.\n\tString getValueFrom(MethodParameter parameter);\n}", "des": "Simply helper to reference a dedicated attribute of an Annotation."}
{"index": 6033, "repo": "spring-hateoas-2.1.2", "code": "public class BasicLinkBuilder extends LinkBuilderSupport<BasicLinkBuilder> {\n\t// Creates a new instance of the sub-class.\n\tprotected BasicLinkBuilder createNewInstance(UriComponents components, List<Affordance> affordances);\n\t// Returns the current concrete instance.\n\tprotected BasicLinkBuilder getThis();\n\t// Creates a new BasicLinkBuilder to link to the current servlet mapping.\n\tstatic BasicLinkBuilder linkToCurrentMapping();\n}", "des": "Simples LinkBuilder implementation possible."}
{"index": 6034, "repo": "spring-hateoas-2.1.2", "code": "public interface CurieProvider {\n\t// Returns an object to render as the base curie information.\n\tCollection<?> getCurieInformation(Links links);\n\t// Returns the rel to be rendered for the given rel.\n\tHalLinkRelation getNamespacedRelFor(LinkRelation rel);\n\t// Returns the rel to be rendered for the given Link.\n\tHalLinkRelation getNamespacedRelFrom(Link link);\n}", "des": "API to provide HAL curie information for links."}
{"index": 6035, "repo": "spring-hateoas-2.1.2", "code": "public interface EmbeddedWrapper {\n\t// Returns the rel to be used when embedding.\n\tOptional<LinkRelation> getRel();\n\t// Returns the type to be used to calculate a type based rel.\n\tClass<?> getRelTargetType();\n\t// Returns the actual value to embed.\n\tObject getValue();\n\t// Returns whether the wrapper has the given rel.\n\tboolean hasRel(LinkRelation rel);\n\t// Returns whether the wrapper is a collection value.\n\tboolean isCollectionValue();\n}", "des": "A wrapper to handle values to be embedded into a EntityModel."}
{"index": 6036, "repo": "spring-hateoas-2.1.2", "code": "public class EmbeddedWrappers extends Object {\n\t// Creates an EmbeddedWrapper for an empty Collection with the given element type.\n\tEmbeddedWrapper emptyCollectionOf(Class<?> type);\n\t// Creates a new EmbeddedWrapper that\n\tEmbeddedWrapper wrap(Object source);\n\t// Creates a new EmbeddedWrapper with the given rel.\n\tEmbeddedWrapper wrap(Object source, LinkRelation rel);\n}", "des": "Interface to mark objects that are aware of the rel they'd like to be exposed under."}
{"index": 6037, "repo": "spring-hateoas-2.1.2", "code": "public static enum EnableHypermediaSupport.HypermediaType extends Enum<EnableHypermediaSupport.HypermediaType> {\n\tString getLocalPackageName();\n\tMediaType getMediaType();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic EnableHypermediaSupport.HypermediaType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic EnableHypermediaSupport.HypermediaType[] values();\n}", "des": "Hypermedia representation types supported."}
{"index": 6038, "repo": "spring-hateoas-2.1.2", "code": "public class EntityModel<T> extends RepresentationModel<EntityModel<T>> {\n\tboolean equals(Object obj);\n\t// Returns the underlying entity.\n\tT getContent();\n\t// Creates a new EntityModel with the given content.\n\tstatic <T> EntityModel<T> of(T content);\n\t// Creates a new EntityModel with the given content and Links.\n\tstatic <T> EntityModel<T> of(T content, Iterable<Link> links);\n\t// Creates a new EntityModel with the given content and Links (optional).\n\tstatic <T> EntityModel<T> of(T content, Link... links);\n}", "des": "A simple EntityModel wrapping a domain object and adding links to it."}
{"index": 6039, "repo": "spring-hateoas-2.1.2", "code": "public enum Format extends Enum<Format> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Format valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Format[] values();\n}", "des": "Enum for all ALPS doc formats."}
{"index": 6040, "repo": "spring-hateoas-2.1.2", "code": "public static enum HalConfiguration.RenderSingleLinks extends Enum<HalConfiguration.RenderSingleLinks> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic HalConfiguration.RenderSingleLinks valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic HalConfiguration.RenderSingleLinks[] values();\n}", "des": "Configuration option how to render single links of a given LinkRelation."}
{"index": 6041, "repo": "spring-hateoas-2.1.2", "code": "public static class HalFormsOptions.Remote extends HalFormsOptions.AbstractHalFormsOptions<HalFormsOptions.Remote> {\n\t// Returns the Link pointing to the resource returning option values.\n\tLink getLink();\n\t// Create a new concrete HalFormsOptions.AbstractHalFormsOptions\n\tprotected HalFormsOptions.Remote with(String promptRef, String valueRef, Long minItems, Long maxItems, Object selectedValue);\n}", "des": "Representation of a remote options element."}
{"index": 6042, "repo": "spring-hateoas-2.1.2", "code": "public class HalFormsPromptedValue extends Object {\n\t// Returns the prompt to be used.\n\tObject getPrompt();\n\t// Returns the value.\n\tObject getValue();\n\t// Creates a new HalFormsPromptedValue with the given plain prompt and value.\n\tstatic HalFormsPromptedValue of(String prompt, Object value);\n\t// Creates a new HalFormsPromptedValue with the given prompt key to be used for i18nization and value.\n\tstatic HalFormsPromptedValue ofI18ned(String promptKey, Object value);\n}", "des": "A value object to describe prompted values for HAL-FORMS options' inline attribute or responses of resources pointed to by the link object."}
{"index": 6043, "repo": "spring-hateoas-2.1.2", "code": "@Configuration(proxyBeanMethods=false) public class HalMediaTypeConfiguration extends Object implements HypermediaMappingInformation {\n\t// Configure an ObjectMapper and register custom serializers and deserializers for the supported media types.\n\tcom.fasterxml.jackson.databind.ObjectMapper configureObjectMapper(com.fasterxml.jackson.databind.ObjectMapper mapper);\n\t// All MediaTypes this hypermedia can handle.\n\tList<MediaType> getMediaTypes();\n}", "des": "Spring configuration to set up HAL support."}
{"index": 6044, "repo": "spring-hateoas-2.1.2", "code": "public class HeaderLinksResponseEntity<T extends RepresentationModel<?>> extends ResponseEntity<T> {\n\t// Wraps the given HttpEntity into a HeaderLinksResponseEntity.\n\tstatic <S extends RepresentationModel<?>>HeaderLinksResponseEntity<S> wrap(HttpEntity<S> entity);\n\t// Wraps the given RepresentationModel into a HeaderLinksResponseEntity.\n\tstatic <S extends RepresentationModel<?>>HeaderLinksResponseEntity<S> wrap(S entity);\n}", "des": "Special ResponseEntity that exposes Link instances in the contained RepresentationModel as link headers instead of in the body."}
{"index": 6045, "repo": "spring-hateoas-2.1.2", "code": "public class HtmlInputType extends Object {\n\t// Returns the HtmlInputType derived from the given ResolvableType.\n\tstatic HtmlInputType from(Class<?> type);\n\t// Returns the HtmlInputType for the given string value.\n\tstatic HtmlInputType of(String value);\n\tString value();\n}", "des": "The types of HTML <input  /> elements."}
{"index": 6046, "repo": "spring-hateoas-2.1.2", "code": "public final class IanaLinkRelations extends Object {\n\t// Is this relation an IANA standard?\n\tstatic boolean isIanaRel(String relation);\n\t// Is this relation an IANA standard?\n\tstatic boolean isIanaRel(LinkRelation relation);\n\t// Convert a string-based link relation to a IanaLinkRelations.\n\tstatic LinkRelation parse(String relation);\n}", "des": "Capture standard IANA-based link relations."}
{"index": 6047, "repo": "spring-hateoas-2.1.2", "code": "public final class JacksonHelper extends Object {\n\t// Navigate a chain of parametric types (e.g.\n\tstatic com.fasterxml.jackson.databind.JavaType findRootType(com.fasterxml.jackson.databind.JavaType contentType);\n\t// Is this a Resources<Resource<?>>?\n\tstatic boolean isResourcesOfResource(com.fasterxml.jackson.databind.JavaType type);\n}", "des": "Jackson utility methods."}
{"index": 6048, "repo": "spring-hateoas-2.1.2", "code": "public static enum Links.MergeMode extends Enum<Links.MergeMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Links.MergeMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Links.MergeMode[] values();\n}", "des": "The mode how to merge two Links instances."}
{"index": 6049, "repo": "spring-hateoas-2.1.2", "code": "public interface MediaTypeConfigurationProvider {\n\t// Returns the primary Spring configuration class to be bootstrapped for the given media type.\n\tClass<? extends HypermediaMappingInformation> getConfiguration();\n\t// Returns whether the provider supports any of the given MediaTypes.\n\tboolean supportsAny(Collection<MediaType> mediaTypes);\n}", "des": "SPI used to register internal media types through spring.factories."}
{"index": 6050, "repo": "spring-hateoas-2.1.2", "code": "public interface MessageResolver {\n\t// Obtains a MessageResolver for the given MessageSource.\n\tstatic MessageResolver of(MessageSource messageSource);\n\t// Resolve the given MessageSourceResolvable.\n\tString resolve(MessageSourceResolvable resolvable);\n}", "des": "A simplified variant of MessageSourceAccessor to allow more direct replacement with a no-op implementation in case the target MessageSource is unavailable to avoid resolution overhead."}
{"index": 6051, "repo": "spring-hateoas-2.1.2", "code": "public static class PagedModel.PageMetadata extends Object {\n\tboolean equals(Object obj);\n\t// Returns the number of the current page.\n\tlong getNumber();\n\t// Returns the requested size of the page.\n\tlong getSize();\n\t// Returns the total number of elements available.\n\tlong getTotalElements();\n\t// Returns how many pages are available in total.\n\tlong getTotalPages();\n}", "des": "Value object for pagination metadata."}
{"index": 6052, "repo": "spring-hateoas-2.1.2", "code": "public interface RepresentationModelAssembler<T,D extends RepresentationModel<?>> {\n\t// Converts an Iterable or Ts into an Iterable of RepresentationModel and wraps them in a CollectionModel instance.\n\tdefault CollectionModel<D> toCollectionModel(Iterable<? extends T> entities);\n\t// Converts the given entity into a D, which extends RepresentationModel.\n\tD toModel(T entity);\n}", "des": "Interface for components that convert a domain type into a RepresentationModel."}
{"index": 6053, "repo": "spring-hateoas-2.1.2", "code": "public class RepresentationModelProcessorInvoker extends Object {\n\t// Invokes all RepresentationModelProcessor instances registered for the type of the given value.\n\t<T extends RepresentationModel<T>>T invokeProcessorsFor(T value);\n\t// Invokes all RepresentationModelProcessor instances registered for the type of the given value and reference type.\n\t<T extends RepresentationModel<T>>T invokeProcessorsFor(T value, ResolvableType referenceType);\n}", "des": "Component to easily invoke all RepresentationModelProcessor instances registered for values of type RepresentationModel."}
{"index": 6054, "repo": "spring-hateoas-2.1.2", "code": "public static class SlicedModel.SliceMetadata extends Object {\n\tboolean equals(Object obj);\n\t// Returns the number of the current slice.\n\tlong getNumber();\n\t// Returns the requested size of the slice.\n\tlong getSize();\n}", "des": "Value object for slice metadata."}
{"index": 6055, "repo": "spring-hateoas-2.1.2", "code": "public class SpringAffordanceBuilder extends Object {\n\t// Returns all Affordances for the given type's method and base URI.\n\tstatic List<Affordance> getAffordances(Class<?> type, Method method, String href);\n\t// Deprecated. since 2.0, use getUriMapping(Class, Method) instead.\n\tstatic String getMapping(Class<?> type, Method method);\n\t// Returns the mapping for the given type's method.\n\tstatic UriMapping getUriMapping(Class<?> type, Method method);\n}", "des": "Extract information needed to assemble an Affordance from a Spring MVC web method."}
{"index": 6056, "repo": "spring-hateoas-2.1.2", "code": "public static enum TemplateVariable.Cardinality extends Enum<TemplateVariable.Cardinality> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic TemplateVariable.Cardinality valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic TemplateVariable.Cardinality[] values();\n}", "des": "The cardinality of the TemplateVariable."}
{"index": 6057, "repo": "spring-hateoas-2.1.2", "code": "public interface TraversonDefaults {\n\t// Returns the HttpMessageConverter instances to be registered for the given MediaTypes.\n\tList<HttpMessageConverter<?>> getHttpMessageConverters(Collection<MediaType> mediaTypes);\n\t// Returns the LinkDiscoverers to be registered by default for the given MediaTypes.\n\tList<LinkDiscoverer> getLinkDiscoverers(Collection<MediaType> mediaTypes);\n}", "des": "SPI that exposes HttpMessageConverters and LinkDiscoverers to be used by default by Traverson."}
{"index": 6058, "repo": "spring-hateoas-2.1.2", "code": "public enum Type extends Enum<Type> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Type valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Type[] values();\n}", "des": "An enum for ALPS descriptor types"}
{"index": 6059, "repo": "spring-hateoas-2.1.2", "code": "public class TypedEntityLinks<T> extends Object {\n\t// Returns a LinkBuilder able to create links to the controller managing the given entity.\n\tLinkBuilder linkForItemResource(T entity);\n\t// Creates a Link pointing to item resource backing the given entity.\n\tLink linkToItemResource(T entity);\n}", "des": "Entity links API to create Links and LinkBuilder instances based on an identifier function."}
{"index": 6060, "repo": "spring-hateoas-2.1.2", "code": "public interface UriComponentsContributor {\n\t// Enhance the given UriComponentsBuilder with the given value.\n\tvoid enhance(UriComponentsBuilder builder, MethodParameter parameter, Object value);\n\t// Returns whether the UriComponentsBuilder supports the given MethodParameter.\n\tboolean supportsParameter(MethodParameter parameter);\n}", "des": "SPI callback to enhance a UriComponentsBuilder when referring to a method through a dummy method invocation."}
{"index": 6061, "repo": "spring-hateoas-2.1.2", "code": "public class UriMapping extends Object {\n\t// Returns the raw mapping.\n\tString getMapping();\n\t// Creates a new UriMapping from a given source mapping string.\n\tstatic UriMapping of(String source);\n}", "des": "A URI mapping on a controller method."}
{"index": 6062, "repo": "spring-hateoas-2.1.2", "code": "public class WebConverters extends Object {\n\tvoid augmentClient(List<HttpMessageConverter<?>> converters);\n\t// Augments the given List of HttpMessageConverters with the hypermedia enabled ones.\n\tvoid augmentServer(List<HttpMessageConverter<?>> converters);\n\t// Creates a new WebConverters from the given ObjectMapper and HypermediaMappingInformations.\n\tstatic WebConverters of(com.fasterxml.jackson.databind.ObjectMapper mapper, List<HypermediaMappingInformation> mappingInformations);\n}", "des": "Value type to handle registration of hypermedia related HttpMessageConverters."}
{"index": 6063, "repo": "spring-hateoas-2.1.2", "code": "public enum WebStack extends Enum<WebStack> {\n\t// Based on what client/server components are on the classpath, return what configuration classes should be registered.\n\tList<String> getAvailableConfigurations();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic WebStack valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic WebStack[] values();\n}", "des": "Utility to glean what web stack is currently available."}
{"index": 6064, "repo": "spring-integration-smb-6.1.2", "code": "public class SmbInboundChannelAdapterSpec extends org.springframework.integration.file.dsl.RemoteFileInboundChannelAdapterSpec<jcifs.smb.SmbFile,SmbInboundChannelAdapterSpec,SmbInboundFileSynchronizingMessageSource> {\n\t// Specify a simple pattern to match remote files.\n\tSmbInboundChannelAdapterSpec patternFilter(String pattern);\n\t// Specify a regular expression to match remote files.\n\tSmbInboundChannelAdapterSpec regexFilter(String regex);\n}", "des": "A RemoteFileInboundChannelAdapterSpec for an SmbInboundFileSynchronizingMessageSource."}
{"index": 6065, "repo": "spring-integration-smb-6.1.2", "code": "public class SmbStreamingInboundChannelAdapterSpec extends org.springframework.integration.file.dsl.RemoteFileStreamingInboundChannelAdapterSpec<jcifs.smb.SmbFile,SmbStreamingInboundChannelAdapterSpec,SmbStreamingMessageSource> {\n\t// Specify a simple pattern to match remote files (e.g.\n\tSmbStreamingInboundChannelAdapterSpec patternFilter(String pattern);\n\t// Specify a regular expression to match remote files (e.g.\n\tSmbStreamingInboundChannelAdapterSpec regexFilter(String regex);\n}", "des": "A RemoteFileStreamingInboundChannelAdapterSpec for a SmbStreamingMessageSource."}
{"index": 6066, "repo": "spring-core-6.0.11", "code": "public abstract class AbstractClassTestingTypeFilter extends Object implements TypeFilter {\n\t// Determine a match based on the given ClassMetadata object.\n\tprotected abstract boolean match(ClassMetadata metadata);\n\t// Determine whether this filter matches for the class described by the given metadata.\n\tfinal boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory);\n}", "des": "Type filter that exposes a ClassMetadata object to subclasses, for class testing purposes."}
{"index": 6067, "repo": "spring-core-6.0.11", "code": "public static enum AccessControl.Visibility extends Enum<AccessControl.Visibility> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic AccessControl.Visibility valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic AccessControl.Visibility[] values();\n}", "des": "Access visibility types as determined by the modifiers on a Member or ResolvableType."}
{"index": 6068, "repo": "spring-core-6.0.11", "code": "public interface AliasRegistry {\n\t// Return the aliases for the given name, if defined.\n\tString[] getAliases(String name);\n\t// Determine whether the given name is defined as an alias (as opposed to the name of an actually registered component).\n\tboolean isAlias(String name);\n\t// Given a name, register an alias for it.\n\tvoid registerAlias(String name, String alias);\n\t// Remove the specified alias from this registry.\n\tvoid removeAlias(String alias);\n}", "des": "Common interface for managing aliases."}
{"index": 6069, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public interface AnnotationFilter {\n\t// Test if the given annotation matches the filter.\n\tdefault boolean matches(Annotation annotation);\n\t// Test if the given type matches the filter.\n\tdefault boolean matches(Class<?> type);\n\t// Test if the given type name matches the filter.\n\tboolean matches(String typeName);\n\t// Create a new AnnotationFilter that matches annotations in the specified packages.\n\tstatic AnnotationFilter packages(String... packages);\n}", "des": "Callback interface that can be used to filter specific annotation types."}
{"index": 6070, "repo": "spring-core-6.0.11", "code": "public final class BridgeMethodResolver extends Object {\n\t// Find the original method for the supplied bridge Method.\n\tstatic Method findBridgedMethod(Method bridgeMethod);\n\t// Compare the signatures of the bridge method and the method which it bridges.\n\tstatic boolean isVisibilityBridgeMethodPair(Method bridgeMethod, Method bridgedMethod);\n}", "des": "Helper for resolving synthetic bridge Methods to the Method being bridged."}
{"index": 6071, "repo": "spring-core-6.0.11", "code": "public class ByteArrayDecoder extends AbstractDataBufferDecoder<byte[]> {\n\t// Whether the decoder supports the given target element type and the MIME type of the source stream.\n\tboolean canDecode(ResolvableType elementType, MimeType mimeType);\n\t// Decode a data buffer to an Object of type T.\n\tbyte[] decode(DataBuffer dataBuffer, ResolvableType elementType, MimeType mimeType, Map<String,Object> hints);\n}", "des": "Decoder for byte arrays."}
{"index": 6072, "repo": "spring-core-6.0.11", "code": "public class ByteBufferDecoder extends AbstractDataBufferDecoder<ByteBuffer> {\n\t// Whether the decoder supports the given target element type and the MIME type of the source stream.\n\tboolean canDecode(ResolvableType elementType, MimeType mimeType);\n\t// Decode a data buffer to an Object of type T.\n\tByteBuffer decode(DataBuffer dataBuffer, ResolvableType elementType, MimeType mimeType, Map<String,Object> hints);\n}", "des": "Decoder for ByteBuffers."}
{"index": 6073, "repo": "spring-core-6.0.11", "code": "public class CachingMetadataReaderFactory extends SimpleMetadataReaderFactory {\n\t// Clear the local MetadataReader cache, if any, removing all cached class metadata.\n\tvoid clearCache();\n\t// Return the maximum number of entries for the MetadataReader cache.\n\tint getCacheLimit();\n\t// Obtain a MetadataReader for the given resource.\n\tMetadataReader getMetadataReader(Resource resource);\n\t// Specify the maximum number of entries for the MetadataReader cache.\n\tvoid setCacheLimit(int cacheLimit);\n}", "des": "Caching implementation of the MetadataReaderFactory interface, caching a MetadataReader instance per Spring Resource handle (i.e."}
{"index": 6074, "repo": "spring-core-6.0.11", "code": "public interface CallbackFilter {\n\t// Map a method to a callback.\n\tint accept(Method method);\n\t// The CallbackFilter in use affects which cached class the Enhancer will use, so this is a reminder that you should correctly implement equals and hashCode for custom CallbackFilter implementations in order to improve performance.\n\tboolean equals(Object o);\n}", "des": "Map methods of subclasses generated by Enhancer to a particular callback."}
{"index": 6075, "repo": "spring-core-6.0.11", "code": "public final class ClassTooLargeException extends IndexOutOfBoundsException {\n\t// Returns the internal name of the class (see org.objectweb.asm.Type#getInternalName()).\n\tString getClassName();\n\t// Returns the number of constant pool items of the class.\n\tint getConstantPoolCount();\n}", "des": "Exception thrown when the constant pool of a class produced by a ClassWriter is too large."}
{"index": 6076, "repo": "spring-core-6.0.11", "code": "protected static interface ConcurrentReferenceHashMap.Reference<K,V> {\n\t// Return the referenced entry, or null if the entry is no longer available.\n\tConcurrentReferenceHashMap.Entry<K,V> get();\n\t// Return the hash for the reference.\n\tint getHash();\n\t// Return the next reference in the chain, or null if none.\n\tConcurrentReferenceHashMap.Reference<K,V> getNext();\n\t// Release this entry and ensure that it will be returned from ReferenceManager#pollForPurge().\n\tvoid release();\n}", "des": "A reference to an ConcurrentReferenceHashMap.Entry contained in the map."}
{"index": 6077, "repo": "spring-core-6.0.11", "code": "public static enum ConcurrentReferenceHashMap.ReferenceType extends Enum<ConcurrentReferenceHashMap.ReferenceType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ConcurrentReferenceHashMap.ReferenceType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ConcurrentReferenceHashMap.ReferenceType[] values();\n}", "des": "Various reference types supported by this map."}
{"index": 6078, "repo": "spring-core-6.0.11", "code": "protected static enum ConcurrentReferenceHashMap.Restructure extends Enum<ConcurrentReferenceHashMap.Restructure> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ConcurrentReferenceHashMap.Restructure valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ConcurrentReferenceHashMap.Restructure[] values();\n}", "des": "The types of restructuring that can be performed."}
{"index": 6079, "repo": "spring-core-6.0.11", "code": "public interface ConditionalHint {\n\t// Whether the condition described for this hint is met.\n\tdefault boolean conditionMatches(ClassLoader classLoader);\n\t// Return the type that should be reachable for this hint to apply, or null if this hint should always been applied.\n\tTypeReference getReachableType();\n}", "des": "Contract for runtime hints that only apply if the described condition is met."}
{"index": 6080, "repo": "spring-core-6.0.11", "code": "public class ConversionFailedException extends ConversionException {\n\t// Return the source type we tried to convert the value from.\n\tTypeDescriptor getSourceType();\n\t// Return the target type we tried to convert the value to.\n\tTypeDescriptor getTargetType();\n\t// Return the offending value.\n\tObject getValue();\n}", "des": "Exception to be thrown when an actual type conversion attempt fails."}
{"index": 6081, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public interface Converter<S,T> {\n\t// Construct a composed Converter that first applies this Converter to its input, and then applies the after Converter to the result.\n\tdefault <U> Converter<S,U> andThen(Converter<? super T,? extends U> after);\n\t// Convert the source object of type S to target type T.\n\tT convert(S source);\n}", "des": "A converter converts a source object of type S to a target of type T."}
{"index": 6082, "repo": "spring-core-6.0.11", "code": "public class ConverterNotFoundException extends ConversionException {\n\t// Return the source type that was requested to convert from.\n\tTypeDescriptor getSourceType();\n\t// Return the target type that was requested to convert to.\n\tTypeDescriptor getTargetType();\n}", "des": "Exception to be thrown when a suitable converter could not be found in a given conversion service."}
{"index": 6083, "repo": "spring-core-6.0.11", "code": "public class ConvertingComparator<S,T> extends Object implements Comparator<S> {\n\tint compare(S o1, S o2);\n\t// Create a new ConvertingComparator that compares map entries based on their keys.\n\tstatic <K, V> ConvertingComparator<Map.Entry<K,V>,K> mapEntryKeys(Comparator<K> comparator);\n\t// Create a new ConvertingComparator that compares map entries based on their values.\n\tstatic <K, V> ConvertingComparator<Map.Entry<K,V>,V> mapEntryValues(Comparator<V> comparator);\n}", "des": "A Comparator that converts values before they are compared."}
{"index": 6084, "repo": "spring-core-6.0.11", "code": "public static interface DataBufferUtils.Matcher {\n\t// Return the delimiter from the last invocation of match(DataBuffer).\n\tbyte[] delimiter();\n\t// Find the first matching delimiter and return the index of the last byte of the delimiter, or -1 if not found.\n\tint match(DataBuffer dataBuffer);\n\t// Reset the state of this matcher.\n\tvoid reset();\n}", "des": "Contract to find delimiter(s) against one or more data buffers that can be passed one at a time to the DataBufferUtils.Matcher.match(DataBuffer) method."}
{"index": 6085, "repo": "spring-core-6.0.11", "code": "public enum DataUnit extends Enum<DataUnit> {\n\t// Return the DataUnit matching the specified suffix.\n\tstatic DataUnit fromSuffix(String suffix);\n\t// Returns the enum constant of this class with the specified name.\n\tstatic DataUnit valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic DataUnit[] values();\n}", "des": "A standard set of DataSize units."}
{"index": 6086, "repo": "spring-core-6.0.11", "code": "public abstract class DecoratingClassLoader extends ClassLoader {\n\t// Add a class name to exclude from decoration (e.g.\n\tvoid excludeClass(String className);\n\t// Add a package name to exclude from decoration (e.g.\n\tvoid excludePackage(String packageName);\n\t// Determine whether the specified class is excluded from decoration by this class loader.\n\tprotected boolean isExcluded(String className);\n}", "des": "Base class for decorating ClassLoaders such as OverridingClassLoader and org.springframework.instrument.classloading.ShadowingClassLoader, providing common handling of excluded packages and classes."}
{"index": 6087, "repo": "spring-core-6.0.11", "code": "public class DefaultConversionService extends GenericConversionService {\n\t// Add common collection converters.\n\tstatic void addCollectionConverters(ConverterRegistry converterRegistry);\n\t// Add converters appropriate for most environments.\n\tstatic void addDefaultConverters(ConverterRegistry converterRegistry);\n\t// Return a shared default ConversionService instance, lazily building it once needed.\n\tstatic ConversionService getSharedInstance();\n}", "des": "A specialization of GenericConversionService configured by default with converters appropriate for most environments."}
{"index": 6088, "repo": "spring-core-6.0.11", "code": "protected static class DefaultResourceLoader.ClassPathContextResource extends ClassPathResource implements ContextResource {\n\t// This implementation creates a ClassPathResource, applying the given path relative to the path used to create this descriptor.\n\tResource createRelative(String relativePath);\n\t// Return the path within the enclosing 'context'.\n\tString getPathWithinContext();\n}", "des": "ClassPathResource that explicitly expresses a context-relative path through implementing the ContextResource interface."}
{"index": 6089, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public interface Deserializer<T> {\n\t// Read (assemble) an object of type T from the given InputStream.\n\tT deserialize(InputStream inputStream);\n\t// Read (assemble) an object of type T from the given byte array.\n\tdefault T deserializeFromByteArray(byte[] serialized);\n}", "des": "A strategy interface for converting from data in an InputStream to an Object."}
{"index": 6090, "repo": "spring-core-6.0.11", "code": "public abstract class EnumerablePropertySource<T> extends PropertySource<T> {\n\t// Return whether this PropertySource contains a property with the given name.\n\tboolean containsProperty(String name);\n\t// Return the names of all properties contained by the source object (never null).\n\tabstract String[] getPropertyNames();\n}", "des": "A PropertySource implementation capable of interrogating its underlying source object to enumerate all possible property name/value pairs."}
{"index": 6091, "repo": "spring-core-6.0.11", "code": "public final class ExecutableHint extends MemberHint {\n\t// Return a Consumer that applies the given ExecutableMode to the accepted ExecutableHint.Builder.\n\tstatic Consumer<ExecutableHint.Builder> builtWith(ExecutableMode mode);\n\t// Return the mode that applies to this hint.\n\tExecutableMode getMode();\n\t// Return the parameter types of the executable.\n\tList<TypeReference> getParameterTypes();\n}", "des": "A hint that describes the need for reflection on a Method or Constructor."}
{"index": 6092, "repo": "spring-core-6.0.11", "code": "public enum ExecutableMode extends Enum<ExecutableMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ExecutableMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ExecutableMode[] values();\n}", "des": "Represent the need of reflection for a given Executable."}
{"index": 6093, "repo": "spring-core-6.0.11", "code": "public interface FieldTypeCustomizer extends KeyFactoryCustomizer {\n\t// Customizes this.FIELD_0 = ? assignment in key constructor\n\tvoid customize(CodeEmitter e, int index, Type type);\n\t// Computes type of field for storing given parameter\n\tType getOutType(int index, Type type);\n}", "des": "Customizes key types for KeyFactory right in constructor."}
{"index": 6094, "repo": "spring-core-6.0.11", "code": "public class FixedBackOff extends Object implements BackOff {\n\t// Return the interval between two attempts in milliseconds.\n\tlong getInterval();\n\t// Return the maximum number of attempts in milliseconds.\n\tlong getMaxAttempts();\n\t// Set the interval between two attempts in milliseconds.\n\tvoid setInterval(long interval);\n\t// Set the maximum number of attempts in milliseconds.\n\tvoid setMaxAttempts(long maxAttempts);\n\t// Start a new back off execution.\n\tBackOffExecution start();\n}", "des": "A simple BackOff implementation that provides a fixed interval between two attempts and a maximum number of retries."}
{"index": 6095, "repo": "spring-core-6.0.11", "code": "public static enum GeneratedFiles.Kind extends Enum<GeneratedFiles.Kind> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic GeneratedFiles.Kind valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic GeneratedFiles.Kind[] values();\n}", "des": "The various kinds of generated files that are supported."}
{"index": 6096, "repo": "spring-core-6.0.11", "code": "public final class GeneratedMethod extends Object {\n\t// Return the generated name of the method.\n\tString getName();\n\t// Return a MethodReference to this generated method.\n\tMethodReference toMethodReference();\n}", "des": "A generated method."}
{"index": 6097, "repo": "spring-core-6.0.11", "code": "public class GeneratedMethods extends Object {\n\t// Add a new GeneratedMethod.\n\tGeneratedMethod add(String[] suggestedNameParts, Consumer<org.springframework.javapoet.MethodSpec.Builder> method);\n\t// Add a new GeneratedMethod.\n\tGeneratedMethod add(String suggestedName, Consumer<org.springframework.javapoet.MethodSpec.Builder> method);\n\t// Specify the prefix to use for method names.\n\tGeneratedMethods withPrefix(String prefix);\n}", "des": "A managed collection of generated methods."}
{"index": 6098, "repo": "spring-core-6.0.11", "code": "public interface GenerationContext {\n\t// Get the GeneratedClasses used by the context.\n\tGeneratedClasses getGeneratedClasses();\n\t// Get the GeneratedFiles used by the context.\n\tGeneratedFiles getGeneratedFiles();\n\t// Get the RuntimeHints used by the context.\n\tRuntimeHints getRuntimeHints();\n\t// Create a new GenerationContext instance using the specified name to qualify generated assets for a dedicated round of code generation.\n\tGenerationContext withName(String name);\n}", "des": "Central interface used for code generation."}
{"index": 6099, "repo": "spring-core-6.0.11", "code": "public interface GeneratorStrategy {\n\t// The GeneratorStrategy in use does not currently, but may in the future, affect the caching of classes generated by AbstractClassGenerator, so this is a reminder that you should correctly implement equals and hashCode to avoid generating too many classes.\n\tboolean equals(Object o);\n\t// Generate the class.\n\tbyte[] generate(ClassGenerator cg);\n}", "des": "The GeneratorStrategy is responsible for taking a ClassGenerator and producing a byte array containing the data for the generated Class."}
{"index": 6100, "repo": "spring-core-6.0.11", "code": "public interface GenericConverter {\n\t// Convert the source object to the targetType described by the TypeDescriptor.\n\tObject convert(Object source, TypeDescriptor sourceType, TypeDescriptor targetType);\n\t// Return the source and target types that this converter can convert between.\n\tSet<GenericConverter.ConvertiblePair> getConvertibleTypes();\n}", "des": "Generic converter interface for converting between two or more types."}
{"index": 6101, "repo": "spring-core-6.0.11", "code": "public class InstanceFilter<T> extends Object {\n\t// Determine if the specified instance matches this filter.\n\tboolean match(T instance);\n\t// Determine if the specified instance matches one of the candidates.\n\tprotected boolean match(T instance, Collection<? extends T> candidates);\n\t// Determine if the specified instance is equal to the specified candidate.\n\tprotected boolean match(T instance, T candidate);\n}", "des": "A simple instance filter that checks if a given instance match based on a collection of includes and excludes element."}
{"index": 6102, "repo": "spring-core-6.0.11", "code": "public class JavaSerializationHint extends Object implements ConditionalHint {\n\tboolean equals(Object o);\n\t// Return the type that should be reachable for this hint to apply, or null if this hint should always been applied.\n\tTypeReference getReachableType();\n\t// Return the type that needs to be serialized using Java serialization at runtime.\n\tTypeReference getType();\n}", "des": "A hint that describes the need for Java serialization at runtime."}
{"index": 6103, "repo": "spring-core-6.0.11", "code": "public static class JdkProxyHint.Builder extends Object {\n\t// Make this hint conditional on the fact that the specified type can be resolved.\n\tJdkProxyHint.Builder onReachableType(TypeReference reachableType);\n\t// Add the specified interfaces that the proxy should implement.\n\tJdkProxyHint.Builder proxiedInterfaces(Class<?>... proxiedInterfaces);\n\t// Add the specified interfaces that the proxy should implement.\n\tJdkProxyHint.Builder proxiedInterfaces(TypeReference... proxiedInterfaces);\n}", "des": "Builder for JdkProxyHint."}
{"index": 6104, "repo": "spring-core-6.0.11", "code": "public abstract class KotlinDetector extends Object {\n\t// Determine whether Kotlin is present in general.\n\tstatic boolean isKotlinPresent();\n\t// Determine whether Kotlin reflection is present.\n\tstatic boolean isKotlinReflectPresent();\n\t// Determine whether the given Class is a Kotlin type (with Kotlin metadata present on it).\n\tstatic boolean isKotlinType(Class<?> clazz);\n\t// Return true if the method is a suspending function.\n\tstatic boolean isSuspendingFunction(Method method);\n}", "des": "A common delegate for detecting Kotlin's presence and for identifying Kotlin types."}
{"index": 6105, "repo": "spring-core-6.0.11", "code": "public class KotlinReflectionParameterNameDiscoverer extends Object implements ParameterNameDiscoverer {\n\t// Return parameter names for a constructor, or null if they cannot be determined.\n\tString[] getParameterNames(Constructor<?> ctor);\n\t// Return parameter names for a method, or null if they cannot be determined.\n\tString[] getParameterNames(Method method);\n}", "des": "ParameterNameDiscoverer implementation which uses Kotlin's reflection facilities for introspecting parameter names."}
{"index": 6106, "repo": "spring-core-6.0.11", "code": "public class LinkedMultiValueMap<K,V> extends MultiValueMapAdapter<K,V> implements Serializable, Cloneable {\n\t// Create a regular copy of this Map.\n\tLinkedMultiValueMap<K,V> clone();\n\t// Create a deep copy of this Map.\n\tLinkedMultiValueMap<K,V> deepCopy();\n}", "des": "Simple implementation of MultiValueMap that wraps a LinkedHashMap, storing multiple values in an ArrayList."}
{"index": 6107, "repo": "spring-core-6.0.11", "code": "public class LocalizedResourceHelper extends Object {\n\t// Find the most specific localized resource for the given name, extension and locale:\n\tResource findLocalizedResource(String name, String extension, Locale locale);\n\t// Set the separator to use in-between file name parts.\n\tvoid setSeparator(String separator);\n}", "des": "Helper class for loading a localized resource, specified through name, extension and current locale."}
{"index": 6108, "repo": "spring-core-6.0.11", "code": "public class MapPropertySource extends EnumerablePropertySource<Map<String,Object>> {\n\t// Return whether this PropertySource contains a property with the given name.\n\tboolean containsProperty(String name);\n\t// Return the value associated with the given name, or null if not found.\n\tObject getProperty(String name);\n\t// Return the names of all properties contained by the source object (never null).\n\tString[] getPropertyNames();\n}", "des": "PropertySource that reads keys and values from a Map object."}
{"index": 6109, "repo": "spring-core-6.0.11", "code": "public enum MemberCategory extends Enum<MemberCategory> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic MemberCategory valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic MemberCategory[] values();\n}", "des": "Predefined Member categories."}
{"index": 6110, "repo": "spring-core-6.0.11", "code": "public static enum MergedAnnotations.SearchStrategy extends Enum<MergedAnnotations.SearchStrategy> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic MergedAnnotations.SearchStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic MergedAnnotations.SearchStrategy[] values();\n}", "des": "Search strategies supported by MergedAnnotations.search(SearchStrategy) as well as MergedAnnotations.from(AnnotatedElement, SearchStrategy) and variants of that method."}
{"index": 6111, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public interface MergedAnnotationSelector<A extends Annotation> {\n\t// Determine if the existing annotation is known to be the best candidate and any subsequent selections may be skipped.\n\tdefault boolean isBestCandidate(MergedAnnotation<A> annotation);\n\t// Select the annotation that should be used.\n\tMergedAnnotation<A> select(MergedAnnotation<A> existing, MergedAnnotation<A> candidate);\n}", "des": "Strategy interface used to select between two MergedAnnotation instances."}
{"index": 6112, "repo": "spring-core-6.0.11", "code": "public abstract class MergedAnnotationSelectors extends Object {\n\t// Select the first directly declared annotation when possible.\n\tstatic <A extends Annotation>MergedAnnotationSelector<A> firstDirectlyDeclared();\n\t// Select the nearest annotation, i.e.\n\tstatic <A extends Annotation>MergedAnnotationSelector<A> nearest();\n}", "des": "MergedAnnotationSelector implementations that provide various options for MergedAnnotation instances."}
{"index": 6113, "repo": "spring-core-6.0.11", "code": "public interface MetadataReader {\n\t// Read full annotation metadata for the underlying class, including metadata for annotated methods.\n\tAnnotationMetadata getAnnotationMetadata();\n\t// Read basic class metadata for the underlying class.\n\tClassMetadata getClassMetadata();\n\t// Return the resource reference for the class file.\n\tResource getResource();\n}", "des": "Simple facade for accessing class metadata, as read by an ASM ClassReader."}
{"index": 6114, "repo": "spring-core-6.0.11", "code": "public interface MetadataReaderFactory {\n\t// Obtain a MetadataReader for the given class name.\n\tMetadataReader getMetadataReader(String className);\n\t// Obtain a MetadataReader for the given resource.\n\tMetadataReader getMetadataReader(Resource resource);\n}", "des": "Factory interface for MetadataReader instances."}
{"index": 6115, "repo": "spring-core-6.0.11", "code": "public final class MethodTooLargeException extends IndexOutOfBoundsException {\n\t// Returns the internal name of the owner class.\n\tString getClassName();\n\t// Returns the size of the method's Code attribute, in bytes.\n\tint getCodeSize();\n\t// Returns the descriptor of the method.\n\tString getDescriptor();\n\t// Returns the name of the method.\n\tString getMethodName();\n}", "des": "Exception thrown when the Code attribute of a method produced by a ClassWriter is too large."}
{"index": 6116, "repo": "spring-core-6.0.11", "code": "public abstract class Mixin extends Object {\n\t// Helper method to create an interface mixin.\n\tstatic Mixin create(Class[] interfaces, Object[] delegates);\n\t// Helper method to create an interface mixin.\n\tstatic Mixin create(Object[] delegates);\n\t// Helper method to create a bean mixin.\n\tstatic Mixin createBean(ClassLoader loader, Object[] beans);\n\tstatic Mixin createBean(Object[] beans);\n\tstatic Class[] getClasses(Object[] delegates);\n\tabstract Mixin newInstance(Object[] delegates);\n}", "des": "Mixin allows multiple objects to be combined into a single larger object."}
{"index": 6117, "repo": "spring-core-6.0.11", "code": "public interface NamingPolicy {\n\t// The NamingPolicy in use does not currently, but may in the future, affect the caching of classes generated by AbstractClassGenerator, so this is a reminder that you should correctly implement equals and hashCode to avoid generating too many classes.\n\tboolean equals(Object o);\n\t// Choose a name for a generated class.\n\tString getClassName(String prefix, String source, Object key, Predicate names);\n}", "des": "Customize the generated class name for AbstractClassGenerator-based utilities."}
{"index": 6118, "repo": "spring-core-6.0.11", "code": "public abstract class NativeConfigurationWriter extends Object {\n\t// Write the GraalVM native configuration from the provided hints.\n\tvoid write(RuntimeHints hints);\n\t// Write the specified GraalVM native configuration file, using the provided BasicJsonWriter.\n\tprotected abstract void writeTo(String fileName, Consumer<org.springframework.aot.nativex.BasicJsonWriter> writer);\n}", "des": "Write RuntimeHints as GraalVM native configuration."}
{"index": 6119, "repo": "spring-core-6.0.11", "code": "public abstract class NativeDetector extends Object {\n\t// Returns true if running in a native image context (for example buildtime, runtime, or agent) expressed by setting the org.graalvm.nativeimage.imagecode system property to any value.\n\tstatic boolean inNativeImage();\n\t// Returns true if running in any of the specified native image context(s).\n\tstatic boolean inNativeImage(NativeDetector.Context... contexts);\n}", "des": "A common delegate for detecting a GraalVM native image environment."}
{"index": 6120, "repo": "spring-core-6.0.11", "code": "public static enum NativeDetector.Context extends Enum<NativeDetector.Context> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic NativeDetector.Context valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic NativeDetector.Context[] values();\n}", "des": "Native image context as defined in GraalVM's ImageInfo."}
{"index": 6121, "repo": "spring-core-6.0.11", "code": "public class Netty5BufferDecoder extends AbstractDataBufferDecoder<io.netty5.buffer.Buffer> {\n\t// Whether the decoder supports the given target element type and the MIME type of the source stream.\n\tboolean canDecode(ResolvableType elementType, MimeType mimeType);\n\t// Decode a data buffer to an Object of type T.\n\tio.netty5.buffer.Buffer decode(DataBuffer dataBuffer, ResolvableType elementType, MimeType mimeType, Map<String,Object> hints);\n}", "des": "Decoder for Buffers."}
{"index": 6122, "repo": "spring-core-6.0.11", "code": "public class NettyByteBufDecoder extends AbstractDataBufferDecoder<io.netty.buffer.ByteBuf> {\n\t// Whether the decoder supports the given target element type and the MIME type of the source stream.\n\tboolean canDecode(ResolvableType elementType, MimeType mimeType);\n\t// Decode a data buffer to an Object of type T.\n\tio.netty.buffer.ByteBuf decode(DataBuffer dataBuffer, ResolvableType elementType, MimeType mimeType, Map<String,Object> hints);\n}", "des": "Decoder for ByteBufs."}
{"index": 6123, "repo": "spring-core-6.0.11", "code": "public interface ParameterNameDiscoverer {\n\t// Return parameter names for a constructor, or null if they cannot be determined.\n\tString[] getParameterNames(Constructor<?> ctor);\n\t// Return parameter names for a method, or null if they cannot be determined.\n\tString[] getParameterNames(Method method);\n}", "des": "Interface to discover parameter names for methods and constructors."}
{"index": 6124, "repo": "spring-core-6.0.11", "code": "public interface PooledDataBuffer extends TouchableDataBuffer {\n\t// Return true if this buffer is allocated; false if it has been deallocated.\n\tboolean isAllocated();\n\t// Decrease the reference count for this buffer by one, and deallocate it once the count reaches zero.\n\tboolean release();\n\t// Increase the reference count for this buffer by one.\n\tPooledDataBuffer retain();\n\t// Associate the given hint with the data buffer for debugging purposes.\n\tPooledDataBuffer touch(Object hint);\n}", "des": "Extension of DataBuffer that allows for buffers that share a memory pool."}
{"index": 6125, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public interface Profiles {\n\t// Test if this Profiles instance matches against the given active profiles predicate.\n\tboolean matches(Predicate<String> activeProfiles);\n\t// Create a new Profiles instance that checks for matches against the given profile expressions.\n\tstatic Profiles of(String... profileExpressions);\n}", "des": "Profile predicate that may be accepted by an Environment."}
{"index": 6126, "repo": "spring-core-6.0.11", "code": "public final class Property extends Object {\n\tboolean equals(Object other);\n\t// The name of the property: e.g.\n\tString getName();\n\t// The object declaring this property, either directly or in a superclass the object extends.\n\tClass<?> getObjectType();\n\t// The property getter method: e.g.\n\tMethod getReadMethod();\n\t// The property type: e.g.\n\tClass<?> getType();\n\t// The property setter method: e.g.\n\tMethod getWriteMethod();\n}", "des": "A description of a JavaBeans Property that allows us to avoid a dependency on java.beans.PropertyDescriptor."}
{"index": 6127, "repo": "spring-core-6.0.11", "code": "public interface PropertySources extends Iterable<PropertySource<?>> {\n\t// Return whether a property source with the given name is contained.\n\tboolean contains(String name);\n\t// Return the property source with the given name, null if not found.\n\tPropertySource<?> get(String name);\n\t// Return a sequential Stream containing the property sources.\n\tdefault Stream<PropertySource<?>> stream();\n}", "des": "Holder containing one or more PropertySource objects."}
{"index": 6128, "repo": "spring-core-6.0.11", "code": "public class ProxyHintsPredicates extends Object {\n\t// Return a predicate that checks whether a JdkProxyHint is registered for the given interfaces.\n\tPredicate<RuntimeHints> forInterfaces(Class<?>... interfaces);\n\t// Return a predicate that checks whether a JdkProxyHint is registered for the given interfaces.\n\tPredicate<RuntimeHints> forInterfaces(TypeReference... interfaces);\n}", "des": "Generator of ProxyHints predicates, testing whether the given hints match the expected behavior for proxies."}
{"index": 6129, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public static interface ReflectionUtils.FieldFilter {\n\t// Create a composite filter based on this filter and the provided filter.\n\tdefault ReflectionUtils.FieldFilter and(ReflectionUtils.FieldFilter next);\n\t// Determine whether the given field matches.\n\tboolean matches(Field field);\n}", "des": "Callback optionally used to filter fields to be operated on by a field callback."}
{"index": 6130, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public static interface ReflectionUtils.MethodFilter {\n\t// Create a composite filter based on this filter and the provided filter.\n\tdefault ReflectionUtils.MethodFilter and(ReflectionUtils.MethodFilter next);\n\t// Determine whether the given method matches.\n\tboolean matches(Method method);\n}", "des": "Callback optionally used to filter methods to be operated on by a method callback."}
{"index": 6131, "repo": "spring-core-6.0.11", "code": "public class ResizableByteArrayOutputStream extends ByteArrayOutputStream {\n\t// Return the current size of this stream's internal buffer.\n\tint capacity();\n\t// Grow the internal buffer size.\n\tvoid grow(int additionalCapacity);\n\t// Resize the internal buffer size to a specified capacity.\n\tvoid resize(int targetCapacity);\n}", "des": "An extension of ByteArrayOutputStream that: has public ResizableByteArrayOutputStream.grow(int) and ResizableByteArrayOutputStream.resize(int) methods to get more control over the size of the internal buffer has a higher initial capacity (256) by default"}
{"index": 6132, "repo": "spring-core-6.0.11", "code": "public class ResourceArrayPropertyEditor extends PropertyEditorSupport {\n\t// Resolve the given path, replacing placeholders with corresponding system property values if necessary.\n\tprotected String resolvePath(String path);\n\t// Treat the given text as a location pattern and convert it to a Resource array.\n\tvoid setAsText(String text);\n\t// Treat the given value as a collection or array and convert it to a Resource array.\n\tvoid setValue(Object value);\n}", "des": "Editor for Resource arrays, to automatically convert String location patterns (e.g."}
{"index": 6133, "repo": "spring-core-6.0.11", "code": "public final class ResourceBundleHint extends Object implements ConditionalHint {\n\tboolean equals(Object o);\n\t// Return the baseName of the resource bundle.\n\tString getBaseName();\n\t// Return the type that should be reachable for this hint to apply, or null if this hint should always been applied.\n\tTypeReference getReachableType();\n}", "des": "A hint that describes the need to access a ResourceBundle."}
{"index": 6134, "repo": "spring-core-6.0.11", "code": "public static class ResourceBundleHint.Builder extends Object {\n\t// Use the baseName of the resource bundle.\n\tResourceBundleHint.Builder baseName(String baseName);\n\t// Make this hint conditional on the fact that the specified type can be resolved.\n\tResourceBundleHint.Builder onReachableType(TypeReference reachableType);\n}", "des": "Builder for ResourceBundleHint."}
{"index": 6135, "repo": "spring-core-6.0.11", "code": "public class ResourceEncoder extends AbstractSingleValueEncoder<Resource> {\n\t// Whether the encoder supports the given source element type and the MIME type for the output stream.\n\tboolean canEncode(ResolvableType elementType, MimeType mimeType);\n\t// Encode T to an output DataBuffer stream.\n\tprotected reactor.core.publisher.Flux<DataBuffer> encode(Resource resource, DataBufferFactory bufferFactory, ResolvableType type, MimeType mimeType, Map<String,Object> hints);\n}", "des": "Encoder for Resources."}
{"index": 6136, "repo": "spring-core-6.0.11", "code": "public interface ResourceLoader {\n\t// Expose the ClassLoader used by this ResourceLoader.\n\tClassLoader getClassLoader();\n\t// Return a Resource handle for the specified resource location.\n\tResource getResource(String location);\n}", "des": "Strategy interface for loading resources (e.g., class path or file system resources)."}
{"index": 6137, "repo": "spring-core-6.0.11", "code": "public final class ResourcePatternHint extends Object implements ConditionalHint {\n\tboolean equals(Object o);\n\t// Return the pattern to use for identifying the resources to match.\n\tString getPattern();\n\t// Return the type that should be reachable for this hint to apply, or null if this hint should always been applied.\n\tTypeReference getReachableType();\n\t// Return the regex Pattern to use for identifying the resources to match.\n\tPattern toRegex();\n}", "des": "A hint that describes resources that should be made available at runtime."}
{"index": 6138, "repo": "spring-core-6.0.11", "code": "public final class ResourcePatternHints extends Object {\n\t// Return the exclude patterns to use to identify the resources to match.\n\tList<ResourcePatternHint> getExcludes();\n\t// Return the include patterns to use to identify the resources to match.\n\tList<ResourcePatternHint> getIncludes();\n}", "des": "A collection of ResourcePatternHint describing whether resources should be made available at runtime using a matching algorithm based on include/exclude patterns."}
{"index": 6139, "repo": "spring-core-6.0.11", "code": "public abstract class ResourcePatternUtils extends Object {\n\t// Return a default ResourcePatternResolver for the given ResourceLoader.\n\tstatic ResourcePatternResolver getResourcePatternResolver(ResourceLoader resourceLoader);\n\t// Return whether the given resource location is a URL: either a special \"classpath\" or \"classpath*\" pseudo URL or a standard URL.\n\tstatic boolean isUrl(String resourceLocation);\n}", "des": "Utility class for determining whether a given URL is a resource location that can be loaded via a ResourcePatternResolver."}
{"index": 6140, "repo": "spring-core-6.0.11", "code": "public class ResourceRegion extends Object {\n\t// Return the byte count of this region in the underlying Resource.\n\tlong getCount();\n\t// Return the start position of this region in the underlying Resource.\n\tlong getPosition();\n\t// Return the underlying Resource for this ResourceRegion.\n\tResource getResource();\n}", "des": "Region of a Resource implementation, materialized by a position within the Resource and a byte count for the length of that region."}
{"index": 6141, "repo": "spring-core-6.0.11", "code": "public class RuntimeHints extends Object {\n\t// Provide access to jni-based hints.\n\tReflectionHints jni();\n\t// Provide access to proxy-based hints.\n\tProxyHints proxies();\n\t// Provide access to reflection-based hints.\n\tReflectionHints reflection();\n\t// Provide access to resource-based hints.\n\tResourceHints resources();\n\t// Provide access to serialization-based hints.\n\tSerializationHints serialization();\n}", "des": "Gather hints that can be used to optimize the application runtime."}
{"index": 6142, "repo": "spring-core-6.0.11", "code": "public abstract class RuntimeHintsPredicates extends Object {\n\t// Return a predicate generator for proxy hints.\n\tstatic ProxyHintsPredicates proxies();\n\t// Return a predicate generator for reflection hints.\n\tstatic ReflectionHintsPredicates reflection();\n\t// Return a predicate generator for resource hints.\n\tstatic ResourceHintsPredicates resource();\n\t// Return a predicate generator for serialization hints.\n\tstatic SerializationHintsPredicates serialization();\n}", "des": "Static generator of predicates that test whether the given RuntimeHints instance matches the expected behavior for reflection, resource, serialization, or proxy generation."}
{"index": 6143, "repo": "spring-core-6.0.11", "code": "public class SerializationDelegate extends Object implements Serializer<Object>, Deserializer<Object> {\n\t// Read (assemble) an object of type T from the given InputStream.\n\tObject deserialize(InputStream inputStream);\n\t// Write an object of type T to the given OutputStream.\n\tvoid serialize(Object object, OutputStream outputStream);\n}", "des": "A convenient delegate with pre-arranged configuration state for common serialization needs."}
{"index": 6144, "repo": "spring-core-6.0.11", "code": "public class SerializationHintsPredicates extends Object {\n\t// Return a predicate that checks whether a serialization hint is registered for the given type.\n\tPredicate<RuntimeHints> onType(Class<?> type);\n\t// Return a predicate that checks whether a serialization hint is registered for the given type reference.\n\tPredicate<RuntimeHints> onType(TypeReference typeReference);\n}", "des": "Generator of SerializationHints predicates, testing whether the given hints match the expected behavior for serialization."}
{"index": 6145, "repo": "spring-core-6.0.11", "code": "public abstract class SerializationUtils extends Object {\n\t// Clone the given object using Java Object Serialization.\n\tstatic <T extends Serializable>T clone(T object);\n\t// Deprecated. This utility uses Java Object Serialization, which allows arbitrary code to be run and is known for being the source of many Remote Code Execution (RCE) vulnerabilities.\n\tstatic Object deserialize(byte[] bytes);\n\t// Serialize the given object to a byte array.\n\tstatic byte[] serialize(Object object);\n}", "des": "Static utilities for serialization and deserialization using Java Object Serialization."}
{"index": 6146, "repo": "spring-core-6.0.11", "code": "@FunctionalInterface public interface Serializer<T> {\n\t// Write an object of type T to the given OutputStream.\n\tvoid serialize(T object, OutputStream outputStream);\n\t// Turn an object of type T into a serialized byte array.\n\tdefault byte[] serializeToByteArray(T object);\n}", "des": "A strategy interface for streaming an object to an OutputStream."}
{"index": 6147, "repo": "spring-core-6.0.11", "code": "public class SimpleMetadataReaderFactory extends Object implements MetadataReaderFactory {\n\t// Obtain a MetadataReader for the given class name.\n\tMetadataReader getMetadataReader(String className);\n\t// Obtain a MetadataReader for the given resource.\n\tMetadataReader getMetadataReader(Resource resource);\n\t// Return the ResourceLoader that this MetadataReaderFactory has been constructed with.\n\tfinal ResourceLoader getResourceLoader();\n}", "des": "Simple implementation of the MetadataReaderFactory interface, creating a new ASM ClassReader for every request."}
{"index": 6148, "repo": "spring-core-6.0.11", "code": "public class StandardReflectionParameterNameDiscoverer extends Object implements ParameterNameDiscoverer {\n\t// Return parameter names for a constructor, or null if they cannot be determined.\n\tString[] getParameterNames(Constructor<?> ctor);\n\t// Return parameter names for a method, or null if they cannot be determined.\n\tString[] getParameterNames(Method method);\n}", "des": "ParameterNameDiscoverer implementation which uses JDK 8's reflection facilities for introspecting parameter names (based on the \"-parameters\" compiler flag)."}
{"index": 6149, "repo": "spring-core-6.0.11", "code": "public static interface StartupStep.Tag {\n\t// Return the Tag name.\n\tString getKey();\n\t// Return the Tag value.\n\tString getValue();\n}", "des": "Simple key/value association for storing step metadata."}
{"index": 6150, "repo": "spring-core-6.0.11", "code": "public static final class StopWatch.TaskInfo extends Object {\n\t// Get the name of this task.\n\tString getTaskName();\n\t// Get the time in milliseconds this task took.\n\tlong getTimeMillis();\n\t// Get the time in nanoseconds this task took.\n\tlong getTimeNanos();\n\t// Get the time in seconds this task took.\n\tdouble getTimeSeconds();\n}", "des": "Nested class to hold data about one task executed within the StopWatch."}
{"index": 6151, "repo": "spring-core-6.0.11", "code": "public abstract class StringSwitcher extends Object {\n\t// Helper method to create a StringSwitcher.\n\tstatic StringSwitcher create(String[] strings, int[] ints, boolean fixedInput);\n\t// Return the integer associated with the given key.\n\tabstract int intValue(String s);\n}", "des": "This class implements a simple String  int mapping for a fixed set of keys."}
{"index": 6152, "repo": "spring-core-6.0.11", "code": "public abstract class SystemPropertyUtils extends Object {\n\t// Resolve ${...} placeholders in the given text, replacing them with corresponding system property values.\n\tstatic String resolvePlaceholders(String text);\n\t// Resolve ${...} placeholders in the given text, replacing them with corresponding system property values.\n\tstatic String resolvePlaceholders(String text, boolean ignoreUnresolvablePlaceholders);\n}", "des": "Helper class for resolving placeholders in texts."}
{"index": 6153, "repo": "spring-core-6.0.11", "code": "public abstract class TransformerUtils extends Object {\n\t// Disable indenting for the supplied Transformer.\n\tstatic void disableIndenting(Transformer transformer);\n\t// Enable indenting for the supplied Transformer.\n\tstatic void enableIndenting(Transformer transformer);\n\t// Enable indenting for the supplied Transformer.\n\tstatic void enableIndenting(Transformer transformer, int indentAmount);\n}", "des": "Contains common behavior relating to Transformers and the javax.xml.transform package in general."}
{"index": 6154, "repo": "spring-core-6.0.11", "code": "public final class TypePath extends Object {\n\t// Converts a type path in string form, in the format used by toString(), into a TypePath object.\n\tstatic TypePath fromString(String typePath);\n\t// Returns the length of this path, i.e.\n\tint getLength();\n\t// Returns the value of the given step of this path.\n\tint getStep(int index);\n\t// Returns the index of the type argument that the given step is stepping into.\n\tint getStepArgument(int index);\n}", "des": "The path to a type argument, wildcard bound, array element type, or static inner type within an enclosing type."}
{"index": 6155, "repo": "spring-core-6.0.11", "code": "public interface WritableResource extends Resource {\n\t// Return an OutputStream for the underlying resource, allowing to (over-)write its content.\n\tOutputStream getOutputStream();\n\t// Indicate whether the contents of this resource can be written via getOutputStream().\n\tdefault boolean isWritable();\n\t// Return a WritableByteChannel.\n\tdefault WritableByteChannel writableChannel();\n}", "des": "Extended interface for a resource that supports writing to it."}
{"index": 6156, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface BaggageInScope extends Closeable {\n\tvoid close();\n\tString get();\n\t// Retrieves baggage from the given TraceContext.\n\tString get(TraceContext traceContext);\n\t// Sets the current baggage in scope.\n\tBaggageInScope makeCurrent();\n\tString name();\n\t// Sets the baggage value.\n\tBaggageInScope set(String value);\n\t// Sets the baggage value for the given TraceContext.\n\tBaggageInScope set(TraceContext traceContext, String value);\n}", "des": "Inspired by OpenZipkin Brave's BaggageField."}
{"index": 6157, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface DocumentedSpan {\n\tdefault EventValue[] getEvents();\n\tString getName();\n\tdefault TagKey[] getTagKeys();\n\t// Returns required prefix to be there for events and tags.\n\tdefault String prefix();\n\t// Asserts on tags, names and allowed events.\n\tdefault AssertingSpan wrap(Span span);\n\t// Asserts on tags, names and allowed events.\n\tdefault AssertingSpanBuilder wrap(Span.Builder span);\n\t// Asserts on tags, names and allowed events.\n\tdefault AssertingSpanCustomizer wrap(SpanCustomizer span);\n}", "des": "In order to describe your spans via e.g."}
{"index": 6158, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface HttpClientHandler {\n\t// Finishes the client span after assigning it tags according to the response or error.\n\tvoid handleReceive(HttpClientResponse response, Span span);\n\t// Starts the client span after assigning it a name and tags.\n\tSpan handleSend(HttpClientRequest request);\n\t// Same as handleSend(HttpClientRequest) but with an explicit parent TraceContext.\n\tSpan handleSend(HttpClientRequest request, TraceContext parent);\n}", "des": "This API is taken from OpenZipkin Brave."}
{"index": 6159, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface HttpServerHandler {\n\t// Conditionally joins a span, or starts a new trace, depending on if a trace context was extracted from the request.\n\tSpan handleReceive(HttpServerRequest request);\n\t// Finishes the server span after assigning it tags according to the response or error.\n\tvoid handleSend(HttpServerResponse response, Span span);\n}", "des": "This API is taken from OpenZipkin Brave."}
{"index": 6160, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface Propagator {\n\t// Extracts the value from upstream.\n\t<C> Span.Builder extract(C carrier, Propagator.Getter<C> getter);\n\tList<String> fields();\n\t// Injects the value downstream, for example as HTTP headers.\n\t<C> void inject(TraceContext context, C carrier, Propagator.Setter<C> setter);\n}", "des": "Inspired by OpenZipkin Brave and OpenTelemetry."}
{"index": 6161, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface SamplerFunction<T> {\n\t// Always sampling SamplerFunction.\n\tstatic <T> SamplerFunction<T> alwaysSample();\n\t// Always deferring SamplerFunction.\n\tstatic <T> SamplerFunction<T> deferDecision();\n\t// Never sampling SamplerFunction.\n\tstatic <T> SamplerFunction<T> neverSample();\n\t// Returns an overriding sampling decision for a new trace.\n\tBoolean trySample(T arg);\n}", "des": "This API was heavily influenced by Brave."}
{"index": 6162, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public static enum SamplerFunction.Constants extends Enum<SamplerFunction.Constants> implements SamplerFunction<Object> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SamplerFunction.Constants valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SamplerFunction.Constants[] values();\n}", "des": "Constant SamplerFunctions."}
{"index": 6163, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface ScopedSpan {\n\tTraceContext context();\n\t// Ends the span.\n\tvoid end();\n\t// Records an exception for this span.\n\tScopedSpan error(Throwable throwable);\n\t// Sets an event on this span.\n\tScopedSpan event(String value);\n\tboolean isNoop();\n\t// Sets a name on this span.\n\tScopedSpan name(String name);\n\t// Sets a tag on this span.\n\tScopedSpan tag(String key, String value);\n}", "des": "Represents the \"current span\" until ScopedSpan.end() ()} is called."}
{"index": 6164, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public static enum Span.Kind extends Enum<Span.Kind> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Span.Kind valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Span.Kind[] values();\n}", "des": "Type of span."}
{"index": 6165, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface SpanCustomizer {\n\t// Sets an event on a span.\n\tSpanCustomizer event(String value);\n\t// Sets a name on a span.\n\tSpanCustomizer name(String name);\n\t// Sets a tag on a span.\n\tSpanCustomizer tag(String key, String value);\n}", "des": "Allows to customize the current span in scope."}
{"index": 6166, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public class ThreadLocalSpan extends Object {\n\tSpanAndScope get();\n\t// Removes the current span from thread local and brings back the previous span to the current thread local.\n\tvoid remove();\n\t// Sets given span and scope.\n\tvoid set(Span span);\n}", "des": "Represents a Span stored in thread local."}
{"index": 6167, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public interface TraceContext {\n\t// Parent span id.\n\tString parentId();\n\tBoolean sampled();\n\t// Span id.\n\tString spanId();\n\t// Trace id.\n\tString traceId();\n}", "des": "Contains trace and span data."}
{"index": 6168, "repo": "spring-cloud-sleuth-api-3.1.9", "code": "public static interface TraceContext.Builder {\n\t// Builds the trace context.\n\tTraceContext build();\n\t// Sets parent id on the trace context.\n\tTraceContext.Builder parentId(String parentId);\n\t// Sets sampled on the trace context.\n\tTraceContext.Builder sampled(Boolean sampled);\n\t// Sets span id on the trace context.\n\tTraceContext.Builder spanId(String spanId);\n\t// Sets trace id on the trace context.\n\tTraceContext.Builder traceId(String traceId);\n}", "des": "Builder for TraceContext."}
{"index": 6169, "repo": "groovy-all-4.0.13", "code": "public abstract class AbstractReaderSource extends Object implements ReaderSource {\n\t// Returns true if the source can be restarted (i.e.\n\tboolean canReopenSource();\n\t// Cleans up any cached resources used by getLine().\n\tvoid cleanup();\n\t// Returns a line from the source, or null, if unavailable.\n\tString getLine(int lineNumber, Janitor janitor);\n}", "des": "For ReaderSources that can choose a parent class, a base that provides common functionality."}
{"index": 6170, "repo": "groovy-all-4.0.13", "code": "public interface AdaptingMetaClass extends MetaClass {\n\t// Returns the MetaClass that this adapter adapts\n\tMetaClass getAdaptee();\n\t// Sets the MetaClass adapted by this MetaClass\n\tvoid setAdaptee(MetaClass metaClass);\n}", "des": "An interface for MetaClass instances that \"adapt\" other MetaClass instances such as a proxy or delegating MetaClass."}
{"index": 6171, "repo": "groovy-all-4.0.13", "code": "public class ArrayTypeUtils extends Object {\n\t// Calculate the dimension of array\n\tstatic int dimension(Class clazz);\n\t// Calculate the dimension of array\n\tstatic int dimension(ClassNode clazz);\n\t// Get the type of array elements\n\tstatic Class elementType(Class clazz);\n\t// Get the type of array elements by the dimension\n\tstatic Class elementType(Class clazz, int dim);\n\t// Get the type of array elements\n\tstatic ClassNode elementType(ClassNode clazz);\n}", "des": "Utilities for handling array types"}
{"index": 6172, "repo": "groovy-all-4.0.13", "code": "public class AstStringCompiler extends Object {\n\t// Compiles the specified source code and returns its statement block and any declared types.\n\tList<ASTNode> compile(String script);\n\t// Compiles the specified source code and returns its statement block, the script class (if desired) and any declared types.\n\tList<ASTNode> compile(String script, CompilePhase compilePhase, boolean statementsOnly);\n}", "des": "This class handles converting Strings to ASTNode lists."}
{"index": 6173, "repo": "groovy-all-4.0.13", "code": "public enum AutoCloneStyle extends Enum<AutoCloneStyle> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic AutoCloneStyle valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic AutoCloneStyle[] values();\n}", "des": "Intended style to use for cloning when using the @AutoClone annotation."}
{"index": 6174, "repo": "groovy-all-4.0.13", "code": "public class BatchingStatementWrapper extends GroovyObjectSupport implements AutoCloseable {\n\tvoid addBatch(String sql);\n\tvoid clearBatch();\n\tvoid close();\n\tint[] executeBatch();\n\t// Increments batch count (after addBatch(..) has been called) and execute delegate.executeBatch() if batchSize has been reached.\n\tprotected void incrementBatchCount();\n\t// Invokes the given method.\n\tObject invokeMethod(String name, Object args);\n\tprotected void processResult(int[] lastResult);\n\tprotected void reset();\n}", "des": "Class which delegates to a Statement but keeps track of a batch count size."}
{"index": 6175, "repo": "groovy-all-4.0.13", "code": "public class BooleanClosureWrapper extends Object {\n\t// normal closure call\n\tboolean call(Object... args);\n\t// Bridge for a call based on a map entry.\n\t<K, V> boolean callForMap(Map.Entry<K,V> entry);\n}", "des": "Helper class for internal use only."}
{"index": 6176, "repo": "groovy-all-4.0.13", "code": "public class BytecodeSequence extends Statement {\n\t// Returns the singular BytecodeInstruction.\n\tBytecodeInstruction getBytecodeInstruction();\n\tList<?> getInstructions();\n\t// Delegates to the visit method used for this class.\n\tvoid visit(GroovyCodeVisitor visitor);\n}", "des": "This class represents a sequence of BytecodeInstructions or ASTNodes."}
{"index": 6177, "repo": "groovy-all-4.0.13", "code": "public class ClassFinder extends Object {\n\t// Returns the found classes\n\tstatic Map<String,Set<String>> find(URI classpathEntryURI, String packageName);\n\t// Returns the found classes\n\tstatic Map<String,Set<String>> find(URI classpathEntryURI, String packageName, boolean recursive);\n}", "des": "Find classes under the specified package via some classpath entry Usage:"}
{"index": 6178, "repo": "groovy-all-4.0.13", "code": "public static class ClassNodeResolver.LookupResult extends Object {\n\t// returns the ClassNode\n\tClassNode getClassNode();\n\t// returns the SourceUnit\n\tSourceUnit getSourceUnit();\n\t// returns true if a ClassNode is stored\n\tboolean isClassNode();\n\t// returns true if a SourceUnit is stored\n\tboolean isSourceUnit();\n}", "des": "Helper class to return either a SourceUnit or ClassNode."}
{"index": 6179, "repo": "groovy-all-4.0.13", "code": "public interface ClosureInvokingMethod {\n\t// Returns the original closure that this method invokes\n\tClosure getClosure();\n\t// The method name\n\tString getName();\n\t// Is it a static method?\n\tboolean isStatic();\n}", "des": "An interface for MetaMethods that invoke closures to implements."}
{"index": 6180, "repo": "groovy-all-4.0.13", "code": "public enum CompilePhase extends Enum<CompilePhase> {\n\t// Returns the CompilePhase for the given integer phase number.\n\tstatic CompilePhase fromPhaseNumber(int phaseNumber);\n\t// Returns the underlying integer Phase number.\n\tint getPhaseNumber();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompilePhase valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompilePhase[] values();\n}", "des": "The phases of the GroovyCompiler."}
{"index": 6181, "repo": "groovy-all-4.0.13", "code": "public class Compiler extends Object {\n\t// Compiles a single File.\n\tvoid compile(File file);\n\t// Compiles a series of Files.\n\tvoid compile(File[] files);\n\t// Compiles a series of Files from file names.\n\tvoid compile(String[] files);\n\t// Compiles a string of code.\n\tvoid compile(String name, String code);\n}", "des": "A convenience front end for getting standard compilations done."}
{"index": 6182, "repo": "groovy-all-4.0.13", "code": "public static enum ConcurrentReferenceHashMap.Option extends Enum<ConcurrentReferenceHashMap.Option> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConcurrentReferenceHashMap.Option valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConcurrentReferenceHashMap.Option[] values();\n}", "des": "Behavior-changing configuration options for the map"}
{"index": 6183, "repo": "groovy-all-4.0.13", "code": "public static enum ConcurrentReferenceHashMap.ReferenceType extends Enum<ConcurrentReferenceHashMap.ReferenceType> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ConcurrentReferenceHashMap.ReferenceType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ConcurrentReferenceHashMap.ReferenceType[] values();\n}", "des": "An option specifying which Java reference type should be used to refer to a key and/or value."}
{"index": 6184, "repo": "groovy-all-4.0.13", "code": "public class ConfigurationException extends RuntimeException implements GroovyExceptionInterface {\n\t// Returns the causing exception, if available.\n\tThrowable getCause();\n\t// It's always fatal.\n\tboolean isFatal();\n\t// Set fatal is just ignored.\n\tvoid setFatal(boolean fatal);\n}", "des": "Thrown when configuration data is invalid."}
{"index": 6185, "repo": "groovy-all-4.0.13", "code": "public class ConvertedMap extends ConversionHandler {\n\tprotected boolean checkMethod(Method method);\n\t// This method is called for all Methods not defined on Object.\n\tObject invokeCustom(Object proxy, Method method, Object[] args);\n\t// Checks whether a method is a core method from java.lang.Object.\n\tstatic boolean isCoreObjectMethod(Method method);\n}", "des": "This class is a general adapter to adapt a map of closures to any Java interface."}
{"index": 6186, "repo": "groovy-all-4.0.13", "code": "protected static class DefaultJsonGenerator.ClosureConverter extends Object implements JsonGenerator.Converter {\n\t// Converts a given value.\n\tObject convert(Object value, String key);\n\t// Any two Converter instances registered for the same type are considered to be equal.\n\tboolean equals(Object o);\n\t// Returns true if this converter can handle conversions of the given type.\n\tboolean handles(Class<?> type);\n}", "des": "A converter that handles converting a given type using a closure."}
{"index": 6187, "repo": "groovy-all-4.0.13", "code": "public enum DefaultsMode extends Enum<DefaultsMode> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic DefaultsMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic DefaultsMode[] values();\n}", "des": "Intended mode to use when generating constructors to emulate default parameter values when using the TupleConstructor annotation."}
{"index": 6188, "repo": "groovy-all-4.0.13", "code": "public abstract class DelegatingScript extends Script {\n\tObject getDelegate();\n\t// Retrieves a property value.\n\tObject getProperty(String property);\n\t// Invoke a method (or closure in the binding) defined.\n\tObject invokeMethod(String name, Object args);\n\t// Sets the delegation target.\n\tvoid setDelegate(Object delegate);\n\t// Sets the given property to the new value.\n\tvoid setProperty(String property, Object newValue);\n}", "des": "Script that performs method invocations and property access like Closure does."}
{"index": 6189, "repo": "groovy-all-4.0.13", "code": "public class DoWhileStatement extends Statement implements LoopingStatement {\n\tBooleanExpression getBooleanExpression();\n\t// Gets the loop block.\n\tStatement getLoopBlock();\n\tvoid setBooleanExpression(BooleanExpression booleanExpression);\n\t// Sets the loop block.\n\tvoid setLoopBlock(Statement loopBlock);\n\tvoid visit(GroovyCodeVisitor visitor);\n}", "des": "Represents a do { ..."}
{"index": 6190, "repo": "groovy-all-4.0.13", "code": "public class EncodingAwareBufferedWriter extends BufferedWriter {\n\t// The encoding as returned by the underlying OutputStreamWriter.\n\tString getEncoding();\n\t// The encoding as returned by the underlying OutputStreamWriter.\n\tString getNormalizedEncoding();\n}", "des": "A buffered writer only for OutputStreamWriter that is aware of the encoding of the OutputStreamWriter."}
{"index": 6191, "repo": "groovy-all-4.0.13", "code": "public interface EvictableCache<K,V> extends MemoizeCache<K,V>, Map<K,V> {\n\t// Clear the cache\n\tdefault void clear();\n\t// Clear the cache\n\tMap<K,V> clearAll();\n\t// Determines if the cache contains an entry for the specified key.\n\tboolean containsKey(Object key);\n\t// Get all keys associated to cached values\n\tSet<K> keys();\n\t// Remove the cached value by the key\n\tV remove(Object key);\n\t// Get the size of the cache\n\tint size();\n\t// Get all cached values\n\tCollection<V> values();\n}", "des": "Represents an evictable memoize cache with its essential methods"}
{"index": 6192, "repo": "groovy-all-4.0.13", "code": "public static enum EvictableCache.EvictionStrategy extends Enum<EvictableCache.EvictionStrategy> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic EvictableCache.EvictionStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic EvictableCache.EvictionStrategy[] values();\n}", "des": "Represents an eviction strategy for the cache with limited size"}
{"index": 6193, "repo": "groovy-all-4.0.13", "code": "public class ExceptionMessage extends Message {\n\t// Returns the underlying Exception.\n\tException getCause();\n\t// Writes out a nicely formatted summary of the exception.\n\tvoid write(PrintWriter output, Janitor janitor);\n}", "des": "A class for error messages produced by the parser system."}
{"index": 6194, "repo": "groovy-all-4.0.13", "code": "public class FileReaderSource extends AbstractReaderSource {\n\tFile getFile();\n\t// Returns a new Reader on the underlying source object.\n\tReader getReader();\n\t// Returns a URI for the file of this source.\n\tURI getURI();\n}", "des": "A ReaderSource for source files."}
{"index": 6195, "repo": "groovy-all-4.0.13", "code": "public class FileScanner extends org.apache.tools.ant.Task {\n\t// Adds a set of files (nested fileset attribute).\n\tvoid addFileset(org.apache.tools.ant.types.FileSet set);\n\t// Clears any file sets that have been added to this scanner\n\tvoid clear();\n\tIterator<File> directories();\n\tboolean hasFiles();\n\tIterator<File> iterator();\n}", "des": "FileScanner is a bean which allows the iteration over a number of files from a collection of FileSet instances."}
{"index": 6196, "repo": "groovy-all-4.0.13", "code": "public enum FileType extends Enum<FileType> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileType[] values();\n}", "des": "Represents particular files of interest."}
{"index": 6197, "repo": "groovy-all-4.0.13", "code": "public enum FileVisitResult extends Enum<FileVisitResult> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic FileVisitResult valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic FileVisitResult[] values();\n}", "des": "Represents special return values for the 'preDir', 'postDir' and 'visit'/supplied Closures used with ResourceGroovyMethods.traverse(java.io.File, java.util.Map, groovy.lang.Closure) and related methods to control subsequent traversal behavior."}
{"index": 6198, "repo": "groovy-all-4.0.13", "code": "public class ForStatement extends Statement implements LoopingStatement {\n\tExpression getCollectionExpression();\n\t// Gets the loop block.\n\tStatement getLoopBlock();\n\tParameter getVariable();\n\tVariableScope getVariableScope();\n\tClassNode getVariableType();\n\tvoid setCollectionExpression(Expression collectionExpression);\n\t// Sets the loop block.\n\tvoid setLoopBlock(Statement loopBlock);\n\tvoid setVariableScope(VariableScope variableScope);\n\tvoid visit(GroovyCodeVisitor visitor);\n}", "des": "Represents a standard for loop in Groovy"}
{"index": 6199, "repo": "groovy-all-4.0.13", "code": "public class GrabAnnotationTransformation extends ClassCodeVisitorSupport implements ASTTransformation, CompilationUnitAware {\n\tSourceUnit getSourceUnit();\n\tvoid setCompilationUnit(CompilationUnit compilationUnit);\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n\t// Adds the annotation to the internal target list if a match is found.\n\tvoid visitAnnotations(AnnotatedNode node);\n}", "des": "Transformation for declarative dependency management."}
{"index": 6200, "repo": "groovy-all-4.0.13", "code": "public class GroovyBugError extends AssertionError {\n\t// Returns the bug text to describe this error\n\tString getBugText();\n\tThrowable getCause();\n\t// Returns the detail message string of this error.\n\tString getMessage();\n\t// Sets the bug text to describe this error\n\tvoid setBugText(String msg);\n}", "des": "This class represents an error that is thrown when a bug is recognized inside the runtime."}
{"index": 6201, "repo": "groovy-all-4.0.13", "code": "public interface GroovyClassVisitor {\n\t// Visit a ClassNode.\n\tvoid visitClass(ClassNode node);\n\t// Visit a ConstructorNode.\n\tvoid visitConstructor(ConstructorNode node);\n\t// Visit a FieldNode.\n\tvoid visitField(FieldNode node);\n\t// Visit a MethodNode.\n\tvoid visitMethod(MethodNode node);\n\t// Visit a PropertyNode.\n\tvoid visitProperty(PropertyNode node);\n}", "des": "A special visitor for working with the structure of a class."}
{"index": 6202, "repo": "groovy-all-4.0.13", "code": "public class Groovydoc extends Object {\n\tboolean equals(Object o);\n\t// Get the content of groovydoc\n\tString getContent();\n\t// Get the holder of the groovydoc\n\tGroovydocHolder getHolder();\n\t// TODO Get list of groovydoc tags\n\tList<GroovydocTag> getTagList();\n\t// Tests if groovydoc is present\n\tboolean isPresent();\n}", "des": "Represents groovydoc"}
{"index": 6203, "repo": "groovy-all-4.0.13", "code": "public interface GroovydocHolder<T> {\n\t// Get the groovydoc\n\tGroovydoc getGroovydoc();\n\t// Get GroovydocHolder instance\n\tT getInstance();\n}", "des": "Represents Groovydoc Holder"}
{"index": 6204, "repo": "groovy-all-4.0.13", "code": "public interface GroovyObject {\n\t// Returns the metaclass for a given class.\n\tMetaClass getMetaClass();\n\t// Retrieves a property value.\n\tdefault Object getProperty(String propertyName);\n\t// Invokes the given method.\n\tdefault Object invokeMethod(String name, Object args);\n\t// Allows the MetaClass to be replaced with a derived implementation.\n\tvoid setMetaClass(MetaClass metaClass);\n\t// Sets the given property to the new value.\n\tdefault void setProperty(String propertyName, Object newValue);\n}", "des": "The interface implemented by all Groovy objects."}
{"index": 6205, "repo": "groovy-all-4.0.13", "code": "public abstract class GroovyObjectSupport extends Object implements GroovyObject {\n\t// Returns the metaclass for a given class.\n\tMetaClass getMetaClass();\n\t// Allows the MetaClass to be replaced with a derived implementation.\n\tvoid setMetaClass(MetaClass metaClass);\n}", "des": "Base class for Java objects wishing to be Groovy objects."}
{"index": 6206, "repo": "groovy-all-4.0.13", "code": "public class GroovyPrintStream extends PrintStream {\n\t// Prints an object Groovy style.\n\tvoid print(Object obj);\n\t// Prints an object Groovy style followed by a newline.\n\tvoid println(Object obj);\n}", "des": "A PrintStream that outputs objects in Groovy style."}
{"index": 6207, "repo": "groovy-all-4.0.13", "code": "public final class GroovyResultSetProxy extends Object implements InvocationHandler {\n\t// Gets a proxy instance that can be used as GroovyResultSet.\n\tGroovyResultSet getImpl();\n\t// Invokes a method for the GroovyResultSet.\n\tObject invoke(Object proxy, Method method, Object[] args);\n}", "des": "GroovyResultSetProxy is used to create a proxy for GroovyResultSet."}
{"index": 6208, "repo": "groovy-all-4.0.13", "code": "public interface GroovyRunner {\n\t// Returns true if this runner is able to run the given class.\n\tboolean canRun(Class<?> scriptClass, GroovyClassLoader loader);\n\t// Runs the given class.\n\tObject run(Class<?> scriptClass, GroovyClassLoader loader);\n}", "des": "Classes which can run scripts should implement this interface."}
{"index": 6209, "repo": "groovy-all-4.0.13", "code": "public class GroovyServlet extends AbstractHttpServlet {\n\t// Hook method to set up the GroovyScriptEngine to use. Subclasses may override this method to provide a custom engine.\n\tprotected GroovyScriptEngine createGroovyScriptEngine();\n\t// Initialize the GroovyServlet.\n\tvoid init(ServletConfig config);\n\t// Handle web requests to the GroovyServlet\n\tvoid service(HttpServletRequest request, HttpServletResponse response);\n}", "des": "This servlet will run Groovy scripts as Groovlets."}
{"index": 6210, "repo": "groovy-all-4.0.13", "code": "public abstract static class GroovyTypeCheckingExtensionSupport.TypeCheckingDSL extends Script {\n\t// Retrieves a property value.\n\tObject getProperty(String property);\n\t// Invoke a method (or closure in the binding) defined.\n\tObject invokeMethod(String name, Object args);\n\t// Sets the given property to the new value.\n\tvoid setProperty(String property, Object newValue);\n}", "des": "Event handler registration: setup Registers closure that runs after the type checker finishes initialization finish Registers closure that runs after the type checker completes type checking beforeVisitClass Registers closure that runs before type checking a class afterVisitClass Registers closure that runs after having finished the visit of a type checked class beforeVisitMethod Registers closure that runs before type checking a method body afterVisitMethod Registers closure that runs after type checking a method body beforeMethodCall Registers closure that runs before the type checker starts type checking a method call afterMethodCall Registers closure that runs once the type checker has finished type checking a method call methodNotFound Registers closure that runs when it fails to find an appropriate method for a method call ambiguousMethods Registers closure that runs when the type checker cannot choose between several candidate methods onMethodSelection Registers closure that runs when it finds a method appropriate for a method call unresolvedVariable Registers closure that runs when the type checker finds an unresolved variable unresolvedProperty Registers closure that runs when the type checker cannot find a property on the receiver unresolvedAttribute Registers closure that runs when the type checker cannot find an attribute on the receiver incompatibleAssignment Registers closure that runs when the type checker thinks that the right-hand side of an assignment is incompatible with the left-hand side incompatibleReturnType Registers closure that runs when the type checker thinks that a return value is incompatibe with the return type Expression categorization: isAnnotationConstantExpression Determines if argument is an AnnotationConstantExpression isArgumentListExpression Determines if argument is an ArgumentListExpression isArrayExpression Determines if argument is an ArrayExpression isAttributeExpression Determines if argument is an AttributeExpression isBinaryExpression Determines if argument is a BinaryExpression isBitwiseNegationExpression Determines if argument is a BitwiseNegationExpression isBooleanExpression Determines if argument is a BooleanExpression isCastExpression Determines if argument is a CastExpression isClassExpression Determines if argument is a ClassExpression isClosureExpression Determines if argument is a ClosureExpression isConstantExpression Determines if argument is a ConstantExpression isConstructorCallExpression Determines if argument is a ConstructorCallExpression isDeclarationExpression Determines if argument is a DeclarationExpression isElvisOperatorExpression Determines if argument is an ElvisOperatorExpression isEmptyExpression Determines if argument is an EmptyExpression isFieldExpression Determines if argument is a FieldExpression isGStringExpression Determines if argument is a GStringExpression isLambdaExpression Determines if argument is a LambdaExpression isListExpression Determines if argument is a ListExpression isMapExpression Determines if argument is a MapExpression isMapEntryExpression Determines if argument is a MapEntryExpression isMethodCallExpression Determines if argument is a MethodCallExpression isMethodPointerExpression Determines if argument is a MethodPointerExpression isMethodReferenceExpression Determines if argument is a MethodReferenceExpression isNamedArgumentListExpression Determines if argument is a NamedArgumentListExpression isNotExpression Determines if argument is a NotExpression isPostfixExpression Determines if argument is a PostfixExpression isPrefixExpression Determines if argument is a PrefixExpression isPropertyExpression Determines if argument is a PropertyExpression isRangeExpression Determines if argument is a RangeExpression isSpreadExpression Determines if argument is a SpreadExpression isSpreadMapExpression Determines if argument is a SpreadMapExpression isStaticMethodCallExpression Determines if argument is a StaticMethodCallExpression isTernaryExpression Determines if argument is a TernaryExpression isTupleExpression Determines if argument is a TupleExpression isUnaryMinusExpression Determines if argument is a UnaryMinusExpression isUnaryPlusExpression Determines if argument is a UnaryPlusExpression isVariableExpression Determines if argument is a VariableExpression General utility: Delegates to AbstractTypeCheckingExtension Imports static members of ClassHelper Imports static members of StaticTypeCheckingSupport"}
{"index": 6211, "repo": "groovy-all-4.0.13", "code": "public class ImportCustomizerFactory extends AbstractFactory {\n\t// Does this factory \"Own\" its child closure.\n\tboolean isHandlesNodeChildren();\n\tObject newInstance(FactoryBuilderSupport builder, Object name, Object value, Map attributes);\n\t// Only called if it isLeaf is false and isHandlesNodeChildren is true\n\tboolean onNodeChildren(FactoryBuilderSupport builder, Object node, Closure childContent);\n}", "des": "This factory allows the generation of an import customizer."}
{"index": 6212, "repo": "groovy-all-4.0.13", "code": "public static enum IndyInterface.CallType extends Enum<IndyInterface.CallType> {\n\tstatic IndyInterface.CallType fromCallSiteName(String callSiteName);\n\t// Returns the name of the call site type\n\tString getCallSiteName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IndyInterface.CallType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IndyInterface.CallType[] values();\n}", "des": "Enum for easy differentiation between call types"}
{"index": 6213, "repo": "groovy-all-4.0.13", "code": "public static enum IndyInterface.CallType extends Enum<IndyInterface.CallType> {\n\tstatic IndyInterface.CallType fromCallSiteName(String callSiteName);\n\t// Returns the name of the call site type\n\tString getCallSiteName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic IndyInterface.CallType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic IndyInterface.CallType[] values();\n}", "des": "Enum for easy differentiation between call types"}
{"index": 6214, "repo": "groovy-all-4.0.13", "code": "public interface InParameter {\n\t// The JDBC data type.\n\tint getType();\n\t// The object holding the data value.\n\tObject getValue();\n}", "des": "A typed parameter to pass to a query"}
{"index": 6215, "repo": "groovy-all-4.0.13", "code": "public class InputStreamReaderSource extends AbstractReaderSource {\n\t// Returns true if the source can be restarted (ie.\n\tboolean canReopenSource();\n\t// Returns a new Reader on the underlying source object.\n\tReader getReader();\n\t// TODO: Should return the URI for this source, but we can't know what it is here.\n\tURI getURI();\n}", "des": "A ReaderSource for source strings."}
{"index": 6216, "repo": "groovy-all-4.0.13", "code": "public interface Interceptor {\n\t// This code is executed after the method is optionally called.\n\tObject afterInvoke(Object object, String methodName, Object[] arguments, Object result);\n\t// This code is executed before the method is optionally called.\n\tObject beforeInvoke(Object object, String methodName, Object[] arguments);\n\tboolean doInvoke();\n}", "des": "Implementers of this interface can be registered in the ProxyMetaClass for notifications about method calls for objects managed by the ProxyMetaClass."}
{"index": 6217, "repo": "groovy-all-4.0.13", "code": "public class IteratorClosureAdapter<T> extends Closure {\n\tList<T> asList();\n\tprotected Object doCall(T argument);\n\t// Returns the metaclass for a given class.\n\tMetaClass getMetaClass();\n\t// Allows the MetaClass to be replaced with a derived implementation.\n\tvoid setMetaClass(MetaClass metaClass);\n}", "des": "A closure which stores calls in a List so that method calls can be iterated over in a 'yield' style way"}
{"index": 6218, "repo": "groovy-all-4.0.13", "code": "public class Java16 extends Java10 {\n\t// Returns a handle with bound receiver to invokeSpecial the given method.\n\tObject getInvokeSpecialHandle(Method method, Object receiver);\n\t// Gives the version the plugin is made for\n\tint getVersion();\n\t// Invokes a handle produced by #getInvokeSpecialdHandle\n\tObject invokeHandle(Object handle, Object[] args);\n\tprotected void makeRecordComponents(CompileUnit cu, ClassNode classNode, Class<?> clazz);\n\tprotected MethodHandles.Lookup newLookup(Class<?> declaringClass);\n}", "des": "Additional Java 16 based functions will be added here as needed."}
{"index": 6219, "repo": "groovy-all-4.0.13", "code": "public class JavaStubCompilationUnit extends CompilationUnit {\n\t// Adds a source file to the unit.\n\tSourceUnit addSource(File file);\n\t// Adds a source file to the unit.\n\tSourceUnit addSource(URL url);\n\t// Synonym for compile(Phases.ALL).\n\tvoid compile();\n\t// Configures its debugging mode and classloader classpath from a given compiler configuration.\n\tvoid configure(CompilerConfiguration config);\n\tint getStubCount();\n}", "des": "Compilation unit to only generate stubs."}
{"index": 6220, "repo": "groovy-all-4.0.13", "code": "public class JmxEventEmitter extends NotificationBroadcasterSupport implements JmxEventEmitterMBean {\n\t// Event type getter\n\tString getEvent();\n\t// Event message getter\n\tString getMessage();\n\t// Called to broadcast message on MBeanServer event bus.\n\tlong send(Object data);\n\t// Event type setter\n\tvoid setEvent(String event);\n\t// Event message setter.\n\tvoid setMessage(String message);\n}", "des": "The JmxEventEmitter is a JMX Broadcaster class that is used to send generic events on the MBeanServer's event bus."}
{"index": 6221, "repo": "groovy-all-4.0.13", "code": "public interface JmxEventEmitterMBean {\n\t// Getter - returns event thrown by emitter.\n\tString getEvent();\n\t// Method called to dispatch event on event bus.\n\tlong send(Object data);\n\t// Setter - sets event thrown by Emitter.\n\tvoid setEvent(String event);\n}", "des": "This is the management interface for JmxEventEmitter."}
{"index": 6222, "repo": "groovy-all-4.0.13", "code": "public class JmxEventListener extends Object implements NotificationListener {\n\t// Factory method that returns an instance of the listener.\n\tstatic JmxEventListener getListener();\n\t// This is the implemented method for NotificationListener.\n\tvoid handleNotification(Notification notification, Object handback);\n}", "des": "The JmxEventListener class is used by the builder to listen to events on the event bus."}
{"index": 6223, "repo": "groovy-all-4.0.13", "code": "public class JsonDelegate extends GroovyObjectSupport {\n\t// Factory method for creating JsonDelegates from closures.\n\tstatic Map<String,Object> cloneDelegateAndGetContent(Closure<?> c);\n\t// Factory method for creating JsonDelegates from closures currying an object argument.\n\tstatic Map<String,Object> curryDelegateAndGetContent(Closure<?> c, Object o);\n\tMap<String,Object> getContent();\n\t// Intercepts calls for setting a key and value for a JSON object\n\tObject invokeMethod(String name, Object args);\n}", "des": "Utility class used as delegate of closures representing JSON objects."}
{"index": 6224, "repo": "groovy-all-4.0.13", "code": "public interface JsonGenerator {\n\t// Indicates whether this JsonGenerator is configured to exclude fields by the given name.\n\tboolean isExcludingFieldsNamed(String name);\n\t// Indicates whether this JsonGenerator is configured to exclude values of the given object (may be null).\n\tboolean isExcludingValues(Object value);\n\t// Converts an object to its JSON representation.\n\tString toJson(Object object);\n}", "des": "Generates JSON from objects."}
{"index": 6225, "repo": "groovy-all-4.0.13", "code": "public static interface JsonGenerator.Converter {\n\t// Converts a given object.\n\tObject convert(Object value, String key);\n\t// Returns true if this converter can handle conversions of the given type.\n\tboolean handles(Class<?> type);\n}", "des": "Handles converting a given type."}
{"index": 6226, "repo": "groovy-all-4.0.13", "code": "public enum JsonParserType extends Enum<JsonParserType> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic JsonParserType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic JsonParserType[] values();\n}", "des": "Allows selection of parser type for new JsonSlurper."}
{"index": 6227, "repo": "groovy-all-4.0.13", "code": "public class JUnit5Runner extends Object implements GroovyRunner {\n\t// Utility method to check via reflection if the parsed class appears to be a JUnit5 test, i.e.\n\tboolean canRun(Class<?> scriptClass, GroovyClassLoader loader);\n\t// Utility method to run a JUnit 5 test.\n\tObject run(Class<?> scriptClass, GroovyClassLoader loader);\n}", "des": "Integration code for running JUnit5 tests in Groovy."}
{"index": 6228, "repo": "groovy-all-4.0.13", "code": "public interface LazyInitializable {\n\t// do initialization\n\tvoid doInit();\n\t// Check if the object is initialized.\n\tboolean isInitialized();\n\tdefault void lazyInit();\n\t// Mark the object initialized.\n\tvoid setInitialized(boolean initialized);\n}", "des": "A LazyInitializable is an object that can be initialized lazily."}
{"index": 6229, "repo": "groovy-all-4.0.13", "code": "public class LinkArgument extends Object {\n\t// Get the href attribute.\n\tString getHref();\n\t// Get the packages attribute.\n\tString getPackages();\n\t// Set the href attribute.\n\tvoid setHref(String hr);\n\t// Set the packages attribute.\n\tvoid setPackages(String packages);\n}", "des": "Represents a link pair (href, packages)."}
{"index": 6230, "repo": "groovy-all-4.0.13", "code": "public interface LoopingStatement {\n\t// Gets the loop block.\n\tStatement getLoopBlock();\n\t// Sets the loop block.\n\tvoid setLoopBlock(Statement loopBlock);\n}", "des": "This is an AST Node that provides some sort of looping mechanism."}
{"index": 6231, "repo": "groovy-all-4.0.13", "code": "@ThreadSafe public final class LRUCache<K,V> extends Object implements MemoizeCache<K,V> {\n\t// Remove all entries holding SoftReferences to gc-evicted objects.\n\tvoid cleanUpNullReferences();\n\t// Gets a value from the cache\n\tV get(K key);\n\t// Try to get the value from cache.\n\tV getAndPut(K key, MemoizeCache.ValueProvider<? super K,? extends V> valueProvider);\n\t// Associates the specified value with the specified key in the cache.\n\tV put(K key, V value);\n}", "des": "A cache backed by a ConcurrentLinkedHashMap"}
{"index": 6232, "repo": "groovy-all-4.0.13", "code": "public enum MacroStub extends Enum<MacroStub> {\n\t<T> T macroMethod(T obj);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MacroStub valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MacroStub[] values();\n}", "des": "Stub for macro calls."}
{"index": 6233, "repo": "groovy-all-4.0.13", "code": "public class ManagedConcurrentValueMap<K,V> extends Object {\n\t// Returns the value stored for the given key at the point of call.\n\tV get(K key);\n\t// Sets a new value for a given key.\n\tvoid put(K key, V value);\n\t// Sets a new bundle used for reference creation.\n\tvoid setBundle(ReferenceBundle bundle);\n}", "des": "This is a basic implementation of a map able to forget its values."}
{"index": 6234, "repo": "groovy-all-4.0.13", "code": "public class MapConstructorASTTransformation extends AbstractASTTransformation implements CompilationUnitAware {\n\t// If the transform is associated with a single annotation, returns a name suitable for displaying in error messages.\n\tString getAnnotationName();\n\tvoid setCompilationUnit(CompilationUnit unit);\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n}", "des": "Handles generation of code for the @MapConstructor annotation."}
{"index": 6235, "repo": "groovy-all-4.0.13", "code": "public static class MarkupTemplateEngine.CachingTemplateResolver extends MarkupTemplateEngine.DefaultTemplateResolver {\n\t// This method is called once the template engine is initialized, providing the resolver with the template engine configuration and its template class loader.\n\tvoid configure(ClassLoader templateClassLoader, TemplateConfiguration configuration);\n\t// Resolvers must implement this method in order to resolve a template, given a template path.\n\tURL resolveTemplate(String templatePath);\n}", "des": "A template resolver which avoids calling ClassLoader.getResource(String) if a template path already has been queried before."}
{"index": 6236, "repo": "groovy-all-4.0.13", "code": "public interface MemoizeCache<K,V> {\n\t// Invoked when some of the held SoftReferences have been evicted by the garbage collector and so should be removed from the cache.\n\tvoid cleanUpNullReferences();\n\t// Gets a value from the cache\n\tV get(K key);\n\t// Try to get the value from cache.\n\tdefault V getAndPut(K key, MemoizeCache.ValueProvider<? super K,? extends V> valueProvider);\n\t// Associates the specified value with the specified key in the cache.\n\tV put(K key, V value);\n}", "des": "Represents a memoize cache with its essential methods"}
{"index": 6237, "repo": "groovy-all-4.0.13", "code": "public class MessageSource extends GroovyObjectSupport {\n\t// Format a message (based on MessageFormat) using the message from the resource bundles using the given code as a pattern and the given objects as arguments.\n\tString format(String code, Object[] args);\n\t// Get a raw message from the resource bundles using the given code.\n\tString getMessage(String code);\n\t// Retrieves a property value.\n\tObject getProperty(String name);\n}", "des": "Message source backed up by one or more ResourceBundle instances for simple i18n support."}
{"index": 6238, "repo": "groovy-all-4.0.13", "code": "public class MetaArrayLengthProperty extends MetaProperty {\n\t// Get this property from the given object.\n\tObject getProperty(Object object);\n\t// Sets the property on the given object to the new value\n\tvoid setProperty(Object object, Object newValue);\n}", "des": "Represents the length property of an array"}
{"index": 6239, "repo": "groovy-all-4.0.13", "code": "public class MixinInstanceMetaMethod extends MetaMethod {\n\t// Gets the class where this method is declared\n\tCachedClass getDeclaringClass();\n\t// Returns the modifiers for this method\n\tint getModifiers();\n\t// Returns the name of the method represented by this class\n\tString getName();\n\tprotected Class[] getPT();\n\t// Access the return type for this method\n\tClass getReturnType();\n\t// Invoke this method\n\tObject invoke(Object object, Object[] arguments);\n}", "des": "MetaMethod for mixed in classes"}
{"index": 6240, "repo": "groovy-all-4.0.13", "code": "public class Namespace extends Object {\n\t// Returns the QName for the given localName.\n\tQName get(String localName);\n\t// Returns the prefix mapped to this namespace\n\tString getPrefix();\n\t// Returns the URI of this namespace\n\tString getUri();\n}", "des": "A simple helper class which acts as a factory of QName instances."}
{"index": 6241, "repo": "groovy-all-4.0.13", "code": "public class NewifyASTTransformation extends ClassCodeExpressionTransformer implements ASTTransformation {\n\tstatic String extractName(String s);\n\tprotected SourceUnit getSourceUnit();\n\t// NOTE: This method does not visit Expressions within Closures, for performance and historical reasons.\n\tExpression transform(Expression expr);\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n}", "des": "Handles generation of code for the @Newify AST transform."}
{"index": 6242, "repo": "groovy-all-4.0.13", "code": "public class NewInstanceMetaMethod extends NewMetaMethod {\n\t// Returns the modifiers for this method\n\tint getModifiers();\n\t// Invoke this method\n\tObject invoke(Object object, Object[] arguments);\n\t// Returns whether this method is static.\n\tboolean isStatic();\n}", "des": "A MetaMethod implementation where the underlying method is really a static helper method on some class but it appears to be an instance method on a class."}
{"index": 6243, "repo": "groovy-all-4.0.13", "code": "public class NewStaticMetaMethod extends NewMetaMethod {\n\t// Returns the modifiers for this method\n\tint getModifiers();\n\t// Invoke this method\n\tObject invoke(Object object, Object[] arguments);\n\t// Returns whether this method is static.\n\tboolean isStatic();\n}", "des": "A MetaMethod implementation where the underlying method is really a static helper method on some class."}
{"index": 6244, "repo": "groovy-all-4.0.13", "code": "public class NullCheckASTTransformation extends AbstractASTTransformation {\n\tstatic boolean hasIncludeGenerated(ClassNode cNode);\n\tstatic ThrowStatement makeThrowStmt(String variableName);\n\t// Mark a method as already processed.\n\tstatic void markAsProcessed(MethodNode mn);\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n}", "des": "Handles generation of code for the @NullCheck annotation."}
{"index": 6245, "repo": "groovy-all-4.0.13", "code": "public static class ObjectGraphBuilder.DefaultRelationNameResolver extends Object implements ObjectGraphBuilder.RelationNameResolver {\n\t// Handles the common English regular plurals with the following rules.\n\tString resolveChildRelationName(String parentName, Object parent, String childName, Object child);\n\t// Follow the most conventional pattern, returns the parentName unchanged.\n\tString resolveParentRelationName(String parentName, Object parent, String childName, Object child);\n}", "des": "Default impl that returns parentName and childName accordingly."}
{"index": 6246, "repo": "groovy-all-4.0.13", "code": "public static interface ObjectGraphBuilder.RelationNameResolver {\n\t// Returns the mapping name of child -> parent\n\tString resolveChildRelationName(String parentName, Object parent, String childName, Object child);\n\t// Returns the mapping name of parent -> child\n\tString resolveParentRelationName(String parentName, Object parent, String childName, Object child);\n}", "des": "Strategy for resolving a relationship property name."}
{"index": 6247, "repo": "groovy-all-4.0.13", "code": "public class ObjectUtil extends Object {\n\t// Clone the specified object\n\tstatic <T> T cloneObject(T object);\n\t// Returns the method handle of cloneObject(Object)\n\tstatic MethodHandle getCloneObjectMethodHandle();\n}", "des": "Util for object's operations with checks"}
{"index": 6248, "repo": "groovy-all-4.0.13", "code": "public enum PackageScopeTarget extends Enum<PackageScopeTarget> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic PackageScopeTarget valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic PackageScopeTarget[] values();\n}", "des": "Intended target when @PackageScope is placed at the class level."}
{"index": 6249, "repo": "groovy-all-4.0.13", "code": "public abstract class ParserPluginFactory extends Object {\n\t// Deprecated.\n\tstatic ParserPluginFactory antlr2();\n\t// Creates the ANTLR 4 parser.\n\tstatic ParserPluginFactory antlr4();\n\tabstract ParserPlugin createParserPlugin();\n}", "des": "A factory of parser plugin instances."}
{"index": 6250, "repo": "groovy-all-4.0.13", "code": "public interface PropertyAccessInterceptor extends Interceptor {\n\t// Intercepts a getXXX call and returns a result.\n\tObject beforeGet(Object object, String property);\n\t// Intercepts a setXXX call\n\tvoid beforeSet(Object object, String property, Object newValue);\n}", "des": "An interface that adds the ability to intercept property getters/setters"}
{"index": 6251, "repo": "groovy-all-4.0.13", "code": "public class PropertyPathFullBinding extends AbstractFullBinding implements PropertyChangeListener {\n\t// Causes automatic updating of bound values to be turned on.\n\tvoid bind();\n\tvoid propertyChange(PropertyChangeEvent evt);\n\t// Causes the current bindings to be reset.\n\tvoid rebind();\n\t// Causes automatic updating of bound values to be turned off.\n\tvoid unbind();\n}", "des": "A property path full binding"}
{"index": 6252, "repo": "groovy-all-4.0.13", "code": "public class Proxy extends GroovyObjectSupport {\n\tObject getAdaptee();\n\t// Invokes the given method.\n\tObject invokeMethod(String name, Object args);\n\tIterator iterator();\n\tvoid setAdaptee(Object adaptee);\n\t// This method is for convenience.\n\tProxy wrap(Object adaptee);\n}", "des": "Dynamic groovy proxy for another object."}
{"index": 6253, "repo": "groovy-all-4.0.13", "code": "public interface ReaderSource extends HasCleanup {\n\t// Returns true if the source can be restarted (ie.\n\tboolean canReopenSource();\n\t// Cleans up any cached resources used by getLine().\n\tvoid cleanup();\n\t// Returns a line from the source, or null, if unavailable.\n\tString getLine(int lineNumber, Janitor janitor);\n\t// Returns a new Reader on the underlying source object.\n\tReader getReader();\n\t// Returns a URI for this source.\n\tURI getURI();\n}", "des": "An interface for things that can supply (and potentially resupply) a Reader on a source stream."}
{"index": 6254, "repo": "groovy-all-4.0.13", "code": "public class RecordCompletionASTTransformation extends AbstractASTTransformation {\n\t// If the transform is associated with a single annotation, returns a name suitable for displaying in error messages.\n\tString getAnnotationName();\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n}", "des": "Handles completion of code for the @RecordType annotation."}
{"index": 6255, "repo": "groovy-all-4.0.13", "code": "public enum RecordTypeMode extends Enum<RecordTypeMode> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic RecordTypeMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic RecordTypeMode[] values();\n}", "des": "Intended mode to use for records when using the @RecordType annotation (or record keyword)."}
{"index": 6256, "repo": "groovy-all-4.0.13", "code": "public class Reference<T> extends GroovyObjectSupport implements Serializable {\n\tT get();\n\t// Retrieves a property value.\n\tObject getProperty(String property);\n\t// Invokes the given method.\n\tObject invokeMethod(String name, Object args);\n\tvoid set(T value);\n\t// Sets the given property to the new value.\n\tvoid setProperty(String property, Object newValue);\n}", "des": "Represents a reference to a value"}
{"index": 6257, "repo": "groovy-all-4.0.13", "code": "public class ReflectorLoader extends ClassLoader {\n\t// helper method to define Reflector classes.\n\tClass defineClass(String name, byte[] bytecode, ProtectionDomain domain);\n\t// Tries to find a Groovy class.\n\tprotected Class findClass(String name);\n\t// try to load one of the defined Reflector classes by name.\n\tClass getLoadedClass(String name);\n\t// Loads a class per name.\n\tprotected Class loadClass(String name, boolean resolve);\n}", "des": "Reflector creation helper."}
{"index": 6258, "repo": "groovy-all-4.0.13", "code": "public class ResultSetMetaDataWrapper extends GroovyObjectSupport {\n\t// Retrieves a property value.\n\tObject getProperty(String property);\n\t// Invokes the given method.\n\tObject invokeMethod(String name, Object args);\n\t// Sets the given property to the new value.\n\tvoid setProperty(String property, Object newValue);\n}", "des": "This class defines a wrapper for accessing a specific column in ResultSetMetaData."}
{"index": 6259, "repo": "groovy-all-4.0.13", "code": "public class ReturnAdder extends Object {\n\t// Deprecated. Use visitMethod(MethodNode) instead.\n\tstatic void addReturnIfNeeded(MethodNode node);\n\t// Adds return statements to given method whenever an implicit return is detected.\n\tvoid visitMethod(MethodNode node);\n}", "des": "Utility class to add return statements."}
{"index": 6260, "repo": "groovy-all-4.0.13", "code": "public class RootLoaderRef extends org.apache.tools.ant.taskdefs.MatchingTask {\n\t// Adds a path to the classpath.\n\torg.apache.tools.ant.types.Path createClasspath();\n\tvoid execute();\n\t// Set the classpath to be used for this compilation.\n\tvoid setClasspath(org.apache.tools.ant.types.Path classpath);\n\t// Adds a reference to a classpath defined elsewhere.\n\tvoid setClasspathRef(org.apache.tools.ant.types.Reference r);\n\t// sets the name of the reference which should store the Loader\n\tvoid setRef(String n);\n}", "des": "Sets the RootLoader as reference."}
{"index": 6261, "repo": "groovy-all-4.0.13", "code": "public class ScriptExtensions extends Object {\n\t// Same as eval(ScriptEngine, Reader, Binding) except that the source of the script is provided as a Reader\n\tstatic Object eval(ScriptEngine self, Reader reader, Binding binding);\n\t// Executes the specified script.\n\tstatic Object eval(ScriptEngine self, String script, Binding binding);\n}", "des": "This class defines new Java 6 specific groovy methods which extend the normal JDK classes inside the Groovy environment."}
{"index": 6262, "repo": "groovy-all-4.0.13", "code": "public class ScriptRunner extends Object {\n\t// Run the script file specified by the file path\n\tstatic void runScript(File path);\n\t// Run the script file specified by the classpath\n\tstatic void runScript(String cp);\n}", "des": "The tool to simulate running script files via groovy command"}
{"index": 6263, "repo": "groovy-all-4.0.13", "code": "public class SealedASTTransformation extends AbstractASTTransformation {\n\t// Reports true if native sealed class information should be written into the bytecode.\n\tstatic boolean sealedNative(AnnotatedNode node);\n\t// Reports true if the Sealed annotation should not be included in the bytecode for a sealed or emulated-sealed class.\n\tstatic boolean sealedSkipAnnotation(AnnotatedNode node);\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n}", "des": "Handles generation of code for the @Sealed annotation."}
{"index": 6264, "repo": "groovy-all-4.0.13", "code": "public enum SealedMode extends Enum<SealedMode> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic SealedMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic SealedMode[] values();\n}", "des": "Intended mode to use for sealed classes when using the @Sealed annotation (or sealed keyword)."}
{"index": 6265, "repo": "groovy-all-4.0.13", "code": "public class SecureASTCustomizerFactory extends AbstractFactory {\n\t// Does this factory \"Own\" its child closure.\n\tboolean isHandlesNodeChildren();\n\tObject newInstance(FactoryBuilderSupport builder, Object name, Object value, Map attributes);\n\t// Only called if it isLeaf is false and isHandlesNodeChildren is true\n\tboolean onNodeChildren(FactoryBuilderSupport builder, Object node, Closure childContent);\n}", "des": "This factory allows the generation of a SecureASTCustomizer."}
{"index": 6266, "repo": "groovy-all-4.0.13", "code": "public class SimpleGroovyTag extends Object implements GroovyTag {\n\t// The tag name, e.g.\n\tString name();\n\t// The optional parameter for tags like \"throws\" and \"param\".\n\tString param();\n\t// The text associated with the tag.\n\tString text();\n}", "des": "Stores info about GroovyDoc tags."}
{"index": 6267, "repo": "groovy-all-4.0.13", "code": "public class SourceText extends Object {\n\t// Returns the column in getNormalizedText() corresponding to the given line and column in the original source text.\n\tint getNormalizedColumn(int line, int column);\n\t// Returns the assertion's source text after removing line breaks.\n\tString getNormalizedText();\n}", "des": "Provides the source text for an assertion statement and translates coordinates in the original source text to coordinates relative to the assertion's (normalized) source text."}
{"index": 6268, "repo": "groovy-all-4.0.13", "code": "public class SqlExtensions extends Object {\n\t// Coerce a GroovyResultSet to a boolean value.\n\tstatic boolean asBoolean(GroovyResultSet grs);\n\t// Return an Iterator given a ResultSetMetaData.\n\tstatic Iterator<ResultSetMetaDataWrapper> iterator(ResultSetMetaData resultSetMetaData);\n\t// Returns a GroovyRowResult given a ResultSet.\n\tstatic GroovyRowResult toRowResult(ResultSet rs);\n\t// Return a java.sql.Timestamp given a java.util.Date.\n\tstatic Timestamp toTimestamp(Date d);\n}", "des": "This class defines all the new SQL-related groovy methods which enhance the normal JDK SQL classes when inside the Groovy environment."}
{"index": 6269, "repo": "groovy-all-4.0.13", "code": "public enum StaticCompilationMetadataKeys extends Enum<StaticCompilationMetadataKeys> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StaticCompilationMetadataKeys valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StaticCompilationMetadataKeys[] values();\n}", "des": "Static compilation AST node metadata keys."}
{"index": 6270, "repo": "groovy-all-4.0.13", "code": "public class StaticCompileTransformation extends StaticTypesTransformation {\n\t// Allows subclasses to provide their own visitor.\n\tprotected StaticTypeCheckingVisitor newVisitor(SourceUnit unit, ClassNode node);\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n}", "des": "Handles the implementation of the CompileStatic transformation."}
{"index": 6271, "repo": "groovy-all-4.0.13", "code": "public enum StaticTypesMarker extends Enum<StaticTypesMarker> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic StaticTypesMarker valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic StaticTypesMarker[] values();\n}", "des": "This enumeration is used by the AST transformations which rely on static type checking, either to store or to retrieve information from AST node metadata."}
{"index": 6272, "repo": "groovy-all-4.0.13", "code": "public class StaticTypesTransformation extends Object implements ASTTransformation, CompilationUnitAware {\n\tprotected void addTypeCheckingExtensions(StaticTypeCheckingVisitor visitor, Expression extensions);\n\t// Allows subclasses to provide their own visitor.\n\tprotected StaticTypeCheckingVisitor newVisitor(SourceUnit unit, ClassNode node);\n\tvoid setCompilationUnit(CompilationUnit unit);\n\t// The method is invoked when an AST Transformation is active.\n\tvoid visit(ASTNode[] nodes, SourceUnit source);\n}", "des": "Handles the implementation of the TypeChecked transformation."}
{"index": 6273, "repo": "groovy-all-4.0.13", "code": "public class StringBufferWriter extends Writer {\n\t// Closing a StringWriter has no effect.\n\tvoid close();\n\t// Flush the stream.\n\tvoid flush();\n\t// Write a portion of an array of characters.\n\tvoid write(char[] text, int offset, int length);\n\t// Write a single character.\n\tvoid write(int c);\n\t// Write a string.\n\tvoid write(String text);\n\t// Write a portion of a string.\n\tvoid write(String text, int offset, int length);\n}", "des": "This class codes around a silly limitation of StringWriter which doesn't allow a StringBuffer to be passed in as a constructor for some bizarre reason."}
{"index": 6274, "repo": "groovy-all-4.0.13", "code": "public class StringReaderSource extends AbstractReaderSource {\n\t// Returns a new Reader on the underlying source object.\n\tReader getReader();\n\t// Returns a Data URI (RFC 2397) containing the literal value of this source string.\n\tURI getURI();\n}", "des": "A ReaderSource for source strings."}
{"index": 6275, "repo": "groovy-all-4.0.13", "code": "public class SyntaxErrorMessage extends Message {\n\t// Returns the underlying SyntaxException.\n\tSyntaxException getCause();\n\t// Writes out a nicely formatted summary of the syntax error.\n\tvoid write(PrintWriter output, Janitor janitor);\n}", "des": "A class for error messages produced by the parser system."}
{"index": 6276, "repo": "groovy-all-4.0.13", "code": "public class SyntaxException extends GroovyException {\n\tint getEndColumn();\n\tint getEndLine();\n\t// Retrieve the line upon which the error occurred.\n\tint getLine();\n\tString getMessage();\n\tString getOriginalMessage();\n\tString getSourceLocator();\n\t// Retrieve the column upon which the error occurred.\n\tint getStartColumn();\n\tint getStartLine();\n\tvoid setSourceLocator(String sourceLocator);\n}", "des": "Base exception indicating a syntax error."}
{"index": 6277, "repo": "groovy-all-4.0.13", "code": "public class TableLayout extends JPanel {\n\t// Adds a new cell to the current grid\n\tvoid addCell(TableLayoutCell cell);\n\tint getCellpadding();\n\t// Creates a new row index for child tr tags\n\tint nextRowIndex();\n\tvoid setCellpadding(int cellpadding);\n}", "des": "Represents a HTML style table layout"}
{"index": 6278, "repo": "groovy-all-4.0.13", "code": "public interface TemplateResolver {\n\t// This method is called once the template engine is initialized, providing the resolver with the template engine configuration and its template class loader.\n\tvoid configure(ClassLoader templateClassLoader, TemplateConfiguration configuration);\n\t// Resolvers must implement this method in order to resolve a template, given a template path.\n\tURL resolveTemplate(String templatePath);\n}", "des": "Interface for template resolvers, which, given a template identifier, return a URL where the template can be loaded."}
{"index": 6279, "repo": "groovy-all-4.0.13", "code": "public class ThreadManagedMetaBeanProperty extends MetaBeanProperty {\n\t// Get the getter method.\n\tMetaMethod getGetter();\n\t// Retrieves the initial value of the ThreadBound property\n\tObject getInitialValue();\n\tObject getInitialValue(Object object);\n\t// Get the setter method.\n\tMetaMethod getSetter();\n\t// Closure responsible for creating the initial value of thread-managed bean properties\n\tvoid setInitialValueCreator(Closure callable);\n}", "des": "This MetaBeanProperty will create a pseudo property whose value is bound to an object using weak references."}
{"index": 6280, "repo": "groovy-all-4.0.13", "code": "public class TraitTypeCheckingExtension extends AbstractTypeCheckingExtension {\n\t// This method is called by the type checker when a method call cannot be resolved.\n\tList<MethodNode> handleMissingMethod(ClassNode receiver, String name, ArgumentListExpression argumentList, ClassNode[] argumentTypes, MethodCall call);\n\t// Subclasses should implement this method whenever they need to perform special checks before the type checker starts working.\n\tvoid setup();\n}", "des": "A type checking extension that will take care of handling errors which are specific to traits."}
{"index": 6281, "repo": "groovy-all-4.0.13", "code": "public class TryWithResourcesASTTransformation extends Object {\n\t// Reference JLS \"14.20.3.\n\tStatement transform(TryCatchStatement tryCatchStatement);\n\t// See https://docs.oracle.com/javase/specs/jls/se9/html/jls-14.html 14.20.3.1.\n\tBinaryExpression transformResourceAccess(Expression variableAccessExpression);\n}", "des": "Transform try-with-resources to try-catch-finally Reference JLS \"14.20.3."}
{"index": 6282, "repo": "groovy-all-4.0.13", "code": "public final class Tuple2<T1,T2> extends Tuple {\n\tTuple2<T1,T2> clone();\n\t// Deprecated.\n\tT1 getFirst();\n\t// Deprecated.\n\tT2 getSecond();\n\tT1 getV1();\n\tT2 getV2();\n}", "des": "Represents a list of 2 typed Objects."}
{"index": 6283, "repo": "groovy-all-4.0.13", "code": "public final class Tuple3<T1,T2,T3> extends Tuple {\n\tTuple3<T1,T2,T3> clone();\n\t// Deprecated.\n\tT1 getFirst();\n\t// Deprecated.\n\tT2 getSecond();\n\t// Deprecated.\n\tT3 getThird();\n\tT1 getV1();\n\tT2 getV2();\n\tT3 getV3();\n}", "des": "Represents a list of 3 typed Objects."}
{"index": 6284, "repo": "groovy-all-4.0.13", "code": "public final class Tuple4<T1,T2,T3,T4> extends Tuple {\n\tTuple4<T1,T2,T3,T4> clone();\n\t// Deprecated.\n\tT1 getFirst();\n\t// Deprecated.\n\tT4 getFourth();\n\t// Deprecated.\n\tT2 getSecond();\n\t// Deprecated.\n\tT3 getThird();\n\tT1 getV1();\n\tT2 getV2();\n\tT3 getV3();\n\tT4 getV4();\n}", "des": "Represents a list of 4 typed Objects."}
{"index": 6285, "repo": "groovy-all-4.0.13", "code": "public final class Tuple5<T1,T2,T3,T4,T5> extends Tuple {\n\tTuple5<T1,T2,T3,T4,T5> clone();\n\t// Deprecated.\n\tT5 getFifth();\n\t// Deprecated.\n\tT1 getFirst();\n\t// Deprecated.\n\tT4 getFourth();\n\t// Deprecated.\n\tT2 getSecond();\n\t// Deprecated.\n\tT3 getThird();\n\tT1 getV1();\n\tT2 getV2();\n\tT3 getV3();\n\tT4 getV4();\n\tT5 getV5();\n}", "des": "Represents a list of 5 typed Objects."}
{"index": 6286, "repo": "groovy-all-4.0.13", "code": "public final class Tuple6<T1,T2,T3,T4,T5,T6> extends Tuple {\n\tTuple6<T1,T2,T3,T4,T5,T6> clone();\n\t// Deprecated.\n\tT5 getFifth();\n\t// Deprecated.\n\tT1 getFirst();\n\t// Deprecated.\n\tT4 getFourth();\n\t// Deprecated.\n\tT2 getSecond();\n\t// Deprecated.\n\tT6 getSixth();\n\t// Deprecated.\n\tT3 getThird();\n\tT1 getV1();\n\tT2 getV2();\n\tT3 getV3();\n\tT4 getV4();\n\tT5 getV5();\n\tT6 getV6();\n}", "des": "Represents a list of 6 typed Objects."}
{"index": 6287, "repo": "groovy-all-4.0.13", "code": "public final class Tuple7<T1,T2,T3,T4,T5,T6,T7> extends Tuple {\n\tTuple7<T1,T2,T3,T4,T5,T6,T7> clone();\n\t// Deprecated.\n\tT5 getFifth();\n\t// Deprecated.\n\tT1 getFirst();\n\t// Deprecated.\n\tT4 getFourth();\n\t// Deprecated.\n\tT2 getSecond();\n\t// Deprecated.\n\tT7 getSeventh();\n\t// Deprecated.\n\tT6 getSixth();\n\t// Deprecated.\n\tT3 getThird();\n\tT1 getV1();\n\tT2 getV2();\n\tT3 getV3();\n\tT4 getV4();\n\tT5 getV5();\n\tT6 getV6();\n\tT7 getV7();\n}", "des": "Represents a list of 7 typed Objects."}
{"index": 6288, "repo": "groovy-all-4.0.13", "code": "public final class Tuple8<T1,T2,T3,T4,T5,T6,T7,T8> extends Tuple {\n\tTuple8<T1,T2,T3,T4,T5,T6,T7,T8> clone();\n\t// Deprecated.\n\tT8 getEighth();\n\t// Deprecated.\n\tT5 getFifth();\n\t// Deprecated.\n\tT1 getFirst();\n\t// Deprecated.\n\tT4 getFourth();\n\t// Deprecated.\n\tT2 getSecond();\n\t// Deprecated.\n\tT7 getSeventh();\n\t// Deprecated.\n\tT6 getSixth();\n\t// Deprecated.\n\tT3 getThird();\n\tT1 getV1();\n\tT2 getV2();\n\tT3 getV3();\n\tT4 getV4();\n\tT5 getV5();\n\tT6 getV6();\n\tT7 getV7();\n\tT8 getV8();\n}", "des": "Represents a list of 8 typed Objects."}
{"index": 6289, "repo": "groovy-all-4.0.13", "code": "public enum TypeCheckingMode extends Enum<TypeCheckingMode> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic TypeCheckingMode valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic TypeCheckingMode[] values();\n}", "des": "This enumeration can be used whenever it is preferred to annotate a class as TypeChecked in general, but where only one or more methods are \"dynamic\"."}
{"index": 6290, "repo": "groovy-all-4.0.13", "code": "public class TypeTransformers extends Object {\n\t// Adds a type transformer applied at runtime.\n\tprotected static MethodHandle addTransformer(MethodHandle handle, int pos, Object arg, Class<?> parameter);\n\t// Apply a transformer as filter.\n\tstatic MethodHandle applyUnsharpFilter(MethodHandle handle, int pos, MethodHandle transformer);\n}", "des": "This class contains several transformers for used during method invocation."}
{"index": 6291, "repo": "groovy-all-4.0.13", "code": "public class URLReaderSource extends AbstractReaderSource {\n\t// Returns a new Reader on the underlying source object.\n\tReader getReader();\n\t// Returns a URI for the URL of this source.\n\tURI getURI();\n}", "des": "A ReaderSource for source files hosted at a URL."}
{"index": 6292, "repo": "groovy-all-4.0.13", "code": "public abstract class Utilities extends Object {\n\t// Returns the end-of-line marker.\n\tstatic String eol();\n\t// Tells if the given string is a valid Java identifier.\n\tstatic boolean isJavaIdentifier(String name);\n\t// Returns a string made up of repetitions of the specified string.\n\tstatic String repeatString(String pattern, int repeats);\n}", "des": "Various utility functions for use in the compiler."}
{"index": 6293, "repo": "groovy-all-4.0.13", "code": "public class ValueHolder extends Object implements ValueModel {\n\t// Add a PropertyChangeListener to the listener list.\n\tvoid addPropertyChangeListener(PropertyChangeListener listener);\n\tClass getType();\n\tObject getValue();\n\tboolean isEditable();\n\t// Removes a PropertyChangeListener from the listener list.\n\tvoid removePropertyChangeListener(PropertyChangeListener listener);\n\tvoid setEditable(boolean editable);\n\tvoid setValue(Object value);\n}", "des": "A simple ValueModel implementation which is a holder of an object value."}
{"index": 6294, "repo": "groovy-all-4.0.13", "code": "public enum Visibility extends Enum<Visibility> {\n\tint getModifier();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Visibility valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Visibility[] values();\n}", "des": "Indicates the visibility of a node."}
{"index": 6295, "repo": "groovy-all-4.0.13", "code": "public class WarningMessage extends LocatedMessage {\n\t// Returns true if this message is as or more important than the specified importance level.\n\tboolean isRelevant(int importance);\n\t// Returns true if a warning would be relevant to the specified level.\n\tstatic boolean isRelevant(int actual, int limit);\n\t// Writes this message to the specified PrintWriter.\n\tvoid write(PrintWriter writer, Janitor janitor);\n}", "des": "A class for warning messages."}
{"index": 6296, "repo": "groovy-all-4.0.13", "code": "public class WhileStatement extends Statement implements LoopingStatement {\n\tBooleanExpression getBooleanExpression();\n\t// Gets the loop block.\n\tStatement getLoopBlock();\n\tvoid setBooleanExpression(BooleanExpression booleanExpression);\n\t// Sets the loop block.\n\tvoid setLoopBlock(Statement loopBlock);\n\tvoid visit(GroovyCodeVisitor visitor);\n}", "des": "Represents a while (condition) { ..."}
{"index": 6297, "repo": "groovy-all-4.0.13", "code": "public class XmlExtensions extends Object {\n\t// Makes NodeList iterable by returning a read-only Iterator which traverses over each Node.\n\tstatic Iterator<Node> iterator(NodeList nodeList);\n\t// Transforms the element to its text equivalent.\n\tstatic String serialize(Element element);\n}", "des": "This class defines all the new XML-related groovy methods which enhance the normal JDK XML classes when inside the Groovy environment."}
{"index": 6298, "repo": "groovy-all-4.0.13", "code": "public class XmlTemplateEngine extends TemplateEngine {\n\t// Creates a template by reading content from the Reader.\n\tTemplate createTemplate(Reader reader);\n\tString getIndentation();\n\t// Closure that can be used to configure the printer.\n\tvoid setConfigurePrinter(Closure configurePrinter);\n\tvoid setIndentation(String indentation);\n}", "des": "Template engine for use in templating scenarios where both the template source and the expected output are intended to be XML."}
{"index": 6299, "repo": "groovy-all-4.0.13", "code": "public final class YamlConverter extends Object {\n\t// Convert json to yaml\n\tstatic String convertJsonToYaml(Reader jsonReader);\n\t// Convert yaml to json\n\tstatic String convertYamlToJson(Reader yamlReader);\n}", "des": "A converter for converting YAML to JSON, vice versa"}
{"index": 6300, "repo": "spring-integration-kafka-6.1.2", "code": "public static enum KafkaMessageDrivenChannelAdapter.ListenerMode extends Enum<KafkaMessageDrivenChannelAdapter.ListenerMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic KafkaMessageDrivenChannelAdapter.ListenerMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic KafkaMessageDrivenChannelAdapter.ListenerMode[] values();\n}", "des": "The listener mode for the container, record or batch."}
{"index": 6301, "repo": "spring-integration-kafka-6.1.2", "code": "public class KafkaOutboundGatewaySpec<K,V,R,S extends KafkaOutboundGatewaySpec<K,V,R,S>> extends KafkaProducerMessageHandlerSpec<K,V,S> {\n\t// Set the time to wait for partition assignment, when used as a gateway, to determine the default reply-to topic/partition.\n\tS assigmentDuration(Duration duration);\n\t// Set a message converter for replies (when a gateway).\n\tS replyMessageConverter(org.springframework.kafka.support.converter.RecordMessageConverter messageConverter);\n}", "des": "A MessageHandlerSpec implementation for the KafkaProducerMessageHandler as a gateway."}
{"index": 6302, "repo": "spring-tx-6.0.11", "code": "public class BeanFactoryTransactionAttributeSourceAdvisor extends org.springframework.aop.support.AbstractBeanFactoryPointcutAdvisor {\n\torg.springframework.aop.Pointcut getPointcut();\n\t// Set the ClassFilter to use for this pointcut.\n\tvoid setClassFilter(org.springframework.aop.ClassFilter classFilter);\n\t// Set the transaction attribute source which is used to find transaction attributes.\n\tvoid setTransactionAttributeSource(TransactionAttributeSource transactionAttributeSource);\n}", "des": "Advisor driven by a TransactionAttributeSource, used to include a transaction advice bean for methods that are transactional."}
{"index": 6303, "repo": "spring-tx-6.0.11", "code": "public abstract class DaoSupport extends Object implements org.springframework.beans.factory.InitializingBean {\n\tfinal void afterPropertiesSet();\n\t// Abstract subclasses must override this to check their configuration.\n\tprotected abstract void checkDaoConfig();\n\t// Concrete subclasses can override this for custom initialization behavior.\n\tprotected void initDao();\n}", "des": "Generic base class for DAOs, defining template methods for DAO initialization."}
{"index": 6304, "repo": "spring-tx-6.0.11", "code": "public abstract class DelegatingTransactionAttribute extends DelegatingTransactionDefinition implements TransactionAttribute, Serializable {\n\t// Return labels associated with this transaction attribute.\n\tCollection<String> getLabels();\n\t// Return a qualifier value associated with this transaction attribute.\n\tString getQualifier();\n\t// Should we roll back on the given exception?\n\tboolean rollbackOn(Throwable ex);\n}", "des": "TransactionAttribute implementation that delegates all calls to a given target TransactionAttribute instance."}
{"index": 6305, "repo": "spring-tx-6.0.11", "code": "public abstract class DelegatingTransactionDefinition extends Object implements TransactionDefinition, Serializable {\n\tboolean equals(Object other);\n\t// Return the isolation level.\n\tint getIsolationLevel();\n\t// Return the name of this transaction.\n\tString getName();\n\t// Return the propagation behavior.\n\tint getPropagationBehavior();\n\t// Return the transaction timeout.\n\tint getTimeout();\n\t// Return whether to optimize as a read-only transaction.\n\tboolean isReadOnly();\n}", "des": "TransactionDefinition implementation that delegates all calls to a given target TransactionDefinition instance."}
{"index": 6306, "repo": "spring-tx-6.0.11", "code": "public class IncorrectResultSizeDataAccessException extends DataRetrievalFailureException {\n\t// Return the actual result size (or -1 if unknown).\n\tint getActualSize();\n\t// Return the expected result size.\n\tint getExpectedSize();\n}", "des": "Data access exception thrown when a result was not of the expected size, for example when expecting a single row but getting 0 or more than 1 rows."}
{"index": 6307, "repo": "spring-tx-6.0.11", "code": "public enum Isolation extends Enum<Isolation> {\n\tint value();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Isolation valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Isolation[] values();\n}", "des": "Enumeration that represents transaction isolation levels for use with the @Transactional annotation, corresponding to the TransactionDefinition interface."}
{"index": 6308, "repo": "spring-tx-6.0.11", "code": "public class JtaTransactionObject extends Object implements SmartTransactionObject {\n\t// This implementation triggers flush callbacks, assuming that they will flush all affected ORM sessions.\n\tvoid flush();\n\t// Return the JTA UserTransaction object for the current transaction.\n\tfinal UserTransaction getUserTransaction();\n\t// This implementation checks the UserTransaction's rollback-only flag.\n\tboolean isRollbackOnly();\n}", "des": "JTA transaction object, representing a UserTransaction."}
{"index": 6309, "repo": "spring-tx-6.0.11", "code": "public interface PlatformTransactionManager extends TransactionManager {\n\t// Commit the given transaction, with regard to its status.\n\tvoid commit(TransactionStatus status);\n\t// Return a currently active transaction or create a new one, according to the specified propagation behavior.\n\tTransactionStatus getTransaction(TransactionDefinition definition);\n\t// Perform a rollback of the given transaction.\n\tvoid rollback(TransactionStatus status);\n}", "des": "This is the central interface in Spring's imperative transaction infrastructure."}
{"index": 6310, "repo": "spring-tx-6.0.11", "code": "public enum Propagation extends Enum<Propagation> {\n\tint value();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Propagation valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Propagation[] values();\n}", "des": "Enumeration that represents transaction propagation behaviors for use with the Transactional annotation, corresponding to the TransactionDefinition interface."}
{"index": 6311, "repo": "spring-tx-6.0.11", "code": "public interface ResourceHolder {\n\t// Determine whether this holder is considered as 'void', i.e.\n\tboolean isVoid();\n\t// Reset the transactional state of this holder.\n\tvoid reset();\n\t// Notify this holder that it has been unbound from transaction synchronization.\n\tvoid unbound();\n}", "des": "Generic interface to be implemented by resource holders."}
{"index": 6312, "repo": "spring-tx-6.0.11", "code": "public class RollbackRuleAttribute extends Object implements Serializable {\n\tboolean equals(Object other);\n\t// Return the depth of the superclass matching, with the following semantics.\n\tint getDepth(Throwable exception);\n\t// Get the configured exception name pattern that this rule uses for matching.\n\tString getExceptionName();\n}", "des": "Rule determining whether a given exception should cause a rollback."}
{"index": 6313, "repo": "spring-tx-6.0.11", "code": "public interface SavepointManager {\n\t// Create a new savepoint.\n\tObject createSavepoint();\n\t// Explicitly release the given savepoint.\n\tvoid releaseSavepoint(Object savepoint);\n\t// Roll back to the given savepoint.\n\tvoid rollbackToSavepoint(Object savepoint);\n}", "des": "Interface that specifies an API to programmatically manage transaction savepoints in a generic fashion."}
{"index": 6314, "repo": "spring-tx-6.0.11", "code": "public class SimpleTransactionFactory extends Object implements TransactionFactory {\n\t// Create an active Transaction object based on the given name and timeout.\n\tTransaction createTransaction(String name, int timeout);\n\t// Determine whether the underlying transaction manager supports XA transactions managed by a resource adapter (i.e.\n\tboolean supportsResourceAdapterManagedTransactions();\n}", "des": "Default implementation of the TransactionFactory strategy interface, simply wrapping a standard JTA TransactionManager."}
{"index": 6315, "repo": "spring-tx-6.0.11", "code": "public interface SmartTransactionObject extends Flushable {\n\t// Flush the underlying sessions to the datastore, if applicable: for example, all affected Hibernate/JPA sessions.\n\tvoid flush();\n\t// Return whether the transaction is internally marked as rollback-only.\n\tboolean isRollbackOnly();\n}", "des": "Interface to be implemented by transaction objects that are able to return an internal rollback-only marker, typically from another transaction that has participated and marked it as rollback-only."}
{"index": 6316, "repo": "spring-tx-6.0.11", "code": "public class SpringJtaSynchronizationAdapter extends Object implements Synchronization {\n\t// JTA afterCompletion callback: invoked after commit/rollback.\n\tvoid afterCompletion(int status);\n\t// JTA beforeCompletion callback: just invoked before commit.\n\tvoid beforeCompletion();\n}", "des": "Adapter that implements the JTA Synchronization interface delegating to an underlying Spring TransactionSynchronization."}
{"index": 6317, "repo": "spring-tx-6.0.11", "code": "public static interface TransactionalApplicationListener.SynchronizationCallback {\n\t// Called after a transactional event listener invocation.\n\tdefault void postProcessEvent(org.springframework.context.ApplicationEvent event, Throwable ex);\n\t// Called before transactional event listener invocation.\n\tdefault void preProcessEvent(org.springframework.context.ApplicationEvent event);\n}", "des": "Callback to be invoked on synchronization-driven event processing, wrapping the target listener invocation (TransactionalApplicationListener.processEvent(E))."}
{"index": 6318, "repo": "spring-tx-6.0.11", "code": "public interface TransactionAnnotationParser {\n\t// Determine whether the given class is a candidate for transaction attributes in the annotation format of this TransactionAnnotationParser.\n\tdefault boolean isCandidateClass(Class<?> targetClass);\n\t// Parse the transaction attribute for the given method or class, based on an annotation type understood by this parser.\n\tTransactionAttribute parseTransactionAnnotation(AnnotatedElement element);\n}", "des": "Strategy interface for parsing known transaction annotation types."}
{"index": 6319, "repo": "spring-tx-6.0.11", "code": "public interface TransactionAttribute extends TransactionDefinition {\n\t// Return labels associated with this transaction attribute.\n\tCollection<String> getLabels();\n\t// Return a qualifier value associated with this transaction attribute.\n\tString getQualifier();\n\t// Should we roll back on the given exception?\n\tboolean rollbackOn(Throwable ex);\n}", "des": "This interface adds a rollbackOn specification to TransactionDefinition."}
{"index": 6320, "repo": "spring-tx-6.0.11", "code": "public interface TransactionAttributeSource {\n\t// Return the transaction attribute for the given method, or null if the method is non-transactional.\n\tTransactionAttribute getTransactionAttribute(Method method, Class<?> targetClass);\n\t// Determine whether the given class is a candidate for transaction attributes in the metadata format of this TransactionAttributeSource.\n\tdefault boolean isCandidateClass(Class<?> targetClass);\n}", "des": "Strategy interface used by TransactionInterceptor for metadata retrieval."}
{"index": 6321, "repo": "spring-tx-6.0.11", "code": "public class TransactionAttributeSourceAdvisor extends org.springframework.aop.support.AbstractPointcutAdvisor {\n\torg.aopalliance.aop.Advice getAdvice();\n\torg.springframework.aop.Pointcut getPointcut();\n\t// Set the ClassFilter to use for this pointcut.\n\tvoid setClassFilter(org.springframework.aop.ClassFilter classFilter);\n\t// Set the transaction interceptor to use for this advisor.\n\tvoid setTransactionInterceptor(TransactionInterceptor interceptor);\n}", "des": "Advisor driven by a TransactionAttributeSource, used to include a TransactionInterceptor only for methods that are transactional."}
{"index": 6322, "repo": "spring-tx-6.0.11", "code": "public abstract class TransactionCallbackWithoutResult extends Object implements TransactionCallback<Object> {\n\t// Gets called by TransactionTemplate.execute(org.springframework.transaction.support.TransactionCallback<T>) within a transactional context.\n\tfinal Object doInTransaction(TransactionStatus status);\n\t// Gets called by TransactionTemplate.execute within a transactional context.\n\tprotected abstract void doInTransactionWithoutResult(TransactionStatus status);\n}", "des": "Simple convenience class for TransactionCallback implementation."}
{"index": 6323, "repo": "spring-tx-6.0.11", "code": "public interface TransactionFactory {\n\t// Create an active Transaction object based on the given name and timeout.\n\tTransaction createTransaction(String name, int timeout);\n\t// Determine whether the underlying transaction manager supports XA transactions managed by a resource adapter (i.e.\n\tboolean supportsResourceAdapterManagedTransactions();\n}", "des": "Strategy interface for creating JTA Transaction objects based on specified transactional characteristics."}
{"index": 6324, "repo": "spring-tx-6.0.11", "code": "public enum TransactionPhase extends Enum<TransactionPhase> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic TransactionPhase valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic TransactionPhase[] values();\n}", "des": "The phase in which a transactional event listener applies."}
{"index": 6325, "repo": "spring-tx-6.0.11", "code": "public interface TransactionStatus extends TransactionExecution, SavepointManager, Flushable {\n\t// Flush the underlying session to the datastore, if applicable: for example, all affected Hibernate/JPA sessions.\n\tvoid flush();\n\t// Return whether this transaction internally carries a savepoint, that is, has been created as nested transaction based on a savepoint.\n\tboolean hasSavepoint();\n}", "des": "Representation of the status of a transaction."}
{"index": 6326, "repo": "spring-boot-actuator-3.1.1", "code": "public abstract class AbstractDiscoveredEndpoint<O extends Operation> extends AbstractExposableEndpoint<O> implements DiscoveredEndpoint<O> {\n\tprotected void appendFields(org.springframework.core.style.ToStringCreator creator);\n\t// Return the source bean that was used to construct the DiscoveredEndpoint.\n\tObject getEndpointBean();\n\t// Return true if the endpoint was discovered by the specified discoverer.\n\tboolean wasDiscoveredBy(Class<? extends EndpointDiscoverer<?,?>> discoverer);\n}", "des": "Abstract base class for endpoints discovered by a EndpointDiscoverer."}
{"index": 6327, "repo": "spring-boot-actuator-3.1.1", "code": "public abstract class AbstractDiscoveredOperation extends Object implements Operation {\n\tprotected void appendFields(org.springframework.core.style.ToStringCreator creator);\n\tOperationMethod getOperationMethod();\n\t// Returns the type of the operation.\n\tOperationType getType();\n\t// Invoke the underlying operation using the given context.\n\tObject invoke(InvocationContext context);\n}", "des": "Abstract base class for endpoints operations discovered by a EndpointDiscoverer."}
{"index": 6328, "repo": "spring-boot-actuator-3.1.1", "code": "public abstract class AbstractExposableEndpoint<O extends Operation> extends Object implements ExposableEndpoint<O> {\n\t// Return the endpoint ID.\n\tEndpointId getEndpointId();\n\t// Returns the operations of the endpoint.\n\tCollection<O> getOperations();\n\t// Returns if the endpoint is enabled by default.\n\tboolean isEnableByDefault();\n}", "des": "Abstract base class for ExposableEndpoint implementations."}
{"index": 6329, "repo": "spring-boot-actuator-3.1.1", "code": "public abstract class AbstractHealthIndicator extends Object implements HealthIndicator {\n\t// Actual health check logic.\n\tprotected abstract void doHealthCheck(Health.Builder builder);\n\t// Return an indication of health.\n\tfinal Health health();\n}", "des": "Base HealthIndicator implementations that encapsulates creation of Health instance and error handling."}
{"index": 6330, "repo": "spring-boot-actuator-3.1.1", "code": "public abstract class AbstractReactiveHealthIndicator extends Object implements ReactiveHealthIndicator {\n\t// Actual health check logic.\n\tprotected abstract reactor.core.publisher.Mono<Health> doHealthCheck(Health.Builder builder);\n\t// Provide the indicator of health.\n\tfinal reactor.core.publisher.Mono<Health> health();\n}", "des": "Base ReactiveHealthIndicator implementations that encapsulates creation of Health instance and error handling."}
{"index": 6331, "repo": "spring-boot-actuator-3.1.1", "code": "public enum ApiVersion extends Enum<ApiVersion> implements Producible<ApiVersion> {\n\t// Mime type that can be produced.\n\torg.springframework.util.MimeType getProducedMimeType();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ApiVersion valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ApiVersion[] values();\n}", "des": "API versions supported for the actuator API."}
{"index": 6332, "repo": "spring-boot-actuator-3.1.1", "code": "public class AuditEvent extends Object implements Serializable {\n\t// Returns the event data.\n\tMap<String,Object> getData();\n\t// Returns the user principal responsible for the event or an empty String if the principal is not available.\n\tString getPrincipal();\n\t// Returns the date/time that the event was logged.\n\tInstant getTimestamp();\n\t// Returns the type of event.\n\tString getType();\n}", "des": "A value object representing an audit event: at a particular time, a particular user or agent carried out an action of a particular type."}
{"index": 6333, "repo": "spring-boot-actuator-3.1.1", "code": "public interface AuditEventRepository {\n\t// Log an event.\n\tvoid add(AuditEvent event);\n\t// Find audit events of specified type relating to the specified principal that occurred after the time provided.\n\tList<AuditEvent> find(String principal, Instant after, String type);\n}", "des": "Repository for AuditEvents."}
{"index": 6334, "repo": "spring-boot-actuator-3.1.1", "code": "public class AvailabilityStateHealthIndicator extends AbstractHealthIndicator {\n\t// Actual health check logic.\n\tprotected void doHealthCheck(Health.Builder builder);\n\t// Return the current availability state.\n\tprotected org.springframework.boot.availability.AvailabilityState getState(org.springframework.boot.availability.ApplicationAvailability applicationAvailability);\n}", "des": "A HealthIndicator that checks a specific AvailabilityState of the application."}
{"index": 6335, "repo": "spring-boot-actuator-3.1.1", "code": "public static interface AvailabilityStateHealthIndicator.StatusMappings<S extends org.springframework.boot.availability.AvailabilityState> {\n\t// Add a new status mapping .\n\tvoid add(S availabilityState, Status status);\n\t// Add the status that should be used if no explicit mapping is defined.\n\tdefault void addDefaultStatus(Status status);\n}", "des": "Callback used to add status mappings."}
{"index": 6336, "repo": "spring-boot-actuator-3.1.1", "code": "public class CacheMetricsRegistrar extends Object {\n\t// Attempt to bind the specified Cache to the registry.\n\tboolean bindCacheToRegistry(org.springframework.cache.Cache cache, io.micrometer.core.instrument.Tag... tags);\n\t// Return additional tags to be associated with the given Cache.\n\tprotected Iterable<io.micrometer.core.instrument.Tag> getAdditionalTags(org.springframework.cache.Cache cache);\n}", "des": "Register supported Cache to a MeterRegistry."}
{"index": 6337, "repo": "spring-boot-actuator-3.1.1", "code": "@Endpoint(id=\"caches\") public class CachesEndpoint extends Object {\n\t// Return a CachesEndpoint.CacheDescriptor for the specified cache.\n\tCachesEndpoint.CacheEntryDescriptor cache(String cache, String cacheManager);\n\t// Return a CachesEndpoint.CachesDescriptor of all available caches.\n\tCachesEndpoint.CachesDescriptor caches();\n\t// Clear the specific Cache.\n\tboolean clearCache(String cache, String cacheManager);\n\t// Clear all the available caches.\n\tvoid clearCaches();\n}", "des": "@Endpoint to expose available caches."}
{"index": 6338, "repo": "spring-boot-actuator-3.1.1", "code": "public class CachingOperationInvoker extends Object implements OperationInvoker {\n\t// Return the maximum time in milliseconds that a response can be cached.\n\tlong getTimeToLive();\n\t// Invoke the underlying operation using the given context.\n\tObject invoke(InvocationContext context);\n}", "des": "An OperationInvoker that caches the response of an operation with a configurable time to live."}
{"index": 6339, "repo": "spring-boot-actuator-3.1.1", "code": "public interface CompositeHealthContributor extends HealthContributor, NamedContributors<HealthContributor> {\n\t// Factory method that will create a CompositeHealthContributor from the specified map.\n\tstatic CompositeHealthContributor fromMap(Map<String,? extends HealthContributor> map);\n\t// Factory method that will create a CompositeHealthContributor from the specified map.\n\tstatic <V> CompositeHealthContributor fromMap(Map<String,V> map, Function<V,? extends HealthContributor> valueAdapter);\n}", "des": "A HealthContributor that is composed of other HealthContributor instances."}
{"index": 6340, "repo": "spring-boot-actuator-3.1.1", "code": "public interface ContributorRegistry<C> extends NamedContributors<C> {\n\t// Register a contributor with the given name.\n\tvoid registerContributor(String name, C contributor);\n\t// Unregister a previously registered contributor.\n\tC unregisterContributor(String name);\n}", "des": "A mutable registry of health endpoint contributors (either HealthContributor or ReactiveHealthContributor)."}
{"index": 6341, "repo": "spring-boot-actuator-3.1.1", "code": "public class DataSourceHealthIndicator extends AbstractHealthIndicator implements org.springframework.beans.factory.InitializingBean {\n\tvoid afterPropertiesSet();\n\t// Actual health check logic.\n\tprotected void doHealthCheck(Health.Builder builder);\n\t// Return the validation query or null.\n\tString getQuery();\n\t// Set the DataSource to use.\n\tvoid setDataSource(DataSource dataSource);\n\t// Set a specific validation query to use to validate a connection.\n\tvoid setQuery(String query);\n}", "des": "HealthIndicator that tests the status of a DataSource and optionally runs a test query."}
{"index": 6342, "repo": "spring-boot-actuator-3.1.1", "code": "public class DefaultHealthContributorRegistry extends Object implements HealthContributorRegistry {\n\t// Return the contributor with the given name.\n\tHealthContributor getContributor(String name);\n\tIterator<NamedContributor<HealthContributor>> iterator();\n\t// Register a contributor with the given name.\n\tvoid registerContributor(String name, HealthContributor contributor);\n\t// Unregister a previously registered contributor.\n\tHealthContributor unregisterContributor(String name);\n}", "des": "Default HealthContributorRegistry implementation."}
{"index": 6343, "repo": "spring-boot-actuator-3.1.1", "code": "public interface DiscoveredEndpoint<O extends Operation> extends ExposableEndpoint<O> {\n\t// Return the source bean that was used to construct the DiscoveredEndpoint.\n\tObject getEndpointBean();\n\t// Return true if the endpoint was discovered by the specified discoverer.\n\tboolean wasDiscoveredBy(Class<? extends EndpointDiscoverer<?,?>> discoverer);\n}", "des": "An endpoint discovered by an EndpointDiscoverer."}
{"index": 6344, "repo": "spring-boot-actuator-3.1.1", "code": "public class EndpointMediaTypes extends Object {\n\t// Returns the media types consumed by an endpoint.\n\tList<String> getConsumed();\n\t// Returns the media types produced by an endpoint.\n\tList<String> getProduced();\n}", "des": "Media types that are, by default, produced and consumed by an endpoint."}
{"index": 6345, "repo": "spring-boot-actuator-3.1.1", "code": "public interface ExposableEndpoint<O extends Operation> {\n\t// Return the endpoint ID.\n\tEndpointId getEndpointId();\n\t// Returns the operations of the endpoint.\n\tCollection<O> getOperations();\n\t// Returns if the endpoint is enabled by default.\n\tboolean isEnableByDefault();\n}", "des": "Information describing an endpoint that can be exposed in some technology specific way."}
{"index": 6346, "repo": "spring-boot-actuator-3.1.1", "code": "public class FilterRegistrationMappingDescription extends RegistrationMappingDescription<jakarta.servlet.FilterRegistration> {\n\t// Returns the servlet name mappings for the registered filter.\n\tCollection<String> getServletNameMappings();\n\t// Returns the URL pattern mappings for the registered filter.\n\tCollection<String> getUrlPatternMappings();\n}", "des": "A RegistrationMappingDescription derived from a FilterRegistration."}
{"index": 6347, "repo": "spring-boot-actuator-3.1.1", "code": "@FunctionalInterface public interface HealthIndicator extends HealthContributor {\n\t// Return an indication of health.\n\tdefault Health getHealth(boolean includeDetails);\n\t// Return an indication of health.\n\tHealth health();\n}", "des": "Strategy interface used to contribute Health to the results returned from the HealthEndpoint."}
{"index": 6348, "repo": "spring-boot-actuator-3.1.1", "code": "public static final class HttpExchange.Request extends Object {\n\t// Return the request headers.\n\tMap<String,List<String>> getHeaders();\n\t// Return the HTTP method requested.\n\tString getMethod();\n\t// Return the remote address that made the request.\n\tString getRemoteAddress();\n\t// Return the URI requested.\n\tURI getUri();\n}", "des": "The request that started the exchange."}
{"index": 6349, "repo": "spring-boot-actuator-3.1.1", "code": "public static final class HttpExchange.Response extends Object {\n\t// Return the response headers.\n\tMap<String,List<String>> getHeaders();\n\t// Return the status code of the response.\n\tint getStatus();\n}", "des": "The response that finished the exchange."}
{"index": 6350, "repo": "spring-boot-actuator-3.1.1", "code": "public interface HttpExchangeRepository {\n\t// Adds an HttpExchange instance to the repository.\n\tvoid add(HttpExchange httpExchange);\n\t// Find all HttpExchange instances contained in the repository.\n\tList<HttpExchange> findAll();\n}", "des": "A repository for HttpExchange instances."}
{"index": 6351, "repo": "spring-boot-actuator-3.1.1", "code": "public enum Include extends Enum<Include> {\n\t// Return the default Include.\n\tstatic Set<Include> defaultIncludes();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Include valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Include[] values();\n}", "des": "Include options for HTTP exchanges."}
{"index": 6352, "repo": "spring-boot-actuator-3.1.1", "code": "public static class Info.Builder extends Object {\n\t// Create a new Info instance based on the state of this builder.\n\tInfo build();\n\t// Record detail using given key and value.\n\tInfo.Builder withDetail(String key, Object value);\n\t// Record several details.\n\tInfo.Builder withDetails(Map<String,Object> details);\n}", "des": "Builder for creating immutable Info instances."}
{"index": 6353, "repo": "spring-boot-actuator-3.1.1", "code": "public static enum InfoPropertiesInfoContributor.Mode extends Enum<InfoPropertiesInfoContributor.Mode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic InfoPropertiesInfoContributor.Mode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic InfoPropertiesInfoContributor.Mode[] values();\n}", "des": "Defines how properties should be exposed."}
{"index": 6354, "repo": "spring-boot-actuator-3.1.1", "code": "public class InMemoryAuditEventRepository extends Object implements AuditEventRepository {\n\t// Log an event.\n\tvoid add(AuditEvent event);\n\t// Find audit events of specified type relating to the specified principal that occurred after the time provided.\n\tList<AuditEvent> find(String principal, Instant after, String type);\n\t// Set the capacity of this event repository.\n\tvoid setCapacity(int capacity);\n}", "des": "In-memory AuditEventRepository implementation."}
{"index": 6355, "repo": "spring-boot-actuator-3.1.1", "code": "public class InMemoryHttpExchangeRepository extends Object implements HttpExchangeRepository {\n\t// Adds an HttpExchange instance to the repository.\n\tvoid add(HttpExchange exchange);\n\t// Find all HttpExchange instances contained in the repository.\n\tList<HttpExchange> findAll();\n\t// Set the capacity of the in-memory repository.\n\tvoid setCapacity(int capacity);\n\t// Flag to say that the repository lists exchanges in reverse order.\n\tvoid setReverse(boolean reverse);\n}", "des": "In-memory implementation of HttpExchangeRepository."}
{"index": 6356, "repo": "spring-boot-actuator-3.1.1", "code": "public class InvocationContext extends Object {\n\t// Returns whether the context is capable of resolving an argument of the given type.\n\tboolean canResolve(Class<?> type);\n\t// Return the invocation arguments.\n\tMap<String,Object> getArguments();\n\t// Resolves an argument with the given argumentType.\n\t<T> T resolveArgument(Class<T> argumentType);\n}", "des": "The context for the invocation of an operation."}
{"index": 6357, "repo": "spring-boot-actuator-3.1.1", "code": "public class JacksonJmxOperationResponseMapper extends Object implements JmxOperationResponseMapper {\n\t// Map the operation's response so that it can be consumed by a JMX compliant client.\n\tObject mapResponse(Object response);\n\t// Map the response type to its JMX compliant counterpart.\n\tClass<?> mapResponseType(Class<?> responseType);\n}", "des": "JmxOperationResponseMapper that delegates to a Jackson ObjectMapper to return a JSON response."}
{"index": 6358, "repo": "spring-boot-actuator-3.1.1", "code": "public interface JmxOperation extends Operation {\n\t// Returns the description of the operation.\n\tString getDescription();\n\t// Returns the name of the operation.\n\tString getName();\n\t// Returns the type of the output of the operation.\n\tClass<?> getOutputType();\n\t// Returns the parameters the operation expects in the order that they should be provided.\n\tList<JmxOperationParameter> getParameters();\n}", "des": "An operation on a JMX endpoint."}
{"index": 6359, "repo": "spring-boot-actuator-3.1.1", "code": "public interface JmxOperationParameter {\n\t// Return the description of the parameter or null if none is available.\n\tString getDescription();\n\t// Return the name of the operation parameter.\n\tString getName();\n\t// Return the type of the operation parameter.\n\tClass<?> getType();\n}", "des": "Describes the parameters of an operation on a JMX endpoint."}
{"index": 6360, "repo": "spring-boot-actuator-3.1.1", "code": "public interface JmxOperationResponseMapper {\n\t// Map the operation's response so that it can be consumed by a JMX compliant client.\n\tObject mapResponse(Object response);\n\t// Map the response type to its JMX compliant counterpart.\n\tClass<?> mapResponseType(Class<?> responseType);\n}", "des": "Maps an operation's response to a JMX-friendly form."}
{"index": 6361, "repo": "spring-boot-actuator-3.1.1", "code": "public class Link extends Object {\n\t// Returns the href of the link.\n\tString getHref();\n\t// Returns whether the href is templated.\n\tboolean isTemplated();\n}", "des": "Details for a link in a HAL-formatted response."}
{"index": 6362, "repo": "spring-boot-actuator-3.1.1", "code": "public interface MappingDescriptionProvider {\n\t// Produce the descriptions of the mappings identified by this provider in the given context.\n\tObject describeMappings(org.springframework.context.ApplicationContext context);\n\t// Returns the name of the mappings described by this provider.\n\tString getMappingName();\n}", "des": "A MappingDescriptionProvider provides a List of mapping descriptions through implementation-specific introspection of an application context."}
{"index": 6363, "repo": "spring-boot-actuator-3.1.1", "code": "public interface NamedContributor<C> {\n\t// Returns the contributor instance.\n\tC getContributor();\n\t// Returns the name of the contributor.\n\tString getName();\n\tstatic <C> NamedContributor<C> of(String name, C contributor);\n}", "des": "A single named health endpoint contributors (either HealthContributor or ReactiveHealthContributor)."}
{"index": 6364, "repo": "spring-boot-actuator-3.1.1", "code": "public interface NamedContributors<C> extends Iterable<NamedContributor<C>> {\n\t// Return the contributor with the given name.\n\tC getContributor(String name);\n\t// Return a stream of the named contributors.\n\tdefault Stream<NamedContributor<C>> stream();\n}", "des": "A collection of named health endpoint contributors (either HealthContributor or ReactiveHealthContributor)."}
{"index": 6365, "repo": "spring-boot-actuator-3.1.1", "code": "public interface Operation {\n\t// Returns the type of the operation.\n\tOperationType getType();\n\t// Invoke the underlying operation using the given context.\n\tObject invoke(InvocationContext context);\n}", "des": "An operation on an endpoint."}
{"index": 6366, "repo": "spring-boot-actuator-3.1.1", "code": "public interface OperationArgumentResolver {\n\t// Return whether an argument of the given type can be resolved.\n\tboolean canResolve(Class<?> type);\n\t// Factory method that creates an OperationArgumentResolver for a specific type using a Supplier.\n\tstatic <T> OperationArgumentResolver of(Class<T> type, Supplier<? extends T> supplier);\n\t// Resolves an argument of the given type.\n\t<T> T resolve(Class<T> type);\n}", "des": "Resolver for an argument of an Operation."}
{"index": 6367, "repo": "spring-boot-actuator-3.1.1", "code": "public class OperationMethod extends Object {\n\t// Return the source Java method.\n\tMethod getMethod();\n\t// Return the operation type.\n\tOperationType getOperationType();\n\t// Return the operation parameters.\n\tOperationParameters getParameters();\n}", "des": "Information describing an operation method on an endpoint method."}
{"index": 6368, "repo": "spring-boot-actuator-3.1.1", "code": "public interface OperationParameter {\n\t// Returns this element's annotation for the specified type if such an annotation is present, else null.\n\t<T extends Annotation>T getAnnotation(Class<T> annotation);\n\t// Returns the parameter name.\n\tString getName();\n\t// Returns the parameter type.\n\tClass<?> getType();\n\t// Return if the parameter is mandatory (does not accept null values).\n\tboolean isMandatory();\n}", "des": "A single operation parameter."}
{"index": 6369, "repo": "spring-boot-actuator-3.1.1", "code": "public interface OperationParameters extends Iterable<OperationParameter> {\n\t// Return the parameter at the specified index.\n\tOperationParameter get(int index);\n\t// Return the total number of parameters.\n\tint getParameterCount();\n\t// Return if any of the contained parameters are mandatory.\n\tdefault boolean hasMandatoryParameter();\n\t// Return true if there is at least one parameter.\n\tdefault boolean hasParameters();\n\t// Return a stream of the contained parameters.\n\tStream<OperationParameter> stream();\n}", "des": "A collection of operation parameters."}
{"index": 6370, "repo": "spring-boot-actuator-3.1.1", "code": "public enum OperationType extends Enum<OperationType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic OperationType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic OperationType[] values();\n}", "des": "An enumeration of the different types of operation supported by an endpoint."}
{"index": 6371, "repo": "spring-boot-actuator-3.1.1", "code": "public enum Outcome extends Enum<Outcome> {\n\t// Returns the Outcome as a Tag named outcome.\n\tio.micrometer.core.instrument.Tag asTag();\n\t// Return the Outcome for the given HTTP status code.\n\tstatic Outcome forStatus(int status);\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Outcome valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Outcome[] values();\n}", "des": "The outcome of an HTTP request."}
{"index": 6372, "repo": "spring-boot-actuator-3.1.1", "code": "public final class ParameterMappingException extends InvalidEndpointRequestException {\n\t// Return the parameter being mapped.\n\tOperationParameter getParameter();\n\t// Return the value being mapped.\n\tObject getValue();\n}", "des": "A ParameterMappingException is thrown when a failure occurs during operation parameter mapping."}
{"index": 6373, "repo": "spring-boot-actuator-3.1.1", "code": "@FunctionalInterface public interface PathMapper {\n\t// Resolve the root path for the specified endpointId from the given path mappers.\n\tstatic String getRootPath(List<PathMapper> pathMappers, EndpointId endpointId);\n\t// Resolve the root path for the specified endpointId.\n\tString getRootPath(EndpointId endpointId);\n}", "des": "Strategy interface used to provide a mapping between an endpoint ID and the root path where it will be exposed."}
{"index": 6374, "repo": "spring-boot-actuator-3.1.1", "code": "public interface Producible<E extends Enum<E> & Producible<E>> {\n\t// Mime type that can be produced.\n\torg.springframework.util.MimeType getProducedMimeType();\n\t// Return if this enum value should be used as the default value when an accept header of */* is provided, or if the Accept header is missing.\n\tdefault boolean isDefault();\n}", "des": "Interface that can be implemented by any Enum that represents a finite set of producible mime-types."}
{"index": 6375, "repo": "spring-boot-actuator-3.1.1", "code": "public class ProducibleOperationArgumentResolver extends Object implements OperationArgumentResolver {\n\t// Return whether an argument of the given type can be resolved.\n\tboolean canResolve(Class<?> type);\n\t// Resolves an argument of the given type.\n\t<T> T resolve(Class<T> type);\n}", "des": "An OperationArgumentResolver for producible enums."}
{"index": 6376, "repo": "spring-boot-actuator-3.1.1", "code": "public static enum PrometheusPushGatewayManager.ShutdownOperation extends Enum<PrometheusPushGatewayManager.ShutdownOperation> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic PrometheusPushGatewayManager.ShutdownOperation valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic PrometheusPushGatewayManager.ShutdownOperation[] values();\n}", "des": "The operation that should be performed on shutdown."}
{"index": 6377, "repo": "spring-boot-actuator-3.1.1", "code": "public static final class QuartzEndpoint.CalendarIntervalTriggerDescriptor extends QuartzEndpoint.TriggerDescriptor {\n\t// Append trigger-implementation specific details to the specified content.\n\tprotected void appendDetails(Map<String,Object> content);\n\t// Append trigger-implementation specific summary items to the specified content.\n\tprotected void appendSummary(Map<String,Object> content);\n}", "des": "Description of a CalendarIntervalTrigger."}
{"index": 6378, "repo": "spring-boot-actuator-3.1.1", "code": "public static final class QuartzEndpoint.CronTriggerDescriptor extends QuartzEndpoint.TriggerDescriptor {\n\t// Append trigger-implementation specific details to the specified content.\n\tprotected void appendDetails(Map<String,Object> content);\n\t// Append trigger-implementation specific summary items to the specified content.\n\tprotected void appendSummary(Map<String,Object> content);\n}", "des": "Description of a CronTrigger."}
{"index": 6379, "repo": "spring-boot-actuator-3.1.1", "code": "public static final class QuartzEndpoint.CustomTriggerDescriptor extends QuartzEndpoint.TriggerDescriptor {\n\t// Append trigger-implementation specific details to the specified content.\n\tprotected void appendDetails(Map<String,Object> content);\n\t// Append trigger-implementation specific summary items to the specified content.\n\tprotected void appendSummary(Map<String,Object> content);\n}", "des": "Description of a custom Trigger."}
{"index": 6380, "repo": "spring-boot-actuator-3.1.1", "code": "public static final class QuartzEndpoint.DailyTimeIntervalTriggerDescriptor extends QuartzEndpoint.TriggerDescriptor {\n\t// Append trigger-implementation specific details to the specified content.\n\tprotected void appendDetails(Map<String,Object> content);\n\t// Append trigger-implementation specific summary items to the specified content.\n\tprotected void appendSummary(Map<String,Object> content);\n}", "des": "Description of a DailyTimeIntervalTrigger."}
{"index": 6381, "repo": "spring-boot-actuator-3.1.1", "code": "public static final class QuartzEndpoint.SimpleTriggerDescriptor extends QuartzEndpoint.TriggerDescriptor {\n\t// Append trigger-implementation specific details to the specified content.\n\tprotected void appendDetails(Map<String,Object> content);\n\t// Append trigger-implementation specific summary items to the specified content.\n\tprotected void appendSummary(Map<String,Object> content);\n}", "des": "Description of a SimpleTrigger."}
{"index": 6382, "repo": "spring-boot-actuator-3.1.1", "code": "@FunctionalInterface public interface ReactiveHealthIndicator extends ReactiveHealthContributor {\n\t// Provide the indicator of health.\n\tdefault reactor.core.publisher.Mono<Health> getHealth(boolean includeDetails);\n\t// Provide the indicator of health.\n\treactor.core.publisher.Mono<Health> health();\n}", "des": "Strategy interface used to contribute Health to the results returned from the reactive variant of the HealthEndpoint."}
{"index": 6383, "repo": "spring-boot-actuator-3.1.1", "code": "public interface RecordableHttpRequest {\n\t// Returns a modifiable copy of the headers of the request.\n\tMap<String,List<String>> getHeaders();\n\t// Returns the method (GET, POST, etc.) of the request.\n\tString getMethod();\n\t// Returns the remote address from which the request was sent, if available.\n\tString getRemoteAddress();\n\t// Returns the URI of the request.\n\tURI getUri();\n}", "des": "The recordable parts of an HTTP request used when creating an HttpExchange."}
{"index": 6384, "repo": "spring-boot-actuator-3.1.1", "code": "public interface RecordableHttpResponse {\n\t// Returns a modifiable copy of the headers of the response.\n\tMap<String,List<String>> getHeaders();\n\t// The status of the response.\n\tint getStatus();\n}", "des": "The recordable parts of an HTTP response used when creating an HttpExchange."}
{"index": 6385, "repo": "spring-boot-actuator-3.1.1", "code": "public class RegistrationMappingDescription<T extends jakarta.servlet.Registration> extends Object {\n\t// Returns the class name of the registered Filter or Servlet.\n\tString getClassName();\n\t// Returns the name of the registered Filter or Servlet.\n\tString getName();\n\t// Returns the registration that is being described.\n\tprotected final T getRegistration();\n}", "des": "A mapping description derived from a Registration."}
{"index": 6386, "repo": "spring-boot-actuator-3.1.1", "code": "public interface SecurityContext {\n\t// Return the currently authenticated Principal or null.\n\tPrincipal getPrincipal();\n\t// Returns true if the currently authenticated user is in the given role, or false otherwise.\n\tboolean isUserInRole(String role);\n}", "des": "Security context in which an endpoint is being invoked."}
{"index": 6387, "repo": "spring-boot-actuator-3.1.1", "code": "public static enum Selector.Match extends Enum<Selector.Match> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Selector.Match valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Selector.Match[] values();\n}", "des": "Match types that can be used with the @Selector."}
{"index": 6388, "repo": "spring-boot-actuator-3.1.1", "code": "public enum Show extends Enum<Show> {\n\t// Return if data should be shown when no SecurityContext is available.\n\tboolean isShown(boolean unauthorizedResult);\n\t// Return if data should be shown.\n\tboolean isShown(SecurityContext securityContext, Collection<String> roles);\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Show valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Show[] values();\n}", "des": "Options for showing data in endpoint responses."}
{"index": 6389, "repo": "spring-boot-actuator-3.1.1", "code": "public final class Status extends Object {\n\tboolean equals(Object obj);\n\t// Return the code for this status.\n\tString getCode();\n\t// Return the description of this status.\n\tString getDescription();\n}", "des": "Value object to express state of a component or subsystem."}
{"index": 6390, "repo": "spring-boot-actuator-3.1.1", "code": "@FunctionalInterface public interface StatusAggregator {\n\t// Return the aggregate status for the given set of statuses.\n\tStatus getAggregateStatus(Set<Status> statuses);\n\t// Return the aggregate status for the given set of statuses.\n\tdefault Status getAggregateStatus(Status... statuses);\n\t// Return StatusAggregator instance using default ordering rules.\n\tstatic StatusAggregator getDefault();\n}", "des": "Strategy used to aggregate Status instances."}
{"index": 6391, "repo": "spring-boot-actuator-3.1.1", "code": "public enum TextOutputFormat extends Enum<TextOutputFormat> implements Producible<TextOutputFormat> {\n\t// Mime type that can be produced.\n\torg.springframework.util.MimeType getProducedMimeType();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic TextOutputFormat valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic TextOutputFormat[] values();\n}", "des": "A Producible enum for supported Prometheus TextFormat."}
{"index": 6392, "repo": "spring-boot-actuator-3.1.1", "code": "public enum WebEndpointHttpMethod extends Enum<WebEndpointHttpMethod> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic WebEndpointHttpMethod valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic WebEndpointHttpMethod[] values();\n}", "des": "An enumeration of HTTP methods supported by web endpoint operations."}
{"index": 6393, "repo": "spring-boot-actuator-3.1.1", "code": "public final class WebEndpointResponse<T> extends Object {\n\t// Returns the body for the response.\n\tT getBody();\n\t// Returns the content type of the response.\n\torg.springframework.util.MimeType getContentType();\n\t// Returns the status for the response.\n\tint getStatus();\n}", "des": "A WebEndpointResponse can be returned by an operation on a @EndpointWebExtension to provide additional, web-specific information such as the HTTP status code."}
{"index": 6394, "repo": "spring-boot-actuator-3.1.1", "code": "public interface WebOperation extends Operation {\n\t// Returns the ID of the operation that uniquely identifies it within its endpoint.\n\tString getId();\n\t// Returns the predicate for requests that can be handled by this operation.\n\tWebOperationRequestPredicate getRequestPredicate();\n\t// Returns if the underlying operation is blocking.\n\tboolean isBlocking();\n}", "des": "An operation on a web endpoint."}
{"index": 6395, "repo": "spring-data-redis-3.1.2", "code": "public enum Aggregate extends Enum<Aggregate> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Aggregate valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Aggregate[] values();\n}", "des": "Sort aggregation operations."}
{"index": 6396, "repo": "spring-data-redis-3.1.2", "code": "public abstract class BatchStrategies extends Object {\n\t// A BatchStrategy using a single KEYS and DEL command to remove all matching keys.\n\tstatic BatchStrategy keys();\n\t// A BatchStrategy using a SCAN cursors and potentially multiple DEL commands to remove all matching keys.\n\tstatic BatchStrategy scan(int batchSize);\n}", "des": "A collection of predefined BatchStrategy implementations using KEYS or SCAN command."}
{"index": 6397, "repo": "spring-data-redis-3.1.2", "code": "public class BeanUtilsHashMapper<T> extends Object implements HashMapper<T,String,String> {\n\t// Convert a hash (map) to an object.\n\tT fromHash(Map<String,String> hash);\n\t// Convert an object to a map that can be used with Redis hashes.\n\tMap<String,String> toHash(T object);\n}", "des": "HashMapper based on Apache Commons BeanUtils project."}
{"index": 6398, "repo": "spring-data-redis-3.1.2", "code": "public static class BitFieldSubCommands.BitFieldGet extends BitFieldSubCommands.AbstractBitFieldSubCommand {\n\t// Creates a new BitFieldSubCommands.BitFieldGet.\n\tstatic BitFieldSubCommands.BitFieldGet create(BitFieldSubCommands.BitFieldType type, BitFieldSubCommands.Offset offset);\n\t// The actual sub command\n\tString getCommand();\n}", "des": "The GET sub command used with BitFieldSubCommands."}
{"index": 6399, "repo": "spring-data-redis-3.1.2", "code": "public static class BitFieldSubCommands.BitFieldSet extends BitFieldSubCommands.AbstractBitFieldSubCommand {\n\t// Creates a new BitFieldSubCommands.BitFieldSet.\n\tstatic BitFieldSubCommands.BitFieldSet create(BitFieldSubCommands.BitFieldType type, BitFieldSubCommands.Offset offset, long value);\n\tboolean equals(Object o);\n\t// The actual sub command\n\tString getCommand();\n\t// Get the value to set.\n\tlong getValue();\n}", "des": "The SET sub command used with BitFieldSubCommands."}
{"index": 6400, "repo": "spring-data-redis-3.1.2", "code": "public static interface BitFieldSubCommands.BitFieldSubCommand {\n\t// The actual sub command\n\tString getCommand();\n\t// The bit offset to apply for the command.\n\tBitFieldSubCommands.Offset getOffset();\n\t// The BitFieldSubCommands.BitFieldType to apply for the command.\n\tBitFieldSubCommands.BitFieldType getType();\n}", "des": "Sub command to be used as part of BitFieldSubCommands."}
{"index": 6401, "repo": "spring-data-redis-3.1.2", "code": "public static class BitFieldSubCommands.BitFieldType extends Object {\n\t// Get the Redis Command representation.\n\tString asString();\n\tboolean equals(Object o);\n\t// Get the actual bits of the type.\n\tint getBits();\n\tboolean isSigned();\n\t// Create new signed BitFieldSubCommands.BitFieldType.\n\tstatic BitFieldSubCommands.BitFieldType signed(int bits);\n\t// Create new unsigned BitFieldSubCommands.BitFieldType.\n\tstatic BitFieldSubCommands.BitFieldType unsigned(int bits);\n}", "des": "The actual Redis bitfield type representation for signed and unsigned integers used with BitFieldSubCommands.BitFieldSubCommand."}
{"index": 6402, "repo": "spring-data-redis-3.1.2", "code": "public static class BitFieldSubCommands.Offset extends Object {\n\tString asString();\n\tboolean equals(Object o);\n\tlong getValue();\n\tboolean isZeroBased();\n\t// Creates new type based offset.\n\tBitFieldSubCommands.Offset multipliedByTypeLength();\n\t// Creates new zero based offset.\n\tstatic BitFieldSubCommands.Offset offset(long offset);\n}", "des": "Offset used inside a BitFieldSubCommands.BitFieldSubCommand."}
{"index": 6403, "repo": "spring-data-redis-3.1.2", "code": "public class BoundingBox extends Object implements Shape {\n\tboolean equals(Object o);\n\t// Returns the height of this bounding box.\n\tDistance getHeight();\n\t// Returns the width of this bounding box.\n\tDistance getWidth();\n}", "des": "Represents a geospatial bounding box defined by width and height."}
{"index": 6404, "repo": "spring-data-redis-3.1.2", "code": "@FunctionalInterface public interface CacheKeyPrefix {\n\t// Compute the prefix for the actual cache key stored in Redis.\n\tString compute(String cacheName);\n\t// Creates a CacheKeyPrefix scheme that prefixes cache keys with the given prefix.\n\tstatic CacheKeyPrefix prefixed(String prefix);\n\t// Creates a default CacheKeyPrefix scheme that prefixes cache keys with the name of the cache followed by double colons.\n\tstatic CacheKeyPrefix simple();\n}", "des": "CacheKeyPrefix is a callback hook for creating custom prefixes prepended to the actual key stored in Redis."}
{"index": 6405, "repo": "spring-data-redis-3.1.2", "code": "public class ChannelTopic extends Object implements Topic {\n\tboolean equals(Object o);\n\t// Returns the topic (as a String).\n\tString getTopic();\n\t// Create a new ChannelTopic for channel subscriptions.\n\tstatic ChannelTopic of(String name);\n}", "des": "Channel topic implementation (maps to a Redis channel)."}
{"index": 6406, "repo": "spring-data-redis-3.1.2", "code": "public static class ClusterCommandExecutor.MultiNodeResult<T> extends Object {\n\tT getFirstNonNullNotEmptyOrDefault(T returnValue);\n\tList<ClusterCommandExecutor.NodeResult<T>> getResults();\n\t// Get List of all individual ClusterCommandExecutor.NodeResult.value.\n\tList<T> resultsAsList();\n\t// Get List of all individual ClusterCommandExecutor.NodeResult.value.\n\tList<T> resultsAsListSortBy(byte[]... keys);\n}", "des": "ClusterCommandExecutor.MultiNodeResult holds all ClusterCommandExecutor.NodeResult of a command executed on multiple RedisClusterNode."}
{"index": 6407, "repo": "spring-data-redis-3.1.2", "code": "public static class ClusterCommandExecutor.NodeResult<T> extends Object {\n\tbyte[] getKey();\n\t// Get the RedisClusterNode the command was executed on.\n\tRedisClusterNode getNode();\n\t// Get the actual value of the command execution.\n\tT getValue();\n\t// Apply the mapper function to the value and return the mapped value.\n\t<U> U mapValue(Function<? super T,? extends U> mapper);\n}", "des": "ClusterCommandExecutor.NodeResult encapsulates the actual value returned by a ClusterCommandExecutor.ClusterCommandCallback on a given RedisClusterNode."}
{"index": 6408, "repo": "spring-data-redis-3.1.2", "code": "public interface ClusterNodeResourceProvider {\n\t// Get the client resource for the given node.\n\t<S> S getResourceForSpecificNode(RedisClusterNode node);\n\t// Return the resource object for the given node.\n\tvoid returnResourceForSpecificNode(RedisClusterNode node, Object resource);\n}", "des": "ClusterNodeResourceProvider provides access to low level client api to directly execute operations against a Redis instance."}
{"index": 6409, "repo": "spring-data-redis-3.1.2", "code": "public class CompositeIndexResolver extends Object implements IndexResolver {\n\t// Resolves all indexes for given type information / value combination.\n\tSet<IndexedData> resolveIndexesFor(String keyspace, String path, TypeInformation<?> typeInformation, Object value);\n\t// Resolves all indexes for given type information / value combination.\n\tSet<IndexedData> resolveIndexesFor(TypeInformation<?> typeInformation, Object value);\n}", "des": "Composite IndexResolver implementation that iterates over a given collection of delegate IndexResolver instances."}
{"index": 6410, "repo": "spring-data-redis-3.1.2", "code": "public enum DataType extends Enum<DataType> {\n\t// Returns the code associated with the current enum.\n\tString code();\n\t// Utility method for converting an enum code to an actual enum.\n\tstatic DataType fromCode(String code);\n\t// Returns the enum constant of this class with the specified name.\n\tstatic DataType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic DataType[] values();\n}", "des": "Enumeration of the Redis data types."}
{"index": 6411, "repo": "spring-data-redis-3.1.2", "code": "public class DecoratingStringHashMapper<T> extends Object implements HashMapper<T,String,String> {\n\t// Convert a hash (map) to an object.\n\tT fromHash(Map hash);\n\t// Convert an object to a map that can be used with Redis hashes.\n\tMap<String,String> toHash(T object);\n}", "des": "Delegating hash mapper used for flattening objects into Strings."}
{"index": 6412, "repo": "spring-data-redis-3.1.2", "code": "public class DefaultMessage extends Object implements Message {\n\t// Returns the body (or the payload) of the message.\n\tbyte[] getBody();\n\t// Returns the channel associated with the message.\n\tbyte[] getChannel();\n}", "des": "Default message implementation."}
{"index": 6413, "repo": "spring-data-redis-3.1.2", "code": "public class FallbackExceptionTranslationStrategy extends PassThroughExceptionTranslationStrategy {\n\t// Returns a new RedisSystemException wrapping the given Exception.\n\tprotected RedisSystemException getFallback(Exception e);\n\t// Potentially translate the given Exception into DataAccessException.\n\tDataAccessException translate(Exception e);\n}", "des": "FallbackExceptionTranslationStrategy returns RedisSystemException for unknown Exceptions."}
{"index": 6414, "repo": "spring-data-redis-3.1.2", "code": "public class GenericToStringSerializer<T> extends Object implements RedisSerializer<T>, BeanFactoryAware {\n\t// Deserialize an object from the given binary data.\n\tT deserialize(byte[] bytes);\n\t// Serialize the given object to binary data.\n\tbyte[] serialize(T object);\n\tvoid setBeanFactory(BeanFactory beanFactory);\n\tvoid setConversionService(ConversionService conversionService);\n\tvoid setTypeConverter(TypeConverter typeConverter);\n}", "des": "Generic String to byte[] (and back) serializer."}
{"index": 6415, "repo": "spring-data-redis-3.1.2", "code": "public class GeoIndexedPropertyValue extends Object implements IndexedData {\n\tprotected boolean canEqual(Object other);\n\tboolean equals(Object o);\n\tstatic String geoIndexName(String path);\n\t// Get the String representation of the index name.\n\tString getIndexName();\n\t// Get the associated keyspace the index resides in.\n\tString getKeyspace();\n\tPoint getPoint();\n\tPoint getValue();\n}", "des": "IndexedData implementation indicating storage of data within a Redis GEO structure."}
{"index": 6416, "repo": "spring-data-redis-3.1.2", "code": "public interface HashMapper<T,K,V> {\n\t// Convert a hash (map) to an object.\n\tT fromHash(Map<K,V> hash);\n\t// Convert an object to a map that can be used with Redis hashes.\n\tMap<K,V> toHash(T object);\n}", "des": "Core mapping contract between Java types and Redis hashes/maps."}
{"index": 6417, "repo": "spring-data-redis-3.1.2", "code": "public interface IndexedData {\n\t// Get the String representation of the index name.\n\tString getIndexName();\n\t// Get the associated keyspace the index resides in.\n\tString getKeyspace();\n}", "des": "IndexedData represents a secondary index for a property path in a given keyspace."}
{"index": 6418, "repo": "spring-data-redis-3.1.2", "code": "public interface IndexResolver {\n\t// Resolves all indexes for given type information / value combination.\n\tSet<IndexedData> resolveIndexesFor(String keyspace, String path, TypeInformation<?> typeInformation, Object value);\n\t// Resolves all indexes for given type information / value combination.\n\tSet<IndexedData> resolveIndexesFor(TypeInformation<?> typeInformation, Object value);\n}", "des": "IndexResolver extracts secondary index structures to be applied on a given path, PersistentProperty and value."}
{"index": 6419, "repo": "spring-data-redis-3.1.2", "code": "public class Jackson2HashMapper extends Object implements HashMapper<Object,String,Object> {\n\t// Convert a hash (map) to an object.\n\tObject fromHash(Map<String,Object> hash);\n\t// Convert an object to a map that can be used with Redis hashes.\n\tMap<String,Object> toHash(Object source);\n}", "des": "ObjectMapper based HashMapper implementation that allows flattening."}
{"index": 6420, "repo": "spring-data-redis-3.1.2", "code": "@FunctionalInterface public interface JacksonObjectReader {\n\t// Create a default JacksonObjectReader delegating to ObjectMapper.readValue(InputStream, JavaType).\n\tstatic JacksonObjectReader create();\n\t// Read an object graph from the given root JSON into a Java object considering the JavaType.\n\tObject read(com.fasterxml.jackson.databind.ObjectMapper mapper, byte[] source, com.fasterxml.jackson.databind.JavaType type);\n}", "des": "Defines the contract for Object Mapping readers."}
{"index": 6421, "repo": "spring-data-redis-3.1.2", "code": "@FunctionalInterface public interface JacksonObjectWriter {\n\t// Create a default JacksonObjectWriter delegating to ObjectMapper.writeValueAsBytes(Object).\n\tstatic JacksonObjectWriter create();\n\t// Write the object graph with the given root source as byte array.\n\tbyte[] write(com.fasterxml.jackson.databind.ObjectMapper mapper, Object source);\n}", "des": "Defines the contract for Object Mapping writers."}
{"index": 6422, "repo": "spring-data-redis-3.1.2", "code": "public class JdkSerializationRedisSerializer extends Object implements RedisSerializer<Object> {\n\t// Deserialize an object from the given binary data.\n\tObject deserialize(byte[] bytes);\n\t// Serialize the given object to binary data.\n\tbyte[] serialize(Object object);\n}", "des": "Java Serialization Redis serializer."}
{"index": 6423, "repo": "spring-data-redis-3.1.2", "code": "public static interface JedisClientConfiguration.JedisPoolingClientConfigurationBuilder {\n\t// Return to JedisClientConfiguration.JedisClientConfigurationBuilder.\n\tJedisClientConfiguration.JedisClientConfigurationBuilder and();\n\t// Build the JedisClientConfiguration with the configuration applied from this builder.\n\tJedisClientConfiguration build();\n\tJedisClientConfiguration.JedisPoolingClientConfigurationBuilder poolConfig(org.apache.commons.pool2.impl.GenericObjectPoolConfig poolConfig);\n}", "des": "Builder for Pooling-related JedisClientConfiguration."}
{"index": 6424, "repo": "spring-data-redis-3.1.2", "code": "public static class JedisClusterConnection.JedisClusterTopologyProvider extends Object implements ClusterTopologyProvider {\n\t// Get the current known ClusterTopology.\n\tClusterTopology getTopology();\n\t// Returns whether getTopology() should return the cached ClusterTopology.\n\tprotected boolean shouldUseCachedValue();\n}", "des": "Jedis specific implementation of ClusterTopologyProvider."}
{"index": 6425, "repo": "spring-data-redis-3.1.2", "code": "public static interface LettuceConnection.PipeliningFlushState {\n\t// Callback if the pipeline gets closed.\n\tvoid onClose(io.lettuce.core.api.StatefulConnection<?,?> connection);\n\t// Callback for each issued Redis command.\n\tvoid onCommand(io.lettuce.core.api.StatefulConnection<?,?> connection);\n\t// Callback if the pipeline gets opened.\n\tvoid onOpen(io.lettuce.core.api.StatefulConnection<?,?> connection);\n}", "des": "State object associated with flushing of the currently ongoing pipeline."}
{"index": 6426, "repo": "spring-data-redis-3.1.2", "code": "public static class MappingRedisConverter.BinaryKeyspaceIdentifier extends Object {\n\tbyte[] getId();\n\tbyte[] getKeyspace();\n\tboolean isPhantomKey();\n\t// Check whether the key is valid, in particular whether the key contains a keyspace and an id part in the form of keyspace:id.\n\tstatic boolean isValid(byte[] key);\n\t// Parse a binary key into MappingRedisConverter.BinaryKeyspaceIdentifier.\n\tstatic MappingRedisConverter.BinaryKeyspaceIdentifier of(byte[] key);\n}", "des": "Value object representing a binary Redis Hash/Object identifier composed from keyspace and object id in the form of keyspace:id."}
{"index": 6427, "repo": "spring-data-redis-3.1.2", "code": "public static class MappingRedisConverter.KeyspaceIdentifier extends Object {\n\tString getId();\n\tString getKeyspace();\n\tboolean isPhantomKey();\n\t// Check whether the key is valid, in particular whether the key contains a keyspace and an id part in the form of keyspace:id.\n\tstatic boolean isValid(String key);\n\t// Parse a key into MappingRedisConverter.KeyspaceIdentifier.\n\tstatic MappingRedisConverter.KeyspaceIdentifier of(String key);\n}", "des": "Value object representing a Redis Hash/Object identifier composed from keyspace and object id in the form of keyspace:id."}
{"index": 6428, "repo": "spring-data-redis-3.1.2", "code": "public interface Message extends Serializable {\n\t// Returns the body (or the payload) of the message.\n\tbyte[] getBody();\n\t// Returns the channel associated with the message.\n\tbyte[] getChannel();\n}", "des": "Class encapsulating a Redis message body and its properties."}
{"index": 6429, "repo": "spring-data-redis-3.1.2", "code": "public enum Metrics extends Enum<Metrics> implements Metric {\n\tString getAbbreviation();\n\tdouble getMultiplier();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Metrics valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Metrics[] values();\n}", "des": "Metrics supported by Redis."}
{"index": 6430, "repo": "spring-data-redis-3.1.2", "code": "public class OxmSerializer extends Object implements InitializingBean, RedisSerializer<Object> {\n\tvoid afterPropertiesSet();\n\t// Deserialize an object from the given binary data.\n\tObject deserialize(byte[] bytes);\n\t// Serialize the given object to binary data.\n\tbyte[] serialize(Object t);\n\tvoid setMarshaller(Marshaller marshaller);\n\tvoid setUnmarshaller(Unmarshaller unmarshaller);\n}", "des": "Serializer adapter on top of Spring's O/X Mapping."}
{"index": 6431, "repo": "spring-data-redis-3.1.2", "code": "public class PatternTopic extends Object implements Topic {\n\tboolean equals(Object o);\n\t// Returns the topic (as a String).\n\tString getTopic();\n\t// Create a new PatternTopic for channel subscriptions based on a pattern.\n\tstatic PatternTopic of(String pattern);\n}", "des": "Pattern topic (matching multiple channels)."}
{"index": 6432, "repo": "spring-data-redis-3.1.2", "code": "public class PendingMessages extends Object implements Streamable<PendingMessage> {\n\t// Get the PendingMessage at the given position.\n\tPendingMessage get(int index);\n\t// The consumer group name.\n\tString getGroupName();\n\t// The Range pending messages have been loaded.\n\tRange<?> getRange();\n\tboolean isEmpty();\n\tIterator<PendingMessage> iterator();\n\tint size();\n\t// Adds the range to the current PendingMessages.\n\tPendingMessages withinRange(Range<?> range);\n}", "des": "Value object holding detailed information about pending messages in consumer group for a given Range and offset."}
{"index": 6433, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveHashCommands.HExistsCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Creates a new ReactiveHashCommands.HExistsCommand given a field name.\n\tstatic ReactiveHashCommands.HExistsCommand field(ByteBuffer field);\n\tByteBuffer getField();\n\t// Applies the hash key.\n\tReactiveHashCommands.HExistsCommand in(ByteBuffer key);\n}", "des": "HEXISTS ReactiveRedisConnection.Command."}
{"index": 6434, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveHashCommands.HRandFieldCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the count.\n\tReactiveHashCommands.HRandFieldCommand count(long count);\n\tlong getCount();\n\t// Applies the hash key.\n\tstatic ReactiveHashCommands.HRandFieldCommand key(ByteBuffer key);\n}", "des": "HRANDFIELD ReactiveRedisConnection.Command."}
{"index": 6435, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveHyperLogLogCommands.PfCountCommand extends Object implements ReactiveRedisConnection.Command {\n\tByteBuffer getKey();\n\tList<ByteBuffer> getKeys();\n\t// Creates a new ReactiveHyperLogLogCommands.PfCountCommand given a key.\n\tstatic ReactiveHyperLogLogCommands.PfCountCommand valueIn(ByteBuffer key);\n\t// Creates a new ReactiveHyperLogLogCommands.PfCountCommand given a Collection of keys.\n\tstatic ReactiveHyperLogLogCommands.PfCountCommand valuesIn(Collection<ByteBuffer> keys);\n}", "des": "PFCOUNT command parameters."}
{"index": 6436, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveHyperLogLogCommands.PfMergeCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<ByteBuffer> getSourceKeys();\n\t// Applies the destinationKey.\n\tReactiveHyperLogLogCommands.PfMergeCommand into(ByteBuffer destinationKey);\n\t// Creates a new ReactiveHyperLogLogCommands.PfMergeCommand given a Collection of sourceKeys.\n\tstatic ReactiveHyperLogLogCommands.PfMergeCommand valuesIn(Collection<ByteBuffer> sourceKeys);\n}", "des": "PFMERGE command parameters."}
{"index": 6437, "repo": "spring-data-redis-3.1.2", "code": "public interface ReactiveHyperLogLogOperations<K,V> {\n\t// Adds the given values to the key.\n\treactor.core.publisher.Mono<Long> add(K key, V... values);\n\t// Removes the given key.\n\treactor.core.publisher.Mono<Boolean> delete(K key);\n\t// Gets the current number of elements within the key.\n\treactor.core.publisher.Mono<Long> size(K... keys);\n\t// Merges all values of given sourceKeys into destination key.\n\treactor.core.publisher.Mono<Boolean> union(K destination, K... sourceKeys);\n}", "des": "Redis cardinality specific operations working on a HyperLogLog multiset."}
{"index": 6438, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveKeyCommands.ExpireAtCommand extends ReactiveRedisConnection.KeyCommand {\n\tInstant getExpireAt();\n\t// Creates a new ReactiveKeyCommands.ExpireAtCommand given a key.\n\tstatic ReactiveKeyCommands.ExpireAtCommand key(ByteBuffer key);\n\t// Applies the expireAt.\n\tReactiveKeyCommands.ExpireAtCommand timeout(Instant expireAt);\n}", "des": "EXPIREAT/PEXPIREAT command parameters."}
{"index": 6439, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveKeyCommands.ExpireCommand extends ReactiveRedisConnection.KeyCommand {\n\tDuration getTimeout();\n\t// Creates a new ReactiveKeyCommands.ExpireCommand given a key.\n\tstatic ReactiveKeyCommands.ExpireCommand key(ByteBuffer key);\n\t// Applies the timeout.\n\tReactiveKeyCommands.ExpireCommand timeout(Duration timeout);\n}", "des": "EXPIRE/PEXPIRE command parameters."}
{"index": 6440, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveKeyCommands.MoveCommand extends ReactiveRedisConnection.KeyCommand {\n\tInteger getDatabase();\n\t// Creates a new ReactiveKeyCommands.MoveCommand given a key.\n\tstatic ReactiveKeyCommands.MoveCommand key(ByteBuffer key);\n\t// Applies the database index.\n\tReactiveKeyCommands.MoveCommand timeout(int database);\n}", "des": "MOVE command parameters."}
{"index": 6441, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveKeyCommands.RenameCommand extends ReactiveRedisConnection.KeyCommand {\n\tByteBuffer getNewKey();\n\t// Creates a new ReactiveKeyCommands.RenameCommand given a key.\n\tstatic ReactiveKeyCommands.RenameCommand key(ByteBuffer key);\n\t// Applies the newKey.\n\tReactiveKeyCommands.RenameCommand to(ByteBuffer newKey);\n}", "des": "RENAME command parameters."}
{"index": 6442, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveListCommands.BRPopLPushCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies a timeout.\n\tReactiveListCommands.BRPopLPushCommand blockingFor(Duration timeout);\n\t// Creates a new ReactiveListCommands.BRPopLPushCommand given a sourceKey.\n\tstatic ReactiveListCommands.BRPopLPushCommand from(ByteBuffer sourceKey);\n\tByteBuffer getDestination();\n\tDuration getTimeout();\n\t// Applies the destinationKey.\n\tReactiveListCommands.BRPopLPushCommand to(ByteBuffer destinationKey);\n}", "des": "BRPOPLPUSH command parameters."}
{"index": 6443, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveListCommands.LIndexCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Creates a new ReactiveListCommands.LIndexCommand given an index.\n\tstatic ReactiveListCommands.LIndexCommand elementAt(long index);\n\t// Applies the key.\n\tReactiveListCommands.LIndexCommand from(ByteBuffer key);\n\tLong getIndex();\n}", "des": "LINDEX command parameters."}
{"index": 6444, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveListCommands.LSetCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Creates a new ReactiveListCommands.LSetCommand given an index.\n\tstatic ReactiveListCommands.LSetCommand elementAt(long index);\n\t// Applies the key.\n\tReactiveListCommands.LSetCommand forKey(ByteBuffer key);\n\tLong getIndex();\n\tByteBuffer getValue();\n\t// Applies the value.\n\tReactiveListCommands.LSetCommand to(ByteBuffer value);\n}", "des": "LSET command parameters."}
{"index": 6445, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveListCommands.RPopLPushCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Creates a new ReactiveListCommands.RPopLPushCommand given a sourceKey.\n\tstatic ReactiveListCommands.RPopLPushCommand from(ByteBuffer sourceKey);\n\tByteBuffer getDestination();\n\t// Applies the destinationKey.\n\tReactiveListCommands.RPopLPushCommand to(ByteBuffer destinationKey);\n}", "des": "RPOPLPUSH command parameters."}
{"index": 6446, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveNumberCommands.DecrByCommand<T extends Number> extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the numeric value.\n\tReactiveNumberCommands.DecrByCommand<T> by(T value);\n\t// Creates a new ReactiveNumberCommands.DecrByCommand given a key.\n\tstatic <T extends Number>ReactiveNumberCommands.DecrByCommand<T> decr(ByteBuffer key);\n\tT getValue();\n}", "des": "DECRBY command parameters."}
{"index": 6447, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveNumberCommands.HIncrByCommand<T extends Number> extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the numeric value.\n\tReactiveNumberCommands.HIncrByCommand<T> by(T value);\n\t// Applies the key.\n\tReactiveNumberCommands.HIncrByCommand<T> forKey(ByteBuffer key);\n\tByteBuffer getField();\n\tT getValue();\n\t// Creates a new ReactiveNumberCommands.HIncrByCommand given a key.\n\tstatic <T extends Number>ReactiveNumberCommands.HIncrByCommand<T> incr(ByteBuffer field);\n}", "des": "HINCRBY command parameters."}
{"index": 6448, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveNumberCommands.IncrByCommand<T extends Number> extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the numeric value.\n\tReactiveNumberCommands.IncrByCommand<T> by(T value);\n\tT getValue();\n\t// Creates a new ReactiveNumberCommands.IncrByCommand given a key.\n\tstatic <T extends Number>ReactiveNumberCommands.IncrByCommand<T> incr(ByteBuffer key);\n}", "des": "INCRBY command parameters."}
{"index": 6449, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveRedisConnection.KeyScanCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Get the ScanOptions to apply.\n\tScanOptions getOptions();\n\t// Creates a new ReactiveRedisConnection.KeyScanCommand given a key.\n\tstatic ReactiveRedisConnection.KeyScanCommand key(ByteBuffer key);\n\t// Applies ScanOptions.\n\tReactiveRedisConnection.KeyScanCommand withOptions(ScanOptions options);\n}", "des": "ReactiveRedisConnection.Command for key-bound scan operations like SCAN, HSCAN, SSCAN and ZSCAN."}
{"index": 6450, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SAddCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<ByteBuffer> getValues();\n\t// Applies the key.\n\tReactiveSetCommands.SAddCommand to(ByteBuffer key);\n\t// Creates a new ReactiveSetCommands.SAddCommand given a value.\n\tstatic ReactiveSetCommands.SAddCommand value(ByteBuffer value);\n\t// Creates a new ReactiveSetCommands.SAddCommand given a Collection of values.\n\tstatic ReactiveSetCommands.SAddCommand values(Collection<ByteBuffer> values);\n}", "des": "SADD command parameters."}
{"index": 6451, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SDiffStoreCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<ByteBuffer> getKeys();\n\t// Creates a new ReactiveSetCommands.SDiffStoreCommand given a Collection of keys.\n\tstatic ReactiveSetCommands.SDiffStoreCommand keys(Collection<ByteBuffer> keys);\n\t// Applies the key at which the result is stored.\n\tReactiveSetCommands.SDiffStoreCommand storeAt(ByteBuffer key);\n}", "des": "SDIFFSTORE command parameters."}
{"index": 6452, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SInterStoreCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<ByteBuffer> getKeys();\n\t// Creates a new ReactiveSetCommands.SInterStoreCommand given a Collection of keys.\n\tstatic ReactiveSetCommands.SInterStoreCommand keys(Collection<ByteBuffer> keys);\n\t// Applies the key at which the result is stored.\n\tReactiveSetCommands.SInterStoreCommand storeAt(ByteBuffer key);\n}", "des": "SINTERSTORE command parameters."}
{"index": 6453, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SIsMemberCommand extends ReactiveRedisConnection.KeyCommand {\n\tByteBuffer getValue();\n\t// Applies the set key.\n\tReactiveSetCommands.SIsMemberCommand of(ByteBuffer set);\n\t// Creates a new ReactiveSetCommands.SIsMemberCommand given a value.\n\tstatic ReactiveSetCommands.SIsMemberCommand value(ByteBuffer value);\n}", "des": "SISMEMBER command parameters."}
{"index": 6454, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SMIsMemberCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<ByteBuffer> getValues();\n\t// Applies the set key.\n\tReactiveSetCommands.SMIsMemberCommand of(ByteBuffer set);\n\t// Creates a new ReactiveSetCommands.SMIsMemberCommand given one or more values.\n\tstatic ReactiveSetCommands.SMIsMemberCommand values(List<ByteBuffer> values);\n}", "des": "SMISMEMBER command parameters."}
{"index": 6455, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SMoveCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the source key.\n\tReactiveSetCommands.SMoveCommand from(ByteBuffer source);\n\tByteBuffer getDestination();\n\tByteBuffer getValue();\n\t// Applies the destination key.\n\tReactiveSetCommands.SMoveCommand to(ByteBuffer destination);\n\t// Creates a new ReactiveSetCommands.SMoveCommand given a value.\n\tstatic ReactiveSetCommands.SMoveCommand value(ByteBuffer value);\n}", "des": "SMOVE command parameters."}
{"index": 6456, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SPopCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveSetCommands.SPopCommand from(ByteBuffer key);\n\tlong getCount();\n\t// Creates a new ReactiveSetCommands.SPopCommand for count members.\n\tstatic ReactiveSetCommands.SPopCommand members(long count);\n\t// Creates a new ReactiveSetCommands.SPopCommand for a single member.\n\tstatic ReactiveSetCommands.SPopCommand one();\n}", "des": "SPOP command parameters."}
{"index": 6457, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SRemCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveSetCommands.SRemCommand from(ByteBuffer key);\n\tList<ByteBuffer> getValues();\n\t// Creates a new ReactiveSetCommands.SRemCommand given a value.\n\tstatic ReactiveSetCommands.SRemCommand value(ByteBuffer value);\n\t// Creates a new ReactiveSetCommands.SRemCommand given a Collection of values.\n\tstatic ReactiveSetCommands.SRemCommand values(Collection<ByteBuffer> values);\n}", "des": "SREM command parameters."}
{"index": 6458, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSetCommands.SUnionStoreCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<ByteBuffer> getKeys();\n\t// Creates a new ReactiveSetCommands.SUnionStoreCommand given a Collection of keys.\n\tstatic ReactiveSetCommands.SUnionStoreCommand keys(Collection<ByteBuffer> keys);\n\t// Applies the key at which the result is stored.\n\tReactiveSetCommands.SUnionStoreCommand storeAt(ByteBuffer key);\n}", "des": "SUNIONSTORE command parameters."}
{"index": 6459, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStreamCommands.DeleteCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<RecordId> getRecordIds();\n\t// Applies the recordIds.\n\tReactiveStreamCommands.DeleteCommand records(String... recordIds);\n\t// Applies the recordIds.\n\tReactiveStreamCommands.DeleteCommand records(RecordId... recordIds);\n\t// Creates a new ReactiveStreamCommands.DeleteCommand given a key.\n\tstatic ReactiveStreamCommands.DeleteCommand stream(ByteBuffer key);\n}", "des": "XDEL command parameters."}
{"index": 6460, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStringCommands.AppendCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the value to append.\n\tReactiveStringCommands.AppendCommand append(ByteBuffer value);\n\tByteBuffer getValue();\n\t// Creates a new ReactiveStringCommands.AppendCommand given a key.\n\tstatic ReactiveStringCommands.AppendCommand key(ByteBuffer key);\n}", "des": "APPEND command parameters."}
{"index": 6461, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStringCommands.BitCountCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Creates a new ReactiveStringCommands.BitCountCommand given a key.\n\tstatic ReactiveStringCommands.BitCountCommand bitCount(ByteBuffer key);\n\tRange<Long> getRange();\n\t// Applies the Range.\n\tReactiveStringCommands.BitCountCommand within(Range<Long> range);\n}", "des": "BITCOUNT command parameters."}
{"index": 6462, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStringCommands.BitFieldCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Creates a new ReactiveStringCommands.BitFieldCommand given a key.\n\tstatic ReactiveStringCommands.BitFieldCommand bitField(ByteBuffer key);\n\t// Applies the BitFieldSubCommands.\n\tReactiveStringCommands.BitFieldCommand commands(BitFieldSubCommands commands);\n\tBitFieldSubCommands getSubCommands();\n}", "des": "BITFIELD command parameters."}
{"index": 6463, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStringCommands.GetBitCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the offset index.\n\tReactiveStringCommands.GetBitCommand atOffset(long offset);\n\t// Creates a new ReactiveStringCommands.GetBitCommand given a key.\n\tstatic ReactiveStringCommands.GetBitCommand bit(ByteBuffer key);\n\tLong getOffset();\n}", "des": "GETBIT command parameters."}
{"index": 6464, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStringCommands.GetExCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Get the Expiration to apply.\n\tExpiration getExpiration();\n\t// Creates a new ReactiveStringCommands.GetExCommand given a key.\n\tstatic ReactiveStringCommands.GetExCommand key(ByteBuffer key);\n\t// Applies Expiration.\n\tReactiveStringCommands.GetExCommand withExpiration(Expiration expiration);\n}", "des": "ReactiveRedisConnection.Command for GETEX."}
{"index": 6465, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStringCommands.SetBitCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the offset index.\n\tReactiveStringCommands.SetBitCommand atOffset(long index);\n\t// Creates a new ReactiveStringCommands.SetBitCommand given a key.\n\tstatic ReactiveStringCommands.SetBitCommand bit(ByteBuffer key);\n\tLong getOffset();\n\tboolean getValue();\n\t// Applies the bit.\n\tReactiveStringCommands.SetBitCommand to(boolean bit);\n}", "des": "SETBIT command parameters."}
{"index": 6466, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveStringCommands.SetRangeCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the index.\n\tReactiveStringCommands.SetRangeCommand atPosition(long index);\n\tLong getOffset();\n\tByteBuffer getValue();\n\t// Creates a new ReactiveStringCommands.SetRangeCommand given a key.\n\tstatic ReactiveStringCommands.SetRangeCommand overwrite(ByteBuffer key);\n\t// Applies the value.\n\tReactiveStringCommands.SetRangeCommand withValue(ByteBuffer value);\n}", "des": "SETRANGE command parameters."}
{"index": 6467, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveSubscription.ChannelMessage<C,M> extends Object implements ReactiveSubscription.Message<C,M> {\n\tboolean equals(Object o);\n\t// Get the channel the message published to.\n\tC getChannel();\n\t// Get the actual message body.\n\tM getMessage();\n}", "des": "Value object for a Redis channel message."}
{"index": 6468, "repo": "spring-data-redis-3.1.2", "code": "public static interface ReactiveSubscription.Message<C,M> {\n\t// Get the channel the message published to.\n\tC getChannel();\n\t// Get the actual message body.\n\tM getMessage();\n}", "des": "ReactiveSubscription.Message represents a Redis channel message within Redis pub/sub."}
{"index": 6469, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZCountCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveZSetCommands.ZCountCommand forKey(ByteBuffer key);\n\tRange<Double> getRange();\n\t// Creates a new ReactiveZSetCommands.ZCountCommand given a Range.\n\tstatic ReactiveZSetCommands.ZCountCommand scoresWithin(Range<Double> range);\n}", "des": "ZCOUNT command parameters."}
{"index": 6470, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZDiffStoreCommand extends ReactiveRedisConnection.KeyCommand {\n\tList<ByteBuffer> getSourceKeys();\n\t// Creates a new ReactiveZSetCommands.ZDiffStoreCommand given a Collection of keys.\n\tstatic ReactiveZSetCommands.ZDiffStoreCommand sourceKeys(Collection<ByteBuffer> keys);\n\t// Applies the key at which the result is stored.\n\tReactiveZSetCommands.ZDiffStoreCommand storeAs(ByteBuffer key);\n}", "des": "ZDIFFSTORE command parameters."}
{"index": 6471, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZIncrByCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the numeric increment.\n\tReactiveZSetCommands.ZIncrByCommand by(Number increment);\n\tNumber getIncrement();\n\tByteBuffer getValue();\n\t// Creates a new ReactiveZSetCommands.ZIncrByCommand given a member.\n\tstatic ReactiveZSetCommands.ZIncrByCommand scoreOf(ByteBuffer member);\n\t// Applies the key.\n\tReactiveZSetCommands.ZIncrByCommand storedWithin(ByteBuffer key);\n}", "des": "ZINCRBY command parameters."}
{"index": 6472, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZLexCountCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveZSetCommands.ZLexCountCommand forKey(ByteBuffer key);\n\tRange<String> getRange();\n\t// Creates a new ReactiveZSetCommands.ZLexCountCommand given a Range of String to retrieve elements count.\n\tstatic ReactiveZSetCommands.ZLexCountCommand stringsWithin(Range<String> range);\n}", "des": "ZLEXCOUNT command parameters."}
{"index": 6473, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZRemCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveZSetCommands.ZRemCommand from(ByteBuffer key);\n\tList<ByteBuffer> getValues();\n\t// Creates a new ReactiveZSetCommands.ZRemCommand given a Tuple.\n\tstatic ReactiveZSetCommands.ZRemCommand values(ByteBuffer value);\n\t// Creates a new ReactiveZSetCommands.ZRemCommand given a Collection of Tuple.\n\tstatic ReactiveZSetCommands.ZRemCommand values(Collection<ByteBuffer> values);\n}", "des": "ZREM command parameters."}
{"index": 6474, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZRemRangeByLexCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveZSetCommands.ZRemRangeByLexCommand from(ByteBuffer key);\n\tRange<String> getRange();\n\t// Creates a new ReactiveZSetCommands.ZRemRangeByLexCommand given a Range.\n\tstatic ReactiveZSetCommands.ZRemRangeByLexCommand lexWithin(Range<String> range);\n}", "des": "ZREMRANGEBYLEX command parameters."}
{"index": 6475, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZRemRangeByRankCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveZSetCommands.ZRemRangeByRankCommand from(ByteBuffer key);\n\tRange<Long> getRange();\n\t// Creates a new ReactiveZSetCommands.ZRemRangeByRankCommand given a Range.\n\tstatic ReactiveZSetCommands.ZRemRangeByRankCommand valuesWithin(Range<Long> range);\n}", "des": "ZREMRANGEBYRANK command parameters."}
{"index": 6476, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZRemRangeByScoreCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveZSetCommands.ZRemRangeByScoreCommand from(ByteBuffer key);\n\tRange<Double> getRange();\n\t// Creates a new ReactiveZSetCommands.ZRemRangeByScoreCommand given a Range.\n\tstatic ReactiveZSetCommands.ZRemRangeByScoreCommand scoresWithin(Range<Double> range);\n}", "des": "ZREMRANGEBYSCORE command parameters."}
{"index": 6477, "repo": "spring-data-redis-3.1.2", "code": "public static class ReactiveZSetCommands.ZScoreCommand extends ReactiveRedisConnection.KeyCommand {\n\t// Applies the key.\n\tReactiveZSetCommands.ZScoreCommand forKey(ByteBuffer key);\n\tByteBuffer getValue();\n\t// Creates a new ReactiveZSetCommands.ZScoreCommand given a member.\n\tstatic ReactiveZSetCommands.ZScoreCommand scoreOf(ByteBuffer member);\n}", "des": "ZSCORE command parameters."}
{"index": 6478, "repo": "spring-data-redis-3.1.2", "code": "public abstract class RedisAssertions extends Object {\n\t// Asserts the given Object is not null.\n\tstatic <T> T requireObject(T target, String message, Object... arguments);\n\t// Asserts the given Object is not null.\n\tstatic <T> T requireObject(T target, Supplier<String> message);\n}", "des": "Abstract utility class for common assertions used in Spring Data Redis."}
{"index": 6479, "repo": "spring-data-redis-3.1.2", "code": "public interface RedisClusterCommandsProvider extends RedisCommandsProvider {\n\t// Get RedisGeoCommands.\n\tRedisClusterCommands clusterCommands();\n\t// Get RedisServerCommands.\n\tRedisClusterServerCommands serverCommands();\n}", "des": "Provides access to RedisClusterCommands and the segregated command interfaces."}
{"index": 6480, "repo": "spring-data-redis-3.1.2", "code": "public class RedisCollectionFactoryBean extends Object implements InitializingBean, BeanNameAware, FactoryBean<RedisStore> {\n\tvoid afterPropertiesSet();\n\tRedisStore getObject();\n\tClass<?> getObjectType();\n\tboolean isSingleton();\n\tvoid setBeanName(String name);\n\t// Sets the key of the store.\n\tvoid setKey(String key);\n\t// Sets the template used by the resulting store.\n\tvoid setTemplate(RedisTemplate<String,?> template);\n\t// Sets the store type.\n\tvoid setType(RedisCollectionFactoryBean.CollectionType type);\n}", "des": "Factory bean that facilitates creation of Redis-based collections."}
{"index": 6481, "repo": "spring-data-redis-3.1.2", "code": "public static enum RedisCollectionFactoryBean.CollectionType extends Enum<RedisCollectionFactoryBean.CollectionType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic RedisCollectionFactoryBean.CollectionType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic RedisCollectionFactoryBean.CollectionType[] values();\n}", "des": "Collection types supported by this factory."}
{"index": 6482, "repo": "spring-data-redis-3.1.2", "code": "public static interface RedisConfiguration.WithDatabaseIndex {\n\t// Get the database index to use.\n\tint getDatabase();\n\t// Set the database index to use.\n\tvoid setDatabase(int dbIndex);\n}", "des": "RedisConfiguration part suitable for configurations that use a specific database."}
{"index": 6483, "repo": "spring-data-redis-3.1.2", "code": "public static interface RedisConfiguration.WithDomainSocket {\n\t// Get the domain socket.\n\tString getSocket();\n\t// Set the socket.\n\tvoid setSocket(String socket);\n}", "des": "RedisConfiguration part suitable for configurations that use native domain sockets for connecting."}
{"index": 6484, "repo": "spring-data-redis-3.1.2", "code": "public static interface RedisConfiguration.WithHostAndPort {\n\tString getHostName();\n\t// Get the Redis server port.\n\tint getPort();\n\t// Set the Redis server hostname\n\tvoid setHostName(String hostName);\n\t// Set the Redis server port.\n\tvoid setPort(int port);\n}", "des": "RedisConfiguration part suitable for configurations that use host/port combinations for connecting."}
{"index": 6485, "repo": "spring-data-redis-3.1.2", "code": "public interface RedisConnectionCommands {\n\t// Returns message via server roundtrip.\n\tbyte[] echo(byte[] message);\n\t// Test connection.\n\tString ping();\n\t// Select the DB with given positive dbIndex.\n\tvoid select(int dbIndex);\n}", "des": "Connection-specific commands supported by Redis."}
{"index": 6486, "repo": "spring-data-redis-3.1.2", "code": "public interface RedisCredentialsProviderFactory {\n\t// Create a RedisCredentialsProvider for data node authentication given RedisConfiguration.\n\tdefault io.lettuce.core.RedisCredentialsProvider createCredentialsProvider(RedisConfiguration redisConfiguration);\n\t// Create a RedisCredentialsProvider for Sentinel node authentication given RedisSentinelConfiguration.\n\tdefault io.lettuce.core.RedisCredentialsProvider createSentinelCredentialsProvider(RedisSentinelConfiguration redisConfiguration);\n}", "des": "Factory interface to create RedisCredentialsProvider from a RedisConfiguration."}
{"index": 6487, "repo": "spring-data-redis-3.1.2", "code": "@FunctionalInterface public interface RedisElementReader<T> {\n\t// Create new RedisElementReader using given RedisSerializer.\n\tstatic <T> RedisElementReader<T> from(RedisSerializer<T> serializer);\n\t// Deserialize a ByteBuffer into the according type.\n\tT read(ByteBuffer buffer);\n}", "des": "Strategy interface that specifies a deserializer that can deserialize a binary element representation stored in Redis into an object."}
{"index": 6488, "repo": "spring-data-redis-3.1.2", "code": "@FunctionalInterface public interface RedisElementWriter<T> {\n\t// Create new RedisElementWriter using given RedisSerializer.\n\tstatic <T> RedisElementWriter<T> from(RedisSerializer<T> serializer);\n\t// Serialize a element to its ByteBuffer representation.\n\tByteBuffer write(T element);\n}", "des": "Strategy interface that specifies a serializer that can serialize an element to its binary representation to be used as Redis protocol payload."}
{"index": 6489, "repo": "spring-data-redis-3.1.2", "code": "public static enum RedisGeoCommands.DistanceUnit extends Enum<RedisGeoCommands.DistanceUnit> implements Metric {\n\tString getAbbreviation();\n\tdouble getMultiplier();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic RedisGeoCommands.DistanceUnit valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic RedisGeoCommands.DistanceUnit[] values();\n}", "des": "Metrics supported by Redis."}
{"index": 6490, "repo": "spring-data-redis-3.1.2", "code": "public interface RedisHyperLogLogCommands {\n\t// Adds given values to the HyperLogLog stored at given key.\n\tLong pfAdd(byte[] key, byte[]... values);\n\t// Return the approximated cardinality of the structures observed by the HyperLogLog at key(s).\n\tLong pfCount(byte[]... keys);\n\t// Merge N different HyperLogLogs at sourceKeys into a single destinationKey.\n\tvoid pfMerge(byte[] destinationKey, byte[]... sourceKeys);\n}", "des": "HyperLogLog specific commands supported by Redis."}
{"index": 6491, "repo": "spring-data-redis-3.1.2", "code": "public class RedisKeyExpiredEvent<T> extends RedisKeyspaceEvent {\n\t// Get the expired objects id.\n\tbyte[] getId();\n\t// Gets the keyspace in which the expiration occured.\n\tString getKeyspace();\n\t// Get the expired Object\n\tObject getValue();\n}", "des": "RedisKeyExpiredEvent is a Redis specific ApplicationEvent published when a particular key in Redis expires."}
{"index": 6492, "repo": "spring-data-redis-3.1.2", "code": "public static enum RedisKeyValueAdapter.ShadowCopy extends Enum<RedisKeyValueAdapter.ShadowCopy> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic RedisKeyValueAdapter.ShadowCopy valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic RedisKeyValueAdapter.ShadowCopy[] values();\n}", "des": "Configuration flag controlling storage of phantom keys (shadow copies) of expiring entities to read them later when publishing RedisKeyspaceEvent."}
{"index": 6493, "repo": "spring-data-redis-3.1.2", "code": "public static enum RedisListCommands.Direction extends Enum<RedisListCommands.Direction> {\n\t// Alias for LEFT.\n\tstatic RedisListCommands.Direction first();\n\t// Alias for RIGHT.\n\tstatic RedisListCommands.Direction last();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic RedisListCommands.Direction valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic RedisListCommands.Direction[] values();\n}", "des": "List move direction."}
{"index": 6494, "repo": "spring-data-redis-3.1.2", "code": "public static enum RedisListCommands.Position extends Enum<RedisListCommands.Position> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic RedisListCommands.Position valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic RedisListCommands.Position[] values();\n}", "des": "List insertion position."}
{"index": 6495, "repo": "spring-data-redis-3.1.2", "code": "public interface RedisMap<K,V> extends RedisStore, ConcurrentMap<K,V> {\n\t// Increment value of the hash key by the given delta.\n\tDouble increment(K key, double delta);\n\t// Increment value of the hash key by the given delta.\n\tLong increment(K key, long delta);\n\t// Get a random entry from the hash.\n\tMap.Entry<K,V> randomEntry();\n\t// Get a random key from the hash.\n\tK randomKey();\n\tIterator<Map.Entry<K,V>> scan();\n}", "des": "Map view of a Redis hash."}
{"index": 6496, "repo": "spring-data-redis-3.1.2", "code": "public enum RedisObservation extends Enum<RedisObservation> implements io.micrometer.observation.docs.ObservationDocumentation {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic RedisObservation valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic RedisObservation[] values();\n}", "des": "A Redis-based Observation."}
{"index": 6497, "repo": "spring-data-redis-3.1.2", "code": "public interface RedisPersistentEntity<T> extends org.springframework.data.keyvalue.core.mapping.KeyValuePersistentEntity<T,RedisPersistentProperty> {\n\t// Get the PersistentProperty that is annotated with TimeToLive.\n\tRedisPersistentProperty getExplicitTimeToLiveProperty();\n\t// Get the TimeToLiveAccessor associated with the entity.\n\tTimeToLiveAccessor getTimeToLiveAccessor();\n\tboolean hasExplictTimeToLiveProperty();\n\tdefault boolean isExpiring();\n}", "des": "Redis specific PersistentEntity."}
{"index": 6498, "repo": "spring-data-redis-3.1.2", "code": "public interface RedisTxCommands {\n\t// Discard all commands issued after multi().\n\tvoid discard();\n\t// Executes all queued commands in a transaction started with multi().\n\tList<Object> exec();\n\t// Mark the start of a transaction block.\n\tvoid multi();\n\t// Flushes all the previously watch(byte[]...) keys.\n\tvoid unwatch();\n\t// Watch given keys for modifications during transaction started with multi().\n\tvoid watch(byte[]... keys);\n}", "des": "Transaction/Batch specific commands supported by Redis."}
{"index": 6499, "repo": "spring-data-redis-3.1.2", "code": "public class RemoveIndexedData extends Object implements IndexedData {\n\t// Get the String representation of the index name.\n\tString getIndexName();\n\t// Get the associated keyspace the index resides in.\n\tString getKeyspace();\n}", "des": "RemoveIndexedData represents a removed index entry from a secondary index for a property path in a given keyspace."}
{"index": 6500, "repo": "spring-data-redis-3.1.2", "code": "public enum ReturnType extends Enum<ReturnType> {\n\tstatic ReturnType fromJavaType(Class<?> javaType);\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ReturnType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ReturnType[] values();\n}", "des": "Represents a data type returned from Redis, currently used to denote the expected return type of Redis scripting commands"}
{"index": 6501, "repo": "spring-data-redis-3.1.2", "code": "public class ScanIteration<T> extends Object implements Iterable<T> {\n\t// The cursor id to be used for subsequent requests.\n\tlong getCursorId();\n\t// Get the items returned.\n\tCollection<T> getItems();\n\tIterator<T> iterator();\n}", "des": "ScanIteration holds the values contained in Redis Multibulk reply on exectuting SCAN command."}
{"index": 6502, "repo": "spring-data-redis-3.1.2", "code": "public interface ScriptExecutor<K> {\n\t// Executes the given RedisScript\n\t<T> T execute(RedisScript<T> script, List<K> keys, Object... args);\n\t// Executes the given RedisScript, using the provided RedisSerializers to serialize the script arguments and result.\n\t<T> T execute(RedisScript<T> script, RedisSerializer<?> argsSerializer, RedisSerializer<T> resultSerializer, List<K> keys, Object... args);\n}", "des": "Executes RedisScripts"}
{"index": 6503, "repo": "spring-data-redis-3.1.2", "code": "public class SimpleIndexedPropertyValue extends Object implements IndexedData {\n\tboolean equals(Object o);\n\t// Get the String representation of the index name.\n\tString getIndexName();\n\t// Get the associated keyspace the index resides in.\n\tString getKeyspace();\n\t// Get the value to index.\n\tObject getValue();\n}", "des": "IndexedData implementation indicating storage of data within a Redis Set."}
{"index": 6504, "repo": "spring-data-redis-3.1.2", "code": "public interface SortParameters {\n\t// Returns the pattern (if set) for sorting by external keys (BY).\n\tbyte[] getByPattern();\n\t// Returns the pattern (if set) for retrieving external keys (GET).\n\tbyte[][] getGetPattern();\n\t// Returns the sorting limit (range or pagination).\n\tSortParameters.Range getLimit();\n\t// Returns the sorting order.\n\tSortParameters.Order getOrder();\n\t// Indicates if the sorting is numeric (default) or alphabetical (lexicographical).\n\tBoolean isAlphabetic();\n}", "des": "Entity containing the parameters for the SORT operation."}
{"index": 6505, "repo": "spring-data-redis-3.1.2", "code": "public static enum SortParameters.Order extends Enum<SortParameters.Order> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic SortParameters.Order valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic SortParameters.Order[] values();\n}", "des": "Sorting order."}
{"index": 6506, "repo": "spring-data-redis-3.1.2", "code": "public class SpelIndexResolver extends Object implements IndexResolver {\n\t// Resolves all indexes for given type information / value combination.\n\tSet<IndexedData> resolveIndexesFor(String keyspace, String path, TypeInformation<?> typeInformation, Object value);\n\t// Resolves all indexes for given type information / value combination.\n\tSet<IndexedData> resolveIndexesFor(TypeInformation<?> typeInformation, Object value);\n\t// Allows setting the BeanResolver\n\tvoid setBeanResolver(BeanResolver beanResolver);\n}", "des": "An IndexResolver that resolves IndexedData using a SpelExpressionParser."}
{"index": 6507, "repo": "spring-data-redis-3.1.2", "code": "public interface StringRecord extends MapRecord<String,String,String> {\n\t// Create a StringRecord from a Map of strings.\n\tstatic StringRecord of(Map<String,String> source);\n\t// Convert a MapRecord of strings into a StringRecord.\n\tstatic StringRecord of(MapRecord<String,String,String> source);\n\t// Create a new instance of Record with the given RecordId.\n\tStringRecord withId(RecordId id);\n\t// Create a new StringRecord with the associated stream key.\n\tStringRecord withStreamKey(String key);\n}", "des": "A Record within the stream backed by a collection of String field/value pairs."}
{"index": 6508, "repo": "spring-data-redis-3.1.2", "code": "public class StringRedisSerializer extends Object implements RedisSerializer<String> {\n\t// Deserialize an object from the given binary data.\n\tString deserialize(byte[] bytes);\n\tClass<?> getTargetType();\n\t// Serialize the given object to binary data.\n\tbyte[] serialize(String string);\n}", "des": "Simple String to byte[] (and back) serializer."}
{"index": 6509, "repo": "spring-data-redis-3.1.2", "code": "public interface Task extends SchedulingAwareRunnable, Cancelable {\n\t// Synchronous, blocking call that awaits until this Task becomes active.\n\tboolean awaitStart(Duration timeout);\n\t// Get the current lifecycle phase.\n\tTask.State getState();\n\tdefault boolean isActive();\n}", "des": "The actual Task to run within the StreamMessageListenerContainer."}
{"index": 6510, "repo": "spring-data-redis-3.1.2", "code": "public static enum Task.State extends Enum<Task.State> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Task.State valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Task.State[] values();\n}", "des": "The Task.State defining the lifecycle phase the actual Task."}
{"index": 6511, "repo": "spring-data-redis-3.1.2", "code": "public static enum ValueEncoding.RedisValueEncoding extends Enum<ValueEncoding.RedisValueEncoding> implements ValueEncoding {\n\tString raw();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ValueEncoding.RedisValueEncoding valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ValueEncoding.RedisValueEncoding[] values();\n}", "des": "Default ValueEncoding implementation of encodings used in Redis."}
{"index": 6512, "repo": "spring-boot-configuration-processor-3.1.1", "code": "public static enum ItemMetadata.ItemType extends Enum<ItemMetadata.ItemType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ItemMetadata.ItemType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ItemMetadata.ItemType[] values();\n}", "des": "The item type."}
{"index": 6513, "repo": "spring-shell-core-3.1.2", "code": "public abstract class AbstractTextComponent<T,C extends AbstractTextComponent.TextComponentContext<T,C>> extends AbstractComponent<C> {\n\t// Bind key map.\n\tprotected void bindKeyMap(org.jline.keymap.KeyMap<String> keyMap);\n\t// Gets a name.\n\tprotected String getName();\n\t// Run internal logic called from public run method.\n\tprotected C runInternal(C context);\n}", "des": "Base class for components which work on a simple text input."}
{"index": 6514, "repo": "spring-shell-core-3.1.2", "code": "public static enum AbstractTextComponent.TextComponentContext.MessageLevel extends Enum<AbstractTextComponent.TextComponentContext.MessageLevel> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic AbstractTextComponent.TextComponentContext.MessageLevel valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic AbstractTextComponent.TextComponentContext.MessageLevel[] values();\n}", "des": "Message levels which can be used to alter how message is shown."}
{"index": 6515, "repo": "spring-shell-core-3.1.2", "code": "public static record Ast.AstResult(List<NonterminalAstNode> nonterminalNodes, List<TerminalAstNode> terminalNodes) extends Record {\n\t// Indicates whether some other object is \"equal to\" this one.\n\tfinal boolean equals(Object o);\n\t// Returns the value of the nonterminalNodes record component.\n\tList<NonterminalAstNode> nonterminalNodes();\n\t// Returns the value of the terminalNodes record component.\n\tList<TerminalAstNode> terminalNodes();\n}", "des": "Representing result from tokens to ast tree generation."}
{"index": 6516, "repo": "spring-shell-core-3.1.2", "code": "public interface BaseInputSpec<T extends BaseInputSpec<T>> {\n\t// Usual this trick to get typed child.\n\tT getThis();\n\t// Sets order of this component.\n\tT order(int order);\n}", "des": "Base spec for other specs."}
{"index": 6517, "repo": "spring-shell-core-3.1.2", "code": "public interface CommandAlias {\n\t// Gets a command an alias.\n\tString getCommand();\n\t// Get group for an alias.\n\tString getGroup();\n\t// Gets an instance of a default CommandAlias.\n\tstatic CommandAlias of(String command, String group);\n}", "des": "Interface representing an alias in a command."}
{"index": 6518, "repo": "spring-shell-core-3.1.2", "code": "public static class CommandAlias.DefaultCommandAlias extends Object implements CommandAlias {\n\t// Gets a command an alias.\n\tString getCommand();\n\t// Get group for an alias.\n\tString getGroup();\n}", "des": "Default implementation of CommandAlias."}
{"index": 6519, "repo": "spring-shell-core-3.1.2", "code": "public static class CommandCatalog.DefaultCommandCatalog extends Object implements CommandCatalog {\n\t// Gets all CommandRegistrations mapped with their names.\n\tMap<String,CommandRegistration> getRegistrations();\n\t// Register a CommandRegistration.\n\tvoid register(CommandRegistration... registration);\n\t// Unregister a CommandRegistration by its command name.\n\tvoid unregister(String... commandName);\n\t// Unregister a CommandRegistration.\n\tvoid unregister(CommandRegistration... registration);\n}", "des": "Default implementation of a CommandCatalog."}
{"index": 6520, "repo": "spring-shell-core-3.1.2", "code": "public interface CommandExitCode {\n\t// Gets a function mappings from exceptions to exit codes.\n\tList<Function<Throwable,Integer>> getMappingFunctions();\n\t// Gets an instance of a default CommandExitCode.\n\tstatic CommandExitCode of();\n\t// Gets an instance of a default CommandExitCode.\n\tstatic CommandExitCode of(List<Function<Throwable,Integer>> functions);\n}", "des": "Interface representing an exit code in a command."}
{"index": 6521, "repo": "spring-shell-core-3.1.2", "code": "public class CommandNotFound extends RuntimeException {\n\tString getMessage();\n\t// Gets command registrations known when this error was created.\n\tMap<String,CommandRegistration> getRegistrations();\n\t// Gets a raw text input.\n\tString getText();\n\t// Gets a words in this exception.\n\tList<String> getWords();\n}", "des": "A result to be handled by the ResultHandler when no command could be mapped to user input"}
{"index": 6522, "repo": "spring-shell-core-3.1.2", "code": "public static interface CommandNotFoundMessageProvider.ProviderContext {\n\t// Gets a list of commands parsed.\n\tList<String> commands();\n\t// Gets an actual error.\n\tThrowable error();\n\t// Gets a command registrations.\n\tMap<String,CommandRegistration> registrations();\n\t// Gets a raw input text.\n\tString text();\n}", "des": "Context for CommandNotFoundResultHandler."}
{"index": 6523, "repo": "spring-shell-core-3.1.2", "code": "public interface CommandParser {\n\t// Gets an instance of a default command parser.\n\tstatic CommandParser of(org.springframework.core.convert.ConversionService conversionService, Map<String,CommandRegistration> registrations, ParserConfig config);\n\t// Parse options with a given arguments.\n\tCommandParser.CommandParserResults parse(String[] args);\n}", "des": "Interface parsing arguments for a CommandRegistration."}
{"index": 6524, "repo": "spring-shell-core-3.1.2", "code": "public static interface CommandParser.CommandParserResult {\n\t// Gets an instance of a default CommandParser.CommandParserResult.\n\tstatic CommandParser.CommandParserResult of(CommandOption option, Object value);\n\t// Gets the CommandOption.\n\tCommandOption option();\n\t// Gets the value.\n\tObject value();\n}", "des": "Result of a parsing CommandOption with an argument."}
{"index": 6525, "repo": "spring-shell-core-3.1.2", "code": "public static class CommandParser.DefaultCommandParserResult extends Object implements CommandParser.CommandParserResult {\n\t// Gets the CommandOption.\n\tCommandOption option();\n\t// Gets the value.\n\tObject value();\n}", "des": "Default implementation of a CommandParser.CommandParserResult."}
{"index": 6526, "repo": "spring-shell-core-3.1.2", "code": "public static class CommandParser.DefaultCommandParserResults extends Object implements CommandParser.CommandParserResults {\n\t// Gets parsing errors.\n\tList<CommandParser.CommandParserException> errors();\n\t// Gets the unmapped positional arguments.\n\tList<String> positional();\n\t// Gets the registration.\n\tCommandRegistration registration();\n\t// Gets the results.\n\tList<CommandParser.CommandParserResult> results();\n}", "des": "Default implementation of a CommandParser.CommandParserResults."}
{"index": 6527, "repo": "spring-shell-core-3.1.2", "code": "public static interface CommandRegistration.AliasSpec {\n\t// Return a builder for chaining.\n\tCommandRegistration.Builder and();\n\t// Define commands for an alias.\n\tCommandRegistration.AliasSpec command(String... commands);\n\t// Define group for an alias.\n\tCommandRegistration.AliasSpec group(String group);\n}", "des": "Spec defining an alias."}
{"index": 6528, "repo": "spring-shell-core-3.1.2", "code": "public static interface CommandRegistration.ErrorHandlingSpec {\n\t// Return a builder for chaining.\n\tCommandRegistration.Builder and();\n\t// Add CommandExceptionResolver.\n\tCommandRegistration.ErrorHandlingSpec resolver(CommandExceptionResolver resolver);\n}", "des": "Spec defining an error handling."}
{"index": 6529, "repo": "spring-shell-core-3.1.2", "code": "public static interface CommandRegistration.ExitCodeSpec {\n\t// Return a builder for chaining.\n\tCommandRegistration.Builder and();\n\t// Define mapping from exception to code.\n\tCommandRegistration.ExitCodeSpec map(Class<? extends Throwable> e, int code);\n\tCommandRegistration.ExitCodeSpec map(Function<Throwable,Integer> function);\n}", "des": "Spec defining an exit code."}
{"index": 6530, "repo": "spring-shell-core-3.1.2", "code": "public static enum CommandRegistration.OptionArity extends Enum<CommandRegistration.OptionArity> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic CommandRegistration.OptionArity valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic CommandRegistration.OptionArity[] values();\n}", "des": "Enumeration of option arity values."}
{"index": 6531, "repo": "spring-shell-core-3.1.2", "code": "public interface ComponentFlow {\n\t// Gets a new instance of an input wizard builder.\n\tstatic ComponentFlow.Builder builder();\n\t// Run a wizard and returns a result from it.\n\tComponentFlow.ComponentFlowResult run();\n}", "des": "Wizart providing an implementation which allows more polished way to ask various inputs from a user using shell style components for simple text/path input, single select and multi-select."}
{"index": 6532, "repo": "spring-shell-core-3.1.2", "code": "public class ConfirmationInput extends AbstractTextComponent<Boolean,ConfirmationInput.ConfirmationInputContext> {\n\t// Gets a real component context using common this trick.\n\tConfirmationInput.ConfirmationInputContext getThisContext(ComponentContext<?> context);\n\t// Read input.\n\tprotected boolean read(org.jline.keymap.BindingReader bindingReader, org.jline.keymap.KeyMap<String> keyMap, ConfirmationInput.ConfirmationInputContext context);\n}", "des": "Component for a confirmation question."}
{"index": 6533, "repo": "spring-shell-core-3.1.2", "code": "public class DefaultSelectItem extends Object implements SelectItem {\n\t// Returns if item is enabled.\n\tboolean enabled();\n\t// Gets an item\n\tString item();\n\t// Gets a name.\n\tString name();\n\t// Return if the item is selected.\n\tboolean selected();\n}", "des": "Default impl for SelectItem."}
{"index": 6534, "repo": "spring-shell-core-3.1.2", "code": "public class DefaultShellContext extends Object implements ShellContext {\n\t// Gets an interaction mode.\n\tInteractionMode getInteractionMode();\n\t// Sets an interaction mode.\n\tvoid setInteractionMode(InteractionMode interactionMode);\n}", "des": "Default implementation of a ShellContext."}
{"index": 6535, "repo": "spring-shell-core-3.1.2", "code": "public record DirectiveResult(String name, String value) extends Record {\n\t// Indicates whether some other object is \"equal to\" this one.\n\tfinal boolean equals(Object o);\n\t// Returns the value of the name record component.\n\tString name();\n\tstatic DirectiveResult of(String name, String value);\n\t// Returns the value of the value record component.\n\tString value();\n}", "des": "Encapsulating Directive with its fields, name and value."}
{"index": 6536, "repo": "spring-shell-core-3.1.2", "code": "public interface Input {\n\t// Return the input as entered by the user.\n\tString rawText();\n\t// Return the input as a list of parsed \"words\", having split the raw input according to parsing rules (for example, handling quoted portions of the readInput as a single \"word\")\n\tdefault List<String> words();\n}", "des": "Represents the input buffer to the shell."}
{"index": 6537, "repo": "spring-shell-core-3.1.2", "code": "public enum InteractionMode extends Enum<InteractionMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic InteractionMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic InteractionMode[] values();\n}", "des": "Enumeration for modes shell is operating."}
{"index": 6538, "repo": "spring-shell-core-3.1.2", "code": "@Order(0) public class InteractiveShellRunner extends Object implements ShellRunner {\n\t// Checks if a particular shell runner can execute.\n\tboolean canRun(org.springframework.boot.ApplicationArguments args);\n\t// Execute application.\n\tvoid run(org.springframework.boot.ApplicationArguments args);\n}", "des": "A ShellRunner that bootstraps the shell in interactive mode."}
{"index": 6539, "repo": "spring-shell-core-3.1.2", "code": "public static record Lexer.LexerResult(List<Token> tokens, List<MessageResult> messageResults) extends Record {\n\t// Indicates whether some other object is \"equal to\" this one.\n\tfinal boolean equals(Object o);\n\t// Returns the value of the messageResults record component.\n\tList<MessageResult> messageResults();\n\t// Returns the value of the tokens record component.\n\tList<Token> tokens();\n}", "des": "Representing result from Lexer tokenisation."}
{"index": 6540, "repo": "spring-shell-core-3.1.2", "code": "public abstract class OptionNameModifierSupport extends Object {\n\t// Convert given name to camelCase.\n\tstatic String toCamelCase(String name);\n\t// Convert given name to kebab-case.\n\tstatic String toKebabCase(String name);\n\t// Convert given name to PascalCase.\n\tstatic String toPascalCase(String name);\n\t// Convert given name to snake_case.\n\tstatic String toSnakeCase(String name);\n}", "des": "Support facilities for CommandRegistration.OptionNameModifier providing common naming types."}
{"index": 6541, "repo": "spring-shell-core-3.1.2", "code": "public enum ParserMessage extends Enum<ParserMessage> {\n\tString formatMessage(int position, Object... inserts);\n\tint getCode();\n\tParserMessage.Type getType();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ParserMessage valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ParserMessage[] values();\n}", "des": "Contains all the messages that can be produced during parsing."}
{"index": 6542, "repo": "spring-shell-core-3.1.2", "code": "public interface ResultHandlerService {\n\t// Handle result.\n\tvoid handle(Object result);\n\t// Handle result to the specified TypeDescriptor.\n\tvoid handle(Object result, org.springframework.core.convert.TypeDescriptor resultType);\n}", "des": "A service interface for result handling."}
{"index": 6543, "repo": "spring-shell-core-3.1.2", "code": "public enum ResultMode extends Enum<ResultMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ResultMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ResultMode[] values();\n}", "des": "Enumeration of a modes instructing how resultValue is handled."}
{"index": 6544, "repo": "spring-shell-core-3.1.2", "code": "@Order(-100) public class ScriptShellRunner extends Object implements ShellRunner {\n\t// Checks if a particular shell runner can execute.\n\tboolean canRun(org.springframework.boot.ApplicationArguments args);\n\t// Execute application.\n\tvoid run(org.springframework.boot.ApplicationArguments args);\n}", "des": "A ShellRunner that looks for process arguments that start with @, which are then interpreted as references to script files to run and exit."}
{"index": 6545, "repo": "spring-shell-core-3.1.2", "code": "@FunctionalInterface public interface SearchMatch {\n\t// Gets an instance of a builder for a SearchMatch.\n\tstatic SearchMatch.Builder builder();\n\t// Match a pattern into a given text.\n\tSearchMatchResult match(String text, String pattern);\n}", "des": "Interface defining a search match for text agains pattern."}
{"index": 6546, "repo": "spring-shell-core-3.1.2", "code": "public static interface SearchMatch.Builder {\n\t// Build instance of a SearchMatch.\n\tSearchMatch build();\n\t// Set a flag for caseSensitive.\n\tSearchMatch.Builder caseSensitive(boolean caseSensitive);\n\t// Set a flag for forward.\n\tSearchMatch.Builder forward(boolean forward);\n\t// Set a flag for normalize.\n\tSearchMatch.Builder normalize(boolean normalize);\n}", "des": "Defines an interface for SearchMatch."}
{"index": 6547, "repo": "spring-shell-core-3.1.2", "code": "public interface SelectItem {\n\t// Returns if item is enabled.\n\tboolean enabled();\n\t// Gets an item\n\tString item();\n\t// Gets a name.\n\tString name();\n\tstatic SelectItem of(String name, String item);\n\tstatic SelectItem of(String name, String item, boolean enabled, boolean selected);\n\t// Return if the item is selected.\n\tboolean selected();\n}", "des": "Interface for selectitem contract in selectors."}
{"index": 6548, "repo": "spring-shell-core-3.1.2", "code": "public interface ShellContext {\n\t// Gets an interaction mode.\n\tInteractionMode getInteractionMode();\n\t// Sets an interaction mode.\n\tvoid setInteractionMode(InteractionMode interactionMode);\n}", "des": "Interface defining a contract for a context which allows to loosely connect different components together and keep things alive between commands."}
{"index": 6549, "repo": "spring-shell-core-3.1.2", "code": "public interface ShellRunner {\n\t// Checks if a particular shell runner can execute.\n\tboolean canRun(org.springframework.boot.ApplicationArguments args);\n\t// Execute application.\n\tvoid run(org.springframework.boot.ApplicationArguments args);\n}", "des": "Interface for shell runners."}
{"index": 6550, "repo": "spring-shell-core-3.1.2", "code": "public class StringInput extends AbstractTextComponent<String,StringInput.StringInputContext> {\n\t// Gets a real component context using common this trick.\n\tStringInput.StringInputContext getThisContext(ComponentContext<?> context);\n\t// Read input.\n\tprotected boolean read(org.jline.keymap.BindingReader bindingReader, org.jline.keymap.KeyMap<String> keyMap, StringInput.StringInputContext context);\n\t// Sets a mask character for input and result value.\n\tvoid setMaskCharacter(Character maskCharacter);\n}", "des": "Component for a simple string input."}
{"index": 6551, "repo": "spring-shell-core-3.1.2", "code": "public class TemplateExecutor extends Object {\n\t// Render template with a given attributes.\n\torg.jline.utils.AttributedString render(String template, Map<String,Object> attributes);\n\t// Render template group with a given attributes expecting to find instance named main.\n\torg.jline.utils.AttributedString renderGroup(String template, Map<String,Object> attributes);\n}", "des": "Template executor which knows to use styling."}
{"index": 6552, "repo": "spring-shell-core-3.1.2", "code": "public interface Theme {\n\t// Gets a theme name.\n\tString getName();\n\t// Gets a theme settings.\n\tThemeSettings getSettings();\n\t// Create a Theme.\n\tstatic Theme of(String name, ThemeSettings themeSettings);\n}", "des": "Contract representing a theme with its name and settings."}
{"index": 6553, "repo": "spring-shell-core-3.1.2", "code": "public class ThemeRegistry extends Object {\n\t// Gets a theme from a registry.\n\tTheme get(String name);\n\t// Register a theme.\n\tvoid register(Theme theme);\n}", "des": "Registry which stores Theme's with its name."}
{"index": 6554, "repo": "spring-shell-core-3.1.2", "code": "public class ThemeResolver extends Object {\n\t// Evaluate expression.\n\torg.jline.utils.AttributedString evaluateExpression(String expression);\n\t// Resolve figure from a tag with activated theme.\n\tString resolveFigureTag(String tag);\n\t// Resolve AttributedStyle from a spec.\n\torg.jline.utils.AttributedStyle resolveStyle(String spec);\n\t// Resolve style from a tag with activated theme.\n\tString resolveStyleTag(String tag);\n}", "des": "Service which helps to do various things with styles."}
{"index": 6555, "repo": "spring-shell-core-3.1.2", "code": "public abstract class ThemeSettings extends Object {\n\t// Gets a default theme settings.\n\tstatic ThemeSettings defaults();\n\t// Gets a dump theme settings.\n\tstatic ThemeSettings dump();\n\t// Gets a FigureSettings.\n\tFigureSettings figures();\n\t// Gets a StyleSettings.\n\tStyleSettings styles();\n}", "des": "Base class defining a settings for themes."}
{"index": 6556, "repo": "spring-context-6.0.11", "code": "@Configuration(proxyBeanMethods=false) public abstract class AbstractCachingConfiguration extends Object implements ImportAware {\n\t// Set the annotation metadata of the importing @Configuration class.\n\tvoid setImportMetadata(org.springframework.core.type.AnnotationMetadata importMetadata);\n\t// Extract the configuration from the nominated CachingConfigurer.\n\tprotected void useCachingConfigurer(AbstractCachingConfiguration.CachingConfigurerSupplier cachingConfigurerSupplier);\n}", "des": "Abstract base @Configuration class providing common structure for enabling Spring's annotation-driven cache management capability."}
{"index": 6557, "repo": "spring-context-6.0.11", "code": "public abstract class AbstractJmxAttribute extends Object {\n\t// Return a currency time limit for this attribute.\n\tint getCurrencyTimeLimit();\n\t// Return a description for this attribute.\n\tString getDescription();\n\t// Set a currency time limit for this attribute.\n\tvoid setCurrencyTimeLimit(int currencyTimeLimit);\n\t// Set a description for this attribute.\n\tvoid setDescription(String description);\n}", "des": "Base class for all JMX metadata classes."}
{"index": 6558, "repo": "spring-context-6.0.11", "code": "public abstract class AbstractNumberFormatter extends Object implements Formatter<Number> {\n\t// Obtain a concrete NumberFormat for the specified locale.\n\tprotected abstract NumberFormat getNumberFormat(Locale locale);\n\t// Parse a text String to produce a T.\n\tNumber parse(String text, Locale locale);\n\t// Print the object of type T for display.\n\tString print(Number number, Locale locale);\n\t// Specify whether parsing is to be lenient.\n\tvoid setLenient(boolean lenient);\n}", "des": "Abstract formatter for Numbers, providing a AbstractNumberFormatter.getNumberFormat(java.util.Locale) template method."}
{"index": 6559, "repo": "spring-context-6.0.11", "code": "public enum AdviceMode extends Enum<AdviceMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic AdviceMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic AdviceMode[] values();\n}", "des": "Enumeration used to determine whether JDK proxy-based or AspectJ weaving-based advice should be applied."}
{"index": 6560, "repo": "spring-context-6.0.11", "code": "public interface AnnotationConfigRegistry {\n\t// Register one or more component classes to be processed.\n\tvoid register(Class<?>... componentClasses);\n\t// Perform a scan within the specified base packages.\n\tvoid scan(String... basePackages);\n}", "des": "Common interface for annotation config application contexts, defining AnnotationConfigRegistry.register(java.lang.Class<?>...) and AnnotationConfigRegistry.scan(java.lang.String...) methods."}
{"index": 6561, "repo": "spring-context-6.0.11", "code": "public interface AnnotationFormatterFactory<A extends Annotation> {\n\t// The types of fields that may be annotated with the <A> annotation.\n\tSet<Class<?>> getFieldTypes();\n\t// Get the Parser to parse a submitted value for a field of fieldType annotated with annotation.\n\tParser<?> getParser(A annotation, Class<?> fieldType);\n\t// Get the Printer to print the value of a field of fieldType annotated with annotation.\n\tPrinter<?> getPrinter(A annotation, Class<?> fieldType);\n}", "des": "A factory that creates formatters to format values of fields annotated with a particular Annotation."}
{"index": 6562, "repo": "spring-context-6.0.11", "code": "public class AnnotationMBeanExporter extends MBeanExporter {\n\t// This callback is only required for resolution of bean names in the \"beans\" Map and for autodetection of MBeans (in the latter case, a ListableBeanFactory is required).\n\tvoid setBeanFactory(org.springframework.beans.factory.BeanFactory beanFactory);\n\t// Specify the default domain to be used for generating ObjectNames when no source-level metadata has been specified.\n\tvoid setDefaultDomain(String defaultDomain);\n}", "des": "Convenient subclass of Spring's standard MBeanExporter, activating annotation usage for JMX exposure of Spring beans: ManagedResource, ManagedAttribute, ManagedOperation, etc."}
{"index": 6563, "repo": "spring-context-6.0.11", "code": "public class AnnotationScopeMetadataResolver extends Object implements ScopeMetadataResolver {\n\t// Resolve the ScopeMetadata appropriate to the supplied bean definition.\n\tScopeMetadata resolveScopeMetadata(org.springframework.beans.factory.config.BeanDefinition definition);\n\t// Set the type of annotation that is checked for by this AnnotationScopeMetadataResolver.\n\tvoid setScopeAnnotationType(Class<? extends Annotation> scopeAnnotationType);\n}", "des": "A ScopeMetadataResolver implementation that by default checks for the presence of Spring's @Scope annotation on the bean class."}
{"index": 6564, "repo": "spring-context-6.0.11", "code": "@FunctionalInterface public interface ApplicationEventPublisher {\n\t// Notify all matching listeners registered with this application of an event.\n\tvoid publishEvent(Object event);\n\t// Notify all matching listeners registered with this application of an application event.\n\tdefault void publishEvent(ApplicationEvent event);\n}", "des": "Interface that encapsulates event publication functionality."}
{"index": 6565, "repo": "spring-context-6.0.11", "code": "@FunctionalInterface public interface ApplicationListener<E extends ApplicationEvent> extends EventListener {\n\t// Create a new ApplicationListener for the given payload consumer.\n\tstatic <T> ApplicationListener<PayloadApplicationEvent<T>> forPayload(Consumer<T> consumer);\n\t// Handle an application event.\n\tvoid onApplicationEvent(E event);\n}", "des": "Interface to be implemented by application event listeners."}
{"index": 6566, "repo": "spring-context-6.0.11", "code": "public interface AsyncConfigurer {\n\t// The Executor instance to be used when processing async method invocations.\n\tdefault Executor getAsyncExecutor();\n\t// The AsyncUncaughtExceptionHandler instance to be used when an exception is thrown during an asynchronous method execution with void return type.\n\tdefault org.springframework.aop.interceptor.AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler();\n}", "des": "Interface to be implemented by @Configuration classes annotated with @EnableAsync that wish to customize the Executor instance used when processing async method invocations or the AsyncUncaughtExceptionHandler instance used to process exception thrown from async method with void return type."}
{"index": 6567, "repo": "spring-context-6.0.11", "code": "public class BeanFactoryCacheOperationSourceAdvisor extends org.springframework.aop.support.AbstractBeanFactoryPointcutAdvisor {\n\torg.springframework.aop.Pointcut getPointcut();\n\t// Set the cache operation attribute source which is used to find cache attributes.\n\tvoid setCacheOperationSource(CacheOperationSource cacheOperationSource);\n\t// Set the ClassFilter to use for this pointcut.\n\tvoid setClassFilter(org.springframework.aop.ClassFilter classFilter);\n}", "des": "Advisor driven by a CacheOperationSource, used to include a cache advice bean for methods that are cacheable."}
{"index": 6568, "repo": "spring-context-6.0.11", "code": "public class BeanPropertyBindingResult extends AbstractPropertyBindingResult implements Serializable {\n\t// Create a new BeanWrapper for the underlying target object.\n\tprotected org.springframework.beans.BeanWrapper createBeanWrapper();\n\t// Returns the BeanWrapper that this instance uses.\n\tfinal org.springframework.beans.ConfigurablePropertyAccessor getPropertyAccessor();\n\t// Return the wrapped target object.\n\tfinal Object getTarget();\n}", "des": "Default implementation of the Errors and BindingResult interfaces, for the registration and evaluation of binding errors on JavaBean objects."}
{"index": 6569, "repo": "spring-context-6.0.11", "code": "public interface BindingErrorProcessor {\n\t// Apply the missing field error to the given BindException.\n\tvoid processMissingFieldError(String missingField, BindingResult bindingResult);\n\t// Translate the given PropertyAccessException to an appropriate error registered on the given Errors instance.\n\tvoid processPropertyAccessException(org.springframework.beans.PropertyAccessException ex, BindingResult bindingResult);\n}", "des": "Strategy for processing DataBinder's missing field errors, and for translating a PropertyAccessException to a FieldError."}
{"index": 6570, "repo": "spring-context-6.0.11", "code": "public abstract class BindingResultUtils extends Object {\n\t// Find the BindingResult for the given name in the given model.\n\tstatic BindingResult getBindingResult(Map<?,?> model, String name);\n\t// Find a required BindingResult for the given name in the given model.\n\tstatic BindingResult getRequiredBindingResult(Map<?,?> model, String name);\n}", "des": "Convenience methods for looking up BindingResults in a model Map."}
{"index": 6571, "repo": "spring-context-6.0.11", "code": "public class BshScriptEvaluator extends Object implements ScriptEvaluator, org.springframework.beans.factory.BeanClassLoaderAware {\n\t// Evaluate the given script.\n\tObject evaluate(ScriptSource script);\n\t// Evaluate the given script with the given arguments.\n\tObject evaluate(ScriptSource script, Map<String,Object> arguments);\n\tvoid setBeanClassLoader(ClassLoader classLoader);\n}", "des": "BeanShell-based implementation of Spring's ScriptEvaluator strategy interface."}
{"index": 6572, "repo": "spring-context-6.0.11", "code": "public interface CacheManager {\n\t// Get the cache associated with the given name.\n\tCache getCache(String name);\n\t// Get a collection of the cache names known by this manager.\n\tCollection<String> getCacheNames();\n}", "des": "Spring's central cache manager SPI."}
{"index": 6573, "repo": "spring-context-6.0.11", "code": "public abstract class CacheOperation extends Object implements BasicOperation {\n\t// This implementation compares the toString() results.\n\tboolean equals(Object other);\n\tString getCacheManager();\n\t// Return the cache name(s) associated with the operation.\n\tSet<String> getCacheNames();\n\tString getCacheResolver();\n\tString getCondition();\n\tString getKey();\n\tString getKeyGenerator();\n\tString getName();\n}", "des": "Base class for cache operations."}
{"index": 6574, "repo": "spring-context-6.0.11", "code": "public interface CacheOperationInvocationContext<O extends BasicOperation> {\n\t// Return the argument list used to invoke the method.\n\tObject[] getArgs();\n\t// Return the method which was invoked.\n\tMethod getMethod();\n\t// Return the cache operation.\n\tO getOperation();\n\t// Return the target instance on which the method was invoked.\n\tObject getTarget();\n}", "des": "Representation of the context of the invocation of a cache operation."}
{"index": 6575, "repo": "spring-context-6.0.11", "code": "public interface CacheOperationSource {\n\t// Return the collection of cache operations for this method, or null if the method contains no cacheable annotations.\n\tCollection<CacheOperation> getCacheOperations(Method method, Class<?> targetClass);\n\t// Determine whether the given class is a candidate for cache operations in the metadata format of this CacheOperationSource.\n\tdefault boolean isCandidateClass(Class<?> targetClass);\n}", "des": "Interface used by CacheInterceptor."}
{"index": 6576, "repo": "spring-context-6.0.11", "code": "protected abstract static class CommonAnnotationBeanPostProcessor.LookupElement extends org.springframework.beans.factory.annotation.InjectionMetadata.InjectedElement {\n\t// Build a DependencyDescriptor for the underlying field/method.\n\tfinal org.springframework.beans.factory.config.DependencyDescriptor getDependencyDescriptor();\n\t// Return the desired type for the lookup.\n\tfinal Class<?> getLookupType();\n\t// Return the resource name for the lookup.\n\tfinal String getName();\n}", "des": "Class representing generic injection information about an annotated field or setter method, supporting @Resource and related annotations."}
{"index": 6577, "repo": "spring-context-6.0.11", "code": "public static enum ConfigurationCondition.ConfigurationPhase extends Enum<ConfigurationCondition.ConfigurationPhase> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ConfigurationCondition.ConfigurationPhase valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ConfigurationCondition.ConfigurationPhase[] values();\n}", "des": "The various configuration phases where the condition could be evaluated."}
{"index": 6578, "repo": "spring-context-6.0.11", "code": "public final class CronExpression extends Object {\n\tboolean equals(Object other);\n\t// Determine whether the given string represents a valid cron expression.\n\tstatic boolean isValidExpression(String expression);\n\t// Calculate the next Temporal that matches this expression.\n\t<T extends Temporal & Comparable<? super T>>T next(T temporal);\n\t// Parse the given crontab expression string into a CronExpression.\n\tstatic CronExpression parse(String expression);\n}", "des": "Representation of a crontab expression that can calculate the next time it matches."}
{"index": 6579, "repo": "spring-context-6.0.11", "code": "public class CronTrigger extends Object implements Trigger {\n\tboolean equals(Object other);\n\t// Return the cron pattern that this trigger has been built with.\n\tString getExpression();\n\t// Determine the next execution time according to the given trigger context.\n\tInstant nextExecution(TriggerContext triggerContext);\n}", "des": "Trigger implementation for cron expressions."}
{"index": 6580, "repo": "spring-context-6.0.11", "code": "public class CurrencyUnitFormatter extends Object implements Formatter<javax.money.CurrencyUnit> {\n\t// Parse a text String to produce a T.\n\tjavax.money.CurrencyUnit parse(String text, Locale locale);\n\t// Print the object of type T for display.\n\tString print(javax.money.CurrencyUnit object, Locale locale);\n}", "des": "Formatter for JSR-354 CurrencyUnit values, from and to currency code Strings."}
{"index": 6581, "repo": "spring-context-6.0.11", "code": "public class DateFormatterRegistrar extends Object implements FormatterRegistrar {\n\t// Add date converters to the specified registry.\n\tstatic void addDateConverters(org.springframework.core.convert.converter.ConverterRegistry converterRegistry);\n\t// Register Formatters and Converters with a FormattingConversionService through a FormatterRegistry SPI.\n\tvoid registerFormatters(FormatterRegistry registry);\n\t// Set a global date formatter to register.\n\tvoid setFormatter(DateFormatter dateFormatter);\n}", "des": "Configures basic date formatting for use with Spring, primarily for DateTimeFormat declarations."}
{"index": 6582, "repo": "spring-context-6.0.11", "code": "public class DateTimeContext extends Object {\n\t// Return the user's chronology (calendar system), if any.\n\tChronology getChronology();\n\t// Get the DateTimeFormatter with this context's settings applied to the base formatter.\n\tDateTimeFormatter getFormatter(DateTimeFormatter formatter);\n\t// Return the user's time zone, if any.\n\tZoneId getTimeZone();\n\t// Set the user's chronology (calendar system).\n\tvoid setChronology(Chronology chronology);\n\t// Set the user's time zone.\n\tvoid setTimeZone(ZoneId timeZone);\n}", "des": "A context that holds user-specific java.time (JSR-310) settings such as the user's Chronology (calendar system) and time zone."}
{"index": 6583, "repo": "spring-context-6.0.11", "code": "public static enum DateTimeFormat.ISO extends Enum<DateTimeFormat.ISO> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic DateTimeFormat.ISO valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic DateTimeFormat.ISO[] values();\n}", "des": "Common ISO date time format patterns."}
{"index": 6584, "repo": "spring-context-6.0.11", "code": "public class DefaultEventListenerFactory extends Object implements EventListenerFactory, org.springframework.core.Ordered {\n\t// Create an ApplicationListener for the specified method.\n\tApplicationListener<?> createApplicationListener(String beanName, Class<?> type, Method method);\n\tint getOrder();\n\tvoid setOrder(int order);\n\t// Specify if this factory supports the specified Method.\n\tboolean supportsMethod(Method method);\n}", "des": "Default EventListenerFactory implementation that supports the regular EventListener annotation."}
{"index": 6585, "repo": "spring-context-6.0.11", "code": "public static interface DeferredImportSelector.Group {\n\t// Process the AnnotationMetadata of the importing @Configuration class using the specified DeferredImportSelector.\n\tvoid process(org.springframework.core.type.AnnotationMetadata metadata, DeferredImportSelector selector);\n\t// Return the entries of which class(es) should be imported for this group.\n\tIterable<DeferredImportSelector.Group.Entry> selectImports();\n}", "des": "Interface used to group results from different import selectors."}
{"index": 6586, "repo": "spring-context-6.0.11", "code": "public static class DeferredImportSelector.Group.Entry extends Object {\n\tboolean equals(Object other);\n\t// Return the fully qualified name of the class to import.\n\tString getImportClassName();\n\t// Return the AnnotationMetadata of the importing Configuration class.\n\torg.springframework.core.type.AnnotationMetadata getMetadata();\n}", "des": "An entry that holds the AnnotationMetadata of the importing Configuration class and the class name to import."}
{"index": 6587, "repo": "spring-context-6.0.11", "code": "public class DirectFieldBindingResult extends AbstractPropertyBindingResult {\n\t// Create a new DirectFieldAccessor for the underlying target object.\n\tprotected org.springframework.beans.ConfigurablePropertyAccessor createDirectFieldAccessor();\n\t// Returns the DirectFieldAccessor that this instance uses.\n\tfinal org.springframework.beans.ConfigurablePropertyAccessor getPropertyAccessor();\n\t// Return the wrapped target object.\n\tfinal Object getTarget();\n}", "des": "Special implementation of the Errors and BindingResult interfaces, supporting registration and evaluation of binding errors on value objects."}
{"index": 6588, "repo": "spring-context-6.0.11", "code": "public class EmbeddedValueResolutionSupport extends Object implements EmbeddedValueResolverAware {\n\t// Resolve the given embedded value through this instance's StringValueResolver.\n\tprotected String resolveEmbeddedValue(String value);\n\t// Set the StringValueResolver to use for resolving embedded definition values.\n\tvoid setEmbeddedValueResolver(org.springframework.util.StringValueResolver resolver);\n}", "des": "Convenient base class for components with a need for embedded value resolution (i.e."}
{"index": 6589, "repo": "spring-context-6.0.11", "code": "public static enum EnableLoadTimeWeaving.AspectJWeaving extends Enum<EnableLoadTimeWeaving.AspectJWeaving> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic EnableLoadTimeWeaving.AspectJWeaving valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic EnableLoadTimeWeaving.AspectJWeaving[] values();\n}", "des": "AspectJ weaving enablement options."}
{"index": 6590, "repo": "spring-context-6.0.11", "code": "public interface EventListenerFactory {\n\t// Create an ApplicationListener for the specified method.\n\tApplicationListener<?> createApplicationListener(String beanName, Class<?> type, Method method);\n\t// Specify if this factory supports the specified Method.\n\tboolean supportsMethod(Method method);\n}", "des": "Strategy interface for creating ApplicationListener for methods annotated with EventListener."}
{"index": 6591, "repo": "spring-context-6.0.11", "code": "public class FieldError extends ObjectError {\n\tboolean equals(Object other);\n\t// Return the affected field of the object.\n\tString getField();\n\t// Return the rejected field value.\n\tObject getRejectedValue();\n\t// Return whether this error represents a binding failure (like a type mismatch); otherwise it is a validation failure.\n\tboolean isBindingFailure();\n}", "des": "Encapsulates a field error, that is, a reason for rejecting a specific field value."}
{"index": 6592, "repo": "spring-context-6.0.11", "code": "public enum FilterType extends Enum<FilterType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic FilterType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic FilterType[] values();\n}", "des": "Enumeration of the type filters that may be used in conjunction with @ComponentScan."}
{"index": 6593, "repo": "spring-context-6.0.11", "code": "public interface GenericApplicationListener extends SmartApplicationListener {\n\t// Overrides SmartApplicationListener.supportsEventType(Class) with delegation to supportsEventType(ResolvableType).\n\tdefault boolean supportsEventType(Class<? extends ApplicationEvent> eventType);\n\t// Determine whether this listener actually supports the given event type.\n\tboolean supportsEventType(org.springframework.core.ResolvableType eventType);\n}", "des": "Extended variant of the standard ApplicationListener interface, exposing further metadata such as the supported event and source type."}
{"index": 6594, "repo": "spring-context-6.0.11", "code": "public interface HierarchicalMessageSource extends MessageSource {\n\t// Return the parent of this MessageSource, or null if none.\n\tMessageSource getParentMessageSource();\n\t// Set the parent that will be used to try to resolve messages that this object can't resolve.\n\tvoid setParentMessageSource(MessageSource parent);\n}", "des": "Sub-interface of MessageSource to be implemented by objects that can resolve messages hierarchically."}
{"index": 6595, "repo": "spring-context-6.0.11", "code": "public interface ImportSelector {\n\t// Return a predicate for excluding classes from the import candidates, to be transitively applied to all classes found through this selector's imports.\n\tdefault Predicate<String> getExclusionFilter();\n\t// Select and return the names of which class(es) should be imported based on the AnnotationMetadata of the importing @Configuration class.\n\tString[] selectImports(org.springframework.core.type.AnnotationMetadata importingClassMetadata);\n}", "des": "Interface to be implemented by types that determine which @Configuration class(es) should be imported based on a given selection criteria, usually one or more annotation attributes."}
{"index": 6596, "repo": "spring-context-6.0.11", "code": "public class InstantFormatter extends Object implements Formatter<Instant> {\n\t// Parse a text String to produce a T.\n\tInstant parse(String text, Locale locale);\n\t// Print the object of type T for display.\n\tString print(Instant object, Locale locale);\n}", "des": "Formatter implementation for a JSR-310 Instant, following JSR-310's parsing rules for an Instant (that is, not using a configurable DateTimeFormatter): accepting the default ISO_INSTANT format as well as RFC_1123_DATE_TIME (which is commonly used for HTTP date header values), as of Spring 4.3."}
{"index": 6597, "repo": "spring-context-6.0.11", "code": "public class IntervalTask extends Task {\n\t// Deprecated. as of 6.0, in favor of getInitialDelayDuration()\n\tlong getInitialDelay();\n\t// Return the initial delay before first execution of the task.\n\tDuration getInitialDelayDuration();\n\t// Deprecated. as of 6.0, in favor of getIntervalDuration()\n\tlong getInterval();\n\t// Return how often the task should be executed.\n\tDuration getIntervalDuration();\n}", "des": "Task implementation defining a Runnable to be executed at a given millisecond interval which may be treated as fixed-rate or fixed-delay depending on context."}
{"index": 6598, "repo": "spring-context-6.0.11", "code": "public class JndiAccessor extends Object {\n\t// Return the JNDI environment to use for JNDI lookups.\n\tProperties getJndiEnvironment();\n\t// Return the JNDI template to use for JNDI lookups.\n\tJndiTemplate getJndiTemplate();\n\t// Set the JNDI environment to use for JNDI lookups.\n\tvoid setJndiEnvironment(Properties jndiEnvironment);\n\t// Set the JNDI template to use for JNDI lookups.\n\tvoid setJndiTemplate(JndiTemplate jndiTemplate);\n}", "des": "Convenient superclass for JNDI accessors, providing \"jndiTemplate\" and \"jndiEnvironment\" bean properties."}
{"index": 6599, "repo": "spring-context-6.0.11", "code": "public class JndiObjectTargetSource extends JndiObjectLocator implements org.springframework.aop.TargetSource {\n\tvoid afterPropertiesSet();\n\tObject getTarget();\n\tClass<?> getTargetClass();\n\tboolean isStatic();\n\tvoid releaseTarget(Object target);\n\t// Set whether to cache the JNDI object once it has been located.\n\tvoid setCache(boolean cache);\n\t// Set whether to look up the JNDI object on startup.\n\tvoid setLookupOnStartup(boolean lookupOnStartup);\n}", "des": "AOP TargetSource that provides configurable JNDI lookups for getTarget() calls."}
{"index": 6600, "repo": "spring-context-6.0.11", "code": "public interface Lifecycle {\n\t// Check whether this component is currently running.\n\tboolean isRunning();\n\t// Start this component.\n\tvoid start();\n\t// Stop this component, typically in a synchronous fashion, such that the component is fully stopped upon return of this method.\n\tvoid stop();\n}", "des": "A common interface defining methods for start/stop lifecycle control."}
{"index": 6601, "repo": "spring-context-6.0.11", "code": "public interface LifecycleProcessor extends Lifecycle {\n\t// Notification of context close phase, e.g.\n\tvoid onClose();\n\t// Notification of context refresh, e.g.\n\tvoid onRefresh();\n}", "des": "Strategy interface for processing Lifecycle beans within the ApplicationContext."}
{"index": 6602, "repo": "spring-context-6.0.11", "code": "public interface LoadTimeWeaver {\n\t// Add a ClassFileTransformer to be applied by this LoadTimeWeaver.\n\tvoid addTransformer(ClassFileTransformer transformer);\n\t// Return a ClassLoader that supports instrumentation through AspectJ-style load-time weaving based on user-defined ClassFileTransformers.\n\tClassLoader getInstrumentableClassLoader();\n\t// Return a throwaway ClassLoader, enabling classes to be loaded and inspected without affecting the parent ClassLoader.\n\tClassLoader getThrowawayClassLoader();\n}", "des": "Defines the contract for adding one or more ClassFileTransformers to a ClassLoader."}
{"index": 6603, "repo": "spring-context-6.0.11", "code": "public class ManagedAttribute extends AbstractJmxAttribute {\n\t// Return the default value of this attribute.\n\tObject getDefaultValue();\n\tint getPersistPeriod();\n\tString getPersistPolicy();\n\t// Set the default value of this attribute.\n\tvoid setDefaultValue(Object defaultValue);\n\tvoid setPersistPeriod(int persistPeriod);\n\tvoid setPersistPolicy(String persistPolicy);\n}", "des": "Metadata that indicates to expose a given bean property as JMX attribute."}
{"index": 6604, "repo": "spring-context-6.0.11", "code": "public class MapBindingResult extends AbstractBindingResult implements Serializable {\n\t// Extract the actual field value for the given field.\n\tprotected Object getActualFieldValue(String field);\n\t// Return the wrapped target object.\n\tfinal Object getTarget();\n\t// Return the target Map to bind onto.\n\tfinal Map<?,?> getTargetMap();\n}", "des": "Map-based implementation of the BindingResult interface, supporting registration and evaluation of binding errors on Map attributes."}
{"index": 6605, "repo": "spring-context-6.0.11", "code": "public interface MBeanExporterListener {\n\t// Called by MBeanExporter after an MBean has been successfully registered with an MBeanServer.\n\tvoid mbeanRegistered(ObjectName objectName);\n\t// Called by MBeanExporter after an MBean has been successfully unregistered from an MBeanServer.\n\tvoid mbeanUnregistered(ObjectName objectName);\n}", "des": "A listener that allows application code to be notified when an MBean is registered and unregistered via an MBeanExporter."}
{"index": 6606, "repo": "spring-context-6.0.11", "code": "public interface MBeanExportOperations {\n\t// Register the supplied resource with JMX.\n\tObjectName registerManagedResource(Object managedResource);\n\t// Register the supplied resource with JMX.\n\tvoid registerManagedResource(Object managedResource, ObjectName objectName);\n\t// Remove the specified MBean from the underlying MBeanServer registry.\n\tvoid unregisterManagedResource(ObjectName objectName);\n}", "des": "Interface that defines the set of MBean export operations that are intended to be accessed by application developers during application runtime."}
{"index": 6607, "repo": "spring-context-6.0.11", "code": "public interface MessageCodesResolver {\n\t// Build message codes for the given error code and object name.\n\tString[] resolveMessageCodes(String errorCode, String objectName);\n\t// Build message codes for the given error code and field specification.\n\tString[] resolveMessageCodes(String errorCode, String objectName, String field, Class<?> fieldType);\n}", "des": "Strategy interface for building message codes from validation error codes."}
{"index": 6608, "repo": "spring-context-6.0.11", "code": "public interface MessageSource {\n\t// Try to resolve the message.\n\tString getMessage(String code, Object[] args, String defaultMessage, Locale locale);\n\t// Try to resolve the message.\n\tString getMessage(String code, Object[] args, Locale locale);\n\t// Try to resolve the message using all the attributes contained within the MessageSourceResolvable argument that was passed in.\n\tString getMessage(MessageSourceResolvable resolvable, Locale locale);\n}", "des": "Strategy interface for resolving messages, with support for the parameterization and internationalization of such messages."}
{"index": 6609, "repo": "spring-context-6.0.11", "code": "@FunctionalInterface public interface MessageSourceResolvable {\n\t// Return the array of arguments to be used to resolve this message.\n\tdefault Object[] getArguments();\n\t// Return the codes to be used to resolve this message, in the order that they should get tried.\n\tString[] getCodes();\n\t// Return the default message to be used to resolve this message.\n\tdefault String getDefaultMessage();\n}", "des": "Interface for objects that are suitable for message resolution in a MessageSource."}
{"index": 6610, "repo": "spring-context-6.0.11", "code": "public enum MetricType extends Enum<MetricType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic MetricType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic MetricType[] values();\n}", "des": "Represents how the measurement values of a ManagedMetric will change over time."}
{"index": 6611, "repo": "spring-context-6.0.11", "code": "public class NamedCacheResolver extends AbstractCacheResolver {\n\t// Provide the name of the cache(s) to resolve against the current cache manager.\n\tprotected Collection<String> getCacheNames(CacheOperationInvocationContext<?> context);\n\t// Set the cache name(s) that this resolver should use.\n\tvoid setCacheNames(Collection<String> cacheNames);\n}", "des": "A CacheResolver that forces the resolution to a configurable collection of name(s) against a given CacheManager."}
{"index": 6612, "repo": "spring-context-6.0.11", "code": "public class NoOpCacheManager extends Object implements CacheManager {\n\t// This implementation always returns a Cache implementation that will not store items.\n\tCache getCache(String name);\n\t// This implementation returns the name of the caches previously requested.\n\tCollection<String> getCacheNames();\n}", "des": "A basic, no operation CacheManager implementation suitable for disabling caching, typically used for backing cache declarations without an actual backing store."}
{"index": 6613, "repo": "spring-context-6.0.11", "code": "public static enum NumberFormat.Style extends Enum<NumberFormat.Style> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic NumberFormat.Style valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic NumberFormat.Style[] values();\n}", "des": "Common number format styles."}
{"index": 6614, "repo": "spring-context-6.0.11", "code": "public class NumberStyleFormatter extends AbstractNumberFormatter {\n\t// Obtain a concrete NumberFormat for the specified locale.\n\tNumberFormat getNumberFormat(Locale locale);\n\t// Specify the pattern to use to format number values.\n\tvoid setPattern(String pattern);\n}", "des": "A general-purpose number formatter using NumberFormat's number style."}
{"index": 6615, "repo": "spring-context-6.0.11", "code": "public class RefreshableScriptTargetSource extends org.springframework.aop.target.dynamic.BeanFactoryRefreshableTargetSource {\n\t// Obtain a fresh target object, retrieving a FactoryBean if necessary.\n\tprotected Object obtainFreshBean(org.springframework.beans.factory.BeanFactory beanFactory, String beanName);\n\t// Determine whether a refresh is required through calling ScriptFactory's requiresScriptedObjectRefresh method.\n\tprotected boolean requiresRefresh();\n}", "des": "Subclass of BeanFactoryRefreshableTargetSource that determines whether a refresh is required through the given ScriptFactory."}
{"index": 6616, "repo": "spring-context-6.0.11", "code": "public enum RegistrationPolicy extends Enum<RegistrationPolicy> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic RegistrationPolicy valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic RegistrationPolicy[] values();\n}", "des": "Indicates registration behavior when attempting to register an MBean that already exists."}
{"index": 6617, "repo": "spring-context-6.0.11", "code": "public class ScheduledMethodRunnable extends Object implements Runnable {\n\t// Return the target method to call.\n\tMethod getMethod();\n\t// Return the target instance to call the method on.\n\tObject getTarget();\n\tvoid run();\n}", "des": "Variant of MethodInvokingRunnable meant to be used for processing of no-arg scheduled methods."}
{"index": 6618, "repo": "spring-context-6.0.11", "code": "public final class ScheduledTask extends Object {\n\t// Trigger cancellation of this scheduled task.\n\tvoid cancel();\n\t// Trigger cancellation of this scheduled task.\n\tvoid cancel(boolean mayInterruptIfRunning);\n\t// Return the underlying task (typically a CronTask, FixedRateTask or FixedDelayTask).\n\tTask getTask();\n}", "des": "A representation of a scheduled task at runtime, used as a return value for scheduling methods."}
{"index": 6619, "repo": "spring-context-6.0.11", "code": "public enum ScopedProxyMode extends Enum<ScopedProxyMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ScopedProxyMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ScopedProxyMode[] values();\n}", "des": "Enumerates the various scoped-proxy options."}
{"index": 6620, "repo": "spring-context-6.0.11", "code": "public class ScopeMetadata extends Object {\n\t// Get the proxy-mode to be applied to the scoped instance.\n\tScopedProxyMode getScopedProxyMode();\n\t// Get the name of the scope.\n\tString getScopeName();\n\t// Set the proxy-mode to be applied to the scoped instance.\n\tvoid setScopedProxyMode(ScopedProxyMode scopedProxyMode);\n\t// Set the name of the scope.\n\tvoid setScopeName(String scopeName);\n}", "des": "Describes scope characteristics for a Spring-managed bean including the scope name and the scoped-proxy behavior."}
{"index": 6621, "repo": "spring-context-6.0.11", "code": "public interface ScriptEvaluator {\n\t// Evaluate the given script.\n\tObject evaluate(ScriptSource script);\n\t// Evaluate the given script with the given arguments.\n\tObject evaluate(ScriptSource script, Map<String,Object> arguments);\n}", "des": "Spring's strategy interface for evaluating a script."}
{"index": 6622, "repo": "spring-context-6.0.11", "code": "public interface ScriptSource {\n\t// Retrieve the current script source text as String.\n\tString getScriptAsString();\n\t// Indicate whether the underlying script data has been modified since the last time getScriptAsString() was called.\n\tboolean isModified();\n\t// Determine a class name for the underlying script.\n\tString suggestedClassName();\n}", "des": "Interface that defines the source of a script."}
{"index": 6623, "repo": "spring-context-6.0.11", "code": "public class SimpleCacheManager extends AbstractCacheManager {\n\t// Load the initial caches for this cache manager.\n\tprotected Collection<? extends Cache> loadCaches();\n\t// Specify the collection of Cache instances to use for this CacheManager.\n\tvoid setCaches(Collection<? extends Cache> caches);\n}", "des": "Simple cache manager working against a given collection of caches."}
{"index": 6624, "repo": "spring-context-6.0.11", "code": "public class SimpleKeyGenerator extends Object implements KeyGenerator {\n\t// Generate a key for the given method and its parameters.\n\tObject generate(Object target, Method method, Object... params);\n\t// Generate a key based on the specified parameters.\n\tstatic Object generateKey(Object... params);\n}", "des": "Simple key generator."}
{"index": 6625, "repo": "spring-context-6.0.11", "code": "public class SimpleLoadTimeWeaver extends Object implements LoadTimeWeaver {\n\t// Add a ClassFileTransformer to be applied by this LoadTimeWeaver.\n\tvoid addTransformer(ClassFileTransformer transformer);\n\t// Return a ClassLoader that supports instrumentation through AspectJ-style load-time weaving based on user-defined ClassFileTransformers.\n\tClassLoader getInstrumentableClassLoader();\n\t// This implementation builds a SimpleThrowawayClassLoader.\n\tClassLoader getThrowawayClassLoader();\n}", "des": "LoadTimeWeaver that builds and exposes a SimpleInstrumentableClassLoader."}
{"index": 6626, "repo": "spring-context-6.0.11", "code": "public class SimpleReflectiveMBeanInfoAssembler extends AbstractConfigurableMBeanInfoAssembler {\n\t// Always returns true.\n\tprotected boolean includeOperation(Method method, String beanKey);\n\t// Always returns true.\n\tprotected boolean includeReadAttribute(Method method, String beanKey);\n\t// Always returns true.\n\tprotected boolean includeWriteAttribute(Method method, String beanKey);\n}", "des": "Simple subclass of AbstractReflectiveMBeanInfoAssembler that always votes yes for method and property inclusion, effectively exposing all public methods and properties as operations and attributes."}
{"index": 6627, "repo": "spring-context-6.0.11", "code": "public interface SmartLifecycle extends Lifecycle, Phased {\n\t// Return the phase that this lifecycle object is supposed to run in.\n\tdefault int getPhase();\n\t// Returns true if this Lifecycle component should get started automatically by the container at the time that the containing ApplicationContext gets refreshed.\n\tdefault boolean isAutoStartup();\n\t// Indicates that a Lifecycle component must stop if it is currently running.\n\tdefault void stop(Runnable callback);\n}", "des": "An extension of the Lifecycle interface for those objects that require to be started upon ApplicationContext refresh and/or shutdown in a particular order."}
{"index": 6628, "repo": "spring-context-6.0.11", "code": "public class StaticScriptSource extends Object implements ScriptSource {\n\t// Retrieve the current script source text as String.\n\tString getScriptAsString();\n\t// Indicate whether the underlying script data has been modified since the last time ScriptSource.getScriptAsString() was called.\n\tboolean isModified();\n\t// Set a fresh script String, overriding the previous script.\n\tvoid setScript(String script);\n\t// Determine a class name for the underlying script.\n\tString suggestedClassName();\n}", "des": "Static implementation of the ScriptSource interface, encapsulating a given String that contains the script source text."}
{"index": 6629, "repo": "spring-context-6.0.11", "code": "public abstract class TaskUtils extends Object {\n\t// Decorate the task for error handling.\n\tstatic DelegatingErrorHandlingRunnable decorateTaskWithErrorHandler(Runnable task, org.springframework.util.ErrorHandler errorHandler, boolean isRepeatingTask);\n\t// Return the default ErrorHandler implementation based on the boolean value indicating whether the task will be repeating or not.\n\tstatic org.springframework.util.ErrorHandler getDefaultErrorHandler(boolean isRepeatingTask);\n}", "des": "Utility methods for decorating tasks with error handling."}
{"index": 6630, "repo": "spring-context-6.0.11", "code": "public interface Trigger {\n\t// Determine the next execution time according to the given trigger context.\n\tInstant nextExecution(TriggerContext triggerContext);\n\t// Deprecated. as of 6.0, in favor of nextExecution(TriggerContext)\n\tdefault Date nextExecutionTime(TriggerContext triggerContext);\n}", "des": "Common interface for trigger objects that determine the next execution time of a task that they get associated with."}
{"index": 6631, "repo": "spring-context-6.0.11", "code": "public class TypeMismatchNamingException extends NamingException {\n\t// Return the actual type that the lookup returned, if available.\n\tfinal Class<?> getActualType();\n\t// Return the required type for the lookup, if available.\n\tfinal Class<?> getRequiredType();\n}", "des": "Exception thrown if a type mismatch is encountered for an object located in a JNDI environment."}
{"index": 6632, "repo": "spring-context-6.0.11", "code": "public interface Validator {\n\t// Can this Validator validate instances of the supplied clazz?\n\tboolean supports(Class<?> clazz);\n\t// Validate the supplied target object, which must be of a Class for which the supports(Class) method typically has (or would) return true.\n\tvoid validate(Object target, Errors errors);\n}", "des": "A validator for application-specific objects."}
{"index": 6633, "repo": "spring-context-6.0.11", "code": "public class WeavingTransformer extends Object {\n\t// Add a class file transformer to be applied by this weaver.\n\tvoid addTransformer(ClassFileTransformer transformer);\n\t// Apply transformation on a given class byte definition.\n\tbyte[] transformIfNecessary(String className, byte[] bytes);\n\t// Apply transformation on a given class byte definition.\n\tbyte[] transformIfNecessary(String className, String internalName, byte[] bytes, ProtectionDomain pd);\n}", "des": "ClassFileTransformer-based weaver, allowing for a list of transformers to be applied on a class byte array."}
{"index": 6634, "repo": "spring-restdocs-core-3.0.0", "code": "public abstract class AbstractDescriptor<T extends AbstractDescriptor<T>> extends Object {\n\t// Adds the given attributes to the descriptor.\n\tfinal T attributes(Attributes.Attribute... attributes);\n\t// Specifies the description.\n\tfinal T description(Object description);\n\t// Returns the descriptor's attributes.\n\tfinal Map<String,Object> getAttributes();\n\t// Returns the description.\n\tfinal Object getDescription();\n}", "des": "Base class for descriptors."}
{"index": 6635, "repo": "spring-restdocs-core-3.0.0", "code": "public abstract class Attributes extends Object {\n\t// Creates a Map of the given attributes.\n\tstatic Map<String,Object> attributes(Attributes.Attribute... attributes);\n\t// Creates an attribute with the given key.\n\tstatic Attributes.AttributeBuilder key(String key);\n}", "des": "A fluent API for building a map of attributes."}
{"index": 6636, "repo": "spring-restdocs-core-3.0.0", "code": "public static final class Attributes.Attribute extends Object {\n\t// Returns the attribute's key.\n\tString getKey();\n\t// Returns the attribute's value.\n\tObject getValue();\n}", "des": "An attribute (key-value pair)."}
{"index": 6637, "repo": "spring-restdocs-core-3.0.0", "code": "public class Constraint extends Object {\n\t// Returns the configuration of the constraint.\n\tMap<String,Object> getConfiguration();\n\t// Returns the name of the constraint.\n\tString getName();\n}", "des": "A constraint."}
{"index": 6638, "repo": "spring-restdocs-core-3.0.0", "code": "public class ContentModifyingOperationPreprocessor extends Object implements OperationPreprocessor {\n\t// Processes the given request.\n\tOperationRequest preprocess(OperationRequest request);\n\t// Processes the given response.\n\tOperationResponse preprocess(OperationResponse response);\n}", "des": "An OperationPreprocessor that applies a ContentModifier to the content of the request or response."}
{"index": 6639, "repo": "spring-restdocs-core-3.0.0", "code": "public class CookieDescriptor extends IgnorableDescriptor<CookieDescriptor> {\n\t// Returns the name for the cookie.\n\tfinal String getName();\n\t// Returns true if the described cookie is optional, otherwise false.\n\tfinal boolean isOptional();\n\t// Marks the cookie as optional.\n\tfinal CookieDescriptor optional();\n}", "des": "A description of a cookie found in a request or response."}
{"index": 6640, "repo": "spring-restdocs-core-3.0.0", "code": "public class FieldDescriptor extends IgnorableDescriptor<FieldDescriptor> {\n\t// Returns the path of the field described by this descriptor.\n\tfinal String getPath();\n\t// Returns the type of the field described by this descriptor.\n\tfinal Object getType();\n\t// Returns true if the described field is optional, otherwise false.\n\tfinal boolean isOptional();\n\t// Marks the field as optional.\n\tfinal FieldDescriptor optional();\n\t// Specifies the type of the field.\n\tfinal FieldDescriptor type(Object type);\n}", "des": "A description of a field found in a request or response payload."}
{"index": 6641, "repo": "spring-restdocs-core-3.0.0", "code": "public interface FieldTypeResolver {\n\t// Create a FieldTypeResolver for the given content and contentType, described by the given descriptors.\n\tstatic FieldTypeResolver forContentWithDescriptors(byte[] content, MediaType contentType, List<FieldDescriptor> descriptors);\n\t// Resolves the type of the field that is described by the given fieldDescriptor based on the content of the payload.\n\tObject resolveFieldType(FieldDescriptor fieldDescriptor);\n}", "des": "Resolves the type of a field in a request or response payload."}
{"index": 6642, "repo": "spring-restdocs-core-3.0.0", "code": "public class HeaderDescriptor extends AbstractDescriptor<HeaderDescriptor> {\n\t// Returns the name for the header.\n\tfinal String getName();\n\t// Returns true if the described header is optional, otherwise false.\n\tfinal boolean isOptional();\n\t// Marks the header as optional.\n\tfinal HeaderDescriptor optional();\n}", "des": "A description of a header found in a request or response."}
{"index": 6643, "repo": "spring-restdocs-core-3.0.0", "code": "public abstract class IgnorableDescriptor<T extends IgnorableDescriptor<T>> extends AbstractDescriptor<T> {\n\t// Marks the described item as being ignored.\n\tfinal T ignored();\n\t// Returns whether or not the item being described should be ignored and, therefore, should not be included in the documentation.\n\tfinal boolean isIgnored();\n}", "des": "Base class for descriptors for items that can be ignored."}
{"index": 6644, "repo": "spring-restdocs-core-3.0.0", "code": "public enum JsonFieldType extends Enum<JsonFieldType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic JsonFieldType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic JsonFieldType[] values();\n}", "des": "An enumeration of the possible types for a field in a JSON request or response payload."}
{"index": 6645, "repo": "spring-restdocs-core-3.0.0", "code": "public class Link extends Object {\n\tboolean equals(Object obj);\n\t// Returns the link's href.\n\tString getHref();\n\t// Returns the link's rel.\n\tString getRel();\n\t// Returns the link's title, or null if it does not have a title.\n\tString getTitle();\n}", "des": "Representation of a link used in a Hypermedia-based API."}
{"index": 6646, "repo": "spring-restdocs-core-3.0.0", "code": "public class LinkDescriptor extends IgnorableDescriptor<LinkDescriptor> {\n\t// Returns the rel of the link described by this descriptor.\n\tfinal String getRel();\n\t// Returns true if the described link is optional, otherwise false.\n\tfinal boolean isOptional();\n\t// Marks the link as optional.\n\tfinal LinkDescriptor optional();\n}", "des": "A description of a link found in a hypermedia API."}
{"index": 6647, "repo": "spring-restdocs-core-3.0.0", "code": "public final class ManualRestDocumentation extends Object implements RestDocumentationContextProvider {\n\t// Notification that a test has completed.\n\tvoid afterTest();\n\t// Returns a RestDocumentationContext for the operation that is about to be performed.\n\tRestDocumentationContext beforeOperation();\n\t// Notification that a test is about to begin.\n\tvoid beforeTest(Class<?> testClass, String testMethodName);\n}", "des": "ManualRestDocumentation is used to manually manage the RestDocumentationContext."}
{"index": 6648, "repo": "spring-restdocs-core-3.0.0", "code": "public class MustacheTemplateEngine extends Object implements TemplateEngine {\n\t// Compiles the template at the given path.\n\tTemplate compileTemplate(String name);\n\t// Returns the Mustache.Compiler used to compile Mustache templates.\n\tprotected final org.springframework.restdocs.mustache.Mustache.Compiler getCompiler();\n\t// Returns the TemplateResourceResolver used to resolve the template resources prior to compilation.\n\tprotected final TemplateResourceResolver getTemplateResourceResolver();\n}", "des": "A Mustache-based TemplateEngine implemented using JMustache."}
{"index": 6649, "repo": "spring-restdocs-core-3.0.0", "code": "public interface Operation {\n\t// Returns a Map of attributes associated with the operation.\n\tMap<String,Object> getAttributes();\n\t// Returns the name of the operation.\n\tString getName();\n\t// Returns the request that was sent.\n\tOperationRequest getRequest();\n\t// Returns the response that was received.\n\tOperationResponse getResponse();\n}", "des": "Describes an operation performed on a RESTful service."}
{"index": 6650, "repo": "spring-restdocs-core-3.0.0", "code": "public interface OperationPreprocessor {\n\t// Processes the given request.\n\tOperationRequest preprocess(OperationRequest request);\n\t// Processes the given response.\n\tOperationResponse preprocess(OperationResponse response);\n}", "des": "An OperationPreprocessor processes the OperationRequest and OperationResponse of an Operation prior to it being documented."}
{"index": 6651, "repo": "spring-restdocs-core-3.0.0", "code": "public abstract class OperationPreprocessorAdapter extends Object implements OperationPreprocessor {\n\t// Returns the given request as-is.\n\tOperationRequest preprocess(OperationRequest request);\n\t// Returns the given response as-is.\n\tOperationResponse preprocess(OperationResponse response);\n}", "des": "An implementation of OperationPreprocessor that returns the request and response as-is."}
{"index": 6652, "repo": "spring-restdocs-core-3.0.0", "code": "public abstract class OperationPreprocessorsConfigurer<PARENT,TYPE> extends AbstractNestedConfigurer<PARENT> {\n\t// Applies the configurer to the given configuration.\n\tvoid apply(Map<String,Object> configuration, RestDocumentationContext context);\n\t// Configures the default operation request preprocessors.\n\tTYPE withRequestDefaults(OperationPreprocessor... preprocessors);\n\t// Configures the default operation response preprocessors.\n\tTYPE withResponseDefaults(OperationPreprocessor... preprocessors);\n}", "des": "A configurer that can be used to configure the default operation preprocessors."}
{"index": 6653, "repo": "spring-restdocs-core-3.0.0", "code": "public interface OperationRequestPart {\n\t// Returns the contents of the part.\n\tbyte[] getContent();\n\t// Returns the content of the part as a String.\n\tString getContentAsString();\n\t// Returns the part's headers.\n\tHttpHeaders getHeaders();\n\t// Returns the name of the part.\n\tString getName();\n\t// Returns the name of the file that is being uploaded in this part.\n\tString getSubmittedFileName();\n}", "des": "A part of a multipart request."}
{"index": 6654, "repo": "spring-restdocs-core-3.0.0", "code": "public interface OperationResponse {\n\t// Returns the content of the response.\n\tbyte[] getContent();\n\t// Returns the content of the response as a String.\n\tString getContentAsString();\n\t// Returns the cookies returned with the response.\n\tCollection<ResponseCookie> getCookies();\n\t// Returns the headers in the response.\n\tHttpHeaders getHeaders();\n\t// Returns the status of the response.\n\tHttpStatusCode getStatus();\n}", "des": "The response that was received as part of performing an operation on a RESTful service."}
{"index": 6655, "repo": "spring-restdocs-core-3.0.0", "code": "public class ParameterDescriptor extends IgnorableDescriptor<ParameterDescriptor> {\n\t// Returns the name of the parameter being described by this descriptor.\n\tfinal String getName();\n\t// Returns true if the described parameter is optional, otherwise false.\n\tfinal boolean isOptional();\n\t// Marks the parameter as optional.\n\tfinal ParameterDescriptor optional();\n}", "des": "A descriptor of a request or path parameter."}
{"index": 6656, "repo": "spring-restdocs-core-3.0.0", "code": "public class RequestBodySnippet extends AbstractBodySnippet {\n\t// Returns the content of the request or response extracted from the given operation.\n\tprotected byte[] getContent(Operation operation);\n\t// Returns the content type of the request or response extracted from the given operation.\n\tprotected MediaType getContentType(Operation operation);\n}", "des": "A Snippet that documents the body of a request."}
{"index": 6657, "repo": "spring-restdocs-core-3.0.0", "code": "public final class RequestCookie extends Object {\n\t// Returns the name of the cookie.\n\tString getName();\n\t// Returns the value of the cookie.\n\tString getValue();\n}", "des": "A representation of a Cookie received in a request."}
{"index": 6658, "repo": "spring-restdocs-core-3.0.0", "code": "public class RequestPartBodySnippet extends AbstractBodySnippet {\n\t// Returns the content of the request or response extracted from the given operation.\n\tprotected byte[] getContent(Operation operation);\n\t// Returns the content type of the request or response extracted from the given operation.\n\tprotected MediaType getContentType(Operation operation);\n}", "des": "A Snippet that documents the body of a request part."}
{"index": 6659, "repo": "spring-restdocs-core-3.0.0", "code": "public class RequestPartDescriptor extends IgnorableDescriptor<RequestPartDescriptor> {\n\t// Returns the name of the request part being described by this descriptor.\n\tfinal String getName();\n\t// Returns true if the described request part is optional, otherwise false.\n\tfinal boolean isOptional();\n\t// Marks the request part as optional.\n\tfinal RequestPartDescriptor optional();\n}", "des": "A descriptor of a request part."}
{"index": 6660, "repo": "spring-restdocs-core-3.0.0", "code": "public class ResponseBodySnippet extends AbstractBodySnippet {\n\t// Returns the content of the request or response extracted from the given operation.\n\tprotected byte[] getContent(Operation operation);\n\t// Returns the content type of the request or response extracted from the given operation.\n\tprotected MediaType getContentType(Operation operation);\n}", "des": "A Snippet that documents the body of a response."}
{"index": 6661, "repo": "spring-restdocs-core-3.0.0", "code": "public final class ResponseCookie extends Object {\n\t// Returns the name of the cookie.\n\tString getName();\n\t// Returns the value of the cookie.\n\tString getValue();\n}", "des": "A representation of a Cookie returned in a response."}
{"index": 6662, "repo": "spring-restdocs-core-3.0.0", "code": "public interface RestDocumentationContext {\n\t// Returns the output directory to which generated snippets should be written.\n\tFile getOutputDirectory();\n\t// Returns the current step count.\n\tint getStepCount();\n\t// Returns the class whose tests are currently executing.\n\tClass<?> getTestClass();\n\t// Returns the name of the test method that is currently executing.\n\tString getTestMethodName();\n}", "des": "RestDocumentationContext encapsulates the context in which the documentation of a RESTful API is being performed."}
{"index": 6663, "repo": "spring-restdocs-core-3.0.0", "code": "public final class RestDocumentationGenerator<REQ,RESP> extends Object {\n\t// Handles the given request and response, producing documentation snippets for them using the given configuration.\n\tvoid handle(REQ request, RESP response, Map<String,Object> configuration);\n\t// Creates a new RestDocumentationGenerator with the same configuration as this one other than its snippets.\n\tRestDocumentationGenerator<REQ,RESP> withSnippets(Snippet... snippets);\n}", "des": "A RestDocumentationGenerator is used to generate documentation snippets from the request and response of an operation performed on a service."}
{"index": 6664, "repo": "spring-restdocs-core-3.0.0", "code": "public class StandardOperation extends Object implements Operation {\n\t// Returns a Map of attributes associated with the operation.\n\tMap<String,Object> getAttributes();\n\t// Returns the name of the operation.\n\tString getName();\n\t// Returns the request that was sent.\n\tOperationRequest getRequest();\n\t// Returns the response that was received.\n\tOperationResponse getResponse();\n}", "des": "Standard implementation of Operation."}
{"index": 6665, "repo": "spring-restdocs-core-3.0.0", "code": "public interface TemplateFormat {\n\t// Returns the file extension to use for files generated from templates in this format.\n\tString getFileExtension();\n\t// Returns the id of this template format.\n\tString getId();\n}", "des": "A TemplateFormat provides information about a particular template format, such as Asciidoctor or Markdown."}
{"index": 6666, "repo": "spring-restdocs-core-3.0.0", "code": "public abstract class TemplateFormats extends Object {\n\t// Returns the Asciidoctor template format with the ID asciidoctor and the file extension adoc.\n\tstatic TemplateFormat asciidoctor();\n\t// Returns the Markdown template format with the ID markdown and the file extension md.\n\tstatic TemplateFormat markdown();\n}", "des": "An enumeration of the built-in formats for which templates are provided."}
{"index": 6667, "repo": "spring-cloud-task-core-3.0.3", "code": "public class DefaultTaskConfigurer extends Object implements TaskConfigurer {\n\t// Retrieves the DataSource that will be used for task operations.\n\tDataSource getTaskDataSource();\n\t// Create a TaskExplorer for the task.\n\tTaskExplorer getTaskExplorer();\n\t// Create a TaskRepository for the Task.\n\tTaskRepository getTaskRepository();\n\t// Create a PlatformTransactionManager for use with the TaskRepository.\n\torg.springframework.transaction.PlatformTransactionManager getTransactionManager();\n}", "des": "Default implementation of the TaskConfigurer interface."}
{"index": 6668, "repo": "spring-cloud-task-core-3.0.3", "code": "public interface TaskConfigurer {\n\t// Retrieves the DataSource that will be used for task operations.\n\tDataSource getTaskDataSource();\n\t// Create a TaskExplorer for the task.\n\tTaskExplorer getTaskExplorer();\n\t// Create a TaskRepository for the Task.\n\tTaskRepository getTaskRepository();\n\t// Create a PlatformTransactionManager for use with the TaskRepository.\n\torg.springframework.transaction.PlatformTransactionManager getTransactionManager();\n}", "des": "Provides a strategy interface for providing configuration customization to the task system."}
{"index": 6669, "repo": "spring-cloud-task-core-3.0.3", "code": "public interface TaskExecutionListener {\n\t// Invoked before the TaskExecution has been updated in the TaskRepository upon task end.\n\tdefault void onTaskEnd(TaskExecution taskExecution);\n\t// Invoked if an uncaught exception occurs during a task execution.\n\tdefault void onTaskFailed(TaskExecution taskExecution, Throwable throwable);\n\t// Invoked after the TaskExecution has been stored in the TaskRepository.\n\tdefault void onTaskStartup(TaskExecution taskExecution);\n}", "des": "The listener interface for receiving task execution events."}
{"index": 6670, "repo": "spring-cloud-task-core-3.0.3", "code": "public enum TaskExecutionObservation extends Enum<TaskExecutionObservation> implements io.micrometer.observation.docs.ObservationDocumentation {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic TaskExecutionObservation valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic TaskExecutionObservation[] values();\n}", "des": "Enumeration for task execution observations."}
{"index": 6671, "repo": "spring-cloud-task-core-3.0.3", "code": "public class TaskListenerExecutor extends Object implements TaskExecutionListener {\n\t// Executes all the methods that have been annotated with @AfterTask.\n\tvoid onTaskEnd(TaskExecution taskExecution);\n\t// Executes all the methods that have been annotated with @FailedTask.\n\tvoid onTaskFailed(TaskExecution taskExecution, Throwable throwable);\n\t// Executes all the methods that have been annotated with @BeforeTask.\n\tvoid onTaskStartup(TaskExecution taskExecution);\n}", "des": "Identifies all beans that contain a TaskExecutionListener annotation and stores the associated method so that it can be called by the TaskExecutionListener at the appropriate time."}
{"index": 6672, "repo": "spring-security-oauth2-client-6.1.2", "code": "public abstract class AbstractOAuth2AuthorizationGrantRequest extends Object {\n\t// Returns the client registration.\n\tClientRegistration getClientRegistration();\n\t// Returns the authorization grant type.\n\torg.springframework.security.oauth2.core.AuthorizationGrantType getGrantType();\n}", "des": "Base implementation of an OAuth 2.0 Authorization Grant request that holds an authorization grant credential and is used when initiating a request to the Authorization Server's Token Endpoint."}
{"index": 6673, "repo": "spring-security-oauth2-client-6.1.2", "code": "public final class InMemoryClientRegistrationRepository extends Object implements ClientRegistrationRepository, Iterable<ClientRegistration> {\n\t// Returns the client registration identified by the provided registrationId, or null if not found.\n\tClientRegistration findByRegistrationId(String registrationId);\n\t// Returns an Iterator of ClientRegistration.\n\tIterator<ClientRegistration> iterator();\n}", "des": "A ClientRegistrationRepository that stores ClientRegistration(s) in-memory."}
{"index": 6674, "repo": "spring-security-oauth2-client-6.1.2", "code": "public final class InMemoryReactiveClientRegistrationRepository extends Object implements ReactiveClientRegistrationRepository, Iterable<ClientRegistration> {\n\t// Returns the client registration identified by the provided registrationId, or null if not found.\n\treactor.core.publisher.Mono<ClientRegistration> findByRegistrationId(String registrationId);\n\t// Returns an Iterator of ClientRegistration.\n\tIterator<ClientRegistration> iterator();\n}", "des": "A Reactive ClientRegistrationRepository that stores ClientRegistration(s) in-memory."}
{"index": 6675, "repo": "spring-security-oauth2-client-6.1.2", "code": "public static final class JdbcOAuth2AuthorizedClientService.OAuth2AuthorizedClientHolder extends Object {\n\t// Returns the OAuth2AuthorizedClient.\n\tOAuth2AuthorizedClient getAuthorizedClient();\n\t// Returns the End-User Authentication (Resource Owner).\n\torg.springframework.security.core.Authentication getPrincipal();\n}", "des": "A holder for an OAuth2AuthorizedClient and End-User Authentication (Resource Owner)."}
{"index": 6676, "repo": "spring-security-oauth2-client-6.1.2", "code": "public class OAuth2AuthorizedClient extends Object implements Serializable {\n\t// Returns the access token credential granted.\n\torg.springframework.security.oauth2.core.OAuth2AccessToken getAccessToken();\n\t// Returns the authorized client's registration.\n\tClientRegistration getClientRegistration();\n\t// Returns the End-User's Principal name.\n\tString getPrincipalName();\n\t// Returns the refresh token credential granted.\n\torg.springframework.security.oauth2.core.OAuth2RefreshToken getRefreshToken();\n}", "des": "A representation of an OAuth 2.0 \"Authorized Client\"."}
{"index": 6677, "repo": "spring-security-oauth2-client-6.1.2", "code": "public class OAuth2RefreshTokenGrantRequest extends AbstractOAuth2AuthorizationGrantRequest {\n\t// Returns the access token credential granted.\n\torg.springframework.security.oauth2.core.OAuth2AccessToken getAccessToken();\n\t// Returns the refresh token credential granted.\n\torg.springframework.security.oauth2.core.OAuth2RefreshToken getRefreshToken();\n\t// Returns the scope(s) to request.\n\tSet<String> getScopes();\n}", "des": "An OAuth 2.0 Refresh Token Grant request that holds the refresh token credential granted to the client."}
{"index": 6678, "repo": "spring-security-oauth2-client-6.1.2", "code": "public class OAuth2UserRequest extends Object {\n\t// Returns the access token.\n\torg.springframework.security.oauth2.core.OAuth2AccessToken getAccessToken();\n\t// Returns the additional parameters that may be used in the request.\n\tMap<String,Object> getAdditionalParameters();\n\t// Returns the client registration.\n\tClientRegistration getClientRegistration();\n}", "des": "Represents a request the OAuth2UserService uses when initiating a request to the UserInfo Endpoint."}
{"index": 6679, "repo": "spring-security-oauth2-client-6.1.2", "code": "public final class OidcIdTokenValidator extends Object implements org.springframework.security.oauth2.core.OAuth2TokenValidator<org.springframework.security.oauth2.jwt.Jwt> {\n\t// Sets the Clock used in Instant.now(Clock) when validating the exp and iat claims.\n\tvoid setClock(Clock clock);\n\t// Sets the maximum acceptable clock skew.\n\tvoid setClockSkew(Duration clockSkew);\n\torg.springframework.security.oauth2.core.OAuth2TokenValidatorResult validate(org.springframework.security.oauth2.jwt.Jwt idToken);\n}", "des": "An OAuth2TokenValidator responsible for validating the claims in an ID Token."}
{"index": 6680, "repo": "spring-websocket-6.0.11", "code": "public abstract class AbstractSockJsMessageCodec extends Object implements SockJsMessageCodec {\n\t// Apply standard JSON string quoting (see json.org).\n\tprotected abstract char[] applyJsonQuoting(String content);\n\t// Encode the given messages as a SockJS message frame.\n\tString encode(String... messages);\n}", "des": "A base class for SockJS message codec that provides an implementation of AbstractSockJsMessageCodec.encode(String[])."}
{"index": 6681, "repo": "spring-websocket-6.0.11", "code": "public abstract class AbstractSubProtocolEvent extends org.springframework.context.ApplicationEvent {\n\t// Return the Message associated with the event.\n\torg.springframework.messaging.Message<byte[]> getMessage();\n\t// Return the user for the session associated with the event.\n\tPrincipal getUser();\n}", "des": "A base class for events for a message received from a WebSocket client and parsed into a higher-level sub-protocol (e.g."}
{"index": 6682, "repo": "spring-websocket-6.0.11", "code": "public abstract class AbstractWebSocketMessage<T> extends Object implements WebSocketMessage<T> {\n\tboolean equals(Object other);\n\t// Return the message payload (never null).\n\tT getPayload();\n\t// Whether this is the last part of a message sent as a series of partial messages.\n\tboolean isLast();\n\tprotected abstract String toStringPayload();\n}", "des": "A message that can be handled or sent on a WebSocket connection."}
{"index": 6683, "repo": "spring-websocket-6.0.11", "code": "public final class CloseStatus extends Object implements Serializable {\n\tboolean equals(Object other);\n\tboolean equalsCode(CloseStatus other);\n\t// Return the status code.\n\tint getCode();\n\t// Return the reason, or null if none.\n\tString getReason();\n\t// Create a new CloseStatus from this one with the specified reason.\n\tCloseStatus withReason(String reason);\n}", "des": "Represents a WebSocket close status code and reason."}
{"index": 6684, "repo": "spring-websocket-6.0.11", "code": "public static enum ConcurrentWebSocketSessionDecorator.OverflowStrategy extends Enum<ConcurrentWebSocketSessionDecorator.OverflowStrategy> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ConcurrentWebSocketSessionDecorator.OverflowStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ConcurrentWebSocketSessionDecorator.OverflowStrategy[] values();\n}", "des": "Enum for options of what to do when the buffer fills up."}
{"index": 6685, "repo": "spring-websocket-6.0.11", "code": "public class Jackson2SockJsMessageCodec extends AbstractSockJsMessageCodec {\n\t// Apply standard JSON string quoting (see json.org).\n\tprotected char[] applyJsonQuoting(String content);\n\t// Decode the given SockJS message frame.\n\tString[] decode(String content);\n\t// Decode the given SockJS message frame.\n\tString[] decodeInputStream(InputStream content);\n}", "des": "A Jackson 2.x codec for encoding and decoding SockJS messages."}
{"index": 6686, "repo": "spring-websocket-6.0.11", "code": "public interface NativeWebSocketSession extends WebSocketSession {\n\t// Return the underlying native WebSocketSession.\n\tObject getNativeSession();\n\t// Return the underlying native WebSocketSession, if available.\n\t<T> T getNativeSession(Class<T> requiredType);\n}", "des": "A WebSocketSession that exposes the underlying, native WebSocketSession through a getter."}
{"index": 6687, "repo": "spring-websocket-6.0.11", "code": "public class SessionDisconnectEvent extends AbstractSubProtocolEvent {\n\t// Return the status with which the session was closed.\n\tCloseStatus getCloseStatus();\n\t// Return the session id.\n\tString getSessionId();\n}", "des": "Event raised when the session of a WebSocket client using a Simple Messaging Protocol (e.g."}
{"index": 6688, "repo": "spring-websocket-6.0.11", "code": "public enum SockJsFrameType extends Enum<SockJsFrameType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic SockJsFrameType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic SockJsFrameType[] values();\n}", "des": "SockJS frame types."}
{"index": 6689, "repo": "spring-websocket-6.0.11", "code": "public interface SockJsMessageCodec {\n\t// Decode the given SockJS message frame.\n\tString[] decode(String content);\n\t// Decode the given SockJS message frame.\n\tString[] decodeInputStream(InputStream content);\n\t// Encode the given messages as a SockJS message frame.\n\tString encode(String... messages);\n}", "des": "Encode and decode messages to and from a SockJS message frame, essentially an array of JSON-encoded messages."}
{"index": 6690, "repo": "spring-websocket-6.0.11", "code": "public interface SockJsSession extends WebSocketSession {\n\t// Disable the SockJS heartbeat, presumably because a higher-level protocol has heartbeats enabled for the session already.\n\tvoid disableHeartbeat();\n\t// Return the time (in ms) since the session was last active, or otherwise if the session is new, then the time since the session was created.\n\tlong getTimeSinceLastActive();\n}", "des": "SockJS extension of Spring's standard WebSocketSession."}
{"index": 6691, "repo": "spring-websocket-6.0.11", "code": "public static interface StompSubProtocolHandler.Stats {\n\t// The number of CONNECT frames processed.\n\tint getTotalConnect();\n\t// The number of CONNECTED frames processed.\n\tint getTotalConnected();\n\t// The number of DISCONNECT frames processed.\n\tint getTotalDisconnect();\n}", "des": "Contract for access to session counters."}
{"index": 6692, "repo": "spring-websocket-6.0.11", "code": "public class WebSocketExtension extends Object {\n\tboolean equals(Object other);\n\t// Return the name of the extension (never null or empty).\n\tString getName();\n\t// Return the parameters of the extension (never null).\n\tMap<String,String> getParameters();\n\t// Parse the given, comma-separated string into a list of WebSocketExtension objects.\n\tstatic List<WebSocketExtension> parseExtensions(String extensions);\n}", "des": "Represents a WebSocket extension as defined in the RFC 6455."}
{"index": 6693, "repo": "spring-websocket-6.0.11", "code": "public interface WebSocketMessage<T> {\n\t// Return the message payload (never null).\n\tT getPayload();\n\t// Return the number of bytes contained in the message.\n\tint getPayloadLength();\n\t// When partial message support is available and requested via WebSocketHandler.supportsPartialMessages(), this method returns true if the current message is the last part of the complete WebSocket message sent by the client.\n\tboolean isLast();\n}", "des": "A message that can be handled or sent on a WebSocket connection."}
{"index": 6694, "repo": "spring-websocket-6.0.11", "code": "public class WebSocketTransport extends Object implements Transport, org.springframework.context.Lifecycle {\n\t// Connect the transport.\n\tCompletableFuture<WebSocketSession> connectAsync(TransportRequest request, WebSocketHandler handler);\n\t// Get the SockJS transport types that this transport can be used for.\n\tList<TransportType> getTransportTypes();\n\t// Return the configured WebSocketClient.\n\tWebSocketClient getWebSocketClient();\n\tboolean isRunning();\n\tvoid start();\n\tvoid stop();\n}", "des": "A SockJS Transport that uses a WebSocketClient."}
{"index": 6695, "repo": "spring-websocket-6.0.11", "code": "public interface XhrTransport extends Transport, InfoReceiver {\n\t// Execute a request to send the message to the server.\n\tvoid executeSendRequest(URI transportUrl, org.springframework.http.HttpHeaders headers, TextMessage message);\n\t// An XhrTransport supports both the \"xhr_streaming\" and \"xhr\" SockJS server transports.\n\tboolean isXhrStreamingDisabled();\n}", "des": "A SockJS Transport that uses HTTP requests to simulate a WebSocket interaction."}
{"index": 6696, "repo": "spring-cloud-commons-3.1.7", "code": "public static enum CompletionContext.Status extends Enum<CompletionContext.Status> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic CompletionContext.Status valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic CompletionContext.Status[] values();\n}", "des": "Request status state."}
{"index": 6697, "repo": "spring-cloud-commons-3.1.7", "code": "public class CompositeDiscoveryClient extends Object implements DiscoveryClient {\n\t// A human-readable description of the implementation, used in HealthIndicator.\n\tString description();\n\tList<DiscoveryClient> getDiscoveryClients();\n\t// Gets all ServiceInstances associated with a particular serviceId.\n\tList<ServiceInstance> getInstances(String serviceId);\n\tList<String> getServices();\n\t// Can be used to verify the client is valid and able to make calls.\n\tvoid probe();\n}", "des": "A DiscoveryClient that is composed of other discovery clients and delegates calls to each of them in order."}
{"index": 6698, "repo": "spring-cloud-commons-3.1.7", "code": "public interface LoadBalancedRetryFactory {\n\t// Creates a BackOffPolicy for a given service.\n\tdefault org.springframework.retry.backoff.BackOffPolicy createBackOffPolicy(String service);\n\t// Creates an array of RetryListeners for a given service.\n\tdefault org.springframework.retry.RetryListener[] createRetryListeners(String service);\n\t// Creates a LoadBalancedRetryPolicy.\n\tdefault LoadBalancedRetryPolicy createRetryPolicy(String service, ServiceInstanceChooser serviceInstanceChooser);\n}", "des": "Factory class used to customize the retry functionality throughout Spring Cloud."}
{"index": 6699, "repo": "spring-cloud-commons-3.1.7", "code": "public class ReactiveCompositeDiscoveryClient extends Object implements ReactiveDiscoveryClient {\n\t// A human-readable description of the implementation, used in HealthIndicator.\n\tString description();\n\tList<ReactiveDiscoveryClient> getDiscoveryClients();\n\t// Gets all ServiceInstances associated with a particular serviceId.\n\treactor.core.publisher.Flux<ServiceInstance> getInstances(String serviceId);\n\treactor.core.publisher.Flux<String> getServices();\n}", "des": "A ReactiveDiscoveryClient that is composed of other discovery clients and delegates calls to each of them in order."}
{"index": 6700, "repo": "spring-cloud-commons-3.1.7", "code": "public interface ReactiveDiscoveryHealthIndicator {\n\t// Provide the name of health indicator.\n\tString getName();\n\t// Provide the indicator of health.\n\treactor.core.publisher.Mono<org.springframework.boot.actuate.health.Health> health();\n}", "des": "A health indicator interface specific to a reactive discovery client implementation."}
{"index": 6701, "repo": "spring-cloud-commons-3.1.7", "code": "public interface RemoteResource {\n\t// Returns the Link to the resource if it is available, or null if it is gone (i.e.\n\torg.springframework.hateoas.Link getLink();\n\t// Discovers the resource if it hasn't been discovered yet or has become unavailable.\n\tvoid verifyOrDiscover();\n}", "des": "A REST resource that can be discovered and can be either gone or available."}
{"index": 6702, "repo": "spring-cloud-commons-3.1.7", "code": "public interface ServiceInstanceChooser {\n\t// Chooses a ServiceInstance from the LoadBalancer for the specified service.\n\tServiceInstance choose(String serviceId);\n\t// Chooses a ServiceInstance from the LoadBalancer for the specified service and LoadBalancer request.\n\t<T> ServiceInstance choose(String serviceId, Request<T> request);\n}", "des": "Implemented by classes which use a load balancer to choose a server to send a request to."}
{"index": 6703, "repo": "spring-cloud-commons-3.1.7", "code": "public interface ServiceRegistry<R extends Registration> {\n\t// Closes the ServiceRegistry.\n\tvoid close();\n\t// Deregisters the registration.\n\tvoid deregister(R registration);\n\t// Gets the status of a particular registration.\n\t<T> T getStatus(R registration);\n\t// Registers the registration.\n\tvoid register(R registration);\n\t// Sets the status of the registration.\n\tvoid setStatus(R registration, String status);\n}", "des": "Contract to register and deregister instances with a Service Registry."}
{"index": 6704, "repo": "spring-cloud-commons-3.1.7", "code": "public class SimpleDiscoveryClient extends Object implements DiscoveryClient {\n\t// A human-readable description of the implementation, used in HealthIndicator.\n\tString description();\n\t// Gets all ServiceInstances associated with a particular serviceId.\n\tList<ServiceInstance> getInstances(String serviceId);\n\t// Default implementation for getting order of discovery clients.\n\tint getOrder();\n\tList<String> getServices();\n}", "des": "A DiscoveryClient that will use the properties file as a source of service instances."}
{"index": 6705, "repo": "spring-cloud-commons-3.1.7", "code": "public class SimpleReactiveDiscoveryClient extends Object implements ReactiveDiscoveryClient {\n\t// A human-readable description of the implementation, used in HealthIndicator.\n\tString description();\n\t// Gets all ServiceInstances associated with a particular serviceId.\n\treactor.core.publisher.Flux<ServiceInstance> getInstances(String serviceId);\n\t// Default implementation for getting order of discovery clients.\n\tint getOrder();\n\treactor.core.publisher.Flux<String> getServices();\n}", "des": "A ReactiveDiscoveryClient that will use the properties file as a source of service instances."}
{"index": 6706, "repo": "spring-data-neo4j-7.1.2", "code": "public static final class CompositeProperty.DefaultToMapConverter<K> extends Object implements Neo4jPersistentPropertyToMapConverter<K,Map<K,Object>> {\n\t// Composes the object back from the map.\n\tMap<K,Object> compose(Map<K,org.neo4j.driver.Value> source, Neo4jConversionService conversionService);\n\t// Decomposes an object into a map.\n\tMap<K,org.neo4j.driver.Value> decompose(Map<K,Object> property, Neo4jConversionService conversionService);\n}", "des": "The default implementation, passing map properties through as they are on the way to the graph and possibly applying a post processor on the way out of the graph."}
{"index": 6707, "repo": "spring-data-neo4j-7.1.2", "code": "public static enum CompositeProperty.Phase extends Enum<CompositeProperty.Phase> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic CompositeProperty.Phase valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic CompositeProperty.Phase[] values();\n}", "des": "Phase of the mapping currently taking place."}
{"index": 6708, "repo": "spring-data-neo4j-7.1.2", "code": "@API(status=STABLE, since=\"6.0\") @FunctionalInterface public interface DatabaseSelectionProvider {\n\t// Creates a statically configured database selection provider always selecting the database with the given name databaseName.\n\tstatic DatabaseSelectionProvider createStaticDatabaseSelectionProvider(String databaseName);\n\tDatabaseSelection getDatabaseSelection();\n\t// A database selection provider always returning the default selection.\n\tstatic DatabaseSelectionProvider getDefaultSelectionProvider();\n}", "des": "A provider interface that knows in which database repositories or either the reactive or imperative template should work."}
{"index": 6709, "repo": "spring-data-neo4j-7.1.2", "code": "public static interface FluentFindOperation.TerminatingFind<T> extends FluentFindOperation.TerminatingFindWithoutQuery<T> {\n\t// Get exactly zero or one result.\n\tdefault Optional<T> one();\n\t// Get exactly zero or one result.\n\tT oneValue();\n}", "des": "Triggers find execution by calling one of the terminating methods."}
{"index": 6710, "repo": "spring-data-neo4j-7.1.2", "code": "public static interface Neo4jClient.OngoingBindSpec<T,S extends Neo4jClient.BindSpec<S>> {\n\t// Bind one convertible object to the given name.\n\tS to(String name);\n\t// Use a binder function for the previously defined value.\n\tS with(Function<T,Map<String,Object>> binder);\n}", "des": "Ongoing bind specification."}
{"index": 6711, "repo": "spring-data-neo4j-7.1.2", "code": "public static interface Neo4jClient.RunnableSpec extends Neo4jClient.BindSpec<Neo4jClient.RunnableSpec> {\n\t// Fetch all records mapped into generic maps\n\tNeo4jClient.RecordFetchSpec<Map<String,Object>> fetch();\n\t// Create a mapping for each record return to a specific type.\n\t<T> Neo4jClient.MappingSpec<T> fetchAs(Class<T> targetClass);\n\t// Execute the query and discard the results.\n\torg.neo4j.driver.summary.ResultSummary run();\n}", "des": "Contract for a runnable query that can be either run returning its result, run without results or be parameterized."}
{"index": 6712, "repo": "spring-data-neo4j-7.1.2", "code": "public static interface Neo4jClient.UnboundRunnableSpec extends Neo4jClient.RunnableSpec {\n\t// Pins the previously defined query to an impersonated user.\n\tNeo4jClient.RunnableSpecBoundToUser asUser(String asUser);\n\t// Pins the previously defined query to a specific database.\n\tNeo4jClient.RunnableSpecBoundToDatabase in(String targetDatabase);\n}", "des": "Contract for a runnable query specification which still can be bound to a specific database and an impersonated user."}
{"index": 6713, "repo": "spring-data-neo4j-7.1.2", "code": "@API(status=STABLE, since=\"6.0.2\") public final class Neo4jEntityScanner extends Object {\n\tstatic Neo4jEntityScanner get();\n\tstatic Neo4jEntityScanner get(ResourceLoader resourceLoader);\n\t// Scan for entities with the specified annotations.\n\tSet<Class<?>> scan(String... basePackages);\n\t// Scan for entities with the specified annotations.\n\tSet<Class<?>> scan(Collection<String> packages);\n}", "des": "A utility class providing a way to discover an initial entity set for a Neo4jMappingContext."}
{"index": 6714, "repo": "spring-data-neo4j-7.1.2", "code": "@API(status=STABLE, since=\"6.0\") public interface Neo4jPersistentPropertyToMapConverter<K,P> {\n\t// Composes the object back from the map.\n\tP compose(Map<K,org.neo4j.driver.Value> source, Neo4jConversionService neo4jConversionService);\n\t// Decomposes an object into a map.\n\tMap<K,org.neo4j.driver.Value> decompose(P property, Neo4jConversionService neo4jConversionService);\n}", "des": "You need to provide an implementation of this interface in case you want to store a property of an entity as separate properties on a node."}
{"index": 6715, "repo": "spring-data-neo4j-7.1.2", "code": "public static record Neo4jPropertyValueTransformers.NegatedValue(Object value) extends Record {\n\t// Indicates whether some other object is \"equal to\" this one.\n\tfinal boolean equals(Object o);\n\t// Returns the value of the value record component.\n\tObject value();\n}", "des": "A wrapper indicating a negated value (will be used as n.property != $parameter (in case of string properties all operators and not only the equality operator are supported, such as not (n.property contains 'x')."}
{"index": 6716, "repo": "spring-data-neo4j-7.1.2", "code": "public static enum NestedRelationshipProcessingStateMachine.ProcessState extends Enum<NestedRelationshipProcessingStateMachine.ProcessState> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic NestedRelationshipProcessingStateMachine.ProcessState valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic NestedRelationshipProcessingStateMachine.ProcessState[] values();\n}", "des": "Valid processing states."}
{"index": 6717, "repo": "spring-data-neo4j-7.1.2", "code": "public static interface ReactiveNeo4jClient.RunnableSpec extends Neo4jClient.BindSpec<ReactiveNeo4jClient.RunnableSpec> {\n\t// Fetch all records mapped into generic maps\n\tReactiveNeo4jClient.RecordFetchSpec<Map<String,Object>> fetch();\n\t// Create a mapping for each record return to a specific type.\n\t<T> ReactiveNeo4jClient.MappingSpec<T> fetchAs(Class<T> targetClass);\n\t// Execute the query and discard the results.\n\treactor.core.publisher.Mono<org.neo4j.driver.summary.ResultSummary> run();\n}", "des": "Contract for a runnable query that can be either run returning its result, run without results or be parameterized."}
{"index": 6718, "repo": "spring-data-neo4j-7.1.2", "code": "public static interface ReactiveNeo4jClient.UnboundRunnableSpec extends ReactiveNeo4jClient.RunnableSpec {\n\t// Pins the previously defined query to an impersonated user.\n\tReactiveNeo4jClient.RunnableSpecBoundToUser asUser(String asUser);\n\t// Pins the previously defined query to a specific database.\n\tReactiveNeo4jClient.RunnableSpecBoundToDatabase in(String targetDatabase);\n}", "des": "Contract for a runnable query specification which still can be bound to a specific database and an impersonated user."}
{"index": 6719, "repo": "spring-data-neo4j-7.1.2", "code": "public static enum Relationship.Direction extends Enum<Relationship.Direction> {\n\tRelationship.Direction opposite();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Relationship.Direction valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Relationship.Direction[] values();\n}", "des": "Enumeration of the direction a relationship can take."}
{"index": 6720, "repo": "spring-data-neo4j-7.1.2", "code": "public enum UserAgent extends Enum<UserAgent> {\n\tString getDriverVersion();\n\tString getSdnVersion();\n\tString getSpringDataVersion();\n\t// Returns the enum constant of this class with the specified name.\n\tstatic UserAgent valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic UserAgent[] values();\n}", "des": "Representation of a user agent containing sensible information to identify queries generated by or executed via Spring Data Neo4j."}
{"index": 6721, "repo": "bedrock-core-7.0.2", "code": "public abstract class AbstractFeature extends Object implements Feature {\n\t// Obtains the Extensible to which this Feature has been added.\n\tExtensible getExtensible();\n\t// Determines if a Feature as been added to an Extensible.\n\tboolean isExtending();\n\t// Invoked prior to the Feature being added to the specified Extensible.\n\tvoid onAddingTo(Extensible extensible);\n\t// Invoked prior to the Feature being removed from the specified Extensible.\n\tvoid onRemovingFrom(Extensible extensible);\n}", "des": "An abstract implementation of a Feature."}
{"index": 6722, "repo": "bedrock-core-7.0.2", "code": "public class Cached<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the adapted Deferred.\n\tDeferred<T> getDeferred();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n\t// Release the currently cached object.\n\tT release();\n}", "des": "A Cached object is a specialized Deferred that holds a reference to (ie: caches) an object that was successfully returned by another Deferred."}
{"index": 6723, "repo": "bedrock-core-7.0.2", "code": "public class Capture<T> extends Object implements Iterator<T> {\n\t// Obtains the captured value.\n\tT get();\n\tboolean hasNext();\n\t// Determine if the Capture has captured a value from the underlying Iterator.\n\tboolean hasValue();\n\tT next();\n\t// Obtains a Capture based on a provided Iterator.\n\tstatic <T> Capture<T> of(Supplier<Iterator<T>> supplier);\n\t// Obtains a Capture based on a provided Iterator.\n\tstatic <T> Capture<T> of(Iterator<T> iterator);\n\tvoid remove();\n}", "des": "A Capture is an Iterator that captures and returns a single value from another underlying Iterator."}
{"index": 6724, "repo": "bedrock-core-7.0.2", "code": "public static class Cell.DisplayNull extends Object implements Option {\n\t// Obtains a Cell.DisplayNull with a specific value\n\tstatic Cell.DisplayNull as(String value);\n\t// Obtains a Cell.DisplayNull that displays null content as an empty String.\n\tstatic Cell.DisplayNull asEmptyString();\n\t// Obtains a Cell.DisplayNull that displays null content as the String \"null\" (without quotes)\n\tstatic Cell.DisplayNull asNull();\n\t// Obtains the value to use for displaying null Cell content.\n\tString getValue();\n}", "des": "An Option to define how null is displayed when provided as Cell content."}
{"index": 6725, "repo": "bedrock-core-7.0.2", "code": "public static enum Cell.Justification extends Enum<Cell.Justification> implements Option {\n\t// Formats the specified content in the specified width according to the mode of justification.\n\tString format(String content, int width);\n\t// Returns the enum constant of this type with the specified name.\n\tstatic Cell.Justification valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic Cell.Justification[] values();\n}", "des": "An Option to define how the content of a Cell is to be justified."}
{"index": 6726, "repo": "bedrock-core-7.0.2", "code": "public static class Cell.Separator extends Object implements Option {\n\t// Obtains the Cell.Separator string\n\tString getSeparator();\n\t// Constructs a custom Cell.Separator.\n\tstatic Cell.Separator of(String separator);\n\t// Obtains the standard Cell.Separator.\n\tstatic Cell.Separator standard();\n}", "des": "An Option to define the separator to use between Cells in a Row."}
{"index": 6727, "repo": "bedrock-core-7.0.2", "code": "public static class Cell.Width extends Object implements Option {\n\t// Obtain a Cell.Width that is configured for automatic detection.\n\tstatic Cell.Width autodetect();\n\t// Determines the width of a Cell in characters.\n\tint getCharacters();\n\t// Determines if the width of a Cell should be automatically detected (ie: the Cell has no preference).\n\tboolean isAutoDetect();\n\t// Obtain a Cell.Width for a Cell that is for a specific width\n\tstatic Cell.Width of(int characters);\n}", "des": "An Option to define how the width of a Cell is calculated."}
{"index": 6728, "repo": "bedrock-core-7.0.2", "code": "public class Decoration extends Object implements Option.Collectable {\n\tboolean equals(Object o);\n\t// Obtains the object of the Decoration.\n\tObject get();\n\t// Obtains the type of Option.Collector into which this Option.Collectable should be placed.\n\tClass<Decorations> getCollectorClass();\n\t// Constructs a Decoration.\n\tstatic Decoration of(Object object);\n}", "des": "A Option.Collectable Option representing a \"decoration\" consisting of an immutable reference to a custom object."}
{"index": 6729, "repo": "bedrock-core-7.0.2", "code": "public interface Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tdefault Class<T> getDeferredClass();\n}", "des": "A Deferred object represents a reference some well-known object, that of which may yet not be available."}
{"index": 6730, "repo": "bedrock-core-7.0.2", "code": "public class DeferredAtomicBoolean extends Object implements Deferred<Boolean> {\n\t// Attempts to obtain the underlying object.\n\tBoolean get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<Boolean> getDeferredClass();\n}", "des": "An DeferredAtomicBoolean is a Deferred representation of an AtomicBoolean."}
{"index": 6731, "repo": "bedrock-core-7.0.2", "code": "public class DeferredAtomicInteger extends Object implements Deferred<Integer> {\n\t// Attempts to obtain the underlying object.\n\tInteger get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<Integer> getDeferredClass();\n}", "des": "An DeferredAtomicInteger is a Deferred representation of an AtomicInteger."}
{"index": 6732, "repo": "bedrock-core-7.0.2", "code": "public class DeferredAtomicLong extends Object implements Deferred<Long> {\n\t// Attempts to obtain the underlying object.\n\tLong get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<Long> getDeferredClass();\n}", "des": "An DeferredAtomicLong is a Deferred representation of an AtomicLong."}
{"index": 6733, "repo": "bedrock-core-7.0.2", "code": "public class DeferredCallable<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A Deferred representation of the Callable."}
{"index": 6734, "repo": "bedrock-core-7.0.2", "code": "public class DeferredInvoke<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n\t// This method is a workaround for: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4071957\n\tprotected Object invoke(Method method, Object object, Object... args);\n}", "des": "A DeferredInvoke is a Deferred that represents a request to invoke a non-void, typically non-static method on a Deferred."}
{"index": 6735, "repo": "bedrock-core-7.0.2", "code": "public class DeferredJMXConnector extends Object implements Deferred<JMXConnector> {\n\t// Attempts to obtain the underlying object.\n\tJMXConnector get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<JMXConnector> getDeferredClass();\n\t// Obtain the JMX Connector URL for the DeferredJMXConnector.\n\tString getJMXConnectionURL();\n}", "des": "A DeferredJMXConnector is a Deferred for a JMXConnector."}
{"index": 6736, "repo": "bedrock-core-7.0.2", "code": "public class DeferredMBeanAttribute<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A DeferredMBeanAttribute is a Deferred for an MBean attribute."}
{"index": 6737, "repo": "bedrock-core-7.0.2", "code": "public class DeferredMBeanInfo extends Object implements Deferred<MBeanInfo> {\n\t// Attempts to obtain the underlying object.\n\tMBeanInfo get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<MBeanInfo> getDeferredClass();\n}", "des": "A DeferredMBeanInfo is a Deferred for an MBeanInfo."}
{"index": 6738, "repo": "bedrock-core-7.0.2", "code": "public class DeferredMBeanProxy<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A DeferredMBeanProxy is a Deferred for a local proxy to an MBean."}
{"index": 6739, "repo": "bedrock-core-7.0.2", "code": "public class DeferredNull<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A strongly-typed Deferred implementation that always returns null."}
{"index": 6740, "repo": "bedrock-core-7.0.2", "code": "public class Diagnostics extends Object implements Option {\n\t// Constructs a Diagnostics being disabled.\n\tstatic Diagnostics disabled();\n\t// Constructs a Diagnostics being enabled.\n\tstatic Diagnostics enabled();\n\t// Constructs a Diagnostics.\n\tstatic Diagnostics enabled(boolean enabled);\n\tboolean equals(Object other);\n\t// Determines if Diagnostics is enabled.\n\tboolean isEnabled();\n}", "des": "An Option to define enabled Bedrock diagnostics."}
{"index": 6741, "repo": "bedrock-core-7.0.2", "code": "public class Ensured<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the adapted Deferred.\n\tDeferred<T> getDeferred();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A specialized Deferred implementation that attempts to guarantee a an object reference will be returned when a call to Ensured.get() is made."}
{"index": 6742, "repo": "bedrock-core-7.0.2", "code": "public class Existing<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A Existing is a specialized Deferred implementation that is based on a well-known and already established object, that is guaranteed to be available when Existing.get() is called."}
{"index": 6743, "repo": "bedrock-core-7.0.2", "code": "public interface Feature {\n\t// Invoked prior to the Feature being added to the specified Extensible.\n\tvoid onAddingTo(Extensible extensible);\n\t// Invoked prior to the Feature being removed from the specified Extensible.\n\tvoid onRemovingFrom(Extensible extensible);\n}", "des": "An optional interface implemented by classes that are expected to become features of an Extensible type."}
{"index": 6744, "repo": "bedrock-core-7.0.2", "code": "public class FileHelper extends Object {\n\t// Create a Temporary Folder.\n\tstatic File createTemporaryFolder(String prefix);\n\t// Attempt to recursively delete the specified file or folder.\n\tstatic boolean recursiveDelete(File file);\n\t// Zips the specified files, including directories and nested directories into the specified zip file.\n\tstatic void zip(Iterable<File> files, String baseFolderName, String toZipFile);\n}", "des": "Common File utilities."}
{"index": 6745, "repo": "bedrock-core-7.0.2", "code": "public class Future<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A Future is a Deferred representation of a standard Java Future."}
{"index": 6746, "repo": "bedrock-core-7.0.2", "code": "public class HttpProxy extends Object implements Option {\n\t// Do not use a Proxy for HTTP connections.\n\tstatic HttpProxy none();\n\t// Open a connection to the specified URL using the Proxy defined by this HttpProxy.\n\tHttpURLConnection openConnection(URL url);\n\t// Use the specified Proxy for HTTP connections.\n\tstatic HttpProxy proxy(Proxy proxy);\n\t// Use the proxy of the specified Proxy.Type and InetSocketAddress.\n\tstatic HttpProxy proxy(Proxy.Type type, InetSocketAddress address);\n}", "des": "An Option that can be used to specify a type of HTTP Proxy to use for HTTP connections."}
{"index": 6747, "repo": "bedrock-core-7.0.2", "code": "public class LaunchLogging extends Object implements Option {\n\t// Constructs a LaunchLogging being disabled.\n\tstatic LaunchLogging disabled();\n\t// Constructs a LaunchLogging being enabled.\n\tstatic LaunchLogging enabled();\n\t// Constructs a LaunchLogging.\n\tstatic LaunchLogging enabled(boolean enabled);\n\tboolean equals(Object other);\n\t// Determines if LaunchLogging is enabled.\n\tboolean isEnabled();\n}", "des": "An Option to define enabled Bedrock launch logging."}
{"index": 6748, "repo": "bedrock-core-7.0.2", "code": "public class NeverAvailable<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A NeverAvailable is a specialized Deferred that always throws an PermanentlyUnavailableException when attempting to call NeverAvailable.get()."}
{"index": 6749, "repo": "bedrock-core-7.0.2", "code": "public class NotAvailable<T> extends Object implements Deferred<T> {\n\t// Attempts to obtain the underlying object.\n\tT get();\n\t// Obtains the Class of the Deferred reference.\n\tClass<T> getDeferredClass();\n}", "des": "A NotAvailable is a specialized Deferred that always throw an TemporarilyUnavailableException exception when calling NotAvailable.get()."}
{"index": 6750, "repo": "bedrock-core-7.0.2", "code": "public class Pair<X,Y> extends Object implements Tuple {\n\t// Obtains the value at the specified index.\n\tObject get(int index);\n\t// Obtains the first value of the Pair.\n\tX getX();\n\t// Obtains the second value of the Pair.\n\tY getY();\n\t// Constructs a Pair.\n\tstatic <X, Y> Pair<X,Y> of(X x, Y y);\n\t// Obtains the number of values in the Tuple.\n\tint size();\n}", "des": "An immutable sequence of two type-safe values."}
{"index": 6751, "repo": "bedrock-core-7.0.2", "code": "public class Primes extends Object {\n\t// Obtains the closest prime number to the specified value.\n\tstatic int closestPrimeTo(int n);\n\t// Obtains the largest prime known to Primes.\n\tstatic int largestPrime();\n\t// Obtains the ith prime number, the first being 2.\n\tstatic int nthPrime(int i);\n}", "des": "A utility class for working with prime numbers between 1 and 1000;"}
{"index": 6752, "repo": "bedrock-core-7.0.2", "code": "public class ProxyHelper extends Object {\n\t// Creates a dynamic proxy of the specified Class routing all method calls to the specified interceptor.\n\tstatic <T> T createProxyOf(Class<T> clazz, ProxyHelper.Interceptor interceptor);\n\t// Creates a dynamic proxy of the specified Object routing all method calls to the specified interceptor.\n\tstatic <T> T createProxyOf(T object, Object interceptor);\n}", "des": "A collection of utilities to assist in using Mockito to create object proxies."}
{"index": 6753, "repo": "bedrock-core-7.0.2", "code": "public class Quadruple<A,B,C,D> extends Object implements Tuple {\n\t// Obtains the value at the specified index.\n\tObject get(int index);\n\t// Obtains the first value of the Quadruple.\n\tA getA();\n\t// Obtains the second value of the Quadruple.\n\tB getB();\n\t// Obtains the third value of the Quadruple.\n\tC getC();\n\t// Obtains the fourth value of the Quadruple.\n\tD getD();\n\t// Obtains the number of values in the Tuple.\n\tint size();\n}", "des": "An immutable sequence of four type-safe values."}
{"index": 6754, "repo": "bedrock-core-7.0.2", "code": "public class Row extends Object implements Iterable<Cell> {\n\t// Adds a Cell to the Row\n\tRow addCell(Cell cell);\n\t// Adds Cell content to the Row\n\tRow addCell(String cell);\n\t// Obtains the specified Cell from the Row (or null if the Cell number is out-of-bounds.\n\tCell getCell(int index);\n\t// Obtains the formatting OptionsByType for the Row.\n\tOptionsByType getOptions();\n\tIterator<Cell> iterator();\n\t// Obtains the number of Cells (ie: the width) in the Row\n\tint width();\n}", "des": "A Row represents zero or more horizontally arranged Cells in a Table."}
{"index": 6755, "repo": "bedrock-core-7.0.2", "code": "public class StopWatch extends Object {\n\t// Obtains the amount of elapsed time in the specified units for the StopWatch.\n\tlong getElapsedTimeIn(TimeUnit units);\n\t// Starts the StopWatch.\n\tvoid start();\n\t// Stops the StopWatch so that the duration can be measured.\n\tvoid stop();\n}", "des": "A simple class that provides the functionality of a stop watch with millisecond accuracy (though this is based on the level of accuracy provided by the underlying operating system)."}
{"index": 6756, "repo": "bedrock-core-7.0.2", "code": "public class SystemProperties extends Object {\n\t// Creates a snapshot (copy) of the existing system properties.\n\tstatic Properties createSnapshot();\n\t// Replaces the current system properties with those defined by the specified Properties collection.\n\tstatic void replaceWith(Properties properties);\n}", "des": "A helper class for working with System Properties."}
{"index": 6757, "repo": "bedrock-core-7.0.2", "code": "public class Tabularize extends Object {\n\t// Obtains a Table representation of a Map (ordered by key).\n\tstatic final Table tabularize(Map<?,?> map);\n\t// Obtains a Table representation of a Properties (ordered by property name).\n\tstatic final Table tabularize(Properties properties);\n}", "des": "Methods to support creating Tables from common data-structures."}
{"index": 6758, "repo": "bedrock-core-7.0.2", "code": "public class Triple<X,Y,Z> extends Object implements Tuple {\n\t// Obtains the value at the specified index.\n\tObject get(int index);\n\t// Obtains the first value of the Triple.\n\tX getX();\n\t// Obtains the second value of the Triple.\n\tY getY();\n\t// Obtains the third value of the Triple.\n\tZ getZ();\n\t// Obtains the number of values in the Tuple.\n\tint size();\n}", "des": "An immutable sequence of three type-safe values."}
{"index": 6759, "repo": "bedrock-core-7.0.2", "code": "public interface Tuple {\n\t// Obtains the value at the specified index.\n\tObject get(int index);\n\t// Obtains the number of values in the Tuple.\n\tint size();\n}", "des": "An immutable sequence of values, each potentially of a different type."}
{"index": 6760, "repo": "bedrock-core-7.0.2", "code": "public class Variable extends Object implements Option.Collectable {\n\t// Obtains the type of Option.Collector into which this Option.Collectable should be placed.\n\tClass<Variables> getCollectorClass();\n\t// Obtains the name of the Variable.\n\tString getName();\n\t// Obtains the value of the Variable.\n\tObject getValue();\n\t// Constructs a Variable.\n\tstatic Variable with(String name, Object object);\n}", "des": "A Option.Collectable Option representing a variable, consisting of a name and value, for an ExpressionEvaluator."}
{"index": 6761, "repo": "bedrock-core-7.0.2", "code": "public class Version extends Object implements Comparable<Version> {\n\tint compareTo(Version other);\n\tboolean equals(Object o);\n\t// Constructs a Version by parsing the specified components of a version number.\n\tstatic Version of(String... strings);\n\t// Construct a Version representing an unknown version number.\n\tstatic Version unknown();\n}", "des": "A utility class for representing Version numbers and comparing them."}
{"index": 6762, "repo": "spring-kafka-3.0.9", "code": "protected static interface AbstractKafkaHeaderMapper.HeaderMatcher {\n\t// Return true if this matcher is a negative matcher.\n\tboolean isNegated();\n\t// Return true if the header matches.\n\tboolean matchHeader(String headerName);\n}", "des": "A matcher for headers."}
{"index": 6763, "repo": "spring-kafka-3.0.9", "code": "protected static class AbstractKafkaHeaderMapper.NeverMatchHeaderMatcher extends Object implements AbstractKafkaHeaderMapper.HeaderMatcher {\n\t// Return true if this matcher is a negative matcher.\n\tboolean isNegated();\n\t// Return true if the header matches.\n\tboolean matchHeader(String headerName);\n}", "des": "A matcher that never matches a set of headers."}
{"index": 6764, "repo": "spring-kafka-3.0.9", "code": "protected static class AbstractKafkaHeaderMapper.SimplePatternBasedHeaderMatcher extends Object implements AbstractKafkaHeaderMapper.HeaderMatcher {\n\t// Return true if this matcher is a negative matcher.\n\tboolean isNegated();\n\t// Return true if the header matches.\n\tboolean matchHeader(String headerName);\n}", "des": "A pattern-based header matcher that matches if the specified header matches the specified simple pattern."}
{"index": 6765, "repo": "spring-kafka-3.0.9", "code": "public class ABSwitchCluster extends Object implements Supplier<String> {\n\tString get();\n\t// Get whether or not the primary cluster is active.\n\tboolean isPrimary();\n\t// Use the primary cluster.\n\tvoid primary();\n\t// Use the secondary cluster.\n\tvoid secondary();\n}", "des": "A Supplier for bootstrap servers that can toggle between 2 lists of servers."}
{"index": 6766, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface AcknowledgingConsumerAwareMessageListener<K,V> extends MessageListener<K,V> {\n\t// Invoked with data from kafka.\n\tdefault void onMessage(org.apache.kafka.clients.consumer.ConsumerRecord<K,V> data);\n\t// Invoked with data from kafka and provides access to the Consumer.\n\tvoid onMessage(org.apache.kafka.clients.consumer.ConsumerRecord<K,V> data, Acknowledgment acknowledgment, org.apache.kafka.clients.consumer.Consumer<?,?> consumer);\n}", "des": "Listener for handling incoming Kafka messages, propagating an acknowledgment handle that recipients can invoke when the message has been processed."}
{"index": 6767, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface AcknowledgingMessageListener<K,V> extends MessageListener<K,V> {\n\t// Invoked with data from kafka.\n\tdefault void onMessage(org.apache.kafka.clients.consumer.ConsumerRecord<K,V> data);\n\t// Invoked with data from kafka.\n\tvoid onMessage(org.apache.kafka.clients.consumer.ConsumerRecord<K,V> data, Acknowledgment acknowledgment);\n}", "des": "Listener for handling incoming Kafka messages, propagating an acknowledgment handle that recipients can invoke when the message has been processed."}
{"index": 6768, "repo": "spring-kafka-3.0.9", "code": "public final class AdapterUtils extends Object {\n\t// Build a ConsumerRecordMetadata from data which must be a ConsumerRecord.\n\tstatic ConsumerRecordMetadata buildConsumerRecordMetadata(Object data);\n\t// Build a ConsumerRecordMetadata from the first ConsumerRecord in data, if any.\n\tstatic Object buildConsumerRecordMetadataFromArray(Object... data);\n\t// Return the default expression when no SendTo value is present.\n\tstatic String getDefaultReplyTopicExpression();\n}", "des": "Utilities for listener adapters."}
{"index": 6769, "repo": "spring-kafka-3.0.9", "code": "public interface BackOffHandler {\n\t// Perform the next back off.\n\tdefault void onNextBackOff(MessageListenerContainer container, Exception exception, long nextBackOff);\n\t// Perform the next back off for a partition.\n\tdefault void onNextBackOff(MessageListenerContainer container, org.apache.kafka.common.TopicPartition partition, long nextBackOff);\n}", "des": "Handler for the provided back off time, listener container and exception."}
{"index": 6770, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface BatchAcknowledgingConsumerAwareMessageListener<K,V> extends BatchMessageListener<K,V> {\n\t// Invoked with data from kafka.\n\tdefault void onMessage(List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> data);\n\t// Invoked with data from kafka and provides access to the Consumer.\n\tvoid onMessage(List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> data, Acknowledgment acknowledgment, org.apache.kafka.clients.consumer.Consumer<?,?> consumer);\n}", "des": "Listener for handling a batch of incoming Kafka messages, propagating an acknowledgment handle that recipients can invoke when the message has been processed."}
{"index": 6771, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface BatchAcknowledgingMessageListener<K,V> extends BatchMessageListener<K,V> {\n\t// Invoked with data from kafka.\n\tdefault void onMessage(List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> data);\n\t// Invoked with data from kafka.\n\tvoid onMessage(List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> data, Acknowledgment acknowledgment);\n}", "des": "Listener for handling a batch of incoming Kafka messages, propagating an acknowledgment handle that recipients can invoke when the message has been processed."}
{"index": 6772, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface BatchConsumerAwareMessageListener<K,V> extends BatchMessageListener<K,V> {\n\t// Invoked with data from kafka.\n\tdefault void onMessage(List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> data);\n\t// Invoked with data from kafka and provides access to the Consumer.\n\tvoid onMessage(List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> data, org.apache.kafka.clients.consumer.Consumer<?,?> consumer);\n}", "des": "Listener for handling a batch of incoming Kafka messages; the list is created from the consumer records object returned by a poll."}
{"index": 6773, "repo": "spring-kafka-3.0.9", "code": "public class BatchListenerFailedException extends KafkaException {\n\t// Return the index in the batch of the failed record.\n\tint getIndex();\n\tString getMessage();\n\t// Return the failed record.\n\torg.apache.kafka.clients.consumer.ConsumerRecord<?,?> getRecord();\n}", "des": "An exception thrown by user code to inform the framework which record in a batch has failed."}
{"index": 6774, "repo": "spring-kafka-3.0.9", "code": "public class CompositeKafkaStreamsInfrastructureCustomizer extends Object implements KafkaStreamsInfrastructureCustomizer {\n\t// Add customizers.\n\tvoid addKafkaStreamsCustomizers(KafkaStreamsInfrastructureCustomizer... customizers);\n\t// Configure the builder.\n\tvoid configureBuilder(org.apache.kafka.streams.StreamsBuilder builder);\n\t// Configure the topology.\n\tvoid configureTopology(org.apache.kafka.streams.Topology topology);\n}", "des": "Composite KafkaStreamsInfrastructureCustomizer customizes KafkaStreams by delegating to a list of provided KafkaStreamsInfrastructureCustomizer."}
{"index": 6775, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface ConsumerAwareListenerErrorHandler extends KafkaListenerErrorHandler {\n\t// Handle the error.\n\tdefault Object handleError(org.springframework.messaging.Message<?> message, ListenerExecutionFailedException exception);\n\t// Handle the error.\n\tObject handleError(org.springframework.messaging.Message<?> message, ListenerExecutionFailedException exception, org.apache.kafka.clients.consumer.Consumer<?,?> consumer);\n}", "des": "An error handler that has access to the consumer."}
{"index": 6776, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface ConsumerAwareMessageListener<K,V> extends MessageListener<K,V> {\n\t// Invoked with data from kafka.\n\tdefault void onMessage(org.apache.kafka.clients.consumer.ConsumerRecord<K,V> data);\n\t// Invoked with data from kafka and provides access to the Consumer.\n\tvoid onMessage(org.apache.kafka.clients.consumer.ConsumerRecord<K,V> data, org.apache.kafka.clients.consumer.Consumer<?,?> consumer);\n}", "des": "Listener for handling individual incoming Kafka messages."}
{"index": 6777, "repo": "spring-kafka-3.0.9", "code": "public static interface ConsumerFactory.Listener<K,V> {\n\t// A new consumer was created.\n\tdefault void consumerAdded(String id, org.apache.kafka.clients.consumer.Consumer<K,V> consumer);\n\t// An existing consumer was removed.\n\tdefault void consumerRemoved(String id, org.apache.kafka.clients.consumer.Consumer<K,V> consumer);\n}", "des": "Called whenever a consumer is added or removed."}
{"index": 6778, "repo": "spring-kafka-3.0.9", "code": "public interface ConsumerPauseResumeEventPublisher {\n\t// Publish a consumer paused event.\n\tvoid publishConsumerPausedEvent(Collection<org.apache.kafka.common.TopicPartition> partitions, String reason);\n\t// Publish a consumer resumed event.\n\tvoid publishConsumerResumedEvent(Collection<org.apache.kafka.common.TopicPartition> partitions);\n}", "des": "Objects that can publish consumer pause/resume events."}
{"index": 6779, "repo": "spring-kafka-3.0.9", "code": "public static enum ConsumerRetryAuthEvent.Reason extends Enum<ConsumerRetryAuthEvent.Reason> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ConsumerRetryAuthEvent.Reason valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ConsumerRetryAuthEvent.Reason[] values();\n}", "des": "Reasons for retrying auth a consumer."}
{"index": 6780, "repo": "spring-kafka-3.0.9", "code": "public static enum ConsumerStoppedEvent.Reason extends Enum<ConsumerStoppedEvent.Reason> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ConsumerStoppedEvent.Reason valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ConsumerStoppedEvent.Reason[] values();\n}", "des": "Reasons for stopping a consumer."}
{"index": 6781, "repo": "spring-kafka-3.0.9", "code": "public class ContainerPausingBackOffHandler extends Object implements BackOffHandler {\n\t// Perform the next back off.\n\tvoid onNextBackOff(MessageListenerContainer container, Exception exception, long nextBackOff);\n\t// Perform the next back off for a partition.\n\tvoid onNextBackOff(MessageListenerContainer container, org.apache.kafka.common.TopicPartition partition, long nextBackOff);\n}", "des": "A BackOffHandler that pauses the container for the backoff."}
{"index": 6782, "repo": "spring-kafka-3.0.9", "code": "public static enum ContainerProperties.AckMode extends Enum<ContainerProperties.AckMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ContainerProperties.AckMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ContainerProperties.AckMode[] values();\n}", "des": "The offset commit behavior enumeration."}
{"index": 6783, "repo": "spring-kafka-3.0.9", "code": "public static enum ContainerProperties.AssignmentCommitOption extends Enum<ContainerProperties.AssignmentCommitOption> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ContainerProperties.AssignmentCommitOption valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ContainerProperties.AssignmentCommitOption[] values();\n}", "des": "Offset commit behavior during assignment."}
{"index": 6784, "repo": "spring-kafka-3.0.9", "code": "public static enum ContainerProperties.EOSMode extends Enum<ContainerProperties.EOSMode> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ContainerProperties.EOSMode valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ContainerProperties.EOSMode[] values();\n}", "des": "Mode for exactly once semantics."}
{"index": 6785, "repo": "spring-kafka-3.0.9", "code": "public class ConversionException extends KafkaException {\n\t// Return the Message, if available.\n\torg.springframework.messaging.Message<?> getMsg();\n\t// Return the consumer record, if available.\n\torg.apache.kafka.clients.consumer.ConsumerRecord<?,?> getRecord();\n\t// Return the consumer record, if available.\n\tList<org.apache.kafka.clients.consumer.ConsumerRecord<?,?>> getRecords();\n}", "des": "Exception for conversions."}
{"index": 6786, "repo": "spring-kafka-3.0.9", "code": "public static class DeadLetterPublishingRecoverer.HeaderNames extends Object {\n\t// The header names for the exception headers.\n\tDeadLetterPublishingRecoverer.HeaderNames.ExceptionInfo getExceptionInfo();\n\t// The header names for the original record headers.\n\tDeadLetterPublishingRecoverer.HeaderNames.Original getOriginal();\n}", "des": "Container class for the name of the headers that will be added to the produced record."}
{"index": 6787, "repo": "spring-kafka-3.0.9", "code": "public static enum DeadLetterPublishingRecoverer.HeaderNames.HeadersToAdd extends Enum<DeadLetterPublishingRecoverer.HeaderNames.HeadersToAdd> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic DeadLetterPublishingRecoverer.HeaderNames.HeadersToAdd valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic DeadLetterPublishingRecoverer.HeaderNames.HeadersToAdd[] values();\n}", "des": "Bits representing which headers to add."}
{"index": 6788, "repo": "spring-kafka-3.0.9", "code": "public static class DeadLetterPublishingRecoverer.HeaderNames.Original extends Object {\n\t// The header name for the consumer group.\n\tString getConsumerGroup();\n\t// The header name for the offset.\n\tString getOffsetHeader();\n\t// The header name for the partition.\n\tString getPartitionHeader();\n\t// The header name for the timestamp.\n\tString getTimestampHeader();\n\t// The header name for the timestamp type.\n\tString getTimestampTypeHeader();\n\t// The header name for the topic.\n\tString getTopicHeader();\n}", "des": "Header names for original record property headers."}
{"index": 6789, "repo": "spring-kafka-3.0.9", "code": "public class DeserializationException extends KafkaException {\n\t// Get the data that failed deserialization (value or key).\n\tbyte[] getData();\n\t// Get the headers.\n\torg.apache.kafka.common.header.Headers getHeaders();\n\t// True if deserialization of the key failed, otherwise deserialization of the value failed.\n\tboolean isKey();\n\t// Set the headers.\n\tvoid setHeaders(org.apache.kafka.common.header.Headers headers);\n}", "des": "Exception returned in the consumer record value or key when a deserialization failure occurs."}
{"index": 6790, "repo": "spring-kafka-3.0.9", "code": "public enum DltStrategy extends Enum<DltStrategy> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic DltStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic DltStrategy[] values();\n}", "des": "Strategies for handling DLT processing."}
{"index": 6791, "repo": "spring-kafka-3.0.9", "code": "public class EndpointHandlerMethod extends Object {\n\t// Return the method.\n\tMethod getMethod();\n\t// Return the method name.\n\tString getMethodName();\n\tObject resolveBean(org.springframework.beans.factory.BeanFactory beanFactory);\n}", "des": "Handler method for retrying endpoints."}
{"index": 6792, "repo": "spring-kafka-3.0.9", "code": "public static enum Jackson2JavaTypeMapper.TypePrecedence extends Enum<Jackson2JavaTypeMapper.TypePrecedence> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic Jackson2JavaTypeMapper.TypePrecedence valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic Jackson2JavaTypeMapper.TypePrecedence[] values();\n}", "des": "The precedence for type conversion - inferred from the method parameter or message headers."}
{"index": 6793, "repo": "spring-kafka-3.0.9", "code": "public abstract class KafkaEvent extends org.springframework.context.ApplicationEvent {\n\t// Get the container for which the event was published, which will be the parent container if the source that emitted the event is a child container, or the source itself otherwise.\n\t<T> T getContainer(Class<T> type);\n\t// Get the container (source) that published the event.\n\t<T> T getSource(Class<T> type);\n}", "des": "Base class for events."}
{"index": 6794, "repo": "spring-kafka-3.0.9", "code": "public static enum KafkaException.Level extends Enum<KafkaException.Level> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic KafkaException.Level valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic KafkaException.Level[] values();\n}", "des": "The log level for KafkaException."}
{"index": 6795, "repo": "spring-kafka-3.0.9", "code": "public abstract class KafkaExceptionLogLevelAware extends Object {\n\t// Set the level at which the exception thrown by this handler is logged.\n\tprotected KafkaException.Level getLogLevel();\n\t// Set the level at which the exception thrown by this handler is logged.\n\tvoid setLogLevel(KafkaException.Level logLevel);\n}", "des": "A top level abstract class for classes that can be configured with a KafkaException.Level."}
{"index": 6796, "repo": "spring-kafka-3.0.9", "code": "public interface KafkaHeaderMapper {\n\t// Map from the given MessageHeaders to the specified target headers.\n\tvoid fromHeaders(org.springframework.messaging.MessageHeaders headers, org.apache.kafka.common.header.Headers target);\n\t// Map from the given native headers to a map of headers for the eventual MessageHeaders.\n\tvoid toHeaders(org.apache.kafka.common.header.Headers source, Map<String,Object> target);\n}", "des": "Header mapper for Apache Kafka."}
{"index": 6797, "repo": "spring-kafka-3.0.9", "code": "public static enum KafkaJaasLoginModuleInitializer.ControlFlag extends Enum<KafkaJaasLoginModuleInitializer.ControlFlag> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic KafkaJaasLoginModuleInitializer.ControlFlag valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic KafkaJaasLoginModuleInitializer.ControlFlag[] values();\n}", "des": "Control flag values for login configuration."}
{"index": 6798, "repo": "spring-kafka-3.0.9", "code": "public enum KafkaListenerObservation extends Enum<KafkaListenerObservation> implements io.micrometer.observation.docs.ObservationDocumentation {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic KafkaListenerObservation valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic KafkaListenerObservation[] values();\n}", "des": "Spring for Apache Kafka Observation for listeners."}
{"index": 6799, "repo": "spring-kafka-3.0.9", "code": "public static enum KafkaListenerObservation.ListenerLowCardinalityTags extends Enum<KafkaListenerObservation.ListenerLowCardinalityTags> implements io.micrometer.common.docs.KeyName {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic KafkaListenerObservation.ListenerLowCardinalityTags valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic KafkaListenerObservation.ListenerLowCardinalityTags[] values();\n}", "des": "Low cardinality tags."}
{"index": 6800, "repo": "spring-kafka-3.0.9", "code": "public class KafkaRecordReceiverContext extends io.micrometer.observation.transport.ReceiverContext<org.apache.kafka.clients.consumer.ConsumerRecord<?,?>> {\n\t// Return the listener id.\n\tString getListenerId();\n\t// Return the consumer record.\n\torg.apache.kafka.clients.consumer.ConsumerRecord<?,?> getRecord();\n\t// Return the source topic.\n\tString getSource();\n}", "des": "ReceiverContext for ConsumerRecords."}
{"index": 6801, "repo": "spring-kafka-3.0.9", "code": "public class KafkaRecordSenderContext extends io.micrometer.observation.transport.SenderContext<org.apache.kafka.clients.producer.ProducerRecord<?,?>> {\n\t// Return the template's bean name.\n\tString getBeanName();\n\t// Return the destination topic.\n\tString getDestination();\n\t// Return the producer record.\n\torg.apache.kafka.clients.producer.ProducerRecord<?,?> getRecord();\n}", "des": "SenderContext for ProducerRecords."}
{"index": 6802, "repo": "spring-kafka-3.0.9", "code": "public abstract class KafkaResourceFactory extends Object {\n\t// Enhance the properties by calling the setBootstrapServersSupplier(Supplier) and replace the bootstrap servers properties.\n\tprotected void checkBootstrap(Map<String,Object> configs);\n\tprotected String getBootstrapServers();\n\t// Set a supplier for the bootstrap server list to override any configured in a subclass.\n\tvoid setBootstrapServersSupplier(Supplier<String> bootstrapServersSupplier);\n}", "des": "Base class for consumer/producer/admin creators."}
{"index": 6803, "repo": "spring-kafka-3.0.9", "code": "public interface KafkaStreamsInfrastructureCustomizer {\n\t// Configure the builder.\n\tdefault void configureBuilder(org.apache.kafka.streams.StreamsBuilder builder);\n\t// Configure the topology.\n\tdefault void configureTopology(org.apache.kafka.streams.Topology topology);\n}", "des": "A customizer for infrastructure components such as the StreamsBuilder and Topology."}
{"index": 6804, "repo": "spring-kafka-3.0.9", "code": "public class KafkaStreamsMicrometerListener extends Object implements StreamsBuilderFactoryBean.Listener {\n\t// A new KafkaStreams was created.\n\tvoid streamsAdded(String id, org.apache.kafka.streams.KafkaStreams kafkaStreams);\n\t// An existing KafkaStreams was removed.\n\tvoid streamsRemoved(String id, org.apache.kafka.streams.KafkaStreams streams);\n}", "des": "Creates a KafkaStreamsMetrics for the KafkaStreams."}
{"index": 6805, "repo": "spring-kafka-3.0.9", "code": "public enum KafkaTemplateObservation extends Enum<KafkaTemplateObservation> implements io.micrometer.observation.docs.ObservationDocumentation {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic KafkaTemplateObservation valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic KafkaTemplateObservation[] values();\n}", "des": "Spring for Apache Kafka Observation for KafkaTemplate."}
{"index": 6806, "repo": "spring-kafka-3.0.9", "code": "public static enum KafkaTemplateObservation.TemplateLowCardinalityTags extends Enum<KafkaTemplateObservation.TemplateLowCardinalityTags> implements io.micrometer.common.docs.KeyName {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic KafkaTemplateObservation.TemplateLowCardinalityTags valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic KafkaTemplateObservation.TemplateLowCardinalityTags[] values();\n}", "des": "Low cardinality tags."}
{"index": 6807, "repo": "spring-kafka-3.0.9", "code": "public class ListenerContainerNoLongerIdleEvent extends KafkaEvent {\n\t// Retrieve the consumer.\n\torg.apache.kafka.clients.consumer.Consumer<?,?> getConsumer();\n\t// How long the container was idle.\n\tlong getIdleTime();\n\t// The id of the listener (if @KafkaListener) or the container bean name.\n\tString getListenerId();\n\t// The TopicPartitions the container is listening to.\n\tCollection<org.apache.kafka.common.TopicPartition> getTopicPartitions();\n}", "des": "An event that is emitted when a container is no longer idle if configured to publish idle events."}
{"index": 6808, "repo": "spring-kafka-3.0.9", "code": "public class ListenerContainerPartitionNoLongerIdleEvent extends KafkaEvent {\n\t// Retrieve the consumer.\n\torg.apache.kafka.clients.consumer.Consumer<?,?> getConsumer();\n\t// How long the partition was idle.\n\tlong getIdleTime();\n\t// The id of the listener (if @KafkaListener) or the container bean name.\n\tString getListenerId();\n\t// The idle TopicPartition.\n\torg.apache.kafka.common.TopicPartition getTopicPartition();\n}", "des": "An event that is emitted when a partition is no longer idle if configured to publish idle events."}
{"index": 6809, "repo": "spring-kafka-3.0.9", "code": "public interface ListenerMetadata {\n\t// Return the group id.\n\tString getGroupId();\n\t// Return the listener id.\n\tString getListenerId();\n\t// Return the listener info.\n\tbyte[] getListenerInfo();\n}", "des": "Metadata associated to a KafkaListener."}
{"index": 6810, "repo": "spring-kafka-3.0.9", "code": "public enum ListenerType extends Enum<ListenerType> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic ListenerType valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic ListenerType[] values();\n}", "des": "Defines the listener type."}
{"index": 6811, "repo": "spring-kafka-3.0.9", "code": "public static enum LogIfLevelEnabled.Level extends Enum<LogIfLevelEnabled.Level> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic LogIfLevelEnabled.Level valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic LogIfLevelEnabled.Level[] values();\n}", "des": "Logging levels."}
{"index": 6812, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface ManualAckListenerErrorHandler extends KafkaListenerErrorHandler {\n\t// Handle the error.\n\tdefault Object handleError(org.springframework.messaging.Message<?> message, ListenerExecutionFailedException exception);\n\t// Handle the error.\n\tObject handleError(org.springframework.messaging.Message<?> message, ListenerExecutionFailedException exception, org.apache.kafka.clients.consumer.Consumer<?,?> consumer, Acknowledgment ack);\n}", "des": "A KafkaListenerErrorHandler that supports manual acks."}
{"index": 6813, "repo": "spring-kafka-3.0.9", "code": "public class MappingJacksonParameterizedConverter extends org.springframework.messaging.converter.MappingJackson2MessageConverter {\n\tprotected Object convertFromInternal(org.springframework.messaging.Message<?> message, Class<?> targetClass, Object conversionHint);\n\t// Return the type mapper.\n\tJackson2JavaTypeMapper getTypeMapper();\n\t// Set a customized type mapper.\n\tvoid setTypeMapper(Jackson2JavaTypeMapper typeMapper);\n}", "des": "Subclass of MappingJackson2MessageConverter that can handle parameterized (generic) types."}
{"index": 6814, "repo": "spring-kafka-3.0.9", "code": "public interface MessageConverter {\n\t// Set up the common headers.\n\tdefault void commonHeaders(Acknowledgment acknowledgment, org.apache.kafka.clients.consumer.Consumer<?,?> consumer, Map<String,Object> rawHeaders, Object theKey, Object topic, Object partition, Object offset, Object timestampType, Object timestamp);\n\t// Get the thread bound group id.\n\tstatic String getGroupId();\n}", "des": "A top level interface for message converters."}
{"index": 6815, "repo": "spring-kafka-3.0.9", "code": "public static record MessagingMessageListenerAdapter.ReplyExpressionRoot(Object request, Object source, Object result) extends Record {\n\t// Indicates whether some other object is \"equal to\" this one.\n\tfinal boolean equals(Object o);\n\t// Returns the value of the request record component.\n\tObject request();\n\t// Returns the value of the result record component.\n\tObject result();\n\t// Returns the value of the source record component.\n\tObject source();\n}", "des": "Root object for reply expression evaluation."}
{"index": 6816, "repo": "spring-kafka-3.0.9", "code": "public class MicrometerConsumerListener<K,V> extends Object implements ConsumerFactory.Listener<K,V> {\n\t// A new consumer was created.\n\tvoid consumerAdded(String id, org.apache.kafka.clients.consumer.Consumer<K,V> consumer);\n\t// An existing consumer was removed.\n\tvoid consumerRemoved(String id, org.apache.kafka.clients.consumer.Consumer<K,V> consumer);\n}", "des": "A consumer factory listener that manages KafkaClientMetrics."}
{"index": 6817, "repo": "spring-kafka-3.0.9", "code": "public final class MicrometerHolder extends Object {\n\t// Remove the timers.\n\tvoid destroy();\n\t// Record failure.\n\tvoid failure(Object sample, String exception);\n\t// Record failure.\n\tvoid failure(Object sample, String exception, Object record);\n\t// Start the timer.\n\tObject start();\n\t// Record success.\n\tvoid success(Object sample);\n\t// Record success.\n\tvoid success(Object sample, Object record);\n}", "des": "A wrapper for micrometer timers when available on the class path."}
{"index": 6818, "repo": "spring-kafka-3.0.9", "code": "public class MicrometerProducerListener<K,V> extends Object implements ProducerFactory.Listener<K,V> {\n\t// A new producer was created.\n\tvoid producerAdded(String id, org.apache.kafka.clients.producer.Producer<K,V> producer);\n\t// An existing producer was removed.\n\tvoid producerRemoved(String id, org.apache.kafka.clients.producer.Producer<K,V> producer);\n}", "des": "A producer factory listener that manages KafkaClientMetrics."}
{"index": 6819, "repo": "spring-kafka-3.0.9", "code": "public class MultiMethodKafkaListenerEndpoint<K,V> extends MethodKafkaListenerEndpoint<K,V> {\n\t// Create a HandlerAdapter for this listener adapter.\n\tprotected HandlerAdapter configureListenerAdapter(MessagingMessageListenerAdapter<K,V> messageListener);\n\t// Set a payload validator.\n\tvoid setValidator(org.springframework.validation.Validator validator);\n}", "des": "The MethodKafkaListenerEndpoint extension for several POJO methods based on the KafkaHandler."}
{"index": 6820, "repo": "spring-kafka-3.0.9", "code": "public class NonResponsiveConsumerEvent extends KafkaEvent {\n\t// Retrieve the consumer.\n\torg.apache.kafka.clients.consumer.Consumer<?,?> getConsumer();\n\t// The id of the listener (if @KafkaListener) or the container bean name.\n\tString getListenerId();\n\t// How long since the last poll.\n\tlong getTimeSinceLastPoll();\n\t// The TopicPartitions the container is listening to.\n\tCollection<org.apache.kafka.common.TopicPartition> getTopicPartitions();\n}", "des": "An event that is emitted when a consumer is not responding to the poll; with early versions of the kafka-clients, this was a possible indication that the broker is down."}
{"index": 6821, "repo": "spring-kafka-3.0.9", "code": "public static interface ProducerFactory.Listener<K,V> {\n\t// A new producer was created.\n\tdefault void producerAdded(String id, org.apache.kafka.clients.producer.Producer<K,V> producer);\n\t// An existing producer was removed.\n\tdefault void producerRemoved(String id, org.apache.kafka.clients.producer.Producer<K,V> producer);\n}", "des": "Called whenever a producer is added or removed."}
{"index": 6822, "repo": "spring-kafka-3.0.9", "code": "public class ProjectingMessageConverter extends MessagingMessageConverter {\n\t// Subclasses can convert the payload; by default, it's sent unchanged to Kafka.\n\tprotected Object convertPayload(org.springframework.messaging.Message<?> message);\n\t// Subclasses can convert the value; by default, it's returned as provided by Kafka unless there is a SmartMessageConverter that can convert it.\n\tprotected Object extractAndConvertValue(org.apache.kafka.clients.consumer.ConsumerRecord<?,?> record, Type type);\n}", "des": "A MessageConverter implementation that uses a Spring Data ProjectionFactory to bind incoming messages to projection interfaces."}
{"index": 6823, "repo": "spring-kafka-3.0.9", "code": "public interface RecordFilterStrategy<K,V> {\n\t// Return true if the record should be discarded.\n\tboolean filter(org.apache.kafka.clients.consumer.ConsumerRecord<K,V> consumerRecord);\n\t// Filter an entire batch of records; to filter all records, return an empty list, not null.\n\tdefault List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> filterBatch(List<org.apache.kafka.clients.consumer.ConsumerRecord<K,V>> records);\n}", "des": "Implementations of this interface can signal that a record about to be delivered to a message listener should be discarded instead of being delivered."}
{"index": 6824, "repo": "spring-kafka-3.0.9", "code": "@FunctionalInterface public interface ReplyHeadersConfigurer {\n\t// A map of additional headers to add to the reply message.\n\tdefault Map<String,Object> additionalHeaders();\n\t// Return true if the header should be copied to the reply message.\n\tboolean shouldCopy(String headerName, Object headerValue);\n}", "des": "A strategy for configuring which headers, if any, should be set in a reply message."}
{"index": 6825, "repo": "spring-kafka-3.0.9", "code": "public static class RetryTopicConfigurationSupport.BlockingRetriesConfigurer extends Object {\n\t// Set the BackOff that should be used with the blocking retry mechanism.\n\tRetryTopicConfigurationSupport.BlockingRetriesConfigurer backOff(org.springframework.util.backoff.BackOff backoff);\n\t// Set the exceptions that should be retried by the blocking retry mechanism.\n\tfinal RetryTopicConfigurationSupport.BlockingRetriesConfigurer retryOn(Class<? extends Exception>... exceptions);\n}", "des": "Configure blocking retries to be used along non-blocking."}
{"index": 6826, "repo": "spring-kafka-3.0.9", "code": "public enum SameIntervalTopicReuseStrategy extends Enum<SameIntervalTopicReuseStrategy> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic SameIntervalTopicReuseStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic SameIntervalTopicReuseStrategy[] values();\n}", "des": "Strategy for topic reuse when multiple, sequential retries have the same backoff interval."}
{"index": 6827, "repo": "spring-kafka-3.0.9", "code": "public static interface StreamsBuilderFactoryBean.Listener {\n\t// A new KafkaStreams was created.\n\tdefault void streamsAdded(String id, org.apache.kafka.streams.KafkaStreams streams);\n\t// An existing KafkaStreams was removed.\n\tdefault void streamsRemoved(String id, org.apache.kafka.streams.KafkaStreams streams);\n}", "des": "Called whenever a KafkaStreams is added or removed."}
{"index": 6828, "repo": "spring-kafka-3.0.9", "code": "public interface ThreadStateProcessor {\n\t// Call to clear thread-bound resources which were set up in setupThreadState(Consumer).\n\tdefault void clearThreadState(org.apache.kafka.clients.consumer.Consumer<?,?> consumer);\n\t// Call to set up thread-bound resources which will be available for the entire duration of enclosed operation involving a Consumer.\n\tdefault void setupThreadState(org.apache.kafka.clients.consumer.Consumer<?,?> consumer);\n}", "des": "A general interface for managing thread-bound resources when a Consumer is available."}
{"index": 6829, "repo": "spring-kafka-3.0.9", "code": "public class TopicPartitionOffset extends Object {\n\tboolean equals(Object o);\n\tLong getOffset();\n\tint getPartition();\n\tTopicPartitionOffset.SeekPosition getPosition();\n\tString getTopic();\n\torg.apache.kafka.common.TopicPartition getTopicPartition();\n\tboolean isRelativeToCurrent();\n\t// Set the offset.\n\tvoid setOffset(Long offset);\n\t// Set whether the offset is relative to the current position.\n\tvoid setRelativeToCurrent(boolean relativeToCurrent);\n}", "des": "A configuration container to represent a topic name, partition number and, optionally, an offset for it."}
{"index": 6830, "repo": "spring-kafka-3.0.9", "code": "public static enum TopicPartitionOffset.SeekPosition extends Enum<TopicPartitionOffset.SeekPosition> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic TopicPartitionOffset.SeekPosition valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic TopicPartitionOffset.SeekPosition[] values();\n}", "des": "Enumeration for \"special\" seeks."}
{"index": 6831, "repo": "spring-kafka-3.0.9", "code": "public enum TopicSuffixingStrategy extends Enum<TopicSuffixingStrategy> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic TopicSuffixingStrategy valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic TopicSuffixingStrategy[] values();\n}", "des": "Constants for the RetryTopic functionality."}
{"index": 6832, "repo": "maven-core-4.0.0-alpha-7", "code": "public abstract class AbstractEventSpy extends Object implements EventSpy {\n\t// Notifies the spy of Maven's termination, allowing it to free any resources allocated by it.\n\tvoid close();\n\t// Initializes the spy.\n\tvoid init(EventSpy.Context context);\n\t// Notifies the spy of some build event/operation.\n\tvoid onEvent(Object event);\n}", "des": "A skeleton eventspy that does nothing other than helping implementors."}
{"index": 6833, "repo": "maven-core-4.0.0-alpha-7", "code": "public abstract class AbstractMavenLifecycleParticipant extends Object {\n\t// Invoked after all MavenProject instances have been created.\n\tvoid afterProjectsRead(MavenSession session);\n\t// Invoked after all projects were built.\n\tvoid afterSessionEnd(MavenSession session);\n\t// Invoked after MavenSession instance has been created.\n\tvoid afterSessionStart(MavenSession session);\n}", "des": "Allows core extensions to participate in Maven build session lifecycle."}
{"index": 6834, "repo": "maven-core-4.0.0-alpha-7", "code": "public abstract class BuildSummary extends Object {\n\t// Gets the project being summarized.\n\tMavenProject getProject();\n\t// Gets the build time of the project in milliseconds.\n\tlong getTime();\n}", "des": "Summarizes the result of a project build in the reactor."}
{"index": 6835, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface ClassRealmConstituent {\n\t// Gets the artifact id of the constituent's artifact.\n\tString getArtifactId();\n\t// Gets the classifier of the constituent's artifact.\n\tString getClassifier();\n\t// Gets the file of the constituent's artifact.\n\tFile getFile();\n\t// Gets the group id of the constituent's artifact.\n\tString getGroupId();\n\t// Gets the type of the constituent's artifact.\n\tString getType();\n\t// Gets the version of the constituent's artifact.\n\tString getVersion();\n}", "des": "Describes a constituent of a class realm."}
{"index": 6836, "repo": "maven-core-4.0.0-alpha-7", "code": "public static enum ClassRealmRequest.RealmType extends Enum<ClassRealmRequest.RealmType> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ClassRealmRequest.RealmType valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ClassRealmRequest.RealmType[] values();\n}", "des": "The type of a class realm."}
{"index": 6837, "repo": "maven-core-4.0.0-alpha-7", "code": "public class CoreExports extends Object {\n\t// Returns artifacts exported by Maven core and core extensions.\n\tSet<String> getExportedArtifacts();\n\t// Returns packages exported by Maven core and core extensions.\n\tMap<String,ClassLoader> getExportedPackages();\n}", "des": "Provides information about artifacts (identified by groupId:artifactId string key) and classpath elements exported by Maven core itself and loaded Maven core extensions."}
{"index": 6838, "repo": "maven-core-4.0.0-alpha-7", "code": "@Named @Singleton public class DefaultLegacySupport extends Object implements LegacySupport {\n\t// Gets the currently active repository session.\n\torg.eclipse.aether.RepositorySystemSession getRepositorySession();\n\t// Gets the currently active session.\n\tMavenSession getSession();\n\t// Sets the currently active session.\n\tvoid setSession(MavenSession session);\n}", "des": "Helps to provide backward-compatibility with plugins that use legacy components."}
{"index": 6839, "repo": "maven-core-4.0.0-alpha-7", "code": "public class DefaultLifecycleMapping extends Object implements LifecycleMapping {\n\tMap<String,Lifecycle> getLifecycles();\n\t// Deprecated.\n\tList<String> getOptionalMojos(String lifecycle);\n\t// Deprecated.\n\tMap<String,String> getPhases(String lifecycle);\n}", "des": "DefaultLifecycleMapping"}
{"index": 6840, "repo": "maven-core-4.0.0-alpha-7", "code": "@Named @Singleton public class DefaultMetadataReader extends Object implements MetadataReader {\n\t// Reads the metadata from the specified file.\n\tMetadata read(File input, Map<String,?> options);\n\t// Reads the metadata from the specified byte stream.\n\tMetadata read(InputStream input, Map<String,?> options);\n\t// Reads the metadata from the specified character reader.\n\tMetadata read(Reader input, Map<String,?> options);\n}", "des": "Handles deserialization of metadata from some kind of textual format like XML."}
{"index": 6841, "repo": "maven-core-4.0.0-alpha-7", "code": "@Named @Singleton public class DefaultRuntimeInformation extends Object implements RuntimeInformation {\n\t// Retrieves the current Maven version, for example \"3.0.2\".\n\tString getMavenVersion();\n\t// Checks whether the current Maven runtime matches the specified version range.\n\tboolean isMavenVersion(String versionRange);\n}", "des": "Provides information about the current Maven runtime."}
{"index": 6842, "repo": "maven-core-4.0.0-alpha-7", "code": "public abstract class DefaultToolchain extends Object implements Toolchain, ToolchainPrivate {\n\tfinal void addProvideToken(String type, RequirementMatcher matcher);\n\tboolean equals(Object obj);\n\tprotected org.slf4j.Logger getLog();\n\tfinal ToolchainModel getModel();\n\t// get the type of toolchain.\n\tfinal String getType();\n\t// Let the toolchain decide if it matches requirements defined in the toolchain plugin configuration.\n\tboolean matchesRequirements(Map<String,String> requirements);\n}", "des": "Default abstract toolchain implementation, to be used as base class for any toolchain implementation to avoid rewriting usual code."}
{"index": 6843, "repo": "maven-core-4.0.0-alpha-7", "code": "@Named @Singleton public class DefaultToolchainManagerPrivate extends DefaultToolchainManager implements ToolchainManagerPrivate {\n\t// Retrieves every toolchains of given type available in user settings.\n\tToolchainPrivate[] getToolchainsForType(String type, MavenSession session);\n\t// Stores the toolchain into build context for later use by toolchain-aware plugins.\n\tvoid storeToolchainToBuildContext(ToolchainPrivate toolchain, MavenSession session);\n}", "des": "TODO: refactor this, component extending component is bad practice."}
{"index": 6844, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface EventSpy {\n\t// Notifies the spy of Maven's termination, allowing it to free any resources allocated by it.\n\tvoid close();\n\t// Initializes the spy.\n\tvoid init(EventSpy.Context context);\n\t// Notifies the spy of some build event/operation.\n\tvoid onEvent(Object event);\n}", "des": "A core extension to monitor Maven's execution."}
{"index": 6845, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface ExecutionEvent {\n\t// Gets the exception that caused the event (if any).\n\tException getException();\n\t// Gets the current mojo execution (if any).\n\tMojoExecution getMojoExecution();\n\t// Gets the current project (if any).\n\tMavenProject getProject();\n\t// Gets the session from which this event originates.\n\tMavenSession getSession();\n\t// Gets the type of the event.\n\tExecutionEvent.Type getType();\n}", "des": "Holds data relevant for an execution event."}
{"index": 6846, "repo": "maven-core-4.0.0-alpha-7", "code": "public static enum ExecutionEvent.Type extends Enum<ExecutionEvent.Type> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ExecutionEvent.Type valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ExecutionEvent.Type[] values();\n}", "des": "The possible types of execution events."}
{"index": 6847, "repo": "maven-core-4.0.0-alpha-7", "code": "@Named(\"jdk\") @Singleton public class JavaToolchainFactory extends Object implements ToolchainFactory {\n\t// Returns the default instance of the particular type of toolchain, can return null if not applicable.\n\tToolchainPrivate createDefaultToolchain();\n\t// Create instance of toolchain.\n\tToolchainPrivate createToolchain(ToolchainModel model);\n\tprotected org.slf4j.Logger getLogger();\n}", "des": "JDK toolchain factory."}
{"index": 6848, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface LegacySupport {\n\t// Gets the currently active repository session.\n\torg.eclipse.aether.RepositorySystemSession getRepositorySession();\n\t// Gets the currently active session.\n\tMavenSession getSession();\n\t// Sets the currently active session.\n\tvoid setSession(MavenSession session);\n}", "des": "Helps to provide backward-compatibility with plugins that use legacy components."}
{"index": 6849, "repo": "maven-core-4.0.0-alpha-7", "code": "public class Lifecycle extends Object {\n\t// Method getId\n\tString getId();\n\t// Method getLifecyclePhases\n\tMap<String,LifecyclePhase> getLifecyclePhases();\n\t// Deprecated.\n\tMap<String,String> getPhases();\n\t// Method setId\n\tvoid setId(String id);\n\t// Method setLifecyclePhases\n\tvoid setLifecyclePhases(Map<String,LifecyclePhase> lifecyclePhases);\n\t// Deprecated.\n\tvoid setPhases(Map<String,String> phases);\n}", "des": "Lifecycle definition for a packaging (multiple packagings share the same lifecycle id = usually \"default\")."}
{"index": 6850, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface LifecycleMapping {\n\tMap<String,Lifecycle> getLifecycles();\n\t// Deprecated.\n\tList<String> getOptionalMojos(String lifecycle);\n\t// Deprecated.\n\tMap<String,String> getPhases(String lifecycle);\n}", "des": "LifecycleMapping"}
{"index": 6851, "repo": "maven-core-4.0.0-alpha-7", "code": "public class MetadataParseException extends IOException {\n\t// Gets the one-based index of the column containing the error.\n\tint getColumnNumber();\n\t// Gets the one-based index of the line containing the error.\n\tint getLineNumber();\n}", "des": "Signals a failure to parse the metadata due to invalid syntax (e.g."}
{"index": 6852, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface MetadataReader {\n\t// Reads the metadata from the specified file.\n\tMetadata read(File input, Map<String,?> options);\n\t// Reads the metadata from the specified byte stream.\n\tMetadata read(InputStream input, Map<String,?> options);\n\t// Reads the metadata from the specified character reader.\n\tMetadata read(Reader input, Map<String,?> options);\n}", "des": "Handles deserialization of metadata from some kind of textual format like XML."}
{"index": 6853, "repo": "maven-core-4.0.0-alpha-7", "code": "public static enum MojoExecution.Source extends Enum<MojoExecution.Source> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MojoExecution.Source valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MojoExecution.Source[] values();\n}", "des": "Describes the source of an execution."}
{"index": 6854, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface PluginPrefixResult {\n\t// The resolved artifact id for the plugin.\n\tString getArtifactId();\n\t// The resolved group id for the plugin.\n\tString getGroupId();\n\t// The repository from which the plugin prefix was resolved.\n\torg.eclipse.aether.repository.ArtifactRepository getRepository();\n}", "des": "Describes the result of a plugin prefix resolution request."}
{"index": 6855, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface PluginVersionResult {\n\t// The repository from which the plugin version was resolved.\n\torg.eclipse.aether.repository.ArtifactRepository getRepository();\n\t// The resolved plugin version.\n\tString getVersion();\n}", "des": "Describes the result of a plugin version resolution request."}
{"index": 6856, "repo": "maven-core-4.0.0-alpha-7", "code": "public static enum ProjectBuildingRequest.RepositoryMerging extends Enum<ProjectBuildingRequest.RepositoryMerging> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ProjectBuildingRequest.RepositoryMerging valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ProjectBuildingRequest.RepositoryMerging[] values();\n}", "des": "The possible merge modes for combining remote repositories."}
{"index": 6857, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface ProjectBuildingResult {\n\t// Gets the result of the dependency resolution for the project.\n\tDependencyResolutionResult getDependencyResolutionResult();\n\t// Gets the POM file from which the project was built.\n\tFile getPomFile();\n\t// Gets the problems that were encountered during the project building.\n\tList<ModelProblem> getProblems();\n\t// Gets the project that was built.\n\tMavenProject getProject();\n\t// Gets the identifier of the project that could not be built.\n\tString getProjectId();\n}", "des": "Collects the output of the project builder."}
{"index": 6858, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface ProjectDependencyGraph {\n\t// Gets all collected projects.\n\tList<MavenProject> getAllProjects();\n\t// Gets the downstream projects of the specified project.\n\tList<MavenProject> getDownstreamProjects(MavenProject project, boolean transitive);\n\t// Gets all projects in their intended build order, i.e.\n\tList<MavenProject> getSortedProjects();\n\t// Gets the upstream projects of the specified project.\n\tList<MavenProject> getUpstreamProjects(MavenProject project, boolean transitive);\n}", "des": "Describes the interdependencies between projects in the reactor."}
{"index": 6859, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface RuntimeInformation {\n\t// Retrieves the current Maven version, for example \"3.0.2\".\n\tString getMavenVersion();\n\t// Checks whether the current Maven runtime matches the specified version range.\n\tboolean isMavenVersion(String versionRange);\n}", "des": "Provides information about the current Maven runtime."}
{"index": 6860, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface Toolchain {\n\t// Gets the platform tool executable.\n\tString findTool(String toolName);\n\t// get the type of toolchain.\n\tString getType();\n}", "des": "Toolchain interface."}
{"index": 6861, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface ToolchainFactory {\n\t// Returns the default instance of the particular type of toolchain, can return null if not applicable.\n\tToolchainPrivate createDefaultToolchain();\n\t// Create instance of toolchain.\n\tToolchainPrivate createToolchain(ToolchainModel model);\n}", "des": "Internal toolchain factory, to prepare toolchains instances."}
{"index": 6862, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface ToolchainManager {\n\t// Retrieve toolchain of specified type from build context.\n\tToolchain getToolchainFromBuildContext(String type, MavenSession context);\n\t// Select all toolchains available in user settings matching the type and requirements, independently from maven-toolchains-plugin.\n\tList<Toolchain> getToolchains(MavenSession session, String type, Map<String,String> requirements);\n}", "des": "Public API for a toolchain-aware plugin to get expected toolchain instance."}
{"index": 6863, "repo": "maven-core-4.0.0-alpha-7", "code": "public interface ToolchainManagerPrivate {\n\t// Retrieves every toolchains of given type available in user settings.\n\tToolchainPrivate[] getToolchainsForType(String type, MavenSession context);\n\t// Stores the toolchain into build context for later use by toolchain-aware plugins.\n\tvoid storeToolchainToBuildContext(ToolchainPrivate toolchain, MavenSession context);\n}", "des": "Component for use by the maven-toolchains-plugin only."}
{"index": 6864, "repo": "jena-core-4.9.0", "code": "public class AbstractDateTime extends Object implements Comparable<AbstractDateTime> {\n\t// Comparison function.\n\tint compare(AbstractDateTime other);\n\t// Normal java comparison function.\n\tint compareTo(AbstractDateTime o);\n\t// Equality function\n\tboolean equals(Object obj);\n\t// If timezone present - normalize dateTime [E Adding durations to dateTimes] Public to allow reuse with type objects.\n\tstatic void normalize(int[] date, int[] timeZone);\n}", "des": "Base class for representation of XSD duration, time, date/time and related datatype instances."}
{"index": 6865, "repo": "jena-core-4.9.0", "code": "public class AddOne extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the second argument to 1+ the first argument."}
{"index": 6866, "repo": "jena-core-4.9.0", "code": "public interface ALiteral extends ANode {\n\t// The datatype URI of a typed literal, or null for an untyped literal.\n\tString getDatatypeURI();\n\t// The value of xml:lang for this literal, often the empty string.\n\tString getLang();\n\t// True if this literal was formed from a rdf:parseType=\"Literal\" construction.\n\tboolean isWellFormedXML();\n}", "des": "A string literal property value from an RDF/XML file."}
{"index": 6867, "repo": "jena-core-4.9.0", "code": "public interface ALiteral extends ANode {\n\t// The datatype URI of a typed literal, or null for an untyped literal.\n\tString getDatatypeURI();\n\t// The value of xml:lang for this literal, often the empty string.\n\tString getLang();\n\t// True if this literal was formed from a rdf:parseType=\"Literal\" construction.\n\tboolean isWellFormedXML();\n}", "des": "A string literal property value from an RDF/XML file."}
{"index": 6868, "repo": "jena-core-4.9.0", "code": "public class AnnotationPropertyImpl extends OntPropertyImpl implements AnnotationProperty {\n\t// Returns the ordinal value of a containment property.\n\tint getOrdinal();\n\t// Answer true to indicate that this resource is an RDF property.\n\tboolean isProperty();\n}", "des": "Implementation for ontology abstraction of annotation property"}
{"index": 6869, "repo": "jena-core-4.9.0", "code": "public interface AResourceInternal extends AResource, ANode {\n\t// Only for blank nodes - non blank need not support.\n\tboolean getHasBeenUsed();\n\t// Only for blank nodes - non blank need not support.\n\tvoid setHasBeenUsed();\n}", "des": "A resource from the input file."}
{"index": 6870, "repo": "jena-core-4.9.0", "code": "public interface AResourceInternal extends AResource, ANode {\n\t// Only for blank nodes - non blank need not support.\n\tboolean getHasBeenUsed();\n\t// Only for blank nodes - non blank need not support.\n\tvoid setHasBeenUsed();\n}", "des": "A resource from the input file."}
{"index": 6871, "repo": "jena-core-4.9.0", "code": "public interface ARPConfig {\n\t// The handlers used during parsing.\n\tARPHandlers getHandlers();\n\t// The options used during parsing.\n\tARPOptions getOptions();\n\t// Copies the handlers from the argument to be used by this instance.\n\tvoid setHandlersWith(ARPHandlers handlers);\n\t// Copies the options from the argument to be used by this instance.\n\tvoid setOptionsWith(ARPOptions opts);\n}", "des": "Used to set event handlers and options on ARP, SAX2Model, and SAX2RDF instances."}
{"index": 6872, "repo": "jena-core-4.9.0", "code": "public interface ARPConfig {\n\t// The handlers used during parsing.\n\tARPHandlers getHandlers();\n\t// The options used during parsing.\n\tARPOptions getOptions();\n\t// Copies the handlers from the argument to be used by this instance.\n\tvoid setHandlersWith(ARPHandlers handlers);\n\t// Copies the options from the argument to be used by this instance.\n\tvoid setOptionsWith(ARPOptions opts);\n}", "des": "Used to set event handlers and options on ARP0, SAX2Model, and SAX2RDF instances."}
{"index": 6873, "repo": "jena-core-4.9.0", "code": "public class AssemblerException extends JenaException {\n\tList<AssemblerGroup.Frame> getDoing();\n\t// Answer the root object whose model-filling was aborted\n\tResource getRoot();\n\t// XXX\n\tAssemblerException pushDoing(AssemblerGroup.Frame frame);\n}", "des": "Assembler Exception class: contains code shared by all the Assembler exceptions."}
{"index": 6874, "repo": "jena-core-4.9.0", "code": "public class AssertDisjointPairs extends BaseBuiltin {\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule head.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n}", "des": "Assert the n^2 differtFrom pairs from a distinctMembers list"}
{"index": 6875, "repo": "jena-core-4.9.0", "code": "public final class Base64 extends Object {\n\t// Decodes Base64 data into octects\n\tstatic byte[] decode(String encoded);\n\t// Encodes hex octects into Base64\n\tstatic String encode(byte[] binaryData);\n}", "des": "This class provides encode/decode for RFC 2045 Base64 as defined by RFC 2045, N."}
{"index": 6876, "repo": "jena-core-4.9.0", "code": "public abstract class BaseGraphMaker extends Object implements GraphMaker {\n\t// Make a fresh anonymous graph.\n\tGraph createGraph();\n\t// A non-strict create.\n\tGraph createGraph(String name);\n\t// Answer the default graph for this maker.\n\tGraph getGraph();\n\t// Answer the default graph of this GraphMaker, if it has one.\n\tGraph openGraph();\n\t// A non-strict open.\n\tGraph openGraph(String name);\n}", "des": "This base class provides convenience functions for the three \"usual\" graph makers and a place to hold the reification style for the graphs it constructs."}
{"index": 6877, "repo": "jena-core-4.9.0", "code": "public interface BindingEnvironment {\n\t// Bind a variable in the current environment to the given value.\n\tboolean bind(Node var, Node value);\n\t// Return the most ground version of the node.\n\tNode getGroundVersion(Node node);\n\t// Instantiate a triple pattern against the current environment.\n\tTriple instantiate(TriplePattern pattern);\n}", "des": "Interface through which the current bound values of variables can be found."}
{"index": 6878, "repo": "jena-core-4.9.0", "code": "public class BindingVectorMultiSet extends Object {\n\t// Increase the current quantity of env\n\tvoid add(BindingVector env);\n\t// Get an iterator over all BindingVectors currently present which match with env\n\tIterator<BindingVector> getSubSet(BindingVector env);\n\t// Copy all item from queue.data into data.\n\tvoid putAll(BindingVectorMultiSet queue);\n\t// Decrease the quantity of env\n\tvoid remove(BindingVector env);\n}", "des": "A multi set of BindingVector's divided in buckets matching an unique combination of values at given indices managed by RETEQueue"}
{"index": 6879, "repo": "jena-core-4.9.0", "code": "public class BlankNodeId extends Object {\n\t// Creates new BlankNodeId with a fresh internal id\n\tstatic BlankNodeId create();\n\t// Creates new BlankNodeId with the given id\n\tstatic BlankNodeId create(String id);\n\t// Test whether two id's are the same\n\tboolean equals(Object other);\n\tboolean equals1(Object obj);\n\t// Answer the label string of this BlankNodeId.\n\tString getLabelString();\n\tint hashCode1();\n}", "des": "System identifier for a blank node."}
{"index": 6880, "repo": "jena-core-4.9.0", "code": "public class Bound extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Predicate used to check if a variable has been bound."}
{"index": 6881, "repo": "jena-core-4.9.0", "code": "public interface ByteList extends List {\n\t// Checks if the byte item is a member of this list.\n\tboolean contains(byte item);\n\t// The number of bytes in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection.\n\tbyte item(int index);\n\t// Construct and return a byte array for bytes contained in this list.\n\tbyte[] toByteArray();\n}", "des": "The ByteList is an immutable ordered collection of byte."}
{"index": 6882, "repo": "jena-core-4.9.0", "code": "public class ByteListImpl extends AbstractList implements ByteList {\n\t// Checks if the byte item is a member of this list.\n\tboolean contains(byte item);\n\tObject get(int index);\n\t// The number of bytes in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection.\n\tbyte item(int index);\n\tint size();\n\t// Construct and return a byte array for bytes contained in this list.\n\tbyte[] toByteArray();\n}", "des": "Implementation of org.apache.xerces.xs.datatypes.ByteList."}
{"index": 6883, "repo": "jena-core-4.9.0", "code": "public class CannotConstructException extends AssemblerException {\n\t// Answer the Assembler that cannot do the construction.\n\tClass<?> getAssemblerClass();\n\t// Answer the (alleged most-specific) type of the object that could not be constructed.\n\tResource getType();\n}", "des": "Exception used to report a failure of a group assembler to construct an object because there is no component assembler associated with the object's most specific type."}
{"index": 6884, "repo": "jena-core-4.9.0", "code": "public class CannotEncodeCharacterException extends JenaException {\n\t// Answer the character that could not be encoded.\n\tchar getBadChar();\n\t// Answer the name of the context in which the encoding failed.\n\tString getEncodingContext();\n}", "des": "Exception to throw when a character cannot be encoded into some context for some reason."}
{"index": 6885, "repo": "jena-core-4.9.0", "code": "public class CharacterModel extends Object {\n\t// Is the character a composing character as defined by the Character Model 2nd Last Call Working Draft.\n\tstatic boolean isComposingChar(char x);\n\t// Is this string fully normalized as defined by the Character Model 2nd Last Call Working Draft.\n\tstatic boolean isFullyNormalizedConstruct(String str);\n\t// Is this string in Unicode Normal Form C.\n\tstatic boolean isNormalFormC(String str);\n\tstatic boolean startsWithComposingCharacter(String str);\n}", "des": "Some support for the Character Model Recommendation from the W3C (currently in second last call working draft)."}
{"index": 6886, "repo": "jena-core-4.9.0", "code": "public class CharacterModel extends Object {\n\t// Is the character a composing character as defined by the Character Model 2nd Last Call Working Draft.\n\tstatic boolean isComposingChar(char x);\n\t// Is this string fully normalized as defined by the Character Model 2nd Last Call Working Draft.\n\tstatic boolean isFullyNormalizedConstruct(String str);\n\t// Is this string in Unicode Normal Form C.\n\tstatic boolean isNormalFormC(String str);\n\tstatic boolean startsWithComposingCharacter(String str);\n}", "des": "Some support for the Character Model Recommendation from the W3C (currently in second last call working draft)."}
{"index": 6887, "repo": "jena-core-4.9.0", "code": "public class ChoicePointFrame extends GenericChoiceFrame {\n\t// Is there another clause in the sequence?\n\tboolean hasNext();\n\t// Initialize a choice point to preserve the current context of the given intepreter and then call the given set of predicates.\n\tvoid init(LPInterpreter interpreter, List<RuleClauseCode> predicateClauses);\n\t// Return the next clause in the sequence.\n\tRuleClauseCode nextClause();\n\t// Note successful return from this choice point.\n\tvoid noteSuccess();\n}", "des": "Represents a single frame in the LP interpreter's choice point stack, represents the OR part of the search tree."}
{"index": 6888, "repo": "jena-core-4.9.0", "code": "public class CollectionGraph extends GraphBase {\n\t// Answer the capabilities of this graph; the default is an AllCapabilities object (the same one each time, not that it matters - Capabilities should be immutable).\n\tCapabilities getCapabilities();\n\t// Add a triple to the triple store.\n\tvoid performAdd(Triple t);\n\t// Remove a triple from the triple store.\n\tvoid performDelete(Triple t);\n}", "des": "A simple graph implementation that wraps a collection of triples."}
{"index": 6889, "repo": "jena-core-4.9.0", "code": "public interface ComplementClass extends BooleanClassDescription {\n\t// Answer the class that the class described by this class description is a complement of.\n\tOntClass getOperand();\n\t// Set the class that the class represented by this class expression is a complement of.\n\tvoid setOperand(Resource cls);\n}", "des": "Class description that is formed from the complement of another class description"}
{"index": 6890, "repo": "jena-core-4.9.0", "code": "public final class Constants extends Object {\n\t// Returns an enumeration of the SAX features.\n\tstatic Enumeration getSAXFeatures();\n\t// Returns an enumeration of the SAX properties.\n\tstatic Enumeration getSAXProperties();\n\t// Returns an enumeration of the Xerces features.\n\tstatic Enumeration getXercesFeatures();\n\t// Returns an enumeration of the Xerces properties.\n\tstatic Enumeration getXercesProperties();\n\t// Prints all of the constants to standard output.\n\tstatic void main(String[] argv);\n}", "des": "Commonly used constants."}
{"index": 6891, "repo": "jena-core-4.9.0", "code": "public class ContNodeIteratorImpl extends NiceIterator<RDFNode> implements NodeIterator {\n\t// default hasNext: no elements, return false.\n\tboolean hasNext();\n\t// default next: throw an exception.\n\tRDFNode next();\n\t// Return the next RDFNode of the iteration.\n\tRDFNode nextNode();\n\t// default remove: we have no elements, so we can't remove any.\n\tvoid remove();\n}", "des": "An internal class not normally of interest to application developers."}
{"index": 6892, "repo": "jena-core-4.9.0", "code": "public class CountLiteralValues extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "CountLiteralValues(X, P, C) sets C to be the number of semantically distinct values for P on resource X."}
{"index": 6893, "repo": "jena-core-4.9.0", "code": "public class DatatypeException extends Exception {\n\t// Return the list of error arguments\n\tObject[] getArgs();\n\t// Return the error code\n\tString getKey();\n\t// Overrides this method to get the formatted and localized error message.\n\tString getMessage();\n}", "des": "Base class for datatype exceptions."}
{"index": 6894, "repo": "jena-core-4.9.0", "code": "public class DatatypeFormatException extends JenaException {\n\t// The datatype that has an invalid lexical form.\n\tRDFDatatype getDataType();\n\t// The invalid lexical form that caused this exception.\n\tString getLexicalForm();\n}", "des": "Exception thrown when a lexical form does not match the stated datatype."}
{"index": 6895, "repo": "jena-core-4.9.0", "code": "public class Difference extends Dyadic implements Graph {\n\tExtendedIterator<Triple> _graphBaseFind(Triple t);\n\t// Add a triple to the difference: add it to the left operand, and remove it from the right operand.\n\tvoid performAdd(Triple t);\n\t// Remove a triple from the difference: remove it from the left operand.\n\tvoid performDelete(Triple t);\n}", "des": "Class representing the dynamic set difference L - R of two graphs."}
{"index": 6896, "repo": "jena-core-4.9.0", "code": "public class Difference extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the third argument to the arithmetic difference between the first and second arguments."}
{"index": 6897, "repo": "jena-core-4.9.0", "code": "public class DisjointUnion extends Dyadic {\n\tboolean graphBaseContains(Triple t);\n\t// Add a triple to the triple store.\n\tvoid performAdd(Triple t);\n\t// Remove a triple from the triple store.\n\tvoid performDelete(Triple t);\n}", "des": "DisjointUnion - a version of Union that assumes the graphs are disjoint, and hence that find need not do duplicate-removal."}
{"index": 6898, "repo": "jena-core-4.9.0", "code": "public class DOM2Model extends SAX2Model {\n\t// Create a new DOM2Model.\n\tstatic DOM2Model createD2M(String base, Model m);\n\t// Create a new DOM2Model.\n\tstatic DOM2Model createD2M(String base, Model m, String lang);\n\t// Parse a DOM Node with the RDF/XML parser, loading the triples into the associated Model.\n\tvoid load(Node document);\n}", "des": "Transform DOM nodes of RDF.XML into Jena Models."}
{"index": 6899, "repo": "jena-core-4.9.0", "code": "public class DOM2Model extends SAX2Model {\n\t// Create a new DOM2Model.\n\tstatic DOM2Model createD2M(String base, Model m);\n\t// Create a new DOM2Model.\n\tstatic DOM2Model createD2M(String base, Model m, String lang);\n\t// Parse a DOM Node with the RDF/XML parser, loading the triples into the associated Model.\n\tvoid load(Node document);\n}", "des": "Transform DOM nodes of RDF.XML into Jena Models."}
{"index": 6900, "repo": "jena-core-4.9.0", "code": "public class Drop extends BaseBuiltin {\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule head.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n\t// Returns false if this builtin is non-monotonic.\n\tboolean isMonotonic();\n}", "des": "A variant of the \"remove\" builtin that will delete matched triples from the graph but will not trigger further rule processing for the removed triples."}
{"index": 6901, "repo": "jena-core-4.9.0", "code": "public abstract class Dyadic extends CompositionBase {\n\t// Close this graph.\n\tvoid close();\n\t// Generic dependsOn, true iff it depends on either of the subgraphs.\n\tboolean dependsOn(Graph other);\n\t// Answer the left (first) operand of this Dyadic.\n\tGraph getL();\n\t// Answer the right (second) operand of this Dyadic.\n\tGraph getR();\n\tUnion union(Graph X);\n}", "des": "Base class for the two-operand composition operations; has two graphs L and R"}
{"index": 6902, "repo": "jena-core-4.9.0", "code": "public interface EntityState {\n\t// Query method to check if entity with this name was declared.\n\tboolean isEntityDeclared(String name);\n\t// Query method to check if entity is unparsed.\n\tboolean isEntityUnparsed(String name);\n}", "des": "The entity state interface defines methods that must be implemented by components that store information about entity declarations, as well as by entity validator that will need to validate attributes of type entity."}
{"index": 6903, "repo": "jena-core-4.9.0", "code": "public class EnvironmentFrame extends FrameObject {\n\t// Allocate a vector of permanent variables for use in the rule execution.\n\tvoid allocate(int n);\n\t// Return the rule associated with this environment, null if no such rule.\n\tRule getRule();\n}", "des": "Represents a single frame in the LP interpreter's environment stack."}
{"index": 6904, "repo": "jena-core-4.9.0", "code": "public class EnvironmentFrameWithDerivation extends EnvironmentFrame {\n\t// Return a safe copy of the list of matched subgoals in this subderivation.\n\tList<Triple> getMatchList();\n\t// Return the final instantiated goal given the current binding state.\n\tTriple getResult();\n\t// Create an initial derivation record for this frame, based on the given argument registers.\n\tvoid initDerivationRecord(Node[] args);\n\t// Instantiate and record a matched subgoal\n\tvoid noteMatch(TriplePattern pattern, int pc);\n}", "des": "Extension of the normal AND-stack environment frame to support incremental derivation logging."}
{"index": 6905, "repo": "jena-core-4.9.0", "code": "public class Equal extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Check that the two args are semantically equal."}
{"index": 6906, "repo": "jena-core-4.9.0", "code": "public interface ExtendedHandler {\n\t// This method is used to modify the behaviour of ARP concerning its reporting of bnode scope endBNodeScope(org.apache.jena.rdfxml.xmlinput.AResource).\n\tboolean discardNodesWithNodeID();\n\t// After this call, no more triples will be reported which use bnode.\n\tvoid endBNodeScope(AResource bnode);\n\t// Called when the </rdf:RDF> tag is seen.\n\tvoid endRDF();\n\t// Called when the <rdf:RDF> tag is seen.\n\tvoid startRDF();\n}", "des": "Extended callbacks from a reader to an RDF application."}
{"index": 6907, "repo": "jena-core-4.9.0", "code": "public interface ExtendedHandler {\n\t// This method is used to modify the behaviour of ARP concerning its reporting of bnode scope endBNodeScope(org.apache.jena.rdfxml.xmlinput0.AResource).\n\tboolean discardNodesWithNodeID();\n\t// After this call, no more triples will be reported which use bnode.\n\tvoid endBNodeScope(AResource bnode);\n\t// Called when the </rdf:RDF> tag is seen.\n\tvoid endRDF();\n\t// Called when the <rdf:RDF> tag is seen.\n\tvoid startRDF();\n}", "des": "Extended callbacks from a reader to an RDF application."}
{"index": 6908, "repo": "jena-core-4.9.0", "code": "public interface FastTripleBunch extends JenaSetHashOptimized<Triple> {\n\t// This method is used to optimize _PO match operations.\n\tboolean anyMatchRandomOrder(Predicate<Triple> predicate);\n\t// Answer true iff this bunch is implemented as an array.\n\tboolean isArray();\n}", "des": "A bunch of triples - a stripped-down set with specialized methods."}
{"index": 6909, "repo": "jena-core-4.9.0", "code": "public class FilterIterator<T> extends WrappedIterator<T> {\n\t// forEachRemaining: defer to the base iterator\n\tvoid forEachRemaining(Consumer<? super T> action);\n\t// Answer true iff there is at least one more acceptable object.\n\tboolean hasNext();\n\t// Answer the next acceptable object from the base iterator.\n\tT next();\n\t// Remove the current member from the underlying iterator.\n\tvoid remove();\n}", "des": "Creates a sub-Iterator by filtering."}
{"index": 6910, "repo": "jena-core-4.9.0", "code": "public interface Finder {\n\t// Return true if the given pattern occurs somewhere in the find sequence.\n\tboolean contains(TriplePattern pattern);\n\t// Basic pattern lookup interface.\n\tExtendedIterator<Triple> find(TriplePattern pattern);\n\t// Extended find interface used in situations where the implementator may or may not be able to answer the complete query.\n\tExtendedIterator<Triple> findWithContinuation(TriplePattern pattern, Finder continuation);\n}", "des": "Minimal interface for preforming simple pattern find operations."}
{"index": 6911, "repo": "jena-core-4.9.0", "code": "public class FinderUtil extends Object {\n\t// Create a continuation object which is a cascade of two continuation objects.\n\tstatic Finder cascade(Finder first, Finder second);\n\t// Create a continuation object which is a cascade of three continuation objects.\n\tstatic Finder cascade(Finder first, Finder second, Finder third);\n\t// Create a continuation object which is a cascade of four continuation objects.\n\tstatic Finder cascade(Finder first, Finder second, Finder third, Finder fourth);\n}", "des": "Some simple helper methods used when working with Finders, particularly to compose them into cascade sequences."}
{"index": 6912, "repo": "jena-core-4.9.0", "code": "public class FrameObject extends Object {\n\t// Close the frame actively.\n\tvoid close();\n\t// Link this frame to an existing frame.\n\tvoid fastLinkTo(FrameObject prior);\n\t// Return the prior frame in the tree.\n\tFrameObject getLink();\n\t// Link this frame to an existing frame.\n\tvoid linkTo(FrameObject prior);\n}", "des": "Base class for stack frame objects."}
{"index": 6913, "repo": "jena-core-4.9.0", "code": "public class FRuleEngineIFactory extends Object {\n\t// Creates a ForwardRuleInfGraphI instance.\n\tFRuleEngineI createFRuleEngineI(ForwardRuleInfGraphI parent, List<Rule> rules, boolean useRETE);\n\t// Return the single global instance of this factory\n\tstatic FRuleEngineIFactory getInstance();\n\t// Replaces the custom global instance.\n\tstatic void setInstance(FRuleEngineIFactory instance);\n}", "des": "Factory class for creating FRuleEngineI."}
{"index": 6914, "repo": "jena-core-4.9.0", "code": "public class FunctorDatatype extends BaseDatatype {\n\t// Compares two instances of values of the given datatype.\n\tboolean isEqual(LiteralLabel value1, LiteralLabel value2);\n\t// Parse a lexical form of this datatype to a value\n\tObject parse(String lexicalForm);\n\t// Convert a value of this datatype out to lexical form.\n\tString unparse(Object value);\n}", "des": "Datatype definition for functor-valued literals."}
{"index": 6915, "repo": "jena-core-4.9.0", "code": "public class GE extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests if the first argument is greater than or equal to the second."}
{"index": 6916, "repo": "jena-core-4.9.0", "code": "public class GenericChoiceFrame extends FrameObject {\n\t// Initialize a choice point to preserve the current context of the given intepreter and then call the given set of predicates.\n\tvoid init(LPInterpreter interpreter);\n\t// Set the continuation point for this frame.\n\tvoid setContinuation(int pc, int ac);\n}", "des": "Core properties of choice frames used use to represent the OR state of the backtracking search."}
{"index": 6917, "repo": "jena-core-4.9.0", "code": "public class GenericRuleReasonerFactory extends Object implements ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n\t// Return the single global instance of this factory\n\tstatic GenericRuleReasonerFactory theInstance();\n}", "des": "Factory object for creating general rule reasoner instances."}
{"index": 6918, "repo": "jena-core-4.9.0", "code": "public class GraphExtract extends Object {\n\t// Answer a new graph which is the reachable subgraph from node in graph with the terminating condition given by the TripleBoundary passed to the constructor.\n\tGraph extract(Node node, Graph graph);\n\t// Answer the graph toUpdate augmented with the sub-graph of extractFrom reachable from root bounded by this instance's TripleBoundary.\n\tGraph extractInto(Graph toUpdate, Node root, Graph extractFrom);\n}", "des": "GraphExtract offers a very simple recursive extraction of a subgraph with a specified root in some supergraph."}
{"index": 6919, "repo": "jena-core-4.9.0", "code": "public class GraphMatcher extends Object {\n\t// Are the two models isomorphic? The isomorphism is defined as a bijection between the anonymous variables such that the statements are identical.\n\tstatic boolean equals(Graph m1, Graph m2);\n\tstatic int hashCode(Graph g);\n\t// Return an isomorphism between the two models.\n\tstatic Node[][] match(Graph m1, Graph m2);\n}", "des": "An implementation of graph isomorphism for Graph equality."}
{"index": 6920, "repo": "jena-core-4.9.0", "code": "public abstract class GraphMemBase extends GraphBase {\n\t// Close this graph; if it is now fully closed, destroy its resources and run the GraphBase close.\n\tvoid close();\n\t// Note a re-opening of this graph by incrementing the count.\n\tGraphMemBase openAgain();\n}", "des": "GraphMemBase - a common base class for GraphMem and SmallGraphMem."}
{"index": 6921, "repo": "jena-core-4.9.0", "code": "public interface GraphWithPerform extends Graph {\n\t// add t to this graph, but do not generate any event\n\tvoid performAdd(Triple t);\n\t// remove t from this graph, but do not generate any event\n\tvoid performDelete(Triple t);\n}", "des": "GraphWithPerform is an implementation interface that extends Graph with the performAdd and performDelete methods used by GraphBase to invoke non-notifying versions of add and delete."}
{"index": 6922, "repo": "jena-core-4.9.0", "code": "public class GreaterThan extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests if the first argument is greater than the second."}
{"index": 6923, "repo": "jena-core-4.9.0", "code": "public abstract class HashCommon<Key> extends Object {\n\t// Answer the item at index i of keys.\n\tObject getItemForTestingAt(int i);\n\tExtendedIterator<Key> keyIterator();\n\tExtendedIterator<Key> keyIterator(HashCommon.NotifyEmpty container);\n\tSpliterator<Key> keySpliterator();\n\t// Remove the object key from this hash's keys if it is present (if it's absent, do nothing).\n\tvoid remove(Key key);\n}", "des": "Shared stuff for our hashing implementations: does the base work for hashing and growth sizes."}
{"index": 6924, "repo": "jena-core-4.9.0", "code": "public abstract class HashCommonBase<E> extends Object {\n\tboolean anyMatch(Predicate<E> predicate);\n\tboolean containsKey(E key);\n\tboolean isEmpty();\n\tExtendedIterator<E> keyIterator();\n\tSpliterator<E> keySpliterator();\n\t// Remove the object key from this hash's keys if it is present (if it's absent, do nothing).\n\tvoid removeUnchecked(E key);\n\tint size();\n\t// Remove the object key from this hash's keys if it is present (if it's absent, do nothing).\n\tboolean tryRemove(E key);\n}", "des": "Common code for hash tables and sets."}
{"index": 6925, "repo": "jena-core-4.9.0", "code": "public abstract class HashCommonSet<K> extends HashCommonBase<K> implements JenaSet<K> {\n\t// Add the key to the set without checking if it is already present.\n\tvoid addUnchecked(K key);\n\t// Add the key to the set if it is not already present.\n\tboolean tryAdd(K key);\n}", "des": "Implementation of JenaSet based on HashCommonBase."}
{"index": 6926, "repo": "jena-core-4.9.0", "code": "public class HashedTripleBunch extends HashCommonSet<Triple> implements TripleBunch {\n\t// Clear the collection.\n\tvoid clear();\n\t// Answer true iff this bunch is implemented as an array.\n\tboolean isArray();\n}", "des": "A bunch of triples, implemented as a set of triples."}
{"index": 6927, "repo": "jena-core-4.9.0", "code": "public final class HexBin extends Object {\n\t// Decode hex string to a byte array\n\tstatic byte[] decode(String encoded);\n\t// Encode a byte array to hex string\n\tstatic String encode(byte[] binaryData);\n}", "des": "format validation This class encodes/decodes hexadecimal data @xerces.internal"}
{"index": 6928, "repo": "jena-core-4.9.0", "code": "public class Hide extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule head.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n}", "des": "Register a node as to be hidden from query result iterators."}
{"index": 6929, "repo": "jena-core-4.9.0", "code": "public abstract class Implementation extends Object {\n\t// true iff wrapping (node, eg) would succeed.\n\tabstract boolean canWrap(Node node, EnhGraph eg);\n\t// Create a new EnhNode wrapping a Node in the context of an EnhGraph\n\tabstract EnhNode wrap(Node node, EnhGraph eg);\n}", "des": "Interface defining a generic factory interface for generating enhanced nodes from normal graph nodes."}
{"index": 6930, "repo": "jena-core-4.9.0", "code": "public class Intersection extends Dyadic implements Graph {\n\t// Add a triple to the triple store.\n\tvoid performAdd(Triple t);\n\t// Remove a triple from the triple store.\n\tvoid performDelete(Triple t);\n}", "des": "The dynamic intersection of two graphs L and R."}
{"index": 6931, "repo": "jena-core-4.9.0", "code": "public final class IntStack extends Object {\n\t// Clears the stack.\n\tvoid clear();\n\t// Returns the element at the specified depth in the stack.\n\tint elementAt(int depth);\n\t// Peeks at the top of the stack.\n\tint peek();\n\t// Pops a value off of the stack.\n\tint pop();\n\t// Prints the stack.\n\tvoid print();\n\t// Pushes a value onto the stack.\n\tvoid push(int value);\n\t// Returns the size of the stack.\n\tint size();\n}", "des": "A simple integer based stack."}
{"index": 6932, "repo": "jena-core-4.9.0", "code": "public interface IRIProvider {\n\t// Create an IRI, throw IRIException if the string does not conform to the grammar or violates additional rules of the provider.\n\tvoid check(String iriStr);\n\t// Create an IRI, throw IRIException if the string does not conform to the grammar.\n\tIRIx create(String iri);\n\tboolean isStrictMode(String scheme);\n\t// Run in strict mode - the exact definition of \"strict\" depends on the provider.\n\tvoid strictMode(String scheme, boolean runStrict);\n}", "des": "Provider: an implementation of a factory for IRIs."}
{"index": 6933, "repo": "jena-core-4.9.0", "code": "public class IRIProviderJDK extends Object implements IRIProvider {\n\t// Create an IRI, throw IRIException if the string does not conform to the grammar or violates additional rules of the provider.\n\tvoid check(String iriStr);\n\t// Create an IRI, throw IRIException if the string does not conform to the grammar.\n\tIRIx create(String iri);\n\tboolean isStrictMode(String scheme);\n\t// Run in strict mode - the exact definition of \"strict\" depends on the provider.\n\tvoid strictMode(String scheme, boolean runStrict);\n}", "des": "IRIProvider implemented using java.net.URI."}
{"index": 6934, "repo": "jena-core-4.9.0", "code": "public class IsBNode extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests the single argument to make sure it is blank node."}
{"index": 6935, "repo": "jena-core-4.9.0", "code": "public class IsFunctor extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests the single argument to make sure it is not a Functor."}
{"index": 6936, "repo": "jena-core-4.9.0", "code": "public class IsLiteral extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests the single argument to make sure it is a literal."}
{"index": 6937, "repo": "jena-core-4.9.0", "code": "public class IteratorOfJenaSets<E> extends NiceIterator<E> {\n\tvoid forEachRemaining(Consumer<? super E> action);\n\t// default hasNext: no elements, return false.\n\tboolean hasNext();\n\t// default next: throw an exception.\n\tE next();\n}", "des": "Iterator that iterates over the entries of sets which are contained in the given iterator of sets."}
{"index": 6938, "repo": "jena-core-4.9.0", "code": "public class JenaRuntime extends Object {\n\tstatic String getLineSeparator();\n\t// Deprecated. To be removed\n\tstatic String getMetadata(String key, String defaultValue);\n\tstatic String getSystemProperty(String propName);\n\tstatic String getSystemProperty(String propName, String defaultValue);\n\t// Deprecated. To be removed\n\tstatic void setFeature(String featureName);\n}", "des": "Methods and constants that define features of the current the environment."}
{"index": 6939, "repo": "jena-core-4.9.0", "code": "public interface JenaSet<E> extends JenaMapSetCommon<E> {\n\t// Add the key to the set without checking if it is already present.\n\tvoid addUnchecked(E key);\n\t// Add the key to the set if it is not already present.\n\tboolean tryAdd(E key);\n}", "des": "Set interface specialized for the use cases in triple store implementations."}
{"index": 6940, "repo": "jena-core-4.9.0", "code": "public abstract class LazyIterator<T> extends NiceIterator<T> {\n\t// default close: don't need to do anything.\n\tvoid close();\n\t// The subclass must define this to return the ExtendedIterator to invoke.\n\tabstract ExtendedIterator<T> create();\n\tvoid forEachRemaining(Consumer<? super T> action);\n\t// default hasNext: no elements, return false.\n\tboolean hasNext();\n\t// default next: throw an exception.\n\tT next();\n\t// default remove: we have no elements, so we can't remove any.\n\tvoid remove();\n}", "des": "An ExtendedIterator that is created lazily."}
{"index": 6941, "repo": "jena-core-4.9.0", "code": "public class LE extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests if the first argument is less than or equal to the second."}
{"index": 6942, "repo": "jena-core-4.9.0", "code": "public class LessThan extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests if the first argument is less than the second."}
{"index": 6943, "repo": "jena-core-4.9.0", "code": "public class ListContains extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Returns true if the first argument is a list which contains the second argument."}
{"index": 6944, "repo": "jena-core-4.9.0", "code": "public class ListEntry extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "listEntry(?list, ?index, ?val) will bind ?val to the ?index'th entry in the RDF list ?list."}
{"index": 6945, "repo": "jena-core-4.9.0", "code": "public class ListEqual extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Test if the two argument lists contain the same semantic elements."}
{"index": 6946, "repo": "jena-core-4.9.0", "code": "public class ListLength extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the second arg to the length of the first arg treated as a list."}
{"index": 6947, "repo": "jena-core-4.9.0", "code": "public class ListMapAsObject extends BaseBuiltin {\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule head.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n}", "des": "For each element in the RDF list (third argument) it asserts triples with that as the object and subject and predicate given by arguments one and two."}
{"index": 6948, "repo": "jena-core-4.9.0", "code": "public class ListMapAsSubject extends BaseBuiltin {\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule head.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n}", "des": "For each element in the RDF list (first argument) it asserts triples with that as the subject and predicate and object given by arguments two and three."}
{"index": 6949, "repo": "jena-core-4.9.0", "code": "public class ListNotContains extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Returns false if the first argument is a list which contains the second argument."}
{"index": 6950, "repo": "jena-core-4.9.0", "code": "public class ListNotEqual extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Test if the two argument lists differ."}
{"index": 6951, "repo": "jena-core-4.9.0", "code": "public class LockMRPlusSW extends ReentrantLock implements Lock {\n\t// Enter a critical section.\n\tvoid enterCriticalSection(boolean readLockRequested);\n\t// Leave a critical section.\n\tvoid leaveCriticalSection();\n}", "des": "A multiple-reader plus single-writer lock."}
{"index": 6952, "repo": "jena-core-4.9.0", "code": "public class LockMRSW extends Object implements Lock {\n\t// Application controlled locking - enter a critical section.\n\tfinal void enterCriticalSection(boolean readLockRequested);\n\t// Application controlled locking - leave a critical section.\n\tfinal void leaveCriticalSection();\n}", "des": "Lock implementation using a Multiple Reader, Single Writer policy."}
{"index": 6953, "repo": "jena-core-4.9.0", "code": "public interface LPAgendaEntry {\n\t// Return the generator associated with this entry (might be the entry itself)\n\tGenerator getGenerator();\n\t// Tests true if this state is ready to be usefully run.\n\tboolean isReady();\n\t// Cycle this object, recording new results in any associated memoization table until hit a stop or suspend point.\n\tvoid pump();\n}", "des": "The signature of classes that can go on the LPEngines processing agenda."}
{"index": 6954, "repo": "jena-core-4.9.0", "code": "public class LPBindingEnvironment extends Object implements BindingEnvironment {\n\t// Bind a variable in the current environment to the given value.\n\tboolean bind(Node var, Node value);\n\t// Return the most ground version of the node.\n\tNode getGroundVersion(Node node);\n\t// Instantiate a triple pattern against the current environment.\n\tTriple instantiate(TriplePattern pattern);\n}", "des": "Implementation of the binding environment interface for use in LP backward rules."}
{"index": 6955, "repo": "jena-core-4.9.0", "code": "public interface LSInputList extends List {\n\t// The number of LSInputs in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tLSInput item(int index);\n}", "des": "The LSInputList interface provides the abstraction of an ordered collection of LSInputs, without defining or constraining how this collection is implemented."}
{"index": 6956, "repo": "jena-core-4.9.0", "code": "public class MakeInstance extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Create or lookup an anonymous instance of a property value."}
{"index": 6957, "repo": "jena-core-4.9.0", "code": "public class MakeSkolem extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind a blank node to the first argument."}
{"index": 6958, "repo": "jena-core-4.9.0", "code": "public class MakeTemp extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule head.\n\tvoid headAction(Node[] args, RuleContext context);\n}", "des": "Create a new anonymous node and bind it to the each argument"}
{"index": 6959, "repo": "jena-core-4.9.0", "code": "public class Map1Iterator<From,To> extends NiceIterator<To> {\n\t// default close: don't need to do anything.\n\tvoid close();\n\tvoid forEachRemaining(Consumer<? super To> action);\n\t// default hasNext: no elements, return false.\n\tboolean hasNext();\n\t// default next: throw an exception.\n\tTo next();\n\t// default remove: we have no elements, so we can't remove any.\n\tvoid remove();\n}", "des": "An iterator that consumes an underlying iterator and maps its results before delivering them; supports remove if the underlying iterator does."}
{"index": 6960, "repo": "jena-core-4.9.0", "code": "public class MapBuiltinRegistry extends BuiltinRegistry {\n\t// Find the implementation of the given builtin functor.\n\tBuiltin getImplementation(String functor);\n\t// Find the implementation of the given builtin functor.\n\tBuiltin getImplementationByURI(String uri);\n\t// Register an implementation for a given builtin functor.\n\tvoid register(String functor, Builtin impl);\n\t// Register an implementation for a given builtin using its default name.\n\tvoid register(Builtin impl);\n}", "des": "A registry for mapping functor names on java objects (instances of subclasses of Builtin) which implement their behaviour."}
{"index": 6961, "repo": "jena-core-4.9.0", "code": "public class MapFilterIterator<T,X> extends NiceIterator<X> implements ExtendedIterator<X> {\n\t// default close: don't need to do anything.\n\tvoid close();\n\tvoid forEachRemaining(Consumer<? super X> action);\n\t// Are there any more acceptable objects.\n\tboolean hasNext();\n\t// The next acceptable object in the iterator.\n\tX next();\n\t// remove's the member from the underlying Iterator; hasNext() may not be called between calls to next() and remove().\n\tvoid remove();\n}", "des": "A MapFilterIterator takes a MapFilter and an [Extended]Iterator and returns a new ExtendedIterator which delivers the sequence of all non-null elements MapFilter(X) for X from the base iterator."}
{"index": 6962, "repo": "jena-core-4.9.0", "code": "public enum MatchPattern extends Enum<MatchPattern> {\n\t// Returns the enum constant of this type with the specified name.\n\tstatic MatchPattern valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic MatchPattern[] values();\n}", "des": "A pattern for matching triples."}
{"index": 6963, "repo": "jena-core-4.9.0", "code": "public class Max extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the third arg to the max of the first two args."}
{"index": 6964, "repo": "jena-core-4.9.0", "code": "public class Min extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the third arg to the min of the first two args."}
{"index": 6965, "repo": "jena-core-4.9.0", "code": "public class Mode extends Object {\n\t// Answer true if the object root with the given name can be created if it does not already exist.\n\tboolean permitCreateNew(Resource root, String name);\n\t// Answer true if the existing object root with the given name can be reused.\n\tboolean permitUseExisting(Resource root, String name);\n}", "des": "A Mode object controls whether persistent objects can be created or reused by an assembler."}
{"index": 6966, "repo": "jena-core-4.9.0", "code": "public class ModelExtract extends Object {\n\t// Answer the rooted sub-model.\n\tModel extract(Resource r, Model s);\n\t// Answer model after updating it with the sub-graph of s rooted at r, bounded by this instances boundary.\n\tModel extractInto(Model model, Resource r, Model s);\n}", "des": "ModelExtract - a wrapper for GraphExtract, allowing rooted sub-models to be extracted from other models with some boundary condition."}
{"index": 6967, "repo": "jena-core-4.9.0", "code": "public interface ModelGetter {\n\t// Answer a Model whose content is that associated with the URL, if possible, and otherwise answer null.\n\tModel getModel(String URL);\n\t// Answer a model appropriate for URL, If none is to hand, and it's possible to create one, create it and load it using loadIfAbsent.\n\tModel getModel(String URL, ModelReader loadIfAbsent);\n}", "des": "A ModelGetter object can retrieve a Model given a URL for it."}
{"index": 6968, "repo": "jena-core-4.9.0", "code": "public interface ModelGraphInterface {\n\t// Answer an RDF node wrapping n suitably; URI nodes become Resources with the same URI, blank nodes become Resources with URI null but the same AnonId, and literal nodes become Literals with n as their value carrier.\n\tRDFNode asRDFNode(Node n);\n\t// Answer a Statement in this Model who's SPO is that of the triple t.\n\tStatement asStatement(Triple t);\n\t// Answer the Graph which this Model is presenting.\n\tGraph getGraph();\n\tResource wrapAsResource(Node n);\n}", "des": "ModelGraphInterface - this interface mediates between the API Model level and the SPI Graph level."}
{"index": 6969, "repo": "jena-core-4.9.0", "code": "public interface ModelSource extends ModelGetter {\n\t// Answer this ModelSource's default model.\n\tModel createDefaultModel();\n\t// Answer a Model that satisfies this ModelSource's shape.\n\tModel createFreshModel();\n\t// Answer a model.\n\tModel openModel(String name);\n\t// Answer the model named by string in this ModelSource, if it [still] has one, or null if there isn't one.\n\tModel openModelIfPresent(String string);\n}", "des": "The revised and soon-to-be-core interface for sources of models, typically generated from RDF descriptions."}
{"index": 6970, "repo": "jena-core-4.9.0", "code": "public class MonitorModel extends ModelCom {\n\t// Compute the differences between the current monitored graph and the last snapshot, forward any changes to registered listeners, then take a new snapshot.\n\tvoid snapshot();\n\t// Compute the differences between the current monitored graph and the last snapshot.\n\tvoid snapshot(List<Statement> additions, List<Statement> deletions);\n}", "des": "Model wrapper which provides normal access to an underlying model but also maintains a snapshot of the triples it was last known to contain."}
{"index": 6971, "repo": "jena-core-4.9.0", "code": "public interface NamespaceHandler {\n\t// A namespace prefix is going out of scope.\n\tvoid endPrefixMapping(String prefix);\n\t// A namespace prefix is being defined..\n\tvoid startPrefixMapping(String prefix, String uri);\n}", "des": "The interface for being notified about namespace use in an RDF/XML document."}
{"index": 6972, "repo": "jena-core-4.9.0", "code": "public interface NamespaceHandler {\n\t// A namespace prefix is going out of scope.\n\tvoid endPrefixMapping(String prefix);\n\t// A namespace prefix is being defined..\n\tvoid startPrefixMapping(String prefix, String uri);\n}", "des": "The interface for being notified about namespace use in an RDF/XML document."}
{"index": 6973, "repo": "jena-core-4.9.0", "code": "public class Node_Blank extends Node_Concrete {\n\t// Nodes only equal other Nodes that have equal labels.\n\tboolean equals(Object other);\n\t// get the blank node id if the node is blank, otherwise die horribly\n\tBlankNodeId getBlankNodeId();\n\t// Answer true iff this node is a blank node [subclasses override]\n\tboolean isBlank();\n\t// Visit a Node and dispatch on it to the appropriate method from the NodeVisitor v.\n\tObject visitWith(NodeVisitor v);\n}", "des": "RDF blank nodes, ie nodes with identity but without URIs."}
{"index": 6974, "repo": "jena-core-4.9.0", "code": "public abstract class Node_Ext<X> extends Node {\n\t// Nodes only equal other Nodes that have equal labels.\n\tboolean equals(Object obj);\n\tX get();\n\t// Answer true iff this node is concrete, ie not variable, ie URI, blank, or literal.\n\tboolean isConcrete();\n\t// Extension node.\n\tboolean isExt();\n\t// Visit a Node and dispatch on it to the appropriate method from the NodeVisitor v.\n\tObject visitWith(NodeVisitor v);\n}", "des": "Extension to the RDF Data model."}
{"index": 6975, "repo": "jena-core-4.9.0", "code": "public class Node_Variable extends Node_Fluid {\n\t// Nodes only equal other Nodes that have equal labels.\n\tboolean equals(Object other);\n\t// get a variable nodes name, otherwise die horribly\n\tString getName();\n\t// Answer true iff this node is a variable node - subclasses override\n\tboolean isVariable();\n\tstatic Object variable(String name);\n\t// Visit a Node and dispatch on it to the appropriate method from the NodeVisitor v.\n\tObject visitWith(NodeVisitor v);\n}", "des": "\"variable\" nodes; these are outside the RDF2003 specification, but are used internally for \"placeholder\" nodes where blank nodes would be wrong, most specifically in Query."}
{"index": 6976, "repo": "jena-core-4.9.0", "code": "public interface NodeIterator extends ExtendedIterator<RDFNode> {\n\t// Terminate the iteration and free up resources.\n\tvoid close();\n\t// Determine if there any more values in the iteration.\n\tboolean hasNext();\n\t// Return the next RDFNode of the iteration.\n\tRDFNode next();\n\t// Return the next RDFNode of the iteration.\n\tRDFNode nextNode();\n\t// Unsupported Operation.\n\tvoid remove();\n}", "des": "An iterator which returns RDF nodes."}
{"index": 6977, "repo": "jena-core-4.9.0", "code": "public interface NodeToTriplesMap extends JenaSet<Triple> {\n\t// Answer true iff this map contains a triple that matches the pattern.\n\tboolean containsMatch(Node index, Node n2, Node n3);\n\t// Answer an iterator over all the triples in this map that match the pattern.\n\tExtendedIterator<Triple> iteratorForMatches(Node index, Node n2, Node n3);\n\t// Answer a stream over all the triples in this map that match the pattern.\n\tStream<Triple> streamForMatches(Node index, Node n2, Node n3);\n}", "des": "A map from a node to the triples that have that node as subject, predicate or object."}
{"index": 6978, "repo": "jena-core-4.9.0", "code": "public class NotBNode extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests the single argument to make sure it is not a blank node."}
{"index": 6979, "repo": "jena-core-4.9.0", "code": "public class NotDType extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests whether the first argument is not an instance of the datatype defined by the resource in the second argument."}
{"index": 6980, "repo": "jena-core-4.9.0", "code": "public class NotEqual extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Check that the two args are different."}
{"index": 6981, "repo": "jena-core-4.9.0", "code": "public class NotFunctor extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests the single argument to make sure it is not a Functor."}
{"index": 6982, "repo": "jena-core-4.9.0", "code": "public class NotLiteral extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Tests the single argument to make sure it is a literal."}
{"index": 6983, "repo": "jena-core-4.9.0", "code": "public class NoValue extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// Flag as non-monotonic so the guard clause will get rerun after deferal as part of a non-trivial conflict set.\n\tboolean isMonotonic();\n}", "des": "Can be used in two arg form (X, P) or three arg form (X, P, V)."}
{"index": 6984, "repo": "jena-core-4.9.0", "code": "public class Now extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the first arg to the current date time in the current locale and timezone."}
{"index": 6985, "repo": "jena-core-4.9.0", "code": "public class NTriple extends Object implements ARPErrorNumbers {\n\t// Replace any non-legal char (or Z) with ZNN where NN are the hex codes in UTF-8\n\tstatic String escapeNTriple(String anonymousID);\n\t// Starts an RDF/XML to NTriple converter.\n\tstatic void main(String[] args);\n\t// Starts an RDF/XML to NTriple converter, using an error handler, and an ARPHandler.\n\tstatic void mainEh(String[] args, ErrorHandler eh, ARPEventHandler ap);\n}", "des": "A command line interface into ARP."}
{"index": 6986, "repo": "jena-core-4.9.0", "code": "public class NTriple extends Object implements ARPErrorNumbers {\n\t// Replace any non-legal char (or Z) with ZNN where NN are the hex codes in UTF-8\n\tstatic String escapeNTriple(String anonymousID);\n\t// Starts an RDF/XML to NTriple converter.\n\tstatic void main(String[] args);\n\t// Starts an RDF/XML to NTriple converter, using an error handler, and an ARPHandler.\n\tstatic void mainEh(String[] args, ErrorHandler eh, ARPEventHandler ap);\n}", "des": "A command line interface into ARP."}
{"index": 6987, "repo": "jena-core-4.9.0", "code": "public abstract class ObjectIterator extends NiceIterator<Node> {\n\tvoid forEachRemaining(Consumer<? super Node> action);\n\t// default hasNext: no elements, return false.\n\tboolean hasNext();\n\t// default next: throw an exception.\n\tNode next();\n\t// default remove: we have no elements, so we can't remove any.\n\tvoid remove();\n}", "des": "Helper class for listObjects."}
{"index": 6988, "repo": "jena-core-4.9.0", "code": "public interface ObjectList extends List<Object> {\n\t// Checks if the Object item is a member of this list.\n\tboolean contains(Object item);\n\t// The number of Objects in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tObject item(int index);\n}", "des": "The ObjectList is an immutable ordered collection of Object."}
{"index": 6989, "repo": "jena-core-4.9.0", "code": "public final class ObjectListImpl extends AbstractList<Object> implements ObjectList {\n\t// Checks if the Object item is a member of this list.\n\tboolean contains(Object item);\n\tObject get(int index);\n\t// The number of Objects in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tObject item(int index);\n\tint size();\n\tObject[] toArray();\n\tObject[] toArray(Object[] a);\n}", "des": "Contains a list of Objects."}
{"index": 6990, "repo": "jena-core-4.9.0", "code": "public static class OneToManyMap.Entry<From,To> extends Object implements Map.Entry<From,To> {\n\t// Compares the specified object with this entry for equality.\n\tboolean equals(Object x);\n\t// Answer the key for the entry\n\tFrom getKey();\n\t// Answer the value for the entry\n\tTo getValue();\n\t// Set the value, which writes through to the map.\n\tTo setValue(To value);\n}", "des": "Helper class to implement the Map.Entry interface to enumerate entries in the map"}
{"index": 6991, "repo": "jena-core-4.9.0", "code": "public static class OntDocumentManager.DefaultReadHook extends Object implements OntDocumentManager.ReadHook {\n\t// Behaviour that is invoked just after the contents of the given source (URI or filename) have been read into the given model.\n\tvoid afterRead(Model model, String source, OntDocumentManager odm);\n\t// Behaviour that is invoked before the contents of the given source (URI or filename) are read into the given model.\n\tString beforeRead(Model model, String source, OntDocumentManager odm);\n}", "des": "The default implementation of OntDocumentManager.ReadHook makes no changes."}
{"index": 6992, "repo": "jena-core-4.9.0", "code": "public static interface OntDocumentManager.ReadHook {\n\t// Behaviour that is invoked just after the contents of the given source (URI or filename) have been read into the given model.\n\tvoid afterRead(Model model, String source, OntDocumentManager odm);\n\t// Behaviour that is invoked before the contents of the given source (URI or filename) are read into the given model.\n\tString beforeRead(Model model, String source, OntDocumentManager odm);\n}", "des": "Interface denoting a handler class that can intervene in the process of reading a source document into a model."}
{"index": 6993, "repo": "jena-core-4.9.0", "code": "public class OntModelSpecAssembler extends AssemblerBase implements Assembler {\n\t// Answer the OntModelSpec in the OntModelSpec class with the given member name, or null if there isn't one.\n\tstatic OntModelSpec getOntModelSpecField(String name);\n\t// The core operation: answer a new object constructed according to the object description hanging from root, using the assembler a for any sub-objects.\n\tObject open(Assembler a, Resource root, Mode irrelevant);\n}", "des": "An OntModelSpecAssembler constructs OntModelSpec's from their RDF description."}
{"index": 6994, "repo": "jena-core-4.9.0", "code": "public static class OntTools.Path extends ArrayList<Statement> {\n\t// Answer a new Path whose elements are this Path with s added at the end\n\tOntTools.Path append(Statement s);\n\tStatement getStatement(int i);\n\t// Answer the RDF node at the end of the path, if defined, or null\n\tRDFNode getTerminal();\n\t// Answer the resource at the end of the path, if defined, or null\n\tResource getTerminalResource();\n\t// Answer true if the last link on the path has object equal to n\n\tboolean hasTerminus(RDFNode n);\n}", "des": "A path is an application of List containing only Statement objects, and in which for all adjacent elements Si-1 and Si, where i > 0, it is true that:"}
{"index": 6995, "repo": "jena-core-4.9.0", "code": "public class OWLExptRuleTranslationHook extends Object implements RulePreprocessHook {\n\t// Validate a triple add to see if it should reinvoke the hook.\n\tboolean needsRerun(FBRuleInfGraph infGraph, Triple t);\n\t// Invoke the preprocessing hook.\n\tvoid run(FBRuleInfGraph infGraph, Finder dataFind, Graph inserts);\n}", "des": "Experimental change to OWL translation hook that doesn't handle translation of restrictions to functors."}
{"index": 6996, "repo": "jena-core-4.9.0", "code": "public class OWLFBRuleReasoner extends FBRuleReasoner {\n\t// Attach the reasoner to a set of RDF data to process.\n\tInfGraph bind(Graph data);\n\t// Precompute the implications of a schema graph.\n\tReasoner bindSchema(Graph tbox);\n\t// Get the single static precomputed rule closure.\n\tInfGraph getPreload();\n\t// Return the rule set, loading it in if necessary\n\tstatic List<Rule> loadRules();\n}", "des": "A hybrid forward/backward implementation of the OWL closure rules."}
{"index": 6997, "repo": "jena-core-4.9.0", "code": "public class OWLFBRuleReasonerFactory extends Object implements ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n\t// Return the single global instance of this factory\n\tstatic ReasonerFactory theInstance();\n}", "des": "Factory class for creating blank instances of the OWL Reasoner."}
{"index": 6998, "repo": "jena-core-4.9.0", "code": "public class OWLMicroReasoner extends GenericRuleReasoner implements Reasoner {\n\t// Attach the reasoner to a set of RDF data to process.\n\tInfGraph bind(Graph data);\n\t// Return the Jena Graph Capabilities that the inference graphs generated by this reasoner are expected to conform to.\n\tCapabilities getGraphCapabilities();\n\t// Return the rule set, loading it in if necessary\n\tstatic List<Rule> loadRules();\n}", "des": "Reasoner configuration for the OWL micro reasoner."}
{"index": 6999, "repo": "jena-core-4.9.0", "code": "public class OWLMicroReasonerFactory extends Object implements ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n\t// Return the single global instance of this factory\n\tstatic ReasonerFactory theInstance();\n}", "des": "Reasoner factory for the OWL micro configuration."}
{"index": 7000, "repo": "jena-core-4.9.0", "code": "public class OWLMiniReasoner extends GenericRuleReasoner implements Reasoner {\n\t// Attach the reasoner to a set of RDF data to process.\n\tInfGraph bind(Graph data);\n\t// Return the Jena Graph Capabilties that the inference graphs generated by this reasoner are expected to conform to.\n\tCapabilities getGraphCapabilities();\n\t// Return the rule set, loading it in if necessary\n\tstatic List<Rule> loadRules();\n}", "des": "Reasoner configuration for the OWL mini reasoner."}
{"index": 7001, "repo": "jena-core-4.9.0", "code": "public class OWLMiniReasonerFactory extends Object implements ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n\t// Return the single global instance of this factory\n\tstatic ReasonerFactory theInstance();\n}", "des": "Reasoner factory for the OWL mini configuration."}
{"index": 7002, "repo": "jena-core-4.9.0", "code": "public class OWLRuleTranslationHook extends Object implements RulePreprocessHook {\n\t// Validate a triple add to see if it should reinvoke the hook.\n\tboolean needsRerun(FBRuleInfGraph infGraph, Triple t);\n\t// Invoke the preprocessing hook.\n\tvoid run(FBRuleInfGraph infGraph, Finder dataFind, Graph inserts);\n}", "des": "A rule preprocessor that scans the data looking for intersection definitions and augments the rule base by translations of the intersection statement."}
{"index": 7003, "repo": "jena-core-4.9.0", "code": "public abstract class Polymorphic<T> extends Object {\n\t// add another view for this object.\n\tvoid addView(Polymorphic<T> other);\n\t// subclasses must override equals.\n\tabstract boolean equals(Object o);\n\t// answer true iff this enhanced node is still underpinned in the graph by triples appropriate to its type.\n\tabstract boolean isValid();\n\t// return _true_ iff this polymorphic object supports the specified interface.\n\t<X extends T>boolean supports(Class<X> t);\n}", "des": "Abstract base class for all polymorphic RDF objects, especially enhanced node and enhanced graph."}
{"index": 7004, "repo": "jena-core-4.9.0", "code": "public class Product extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the third arg to the product of the first two args."}
{"index": 7005, "repo": "jena-core-4.9.0", "code": "public class ProfileRegistry extends Object {\n\t// Answer the singleton instance\n\tstatic ProfileRegistry getInstance();\n\t// Answer the language profile for the given language URI, or null if not known.\n\tProfile getProfile(String uri);\n\t// Add a language profile with the given URI key\n\tvoid registerProfile(String uri, Profile profile);\n}", "des": "Provides a means to map between the URI's that represent ontology languages and their language profiles."}
{"index": 7006, "repo": "jena-core-4.9.0", "code": "public interface Property extends Resource {\n\t// Returns the localname of this resource within its namespace if it is a URI else null.\n\tString getLocalName();\n\t// Returns the namespace associated with this resource if it is a URI, else return null.\n\tString getNameSpace();\n\t// Returns the ordinal value of a containment property.\n\tint getOrdinal();\n\t// Override RDFNode.inModel() to produce a staticly-typed Property in the given Model.\n\tProperty inModel(Model m);\n\tboolean isProperty();\n}", "des": "An RDF Property."}
{"index": 7007, "repo": "jena-core-4.9.0", "code": "public class PropertyImpl extends ResourceImpl implements Property {\n\t// Returns the ordinal value of a containment property.\n\tint getOrdinal();\n\t// Override RDFNode.inModel() to produce a statically-typed Resource in the given Model.\n\tProperty inModel(Model m);\n\tboolean isProperty();\n}", "des": "An implementation of Property."}
{"index": 7008, "repo": "jena-core-4.9.0", "code": "public class QName extends Object implements Cloneable {\n\t// Clears the values of the qname components.\n\tvoid clear();\n\t// Returns a clone of this object.\n\tObject clone();\n\t// Returns true if the two objects are equal.\n\tboolean equals(Object object);\n\t// Convenience method to set the values of the qname components.\n\tvoid setValues(String prefix, String localpart, String rawname, String uri);\n\t// Convenience method to set the values of the qname components.\n\tvoid setValues(QName qname);\n}", "des": "A structure that holds the components of an XML Namespaces qualified name."}
{"index": 7009, "repo": "jena-core-4.9.0", "code": "public class Quotient extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the third arg to the ratio of the first two args."}
{"index": 7010, "repo": "jena-core-4.9.0", "code": "public class RandomOrderGraph extends WrappedGraph {\n\tstatic Graph createDefaultGraph();\n\tstatic Model createDefaultModel();\n\t// Returns an iterator over Triples matching a pattern.\n\tExtendedIterator<Triple> find(Node s, Node p, Node o);\n\t// Returns an iterator over all the Triples that match the triple pattern.\n\tExtendedIterator<Triple> find(Triple triple);\n\t// returns this Graph's capabilities\n\tCapabilities getCapabilities();\n}", "des": "Wraps a graph and randomizes the order of find results."}
{"index": 7011, "repo": "jena-core-4.9.0", "code": "public class RandomOrderIterator<T> extends WrappedIterator<T> {\n\t// hasNext: defer to the base iterator\n\tboolean hasNext();\n\t// next: defer to the base iterator\n\tT next();\n\t// default remove: we have no elements, so we can't remove any.\n\tvoid remove();\n}", "des": "RandomOrderIterator - Reorders the elements returned by an Iterator."}
{"index": 7012, "repo": "jena-core-4.9.0", "code": "public class RDFDefaultErrorHandler extends Object implements RDFErrorHandler {\n\t// report an error\n\tvoid error(Exception e);\n\t// report a catastrophic error.\n\tvoid fatalError(Exception e);\n\t// report a warning\n\tvoid warning(Exception e);\n}", "des": "The default error handler for RDF/XML I/O."}
{"index": 7013, "repo": "jena-core-4.9.0", "code": "public interface RDFErrorHandler {\n\t// report an error\n\tvoid error(Exception e);\n\t// report a catastrophic error.\n\tvoid fatalError(Exception e);\n\t// report a warning\n\tvoid warning(Exception e);\n}", "des": "A generic error handler."}
{"index": 7014, "repo": "jena-core-4.9.0", "code": "public class RDFhtml extends BaseDatatype implements RDFDatatype {\n\t// Compares two instances of values of the given datatype.\n\tboolean isEqual(LiteralLabel value1, LiteralLabel value2);\n\t// Parse a lexical form of this datatype to a value\n\tObject parse(String lexicalForm);\n\t// Convert a value of this datatype out to lexical form.\n\tString unparse(Object value);\n}", "des": "rdf:html."}
{"index": 7015, "repo": "jena-core-4.9.0", "code": "public class RDFjson extends BaseDatatype implements RDFDatatype {\n\t// Compares two instances of values of the given datatype.\n\tboolean isEqual(LiteralLabel value1, LiteralLabel value2);\n\t// Parse a lexical form of this datatype to a value\n\tObject parse(String lexicalForm);\n\t// Convert a value of this datatype out to lexical form.\n\tString unparse(Object value);\n}", "des": "rdf:json."}
{"index": 7016, "repo": "jena-core-4.9.0", "code": "public class RDFLangString extends BaseDatatype implements RDFDatatype {\n\t// Compares two instances of values of the given datatype.\n\tboolean isEqual(LiteralLabel value1, LiteralLabel value2);\n\t// Parse a lexical form of this datatype to a value\n\tObject parse(String lexicalForm);\n\t// Convert a value of this datatype out to lexical form.\n\tString unparse(Object value);\n}", "des": "rdf:langString."}
{"index": 7017, "repo": "jena-core-4.9.0", "code": "public interface RDFReaderF {\n\t// return an RDFReader instance for the default serialization language.\n\tRDFReaderI getReader();\n\t// return an RDFReader instance for the specified serialization language.\n\tRDFReaderI getReader(String lang);\n}", "des": "An RDFReader factory interface."}
{"index": 7018, "repo": "jena-core-4.9.0", "code": "public class RDFSCMPPreprocessHook extends Object implements RulePreprocessHook {\n\t// Validate a triple add to see if it should reinvoke the hook.\n\tboolean needsRerun(FBRuleInfGraph infGraph, Triple t);\n\t// Invoke the preprocessing hook.\n\tvoid run(FBRuleInfGraph infGraph, Finder dataFind, Graph inserts);\n}", "des": "A rule preprocessor that scans all supplied data looking for instances of container membership properties and adds those to the deductions set."}
{"index": 7019, "repo": "jena-core-4.9.0", "code": "public class RDFSFBRuleReasoner extends FBRuleReasoner {\n\t// Return the Jena Graph Capabilities that the inference graphs generated by this reasoner are expected to conform to.\n\tCapabilities getGraphCapabilities();\n\t// Return the RDFS rule set, loading it in if necessary\n\tstatic List<Rule> loadRules();\n}", "des": "A backward chaining implementation of the RDFS closure rules based upon the basic backward rule interpreter."}
{"index": 7020, "repo": "jena-core-4.9.0", "code": "public class RDFSFBRuleReasonerFactory extends Object implements ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n\t// Return the single global instance of this factory\n\tstatic ReasonerFactory theInstance();\n}", "des": "Factory class for creating blank instances of the hybrid rule RDFS reasoner."}
{"index": 7021, "repo": "jena-core-4.9.0", "code": "public class RDFSForwardRuleReasoner extends GenericRuleReasoner {\n\t// Return the Jena Graph Capabilities that the inference graphs generated by this reasoner are expected to conform to.\n\tCapabilities getGraphCapabilities();\n\t// Return the RDFS rule set, loading it in if necessary\n\tstatic List<Rule> loadRules();\n}", "des": "A pure forward chaining implementation of the RDFS closure rules based upon the basic forward rule interpreter."}
{"index": 7022, "repo": "jena-core-4.9.0", "code": "public class RDFSRuleReasoner extends GenericRuleReasoner {\n\t// Attach the reasoner to a set of RDF data to process.\n\tInfGraph bind(Graph data);\n\t// Precompute the implications of a schema graph.\n\tReasoner bindSchema(Graph tbox);\n\t// Return the Jena Graph Capabilities that the inference graphs generated by this reasoner are expected to conform to.\n\tCapabilities getGraphCapabilities();\n\t// Return the RDFS rule set, loading it in if necessary.\n\tstatic List<Rule> loadRulesLevel(String level);\n}", "des": "A full implementation of RDFS reasoning using a hybrid rule system, together with optimized subclass/subproperty closure using the transitive graph caches."}
{"index": 7023, "repo": "jena-core-4.9.0", "code": "public class RDFSRuleReasonerFactory extends Object implements ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n\t// Return the single global instance of this factory\n\tstatic ReasonerFactory theInstance();\n}", "des": "Factory class for creating blank instances of the hybrid rule RDFS reasoner with TGC support."}
{"index": 7024, "repo": "jena-core-4.9.0", "code": "public interface RDFVisitor {\n\t// Method to call when visiting a blank node r with identifier id.\n\tObject visitBlank(Resource r, AnonId id);\n\t// Method to call when visiting a literal RDF node l.\n\tObject visitLiteral(Literal l);\n\t// Method to call when visiting a resource with a statement.\n\tdefault Object visitStmt(Resource r, Statement statement);\n\t// Method to call when visiting a URI node r with the given uri.\n\tObject visitURI(Resource r, String uri);\n}", "des": "The interface for visiting (ie type-dispatching) an RDF Node."}
{"index": 7025, "repo": "jena-core-4.9.0", "code": "public interface RDFWriterF {\n\t// return an RDFWriter instance for the default serialization language.\n\tRDFWriterI getWriter();\n\t// an RDFWriter instance for the specified serialization language.\n\tRDFWriterI getWriter(String lang);\n}", "des": "An RDFWriter factory interface."}
{"index": 7026, "repo": "jena-core-4.9.0", "code": "public interface RDFWriterI {\n\t// Set an error handler.\n\tRDFErrorHandler setErrorHandler(RDFErrorHandler errHandler);\n\t// Set a property to control the behaviour of this writer.\n\tObject setProperty(String propName, Object propValue);\n\t// Serialize Model model to OutputStream out.\n\tvoid write(Model model, OutputStream out, String base);\n\t// Caution: Serialize Model model to Writer out.\n\tvoid write(Model model, Writer out, String base);\n}", "des": "RDFWriterI is an interface to RDF serializers."}
{"index": 7027, "repo": "jena-core-4.9.0", "code": "public class RDFXML_Abbrev extends BaseXMLWriter implements RDFErrorHandler {\n\t// report an error\n\tvoid error(Exception e);\n\t// report a catastrophic error.\n\tvoid fatalError(Exception e);\n\t// report a warning\n\tvoid warning(Exception e);\n}", "des": "Writes out RDF in the abbreviated syntax, for human consumption not only machine readable."}
{"index": 7028, "repo": "jena-core-4.9.0", "code": "public interface ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n}", "des": "The interface through which a reasoner (inference engine) can be instantiated."}
{"index": 7029, "repo": "jena-core-4.9.0", "code": "public class ReasonerFactoryAssembler extends AssemblerBase implements Assembler {\n\t// Answer a ReasonerFactory which delivers reasoners with the given URL reasonerURL.\n\tstatic ReasonerFactory getReasonerFactoryByURL(Resource root, Resource reasonerURL);\n\t// The core operation: answer a new object constructed according to the object description hanging from root, using the assembler a for any sub-objects.\n\tObject open(Assembler a, Resource root, Mode irrelevant);\n}", "des": "The ReasonerFactoryAssembler constructs a ReasonerFactory from the description."}
{"index": 7030, "repo": "jena-core-4.9.0", "code": "public class ReasonerVocabulary extends Object {\n\t// Return namespace used for system level descriptive properties of any reasoner\n\tstatic final String getJenaReasonerNS();\n\t// Return namespace used for Rubric specific properties\n\tstatic final String getRBNamespace();\n}", "des": "A collection of RDF terms used in driving or configuring some of the builtin reasoners."}
{"index": 7031, "repo": "jena-core-4.9.0", "code": "public class Remove extends BaseBuiltin {\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule head.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n\t// Returns false if this builtin is non-monotonic.\n\tboolean isMonotonic();\n}", "des": "Remove the body clause given by index arguments from the database."}
{"index": 7032, "repo": "jena-core-4.9.0", "code": "public class RETEClauseFilter extends Object implements RETESourceNode {\n\t// Clone this node in the network.\n\tRETENode clone(Map<RETENode,RETENode> netCopy, RETERuleContext context);\n\t// Create a filter node from a rule clause.\n\tstatic RETEClauseFilter compile(TriplePattern clause, int envLength, List<Node> varList);\n\t// Insert or remove a triple into the network.\n\tvoid fire(Triple triple, boolean isAdd);\n\t// Set the continuation node for this node.\n\tvoid setContinuation(RETESinkNode continuation);\n}", "des": "Checks a triple against the grounded matches and intra-triple matches for a single rule clause."}
{"index": 7033, "repo": "jena-core-4.9.0", "code": "public class RETEConflictSet extends Object {\n\t// Record a request for a rule firing.\n\tvoid add(Rule rule, BindingEnvironment env, boolean isAdd);\n\t// Execute a single rule firing.\n\tstatic void execute(RETERuleContext context, boolean isAdd);\n\t// Pick on pending rule from the conflict set and fire it.\n\tboolean fireOne();\n\t// Return true if there are no more rules awaiting firing.\n\tboolean isEmpty();\n}", "des": "Manages a set of ready-to-fire rules."}
{"index": 7034, "repo": "jena-core-4.9.0", "code": "public class RETEQueue extends Object implements RETESinkNode, RETESourceNode {\n\t// Clone this node in the network.\n\tRETENode clone(Map<RETENode,RETENode> netCopy, RETERuleContext context);\n\t// Propagate a token to this node.\n\tvoid fire(BindingVector env, boolean isAdd);\n\t// Set the continuation node for this node (and any sibling)\n\tvoid setContinuation(RETESinkNode continuation);\n\t// Set the sibling for this node.\n\tvoid setSibling(RETEQueue sibling);\n}", "des": "Represents one input left of a join node."}
{"index": 7035, "repo": "jena-core-4.9.0", "code": "public class RETERuleInfGraph extends BasicForwardRuleInfGraph {\n\t// Add one triple to the data graph, run any rules triggered by the new data item, recursively adding any generated triples.\n\tvoid performAdd(Triple t);\n\t// Removes the triple t (if possible) from the set belonging to this graph.\n\tvoid performDelete(Triple t);\n}", "des": "RETE implementation of the forward rule inference graph."}
{"index": 7036, "repo": "jena-core-4.9.0", "code": "public class RETETerminal extends Object implements RETESinkNode {\n\t// Clone this node in the network.\n\tRETENode clone(Map<RETENode,RETENode> netCopy, RETERuleContext contextIn);\n\t// Propagate a token to this node.\n\tvoid fire(BindingVector env, boolean isAdd);\n\t// Change the engine/graph to which this terminal should deliver its results.\n\tvoid setContext(RETEEngine engine, ForwardRuleInfGraphI graph);\n}", "des": "The final node in a RETE graph."}
{"index": 7037, "repo": "jena-core-4.9.0", "code": "public final class REUtil extends Object {\n\t// Creates a RegularExpression instance.\n\tstatic RegularExpression createRegex(String pattern, String options);\n\t// Sample entry.\n\tstatic void main(String[] argv);\n\tstatic boolean matches(String regex, String target);\n\tstatic boolean matches(String regex, String options, String target);\n\tstatic String quoteMeta(String literal);\n}", "des": "@xerces.internal"}
{"index": 7038, "repo": "jena-core-4.9.0", "code": "public class RoaringBitmapTripleIterator extends NiceIterator<Triple> {\n\tvoid forEachRemaining(Consumer<? super Triple> action);\n\t// default hasNext: no elements, return false.\n\tboolean hasNext();\n\t// default next: throw an exception.\n\tTriple next();\n}", "des": "A triple iterator that iterates over triple indices in a RoaringBitmap BatchIterator."}
{"index": 7039, "repo": "jena-core-4.9.0", "code": "public class RuleDerivation extends Object implements Derivation {\n\t// Compare two derivations.\n\tboolean equals(Object other);\n\tTriple getConclusion();\n\tList<Triple> getMatches();\n\tRule getRule();\n\t// Print a deep traceback of this derivation back to axioms and source assertions.\n\tvoid printTrace(PrintWriter out, boolean bindings);\n}", "des": "Derivation records are used to determine how an inferred triple was derived from a set of source triples and a reasoner."}
{"index": 7040, "repo": "jena-core-4.9.0", "code": "public interface RulePreprocessHook {\n\t// Validate a triple add to see if it should reinvoke the hook.\n\tboolean needsRerun(FBRuleInfGraph infGraph, Triple t);\n\t// Invoke the preprocessing hook.\n\tvoid run(FBRuleInfGraph infGraph, Finder dataFind, Graph inserts);\n}", "des": "Implementors of this interface can be used as preprocessing passes during intialization of (hybrid) rule systems."}
{"index": 7041, "repo": "jena-core-4.9.0", "code": "public interface RuleReasoner extends Reasoner {\n\t// Answer the rules used by this Reasoner.\n\tList<Rule> getRules();\n\t// Set the rules used by this reasoner.\n\tvoid setRules(List<Rule> rules);\n}", "des": "RuleReasoner - an interface to capture the idea of a Reasoner that relies on Rules; motivated primarily by the testing for ModelSpecs which specify Rules for Reasoners."}
{"index": 7042, "repo": "jena-core-4.9.0", "code": "public class RuleStore extends Object {\n\t// Add all the rules and from an existing rulestore into this one.\n\tvoid addAll(RuleStore store);\n\t// Add a single rule to the store.\n\tvoid addRule(Rule rule);\n\t// Delete all the rules.\n\tvoid deleteAllRules();\n\t// Remove a single rule from the store\n\tvoid deleteRule(Rule rule);\n\t// Return an ordered list of all registered rules.\n\tList<Rule> getAllRules();\n\t// Return a list of rules that match the given goal pattern\n\tList<Rule> rulesFor(TriplePattern goal);\n}", "des": "Indexes a collection of rule."}
{"index": 7043, "repo": "jena-core-4.9.0", "code": "public class SafeGraph extends WrappedGraph implements Graph {\n\t// Returns an iterator over Triples matching a pattern.\n\tExtendedIterator<Triple> find(Node s, Node p, Node o);\n\t// Returns an iterator over all the Triples that match the triple pattern.\n\tExtendedIterator<Triple> find(Triple triple);\n\t// Return the unfiltered version of the graph\n\tGraph getRawGraph();\n}", "des": "A SafeGraph wraps a graph which might contain generalized RDF triples and hides them from API queries so that consumers of it are safe (but can use getRawGraph() to get back the unsafe graph."}
{"index": 7044, "repo": "jena-core-4.9.0", "code": "public class SeqNodeIteratorImpl extends NiceIterator<RDFNode> implements NodeIterator {\n\t// default hasNext: no elements, return false.\n\tboolean hasNext();\n\t// default next: throw an exception.\n\tRDFNode next();\n\t// Return the next RDFNode of the iteration.\n\tRDFNode nextNode();\n\t// default remove: we have no elements, so we can't remove any.\n\tvoid remove();\n}", "des": "An internal class not normally of interest to developers."}
{"index": 7045, "repo": "jena-core-4.9.0", "code": "public class SetupJenaIRI extends Object {\n\t// An IRIFactory with more detailed warnings.\n\tstatic IRIFactory iriCheckerFactory();\n\t// The IRI checker setup, focused on parsing and languages.\n\tstatic IRIFactory iriFactory();\n}", "des": "Setup of jena-iri package IRI Factory for parsing and for checking."}
{"index": 7046, "repo": "jena-core-4.9.0", "code": "public interface ShortList extends List {\n\t// Checks if the unsigned short item is a member of this list.\n\tboolean contains(short item);\n\t// The number of unsigned shorts in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection.\n\tshort item(int index);\n}", "des": "The ShortList is an immutable ordered collection of unsigned short."}
{"index": 7047, "repo": "jena-core-4.9.0", "code": "public final class ShortListImpl extends AbstractList implements ShortList {\n\t// Checks if the unsigned short item is a member of this list.\n\tboolean contains(short item);\n\tboolean equals(Object obj);\n\tObject get(int index);\n\t// The number of Objects in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection.\n\tshort item(int index);\n\tint size();\n}", "des": "Contains a list of shorts."}
{"index": 7048, "repo": "jena-core-4.9.0", "code": "public class SingletonIterator<T> extends NiceIterator<T> implements ExtendedIterator<T> {\n\tvoid forEachRemaining(Consumer<? super T> action);\n\t// Can return a single value\n\tboolean hasNext();\n\t// Return the value\n\tT next();\n}", "des": "A ClosableIterator that contains only one element"}
{"index": 7049, "repo": "jena-core-4.9.0", "code": "public class SparseArrayIterator<E> extends NiceIterator<E> implements Iterator<E> {\n\tvoid forEachRemaining(Consumer<? super E> action);\n\t// Returns true if the iteration has more elements.\n\tboolean hasNext();\n\t// Returns the next element in the iteration.\n\tE next();\n}", "des": "An iterator over a sparse array, that skips null entries."}
{"index": 7050, "repo": "jena-core-4.9.0", "code": "public interface StatementBoundary {\n\t// Answer a TripleBoundary corresponding to this StatementBoundary, where Triples may be converted to Statements using m.\n\tTripleBoundary asTripleBoundary(Model m);\n\t// Answer true if this statement is a boundary of the search.\n\tboolean stopAt(Statement s);\n}", "des": "An interface for expressing search boundaries in terms of bounding statements."}
{"index": 7051, "repo": "jena-core-4.9.0", "code": "public interface StatementHandler {\n\t// A triple in the file.\n\tvoid statement(AResource subj, AResource pred, ALiteral lit);\n\t// A triple in the file.\n\tvoid statement(AResource subj, AResource pred, AResource obj);\n}", "des": "The callback from a reader to an RDF application."}
{"index": 7052, "repo": "jena-core-4.9.0", "code": "public interface StatementHandler {\n\t// A triple in the file.\n\tvoid statement(AResource subj, AResource pred, ALiteral lit);\n\t// A triple in the file.\n\tvoid statement(AResource subj, AResource pred, AResource obj);\n}", "des": "The callback from a reader to an RDF application."}
{"index": 7053, "repo": "jena-core-4.9.0", "code": "public class StatementTripleBoundary extends Object implements StatementBoundary {\n\t// Answer the supplied-to-constructor TripleBoundary.\n\tTripleBoundary asTripleBoundary(Model ignored);\n\t// Answer whatever the triple-boundary answers for the triple of s.\n\tboolean stopAt(Statement s);\n}", "des": "StatementTripleBoundary - a StatementBoundary that just wraps a TripleBoundary."}
{"index": 7054, "repo": "jena-core-4.9.0", "code": "public interface StmtIterator extends ExtendedIterator<Statement> {\n\t// Return the next Statement of the iteration.\n\tStatement nextStatement();\n\t// Answer a Model of the [remaining] Statements of this iterator, consuming this iterator.\n\tdefault Model toModel();\n}", "des": "An iterator which returns RDF Statements."}
{"index": 7055, "repo": "jena-core-4.9.0", "code": "public class StmtIteratorImpl extends WrappedIterator<Statement> implements StmtIterator {\n\t// return *and remember* the next element.\n\tStatement next();\n\t// Return the next Statement of the iteration.\n\tStatement nextStatement();\n\t// default remove: we have no elements, so we can't remove any.\n\tvoid remove();\n}", "des": "An implementation of StmtIterator."}
{"index": 7056, "repo": "jena-core-4.9.0", "code": "public class StrConcat extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Builtin which concatenates a set of strings."}
{"index": 7057, "repo": "jena-core-4.9.0", "code": "public interface StringList extends List {\n\t// Checks if the GenericString item is a member of this list.\n\tboolean contains(String item);\n\t// The number of GenericStrings in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tString item(int index);\n}", "des": "The StringList is an immutable ordered collection of GenericString."}
{"index": 7058, "repo": "jena-core-4.9.0", "code": "public final class StringListImpl extends AbstractList implements StringList {\n\t// Checks if the GenericString item is a member of this list.\n\tboolean contains(String item);\n\tObject get(int index);\n\t// The number of Objects in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tString item(int index);\n\tint size();\n\tObject[] toArray();\n\tObject[] toArray(Object[] a);\n}", "des": "Contains a list of Strings."}
{"index": 7059, "repo": "jena-core-4.9.0", "code": "public class Sum extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return the expected number of arguments for this functor or 0 if the number is flexible.\n\tint getArgLength();\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Bind the third arg to the sum of the first two args."}
{"index": 7060, "repo": "jena-core-4.9.0", "code": "public class Table extends BaseBuiltin {\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule body.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n}", "des": "Arrange that the given predicate is tabled by the backchaining engine."}
{"index": 7061, "repo": "jena-core-4.9.0", "code": "public class TableAll extends BaseBuiltin {\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n\t// This method is invoked when the builtin is called in a rule body.\n\tvoid headAction(Node[] args, int length, RuleContext context);\n}", "des": "Arrange that all backchaining goals should be tabled (aka memoized) by the LP engine."}
{"index": 7062, "repo": "jena-core-4.9.0", "code": "public static class TempNodeCache.NodePair extends Object {\n\t// Equality of each component.\n\tboolean equals(Object o);\n\t// Return the first node in the pair.\n\tNode getFirst();\n\t// Return the second node in the pair.\n\tNode getSecond();\n}", "des": "Inner class used to hold and hash a node pair."}
{"index": 7063, "repo": "jena-core-4.9.0", "code": "public class Tokenizer extends Object {\n\t// Test if there are more tokens which can be returned.\n\tboolean hasMoreTokens();\n\t// Return the next token.\n\tString nextToken();\n}", "des": "A tokenizer, similar to java's StringTokenizer but allows for quoted character strings which can include other separators."}
{"index": 7064, "repo": "jena-core-4.9.0", "code": "public class TrackingTripleIterator extends WrappedIterator<Triple> {\n\t// forEachRemaining: defer to the base iterator\n\tvoid forEachRemaining(Consumer<? super Triple> action);\n\t// Answer the next object, remembering it in current.\n\tTriple next();\n}", "des": "A WrappedIterator which remembers the last object next'ed in a protected instance variable, so that subclasses have access to it during .remove."}
{"index": 7065, "repo": "jena-core-4.9.0", "code": "public class TransitiveReasonerFactory extends Object implements ReasonerFactory {\n\t// Constructor method that builds an instance of the associated Reasoner\n\tReasoner create(Resource configuration);\n\t// Return a description of the capabilities of this reasoner encoded in RDF.\n\tModel getCapabilities();\n\t// Return the URI labelling this type of reasoner\n\tString getURI();\n\t// Return the single global instance of this factory\n\tstatic ReasonerFactory theInstance();\n}", "des": "Factory class for creating blank instances of the transitive reasoner."}
{"index": 7066, "repo": "jena-core-4.9.0", "code": "public class TripleMatchFrame extends GenericTripleMatchFrame {\n\t// Override close method to reclaim the iterator.\n\tvoid close();\n\t// Initialize the triple match to preserve the current context of the given LPInterpreter and search for the match defined by the current argument registers\n\tvoid init(LPInterpreter interpreter);\n\t// Find the next result triple and bind the result vars appropriately.\n\tboolean nextMatch(LPInterpreter interpreter);\n}", "des": "Frame on the choice point stack used to represent the state of a direct graph triple match."}
{"index": 7067, "repo": "jena-core-4.9.0", "code": "public class Unbound extends BaseBuiltin {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Predicate used to check if a variable has not been bound."}
{"index": 7068, "repo": "jena-core-4.9.0", "code": "public class Union extends Dyadic implements Graph {\n\tboolean graphBaseContains(Triple t);\n\t// To add a triple to the union, add it to the left operand; this is asymmetric.\n\tvoid performAdd(Triple t);\n\t// To remove a triple, remove it from both operands.\n\tvoid performDelete(Triple t);\n}", "des": "A class representing the dynamic union of two graphs."}
{"index": 7069, "repo": "jena-core-4.9.0", "code": "public class UnsupportedPolymorphismException extends JenaException {\n\t// Answer the class that the node couldn't be polymorphed to\n\tClass<?> getBadClass();\n\t// Answer the node that couldn't be polymorphed.\n\tObject getBadNode();\n}", "des": "Exception to throw if an enhanced graph does not support polymorphism to a specific class."}
{"index": 7070, "repo": "jena-core-4.9.0", "code": "public class UriConcat extends StrConcat {\n\t// This method is invoked when the builtin is called in a rule body.\n\tboolean bodyCall(Node[] args, int length, RuleContext context);\n\t// Return a name for this builtin, normally this will be the name of the functor that will be used to invoke it.\n\tString getName();\n}", "des": "Builtin which concatenates a set of strings to generate a new URI."}
{"index": 7071, "repo": "jena-core-4.9.0", "code": "public class URIref extends Object {\n\t// Convert a URI, in US-ASCII, with escaped characters taken from UTF-8, to the corresponding Unicode string.\n\tstatic String decode(String uri);\n\t// Convert a Unicode string, first to UTF-8 and then to an RFC 2396 compliant URI with optional fragment identifier using %NN escape mechanism as appropriate.\n\tstatic String encode(String unicode);\n}", "des": "This class provides methods to encode and decode URI References in accordance with http://www.w3.org/TR/charmod/#sec-URIs ."}
{"index": 7072, "repo": "jena-core-4.9.0", "code": "public class ValidationManager extends Object {\n\t// Each validator should call this method to add its ValidationState into the validation manager.\n\tfinal void addValidationState(ValidationState vs);\n\tfinal boolean isCachedDTD();\n\tfinal boolean isGrammarFound();\n\tfinal void reset();\n\tfinal void setCachedDTD(boolean cachedDTD);\n\t// Set the information required to validate entity values.\n\tfinal void setEntityState(EntityState state);\n\tfinal void setGrammarFound(boolean grammar);\n}", "des": "ValidationManager is a coordinator property for validators in the pipeline."}
{"index": 7073, "repo": "jena-core-4.9.0", "code": "public interface ValidityReport {\n\t// Return an iterator over the separate ValidityReport.Report records.\n\tIterator<ValidityReport.Report> getReports();\n\t// Returns true if the model is both valid (logically consistent) and no warnings were generated.\n\tboolean isClean();\n\t// Returns true if no logical inconsistencies were detected.\n\tboolean isValid();\n}", "des": "Data structure used to report the results of validation or consistency checking operations."}
{"index": 7074, "repo": "jena-core-4.9.0", "code": "public final class WrappedReasonerFactory extends Object implements ReasonerFactory {\n\t// Answer a Reasoner created according to the underlying factory, and then loaded with this Wrapper's rules (if the Reasoner is a RuleReasoner) and bound to this Wrapper's schemas (in an unspecified order).\n\tReasoner create(Resource ignored);\n\t// Answer the capabilities of the underlying ReasonerFactory.\n\tModel getCapabilities();\n\t// Answer the URI of the underlying ReasonerFactory.\n\tString getURI();\n}", "des": "WrappedReasonerFactory - a wrapper round ReasonerFactories that accepts a Resource configuring initial rules, schemas, etc."}
{"index": 7075, "repo": "jena-core-4.9.0", "code": "public class XMLLiteralType extends BaseDatatype implements RDFDatatype {\n\t// Test whether the given string is a legal lexical form of this datatype.\n\tboolean isValid(String lexicalForm);\n\t// Parse a lexical form of this datatype to a value\n\tObject parse(String lexicalForm);\n\t// Convert a serialize a value of this datatype out to lexical form.\n\tString unparse(Object value);\n}", "des": "Builtin data type to represent XMLLiteral (i.e."}
{"index": 7076, "repo": "jena-core-4.9.0", "code": "public class XMLLiteralType0 extends BaseDatatype implements RDFDatatype {\n\t// Test whether the given string is a legal lexical form of this datatype.\n\tboolean isValid(String lexicalForm);\n\t// Parse a lexical form of this datatype to a value\n\tObject parse(String lexicalForm);\n\t// Convert a serialize a value of this datatype out to lexical form.\n\tString unparse(Object value);\n}", "des": "Builtin data type to represent XMLLiteral (i.e."}
{"index": 7077, "repo": "jena-core-4.9.0", "code": "public interface XSAnnotation extends XSObject {\n\t// A text representation of the annotation.\n\tString getAnnotationString();\n\t// Write contents of the annotation to the specified object.\n\tboolean writeAnnotation(Object target, short targetType);\n}", "des": "This interface represents the Annotation schema component."}
{"index": 7078, "repo": "jena-core-4.9.0", "code": "public interface XSAttributeGroupDefinition extends XSObject {\n\t// An annotation if it exists, otherwise null.\n\tXSAnnotation getAnnotation();\n\t// A sequence of [annotations] or an empty XSObjectList.\n\tXSObjectList getAnnotations();\n\t// A set of [attribute uses] if it exists, otherwise an empty XSObjectList.\n\tXSObjectList getAttributeUses();\n\t// A [wildcard] if it exists, otherwise null.\n\tXSWildcard getAttributeWildcard();\n}", "des": "This interface represents the Attribute Group Definition schema component."}
{"index": 7079, "repo": "jena-core-4.9.0", "code": "public abstract class XSDbinary extends XSDDatatype {\n\t// Default implementation of getHashCode() delegates to the default from the literal label.\n\tint getHashCode(LiteralLabel lit);\n\t// Compares two instances of values of the given datatype.\n\tboolean isEqual(LiteralLabel value1, LiteralLabel value2);\n\t// Test whether the given object is a legal value form of this datatype.\n\tboolean isValidValue(Object valueForm);\n}", "des": "Root class for XSD datatypes with binary values, xsd:hexBinary and xsd:base64Binary."}
{"index": 7080, "repo": "jena-core-4.9.0", "code": "public class XSDTimeType extends XSDAbstractDateTimeType {\n\t// Parse a validated date.\n\tObject parseValidated(String str);\n\t// Convert a value of this datatype out to lexical form.\n\tString unparse(Object value);\n}", "des": "Type processor for time, most of the machinery is in the base XSDAbstractDateTimeType class."}
{"index": 7081, "repo": "jena-core-4.9.0", "code": "public interface XSImplementation {\n\t// Creates an immutable LSInputList from the given array of LSInputs.\n\tLSInputList createLSInputList(LSInput[] values);\n\t// Creates an immutable StringList from the given array of Strings.\n\tStringList createStringList(String[] values);\n\t// Creates a new XSLoader.\n\tXSLoader createXSLoader(StringList versions);\n\t// A list containing the versions of XML Schema documents recognized by this XSImplemenation.\n\tStringList getRecognizedVersions();\n}", "des": "This interface allows one to retrieve an instance of XSLoader."}
{"index": 7082, "repo": "jena-core-4.9.0", "code": "public interface XSModelGroup extends XSTerm {\n\t// An annotation if it exists, otherwise null.\n\tXSAnnotation getAnnotation();\n\t// A sequence of [annotations] or an empty XSObjectList.\n\tXSObjectList getAnnotations();\n\t// [compositor]: one of all, choice or sequence.\n\tshort getCompositor();\n\t// A list of [particles] if it exists, otherwise an empty XSObjectList.\n\tXSObjectList getParticles();\n}", "des": "This interface represents the Model Group schema component."}
{"index": 7083, "repo": "jena-core-4.9.0", "code": "public interface XSModelGroupDefinition extends XSObject {\n\t// An annotation if it exists, otherwise null.\n\tXSAnnotation getAnnotation();\n\t// A sequence of [annotations] or an empty XSObjectList.\n\tXSObjectList getAnnotations();\n\t// A model group.\n\tXSModelGroup getModelGroup();\n}", "des": "This interface represents the Model Group Definition schema component."}
{"index": 7084, "repo": "jena-core-4.9.0", "code": "public interface XSMultiValueFacet extends XSObject {\n\t// A sequence of [annotations] or an empty XSObjectList.\n\tXSObjectList getAnnotations();\n\t// A list of XSValue objects.\n\tObjectList getEnumerationValues();\n\t// The name of the facet, i.e.\n\tshort getFacetKind();\n\t// Values of this facet.\n\tStringList getLexicalFacetValues();\n}", "des": "Describes a multi-value constraining facets: pattern and enumeration."}
{"index": 7085, "repo": "jena-core-4.9.0", "code": "public interface XSNamedMap extends Map {\n\t// The number of XSObjects in the XSObjectList.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tXSObject item(int index);\n\t// Retrieves an XSObject specified by local name and namespace URI.\n\tXSObject itemByName(String namespace, String localName);\n}", "des": "Objects implementing the XSNamedMap interface are used to represent immutable collections of XML Schema components that can be accessed by name."}
{"index": 7086, "repo": "jena-core-4.9.0", "code": "public interface XSNamespaceItemList extends List {\n\t// The number of XSNamespaceItems in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tXSNamespaceItem item(int index);\n}", "des": "The XSNamesaceItemList interface provides the abstraction of an immutable ordered collection of XSNamespaceItems, without defining or constraining how this collection is implemented."}
{"index": 7087, "repo": "jena-core-4.9.0", "code": "public interface XSNotationDeclaration extends XSObject {\n\t// An annotation if it exists, otherwise null.\n\tXSAnnotation getAnnotation();\n\t// A sequence of [annotations] or an empty XSObjectList.\n\tXSObjectList getAnnotations();\n\t// The string representing the public identifier for this notation declaration, if present; null otherwise.\n\tString getPublicId();\n\t// The URI reference representing the system identifier for the notation declaration, if present, null otherwise.\n\tString getSystemId();\n}", "des": "This interface represents the Notation Declaration schema component."}
{"index": 7088, "repo": "jena-core-4.9.0", "code": "public interface XSObjectList extends List {\n\t// The number of XSObjects in the list.\n\tint getLength();\n\t// Returns the indexth item in the collection or null if index is greater than or equal to the number of objects in the list.\n\tXSObject item(int index);\n}", "des": "The XSObjectList interface provides the abstraction of an immutable ordered collection of XSObjects, without defining or constraining how this collection is implemented."}
{"index": 7089, "repo": "jena-core-4.9.0", "code": "public interface XSParticle extends XSObject {\n\t// A sequence of [annotations] or an empty XSObjectList.\n\tXSObjectList getAnnotations();\n\t// [max occurs]: determines the maximum number of terms that can occur.\n\tint getMaxOccurs();\n\t// [max occurs]: whether the maxOccurs value is unbounded.\n\tboolean getMaxOccursUnbounded();\n\t// [min occurs]: determines the minimum number of terms that can occur.\n\tint getMinOccurs();\n\t// [term]: one of a model group, a wildcard, or an element declaration.\n\tXSTerm getTerm();\n}", "des": "This interface represents the Particle schema component."}
{"index": 7090, "repo": "spring-cloud-config-server-3.1.8", "code": "public static enum ProxyHostProperties.ProxyForScheme extends Enum<ProxyHostProperties.ProxyForScheme> {\n\tstatic ProxyHostProperties.ProxyForScheme forLowerCaseName(String lowerCaseName);\n\tString lowercaseName();\n\t// Returns the enum constant of this type with the specified name.\n\tstatic ProxyHostProperties.ProxyForScheme valueOf(String name);\n\t// Returns an array containing the constants of this enum type, in the order they are declared.\n\tstatic ProxyHostProperties.ProxyForScheme[] values();\n}", "des": "Proxy for a given scheme."}
{"index": 7091, "repo": "spring-boot-cli-3.1.1", "code": "public abstract class AbstractCommand extends Object implements Command {\n\t// Returns a description of the command.\n\tString getDescription();\n\t// Return some examples for the command.\n\tCollection<HelpExample> getExamples();\n\t// Gets full help text for the command, e.g.\n\tString getHelp();\n\t// Returns the name of the command.\n\tString getName();\n\t// Returns help for each supported option.\n\tCollection<OptionHelp> getOptionsHelp();\n\t// Returns usage help for the command.\n\tString getUsageHelp();\n}", "des": "Abstract Command implementation."}
{"index": 7092, "repo": "spring-boot-cli-3.1.1", "code": "public interface Command {\n\t// Returns a description of the command.\n\tString getDescription();\n\t// Return some examples for the command.\n\tCollection<HelpExample> getExamples();\n\t// Gets full help text for the command, e.g.\n\tString getHelp();\n\t// Returns the name of the command.\n\tString getName();\n\t// Returns help for each supported option.\n\tCollection<OptionHelp> getOptionsHelp();\n\t// Returns usage help for the command.\n\tString getUsageHelp();\n\t// Run the command.\n\tExitStatus run(String... args);\n}", "des": "A single command that can be run from the CLI."}
{"index": 7093, "repo": "spring-boot-cli-3.1.1", "code": "public static enum CommandException.Option extends Enum<CommandException.Option> {\n\t// Returns the enum constant of this class with the specified name.\n\tstatic CommandException.Option valueOf(String name);\n\t// Returns an array containing the constants of this enum class, in the order they are declared.\n\tstatic CommandException.Option[] values();\n}", "des": "Specific options understood by the CommandRunner."}
{"index": 7094, "repo": "spring-boot-cli-3.1.1", "code": "public class EncodePasswordCommand extends OptionParsingCommand {\n\t// Return some examples for the command.\n\tCollection<HelpExample> getExamples();\n\t// Returns usage help for the command.\n\tString getUsageHelp();\n}", "des": "Command to encode passwords for use with Spring Security."}
{"index": 7095, "repo": "spring-boot-cli-3.1.1", "code": "public final class ExitStatus extends Object {\n\t// An exit code appropriate for use in System.exit().\n\tint getCode();\n\t// A name describing the outcome.\n\tString getName();\n\t// Convert the existing code to a hangup.\n\tExitStatus hangup();\n\t// Flag to signal that the caller can (or should) hangup.\n\tboolean isHangup();\n}", "des": "Encapsulation of the outcome of a command."}
{"index": 7096, "repo": "spring-boot-cli-3.1.1", "code": "public class HelpCommand extends AbstractCommand {\n\t// Gets full help text for the command, e.g.\n\tString getHelp();\n\t// Returns help for each supported option.\n\tCollection<OptionHelp> getOptionsHelp();\n\t// Returns usage help for the command.\n\tString getUsageHelp();\n\t// Run the command.\n\tExitStatus run(String... args);\n}", "des": "Internal Command used for 'help' requests."}
{"index": 7097, "repo": "spring-boot-cli-3.1.1", "code": "public class InitCommand extends OptionParsingCommand {\n\t// Return some examples for the command.\n\tCollection<HelpExample> getExamples();\n\t// Returns usage help for the command.\n\tString getUsageHelp();\n}", "des": "Command that initializes a project using Spring initializr."}
{"index": 7098, "repo": "spring-boot-cli-3.1.1", "code": "public interface OptionHelp {\n\t// Returns the set of options that are mutually synonymous.\n\tSet<String> getOptions();\n\t// Returns usage help for the option.\n\tString getUsageHelp();\n}", "des": "Help for a specific option."}
{"index": 7099, "repo": "spring-boot-cli-3.1.1", "code": "public abstract class OptionParsingCommand extends AbstractCommand {\n\tprotected OptionHandler getHandler();\n\t// Gets full help text for the command, e.g.\n\tString getHelp();\n\t// Returns help for each supported option.\n\tCollection<OptionHelp> getOptionsHelp();\n\t// Run the command.\n\tfinal ExitStatus run(String... args);\n}", "des": "Base class for a Command that parse options using an OptionHandler."}
{"index": 7100, "repo": "spring-boot-cli-3.1.1", "code": "public class Shell extends Object {\n\t// Final handle an interrupt signal (CTRL-C).\n\tprotected void handleSigInt();\n\t// Run the shell until the user exists.\n\tvoid run();\n}", "des": "A shell for Spring Boot."}
{"index": 7101, "repo": "spring-boot-cli-3.1.1", "code": "public class ShellPrompts extends Object {\n\t// Returns the current prompt.\n\tString getPrompt();\n\t// Pop a previously pushed prompt, returning to the previous value.\n\tvoid popPrompt();\n\t// Push a new prompt to be used by the shell.\n\tvoid pushPrompt(String prompt);\n}", "des": "Abstraction to manage a stack of prompts."}
{"index": 7102, "repo": "spring-oxm-6.0.11", "code": "public interface Marshaller {\n\t// Marshal the object graph with the given root into the provided Result.\n\tvoid marshal(Object graph, Result result);\n\t// Indicate whether this marshaller can marshal instances of the supplied type.\n\tboolean supports(Class<?> clazz);\n}", "des": "Defines the contract for Object XML Mapping Marshallers."}
{"index": 7103, "repo": "spring-oxm-6.0.11", "code": "public class MarshallingSource extends SAXSource {\n\t// Return the object to be marshalled.\n\tObject getContent();\n\t// Return the Marshaller used by this MarshallingSource.\n\tMarshaller getMarshaller();\n\t// Throws a UnsupportedOperationException.\n\tvoid setInputSource(InputSource inputSource);\n\t// Throws a UnsupportedOperationException.\n\tvoid setXMLReader(XMLReader reader);\n}", "des": "Source implementation that uses a Marshaller.Can be constructed with a Marshaller and an object to be marshalled."}
{"index": 7104, "repo": "spring-oxm-6.0.11", "code": "public interface MimeContainer {\n\t// Add the given data handler as an attachment to this container.\n\tvoid addAttachment(String contentId, DataHandler dataHandler);\n\t// Turn this message into a XOP package.\n\tboolean convertToXopPackage();\n\t// Return the attachment with the given content id, or null if not found.\n\tDataHandler getAttachment(String contentId);\n\t// Indicate whether this container is a XOP package.\n\tboolean isXopPackage();\n}", "des": "Represents a container for MIME attachments Concrete implementations might adapt a SOAPMessage or an email message."}
{"index": 7105, "repo": "spring-oxm-6.0.11", "code": "public interface Unmarshaller {\n\t// Indicate whether this unmarshaller can unmarshal instances of the supplied type.\n\tboolean supports(Class<?> clazz);\n\t// Unmarshal the given Source into an object graph.\n\tObject unmarshal(Source source);\n}", "des": "Defines the contract for Object XML Mapping unmarshallers."}
{"index": 7106, "repo": "spring-integration-mqtt-6.1.2", "code": "public interface ClientManager<T,C> extends org.springframework.context.SmartLifecycle, MqttComponent<C> {\n\t// Register a callback for the connectComplete event from the client.\n\tvoid addCallback(ClientManager.ConnectCallback connectCallback);\n\t// Return the managed client.\n\tT getClient();\n\t// If manual acknowledge has to be used; false by default.\n\tboolean isManualAcks();\n\t// Remove the callback from registration.\n\tboolean removeCallback(ClientManager.ConnectCallback connectCallback);\n}", "des": "A utility abstraction over MQTT client which can be used in any MQTT-related component without need to handle generic client callbacks, reconnects etc."}
{"index": 7107, "repo": "spring-integration-mqtt-6.1.2", "code": "public interface MqttComponent<T> extends org.springframework.beans.factory.BeanNameAware {\n\t// Return this component's bean name.\n\tString getBeanName();\n\t// Return information about the connection.\n\tT getConnectionInfo();\n}", "des": "A component that interfaces with MQTT."}
{"index": 7108, "repo": "spring-data-couchbase-5.1.2", "code": "public class AuditingEntityCallback extends Object implements BeforeConvertCallback<Object>, AfterConvertCallback<Object>, Ordered {\n\tint getOrder();\n\t// Entity callback method invoked after a domain object is materialized from a CouchbaseDocument.\n\tObject onAfterConvert(Object entity, CouchbaseDocument document, String collection);\n\t// Entity callback method invoked before a domain object is converted to be persisted.\n\tObject onBeforeConvert(Object entity, String collection);\n}", "des": "EntityCallback to populate auditing related fields on an entity about to be saved."}
{"index": 7109, "repo": "spring-data-couchbase-5.1.2", "code": "public class BasicCouchbasePersistentProperty extends AnnotationBasedPersistentProperty<CouchbasePersistentProperty> implements CouchbasePersistentProperty {\n\t// Creates a new Association.\n\tprotected Association<CouchbasePersistentProperty> createAssociation();\n\t// Returns the field name of the property.\n\tString getFieldName();\n\tboolean isExpirationProperty();\n\tboolean isIdProperty();\n}", "des": "Implements annotated property representations of a given Field instance."}
{"index": 7110, "repo": "spring-data-couchbase-5.1.2", "code": "public class BasicQuery extends Query {\n\tboolean equals(Object o);\n\tboolean isReadonly();\n\tboolean isSorted();\n\t// Set the fields (projection) CouchbaseDocument.\n\tvoid setProjectionFields(Map<String,String> projectionFields);\n\t// Set the sort CouchbaseDocument.\n\tvoid setSort(Sort sort);\n}", "des": "BasicQuery for Querydsl"}
{"index": 7111, "repo": "spring-data-couchbase-5.1.2", "code": "@FunctionalInterface public interface CacheKeyPrefix {\n\t// Compute the prefix for the actual key stored in Couchbase.\n\tString compute(String cacheName);\n\t// Creates a CacheKeyPrefix scheme that prefixes cache keys with the given prefix.\n\tstatic CacheKeyPrefix prefixed(String prefix);\n\t// Creates a default CacheKeyPrefix scheme that prefixes cache keys with cacheName followed by double colons.\n\tstatic CacheKeyPrefix simple();\n}", "des": "CacheKeyPrefix provides a hook for creating custom prefixes prepended to the actual key stored in Couchbase."}
{"index": 7112, "repo": "spring-data-couchbase-5.1.2", "code": "public class CouchbaseDocumentPropertyAccessor extends MapAccessor {\n\t// It can always read from those properties.\n\tboolean canRead(EvaluationContext context, Object target, String name);\n\t// Returns the target classes of the properties.\n\tClass<?>[] getSpecificTargetClasses();\n\t// Read the value from the property.\n\tTypedValue read(EvaluationContext context, Object target, String name);\n}", "des": "A property accessor for document properties."}
{"index": 7113, "repo": "spring-data-couchbase-5.1.2", "code": "public class CouchbaseRepositoryBase<T,ID> extends Object {\n\t// Get the Collection from 1.\n\tprotected String getCollection();\n\t// Returns the information for the underlying template.\n\tCouchbaseEntityInformation<T,String> getEntityInformation();\n\tClass<?> getRepositoryInterface();\n\t// Get the Scope from 1.\n\tprotected String getScope();\n}", "des": "Common base for SimpleCouchbaseRepository and SimpleReactiveCouchbaseRepository"}
{"index": 7114, "repo": "spring-data-couchbase-5.1.2", "code": "public interface ExecutableExistsByIdOperation {\n\t// Deprecated.\n\tExecutableExistsByIdOperation.ExecutableExistsById existsById();\n\t// Checks if the document exists in the bucket.\n\tExecutableExistsByIdOperation.ExecutableExistsById existsById(Class<?> domainType);\n}", "des": "Insert Operations"}
{"index": 7115, "repo": "spring-data-couchbase-5.1.2", "code": "public static interface ExecutableExistsByIdOperation.TerminatingExistsById extends OneAndAllExists {\n\t// Performs the operation on the collection of ids.\n\tMap<String,Boolean> all(Collection<String> ids);\n\t// Performs the operation on the ID given.\n\tboolean one(String id);\n}", "des": "Terminating operations invoking the actual execution."}
{"index": 7116, "repo": "spring-data-couchbase-5.1.2", "code": "public static interface ExecutableFindByIdOperation.TerminatingFindById<T> extends OneAndAllId<T> {\n\t// Finds a list of documents based on the given IDs.\n\tCollection<? extends T> all(Collection<String> ids);\n\t// Finds one document based on the given ID.\n\tT one(String id);\n}", "des": "Terminating operations invoking the actual execution."}
{"index": 7117, "repo": "spring-data-couchbase-5.1.2", "code": "public static interface ExecutableFindByQueryOperation.FindByQueryWithQuery<T> extends ExecutableFindByQueryOperation.TerminatingFindByQuery<T>, WithQuery<T> {\n\t// Set the filter for the query to be used.\n\tExecutableFindByQueryOperation.TerminatingFindByQuery<T> matching(Query query);\n\t// Set the filter criteria to be used.\n\tdefault ExecutableFindByQueryOperation.TerminatingFindByQuery<T> matching(QueryCriteriaDefinition criteria);\n}", "des": "Fluent methods to specify the query"}
{"index": 7118, "repo": "spring-data-couchbase-5.1.2", "code": "public static interface ExecutableFindFromReplicasByIdOperation.TerminatingFindFromReplicasById<T> extends AnyId<T> {\n\t// Finds one document based on the given ID.\n\tT any(String id);\n\t// Finds a list of documents based on the given IDs.\n\tCollection<? extends T> any(Collection<String> ids);\n}", "des": "Terminating operations invoking the actual get execution."}
{"index": 7119, "repo": "spring-data-couchbase-5.1.2", "code": "public static interface ExecutableInsertByIdOperation.TerminatingInsertById<T> extends OneAndAllEntity<T> {\n\t// Insert a collection of entities.\n\tCollection<? extends T> all(Collection<? extends T> objects);\n\t// Insert one entity.\n\tT one(T object);\n}", "des": "Terminating operations invoking the actual execution."}
